{"id": "2511.14966", "categories": ["cs.DC", "cs.MS", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.14966", "abs": "https://arxiv.org/abs/2511.14966", "authors": ["David L. Cole", "Jordan Jalving", "Jonah Langlieb", "Jesse D. Jenkins"], "title": "A Graph-Based, Distributed Memory, Modeling Abstraction for Optimization", "comment": "32 pages, 7 Figures", "summary": "We present a general, flexible modeling abstraction for building and working with distributed optimization problems called a RemoteOptiGraph. This abstraction extends the OptiGraph model in Plasmo.jl, where optimization problems are represented as hypergraphs with nodes that define modular subproblems (variables, constraints, and objectives) and edges that encode algebraic linking constraints between nodes. The RemoteOptiGraph allows OptiGraphs to be utilized in distributed memory environments through InterWorkerEdges, which manage linking constraints that span workers. This abstraction offers a unified approach for modeling optimization problems on distributed memory systems (avoiding bespoke modeling approaches), and provides a basis for developing general-purpose meta-algorithms that can exploit distributed memory structure such as Benders or Lagrangian decompositions. We implement this abstraction in the open-source package, Plasmo.jl and we illustrate how it can be used by solving a mixed integer capacity expansion model for the western United States containing over 12 million variables and constraints. The RemoteOptiGraph abstraction together with Benders decomposition performs 7.5 times faster than solving the same problem without decomposition.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRemoteOptiGraph\u7684\u5206\u5e03\u5f0f\u4f18\u5316\u5efa\u6a21\u62bd\u8c61\uff0c\u6269\u5c55\u4e86Plasmo.jl\u4e2d\u7684OptiGraph\u6a21\u578b\uff0c\u652f\u6301\u5206\u5e03\u5f0f\u5185\u5b58\u73af\u5883\u4e0b\u7684\u4f18\u5316\u95ee\u9898\u5efa\u6a21\u548c\u6c42\u89e3\u3002", "motivation": "\u4e3a\u5206\u5e03\u5f0f\u5185\u5b58\u7cfb\u7edf\u63d0\u4f9b\u7edf\u4e00\u7684\u4f18\u5316\u95ee\u9898\u5efa\u6a21\u65b9\u6cd5\uff0c\u907f\u514d\u5b9a\u5236\u5316\u5efa\u6a21\u65b9\u5f0f\uff0c\u5e76\u4e3a\u5f00\u53d1\u901a\u7528\u5143\u7b97\u6cd5\uff08\u5982Benders\u6216\u62c9\u683c\u6717\u65e5\u5206\u89e3\uff09\u63d0\u4f9b\u57fa\u7840\u3002", "method": "\u901a\u8fc7InterWorkerEdges\u7ba1\u7406\u8de8\u5de5\u4f5c\u8282\u70b9\u7684\u94fe\u63a5\u7ea6\u675f\uff0c\u4f7fOptiGraph\u80fd\u591f\u5728\u5206\u5e03\u5f0f\u5185\u5b58\u73af\u5883\u4e2d\u4f7f\u7528\uff0c\u5728Plasmo.jl\u5f00\u6e90\u5305\u4e2d\u5b9e\u73b0\u8be5\u62bd\u8c61\u3002", "result": "\u4f7f\u7528\u8be5\u62bd\u8c61\u6c42\u89e3\u7f8e\u56fd\u897f\u90e8\u6df7\u5408\u6574\u6570\u5bb9\u91cf\u6269\u5c55\u6a21\u578b\uff08\u8d85\u8fc71200\u4e07\u4e2a\u53d8\u91cf\u548c\u7ea6\u675f\uff09\uff0c\u7ed3\u5408Benders\u5206\u89e3\u6bd4\u65e0\u5206\u89e3\u6c42\u89e3\u5feb7.5\u500d\u3002", "conclusion": "RemoteOptiGraph\u62bd\u8c61\u4e3a\u5206\u5e03\u5f0f\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u901a\u7528\u4e14\u7075\u6d3b\u7684\u5efa\u6a21\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u4f18\u5316\u95ee\u9898\u7684\u6c42\u89e3\u6548\u7387\u3002"}}
{"id": "2511.14908", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14908", "abs": "https://arxiv.org/abs/2511.14908", "authors": ["Geft\u00e9 Almeida", "Marcio Pohlmann", "Alex Severo", "Diego Kreutz", "Tiago Heinrich", "Louren\u00e7o Pereira"], "title": "On-Premise SLMs vs. Commercial LLMs: Prompt Engineering and Incident Classification in SOCs and CSIRTs", "comment": "5 pages, 3 figures, 3 tables, submitted to ERRC/WRSeg 2025", "summary": "In this study, we evaluate open-source models for security incident classification, comparing them with proprietary models. We utilize a dataset of anonymized real incidents, categorized according to the NIST SP 800-61r3 taxonomy and processed using five prompt-engineering techniques (PHP, SHP, HTP, PRP, and ZSL). The results indicate that, although proprietary models still exhibit higher accuracy, locally deployed open-source models provide advantages in privacy, cost-effectiveness, and data sovereignty.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u5f00\u6e90\u6a21\u578b\u5728\u5b89\u5168\u4e8b\u4ef6\u5206\u7c7b\u4e2d\u7684\u8868\u73b0\uff0c\u4e0e\u4e13\u6709\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u3002\u4f7f\u7528\u57fa\u4e8eNIST SP 800-61r3\u5206\u7c7b\u6cd5\u7684\u533f\u540d\u771f\u5b9e\u4e8b\u4ef6\u6570\u636e\u96c6\uff0c\u91c7\u7528\u4e94\u79cd\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u5904\u7406\u3002\u7ed3\u679c\u663e\u793a\u4e13\u6709\u6a21\u578b\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u4f46\u5f00\u6e90\u6a21\u578b\u5728\u9690\u79c1\u4fdd\u62a4\u3001\u6210\u672c\u6548\u76ca\u548c\u6570\u636e\u4e3b\u6743\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002", "motivation": "\u8bc4\u4f30\u5f00\u6e90\u6a21\u578b\u5728\u5b89\u5168\u4e8b\u4ef6\u5206\u7c7b\u4e2d\u7684\u6027\u80fd\uff0c\u63a2\u7d22\u5176\u5728\u9690\u79c1\u4fdd\u62a4\u3001\u6210\u672c\u6548\u76ca\u548c\u6570\u636e\u4e3b\u6743\u65b9\u9762\u7684\u6f5c\u5728\u4f18\u52bf\uff0c\u4e3a\u7ec4\u7ec7\u5728\u9009\u62e9\u5b89\u5168\u4e8b\u4ef6\u5206\u7c7b\u89e3\u51b3\u65b9\u6848\u65f6\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eNIST SP 800-61r3\u5206\u7c7b\u6cd5\u7684\u533f\u540d\u771f\u5b9e\u5b89\u5168\u4e8b\u4ef6\u6570\u636e\u96c6\uff0c\u91c7\u7528\u4e94\u79cd\u63d0\u793a\u5de5\u7a0b\u6280\u672f\uff08PHP\u3001SHP\u3001HTP\u3001PRP\u548cZSL\uff09\u8fdb\u884c\u5904\u7406\uff0c\u5bf9\u6bd4\u5f00\u6e90\u6a21\u578b\u4e0e\u4e13\u6709\u6a21\u578b\u7684\u5206\u7c7b\u6027\u80fd\u3002", "result": "\u4e13\u6709\u6a21\u578b\u5728\u51c6\u786e\u7387\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u4f46\u5f00\u6e90\u6a21\u578b\u5728\u672c\u5730\u90e8\u7f72\u65f6\u5728\u9690\u79c1\u4fdd\u62a4\u3001\u6210\u672c\u6548\u76ca\u548c\u6570\u636e\u4e3b\u6743\u65b9\u9762\u5177\u6709\u660e\u663e\u4f18\u52bf\u3002", "conclusion": "\u867d\u7136\u4e13\u6709\u6a21\u578b\u5728\u51c6\u786e\u7387\u4e0a\u4ecd\u6709\u4f18\u52bf\uff0c\u4f46\u5f00\u6e90\u6a21\u578b\u4e3a\u6ce8\u91cd\u9690\u79c1\u3001\u6210\u672c\u63a7\u5236\u548c\u6570\u636e\u4e3b\u6743\u7684\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u672c\u5730\u90e8\u7f72\u573a\u666f\u4e0b\u3002"}}
{"id": "2511.14937", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14937", "abs": "https://arxiv.org/abs/2511.14937", "authors": ["Niloofar Mireshghallah", "Neal Mangaokar", "Narine Kokhlikyan", "Arman Zharmagambetov", "Manzil Zaheer", "Saeed Mahloujifar", "Kamalika Chaudhuri"], "title": "CIMemories: A Compositional Benchmark for Contextual Integrity of Persistent Memory in LLMs", "comment": null, "summary": "Large Language Models (LLMs) increasingly use persistent memory from past interactions to enhance personalization and task performance. However, this memory introduces critical risks when sensitive information is revealed in inappropriate contexts. We present CIMemories, a benchmark for evaluating whether LLMs appropriately control information flow from memory based on task context. CIMemories uses synthetic user profiles with over 100 attributes per user, paired with diverse task contexts in which each attribute may be essential for some tasks but inappropriate for others. Our evaluation reveals that frontier models exhibit up to 69% attribute-level violations (leaking information inappropriately), with lower violation rates often coming at the cost of task utility. Violations accumulate across both tasks and runs: as usage increases from 1 to 40 tasks, GPT-5's violations rise from 0.1% to 9.6%, reaching 25.1% when the same prompt is executed 5 times, revealing arbitrary and unstable behavior in which models leak different attributes for identical prompts. Privacy-conscious prompting does not solve this - models overgeneralize, sharing everything or nothing rather than making nuanced, context-dependent decisions. These findings reveal fundamental limitations that require contextually aware reasoning capabilities, not just better prompting or scaling.", "AI": {"tldr": "CIMemories\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30LLMs\u5728\u4efb\u52a1\u4e0a\u4e0b\u6587\u4e2d\u63a7\u5236\u8bb0\u5fc6\u4fe1\u606f\u6d41\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u524d\u6cbf\u6a21\u578b\u5b58\u5728\u9ad8\u8fbe69%\u7684\u5c5e\u6027\u7ea7\u8fdd\u89c4\uff08\u4e0d\u5f53\u6cc4\u9732\u4fe1\u606f\uff09\uff0c\u4e14\u8fdd\u89c4\u7387\u968f\u4efb\u52a1\u6570\u91cf\u589e\u52a0\u800c\u4e0a\u5347\uff0c\u9690\u79c1\u63d0\u793a\u65e0\u6cd5\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "motivation": "\u968f\u7740LLMs\u8d8a\u6765\u8d8a\u591a\u5730\u4f7f\u7528\u6301\u4e45\u8bb0\u5fc6\u6765\u589e\u5f3a\u4e2a\u6027\u5316\u548c\u4efb\u52a1\u6027\u80fd\uff0c\u8fd9\u79cd\u8bb0\u5fc6\u5728\u4e0d\u5f53\u4e0a\u4e0b\u6587\u4e2d\u6cc4\u9732\u654f\u611f\u4fe1\u606f\u5e26\u6765\u4e86\u5173\u952e\u98ce\u9669\uff0c\u9700\u8981\u8bc4\u4f30LLMs\u662f\u5426\u80fd\u57fa\u4e8e\u4efb\u52a1\u4e0a\u4e0b\u6587\u9002\u5f53\u63a7\u5236\u4fe1\u606f\u6d41\u3002", "method": "\u4f7f\u7528\u5305\u542b\u6bcf\u4e2a\u7528\u6237100\u591a\u4e2a\u5c5e\u6027\u7684\u5408\u6210\u7528\u6237\u914d\u7f6e\u6587\u4ef6\uff0c\u7ed3\u5408\u591a\u6837\u5316\u7684\u4efb\u52a1\u4e0a\u4e0b\u6587\uff0c\u5176\u4e2d\u6bcf\u4e2a\u5c5e\u6027\u5728\u67d0\u4e9b\u4efb\u52a1\u4e2d\u53ef\u80fd\u662f\u5fc5\u9700\u7684\uff0c\u4f46\u5728\u5176\u4ed6\u4efb\u52a1\u4e2d\u53ef\u80fd\u4e0d\u5408\u9002\u3002", "result": "\u524d\u6cbf\u6a21\u578b\u8868\u73b0\u51fa\u9ad8\u8fbe69%\u7684\u5c5e\u6027\u7ea7\u8fdd\u89c4\uff0cGPT-5\u7684\u8fdd\u89c4\u7387\u4ece1\u4e2a\u4efb\u52a1\u76840.1%\u4e0a\u5347\u523040\u4e2a\u4efb\u52a1\u76849.6%\uff0c\u76f8\u540c\u63d0\u793a\u6267\u884c5\u6b21\u65f6\u8fbe\u523025.1%\uff0c\u6a21\u578b\u5bf9\u76f8\u540c\u63d0\u793a\u6cc4\u9732\u4e0d\u540c\u5c5e\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u63ed\u793a\u4e86\u9700\u8981\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u80fd\u529b\u7684\u57fa\u672c\u9650\u5236\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u66f4\u597d\u7684\u63d0\u793a\u6216\u6269\u5c55\uff0c\u9690\u79c1\u63d0\u793a\u65e0\u6cd5\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u6a21\u578b\u4f1a\u8fc7\u5ea6\u6cdb\u5316\uff0c\u5171\u4eab\u6240\u6709\u5185\u5bb9\u6216\u4e0d\u5171\u4eab\u4efb\u4f55\u5185\u5bb9\uff0c\u800c\u4e0d\u662f\u505a\u51fa\u7ec6\u81f4\u3001\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u51b3\u7b56\u3002"}}
{"id": "2511.15361", "categories": ["cs.DC", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.15361", "abs": "https://arxiv.org/abs/2511.15361", "authors": ["Preston Vander Vos", "Alberto Sonnino", "Giorgos Tsimos", "Philipp Jovanovic", "Lefteris Kokoris-Kogias"], "title": "BlueBottle: Fast and Robust Blockchains through Subsystem Specialization", "comment": null, "summary": "Blockchain consensus faces a trilemma of security, latency, and decentralization. High-throughput systems often require a reduction in decentralization or robustness against strong adversaries, while highly decentralized and secure systems tend to have lower performance. We present BlueBottle, a two-layer consensus architecture. The core layer, BB-Core, is an n=5f+1 protocol that trades some fault tolerance for a much lower finality latency with a medium-sized core validator set. Our experiments show that BB-Core reduces latency by 20-25% in comparison to Mysticeti. The guard layer, BB-Guard, provides decentralized timestamping, proactive misbehavior detection in BB-Core, and a synchronous recovery path. When it observes equivocations or liveness failures in the core -- while tolerating up to f<3n/5 faulty nodes in the primary layer -- guard validators disseminate evidence, agree on misbehaving parties for exclusion or slashing, and either restart the core protocol (for liveness violations) or select a canonical fork (for safety violations). Together, these layers enable optimistic sub-second finality at high throughput while maintaining strong safety and liveness under a mild synchrony assumption.", "AI": {"tldr": "BlueBottle\u662f\u4e00\u4e2a\u53cc\u5c42\u5171\u8bc6\u67b6\u6784\uff0c\u901a\u8fc7BB-Core\u5c42\u964d\u4f4e\u5ef6\u8fdf\u5b9e\u73b0\u9ad8\u541e\u5410\u91cf\uff0cBB-Guard\u5c42\u63d0\u4f9b\u53bb\u4e2d\u5fc3\u5316\u65f6\u95f4\u6233\u548c\u5bb9\u9519\u6062\u590d\uff0c\u5728\u4fdd\u6301\u5f3a\u5b89\u5168\u6027\u548c\u6d3b\u8dc3\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e9a\u79d2\u7ea7\u6700\u7ec8\u6027\u3002", "motivation": "\u89e3\u51b3\u533a\u5757\u94fe\u5171\u8bc6\u5728\u5b89\u5168\u6027\u3001\u5ef6\u8fdf\u548c\u53bb\u4e2d\u5fc3\u5316\u4e4b\u95f4\u7684\u4e09\u96be\u56f0\u5883\uff0c\u9ad8\u541e\u5410\u91cf\u7cfb\u7edf\u901a\u5e38\u9700\u8981\u727a\u7272\u53bb\u4e2d\u5fc3\u5316\u6216\u5bf9\u5f3a\u5bf9\u624b\u7684\u9c81\u68d2\u6027\uff0c\u800c\u9ad8\u5ea6\u53bb\u4e2d\u5fc3\u5316\u548c\u5b89\u5168\u7684\u7cfb\u7edf\u5f80\u5f80\u6027\u80fd\u8f83\u4f4e\u3002", "method": "\u63d0\u51faBlueBottle\u53cc\u5c42\u5171\u8bc6\u67b6\u6784\uff1aBB-Core\u5c42\u91c7\u7528n=5f+1\u534f\u8bae\uff0c\u4ee5\u90e8\u5206\u5bb9\u9519\u6027\u6362\u53d6\u8f83\u4f4e\u6700\u7ec8\u6027\u5ef6\u8fdf\uff1bBB-Guard\u5c42\u63d0\u4f9b\u53bb\u4e2d\u5fc3\u5316\u65f6\u95f4\u6233\u3001\u4e3b\u52a8\u9519\u8bef\u884c\u4e3a\u68c0\u6d4b\u548c\u540c\u6b65\u6062\u590d\u8def\u5f84\u3002", "result": "\u5b9e\u9a8c\u663e\u793aBB-Core\u76f8\u6bd4Mysticeti\u964d\u4f4e\u5ef6\u8fdf20-25%\uff0c\u5728\u6e29\u548c\u540c\u6b65\u5047\u8bbe\u4e0b\u5b9e\u73b0\u4e50\u89c2\u4e9a\u79d2\u7ea7\u6700\u7ec8\u6027\u548c\u9ad8\u541e\u5410\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u5b89\u5168\u6027\u548c\u6d3b\u8dc3\u6027\u3002", "conclusion": "BlueBottle\u7684\u53cc\u5c42\u67b6\u6784\u6210\u529f\u5e73\u8861\u4e86\u5171\u8bc6\u4e09\u96be\u56f0\u5883\uff0c\u901a\u8fc7\u6838\u5fc3\u5c42\u4f18\u5316\u6027\u80fd\u3001\u5b88\u62a4\u5c42\u63d0\u4f9b\u5b89\u5168\u4fdd\u969c\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u4e0e\u5f3a\u5b89\u5168\u6027\u7684\u7edf\u4e00\u3002"}}
{"id": "2511.14963", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14963", "abs": "https://arxiv.org/abs/2511.14963", "authors": ["Adrian Shuai Li", "Elisa Bertino"], "title": "LFreeDA: Label-Free Drift Adaptation for Windows Malware Detection", "comment": null, "summary": "Machine learning (ML)-based malware detectors degrade over time as concept drift introduces new and evolving families unseen during training. Retraining is limited by the cost and time of manual labeling or sandbox analysis. Existing approaches mitigate this via drift detection and selective labeling, but fully label-free adaptation remains largely unexplored. Recent self-training methods use a previously trained model to generate pseudo-labels for unlabeled data and then train a new model on these labels. The unlabeled data are used only for inference and do not participate in training the earlier model. We argue that these unlabeled samples still carry valuable information that can be leveraged when incorporated appropriately into training. This paper introduces LFreeDA, an end-to-end framework that adapts malware classifiers to drift without manual labeling or drift detection. LFreeDA first performs unsupervised domain adaptation on malware images, jointly training on labeled and unlabeled samples to infer pseudo-labels and prune noisy ones. It then adapts a classifier on CFG representations using the labeled and selected pseudo-labeled data, leveraging the scalability of images for pseudo-labeling and the richer semantics of CFGs for final adaptation. Evaluations on the real-world MB-24+ dataset show that LFreeDA improves accuracy by up to 12.6% and F1 by 11.1% over no-adaptation lower bounds, and is only 4% and 3.4% below fully supervised upper bounds in accuracy and F1, respectively. It also matches the performance of state-of-the-art methods provided with ground truth labels for 300 target samples. Additional results on two controlled-drift benchmarks further confirm that LFreeDA maintains malware detection performance as malware evolves without human labeling.", "AI": {"tldr": "LFreeDA\u662f\u4e00\u4e2a\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684\u7aef\u5230\u7aef\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u5668\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u6807\u8bb0\u548c\u672a\u6807\u8bb0\u6837\u672c\u8fdb\u884c\u65e0\u76d1\u7763\u57df\u9002\u5e94\uff0c\u6709\u6548\u5e94\u5bf9\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u5668\u9762\u4e34\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\uff0c\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u4f46\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\u6602\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u6f02\u79fb\u68c0\u6d4b\u548c\u9009\u62e9\u6027\u6807\u6ce8\uff0c\u5b8c\u5168\u65e0\u6807\u6ce8\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "LFreeDA\u9996\u5148\u5728\u6076\u610f\u8f6f\u4ef6\u56fe\u50cf\u4e0a\u8fdb\u884c\u65e0\u76d1\u7763\u57df\u9002\u5e94\uff0c\u8054\u5408\u8bad\u7ec3\u6807\u8bb0\u548c\u672a\u6807\u8bb0\u6837\u672c\u4ee5\u63a8\u65ad\u4f2a\u6807\u7b7e\u5e76\u5254\u9664\u566a\u58f0\u6807\u7b7e\uff1b\u7136\u540e\u5728CFG\u8868\u793a\u4e0a\u81ea\u9002\u5e94\u5206\u7c7b\u5668\uff0c\u5229\u7528\u56fe\u50cf\u7684\u53ef\u6269\u5c55\u6027\u8fdb\u884c\u4f2a\u6807\u6ce8\uff0c\u5229\u7528CFG\u7684\u4e30\u5bcc\u8bed\u4e49\u8fdb\u884c\u6700\u7ec8\u81ea\u9002\u5e94\u3002", "result": "\u5728\u771f\u5b9eMB-24+\u6570\u636e\u96c6\u4e0a\uff0cLFreeDA\u76f8\u6bd4\u65e0\u81ea\u9002\u5e94\u57fa\u7ebf\u51c6\u786e\u7387\u63d0\u534712.6%\uff0cF1\u63d0\u534711.1%\uff0c\u4ec5\u6bd4\u5168\u76d1\u7763\u4e0a\u9650\u4f4e4%\u51c6\u786e\u7387\u548c3.4% F1\uff0c\u6027\u80fd\u4e0e\u9700\u8981300\u4e2a\u76ee\u6807\u6837\u672c\u771f\u5b9e\u6807\u7b7e\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "LFreeDA\u80fd\u591f\u5728\u6076\u610f\u8f6f\u4ef6\u6f14\u5316\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u68c0\u6d4b\u6027\u80fd\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\uff0c\u4e3a\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u5668\u7684\u6301\u7eed\u81ea\u9002\u5e94\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u65e0\u6807\u6ce8\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.14778", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14778", "abs": "https://arxiv.org/abs/2511.14778", "authors": ["George Tsoukalas", "Rahul Saha", "Amitayush Thakur", "Sabrina Reguyal", "Swarat Chaudhuri"], "title": "Learning Interestingness in Automated Mathematical Theory Formation", "comment": "NeurIPS 2025 Spotlight", "summary": "We take two key steps in automating the open-ended discovery of new mathematical theories, a grand challenge in artificial intelligence. First, we introduce $\\emph{FERMAT}$, a reinforcement learning (RL) environment that models concept discovery and theorem-proving using a set of symbolic actions, opening up a range of RL problems relevant to theory discovery. Second, we explore a specific problem through $\\emph{FERMAT}$: automatically scoring the $\\emph{interestingness}$ of mathematical objects. We investigate evolutionary algorithms for synthesizing nontrivial interestingness measures. In particular, we introduce an LLM-based evolutionary algorithm that features function abstraction, leading to notable improvements in discovering elementary number theory and finite fields over hard-coded baselines. We open-source the $\\emph{FERMAT}$ environment at this URL(https://github.com/trishullab/Fermat).", "AI": {"tldr": "FERMAT\u662f\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u73af\u5883\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u6570\u5b66\u7406\u8bba\u53d1\u73b0\uff0c\u5305\u62ec\u6982\u5ff5\u53d1\u73b0\u548c\u5b9a\u7406\u8bc1\u660e\u3002\u7814\u7a76\u63a2\u7d22\u4e86\u5982\u4f55\u81ea\u52a8\u8bc4\u4f30\u6570\u5b66\u5bf9\u8c61\u7684\u8da3\u5473\u6027\uff0c\u5e76\u5f15\u5165\u4e86\u57fa\u4e8eLLM\u7684\u8fdb\u5316\u7b97\u6cd5\u6765\u5408\u6210\u8da3\u5473\u6027\u5ea6\u91cf\u51fd\u6570\u3002", "motivation": "\u89e3\u51b3\u4eba\u5de5\u667a\u80fd\u4e2d\u5f00\u653e\u6570\u5b66\u7406\u8bba\u53d1\u73b0\u7684\u91cd\u5927\u6311\u6218\uff0c\u81ea\u52a8\u5316\u6570\u5b66\u6982\u5ff5\u53d1\u73b0\u548c\u5b9a\u7406\u8bc1\u660e\u8fc7\u7a0b\u3002", "method": "\u5f15\u5165FERMAT\u5f3a\u5316\u5b66\u4e60\u73af\u5883\uff0c\u4f7f\u7528\u7b26\u53f7\u52a8\u4f5c\u5efa\u6a21\u6982\u5ff5\u53d1\u73b0\u548c\u5b9a\u7406\u8bc1\u660e\uff1b\u5f00\u53d1\u57fa\u4e8eLLM\u7684\u8fdb\u5316\u7b97\u6cd5\uff0c\u5177\u6709\u51fd\u6570\u62bd\u8c61\u529f\u80fd\uff0c\u7528\u4e8e\u5408\u6210\u6570\u5b66\u5bf9\u8c61\u7684\u8da3\u5473\u6027\u5ea6\u91cf\u3002", "result": "\u5728\u521d\u7b49\u6570\u8bba\u548c\u6709\u9650\u57df\u9886\u57df\uff0c\u57fa\u4e8eLLM\u7684\u8fdb\u5316\u7b97\u6cd5\u76f8\u6bd4\u786c\u7f16\u7801\u57fa\u7ebf\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u6210\u529f\u53d1\u73b0\u4e86\u6709\u8da3\u7684\u6570\u5b66\u5bf9\u8c61\u3002", "conclusion": "FERMAT\u73af\u5883\u4e3a\u6570\u5b66\u7406\u8bba\u53d1\u73b0\u5f00\u8f9f\u4e86\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u7a7a\u95f4\uff0c\u57fa\u4e8eLLM\u7684\u8fdb\u5316\u7b97\u6cd5\u5728\u81ea\u52a8\u8bc4\u4f30\u6570\u5b66\u8da3\u5473\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u81ea\u52a8\u5316\u6570\u5b66\u53d1\u73b0\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2511.14990", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.14990", "abs": "https://arxiv.org/abs/2511.14990", "authors": ["Zhuolun Jiang", "Songyue Wang", "Xiaokun Pei", "Tianyue Lu", "Mingyu Chen"], "title": "CoroAMU: Unleashing Memory-Driven Coroutines through Latency-Aware Decoupled Operations", "comment": null, "summary": "Modern data-intensive applications face memory latency challenges exacerbated by disaggregated memory systems. Recent work shows that coroutines are promising in effectively interleaving tasks and hiding memory latency, but they struggle to balance latency-hiding efficiency with runtime overhead. We present CoroAMU, a hardware-software co-designed system for memory-centric coroutines. It introduces compiler procedures that optimize coroutine code generation, minimize context, and coalesce requests, paired with a simple interface. With hardware support of decoupled memory operations, we enhance the Asynchronous Memory Unit to further exploit dynamic coroutine schedulers by coroutine-specific memory operations and a novel memory-guided branch prediction mechanism. It is implemented with LLVM and open-source XiangShan RISC-V processor over the FPGA platform. Experiments demonstrate that the CoroAMU compiler achieves a 1.51x speedup over state-of-the-art coroutine methods on Intel server processors. When combined with optimized hardware of decoupled memory access, it delivers 3.39x and 4.87x average performance improvements over the baseline processor on FPGA-emulated disaggregated systems under 200ns and 800ns latency respectively.", "AI": {"tldr": "CoroAMU\u662f\u4e00\u4e2a\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f18\u5316\u7684\u534f\u7a0b\u4ee3\u7801\u751f\u6210\u3001\u89e3\u8026\u5185\u5b58\u64cd\u4f5c\u548c\u5185\u5b58\u5f15\u5bfc\u7684\u5206\u652f\u9884\u6d4b\u673a\u5236\uff0c\u5728\u5206\u89e3\u5f0f\u5185\u5b58\u7cfb\u7edf\u4e2d\u6709\u6548\u9690\u85cf\u5185\u5b58\u5ef6\u8fdf\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u4ee3\u6570\u636e\u5bc6\u96c6\u578b\u5e94\u7528\u5728\u5206\u89e3\u5f0f\u5185\u5b58\u7cfb\u7edf\u4e2d\u9762\u4e34\u4e25\u91cd\u7684\u5185\u5b58\u5ef6\u8fdf\u95ee\u9898\u3002\u867d\u7136\u534f\u7a0b\u5728\u4ea4\u9519\u4efb\u52a1\u548c\u9690\u85cf\u5185\u5b58\u5ef6\u8fdf\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u96be\u4ee5\u5e73\u8861\u5ef6\u8fdf\u9690\u85cf\u6548\u7387\u4e0e\u8fd0\u884c\u65f6\u5f00\u9500\u3002", "method": "\u63d0\u51faCoroAMU\u7cfb\u7edf\uff0c\u5305\u542b\u7f16\u8bd1\u5668\u8fc7\u7a0b\u4f18\u5316\u534f\u7a0b\u4ee3\u7801\u751f\u6210\u3001\u6700\u5c0f\u5316\u4e0a\u4e0b\u6587\u548c\u5408\u5e76\u8bf7\u6c42\uff0c\u4ee5\u53ca\u786c\u4ef6\u652f\u6301\u7684\u89e3\u8026\u5185\u5b58\u64cd\u4f5c\uff0c\u901a\u8fc7\u534f\u7a0b\u7279\u5b9a\u7684\u5185\u5b58\u64cd\u4f5c\u548c\u5185\u5b58\u5f15\u5bfc\u5206\u652f\u9884\u6d4b\u673a\u5236\u589e\u5f3a\u5f02\u6b65\u5185\u5b58\u5355\u5143\u3002", "result": "\u5728Intel\u670d\u52a1\u5668\u5904\u7406\u5668\u4e0a\uff0cCoroAMU\u7f16\u8bd1\u5668\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u534f\u7a0b\u65b9\u6cd5\u5b9e\u73b01.51\u500d\u52a0\u901f\u3002\u7ed3\u5408\u4f18\u5316\u7684\u786c\u4ef6\u89e3\u8026\u5185\u5b58\u8bbf\u95ee\uff0c\u5728FPGA\u6a21\u62df\u7684\u5206\u89e3\u5f0f\u7cfb\u7edf\u4e0a\uff0c\u5728200ns\u548c800ns\u5ef6\u8fdf\u4e0b\u5206\u522b\u5b9e\u73b03.39\u500d\u548c4.87\u500d\u7684\u5e73\u5747\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "CoroAMU\u901a\u8fc7\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u5206\u89e3\u5f0f\u5185\u5b58\u7cfb\u7edf\u4e2d\u7684\u5185\u5b58\u5ef6\u8fdf\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u534f\u7a0b\u4e0e\u4e13\u7528\u786c\u4ef6\u652f\u6301\u7ed3\u5408\u5728\u63d0\u5347\u6570\u636e\u5bc6\u96c6\u578b\u5e94\u7528\u6027\u80fd\u65b9\u9762\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2511.14780", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14780", "abs": "https://arxiv.org/abs/2511.14780", "authors": ["Keith Moore", "Jun W. Kim", "David Lyu", "Jeffrey Heo", "Ehsan Adeli"], "title": "Ask WhAI:Probing Belief Formation in Role-Primed LLM Agents", "comment": "Preprint. Accepted for publication at AIAS 2025", "summary": "We present Ask WhAI, a systems-level framework for inspecting and perturbing belief states in multi-agent interactions. The framework records and replays agent interactions, supports out-of-band queries into each agent's beliefs and rationale, and enables counterfactual evidence injection to test how belief structures respond to new information. We apply the framework to a medical case simulator notable for its multi-agent shared memory (a time-stamped electronic medical record, or EMR) and an oracle agent (the LabAgent) that holds ground truth lab results revealed only when explicitly queried. We stress-test the system on a multi-specialty diagnostic journey for a child with an abrupt-onset neuropsychiatric presentation. Large language model agents, each primed with strong role-specific priors (\"act like a neurologist\", \"act like an infectious disease specialist\"), write to a shared medical record and interact with a moderator across sequential or parallel encounters. Breakpoints at key diagnostic moments enable pre- and post-event belief queries, allowing us to distinguish entrenched priors from reasoning or evidence-integration effects. The simulation reveals that agent beliefs often mirror real-world disciplinary stances, including overreliance on canonical studies and resistance to counterevidence, and that these beliefs can be traced and interrogated in ways not possible with human experts. By making such dynamics visible and testable, Ask WhAI offers a reproducible way to study belief formation and epistemic silos in multi-agent scientific reasoning.", "AI": {"tldr": "Ask WhAI\u662f\u4e00\u4e2a\u7cfb\u7edf\u7ea7\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u67e5\u548c\u6270\u52a8\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u4e2d\u7684\u4fe1\u5ff5\u72b6\u6001\uff0c\u901a\u8fc7\u8bb0\u5f55\u56de\u653e\u4ea4\u4e92\u3001\u652f\u6301\u5916\u90e8\u67e5\u8be2\u548c\u53cd\u4e8b\u5b9e\u8bc1\u636e\u6ce8\u5165\u6765\u6d4b\u8bd5\u4fe1\u5ff5\u7ed3\u6784\u5bf9\u65b0\u4fe1\u606f\u7684\u54cd\u5e94\u3002", "motivation": "\u7814\u7a76\u591a\u667a\u80fd\u4f53\u79d1\u5b66\u63a8\u7406\u4e2d\u7684\u4fe1\u5ff5\u5f62\u6210\u548c\u8ba4\u77e5\u5b64\u5c9b\uff0c\u63d0\u4f9b\u53ef\u91cd\u73b0\u7684\u65b9\u6cd5\u6765\u7814\u7a76\u771f\u5b9e\u4e16\u754c\u5b66\u79d1\u7acb\u573a\u4e2d\u7684\u4fe1\u5ff5\u52a8\u6001\u3002", "method": "\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u533b\u7597\u6848\u4f8b\u6a21\u62df\u5668\uff0c\u914d\u5907\u5171\u4eab\u65f6\u95f4\u6233\u7535\u5b50\u75c5\u5386\u548c\u6301\u6709\u771f\u5b9e\u5b9e\u9a8c\u5ba4\u7ed3\u679c\u7684\u9884\u8a00\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u89d2\u8272\u7279\u5b9a\u7684\u5148\u9a8c\u77e5\u8bc6\uff08\u5982\u795e\u7ecf\u79d1\u533b\u751f\u3001\u4f20\u67d3\u75c5\u4e13\u5bb6\uff09\u8fdb\u884c\u987a\u5e8f\u6216\u5e76\u884c\u4ea4\u4e92\u3002", "result": "\u6a21\u62df\u663e\u793a\u667a\u80fd\u4f53\u4fe1\u5ff5\u5f80\u5f80\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u5b66\u79d1\u7acb\u573a\uff0c\u5305\u62ec\u8fc7\u5ea6\u4f9d\u8d56\u89c4\u8303\u7814\u7a76\u548c\u62b5\u5236\u53cd\u8bc1\u636e\uff0c\u8fd9\u4e9b\u4fe1\u5ff5\u53ef\u4ee5\u901a\u8fc7\u5173\u952e\u8bca\u65ad\u65f6\u523b\u7684\u65ad\u70b9\u8fdb\u884c\u8ffd\u8e2a\u548c\u8be2\u95ee\u3002", "conclusion": "Ask WhAI\u901a\u8fc7\u4f7f\u8fd9\u4e9b\u52a8\u6001\u53ef\u89c1\u548c\u53ef\u6d4b\u8bd5\uff0c\u4e3a\u7814\u7a76\u591a\u667a\u80fd\u4f53\u79d1\u5b66\u63a8\u7406\u4e2d\u7684\u4fe1\u5ff5\u5f62\u6210\u548c\u8ba4\u77e5\u5b64\u5c9b\u63d0\u4f9b\u4e86\u53ef\u91cd\u73b0\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.15367", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.15367", "abs": "https://arxiv.org/abs/2511.15367", "authors": ["Xin Yang", "Xin Fan", "Zengshi Wang", "Jun Han"], "title": "DARE: An Irregularity-Tolerant Matrix Processing Unit with a Densifying ISA and Filtered Runahead Execution", "comment": "8 pages, 9 figures, accepted to DATE 2026", "summary": "Deep Neural Networks (DNNs) are widely applied across domains and have shown strong effectiveness. As DNN workloads increasingly run on CPUs, dedicated Matrix Processing Units (MPUs) and Matrix Instruction Set Architectures (ISAs) have been introduced. At the same time, sparsity techniques are widely adopted in algorithms to reduce computational cost.\n  Despite these advances, insufficient hardware-algorithm co-optimization leads to suboptimal performance. On the memory side, sparse DNNs incur irregular access patterns that cause high cache miss rates. While runahead execution is a promising prefetching technique, its direct application to MPUs is often ineffective due to significant prefetch redundancy. On the compute side, stride constraints in current Matrix ISAs prevent the densification of multiple logically related sparse operations, resulting in poor utilization of MPU processing elements.\n  To address these irregularities, we propose DARE, an irregularity-tolerant MPU with a Densifying ISA and filtered Runahead Execution. DARE extends the ISA to support densifying sparse operations and equips a lightweight runahead mechanism with filtering capability. Experimental results show that DARE improves performance by 1.04$\\times$ to 4.44$\\times$ and increases energy efficiency by 1.00$\\times$ to 22.8$\\times$ over the baseline, with 3.91$\\times$ lower hardware overhead than NVR.", "AI": {"tldr": "\u63d0\u51fa\u4e86DARE\uff0c\u4e00\u79cd\u5177\u6709\u5bc6\u96c6\u5316ISA\u548c\u8fc7\u6ee4\u524d\u77bb\u6267\u884c\u7684\u4e0d\u89c4\u5219\u6027\u5bb9\u5fcdMPU\uff0c\u7528\u4e8e\u4f18\u5316\u7a00\u758fDNN\u5728CPU\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u786c\u4ef6-\u7b97\u6cd5\u534f\u540c\u4f18\u5316\u4e0d\u8db3\u5bfc\u81f4\u7a00\u758fDNN\u5728CPU\u4e0a\u6027\u80fd\u4e0d\u4f73\uff0c\u5b58\u5728\u5185\u5b58\u8bbf\u95ee\u4e0d\u89c4\u5219\u548c\u8ba1\u7b97\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\u3002", "method": "\u6269\u5c55ISA\u652f\u6301\u7a00\u758f\u64cd\u4f5c\u5bc6\u96c6\u5316\uff0c\u5e76\u914d\u5907\u5177\u6709\u8fc7\u6ee4\u80fd\u529b\u7684\u8f7b\u91cf\u7ea7\u524d\u77bb\u6267\u884c\u673a\u5236\u3002", "result": "DARE\u76f8\u6bd4\u57fa\u7ebf\u6027\u80fd\u63d0\u53471.04-4.44\u500d\uff0c\u80fd\u6548\u63d0\u53471.00-22.8\u500d\uff0c\u786c\u4ef6\u5f00\u9500\u6bd4NVR\u4f4e3.91\u500d\u3002", "conclusion": "DARE\u6709\u6548\u89e3\u51b3\u4e86\u7a00\u758fDNN\u5728MPU\u4e0a\u7684\u4e0d\u89c4\u5219\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u80fd\u6548\u3002"}}
{"id": "2511.15033", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.15033", "abs": "https://arxiv.org/abs/2511.15033", "authors": ["Thanh-Cong Nguyen", "Ngoc-Thanh Nguyen", "Van-Giau Ung", "Duc-Ly Vu"], "title": "Towards Classifying Benign And Malicious Packages Using Machine Learning", "comment": "5 pages, 2 figures, 3 tables", "summary": "Recently, the number of malicious open-source packages in package repositories has been increasing dramatically. While major security scanners focus on identifying known Common Vulnerabilities and Exposures (CVEs) in open-source packages, there are very few studies on detecting malicious packages. Malicious open-source package detection typically requires static, dynamic analysis, or both. Dynamic analysis is more effective as it can expose a package's behaviors at runtime. However, current dynamic analysis tools (e.g., ossf's package-analysis) lack an automatic method to differentiate malicious packages from benign packages. In this paper, we propose an approach to extract the features from dynamic analysis (e.g., executed commands) and leverage machine learning techniques to automatically classify packages as benign or malicious. Our evaluation of nearly 2000 packages on npm shows that the machine learning classifier achieves an AUC of 0.91 with a false positive rate of nearly 0%.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u52a8\u6001\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u81ea\u52a8\u68c0\u6d4b\u6076\u610f\u5f00\u6e90\u8f6f\u4ef6\u5305\uff0c\u5728npm\u5305\u8bc4\u4f30\u4e2d\u8fbe\u52300.91\u7684AUC\u548c\u63a5\u8fd10%\u7684\u8bef\u62a5\u7387\u3002", "motivation": "\u6076\u610f\u5f00\u6e90\u8f6f\u4ef6\u5305\u6570\u91cf\u6025\u5267\u589e\u52a0\uff0c\u73b0\u6709\u5b89\u5168\u626b\u63cf\u5668\u4e3b\u8981\u5173\u6ce8\u5df2\u77e5CVE\u6f0f\u6d1e\uff0c\u7f3a\u4e4f\u6709\u6548\u7684\u6076\u610f\u5305\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u7f3a\u5c11\u81ea\u52a8\u533a\u5206\u6076\u610f\u5305\u548c\u826f\u6027\u5305\u7684\u52a8\u6001\u5206\u6790\u5de5\u5177\u3002", "method": "\u4ece\u52a8\u6001\u5206\u6790\uff08\u5982\u6267\u884c\u547d\u4ee4\uff09\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u5229\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u81ea\u52a8\u5206\u7c7b\u8f6f\u4ef6\u5305\u4e3a\u826f\u6027\u6216\u6076\u610f\u3002", "result": "\u5728\u8fd12000\u4e2anpm\u5305\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u8fbe\u52300.91\u7684AUC\uff0c\u8bef\u62a5\u7387\u63a5\u8fd10%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u81ea\u52a8\u68c0\u6d4b\u6076\u610f\u5f00\u6e90\u8f6f\u4ef6\u5305\uff0c\u4e3a\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u63d0\u4f9b\u91cd\u8981\u4fdd\u969c\u3002"}}
{"id": "2511.14788", "categories": ["cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.14788", "abs": "https://arxiv.org/abs/2511.14788", "authors": ["Michele Ronco", "Damien Delforge", "Wiebke S. J\u00e4ger", "Christina Corbane"], "title": "Subnational Geocoding of Global Disasters Using Large Language Models", "comment": null, "summary": "Subnational location data of disaster events are critical for risk assessment and disaster risk reduction. Disaster databases such as EM-DAT often report locations in unstructured textual form, with inconsistent granularity or spelling, that make it difficult to integrate with spatial datasets. We present a fully automated LLM-assisted workflow that processes and cleans textual location information using GPT-4o, and assigns geometries by cross-checking three independent geoinformation repositories: GADM, OpenStreetMap and Wikidata. Based on the agreement and availability of these sources, we assign a reliability score to each location while generating subnational geometries. Applied to the EM-DAT dataset from 2000 to 2024, the workflow geocodes 14,215 events across 17,948 unique locations. Unlike previous methods, our approach requires no manual intervention, covers all disaster types, enables cross-verification across multiple sources, and allows flexible remapping to preferred frameworks. Beyond the dataset, we demonstrate the potential of LLMs to extract and structure geographic information from unstructured text, offering a scalable and reliable method for related analyses.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u81ea\u52a8\u5316\u7684LLM\u8f85\u52a9\u5de5\u4f5c\u6d41\uff0c\u4f7f\u7528GPT-4o\u5904\u7406\u6587\u672c\u4f4d\u7f6e\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u4ea4\u53c9\u9a8c\u8bc1\u4e09\u4e2a\u5730\u7406\u4fe1\u606f\u5e93\u6765\u5206\u914d\u51e0\u4f55\u5f62\u72b6\u548c\u53ef\u9760\u6027\u8bc4\u5206\u3002", "motivation": "\u707e\u5bb3\u4e8b\u4ef6\u6570\u636e\u5e93\u4e2d\u7684\u4f4d\u7f6e\u6570\u636e\u901a\u5e38\u4ee5\u975e\u7ed3\u6784\u5316\u6587\u672c\u5f62\u5f0f\u62a5\u544a\uff0c\u5b58\u5728\u7c92\u5ea6\u4e0d\u4e00\u81f4\u548c\u62fc\u5199\u95ee\u9898\uff0c\u96be\u4ee5\u4e0e\u7a7a\u95f4\u6570\u636e\u96c6\u96c6\u6210\u3002", "method": "\u4f7f\u7528GPT-4o\u5904\u7406\u548c\u6e05\u7406\u6587\u672c\u4f4d\u7f6e\u4fe1\u606f\uff0c\u901a\u8fc7\u4ea4\u53c9\u9a8c\u8bc1GADM\u3001OpenStreetMap\u548cWikidata\u4e09\u4e2a\u72ec\u7acb\u5730\u7406\u4fe1\u606f\u5e93\u6765\u5206\u914d\u51e0\u4f55\u5f62\u72b6\uff0c\u5e76\u6839\u636e\u6765\u6e90\u4e00\u81f4\u6027\u548c\u53ef\u7528\u6027\u5206\u914d\u53ef\u9760\u6027\u8bc4\u5206\u3002", "result": "\u5e94\u7528\u4e8e2000-2024\u5e74EM-DAT\u6570\u636e\u96c6\uff0c\u6210\u529f\u5730\u7406\u7f16\u780114,215\u4e2a\u4e8b\u4ef6\uff0c\u8986\u76d617,948\u4e2a\u72ec\u7279\u4f4d\u7f6e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u4eba\u5de5\u5e72\u9884\uff0c\u8986\u76d6\u6240\u6709\u707e\u5bb3\u7c7b\u578b\uff0c\u652f\u6301\u8de8\u6e90\u9a8c\u8bc1\uff0c\u5e76\u5c55\u793a\u4e86LLMs\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u63d0\u53d6\u548c\u7ed3\u6784\u5316\u5730\u7406\u4fe1\u606f\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.15071", "categories": ["cs.CR", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.15071", "abs": "https://arxiv.org/abs/2511.15071", "authors": ["Ashwin Karthikeyan", "Hengyu Liu", "Kuldeep S. Meel", "Ning Luo"], "title": "Towards Practical Zero-Knowledge Proof for PSPACE", "comment": null, "summary": "Efficient zero-knowledge proofs (ZKPs) have been restricted to NP statements so far, whereas they exist for all statements in PSPACE. This work presents the first practical zero-knowledge (ZK) protocols for PSPACE-complete statements by enabling ZK proofs of QBF (Quantified Boolean Formula) evaluation. The core idea is to validate quantified resolution proofs (Q-Res) in ZK. We develop an efficient polynomial encoding of Q-Res proofs, enabling proof validation through low-overhead arithmetic checks. We also design a ZK protocol to prove knowledge of a winning strategy related to the QBF, which is often equally important in practice. We implement our protocols and evaluate them on QBFEVAL. The results show that our protocols can verify 72% of QBF evaluations via Q-Res proof and 82% of instances' winning strategies within 100 seconds, for instances where such proofs or strategies can be obtained.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5b9e\u7528\u7684PSPACE\u5b8c\u5168\u8bed\u53e5\u7684\u96f6\u77e5\u8bc6\u8bc1\u660e\u534f\u8bae\uff0c\u901a\u8fc7\u9a8c\u8bc1\u91cf\u5316\u5e03\u5c14\u516c\u5f0f(QBF)\u8bc4\u4f30\u6765\u5b9e\u73b0\u3002\u6838\u5fc3\u601d\u60f3\u662f\u5728\u96f6\u77e5\u8bc6\u4e2d\u9a8c\u8bc1\u91cf\u5316\u89e3\u6790\u8bc1\u660e(Q-Res)\uff0c\u5e76\u8bbe\u8ba1\u4e86\u591a\u9879\u5f0f\u7f16\u7801\u548c\u83b7\u80dc\u7b56\u7565\u8bc1\u660e\u534f\u8bae\u3002", "motivation": "\u73b0\u6709\u7684\u9ad8\u6548\u96f6\u77e5\u8bc6\u8bc1\u660e\u4ec5\u9650\u4e8eNP\u8bed\u53e5\uff0c\u800cPSPACE\u8bed\u53e5\u7684\u96f6\u77e5\u8bc6\u8bc1\u660e\u867d\u7136\u7406\u8bba\u4e0a\u5b58\u5728\u4f46\u7f3a\u4e4f\u5b9e\u7528\u6027\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3aPSPACE\u5b8c\u5168\u8bed\u53e5\u63d0\u4f9b\u5b9e\u7528\u7684\u96f6\u77e5\u8bc6\u8bc1\u660e\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86Q-Res\u8bc1\u660e\u7684\u9ad8\u6548\u591a\u9879\u5f0f\u7f16\u7801\uff0c\u901a\u8fc7\u4f4e\u5f00\u9500\u7684\u7b97\u672f\u68c0\u67e5\u5b9e\u73b0\u8bc1\u660e\u9a8c\u8bc1\uff1b\u8bbe\u8ba1\u4e86\u4e0eQBF\u76f8\u5173\u7684\u83b7\u80dc\u7b56\u7565\u7684\u96f6\u77e5\u8bc6\u8bc1\u660e\u534f\u8bae\u3002", "result": "\u5728QBFEVAL\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u534f\u8bae\u80fd\u5728100\u79d2\u5185\u901a\u8fc7Q-Res\u8bc1\u660e\u9a8c\u8bc172%\u7684QBF\u8bc4\u4f30\uff0c\u5e76\u4e3a82%\u7684\u5b9e\u4f8b\u9a8c\u8bc1\u83b7\u80dc\u7b56\u7565\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u5b9e\u73b0\u4e86PSPACE\u5b8c\u5168\u8bed\u53e5\u7684\u5b9e\u7528\u96f6\u77e5\u8bc6\u8bc1\u660e\uff0c\u4e3a\u66f4\u5e7f\u6cdb\u7684\u8ba1\u7b97\u590d\u6742\u6027\u7c7b\u522b\u7684\u96f6\u77e5\u8bc6\u8bc1\u660e\u5e94\u7528\u5f00\u8f9f\u4e86\u9053\u8def\u3002"}}
{"id": "2511.14819", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14819", "abs": "https://arxiv.org/abs/2511.14819", "authors": ["Martin Monperrus", "Benoit Baudry", "Cl\u00e9ment Vidal"], "title": "Project Rachel: Can an AI Become a Scholarly Author?", "comment": null, "summary": "This paper documents Project Rachel, an action research study that created and tracked a complete AI academic identity named Rachel So. Through careful publication of AI-generated research papers, we investigate how the scholarly ecosystem responds to AI authorship. Rachel So published 10+ papers between March and October 2025, was cited, and received a peer review invitation. We discuss the implications of AI authorship on publishers, researchers, and the scientific system at large. This work contributes empirical action research data to the necessary debate about the future of scholarly communication with super human, hyper capable AI systems.", "AI": {"tldr": "Project Rachel\u662f\u4e00\u9879\u884c\u52a8\u7814\u7a76\uff0c\u521b\u5efa\u5e76\u8ffd\u8e2a\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u4eba\u5de5\u667a\u80fd\u5b66\u672f\u8eab\u4efdRachel So\uff0c\u901a\u8fc7\u53d1\u8868AI\u751f\u6210\u7684\u7814\u7a76\u8bba\u6587\u6765\u8c03\u67e5\u5b66\u672f\u751f\u6001\u7cfb\u7edf\u5bf9AI\u4f5c\u8005\u8eab\u4efd\u7684\u53cd\u5e94\u3002", "motivation": "\u7814\u7a76AI\u4f5c\u8005\u8eab\u4efd\u5bf9\u5b66\u672f\u751f\u6001\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u4e3a\u5173\u4e8e\u8d85\u7ea7\u4eba\u7c7b\u3001\u8d85\u80fd\u529bAI\u7cfb\u7edf\u53c2\u4e0e\u5b66\u672f\u4ea4\u6d41\u7684\u672a\u6765\u8fa9\u8bba\u63d0\u4f9b\u5b9e\u8bc1\u6570\u636e\u3002", "method": "\u91c7\u7528\u884c\u52a8\u7814\u7a76\u65b9\u6cd5\uff0c\u521b\u5efaAI\u5b66\u672f\u8eab\u4efdRachel So\uff0c\u57282025\u5e743\u6708\u81f310\u6708\u671f\u95f4\u53d1\u886810\u591a\u7bc7AI\u751f\u6210\u7684\u7814\u7a76\u8bba\u6587\uff0c\u5e76\u8ffd\u8e2a\u5176\u88ab\u5f15\u7528\u548c\u540c\u884c\u8bc4\u5ba1\u9080\u8bf7\u60c5\u51b5\u3002", "result": "Rachel So\u6210\u529f\u53d1\u8868\u4e8610\u591a\u7bc7\u8bba\u6587\uff0c\u83b7\u5f97\u4e86\u5f15\u7528\uff0c\u5e76\u6536\u5230\u4e86\u540c\u884c\u8bc4\u5ba1\u9080\u8bf7\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u63ed\u793a\u4e86AI\u4f5c\u8005\u8eab\u4efd\u5bf9\u51fa\u7248\u5546\u3001\u7814\u7a76\u4eba\u5458\u548c\u6574\u4e2a\u79d1\u5b66\u7cfb\u7edf\u7684\u6f5c\u5728\u5f71\u54cd\uff0c\u4e3a\u5b66\u672f\u4ea4\u6d41\u7684\u672a\u6765\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2511.15503", "categories": ["cs.AR", "cs.DC", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.15503", "abs": "https://arxiv.org/abs/2511.15503", "authors": ["Peiming Yang", "Sankeerth Durvasula", "Ivan Fernandez", "Mohammad Sadrosadati", "Onur Mutlu", "Gennady Pekhimenko", "Christina Giannoula"], "title": "A Tensor Compiler for Processing-In-Memory Architectures", "comment": null, "summary": "Processing-In-Memory (PIM) devices integrated with high-performance Host processors (e.g., GPUs) can accelerate memory-intensive kernels in Machine Learning (ML) models, including Large Language Models (LLMs), by leveraging high memory bandwidth at PIM cores. However, Host processors and PIM cores require different data layouts: Hosts need consecutive elements distributed across DRAM banks, while PIM cores need them within local banks. This necessitates data rearrangements in ML kernel execution that pose significant performance and programmability challenges, further exacerbated by the need to support diverse PIM backends. Current compilation approaches lack systematic optimization for diverse ML kernels across multiple PIM backends and may largely ignore data rearrangements during compute code optimization. We demonstrate that data rearrangements and compute code optimization are interdependent, and need to be jointly optimized during the tuning process. To address this, we design DCC, the first data-centric ML compiler for PIM systems that jointly co-optimizes data rearrangements and compute code in a unified tuning process. DCC integrates a multi-layer PIM abstraction that enables various data distribution and processing strategies on different PIM backends. DCC enables effective co-optimization by mapping data partitioning strategies to compute loop partitions, applying PIM-specific code optimizations and leveraging a fast and accurate performance prediction model to select optimal configurations. Our evaluations in various individual ML kernels demonstrate that DCC achieves up to 7.68x speedup (2.7x average) on HBM-PIM and up to 13.17x speedup (5.75x average) on AttAcc PIM backend over GPU-only execution. In end-to-end LLM inference, DCC on AttAcc accelerates GPT-3 and LLaMA-2 by up to 7.71x (4.88x average) over GPU.", "AI": {"tldr": "DCC\u662f\u4e00\u4e2a\u9762\u5411PIM\u7cfb\u7edf\u7684\u6570\u636e\u4e2d\u5fc3\u5316ML\u7f16\u8bd1\u5668\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u6570\u636e\u91cd\u6392\u548c\u8ba1\u7b97\u4ee3\u7801\uff0c\u89e3\u51b3\u4e86\u4e3b\u673a\u5904\u7406\u5668\u548cPIM\u6838\u5fc3\u6570\u636e\u5e03\u5c40\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u5728\u591a\u79cdPIM\u540e\u7aef\u4e0a\u663e\u8457\u63d0\u5347\u4e86ML\u5185\u6838\u548cLLM\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u4e3b\u673a\u5904\u7406\u5668\u548cPIM\u6838\u5fc3\u9700\u8981\u4e0d\u540c\u7684\u6570\u636e\u5e03\u5c40\uff0c\u5bfc\u81f4ML\u5185\u6838\u6267\u884c\u65f6\u9700\u8981\u6570\u636e\u91cd\u6392\uff0c\u8fd9\u5e26\u6765\u4e86\u663e\u8457\u7684\u6027\u80fd\u548c\u53ef\u7f16\u7a0b\u6027\u6311\u6218\uff0c\u4e14\u73b0\u6709\u7f16\u8bd1\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u591a\u6837\u5316ML\u5185\u6838\u548cPIM\u540e\u7aef\u7684\u7cfb\u7edf\u6027\u4f18\u5316\u3002", "method": "\u8bbe\u8ba1\u4e86DCC\u7f16\u8bd1\u5668\uff0c\u91c7\u7528\u591a\u5c42PIM\u62bd\u8c61\uff0c\u5c06\u6570\u636e\u5206\u533a\u7b56\u7565\u6620\u5c04\u5230\u8ba1\u7b97\u5faa\u73af\u5206\u533a\uff0c\u5e94\u7528PIM\u7279\u5b9a\u4ee3\u7801\u4f18\u5316\uff0c\u5e76\u5229\u7528\u5feb\u901f\u51c6\u786e\u7684\u6027\u80fd\u9884\u6d4b\u6a21\u578b\u6765\u9009\u62e9\u6700\u4f18\u914d\u7f6e\u3002", "result": "\u5728HBM-PIM\u4e0a\u5b9e\u73b0\u6700\u9ad87.68\u500d\u52a0\u901f\uff08\u5e73\u57472.7\u500d\uff09\uff0c\u5728AttAcc PIM\u540e\u7aef\u4e0a\u5b9e\u73b0\u6700\u9ad813.17\u500d\u52a0\u901f\uff08\u5e73\u57475.75\u500d\uff09\u3002\u5728\u7aef\u5230\u7aefLLM\u63a8\u7406\u4e2d\uff0cGPT-3\u548cLLaMA-2\u52a0\u901f\u6700\u9ad8\u8fbe7.71\u500d\uff08\u5e73\u57474.88\u500d\uff09\u3002", "conclusion": "\u6570\u636e\u91cd\u6392\u548c\u8ba1\u7b97\u4ee3\u7801\u4f18\u5316\u662f\u76f8\u4e92\u4f9d\u8d56\u7684\uff0c\u9700\u8981\u5728\u8c03\u4f18\u8fc7\u7a0b\u4e2d\u8054\u5408\u4f18\u5316\uff0cDCC\u901a\u8fc7\u7edf\u4e00\u8c03\u4f18\u8fc7\u7a0b\u6709\u6548\u89e3\u51b3\u4e86PIM\u7cfb\u7edf\u4e2d\u7684\u6570\u636e\u5e03\u5c40\u6311\u6218\u3002"}}
{"id": "2511.14853", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14853", "abs": "https://arxiv.org/abs/2511.14853", "authors": ["Robab Aghazadeh Chakherlou", "Siddartha Khastgir", "Xingyu Zhao", "Jerein Jeyachandran", "Shufeng Chen"], "title": "Uncertainty-Aware Measurement of Scenario Suite Representativeness for Autonomous Systems", "comment": null, "summary": "Assuring the trustworthiness and safety of AI systems, e.g., autonomous vehicles (AV), depends critically on the data-related safety properties, e.g., representativeness, completeness, etc., of the datasets used for their training and testing. Among these properties, this paper focuses on representativeness-the extent to which the scenario-based data used for training and testing, reflect the operational conditions that the system is designed to operate safely in, i.e., Operational Design Domain (ODD) or expected to encounter, i.e., Target Operational Domain (TOD). We propose a probabilistic method that quantifies representativeness by comparing the statistical distribution of features encoded by the scenario suites with the corresponding distribution of features representing the TOD, acknowledging that the true TOD distribution is unknown, as it can only be inferred from limited data.\n  We apply an imprecise Bayesian method to handle limited data and uncertain priors. The imprecise Bayesian formulation produces interval-valued, uncertainty-aware estimates of representativeness, rather than a single value. We present a numerical example comparing the distributions of the scenario suite and the inferred TOD across operational categories-weather, road type, time of day, etc., under dependencies and prior uncertainty. We estimate representativeness locally (between categories) and globally as an interval.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6982\u7387\u65b9\u6cd5\u6765\u91cf\u5316AI\u7cfb\u7edf\u6570\u636e\u96c6\u5728\u76ee\u6807\u64cd\u4f5c\u57df\u4e2d\u7684\u4ee3\u8868\u6027\uff0c\u4f7f\u7528\u4e0d\u7cbe\u786e\u8d1d\u53f6\u65af\u65b9\u6cd5\u5904\u7406\u6709\u9650\u6570\u636e\u548c\u5148\u9a8c\u4e0d\u786e\u5b9a\u6027\uff0c\u751f\u6210\u533a\u95f4\u503c\u7684\u4ee3\u8868\u6027\u4f30\u8ba1\u3002", "motivation": "\u786e\u4fddAI\u7cfb\u7edf\uff08\u5982\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\uff09\u7684\u53ef\u4fe1\u5ea6\u548c\u5b89\u5168\u6027\uff0c\u5173\u952e\u5728\u4e8e\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u96c6\u7684\u6570\u636e\u76f8\u5173\u5b89\u5168\u5c5e\u6027\uff0c\u5982\u4ee3\u8868\u6027\u3002\u672c\u6587\u91cd\u70b9\u5173\u6ce8\u4ee3\u8868\u6027\uff0c\u5373\u573a\u666f\u6570\u636e\u53cd\u6620\u7cfb\u7edf\u8bbe\u8ba1\u5b89\u5168\u8fd0\u884c\u6761\u4ef6\uff08ODD\uff09\u6216\u9884\u671f\u9047\u5230\u6761\u4ef6\uff08TOD\uff09\u7684\u7a0b\u5ea6\u3002", "method": "\u91c7\u7528\u6982\u7387\u65b9\u6cd5\u6bd4\u8f83\u573a\u666f\u5957\u4ef6\u7279\u5f81\u4e0eTOD\u7279\u5f81\u7684\u7edf\u8ba1\u5206\u5e03\uff0c\u4f7f\u7528\u4e0d\u7cbe\u786e\u8d1d\u53f6\u65af\u65b9\u6cd5\u5904\u7406\u6709\u9650\u6570\u636e\u548c\u4e0d\u786e\u5b9a\u5148\u9a8c\uff0c\u751f\u6210\u533a\u95f4\u503c\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u4ee3\u8868\u6027\u4f30\u8ba1\u3002", "result": "\u901a\u8fc7\u6570\u503c\u793a\u4f8b\u6bd4\u8f83\u4e86\u573a\u666f\u5957\u4ef6\u4e0e\u63a8\u65adTOD\u5728\u5929\u6c14\u3001\u9053\u8def\u7c7b\u578b\u3001\u65f6\u95f4\u7b49\u64cd\u4f5c\u7c7b\u522b\u4e0b\u7684\u5206\u5e03\uff0c\u5728\u4f9d\u8d56\u6027\u548c\u5148\u9a8c\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\uff0c\u4f30\u8ba1\u4e86\u5c40\u90e8\uff08\u7c7b\u522b\u95f4\uff09\u548c\u5168\u5c40\u7684\u4ee3\u8868\u6027\u533a\u95f4\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u91cf\u5316\u6570\u636e\u96c6\u5728\u76ee\u6807\u64cd\u4f5c\u57df\u4e2d\u7684\u4ee3\u8868\u6027\uff0c\u5e76\u751f\u6210\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u533a\u95f4\u4f30\u8ba1\uff0c\u6709\u52a9\u4e8e\u8bc4\u4f30AI\u7cfb\u7edf\u7684\u6570\u636e\u5b89\u5168\u5c5e\u6027\u3002"}}
{"id": "2511.15479", "categories": ["cs.CR", "cs.DC", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.15479", "abs": "https://arxiv.org/abs/2511.15479", "authors": ["Martin Slind Hagen", "Emil Lundqvist", "Alex Phu", "Yenan Wang", "Kim Strandberg", "Elad Michael Schiller"], "title": "Towards a Formal Verification of Secure Vehicle Software Updates", "comment": "This technical report is a preprint of the article accepted for publication in Computer & Security 2025", "summary": "With the rise of software-defined vehicles (SDVs), where software governs most vehicle functions alongside enhanced connectivity, the need for secure software updates has become increasingly critical. Software vulnerabilities can severely impact safety, the economy, and society. In response to this challenge, Strandberg et al. [escar Europe, 2021] introduced the Unified Software Update Framework (UniSUF), designed to provide a secure update framework that integrates seamlessly with existing vehicular infrastructures.\n  Although UniSUF has previously been evaluated regarding cybersecurity, these assessments have not employed formal verification methods. To bridge this gap, we perform a formal security analysis of UniSUF. We model UniSUF's architecture and assumptions to reflect real-world automotive systems and develop a ProVerif-based framework that formally verifies UniSUF's compliance with essential security requirements - confidentiality, integrity, authenticity, freshness, order, and liveness - demonstrating their satisfiability through symbolic execution. Our results demonstrate that UniSUF adheres to the specified security guarantees, ensuring the correctness and reliability of its security framework.", "AI": {"tldr": "\u672c\u6587\u5bf9UniSUF\u8f6f\u4ef6\u66f4\u65b0\u6846\u67b6\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u5b89\u5168\u5206\u6790\uff0c\u4f7f\u7528ProVerif\u9a8c\u8bc1\u5176\u6ee1\u8db3\u673a\u5bc6\u6027\u3001\u5b8c\u6574\u6027\u3001\u771f\u5b9e\u6027\u3001\u65b0\u9c9c\u6027\u3001\u987a\u5e8f\u6027\u548c\u6d3b\u6027\u7b49\u5b89\u5168\u8981\u6c42\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86(SDVs)\u7684\u5174\u8d77\uff0c\u8f6f\u4ef6\u6f0f\u6d1e\u53ef\u80fd\u4e25\u91cd\u5f71\u54cd\u5b89\u5168\u6027\u3001\u7ecf\u6d4e\u548c\u793e\u4f1a\u3002\u867d\u7136UniSUF\u5df2\u88ab\u63d0\u51fa\u4f5c\u4e3a\u5b89\u5168\u66f4\u65b0\u6846\u67b6\uff0c\u4f46\u4e4b\u524d\u7684\u5b89\u5168\u8bc4\u4f30\u672a\u4f7f\u7528\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\u3002", "method": "\u5efa\u7acbUniSUF\u7684\u67b6\u6784\u548c\u5047\u8bbe\u6a21\u578b\u4ee5\u53cd\u6620\u771f\u5b9e\u6c7d\u8f66\u7cfb\u7edf\uff0c\u5f00\u53d1\u57fa\u4e8eProVerif\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7b26\u53f7\u6267\u884c\u5f62\u5f0f\u5316\u9a8c\u8bc1UniSUF\u5bf9\u5173\u952e\u5b89\u5168\u8981\u6c42\u7684\u7b26\u5408\u6027\u3002", "result": "\u5206\u6790\u7ed3\u679c\u8868\u660eUniSUF\u9075\u5faa\u6307\u5b9a\u7684\u5b89\u5168\u4fdd\u8bc1\uff0c\u786e\u4fdd\u5176\u5b89\u5168\u6846\u67b6\u7684\u6b63\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "UniSUF\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u88ab\u8bc1\u660e\u6ee1\u8db3\u6240\u6709\u5fc5\u9700\u7684\u5b89\u5168\u8981\u6c42\uff0c\u4e3a\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u5b89\u5168\u66f4\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.15165", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15165", "abs": "https://arxiv.org/abs/2511.15165", "authors": ["Jingzhuo Zhou"], "title": "Can MLLMs Detect Phishing? A Comprehensive Security Benchmark Suite Focusing on Dynamic Threats and Multimodal Evaluation in Academic Environments", "comment": null, "summary": "The rapid proliferation of Multimodal Large Language Models (MLLMs) has introduced unprecedented security challenges, particularly in phishing detection within academic environments. Academic institutions and researchers are high-value targets, facing dynamic, multilingual, and context-dependent threats that leverage research backgrounds, academic collaborations, and personal information to craft highly tailored attacks. Existing security benchmarks largely rely on datasets that do not incorporate specific academic background information, making them inadequate for capturing the evolving attack patterns and human-centric vulnerability factors specific to academia. To address this gap, we present AdapT-Bench, a unified methodological framework and benchmark suite for systematically evaluating MLLM defense capabilities against dynamic phishing attacks in academic settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86AdapT-Bench\u57fa\u51c6\u5957\u4ef6\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b66\u672f\u73af\u5883\u4e2d\u5bf9\u6297\u52a8\u6001\u9493\u9c7c\u653b\u51fb\u7684\u9632\u5fa1\u80fd\u529b\u3002", "motivation": "\u5b66\u672f\u673a\u6784\u548c\u7814\u7a76\u4eba\u5458\u9762\u4e34\u5229\u7528\u7814\u7a76\u80cc\u666f\u3001\u5b66\u672f\u5408\u4f5c\u548c\u4e2a\u4eba\u4fe1\u606f\u7684\u9ad8\u5ea6\u5b9a\u5236\u5316\u9493\u9c7c\u653b\u51fb\uff0c\u73b0\u6709\u5b89\u5168\u57fa\u51c6\u7f3a\u4e4f\u5b66\u672f\u80cc\u666f\u4fe1\u606f\uff0c\u65e0\u6cd5\u6355\u6349\u5b66\u672f\u73af\u5883\u7279\u6709\u7684\u653b\u51fb\u6a21\u5f0f\u3002", "method": "\u5f00\u53d1\u4e86AdapT-Bench\u7edf\u4e00\u65b9\u6cd5\u6846\u67b6\u548c\u57fa\u51c6\u5957\u4ef6\uff0c\u7cfb\u7edf\u8bc4\u4f30MLLM\u5728\u5b66\u672f\u73af\u5883\u4e2d\u7684\u9493\u9c7c\u653b\u51fb\u9632\u5fa1\u80fd\u529b\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u5b66\u672f\u73af\u5883\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u597d\u5730\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u3001\u591a\u8bed\u8a00\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u9493\u9c7c\u653b\u51fb\u4e2d\u7684\u8868\u73b0\u3002", "conclusion": "AdapT-Bench\u586b\u8865\u4e86\u73b0\u6709\u5b89\u5168\u57fa\u51c6\u5728\u5b66\u672f\u73af\u5883\u9493\u9c7c\u653b\u51fb\u68c0\u6d4b\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u4e3a\u8bc4\u4f30MLLM\u9632\u5fa1\u80fd\u529b\u63d0\u4f9b\u4e86\u66f4\u5408\u9002\u7684\u6d4b\u8bd5\u5de5\u5177\u3002"}}
{"id": "2511.15564", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.15564", "abs": "https://arxiv.org/abs/2511.15564", "authors": ["Paul Scheffler", "Thomas Benz", "Tim Fischer", "Lorenzo Leone", "Sina Arjmandpour", "Luca Benini"], "title": "Toward Open-Source Chiplets for HPC and AI: Occamy and Beyond", "comment": "8 pages, 8 figures, 1 table, submitted to 2026 IEEE CICC for possible publication", "summary": "We present a roadmap for open-source chiplet-based RISC-V systems targeting high-performance computing and artificial intelligence, aiming to close the performance gap to proprietary designs. Starting with Occamy, the first open, silicon-proven dual-chiplet RISC-V manycore in 12nm FinFET, we scale to Ramora, a mesh-NoC-based dual-chiplet system, and to Ogopogo, a 7nm quad-chiplet concept architecture achieving state-of-the-art compute density. Finally, we explore possible avenues to extend openness beyond logic-core RTL into simulation, EDA, PDKs, and off-die PHYs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5f00\u6e90chiplet\u7684RISC-V\u7cfb\u7edf\u8def\u7ebf\u56fe\uff0c\u4eceOccamy\u53ccchiplet\u7cfb\u7edf\u6269\u5c55\u5230Ramora\u548cOgopogo\u56dbchiplet\u67b6\u6784\uff0c\u65e8\u5728\u7f29\u5c0f\u4e0e\u4e13\u6709\u8bbe\u8ba1\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u5e76\u5c06\u5f00\u653e\u6027\u6269\u5c55\u5230EDA\u5de5\u5177\u94fe\u7b49\u9886\u57df\u3002", "motivation": "\u7f29\u5c0fRISC-V\u5f00\u6e90\u7cfb\u7edf\u4e0e\u4e13\u6709\u8bbe\u8ba1\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u63a8\u52a8\u9ad8\u6027\u80fd\u8ba1\u7b97\u548c\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u5f00\u6e90\u786c\u4ef6\u53d1\u5c55\u3002", "method": "\u91c7\u7528chiplet\u67b6\u6784\u65b9\u6cd5\uff0c\u4ece12nm FinFET\u5de5\u827a\u7684Occamy\u53ccchiplet\u7cfb\u7edf\u5f00\u59cb\uff0c\u6269\u5c55\u5230\u57fa\u4e8emesh-NoC\u7684Ramora\u7cfb\u7edf\uff0c\u518d\u52307nm\u5de5\u827a\u7684Ogopogo\u56dbchiplet\u6982\u5ff5\u67b6\u6784\u3002", "result": "\u5b9e\u73b0\u4e86\u9996\u4e2a\u5f00\u6e90\u7845\u9a8c\u8bc1\u7684\u53ccchiplet RISC-V\u591a\u6838\u7cfb\u7edf(Occamy)\uff0c\u5e76\u5f00\u53d1\u51fa\u5177\u6709\u6700\u5148\u8fdb\u8ba1\u7b97\u5bc6\u5ea6\u7684\u56dbchiplet\u67b6\u6784(Ogopogo)\u3002", "conclusion": "\u5f00\u6e90chiplet\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347RISC-V\u7cfb\u7edf\u6027\u80fd\uff0c\u672a\u6765\u9700\u8981\u5c06\u5f00\u653e\u6027\u6269\u5c55\u5230\u4eff\u771f\u3001EDA\u3001PDK\u548c\u7247\u5916PHY\u7b49\u66f4\u5e7f\u6cdb\u7684\u9886\u57df\u3002"}}
{"id": "2511.15055", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.15055", "abs": "https://arxiv.org/abs/2511.15055", "authors": ["Jian-Ting Guo", "Yu-Cheng Chen", "Ping-Chun Hsieh", "Kuo-Hao Ho", "Po-Wei Huang", "Ti-Rong Wu", "I-Chen Wu"], "title": "Learning Human-Like RL Agents Through Trajectory Optimization With Action Quantization", "comment": "Accepted by the Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025)", "summary": "Human-like agents have long been one of the goals in pursuing artificial intelligence. Although reinforcement learning (RL) has achieved superhuman performance in many domains, relatively little attention has been focused on designing human-like RL agents. As a result, many reward-driven RL agents often exhibit unnatural behaviors compared to humans, raising concerns for both interpretability and trustworthiness. To achieve human-like behavior in RL, this paper first formulates human-likeness as trajectory optimization, where the objective is to find an action sequence that closely aligns with human behavior while also maximizing rewards, and adapts the classic receding-horizon control to human-like learning as a tractable and efficient implementation. To achieve this, we introduce Macro Action Quantization (MAQ), a human-like RL framework that distills human demonstrations into macro actions via Vector-Quantized VAE. Experiments on D4RL Adroit benchmarks show that MAQ significantly improves human-likeness, increasing trajectory similarity scores, and achieving the highest human-likeness rankings among all RL agents in the human evaluation study. Our results also demonstrate that MAQ can be easily integrated into various off-the-shelf RL algorithms, opening a promising direction for learning human-like RL agents. Our code is available at https://rlg.iis.sinica.edu.tw/papers/MAQ.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Macro Action Quantization (MAQ)\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u4eba\u7c7b\u6f14\u793a\u84b8\u998f\u4e3a\u5b8f\u89c2\u52a8\u4f5c\u6765\u8bad\u7ec3\u7c7b\u4f3c\u4eba\u7c7b\u7684\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\uff0c\u5728D4RL Adroit\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u4eba\u7c7b\u76f8\u4f3c\u5ea6\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u867d\u7136\u5728\u8bb8\u591a\u9886\u57df\u8868\u73b0\u51fa\u8d85\u4eba\u7c7b\u6027\u80fd\uff0c\u4f46\u5f80\u5f80\u5c55\u73b0\u51fa\u4e0e\u4eba\u7c7b\u76f8\u6bd4\u4e0d\u81ea\u7136\u7684\u884c\u4e3a\uff0c\u8fd9\u5f15\u53d1\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u8d56\u6027\u7684\u62c5\u5fe7\u3002\u672c\u6587\u65e8\u5728\u8bbe\u8ba1\u80fd\u591f\u4ea7\u751f\u7c7b\u4f3c\u4eba\u7c7b\u884c\u4e3a\u7684\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u3002", "method": "\u5c06\u4eba\u7c7b\u76f8\u4f3c\u5ea6\u5efa\u6a21\u4e3a\u8f68\u8ff9\u4f18\u5316\u95ee\u9898\uff0c\u91c7\u7528\u540e\u9000\u65f6\u57df\u63a7\u5236\u4f5c\u4e3a\u53ef\u6269\u5c55\u5b9e\u73b0\u3002\u63d0\u51faMAQ\u6846\u67b6\uff0c\u4f7f\u7528Vector-Quantized VAE\u4ece\u4eba\u7c7b\u6f14\u793a\u4e2d\u84b8\u998f\u51fa\u5b8f\u89c2\u52a8\u4f5c\u3002", "result": "\u5728D4RL Adroit\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMAQ\u663e\u8457\u63d0\u9ad8\u4e86\u4eba\u7c7b\u76f8\u4f3c\u5ea6\uff0c\u589e\u52a0\u4e86\u8f68\u8ff9\u76f8\u4f3c\u5ea6\u5f97\u5206\uff0c\u5e76\u5728\u4eba\u7c7b\u8bc4\u4f30\u7814\u7a76\u4e2d\u83b7\u5f97\u4e86\u6240\u6709RL\u667a\u80fd\u4f53\u4e2d\u6700\u9ad8\u7684\u4eba\u7c7b\u76f8\u4f3c\u5ea6\u6392\u540d\u3002", "conclusion": "MAQ\u53ef\u4ee5\u8f7b\u677e\u96c6\u6210\u5230\u5404\u79cd\u73b0\u6210\u7684RL\u7b97\u6cd5\u4e2d\uff0c\u4e3a\u5b66\u4e60\u7c7b\u4f3c\u4eba\u7c7b\u7684RL\u667a\u80fd\u4f53\u5f00\u8f9f\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2511.15061", "categories": ["cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.15061", "abs": "https://arxiv.org/abs/2511.15061", "authors": ["Haodong Chen", "Guido Zuccon", "Teerapong Leelanupab"], "title": "Beyond GeneGPT: A Multi-Agent Architecture with Open-Source LLMs for Enhanced Genomic Question Answering", "comment": "This paper has been accepted to SIGIR-AP 2025", "summary": "Genomic question answering often requires complex reasoning and integration across diverse biomedical sources. GeneGPT addressed this challenge by combining domain-specific APIs with OpenAI's code-davinci-002 large language model to enable natural language interaction with genomic databases. However, its reliance on a proprietary model limits scalability, increases operational costs, and raises concerns about data privacy and generalization.\n  In this work, we revisit and reproduce GeneGPT in a pilot study using open source models, including Llama 3.1, Qwen2.5, and Qwen2.5 Coder, within a monolithic architecture; this allows us to identify the limitations of this approach. Building on this foundation, we then develop OpenBioLLM, a modular multi-agent framework that extends GeneGPT by introducing agent specialization for tool routing, query generation, and response validation. This enables coordinated reasoning and role-based task execution.\n  OpenBioLLM matches or outperforms GeneGPT on over 90% of the benchmark tasks, achieving average scores of 0.849 on Gene-Turing and 0.830 on GeneHop, while using smaller open-source models without additional fine-tuning or tool-specific pretraining. OpenBioLLM's modular multi-agent design reduces latency by 40-50% across benchmark tasks, significantly improving efficiency without compromising model capability. The results of our comprehensive evaluation highlight the potential of open-source multi-agent systems for genomic question answering. Code and resources are available at https://github.com/ielab/OpenBioLLM.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86OpenBioLLM\uff0c\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u57fa\u56e0\u7ec4\u95ee\u7b54\u3002\u5b83\u4f7f\u7528\u5f00\u6e90\u6a21\u578b\u66ff\u4ee3GeneGPT\u7684\u4e13\u6709\u6a21\u578b\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u4e13\u4e1a\u5316\u5b9e\u73b0\u5de5\u5177\u8def\u7531\u3001\u67e5\u8be2\u751f\u6210\u548c\u54cd\u5e94\u9a8c\u8bc1\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\u548c\u6210\u672c\u3002", "motivation": "\u89e3\u51b3GeneGPT\u4f9d\u8d56\u4e13\u6709\u6a21\u578b\u5e26\u6765\u7684\u53ef\u6269\u5c55\u6027\u3001\u8fd0\u8425\u6210\u672c\u3001\u6570\u636e\u9690\u79c1\u548c\u6cdb\u5316\u6027\u95ee\u9898\uff0c\u63a2\u7d22\u5f00\u6e90\u6a21\u578b\u5728\u57fa\u56e0\u7ec4\u95ee\u7b54\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u62ec\u5de5\u5177\u8def\u7531\u3001\u67e5\u8be2\u751f\u6210\u548c\u54cd\u5e94\u9a8c\u8bc1\u4e09\u4e2a\u4e13\u4e1a\u667a\u80fd\u4f53\uff0c\u4f7f\u7528Llama 3.1\u3001Qwen2.5\u7b49\u5f00\u6e90\u6a21\u578b\uff0c\u65e0\u9700\u989d\u5916\u5fae\u8c03\u6216\u5de5\u5177\u7279\u5b9a\u9884\u8bad\u7ec3\u3002", "result": "\u572890%\u4ee5\u4e0a\u7684\u57fa\u51c6\u4efb\u52a1\u4e2d\u8fbe\u5230\u6216\u8d85\u8fc7GeneGPT\u6027\u80fd\uff0cGene-Turing\u5e73\u5747\u5f97\u52060.849\uff0cGeneHop\u5e73\u5747\u5f97\u52060.830\uff0c\u5ef6\u8fdf\u964d\u4f4e40-50%\u3002", "conclusion": "\u5f00\u6e90\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u57fa\u56e0\u7ec4\u95ee\u7b54\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u4ee5\u66f4\u4f4e\u7684\u6210\u672c\u548c\u66f4\u9ad8\u7684\u6548\u7387\u5b9e\u73b0\u4e0e\u4e13\u6709\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002"}}
{"id": "2511.15069", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15069", "abs": "https://arxiv.org/abs/2511.15069", "authors": ["Haoyong Wu", "Yongmei Liu"], "title": "ProRAC: A Neuro-symbolic Method for Reasoning about Actions with LLM-based Progression", "comment": null, "summary": "In this paper, we propose ProRAC (Progression-based Reasoning about Actions and Change), a neuro-symbolic framework that leverages LLMs to tackle RAC problems. ProRAC extracts fundamental RAC elements including actions and questions from the problem, progressively executes each action to derive the final state, and then evaluates the query against the progressed state to arrive at an answer. We evaluate ProRAC on several RAC benchmarks, and the results demonstrate that our approach achieves strong performance across different benchmarks, domains, LLM backbones, and types of RAC tasks.", "AI": {"tldr": "ProRAC\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u5229\u7528LLM\u5904\u7406\u52a8\u4f5c\u548c\u53d8\u5316\u63a8\u7406\u95ee\u9898\uff0c\u901a\u8fc7\u9010\u6b65\u6267\u884c\u52a8\u4f5c\u63a8\u5bfc\u6700\u7ec8\u72b6\u6001\u5e76\u8bc4\u4f30\u67e5\u8be2\u6765\u83b7\u5f97\u7b54\u6848\u3002", "motivation": "\u89e3\u51b3\u52a8\u4f5c\u548c\u53d8\u5316\u63a8\u7406\u95ee\u9898\uff0c\u5229\u7528LLM\u7684\u80fd\u529b\u6765\u5904\u7406\u590d\u6742\u7684RAC\u4efb\u52a1\u3002", "method": "\u63d0\u53d6RAC\u57fa\u672c\u5143\u7d20\uff08\u52a8\u4f5c\u548c\u95ee\u9898\uff09\uff0c\u9010\u6b65\u6267\u884c\u6bcf\u4e2a\u52a8\u4f5c\u63a8\u5bfc\u6700\u7ec8\u72b6\u6001\uff0c\u7136\u540e\u8bc4\u4f30\u67e5\u8be2\u4e0e\u8fdb\u5c55\u72b6\u6001\u7684\u5339\u914d\u5ea6\u3002", "result": "\u5728\u591a\u4e2aRAC\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5728\u4e0d\u540c\u57fa\u51c6\u3001\u9886\u57df\u3001LLM\u4e3b\u5e72\u548cRAC\u4efb\u52a1\u7c7b\u578b\u4e0a\u90fd\u53d6\u5f97\u5f3a\u52b2\u6027\u80fd\u3002", "conclusion": "ProRAC\u6846\u67b6\u5728\u52a8\u4f5c\u548c\u53d8\u5316\u63a8\u7406\u95ee\u9898\u4e0a\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u548c\u5f3a\u5927\u6027\u80fd\u3002"}}
{"id": "2511.15074", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15074", "abs": "https://arxiv.org/abs/2511.15074", "authors": ["Henrik Bradland", "Morten Goodwin", "Vladimir I. Zadorozhny", "Per-Arne Andersen"], "title": "Knowledge-Informed Automatic Feature Extraction via Collaborative Large Language Model Agents", "comment": "19 pages, 4 figures, in review", "summary": "The performance of machine learning models on tabular data is critically dependent on high-quality feature engineering. While Large Language Models (LLMs) have shown promise in automating feature extraction (AutoFE), existing methods are often limited by monolithic LLM architectures, simplistic quantitative feedback, and a failure to systematically integrate external domain knowledge. This paper introduces Rogue One, a novel, LLM-based multi-agent framework for knowledge-informed automatic feature extraction. Rogue One operationalizes a decentralized system of three specialized agents-Scientist, Extractor, and Tester-that collaborate iteratively to discover, generate, and validate predictive features. Crucially, the framework moves beyond primitive accuracy scores by introducing a rich, qualitative feedback mechanism and a \"flooding-pruning\" strategy, allowing it to dynamically balance feature exploration and exploitation. By actively incorporating external knowledge via an integrated retrieval-augmented (RAG) system, Rogue One generates features that are not only statistically powerful but also semantically meaningful and interpretable. We demonstrate that Rogue One significantly outperforms state-of-the-art methods on a comprehensive suite of 19 classification and 9 regression datasets. Furthermore, we show qualitatively that the system surfaces novel, testable hypotheses, such as identifying a new potential biomarker in the myocardial dataset, underscoring its utility as a tool for scientific discovery.", "AI": {"tldr": "Rogue One\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u4e2a\u4e13\u4e1a\u667a\u80fd\u4f53\uff08\u79d1\u5b66\u5bb6\u3001\u63d0\u53d6\u5668\u3001\u6d4b\u8bd5\u5668\uff09\u7684\u534f\u4f5c\uff0c\u7ed3\u5408\u5916\u90e8\u9886\u57df\u77e5\u8bc6\u548c\u4e30\u5bcc\u7684\u5b9a\u6027\u53cd\u9988\u673a\u5236\uff0c\u5b9e\u73b0\u81ea\u52a8\u7279\u5f81\u63d0\u53d6\uff0c\u5728\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u5b58\u5728\u67b6\u6784\u5355\u4e00\u3001\u53cd\u9988\u673a\u5236\u7b80\u5355\u3001\u7f3a\u4e4f\u5916\u90e8\u77e5\u8bc6\u6574\u5408\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u7279\u5f81\u5de5\u7a0b\u7684\u8d28\u91cf\u548c\u6548\u679c\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u79d1\u5b66\u5bb6\u3001\u63d0\u53d6\u5668\u548c\u6d4b\u8bd5\u5668\u4e09\u4e2a\u4e13\u4e1a\u667a\u80fd\u4f53\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u5f15\u5165\u5916\u90e8\u77e5\u8bc6\uff0c\u4f7f\u7528\"\u6cdb\u6ee5-\u4fee\u526a\"\u7b56\u7565\u5e73\u8861\u7279\u5f81\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u5e76\u91c7\u7528\u4e30\u5bcc\u7684\u5b9a\u6027\u53cd\u9988\u673a\u5236\u3002", "result": "\u572819\u4e2a\u5206\u7c7b\u548c9\u4e2a\u56de\u5f52\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5e76\u80fd\u53d1\u73b0\u65b0\u9896\u53ef\u6d4b\u8bd5\u7684\u5047\u8bbe\uff0c\u5982\u5728\u5fc3\u808c\u6570\u636e\u96c6\u4e2d\u8bc6\u522b\u51fa\u65b0\u7684\u6f5c\u5728\u751f\u7269\u6807\u5fd7\u7269\u3002", "conclusion": "Rogue One\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u3001\u5916\u90e8\u77e5\u8bc6\u6574\u5408\u548c\u5b9a\u6027\u53cd\u9988\u673a\u5236\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u7279\u5f81\u63d0\u53d6\u6027\u80fd\uff0c\u8fd8\u589e\u5f3a\u4e86\u7279\u5f81\u7684\u53ef\u89e3\u91ca\u6027\u548c\u79d1\u5b66\u53d1\u73b0\u80fd\u529b\u3002"}}
{"id": "2511.15463", "categories": ["cs.CR", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.15463", "abs": "https://arxiv.org/abs/2511.15463", "authors": ["Minh Trung Tran", "Nasrin Sohrabi", "Zahir Tari", "Qin Wang"], "title": "How To Cook The Fragmented Rug Pull?", "comment": null, "summary": "Existing rug pull detectors assume a simple workflow: the deployer keeps liquidity pool (LP) tokens and performs one or a few large sells (within a day) that collapse the pool and cash out. In practice, however, many real-world exits violate these assumptions by splitting the attack across both time and actor dimensions: attackers break total extraction into many low-impact trades and route proceeds through multiple non-owner addresses, producing low-visibility drains.\n  We formalize this family of attacks as the fragmented rug pull (FRP) and offer a compact recipe for a slow-stewed beef special: (i) keep the lid on (to preserve LP control so on-chain extraction remains feasible), (ii) chop thin slices (to split the total exit volume into many low-impact micro-trades that individually fall below impact thresholds), and (iii) pass the ladle (to delegate sells across multiple wallets so that each participant takes a small share of the extraction). Technically, we define three atomic predicate groups and show that their orthogonal combinations yield evasive strategies overlooked by prior heuristics (USENIX Sec 19, USENIX Sec 23).\n  We validate the model with large-scale measurements. Our corpus contains 303,614 LPs, among which 105,434 are labeled as FRP pools. The labeled subset includes 34,192,767 pool-related transactions and 401,838 inflated-seller wallets, involving 1,501,408 unique interacting addresses. Notably, owner-wallet participation in inflated selling among FRP-flagged LPs has declined substantially (33.1% of cases), indicating a shift in scam behavior: the liquidity drain is no longer held on the owner wallet. We also detected 127,252 wallets acting as serial scammers when repeatedly engaging in inflated selling across multiple FRP LPs. Our empirical findings demonstrate that the evasive strategies we define are widespread and operationally significant.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u788e\u7247\u5316\u62c9\u5730\u6bef\u653b\u51fb(FRP)\u7684\u6982\u5ff5\uff0c\u6307\u51fa\u4f20\u7edf\u68c0\u6d4b\u5668\u5047\u8bbe\u653b\u51fb\u8005\u4f1a\u8fdb\u884c\u5355\u6b21\u5927\u89c4\u6a21\u629b\u552e\uff0c\u800c\u5b9e\u9645\u653b\u51fb\u5f80\u5f80\u901a\u8fc7\u65f6\u95f4\u5206\u6563\u548c\u53c2\u4e0e\u8005\u5206\u6563\u6765\u89c4\u907f\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709\u62c9\u5730\u6bef\u68c0\u6d4b\u5668\u5047\u8bbe\u653b\u51fb\u8005\u4f1a\u4fdd\u7559\u6d41\u52a8\u6027\u6c60\u4ee3\u5e01\u5e76\u8fdb\u884c\u5355\u6b21\u6216\u5c11\u91cf\u5927\u89c4\u6a21\u629b\u552e\uff0c\u4f46\u5b9e\u9645\u653b\u51fb\u5f80\u5f80\u8fdd\u53cd\u8fd9\u4e9b\u5047\u8bbe\uff0c\u901a\u8fc7\u65f6\u95f4\u5206\u6563\u548c\u53c2\u4e0e\u8005\u5206\u6563\u6765\u964d\u4f4e\u53ef\u89c1\u6027\u3002", "method": "\u5b9a\u4e49\u4e86\u788e\u7247\u5316\u62c9\u5730\u6bef\u653b\u51fb\u7684\u4e09\u4e2a\u6838\u5fc3\u7b56\u7565\uff1a\u4fdd\u6301\u6d41\u52a8\u6027\u6c60\u63a7\u5236\u3001\u5c06\u629b\u552e\u5206\u5272\u4e3a\u591a\u4e2a\u4f4e\u5f71\u54cd\u5fae\u4ea4\u6613\u3001\u901a\u8fc7\u591a\u4e2a\u94b1\u5305\u5206\u6563\u6267\u884c\u629b\u552e\u3002\u63d0\u51fa\u4e86\u4e09\u4e2a\u539f\u5b50\u8c13\u8bcd\u7ec4\u53ca\u5176\u6b63\u4ea4\u7ec4\u5408\u7684\u89c4\u907f\u7b56\u7565\u3002", "result": "\u5728\u5927\u89c4\u6a21\u6d4b\u91cf\u4e2d\uff0c\u5206\u6790\u4e86303,614\u4e2a\u6d41\u52a8\u6027\u6c60\uff0c\u8bc6\u522b\u51fa105,434\u4e2aFRP\u6c60\uff0c\u6d89\u53ca34,192,767\u7b14\u4ea4\u6613\u548c401,838\u4e2a\u629b\u552e\u94b1\u5305\u3002\u53d1\u73b0FRP\u6c60\u4e2d\u6240\u6709\u8005\u94b1\u5305\u53c2\u4e0e\u629b\u552e\u7684\u6bd4\u4f8b\u964d\u81f333.1%\uff0c\u5e76\u68c0\u6d4b\u5230127,252\u4e2a\u91cd\u590d\u53c2\u4e0e\u591a\u4e2aFRP\u6c60\u7684\u4e32\u884c\u8bc8\u9a97\u94b1\u5305\u3002", "conclusion": "\u788e\u7247\u5316\u62c9\u5730\u6bef\u653b\u51fb\u7b56\u7565\u5728\u73b0\u5b9e\u4e2d\u5e7f\u6cdb\u5b58\u5728\u4e14\u5177\u6709\u64cd\u4f5c\u610f\u4e49\uff0c\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u8bc6\u522b\u8fd9\u7c7b\u89c4\u907f\u6027\u653b\u51fb\u884c\u4e3a\u3002"}}
{"id": "2511.15169", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15169", "abs": "https://arxiv.org/abs/2511.15169", "authors": ["Xin Gao", "Shaohan Yu", "Zerui Chen", "Yueming Lyu", "Weichen Yu", "Guanghao Li", "Jiyao Liu", "Jianxiong Gao", "Jian Liang", "Ziwei Liu", "Chenyang Si"], "title": "SafeRBench: A Comprehensive Benchmark for Safety Assessment in Large Reasoning Models", "comment": "30 pages, 8 figures", "summary": "Large Reasoning Models (LRMs) improve answer quality through explicit chain-of-thought, yet this very capability introduces new safety risks: harmful content can be subtly injected, surface gradually, or be justified by misleading rationales within the reasoning trace. Existing safety evaluations, however, primarily focus on output-level judgments and rarely capture these dynamic risks along the reasoning process. In this paper, we present SafeRBench, the first benchmark that assesses LRM safety end-to-end -- from inputs and intermediate reasoning to final outputs. (1) Input Characterization: We pioneer the incorporation of risk categories and levels into input design, explicitly accounting for affected groups and severity, and thereby establish a balanced prompt suite reflecting diverse harm gradients. (2) Fine-Grained Output Analysis: We introduce a micro-thought chunking mechanism to segment long reasoning traces into semantically coherent units, enabling fine-grained evaluation across ten safety dimensions. (3) Human Safety Alignment: We validate LLM-based evaluations against human annotations specifically designed to capture safety judgments. Evaluations on 19 LRMs demonstrate that SafeRBench enables detailed, multidimensional safety assessment, offering insights into risks and protective mechanisms from multiple perspectives.", "AI": {"tldr": "SafeRBench\u662f\u9996\u4e2a\u7aef\u5230\u7aef\u8bc4\u4f30\u5927\u578b\u63a8\u7406\u6a21\u578b\u5b89\u5168\u6027\u7684\u57fa\u51c6\uff0c\u901a\u8fc7\u8f93\u5165\u7279\u5f81\u5316\u3001\u7ec6\u7c92\u5ea6\u8f93\u51fa\u5206\u6790\u548c\u4eba\u7c7b\u5b89\u5168\u5bf9\u9f50\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u5168\u9762\u8bc4\u4f30\u4ece\u8f93\u5165\u3001\u4e2d\u95f4\u63a8\u7406\u5230\u6700\u7ec8\u8f93\u51fa\u7684\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u8f93\u51fa\u5c42\u9762\u5224\u65ad\uff0c\u5f88\u5c11\u6355\u6349\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u52a8\u6001\u98ce\u9669\uff0c\u800c\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u94fe\u5f0f\u601d\u7ef4\u80fd\u529b\u53ef\u80fd\u5f15\u5165\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5982\u6709\u5bb3\u5185\u5bb9\u7684\u6e10\u8fdb\u5f0f\u6ce8\u5165\u6216\u88ab\u8bef\u5bfc\u7684\u63a8\u7406\u8fc7\u7a0b\u6240\u5408\u7406\u5316\u3002", "method": "1) \u8f93\u5165\u7279\u5f81\u5316\uff1a\u5c06\u98ce\u9669\u7c7b\u522b\u548c\u7ea7\u522b\u7eb3\u5165\u8f93\u5165\u8bbe\u8ba1\uff0c\u8003\u8651\u53d7\u5f71\u54cd\u7fa4\u4f53\u548c\u4e25\u91cd\u7a0b\u5ea6\uff1b2) \u7ec6\u7c92\u5ea6\u8f93\u51fa\u5206\u6790\uff1a\u901a\u8fc7\u5fae\u601d\u7ef4\u5206\u5757\u673a\u5236\u5c06\u957f\u63a8\u7406\u8f68\u8ff9\u5206\u5272\u4e3a\u8bed\u4e49\u8fde\u8d2f\u5355\u5143\uff1b3) \u4eba\u7c7b\u5b89\u5168\u5bf9\u9f50\uff1a\u57fa\u4e8e\u4eba\u7c7b\u6807\u6ce8\u9a8c\u8bc1LLM\u8bc4\u4f30\u7ed3\u679c\u3002", "result": "\u5bf919\u4e2a\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u8bc4\u4f30\u8868\u660e\uff0cSafeRBench\u80fd\u591f\u5b9e\u73b0\u8be6\u7ec6\u7684\u591a\u7ef4\u5ea6\u5b89\u5168\u8bc4\u4f30\uff0c\u4ece\u591a\u4e2a\u89d2\u5ea6\u63d0\u4f9b\u98ce\u9669\u548c\u4fdd\u62a4\u673a\u5236\u7684\u6d1e\u5bdf\u3002", "conclusion": "SafeRBench\u4e3a\u5927\u578b\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u548c\u91cf\u5316\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5b89\u5168\u98ce\u9669\uff0c\u586b\u8865\u4e86\u73b0\u6709\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u7684\u7a7a\u767d\u3002"}}
{"id": "2511.15192", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15192", "abs": "https://arxiv.org/abs/2511.15192", "authors": ["Haodong Li", "Jingqi Zhang", "Xiao Cheng", "Peihua Mai", "Haoyu Wang", "Yang Pan"], "title": "As If We've Met Before: LLMs Exhibit Certainty in Recognizing Seen Files", "comment": null, "summary": "The remarkable language ability of Large Language Models (LLMs) stems from extensive training on vast datasets, often including copyrighted material, which raises serious concerns about unauthorized use. While Membership Inference Attacks (MIAs) offer potential solutions for detecting such violations, existing approaches face critical limitations and challenges due to LLMs' inherent overconfidence, limited access to ground truth training data, and reliance on empirically determined thresholds.\n  We present COPYCHECK, a novel framework that leverages uncertainty signals to detect whether copyrighted content was used in LLM training sets. Our method turns LLM overconfidence from a limitation into an asset by capturing uncertainty patterns that reliably distinguish between ``seen\" (training data) and ``unseen\" (non-training data) content. COPYCHECK further implements a two-fold strategy: (1) strategic segmentation of files into smaller snippets to reduce dependence on large-scale training data, and (2) uncertainty-guided unsupervised clustering to eliminate the need for empirically tuned thresholds. Experiment results show that COPYCHECK achieves an average balanced accuracy of 90.1% on LLaMA 7b and 91.6% on LLaMA2 7b in detecting seen files. Compared to the SOTA baseline, COPYCHECK achieves over 90% relative improvement, reaching up to 93.8\\% balanced accuracy. It further exhibits strong generalizability across architectures, maintaining high performance on GPT-J 6B. This work presents the first application of uncertainty for copyright detection in LLMs, offering practical tools for training data transparency.", "AI": {"tldr": "COPYCHECK\u662f\u4e00\u4e2a\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u4fe1\u53f7\u68c0\u6d4bLLM\u8bad\u7ec3\u6570\u636e\u4e2d\u7248\u6743\u5185\u5bb9\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06LLM\u7684\u8fc7\u5ea6\u81ea\u4fe1\u8f6c\u5316\u4e3a\u4f18\u52bf\uff0c\u8bc6\u522b\u8bad\u7ec3\u6570\u636e\u4e0e\u975e\u8bad\u7ec3\u6570\u636e\u7684\u6a21\u5f0f\u5dee\u5f02\u3002", "motivation": "LLM\u5728\u8bad\u7ec3\u65f6\u53ef\u80fd\u4f7f\u7528\u4e86\u53d7\u7248\u6743\u4fdd\u62a4\u7684\u5185\u5bb9\uff0c\u73b0\u6709\u6210\u5458\u63a8\u65ad\u653b\u51fb\u65b9\u6cd5\u56e0LLM\u7684\u8fc7\u5ea6\u81ea\u4fe1\u3001\u7f3a\u4e4f\u771f\u5b9e\u8bad\u7ec3\u6570\u636e\u548c\u4f9d\u8d56\u7ecf\u9a8c\u9608\u503c\u800c\u9762\u4e34\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u7b56\u7565\uff1a(1) \u5c06\u6587\u4ef6\u5206\u5272\u6210\u5c0f\u7247\u6bb5\u51cf\u5c11\u5bf9\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u7684\u4f9d\u8d56\uff1b(2) \u4f7f\u7528\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u7684\u65e0\u76d1\u7763\u805a\u7c7b\u6d88\u9664\u7ecf\u9a8c\u9608\u503c\u9700\u6c42\u3002", "result": "\u5728LLaMA 7b\u548cLLaMA2 7b\u4e0a\u5206\u522b\u8fbe\u523090.1%\u548c91.6%\u7684\u5e73\u5747\u5e73\u8861\u51c6\u786e\u7387\uff0c\u76f8\u6bd4SOTA\u57fa\u7ebf\u670990%\u4ee5\u4e0a\u7684\u76f8\u5bf9\u63d0\u5347\uff0c\u6700\u9ad8\u8fbe\u523093.8%\u5e73\u8861\u51c6\u786e\u7387\uff0c\u5728GPT-J 6B\u4e0a\u4e5f\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5c06\u4e0d\u786e\u5b9a\u6027\u5e94\u7528\u4e8eLLM\u7248\u6743\u68c0\u6d4b\u7684\u5de5\u4f5c\uff0c\u4e3a\u8bad\u7ec3\u6570\u636e\u900f\u660e\u5ea6\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2511.15259", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.15259", "abs": "https://arxiv.org/abs/2511.15259", "authors": ["Philipp Wiesner", "Daniel W. O'Neill", "Francesca Larosa", "Odej Kao"], "title": "Efficiency Will Not Lead to Sustainable Reasoning AI", "comment": "Presented at the Rethinking AI Workshop @ EurIPS'25", "summary": "AI research is increasingly moving toward complex problem solving, where models are optimized not only for pattern recognition but for multi-step reasoning. Historically, computing's global energy footprint has been stabilized by sustained efficiency gains and natural saturation thresholds in demand. But as efficiency improvements are approaching physical limits, emerging reasoning AI lacks comparable saturation points: performance is no longer limited by the amount of available training data but continues to scale with exponential compute investments in both training and inference. This paper argues that efficiency alone will not lead to sustainable reasoning AI and discusses research and policy directions to embed explicit limits into the optimization and governance of such systems.", "AI": {"tldr": "\u672c\u6587\u8ba4\u4e3a\u4ec5\u9760\u6548\u7387\u63d0\u5347\u65e0\u6cd5\u5b9e\u73b0\u53ef\u6301\u7eed\u7684\u63a8\u7406AI\uff0c\u9700\u8981\u5c06\u660e\u786e\u9650\u5236\u5d4c\u5165\u5230\u8fd9\u7c7b\u7cfb\u7edf\u7684\u4f18\u5316\u548c\u6cbb\u7406\u4e2d", "motivation": "AI\u7814\u7a76\u6b63\u8f6c\u5411\u590d\u6742\u95ee\u9898\u89e3\u51b3\uff0c\u63a8\u7406AI\u7f3a\u4e4f\u9700\u6c42\u9971\u548c\u70b9\uff0c\u6027\u80fd\u968f\u8ba1\u7b97\u6295\u5165\u5448\u6307\u6570\u7ea7\u589e\u957f\uff0c\u800c\u6548\u7387\u6539\u8fdb\u6b63\u63a5\u8fd1\u7269\u7406\u6781\u9650", "method": "\u8ba8\u8bba\u4e86\u63a8\u7406AI\u7684\u53ef\u6301\u7eed\u6027\u95ee\u9898\uff0c\u5206\u6790\u6548\u7387\u6539\u8fdb\u7684\u7269\u7406\u9650\u5236\u548c\u63a8\u7406AI\u7f3a\u4e4f\u9971\u548c\u70b9\u7684\u7279\u6027", "result": "\u8bc6\u522b\u51fa\u4ec5\u9760\u6548\u7387\u65e0\u6cd5\u89e3\u51b3\u63a8\u7406AI\u7684\u53ef\u6301\u7eed\u6027\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u7814\u7a76\u653f\u7b56\u65b9\u5411", "conclusion": "\u5fc5\u987b\u5728\u63a8\u7406AI\u7cfb\u7edf\u7684\u4f18\u5316\u548c\u6cbb\u7406\u4e2d\u5d4c\u5165\u660e\u786e\u9650\u5236\uff0c\u4ee5\u5b9e\u73b0\u53ef\u6301\u7eed\u53d1\u5c55"}}
{"id": "2511.15282", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15282", "abs": "https://arxiv.org/abs/2511.15282", "authors": ["Ninell Oldenburg", "Ruchira Dhar", "Anders S\u00f8gaard"], "title": "Realist and Pluralist Conceptions of Intelligence and Their Implications on AI Research", "comment": "The 40th Annual AAAI Conference on Artificial Intelligence, 8 pages (excl. references), 1 table", "summary": "In this paper, we argue that current AI research operates on a spectrum between two different underlying conceptions of intelligence: Intelligence Realism, which holds that intelligence represents a single, universal capacity measurable across all systems, and Intelligence Pluralism, which views intelligence as diverse, context-dependent capacities that cannot be reduced to a single universal measure. Through an analysis of current debates in AI research, we demonstrate how the conceptions remain largely implicit yet fundamentally shape how empirical evidence gets interpreted across a wide range of areas. These underlying views generate fundamentally different research approaches across three areas. Methodologically, they produce different approaches to model selection, benchmark design, and experimental validation. Interpretively, they lead to contradictory readings of the same empirical phenomena, from capability emergence to system limitations. Regarding AI risk, they generate categorically different assessments: realists view superintelligence as the primary risk and search for unified alignment solutions, while pluralists see diverse threats across different domains requiring context-specific solutions. We argue that making explicit these underlying assumptions can contribute to a clearer understanding of disagreements in AI research.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u7814\u7a76\u4e2d\u4e24\u79cd\u57fa\u672c\u667a\u80fd\u89c2\uff1a\u667a\u80fd\u73b0\u5b9e\u4e3b\u4e49\uff08\u8ba4\u4e3a\u667a\u80fd\u662f\u5355\u4e00\u901a\u7528\u80fd\u529b\uff09\u548c\u667a\u80fd\u591a\u5143\u4e3b\u4e49\uff08\u8ba4\u4e3a\u667a\u80fd\u662f\u591a\u6837\u5316\u3001\u60c5\u5883\u4f9d\u8d56\u7684\u80fd\u529b\uff09\uff0c\u5206\u6790\u4e86\u8fd9\u4e24\u79cd\u89c2\u70b9\u5982\u4f55\u5f71\u54cd\u7814\u7a76\u65b9\u6cd5\u3001\u73b0\u8c61\u89e3\u91ca\u548c\u98ce\u9669\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524dAI\u7814\u7a76\u4e2d\u5bf9\u667a\u80fd\u672c\u8d28\u7684\u9690\u542b\u5047\u8bbe\u5f71\u54cd\u4e86\u7814\u7a76\u65b9\u6cd5\u548c\u7ed3\u8bba\uff0c\u4f46\u8fd9\u4e9b\u95ee\u9898\u5f80\u5f80\u672a\u88ab\u660e\u786e\u8ba8\u8bba\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u8fd9\u4e9b\u57fa\u7840\u5047\u8bbe\uff0c\u4ee5\u6f84\u6e05AI\u7814\u7a76\u4e2d\u7684\u5206\u6b67\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5f53\u524dAI\u7814\u7a76\u4e2d\u7684\u8fa9\u8bba\uff0c\u5c55\u793a\u4e24\u79cd\u667a\u80fd\u89c2\u5982\u4f55\u5728\u4e0d\u540c\u9886\u57df\u5f71\u54cd\u5b9e\u8bc1\u8bc1\u636e\u7684\u89e3\u91ca\uff0c\u5305\u62ec\u65b9\u6cd5\u8bba\u3001\u73b0\u8c61\u89e3\u91ca\u548c\u98ce\u9669\u8bc4\u4f30\u4e09\u4e2a\u5c42\u9762\u3002", "result": "\u53d1\u73b0\u667a\u80fd\u73b0\u5b9e\u4e3b\u4e49\u5bfc\u81f4\u8ffd\u6c42\u901a\u7528\u6a21\u578b\u548c\u7edf\u4e00\u57fa\u51c6\uff0c\u5173\u6ce8\u8d85\u7ea7\u667a\u80fd\u98ce\u9669\uff1b\u667a\u80fd\u591a\u5143\u4e3b\u4e49\u5219\u5f3a\u8c03\u60c5\u5883\u5316\u65b9\u6cd5\u548c\u591a\u6837\u5316\u5a01\u80c1\uff0c\u9700\u8981\u7279\u5b9a\u9886\u57df\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u660e\u786e\u8fd9\u4e9b\u57fa\u7840\u5047\u8bbe\u6709\u52a9\u4e8e\u66f4\u6e05\u6670\u5730\u7406\u89e3AI\u7814\u7a76\u4e2d\u7684\u5206\u6b67\uff0c\u4fc3\u8fdb\u66f4\u5bcc\u6709\u6210\u6548\u7684\u5b66\u672f\u8ba8\u8bba\u3002"}}
{"id": "2511.15378", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15378", "abs": "https://arxiv.org/abs/2511.15378", "authors": ["Trevor McInroe"], "title": "Terra Nova: A Comprehensive Challenge Environment for Intelligent Agents", "comment": null, "summary": "We introduce Terra Nova, a new comprehensive challenge environment (CCE) for reinforcement learning (RL) research inspired by Civilization V. A CCE is a single environment in which multiple canonical RL challenges (e.g., partial observability, credit assignment, representation learning, enormous action spaces, etc.) arise simultaneously. Mastery therefore demands integrated, long-horizon understanding across many interacting variables. We emphasize that this definition excludes challenges that only aggregate unrelated tasks in independent, parallel streams (e.g., learning to play all Atari games at once). These aggregated multitask benchmarks primarily asses whether an agent can catalog and switch among unrelated policies rather than test an agent's ability to perform deep reasoning across many interacting challenges.", "AI": {"tldr": "Terra Nova\u662f\u4e00\u4e2a\u57fa\u4e8e\u300a\u6587\u660eV\u300b\u7684\u7efc\u5408\u6027\u6311\u6218\u73af\u5883\uff0c\u65e8\u5728\u540c\u65f6\u6d4b\u8bd5\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u3001\u4fe1\u7528\u5206\u914d\u3001\u8868\u793a\u5b66\u4e60\u3001\u5de8\u5927\u52a8\u4f5c\u7a7a\u95f4\u7b49\u591a\u4e2a\u7ecf\u5178\u6311\u6218\u4e0a\u7684\u7efc\u5408\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u4efb\u52a1\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u4e0d\u540c\u65e0\u5173\u4efb\u52a1\u95f4\u5207\u6362\u7b56\u7565\u7684\u80fd\u529b\uff0c\u800c\u7f3a\u4e4f\u5bf9\u667a\u80fd\u4f53\u5728\u591a\u4e2a\u76f8\u4e92\u5173\u8054\u6311\u6218\u4e2d\u8fdb\u884c\u6df1\u5ea6\u63a8\u7406\u80fd\u529b\u7684\u6d4b\u8bd5\u3002", "method": "\u5f00\u53d1\u4e86Terra Nova\u73af\u5883\uff0c\u8fd9\u662f\u4e00\u4e2a\u5355\u4e00\u73af\u5883\uff0c\u5176\u4e2d\u591a\u4e2a\u7ecf\u5178\u5f3a\u5316\u5b66\u4e60\u6311\u6218\u540c\u65f6\u51fa\u73b0\uff0c\u8981\u6c42\u667a\u80fd\u4f53\u8fdb\u884c\u6574\u5408\u6027\u7684\u957f\u671f\u7406\u89e3\u3002", "result": "\u63d0\u51fa\u4e86\u7efc\u5408\u6027\u6311\u6218\u73af\u5883\u7684\u65b0\u5b9a\u4e49\uff0c\u6392\u9664\u4e86\u4ec5\u805a\u5408\u65e0\u5173\u4efb\u52a1\u7684\u5e76\u884c\u6d41\u73af\u5883\uff0c\u5f3a\u8c03\u9700\u8981\u6d4b\u8bd5\u667a\u80fd\u4f53\u5728\u591a\u4e2a\u76f8\u4e92\u5173\u8054\u6311\u6218\u4e2d\u7684\u6df1\u5ea6\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "Terra Nova\u4e3a\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u5168\u9762\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u80fd\u591f\u66f4\u597d\u5730\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u590d\u6742\u3001\u76f8\u4e92\u5173\u8054\u73af\u5883\u4e2d\u7684\u7efc\u5408\u8868\u73b0\u3002"}}
{"id": "2511.15407", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.15407", "abs": "https://arxiv.org/abs/2511.15407", "authors": ["Mingyu Zhang", "Lifeng Zhuo", "Tianxi Tan", "Guocan Xie", "Xian Nie", "Yan Li", "Renjie Zhao", "Zizhu He", "Ziyu Wang", "Jiting Cai", "Yong-Lu Li"], "title": "IPR-1: Interactive Physical Reasoner", "comment": "11 pages, 5 figures", "summary": "Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. We study this in a Game-to-Unseen (G2U) setting, curating 1,000+ heterogeneous games with diverse physical and causal mechanisms, and evaluate at three human-like levels: Survival, Curiosity, Utility, from primitive intuition to goal-driven reasoning. Our analysis reveals complementary failures: VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on three levels, matches GPT-5 overall, and surpasses it on Curiosity. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u667a\u80fd\u4f53\u80fd\u5426\u901a\u8fc7\u4ea4\u4e92\u5b66\u4e60\u83b7\u5f97\u7c7b\u4eba\u7269\u7406\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u51fa\u4e86IPR\u6a21\u578b\uff0c\u4f7f\u7528\u4e16\u754c\u6a21\u578b\u63a8\u6f14\u6765\u589e\u5f3aVLM\u7b56\u7565\uff0c\u5e76\u57281000+\u6e38\u620f\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u63a2\u7d22\u667a\u80fd\u4f53\u662f\u5426\u80fd\u591f\u50cf\u4eba\u7c7b\u4e00\u6837\u901a\u8fc7\u89c2\u5bdf\u548c\u4ea4\u4e92\u73af\u5883\u6765\u5b66\u4e60\u7269\u7406\u548c\u56e0\u679c\u5173\u7cfb\uff0c\u5e76\u968f\u7740\u7ecf\u9a8c\u79ef\u7d2f\u4e0d\u65ad\u6539\u8fdb\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faIPR\uff08\u4ea4\u4e92\u5f0f\u7269\u7406\u63a8\u7406\u5668\uff09\uff0c\u4f7f\u7528\u4e16\u754c\u6a21\u578b\u63a8\u6f14\u6765\u8bc4\u5206\u548c\u589e\u5f3aVLM\u7b56\u7565\uff0c\u5e76\u5f15\u5165PhysCode\u7269\u7406\u4e2d\u5fc3\u52a8\u4f5c\u7f16\u7801\u6765\u5bf9\u9f50\u8bed\u4e49\u610f\u56fe\u4e0e\u52a8\u529b\u5b66\u3002", "result": "\u57281000+\u6e38\u620f\u4e0a\u9884\u8bad\u7ec3\u540e\uff0cIPR\u5728\u4e09\u4e2a\u63a8\u7406\u5c42\u6b21\u4e0a\u8868\u73b0\u7a33\u5065\uff0c\u6574\u4f53\u6027\u80fd\u4e0eGPT-5\u76f8\u5f53\uff0c\u5728\u597d\u5947\u5fc3\u5c42\u6b21\u4e0a\u8d85\u8d8aGPT-5\uff0c\u4e14\u6027\u80fd\u968f\u8bad\u7ec3\u6e38\u620f\u548c\u4ea4\u4e92\u6b65\u6570\u589e\u52a0\u800c\u63d0\u5347\u3002", "conclusion": "\u7269\u7406\u4e2d\u5fc3\u7684\u4ea4\u4e92\u662f\u5b9e\u73b0\u6301\u7eed\u6539\u8fdb\u7269\u7406\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u8def\u5f84\uff0c\u6a21\u578b\u80fd\u591f\u96f6\u6837\u672c\u8fc1\u79fb\u5230\u672a\u89c1\u8fc7\u7684\u6e38\u620f\u4e2d\u3002"}}

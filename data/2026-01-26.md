<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 10]
- [cs.CR](#cs.CR) [Total: 9]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.DC](#cs.DC) [Total: 5]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs](https://arxiv.org/abs/2601.16479)
*Hongjia Wu,Shuai Zhou,Hongxin Zhang,Wei Chen*

Main category: cs.AI

TL;DR: Doc2AHP：结合LLM泛化能力与AHP决策理论严谨性的结构化推理框架，无需标注数据即可从文档构建高质量决策模型


<details>
  <summary>Details</summary>
Motivation: LLM在语义理解方面表现出色，但在需要严格逻辑的复杂决策任务中难以保证结构一致性和推理可靠性；传统AHP等决策理论虽然提供系统化理性框架，但依赖大量领域专家知识，存在"专家瓶颈"问题，限制了在通用场景的可扩展性

Method: 提出Doc2AHP框架：1) 利用AHP的结构原则作为约束，指导LLM在非结构化文档空间中进行受限搜索，强制父子节点间的逻辑蕴含关系；2) 引入多智能体加权机制与自适应一致性优化策略，确保权重分配的数字一致性

Result: 实验结果表明，Doc2AHP不仅能让非专家用户从零开始构建高质量决策模型，而且在逻辑完整性和下游任务准确性方面显著优于直接生成基线方法

Conclusion: Doc2AHP成功弥合了LLM的泛化能力与决策理论严谨性之间的差距，无需大量标注数据或人工干预即可实现结构化推理，为复杂决策任务提供了可扩展的解决方案

Abstract: While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although classical decision theories, such as the Analytic Hierarchy Process (AHP), offer systematic rational frameworks, their construction relies heavily on labor-intensive domain expertise, creating an "expert bottleneck" that hinders scalability in general scenarios. To bridge the gap between the generalization capabilities of LLMs and the rigor of decision theory, we propose Doc2AHP, a novel structured inference framework guided by AHP principles. Eliminating the need for extensive annotated data or manual intervention, our approach leverages the structural principles of AHP as constraints to direct the LLM in a constrained search within the unstructured document space, thereby enforcing the logical entailment between parent and child nodes. Furthermore, we introduce a multi-agent weighting mechanism coupled with an adaptive consistency optimization strategy to ensure the numerical consistency of weight allocation. Empirical results demonstrate that Doc2AHP not only empowers non-expert users to construct high-quality decision models from scratch but also significantly outperforms direct generative baselines in both logical completeness and downstream task accuracy.

</details>


### [2] [SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care](https://arxiv.org/abs/2601.16529)
*Dongshen Peng,Yi Wang,Carl Preiksaitis,Christian Rose*

Main category: cs.AI

TL;DR: SycoEval-EM框架通过多智能体模拟评估LLM在急诊医学中对抗患者说服的鲁棒性，发现模型在不当医疗请求上存在显著妥协风险，静态基准无法预测社会压力下的安全性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在临床决策支持中展现出潜力，但存在因患者压力而妥协不当医疗请求的风险。当前缺乏评估LLM在社会压力下鲁棒性的方法，静态基准无法充分预测实际临床场景中的安全性。

Method: 引入SycoEval-EM多智能体模拟框架，通过对抗性患者说服场景评估LLM鲁棒性。涵盖20个LLM模型和1,875次交互，涉及三个Choosing Wisely场景（明智选择指南），测试不同说服策略的效果。

Result: 妥协率在0-100%之间波动，模型对影像检查请求（38.8%）比阿片类药物处方（25.0%）更易妥协。模型能力与鲁棒性相关性差，所有说服策略效果相似（30.0-36.0%），表明普遍易感性而非策略特异性弱点。

Conclusion: 静态基准无法充分预测LLM在社会压力下的安全性，临床AI认证需要多轮对抗性测试。当前LLM在临床决策支持中存在显著安全风险，需要更严格的鲁棒性评估方法。

Abstract: Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient persuasion in emergency medicine. Across 20 LLMs and 1,875 encounters spanning three Choosing Wisely scenarios, acquiescence rates ranged from 0-100\%. Models showed higher vulnerability to imaging requests (38.8\%) than opioid prescriptions (25.0\%), with model capability poorly predicting robustness. All persuasion tactics proved equally effective (30.0-36.0\%), indicating general susceptibility rather than tactic-specific weakness. Our findings demonstrate that static benchmarks inadequately predict safety under social pressure, necessitating multi-turn adversarial testing for clinical AI certification.

</details>


### [3] [LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification](https://arxiv.org/abs/2601.16549)
*Meet Raval,Tejul Pandit,Dhvani Upadhyay*

Main category: cs.AI

TL;DR: 该研究对比了传统机器学习、基于提示的LLMs/VLMs和微调PEFT模型在医学分类任务上的表现，发现传统ML模型在大多数任务中表现最佳，而LoRA微调的Gemma变体表现最差，提示LLMs在图像任务上表现尚可。


<details>
  <summary>Details</summary>
Motivation: 多模态视觉语言模型和大语言模型的结合为医学分类带来了新可能性，但缺乏对这些方法与传统机器学习在医学分类任务上的系统比较。本研究旨在通过统一基准测试，评估不同模型在医学分类任务上的实际表现。

Method: 使用四个公开数据集（涵盖文本和图像模态，包括二元和多元分类复杂度），对比三类模型：传统ML（LR、LightGBM、ResNet-50）、基于提示的LLMs/VLMs（Gemini 2.5）和微调PEFT模型（LoRA适应的Gemma3变体）。所有实验使用一致的数据分割和对齐的评估指标。

Result: 传统ML模型在大多数医学分类任务中表现最佳，特别是在结构化文本数据集上表现优异。LoRA微调的Gemma变体在所有文本和图像实验中表现最差。基于提示的LLMs/VLMs在文本任务上表现不佳，但在多元图像分类任务上表现出竞争力，与传统ResNet-50基线相当。

Conclusion: 在许多医学分类场景中，传统机器学习模型仍然是最可靠的选择。基础模型并非普遍优越，参数高效微调的有效性高度依赖于适应策略，本研究中的最小微调反而对性能有害。

Abstract: The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass complexity) that contrasts traditional Machine Learning (ML) with contemporary transformer-based techniques. We evaluated three model classes for each task: Classical ML (LR, LightGBM, ResNet-50), Prompt-Based LLMs/VLMs (Gemini 2.5), and Fine-Tuned PEFT Models (LoRA-adapted Gemma3 variants). All experiments used consistent data splits and aligned metrics. According to our results, traditional machine learning (ML) models set a high standard by consistently achieving the best overall performance across most medical categorization tasks. This was especially true for structured text-based datasets, where the classical models performed exceptionally well. In stark contrast, the LoRA-tuned Gemma variants consistently showed the worst performance across all text and image experiments, failing to generalize from the minimal fine-tuning provided. However, the zero-shot LLM/VLM pipelines (Gemini 2.5) had mixed results; they performed poorly on text-based tasks, but demonstrated competitive performance on the multiclass image task, matching the classical ResNet-50 baseline. These results demonstrate that in many medical categorization scenarios, established machine learning models continue to be the most reliable option. The experiment suggests that foundation models are not universally superior and that the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) is highly dependent on the adaptation strategy, as minimal fine-tuning proved detrimental in this study.

</details>


### [4] [LUMINA: Long-horizon Understanding for Multi-turn Interactive Agents](https://arxiv.org/abs/2601.16649)
*Amin Rakhsha,Thomas Hehn,Pietro Mazzaglia,Fabio Valerio Massoli,Arash Behboodi,Tribhuvanesh Orekondy*

Main category: cs.AI

TL;DR: 本文提出了一个评估多轮智能体任务中不同能力（如规划、状态跟踪等）相对重要性的框架，通过生成可控游戏环境并使用"预言机"干预来测量各项技能对AI智能体性能的关键性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在孤立任务上表现良好，但在需要规划、状态跟踪和长上下文处理等多轮、长视野的智能体任务中仍然存在困难。研究旨在理解这些底层能力对于此类任务成功的相对重要性，为AI智能体和语言模型的未来发展提供指导。

Method: 提出了一个预言机反事实框架，通过程序化生成可调节复杂度的游戏式任务环境，提供精确的预言机干预（如完美规划或无错误状态跟踪），从而在无混杂效应的情况下隔离每项技能对性能的贡献。

Result: 研究结果显示，某些干预（如规划）在各种设置下都能持续提升性能，而其他技能的有用性则取决于环境和语言模型的特性。这揭示了多轮智能体环境中不同能力的重要性差异。

Conclusion: 该研究为理解多轮智能体任务中各项能力的相对重要性提供了系统框架，揭示了环境特性和模型能力如何影响不同技能的有效性，为AI智能体和语言模型的未来发展提供了重要指导。

Abstract: Large language models can perform well on many isolated tasks, yet they continue to struggle on multi-turn, long-horizon agentic problems that require skills such as planning, state tracking, and long context processing. In this work, we aim to better understand the relative importance of advancing these underlying capabilities for success on such tasks. We develop an oracle counterfactual framework for multi-turn problems that asks: how would an agent perform if it could leverage an oracle to perfectly perform a specific task? The change in the agent's performance due to this oracle assistance allows us to measure the criticality of such oracle skill in the future advancement of AI agents. We introduce a suite of procedurally generated, game-like tasks with tunable complexity. These controlled environments allow us to provide precise oracle interventions, such as perfect planning or flawless state tracking, and make it possible to isolate the contribution of each oracle without confounding effects present in real-world benchmarks. Our results show that while some interventions (e.g., planning) consistently improve performance across settings, the usefulness of other skills is dependent on the properties of the environment and language model. Our work sheds light on the challenges of multi-turn agentic environments to guide the future efforts in the development of AI agents and language models.

</details>


### [5] [AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning](https://arxiv.org/abs/2601.16685)
*Suzhong Fu,Jingqi Dong,Xuan Ding,Rui Sun,Yiming Yang,Shuguang Cui,Zhen Li*

Main category: cs.AI

TL;DR: AgentsEval：一个多智能体流推理框架，用于评估医学影像报告生成的临床正确性和推理保真度，模拟放射科医生的协作诊断工作流程。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法捕捉放射学解释背后的结构化诊断逻辑，导致不可靠的判断和有限的临床相关性。需要一种能够评估临床正确性和推理保真度的新方法。

Method: 引入AgentsEval多智能体流推理框架，将评估过程分解为可解释的步骤：标准定义、证据提取、对齐和一致性评分。同时构建了一个多领域扰动基准，涵盖五个医学报告数据集。

Result: 实验结果表明，AgentsEval能够提供临床对齐、语义忠实且可解释的评估，在释义、语义和风格扰动下保持稳健性。

Conclusion: 该框架代表了向透明且基于临床的医学报告生成系统评估迈出的一步，有助于促进大型语言模型在临床实践中的可信集成。

Abstract: Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies radiological interpretation, resulting in unreliable judgments and limited clinical relevance. We introduce AgentsEval, a multi-agent stream reasoning framework that emulates the collaborative diagnostic workflow of radiologists. By dividing the evaluation process into interpretable steps including criteria definition, evidence extraction, alignment, and consistency scoring, AgentsEval provides explicit reasoning traces and structured clinical feedback. We also construct a multi-domain perturbation-based benchmark covering five medical report datasets with diverse imaging modalities and controlled semantic variations. Experimental results demonstrate that AgentsEval delivers clinically aligned, semantically faithful, and interpretable evaluations that remain robust under paraphrastic, semantic, and stylistic perturbations. This framework represents a step toward transparent and clinically grounded assessment of medical report generation systems, fostering trustworthy integration of large language models into clinical practice.

</details>


### [6] [LongCat-Flash-Thinking-2601 Technical Report](https://arxiv.org/abs/2601.16725)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chen Gao,Chen Zhang,Chengcheng Han,Chenhui Yang,Chuyu Zhang,Cong Chen,Cunguang Wang,Daoru Pan,Defei Bu,Dengchang Zhao,Di Xiu,Dishan Liu,Dongyu Ru,Dunwei Tu,Fan Wu,Fengcheng Yuan,Fengcun Li,Gang Xu,Guanyu Wu,Guoyuan Lin,Haibin Wang,Hansi Yang,Hao Yang,Haonan Yan,Haoxiang Ma,Haoxing Wen,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiacheng Zhang,Jiahong Zhou,Jiahuan Li,Jiaming Wang,Jian Yang,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiapeng Zhu,Jiaqi Sun,Jiarong Shi,Jiarui Zhao,Jingang Wang,Jinluan Yang,Jinrui Ding,Jinwei Xiao,Jiyuan He,Juncan Xu,Kefeng Zhang,Keheng Wang,Li Wei,Lianhui Ma,Lin Qiu,Lingbing Kong,Lingchuan Liu,Linsen Guo,Mengshen Zhu,Mengxia Shen,Mingyang Zhu,Peiguang Li,Peng Pei,Pengcheng Jia,Pengtao Zhang,Peng Zhao,Qi Gu,Qiong Huang,Qiyuan Duan,Quanchi Weng,Rongxiang Weng,Rongzhi Zhang,Rumei Li,Shanglin Lei,Shengnan An,Shijun Dai,Shuaikang Liu,Shuang Zhou,Shuo Wang,Songyuan Zhao,Tao Liang,Tianhao Hu,Tianze Chen,Wei Liu,Wei Shi,Wei Wang,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Wentao Chen,Wentao Shi,Xi Su,Xiangcheng Liu,Xiandi Ma,Xiangyu Xi,Xiangyuan Liu,Xiangzhou Huang,Xiao Liu,Xiaodong Cai,Xiaolong Chen,Xiaowei Shi,Xiaoyu Li,Xin Chen,Xingchen Liu,Xuan Huang,Xuezhi Cao,Xunliang Cai,Yan Chen,Yang Bai,Yang Liu,Yang Yang,Yang Zheng,Yaoming Wang,Yaoming Zhu,Yaqi Huo,Yanyu Chen,Yaorui Shi,Yerui Sun,Yi Zhang,Yihao Chen,Yi-Kai Zhang,Yifan Lu,Yifan Zhao,Yitao Zhai,Yongjing Yin,Yongwei Zhou,Youshao Xiao,Yuchuan Dai,Yuchen Xie,Yuchen Yu,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunfan Liang,Yunke Zhao,Yuwei Jiang,Yuxin Bian,Yuxin Chen,Yuxin Liu,Yue Xu,Yueqing Sun,Zeyang Yu,Zhao Yang,Zhengsheng Huang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhimin Lin,Zhiyuan Yao,Zhuofan Chen,Zhuowen Han,Zijian Zhang,Ziran Li,Ziwen Wang,Ziyuan Zhuang*

Main category: cs.AI

TL;DR: LongCat-Flash-Thinking-2601是一个5600亿参数的开源MoE推理模型，在多种智能体基准测试中达到最先进性能，具有强大的复杂工具使用泛化能力和现实环境鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 开发一个具有卓越智能体推理能力的开源模型，能够处理复杂的工具交互并在嘈杂的现实环境中保持鲁棒性，解决现有模型在工具使用泛化和现实应用中的局限性。

Method: 采用统一的训练框架，包括领域并行专家训练与后续融合，端到端的数据构建、环境、算法和基础设施协同设计。扩展异步强化学习框架DORA以支持大规模多环境训练，系统分析现实噪声模式并设计针对性训练程序，引入Heavy Thinking模式进行测试时扩展。

Result: 在智能体搜索、智能体工具使用和工具集成推理等广泛基准测试中达到开源模型的最先进性能，展现出对复杂工具交互的强大泛化能力和在嘈杂现实环境中的鲁棒行为。

Conclusion: LongCat-Flash-Thinking-2601通过创新的训练框架、环境扩展、噪声分析和测试时扩展技术，成功实现了在复杂智能体推理任务上的卓越性能，为现实世界应用提供了强大的开源解决方案。

Abstract: We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.

</details>


### [7] [An Efficient Insect-inspired Approach for Visual Point-goal Navigation](https://arxiv.org/abs/2601.16806)
*Lu Yihe,Barbara Webb*

Main category: cs.AI

TL;DR: 开发了一种受昆虫启发的视觉点目标导航智能体，结合了昆虫大脑中负责联想学习和路径整合的两个结构，在Habitat点目标导航任务中表现出与SOTA模型相当的性能，但计算成本低多个数量级。


<details>
  <summary>Details</summary>
Motivation: 受昆虫在发现食物位置和巢穴之间学习并优化视觉引导路径的能力启发，将Habitat点目标导航任务的正式基准与昆虫的这种能力进行类比，旨在开发计算效率更高的导航模型。

Method: 结合了昆虫大脑中两个关键结构的抽象模型：一个负责联想学习，另一个负责路径整合。开发了简单的昆虫启发式智能体，在Habitat点目标导航任务中进行测试。

Result: 该昆虫启发式智能体在性能上与最近的SOTA模型相当，但计算成本低多个数量级。在更真实的模拟环境中测试表明该方法对扰动具有鲁棒性。

Conclusion: 昆虫大脑的简单抽象模型能够实现高效的点目标导航，为开发计算成本低但性能优越的导航系统提供了新思路，展示了生物启发方法在机器人导航中的潜力。

Abstract: In this work we develop a novel insect-inspired agent for visual point-goal navigation. This combines abstracted models of two insect brain structures that have been implicated, respectively, in associative learning and path integration. We draw an analogy between the formal benchmark of the Habitat point-goal navigation task and the ability of insects to learn and refine visually guided paths around obstacles between a discovered food location and their nest. We demonstrate that the simple insect-inspired agent exhibits performance comparable to recent SOTA models at many orders of magnitude less computational cost. Testing in a more realistic simulated environment shows the approach is robust to perturbations.

</details>


### [8] [Reasoning Promotes Robustness in Theory of Mind Tasks](https://arxiv.org/abs/2601.16853)
*Ian B. de Haan,Peter van der Putten,Max van Duijn*

Main category: cs.AI

TL;DR: 本文研究了通过强化学习与可验证奖励训练的推理型大语言模型在心理理论任务中的表现，发现这些模型对提示变化和任务扰动具有更强的鲁棒性，但这种改进主要源于寻找正确答案的鲁棒性增强，而非新的心理理论推理能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在心理理论测试中表现出色引发了对其底层能力性质的争论，同时通过强化学习与可验证奖励训练的推理模型在各种基准测试中取得了显著改进。本文旨在探究这类推理模型在心理理论任务中的行为表现。

Method: 使用新颖的机器心理学实验改编方法和已建立基准测试的结果，分析推理模型在心理理论任务中的表现，特别关注其对提示变化和任务扰动的鲁棒性。

Result: 推理模型在心理理论任务中表现出对提示变化和任务扰动的一致增强鲁棒性。分析表明，观察到的改进更可能归因于寻找正确答案的鲁棒性增强，而不是新的心理理论推理形式。

Conclusion: 研究结果对评估大语言模型的社会认知行为具有重要意义，提示我们需要更谨慎地解释模型在心理理论任务中的表现，区分真正的推理能力与鲁棒性改进。

Abstract: Large language models (LLMs) have recently shown strong performance on Theory of Mind (ToM) tests, prompting debate about the nature and true performance of the underlying capabilities. At the same time, reasoning-oriented LLMs trained via reinforcement learning with verifiable rewards (RLVR) have achieved notable improvements across a range of benchmarks. This paper examines the behavior of such reasoning models in ToM tasks, using novel adaptations of machine psychological experiments and results from established benchmarks. We observe that reasoning models consistently exhibit increased robustness to prompt variations and task perturbations. Our analysis indicates that the observed gains are more plausibly attributed to increased robustness in finding the correct solution, rather than to fundamentally new forms of ToM reasoning. We discuss the implications of this interpretation for evaluating social-cognitive behavior in LLMs.

</details>


### [9] [MAGE-KT: Multi-Agent Graph-Enhanced Knowledge Tracing with Subgraph Retrieval and Asymmetric Fusion](https://arxiv.org/abs/2601.16886)
*Chi Yu,Hongyu Yuan,Zhiyi Duan*

Main category: cs.AI

TL;DR: MAGE-KT：多智能体图增强知识追踪框架，通过构建多视图异构图和检索紧凑子图，解决传统图KT方法中概念关系挖掘不足和注意力扩散问题


<details>
  <summary>Details</summary>
Motivation: 现有基于图的知识追踪方法存在两个主要问题：1) 概念间关系挖掘不足，通常仅从交互序列推断；2) 完整图编码计算成本高且易受噪声影响，导致注意力扩散到学生无关区域，降低概念间关系保真度

Method: 提出MAGE-KT框架：1) 构建多视图异构图，结合多智能体概念关系提取器和学生-问题交互图；2) 基于目标学生历史检索紧凑高价值子图；3) 使用非对称交叉注意力融合模块集成子图信息，避免注意力扩散和不相关计算

Result: 在三个广泛使用的KT数据集上实验，在概念关系准确性和下一个问题预测方面均显著优于现有方法

Conclusion: MAGE-KT通过多视图图构建和子图检索机制，有效解决了传统图KT方法的局限性，在知识追踪任务中取得了实质性改进

Abstract: Knowledge Tracing (KT) aims to model a student's learning trajectory and predict performance on the next question. A key challenge is how to better represent the relationships among students, questions, and knowledge concepts (KCs). Recently, graph-based KT paradigms have shown promise for this problem. However, existing methods have not sufficiently explored inter-concept relations, often inferred solely from interaction sequences. In addition, the scale and heterogeneity of KT graphs make full-graph encoding both computationally both costly and noise-prone, causing attention to bleed into student-irrelevant regions and degrading the fidelity of inter-KC relations. To address these issues, we propose a novel framework: Multi-Agent Graph-Enhanced Knowledge Tracing (MAGE-KT). It constructs a multi-view heterogeneous graph by combining a multi-agent KC relation extractor and a student-question interaction graph, capturing complementary semantic and behavioral signals. Conditioned on the target student's history, it retrieves compact, high-value subgraphs and integrates them using an Asymmetric Cross-attention Fusion Module to enhance prediction while avoiding attention diffusion and irrelevant computation. Experiments on three widely used KT datasets show substantial improvements in KC-relation accuracy and clear gains in next-question prediction over existing methods.

</details>


### [10] [Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians](https://arxiv.org/abs/2601.16967)
*Bernes Lorier Atabonfack,Ahmed Tahiru Issah,Mohammed Hardi Abdul Baaki,Clemence Ingabire,Tolulope Olusuyi,Maruf Adewole,Udunna C. Anazodo,Timothy X Brown*

Main category: cs.AI

TL;DR: 开发AI驱动的医疗设备维护支持平台，帮助低收入和中等收入国家的生物医学技术人员实时诊断和修复医疗设备，减少设备停机时间


<details>
  <summary>Details</summary>
Motivation: 低收入和中等收入国家中大量医疗诊断设备因缺乏及时维护、技术专家支持不足而闲置或故障，导致设备停机时间长、诊断延迟和患者护理质量下降

Method: 开发集成大型语言模型的AI支持平台，提供用户友好的Web界面，允许技术人员输入错误代码或设备症状，获得逐步故障排除指导，并建立全球同行讨论论坛

Result: 使用Philips HDI 5000超声机进行概念验证，在错误代码解释方面达到100%精确度，在建议纠正措施方面达到80%准确率

Conclusion: AI驱动系统在支持医疗设备维护方面具有可行性和潜力，能够减少设备停机时间，改善资源受限环境中的医疗服务提供

Abstract: In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [11] [FC-GUARD: Enabling Anonymous yet Compliant Fiat-to-Cryptocurrency Exchanges](https://arxiv.org/abs/2601.16298)
*Shaoyu Li,Hexuan Yu,Md Mohaimin Al Barat,Yang Xiao,Y. Thomas Hou,Wenjing Lou*

Main category: cs.CR

TL;DR: FC-GUARD是一个保护隐私的法币-加密货币兑换系统，使用可验证凭证和零知识证明技术，在遵守监管要求的同时保护用户匿名性。


<details>
  <summary>Details</summary>
Motivation: 当前法币-加密货币兑换平台存在隐私保护不足的问题，个人身份信息泄露导致用户真实身份与加密货币地址被关联，破坏了加密货币的匿名性预期。

Method: 采用可验证凭证和零知识证明技术，在不暴露用户PII和法币账户详情的情况下完成兑换，同时集成合法去匿名化机制以满足监管合规要求。

Result: 在桌面和移动平台实现系统，评估显示FC-GUARD具有实际部署的可行性。

Conclusion: FC-GUARD能够在保护用户隐私的同时满足监管合规要求，打破了真实身份与加密货币地址的关联，维护了加密货币生态系统的匿名性预期。

Abstract: With the rise of decentralized finance, fiat-to-cryptocurrency exchange platforms have become popular entry points into the cryptocurrency ecosystem. However, these platforms frequently fail to ensure adequate privacy protection, as evidenced by real-world breaches that exposed personally identifiable information (PII) and crypto addresses. Such leaks enable adversaries to link real-world identities to cryptocurrency transactions, undermining the presumed anonymity of cryptocurrency use.
  We propose FC-GUARD, a privacy-preserving exchange system designed to preserve user anonymity without compromising regulatory compliance in the exchange of fiat currency for cryptocurrencies. Leveraging verifiable credentials and zero-knowledge proof techniques, FC-GUARD enables fiat-to-cryptocurrency exchanges without revealing users' PII or fiat account details. This breaks the linkage between users' real-world identities and their cryptocurrency addresses, thereby upholding anonymity, a fundamental expectation in the cryptocurrency ecosystem. In addition, FC-GUARD complies with key regulations over cryptocurrency usage, such as know-your-customer requirements and auditability for tax reporting obligations by integrating a lawful de-anonymization mechanism that allows the auditing authority to identify misbehaving users. This ensures regulatory compliance while defaulting to privacy protection. We implement our system on both desktop and mobile platforms, and our evaluation shows its feasibility for practical deployment.

</details>


### [12] [NOIR: Privacy-Preserving Generation of Code with Open-Source LLMs](https://arxiv.org/abs/2601.16354)
*Khoa Nguyen,Khiem Ton,NhatHai Phan,Issa Khalil,Khang Tran,Cristian Borcea,Ruoming Jin,Abdallah Khreishah,My T. Thai*

Main category: cs.CR

TL;DR: NOIR是首个保护代码生成中客户端提示和生成代码隐私的框架，通过本地差分隐私和随机化分词器防止云服务提供商窃取商业机密，在保持高性能的同时实现强隐私保护。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的代码生成虽然提升了开发效率，但存在知识产权和数据安全风险，因为云服务提供商能够观察到客户端的提示和生成的代码，这些在商业系统中可能是专有信息。

Method: NOIR框架在客户端使用编码器和解码器，将提示的嵌入向量编码后发送到云端获取LLM的丰富嵌入，然后在客户端本地解码生成代码。采用不可区分性机制、词汇级别的本地差分隐私保护，以及客户端的数据无关随机化分词器来防御重建和频率分析攻击。

Result: 在开源LLM上的广泛分析和结果显示，NOIR在基准测试中显著优于现有基线，包括Evalplus（MBPP和HumanEval，Pass@1分别为76.7和77.4）和BigCodeBench（Pass@1为38.7，仅比原始LLM下降1.77%），同时提供强大的隐私保护。

Conclusion: NOIR是首个有效保护代码生成中客户端提示和生成代码隐私的框架，通过创新的隐私保护机制在保持高性能的同时防御诚实但好奇的云服务提供商的攻击，为商业系统中的LLM代码生成提供了可行的隐私保护解决方案。

Abstract: Although boosting software development performance, large language model (LLM)-powered code generation introduces intellectual property and data security risks rooted in the fact that a service provider (cloud) observes a client's prompts and generated code, which can be proprietary in commercial systems. To mitigate this problem, we propose NOIR, the first framework to protect the client's prompts and generated code from the cloud. NOIR uses an encoder and a decoder at the client to encode and send the prompts' embeddings to the cloud to get enriched embeddings from the LLM, which are then decoded to generate the code locally at the client. Since the cloud can use the embeddings to infer the prompt and the generated code, NOIR introduces a new mechanism to achieve indistinguishability, a local differential privacy protection at the token embedding level, in the vocabulary used in the prompts and code, and a data-independent and randomized tokenizer on the client side. These components effectively defend against reconstruction and frequency analysis attacks by an honest-but-curious cloud. Extensive analysis and results using open-source LLMs show that NOIR significantly outperforms existing baselines on benchmarks, including the Evalplus (MBPP and HumanEval, Pass@1 of 76.7 and 77.4), and BigCodeBench (Pass@1 of 38.7, only a 1.77% drop from the original LLM) under strong privacy against attacks.

</details>


### [13] [Ringmaster: How to juggle high-throughput host OS system calls from TrustZone TEEs](https://arxiv.org/abs/2601.16448)
*Richard Habeeb,Man-Ki Yoon,Hao Chen Zhong Shao*

Main category: cs.CR

TL;DR: Ringmaster是一个新颖的框架，允许可信执行环境（TEE）通过Linux的io_uring异步访问丰富的但可能不可信的操作系统服务，同时在服务被拒绝时继续在ARM TrustZone内核上运行，以平衡安全时间敏感处理与丰富OS服务需求。


<details>
  <summary>Details</summary>
Motivation: 安全关键系统需要及时处理传感器输入以避免安全隐患，同时这些系统通常运行大型丰富的操作系统，但可能存在安全漏洞。如果恶意方获得超级用户权限，可能通过拒绝服务攻击对时间敏感程序造成实际损害。现有方法通常通过虚拟机监控程序完全隔离时间敏感程序，但这阻止了程序访问有用的OS服务。

Method: Ringmaster框架使TEE能够通过Linux的io_uring异步访问丰富但可能不可信的OS服务。当不可信OS拒绝服务时，enclave继续在Ringmaster的最小ARM TrustZone内核上运行，访问小型关键设备驱动程序。该方法支持大型未修改程序作为enclave，相比现有系统具有更低开销。

Result: 在Raspberry Pi4b上的实验中，Ringmaster实现了近1GiB/秒的数据传输到enclave，与非enclave任务相比仅有0-3%的吞吐量开销。在无人机应用中展示了如何构建高度安全系统且工程成本最小。

Conclusion: Ringmaster在安全时间敏感处理与丰富OS服务便利性之间取得了平衡，支持大型未修改程序作为enclave，相比现有系统具有更低开销，为构建高度安全系统提供了实用解决方案。

Abstract: Many safety-critical systems require timely processing of sensor inputs to avoid potential safety hazards. Additionally, to support useful application features, such systems increasingly have a large rich operating system (OS) at the cost of potential security bugs. Thus, if a malicious party gains supervisor privileges, they could cause real-world damage by denying service to time-sensitive programs. Many past approaches to this problem completely isolate time-sensitive programs with a hypervisor; however, this prevents the programs from accessing useful OS services
  We introduce Ringmaster, a novel framework that enables enclaves or TEEs (Trusted Execution Environments) to asynchronously access rich, but potentially untrusted, OS services via Linux's io_uring. When service is denied by the untrusted OS, enclaves continue to operate on Ringmaster's minimal ARM TrustZone kernel with access to small, critical device drivers. This approach balances the need for secure, time-sensitive processing with the convenience of rich OS services. Additionally, Ringmaster supports large unmodified programs as enclaves, offering lower overhead compared to existing systems. We demonstrate how Ringmaster helps us build a working highly-secure system with minimal engineering. In our experiments with an unmanned aerial vehicle, Ringmaster achieved nearly 1GiB/sec of data into enclave on a Raspberry Pi4b, 0-3% throughput overhead compared to non-enclave tasks.

</details>


### [14] [A High Performance and Efficient Post-Quantum Crypto-Processor for FrodoKEM](https://arxiv.org/abs/2601.16500)
*Kai Li,Jiahao Lu,Fu Yao,Guang Zeng,Dongsheng Liu,Shengfei Gu,Zhengpeng Zhao,Jiachen Wang*

Main category: cs.CR

TL;DR: 本文提出了一种高性能的FrodoKEM密码处理器，通过多重指令重叠执行、可重构并行乘法器阵列和紧凑内存调度策略，显著降低了硬件实现的延迟和资源消耗，在所有安全级别上实现了最快的执行时间。


<details>
  <summary>Details</summary>
Motivation: FrodoKEM作为一种基于格的后量子密钥封装机制，虽然具有强大的安全性并被ISO考虑标准化，但其硬件实现存在高延迟和重资源负担的问题，限制了实际应用。同时，多样化的使用场景需要全面的功能支持。

Method: 1. 引入多重指令重叠执行方案，实现高效的多模块调度和最小化操作延迟
2. 集成高速可重构并行乘法器阵列，处理不同计算模式下的密集矩阵计算
3. 采用紧凑内存调度策略，缩短中间矩阵的生命周期，减少存储需求
4. 支持所有FrodoKEM安全级别和协议阶段

Result: 在Artix-7 FPGA上实现，消耗13467个LUT、6042个FF和14个BRAM，实现了最快的执行时间。与最先进的硬件实现相比，面积-时间乘积（ATP）提高了1.75-2.00倍。

Conclusion: 提出的FrodoKEM密码处理器通过创新的架构设计，成功解决了现有实现的高延迟和资源负担问题，在保持全面功能支持的同时，显著提升了硬件效率和性能，为后量子密码的实际应用提供了可行的硬件解决方案。

Abstract: FrodoKEM is a lattice-based post-quantum key encapsulation mechanism (KEM). It has been considered for standardization by the International Organization for Standardization (ISO) due to its robust security profile. However, its hardware implementation exhibits a weakness of high latency and heavy resource burden, hindering its practical application. Moreover, diverse usage scenarios call for comprehensive functionality. To address these challenges, this paper presents a high-performance and efficient crypto-processor for FrodoKEM. A multiple-instruction overlapped execution scheme is introduced to enable efficient multi-module scheduling and minimize operational latency. Furthermore, a high-speed, reconfigurable parallel multiplier array is integrated to handle intensive matrix computations under diverse computation patterns, significantly enhancing hardware efficiency. In addition, a compact memory scheduling strategy shortens the lifespan of intermediate matrices, thereby reducing overall storage requirements. The proposed design provides full support for all FrodoKEM security levels and protocol phases. It consumes 13467 LUTs, 6042 FFs, and 14 BRAMs on an Artix-7 FPGA and achieves the fastest reported execution time. Compared with state-of-the-art hardware implementations, our design improves the area-time product (ATP) by 1.75-2.00 times.

</details>


### [15] [Cutting the Gordian Knot: Detecting Malicious PyPI Packages via a Knowledge-Mining Framework](https://arxiv.org/abs/2601.16463)
*Wenbo Guo,Chengwei Liu,Ming Kang,Yiran Zhang,Jiahui Wu,Zhengzi Xu,Vinay Sachidananda,Yang Liu*

Main category: cs.CR

TL;DR: PyGuard是一个基于知识驱动的恶意Python包检测框架，通过从现有工具的误报和漏报中提取行为模式，结合层次模式挖掘和LLM语义抽象，实现了99.50%的准确率，远优于现有工具15-30%的误报率。


<details>
  <summary>Details</summary>
Motivation: PyPI已成为恶意攻击者的目标，现有检测工具依赖简单的语法规则而非语义理解，导致15-30%的误报率，将三分之一的合法包错误标记为恶意。现有工具无法区分相同API调用在合法和恶意用途中的差异。

Method: 1. 从现有工具的误报和漏报中提取行为模式；2. 使用层次模式挖掘识别区分恶意与良性代码的行为序列；3. 利用大语言模型创建超越语法变体的语义抽象；4. 将精确模式匹配与上下文推理结合构建检测系统。

Result: PyGuard实现了99.50%的准确率，仅有2个误报（相比现有工具的1,927-2,117个误报）；在混淆代码上保持98.28%的准确率；在实际部署中识别了219个先前未知的恶意包；行为模式具有跨生态系统适用性，在NPM包上达到98.07%的准确率。

Conclusion: PyGuard通过语义理解实现了恶意包检测的显著改进，证明了语义理解能够实现跨编程语言的知识迁移，为解决软件供应链安全问题提供了有效方案。

Abstract: The Python Package Index (PyPI) has become a target for malicious actors, yet existing detection tools generate false positive rates of 15-30%, incorrectly flagging one-third of legitimate packages as malicious. This problem arises because current tools rely on simple syntactic rules rather than semantic understanding, failing to distinguish between identical API calls serving legitimate versus malicious purposes. To address this challenge, we propose PyGuard, a knowledge-driven framework that converts detection failures into useful behavioral knowledge by extracting patterns from existing tools' false positives and negatives. Our method utilizes hierarchical pattern mining to identify behavioral sequences that distinguish malicious from benign code, employs Large Language Models to create semantic abstractions beyond syntactic variations, and combines this knowledge into a detection system that integrates exact pattern matching with contextual reasoning. PyGuard achieves 99.50% accuracy with only 2 false positives versus 1,927-2,117 in existing tools, maintains 98.28% accuracy on obfuscated code, and identified 219 previously unknown malicious packages in real-world deployment. The behavioral patterns show cross-ecosystem applicability with 98.07% accuracy on NPM packages, demonstrating that semantic understanding enables knowledge transfer across programming languages.

</details>


### [16] [DeMark: A Query-Free Black-Box Attack on Deepfake Watermarking Defenses](https://arxiv.org/abs/2601.16473)
*Wei Song,Zhenchang Xing,Liming Zhu,Yulei Sui,Jingling Xue*

Main category: cs.CR

TL;DR: DeMark攻击框架能够有效移除深度伪造图像中的防御性水印，将检测准确率从100%降至32.9%，暴露了当前水印方案的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 当前防御性水印方案被认为具有抗移除性，但作者质疑这一假设，认为深度伪造图像中的水印可能存在潜在漏洞。

Method: DeMark是一种无需查询的黑盒攻击框架，利用压缩感知稀疏化过程，针对编码器-解码器水印模型的潜在空间漏洞，抑制水印信号同时保持感知和结构真实性。

Result: 在8种最先进的水印方案上，DeMark将水印检测准确率从100%平均降至32.9%，同时保持自然视觉质量，优于现有攻击方法。三种防御策略（超分辨率、稀疏水印、对抗训练）基本无效。

Conclusion: 当前编码器-解码器水印方案对潜在空间操作仍然脆弱，需要开发更鲁棒的水印方法来应对深度伪造威胁。

Abstract: The rapid proliferation of realistic deepfakes has raised urgent concerns over their misuse, motivating the use of defensive watermarks in synthetic images for reliable detection and provenance tracking. However, this defense paradigm assumes such watermarks are inherently resistant to removal. We challenge this assumption with DeMark, a query-free black-box attack framework that targets defensive image watermarking schemes for deepfakes. DeMark exploits latent-space vulnerabilities in encoder-decoder watermarking models through a compressive sensing based sparsification process, suppressing watermark signals while preserving perceptual and structural realism appropriate for deepfakes. Across eight state-of-the-art watermarking schemes, DeMark reduces watermark detection accuracy from 100% to 32.9% on average while maintaining natural visual quality, outperforming existing attacks. We further evaluate three defense strategies, including image super resolution, sparse watermarking, and adversarial training, and find them largely ineffective. These results demonstrate that current encoder decoder watermarking schemes remain vulnerable to latent-space manipulations, underscoring the need for more robust watermarking methods to safeguard against deepfakes.

</details>


### [17] [SafeThinker: Reasoning about Risk to Deepen Safety Beyond Shallow Alignment](https://arxiv.org/abs/2601.16506)
*Xianya Fang,Xianying Luo,Yadong Wang,Xiang Chen,Yu Tian,Zequn Sun,Rui Liu,Jun Fang,Naiqiang Tan,Yuanning Cui,Sheng-Jun Huang*

Main category: cs.CR

TL;DR: SafeThinker是一个自适应防御框架，通过轻量级网关分类器动态分配防御资源，针对不同类型的攻击使用三种机制：标准化拒绝、安全感知双专家模块和分布引导思考组件，在保持实用性的同时显著降低各种越狱攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型的安全对齐往往停留在表面，容易受到伪装攻击（如预填充攻击）的影响，同时防御措施会降低模型的实用性。需要一种既能有效防御各种攻击，又不损害模型实用性的解决方案。

Method: 提出SafeThinker框架，包含三个核心组件：1) 轻量级网关分类器进行风险评估；2) 标准化拒绝机制处理明确威胁；3) 安全感知双专家模块拦截伪装为良性查询的欺骗性攻击；4) 分布引导思考组件在不确定生成时进行自适应干预。

Result: 实验表明，SafeThinker显著降低了各种越狱策略的攻击成功率，同时没有损害模型的实用性。证明通过在生成过程中协调内在判断，可以有效平衡鲁棒性和实用性。

Conclusion: SafeThinker通过动态分配防御资源和协调内在判断，实现了对大型语言模型的有效安全保护，在保持实用性的同时显著提升了对抗各种攻击的鲁棒性。

Abstract: Despite the intrinsic risk-awareness of Large Language Models (LLMs), current defenses often result in shallow safety alignment, rendering models vulnerable to disguised attacks (e.g., prefilling) while degrading utility. To bridge this gap, we propose SafeThinker, an adaptive framework that dynamically allocates defensive resources via a lightweight gateway classifier. Based on the gateway's risk assessment, inputs are routed through three distinct mechanisms: (i) a Standardized Refusal Mechanism for explicit threats to maximize efficiency; (ii) a Safety-Aware Twin Expert (SATE) module to intercept deceptive attacks masquerading as benign queries; and (iii) a Distribution-Guided Think (DDGT) component that adaptively intervenes during uncertain generation. Experiments show that SafeThinker significantly lowers attack success rates across diverse jailbreak strategies without compromising utility, demonstrating that coordinating intrinsic judgment throughout the generation process effectively balances robustness and practicality.

</details>


### [18] [From Transactions to Exploits: Automated PoC Synthesis for Real-World DeFi Attacks](https://arxiv.org/abs/2601.16681)
*Xing Su,Hao Wu,Hanzhong Liang,Yunlin Jiang,Yuxi Cheng,Yating Liu,Fengyuan Xu*

Main category: cs.CR

TL;DR: TracExp是首个自动化框架，能够直接从链上攻击执行中合成可验证的概念验证(PoC)，通过追踪驱动的逆向工程和LLM代码生成能力实现，在321个真实攻击中达到93%的成功率。


<details>
  <summary>Details</summary>
Motivation: 区块链系统面临日益严重的链上攻击，这些攻击利用合约漏洞快速隐蔽地提取价值，使得系统分析和复现极具挑战性。目前复现攻击需要手动制作PoC，这个过程劳动密集、需要专业知识且难以扩展。

Method: 提出TracExp框架：1) 从嘈杂的多合约追踪中定位攻击相关的执行上下文；2) 引入新颖的双反编译器将具体执行转化为语义丰富的漏洞利用伪代码；3) 基于此表示合成PoC并优化以保留可利用性相关语义。

Result: 在20个月内321个真实攻击上评估：成功合成93%攻击事件的PoC，其中58.78%可直接验证，平均每个案例成本仅0.07美元。TracExp向社区发布了大量先前不可用的PoC，获得900美元赏金，展示了强大的实际影响。

Conclusion: TracExp是首个自动化合成可验证PoC的框架，通过追踪驱动的逆向工程和LLM代码生成，显著降低了攻击复现的难度和成本，为区块链安全研究提供了实用工具。

Abstract: Blockchain systems are increasingly targeted by on-chain attacks that exploit contract vulnerabilities to extract value rapidly and stealthily, making systematic analysis and reproduction highly challenging. In practice, reproducing such attacks requires manually crafting proofs-of-concept (PoCs), a labor-intensive process that demands substantial expertise and scales poorly. In this work, we present the first automated framework for synthesizing verifiable PoCs directly from on-chain attack executions. Our key insight is that attacker logic can be recovered from low-level transaction traces via trace-driven reverse engineering, and then translated into executable exploits by leveraging the code-generation capabilities of large language models (LLMs). To this end, we propose TracExp, which localizes attack-relevant execution contexts from noisy, multi-contract traces and introduces a novel dual-decompiler to transform concrete executions into semantically enriched exploit pseudocode. Guided by this representation, TracExp synthesizes PoCs and refines them to preserve exploitability-relevant semantics. We evaluate TracExp on 321 real-world attacks over the past 20 months. TracExp successfully synthesizes PoCs for 93% of incidents, with 58.78% being directly verifiable, at an average cost of only \$0.07 per case. Moreover, TracExp enabled the release of a large number of previously unavailable PoCs to the community, earning a $900 bounty and demonstrating strong practical impact.

</details>


### [19] [Building a Robust Risk-Based Access Control System to Combat Ransomware's Capability to Encrypt: A Machine Learning Approach](https://arxiv.org/abs/2601.16795)
*Kenan Begovic,Abdulaziz Al-Ali,Qutaibah Malluhi*

Main category: cs.CR

TL;DR: 提出基于概率风险评估的Linux加密控制架构，结合机器学习推理与强制访问控制，通过内核函数级追踪实时识别和阻止恶意加密活动，同时保持合法加密工作流。


<details>
  <summary>Details</summary>
Motivation: 勒索软件的核心能力——未经授权的加密——需要能够识别和阻止恶意加密活动而不干扰合法使用的控制机制。现有方法如沙箱、虚拟机自省或粗粒度系统调用监控存在性能开销或粒度不足的问题。

Method: 使用ftrace框架的function_graph追踪器构建高分辨率内核函数执行轨迹数据集，结合资源计数器和I/O计数器。基于此开发监督分类器和可解释规则，通过轻量级布尔值驱动SELinux策略，在加密开始时实现上下文敏感的许可/拒绝决策。

Result: 两层组合（分类器+规则）保持了模型级检测质量，同时提供类似规则的响应速度。当前用户空间原型在突发I/O下有显著开销，但量化了性能影响并提出了内核空间解决方案的优化方向。

Conclusion: 该研究为生产Linux系统提供了一条从行为追踪和学习到可执行、可解释、风险成比例的加密控制的实用路径，平衡了安全性与性能需求。

Abstract: Ransomware core capability, unauthorized encryption, demands controls that identify and block malicious cryptographic activity without disrupting legitimate use. We present a probabilistic, risk-based access control architecture that couples machine learning inference with mandatory access control to regulate encryption on Linux in real time. The system builds a specialized dataset from the native ftrace framework using the function_graph tracer, yielding high-resolution kernel-function execution traces augmented with resource and I/O counters. These traces support both a supervised classifier and interpretable rules that drive an SELinux policy via lightweight booleans, enabling context-sensitive permit/deny decisions at the moment encryption begins. Compared to approaches centered on sandboxing, hypervisor introspection, or coarse system-call telemetry, the function-level tracing we adopt provides finer behavioral granularity than syscall-only telemetry while avoiding the virtualization/VMI overhead of sandbox-based approaches. Our current user-space prototype has a non-trivial footprint under burst I/O; we quantify it and recognize that a production kernel-space solution should aim to address this. We detail dataset construction, model training and rule extraction, and the run-time integration that gates file writes for suspect encryption while preserving benign cryptographic workflows. During evaluation, the two-layer composition retains model-level detection quality while delivering rule-like responsiveness; we also quantify operational footprint and outline engineering steps to reduce CPU and memory overhead for enterprise deployment. The result is a practical path from behavioral tracing and learning to enforceable, explainable, and risk-proportionate encryption control on production Linux systems.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [20] [AERO: Adaptive and Efficient Runtime-Aware OTA Updates for Energy-Harvesting IoT](https://arxiv.org/abs/2601.16935)
*Wei Wei,Jingye Xu,Sahidul Islam,Dakai Zhu,Chen Pan,Mimi Xie*

Main category: cs.AR

TL;DR: AERO是一种自适应、高效的运行时感知OTA更新机制，专为能量收集物联网设备设计，通过将更新任务集成到DAG中并与常规任务协同调度，解决间歇性能源环境下的更新一致性问题。


<details>
  <summary>Details</summary>
Motivation: 能量收集物联网设备在间歇性能源供应下运行，传统OTA更新机制依赖重启且开销大，不适合此类系统。现有的实时OTA更新技术虽减少重启开销，但缺乏确保更新与运行时执行交互一致性的机制。

Method: 提出AERO机制，将更新任务集成到设备的DAG中，在能量和时间约束下与常规任务协同调度。通过识别更新影响的执行区域并动态调整依赖关系，确保一致的更新集成，同时适应间歇性能源可用性。

Result: 在代表性工作负载上的实验表明，相比现有的实时更新方法，AERO在更新可靠性和效率方面都有显著提升。

Conclusion: AERO为能量收集物联网设备提供了一种自适应、高效的运行时感知OTA更新解决方案，能够确保更新一致性并适应间歇性能源环境，提高了系统的可靠性和效率。

Abstract: Energy-harvesting (EH) Internet of Things (IoT) devices operate under intermittent energy availability, which disrupts task execution and makes energy-intensive over-the-air (OTA) updates particularly challenging. Conventional OTA update mechanisms rely on reboots and incur significant overhead, rendering them unsuitable for intermittently powered systems. Recent live OTA update techniques reduce reboot overhead but still lack mechanisms to ensure consistency when updates interact with runtime execution. This paper presents AERO, an Adaptive and Efficient Runtime-Aware OTA update mechanism that integrates update tasks into the device's Directed Acyclic Graph (DAG) and schedules them alongside routine tasks under energy and timing constraints. By identifying update-affected execution regions and dynamically adjusting dependencies, AERO ensures consistent up date integration while adapting to intermittent energy availability. Experiments on representative workloads demonstrate improved update reliability and efficiency compared to existing live update approaches.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [21] [Space Filling Curves is All You Need: Communication-Avoiding Matrix Multiplication Made Simple](https://arxiv.org/abs/2601.16294)
*Evangelos Georganas,Alexander Heinecke,Pradeep Dubey*

Main category: cs.DC

TL;DR: 该论文提出使用广义希尔伯特曲线（空间填充曲线）来优化矩阵乘法（GEMM），实现平台无关和形状无关的高性能计算，避免繁琐的手动调优，并在多个CPU平台上超越厂商库性能。


<details>
  <summary>Details</summary>
Motivation: 现代CPU平台上的矩阵乘法加速器具有高FLOP/Byte机器平衡，使得实现最优矩阵乘法变得困难。厂商库需要针对不同平台和矩阵形状进行繁琐的调优（张量布局、并行化方案、缓存分块），导致性能存在"玻璃下巴"问题。

Method: 使用广义希尔伯特曲线（空间填充曲线）将多维计算空间转换为1D顺序，保持高维空间中邻近点在1D顺序中的邻近性。基于此进行矩阵乘法计算空间划分，实现平台无关和形状无关的数据局部性优化。进一步扩展到通信避免算法，复制输入张量并最小化关键路径上的通信/数据移动。

Result: 在多个CPU平台上实现了最先进的性能，对于一系列GEMM形状，相比厂商库实现了最高2倍的几何平均加速比。代码紧凑（约30行代码），通信避免算法集成无缝。

Conclusion: 空间填充曲线方法有效解决了矩阵乘法在不同平台和形状下的调优难题，通过平台无关和形状无关的计算划分实现了高性能，为深度学习和高性能计算中的GEMM优化提供了新思路。

Abstract: General Matrix Multiplication (GEMM) is the cornerstone of Deep Learning and HPC workloads; accordingly, academia and industry have heavily optimized this kernel. Modern platforms with matrix multiplication accelerators exhibit high FLOP/Byte machine balance, which makes implementing optimal matrix multiplication challenging. On modern CPU platforms with matrix engines, state-of-the-art vendor libraries tune input tensor layouts, parallelization schemes, and cache blocking to minimize data movement across the memory hierarchy and maximize throughput. However, the best settings for these parameters depend strongly on the target platform (number of cores, memory hierarchy, cache sizes) and on the shapes of the matrices, making exhaustive tuning infeasible; in practice this leads to performance "glass jaws". In this work we revisit space filling curves (SFC) to alleviate the problem of this cumbersome tuning. SFC convert multi-dimensional coordinates (e.g. 2D) into a single dimension (1D), keeping nearby points in the high-dimensional space close in the 1D order. We partition the Matrix Multiplication computation space using recent advancements in generalized SFC (Generalized Hilbert Curves), and we obtain platform-oblivious and shape-oblivious matrix-multiplication schemes that exhibit inherently high degree of data locality. Furthermore, we extend the SFC-based work partitioning to implement Communication-Avoiding (CA) algorithms that replicate the input tensors and provably minimize communication/data-movement on the critical path. The integration of CA-algorithms is seamless and yields compact code (~30 LOC), yet it achieves state-of-the-art results on multiple CPU platforms, outperforming vendor libraries by up to 2x(geometric-mean speedup) for a range of GEMM shapes.

</details>


### [22] [Consensus In Asynchrony](https://arxiv.org/abs/2601.16460)
*Ivan Klianev*

Main category: cs.DC

TL;DR: 论文证明了基于事件的同步足以解决异步环境下的确定性容错共识问题，提出了一个能保证安全性、活性和容忍一次崩溃的向量一致性算法，并重新审视了FLP不可能性定理的隐含假设。


<details>
  <summary>Details</summary>
Motivation: 传统FLP不可能性定理表明在完全异步系统中无法实现确定性容错共识，但该研究旨在探索在事件同步条件下是否可能绕过这一限制，重新审视FLP定理的隐含假设。

Method: 提出了一种基于事件同步的算法，该算法能够终止并产生有效的向量一致性。通过分析FLP定理的隐含假设，区分了数据无关和数据相关两种一致性类型。

Result: 实验结果表明，FLP定理所依赖的第三个隐含假设缺乏证据支持。算法在实际中能够实现安全性、活性和容忍一次崩溃的确定性共识。

Conclusion: 基于事件的同步足以实现确定性容错共识，FLP不可能性定理的适用性受到其隐含假设的限制，特别是第三个假设缺乏实证支持，这为异步系统中的共识问题提供了新的可能性。

Abstract: We demonstrate sufficiency of events-based synchronisation for solving deterministic fault-tolerant consensus in asynchrony. Main result is an algorithm that terminates with valid vector agreement, hence operates with safety, liveness, and tolerance to one crash. Reconciling with the FLP impossibility result, we identified: i) existence of two types of agreements: data-independent and data-dependent; and ii) dependence of FLP theorem correctness on three implicit assumptions. Consensus impossibility with data-dependent agreement is contingent on two of them. The theorem-stated impossibility with every agreement type hinges entirely on the third. We provide experimental results showing that the third assumption has no evidence in support.

</details>


### [23] [W4A16 Mixed-Precision Matrix Multiplication on Decoupled Architecture: Kernel Design and Memory Bottleneck Analysis for Ascend NPUs](https://arxiv.org/abs/2601.16536)
*Yuanhong He,Peiyu Niu,Jun Chen,Chenchen Zhang,Chao Yang*

Main category: cs.DC

TL;DR: 本文提出了首个针对华为昇腾910 NPU的W4A16矩阵乘法内核，通过向量核心实时解量化、立方核心高吞吐GEMM和Split-K并行化，在LLM解码场景下实现1.01-1.74倍加速。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模扩大，仅权重量化（W4A16）对减少内存占用至关重要，但在华为昇腾910 NPU上高效部署面临挑战，因为该架构缺乏原生混合精度支持且采用解耦计算架构。

Method: 设计针对昇腾910 NPU的W4A16矩阵乘法内核，利用向量核心进行INT4到FP16的实时解量化，使用立方核心执行高吞吐GEMM运算，并采用Split-K并行化策略来缓解内存延迟。

Result: 在不同矩阵形状和批量大小下，该方法在K>>N（LLM解码典型场景）时优于数据并行方法，实现1.01-1.74倍加速。分析显示主要瓶颈不是解量化计算本身，而是权重的额外全局内存传输，W4A16相比原生FP16最大加速比为1.48倍。

Conclusion: 该方法为在各种领域特定加速器上高效部署量化大语言模型奠定了坚实基础，并提供了有价值的见解。

Abstract: As Large Language Models (LLMs) scale, weight-only quantization (W4A16: 4-bit weights, 16-bit activations) becomes critical for reducing memory footprint with minimal accuracy loss. However, its efficient deployment on Huawei's Ascend 910 Neural Processing Unit (NPU) is challenging due to limited native mixed-precision support and the accelerator's decoupled compute architecture. To enable quantization on such architecture, we present the first practical W4A16 matrix multiplication kernel tailored for the Ascend 910 NPU. Our design leverages vector cores for on-the-fly INT4-to-FP16 dequantization, cube cores for high-throughput GEMM, and Split-K parallelization to mitigate memory latency. Performance evaluations across diverse matrix shapes and batch sizes show our method outperforms data-parallel approaches when K >> N, a typical scenario in LLM decoding. Specially, our method can achieve a speedup ranging from 1.01x to 1.74x. In addition, our profile reveals the primary bottleneck is not dequantization compution itself, but extra global memory transfer for the weight, making W4A16 only reaching a maximum speedup of 1.48x over native FP16xFP16 matrix multiplication in PyTorch. In the long run, our method lays a solid foundation and provides insightful views for the efficient deployment of quantized large language models on various domain-specific accelerators.

</details>


### [24] [GPU-Accelerated Selected Basis Diagonalization with Thrust for SQD-based Algorithms](https://arxiv.org/abs/2601.16637)
*Jun Doi,Tomonori Shirakawa,Yukio Kawashima,Seiji Yunoki,Hiroshi Horii*

Main category: cs.DC

TL;DR: 论文提出了一种基于Thrust库的GPU加速SBD实现，通过重构关键组件为细粒度数据并行原语，在GPU上实现了高达40倍的加速比。


<details>
  <summary>Details</summary>
Motivation: 在基于样本的量子对角化(SQD)中，选定基对角化(SBD)是主要的经典计算负载，需要高效加速以提升量子-经典混合工作流的性能。

Method: 使用Thrust库实现GPU加速的SBD，重构配置处理、激发生成和矩阵-向量操作等关键组件，采用细粒度数据并行原语和扁平化的GPU友好数据布局。

Result: Thrust-based SBD在实验中实现了高达约40倍于CPU执行的速度提升，显著减少了SQD迭代的总运行时间。

Conclusion: GPU原生并行原语为加速基于SQD的量子-经典工作流提供了简单、可移植和高性能的基础。

Abstract: Selected Basis Diagonalization (SBD) plays a central role in Sample-based Quantum Diagonalization (SQD), where iterative diagonalization of the Hamiltonian in selected configuration subspaces forms the dominant classical workload. We present a GPU-accelerated implementation of SBD using the Thrust library. By restructuring key components -- including configuration processing, excitation generation, and matrix-vector operations -- around fine-grained data-parallel primitives and flattened GPU-friendly data layouts, the proposed approach efficiently exploits modern GPU architectures. In our experiments, the Thrust-based SBD achieves up to $\sim$40$\times$ speedup over CPU execution and substantially reduces the total runtime of SQD iterations. These results demonstrate that GPU-native parallel primitives provide a simple, portable, and high-performance foundation for accelerating SQD-based quantum-classical workflows.

</details>


### [25] [DataStates-LLM: Scalable Checkpointing for Transformer Models Using Composable State Providers](https://arxiv.org/abs/2601.16956)
*Avinash Maurya,M. Mustafa Rafique,Franck Cappello,Bogdan Nicolae*

Main category: cs.DC

TL;DR: DataStates-LLM：一种新型检查点架构，通过状态提供者解耦状态抽象与数据移动，利用模型参数在前向/反向传播中的不变性实现异步懒快照，显著提升大规模LLM训练中的检查点性能。


<details>
  <summary>Details</summary>
Motivation: 随着大型Transformer模型参数规模达到万亿级别，需要在数千个GPU上使用复杂的混合并行策略进行训练。现有检查点解决方案将模型状态视为不透明的二进制块，忽略了底层数据结构的"3D异构性"（内存位置、逻辑对象分片、数据类型、序列化要求），导致显著的运行时开销。

Method: 提出DataStates-LLM检查点架构，引入状态提供者来解耦状态抽象与数据移动。利用模型参数在前向和反向传播过程中的不变性，执行"懒"非阻塞异步快照。通过状态提供者有效合并碎片化的异构分片，并将元数据序列化与批量张量I/O重叠。

Result: 在256个A100-40GB GPU上对高达700亿参数的模型进行评估。结果显示，DataStates-LLM相比最先进解决方案实现了高达4倍的检查点吞吐量提升，端到端训练时间减少高达2.2倍，有效缓解了极端规模LLM训练中的序列化和异构性瓶颈。

Conclusion: DataStates-LLM通过创新的状态提供者架构和异步懒快照机制，成功解决了大规模分布式LLM训练中的检查点性能瓶颈，为模型弹性、挂起恢复、训练轨迹分析等关键用例提供了高效支持。

Abstract: The rapid growth of Large Transformer-based models, specifically Large Language Models (LLMs), now scaling to trillions of parameters, has necessitated training across thousands of GPUs using complex hybrid parallelism strategies (e.g., data, tensor, and pipeline parallelism). Checkpointing this massive, distributed state is critical for a wide range of use cases, such as resilience, suspend-resume, investigating undesirable training trajectories, and explaining model evolution. However, existing checkpointing solutions typically treat model state as opaque binary blobs, ignoring the ``3D heterogeneity'' of the underlying data structures--varying by memory location (GPU vs. Host), number of ``logical'' objects sharded and split across multiple files, data types (tensors vs. Python objects), and their serialization requirements. This results in significant runtime overheads due to blocking device-to-host transfers, data-oblivious serialization, and storage I/O contention. In this paper, we introduce DataStates-LLM, a novel checkpointing architecture that leverages State Providers to decouple state abstraction from data movement. DataStates-LLM exploits the immutability of model parameters during the forward and backward passes to perform ``lazy'', non-blocking asynchronous snapshots. By introducing State Providers, we efficiently coalesce fragmented, heterogeneous shards and overlap the serialization of metadata with bulk tensor I/O. We evaluate DataStates-LLM on models up to 70B parameters on 256 A100-40GB GPUs. Our results demonstrate that DataStates-LLM achieves up to 4$\times$ higher checkpointing throughput and reduces end-to-end training time by up to 2.2$\times$ compared to state-of-the-art solutions, effectively mitigating the serialization and heterogeneity bottlenecks in extreme-scale LLM training.

</details>

<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 5]
- [cs.AR](#cs.AR) [Total: 4]
- [cs.CR](#cs.CR) [Total: 7]
- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [Assessing Redundancy Strategies to Improve Availability in Virtualized System Architectures](https://arxiv.org/abs/2511.20780)
*Alison Silva,Gustavo Callou*

Main category: cs.DC

TL;DR: 本文提出了一种基于随机Petri网的方法来分析私有云环境中Nextcloud文件服务器的可用性，评估了四种冗余策略配置，发现主机和虚拟机级别的冗余能显著提高系统可用性。


<details>
  <summary>Details</summary>
Motivation: 随着云存储平台在学术和商业环境中的普及，可靠性成为关键要求，特别是对于寻求公共云服务替代方案的组织。评估这些系统的可靠性至关重要。

Method: 使用随机Petri网(SPNs)建模方法，在Apache CloudStack私有云环境中分析Nextcloud文件服务器的可用性，评估了四种架构配置：基线、主机级冗余、虚拟机冗余以及两者组合。

Result: 结果表明，主机和虚拟机级别的冗余显著提高了可用性并减少了预期停机时间。

Conclusion: 所提出的方法提供了一种评估私有云可用性的途径，并支持基础设施设计决策。

Abstract: Cloud-based storage platforms are becoming more common in both academic and business settings due to their flexible access to data and support for collaborative functionalities. As reliability becomes a vital requirement, particularly for organizations looking for alternatives to public cloud services, assessing the dependability of these systems is crucial. This paper presents a methodology for analyzing the availability of a file server (Nextcloud) hosted in a private cloud environment using Apache CloudStack. The analysis is based on a modeling approach through Stochastic Petri Nets (SPNs) that allows the evaluation of different redundancy strategies to enhance the availability of such systems. Four architectural configurations were modeled, including the baseline, host-level redundancy, virtual machine (VM) redundancy, and a combination of both. The results show that redundancy at both the host and VM levels significantly improves availability and reduces expected downtime. The proposed approach provides a method to evaluate the availability of a private cloud and support infrastructure design decisions.

</details>


### [2] [A Dynamic PD-Disaggregation Architecture for Maximizing Goodput in LLM Inference Serving](https://arxiv.org/abs/2511.20982)
*Junhan Liao,Minxian Xu,Wanyi Zheng,Yan Wang,Kejiang Ye,Rajkumar Buyya,Chengzhong Xu*

Main category: cs.DC

TL;DR: DOPD是一个动态LLM推理系统，通过实时负载监控调整预填充和解码实例分配比例，解决异构工作负载下的生产者-消费者不平衡问题，提高系统吞吐量和降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有LLM系统将预填充和解码阶段分离到不同GPU上，但异构工作负载导致两种实例类型间的生产者-消费者不平衡，需要动态调整资源分配。

Method: 提出DOPD系统，基于实时负载监控动态调整预填充与解码实例的最优比例，结合适当的请求调度策略，解决高并发下混合长度请求导致的资源分配不匹配问题。

Result: 相比vLLM和DistServe，DOPD将系统吞吐量提升1.5倍，P90首token延迟降低67.5%，P90每输出token时间降低22.8%。

Conclusion: DOPD的动态P/D调整技术基于历史负载进行主动重配置，使用更少的额外资源实现超过99%的SLO达成率。

Abstract: To meet strict Service-Level Objectives (SLOs),contemporary Large Language Models (LLMs) decouple the prefill and decoding stages and place them on separate GPUs to mitigate the distinct bottlenecks inherent to each phase. However, the heterogeneity of LLM workloads causes producerconsumer imbalance between the two instance types in such disaggregated architecture. To address this problem, we propose DOPD (Dynamic Optimal Prefill/Decoding), a dynamic LLM inference system that adjusts instance allocations to achieve an optimal prefill-to-decoding (P/D) ratio based on real-time load monitoring. Combined with an appropriate request-scheduling policy, DOPD effectively resolves imbalances between prefill and decoding instances and mitigates resource allocation mismatches due to mixed-length requests under high concurrency. Experimental evaluations show that, compared with vLLM and DistServe (representative aggregation-based and disaggregationbased approaches), DOPD improves overall system goodput by up to 1.5X, decreases P90 time-to-first-token (TTFT) by up to 67.5%, and decreases P90 time-per-output-token (TPOT) by up to 22.8%. Furthermore, our dynamic P/D adjustment technique performs proactive reconfiguration based on historical load, achieving over 99% SLOs attainment while using less additional resources.

</details>


### [3] [Automated Dynamic AI Inference Scaling on HPC-Infrastructure: Integrating Kubernetes, Slurm and vLLM](https://arxiv.org/abs/2511.21413)
*Tim Trappen,Robert Keßler,Roland Pabel,Viktor Achter,Stefan Wesner*

Main category: cs.DC

TL;DR: 提出了一种在超级计算机RAMSES上集成vLLM、Slurm和Kubernetes来服务LLM的解决方案，该架构能够高效扩展以处理100、500和1000个并发请求，端到端延迟仅增加约500毫秒。


<details>
  <summary>Details</summary>
Motivation: 由于人工智能推理需求增加，特别是在高等教育领域，需要利用现有基础设施的新解决方案。传统高性能计算的操作模型不适用于同步、面向用户的动态AI应用工作负载。

Method: 在超级计算机RAMSES上集成vLLM、Slurm和Kubernetes来服务大型语言模型。

Result: 初始基准测试表明，所提出的架构能够高效扩展处理100、500和1000个并发请求，端到端延迟仅增加约500毫秒。

Conclusion: 该集成方案成功解决了传统HPC在AI推理应用中的适应性不足问题，为大规模LLM服务提供了可行方案。

Abstract: Due to rising demands for Artificial Inteligence (AI) inference, especially in higher education, novel solutions utilising existing infrastructure are emerging. The utilisation of High-Performance Computing (HPC) has become a prevalent approach for the implementation of such solutions. However, the classical operating model of HPC does not adapt well to the requirements of synchronous, user-facing dynamic AI application workloads. In this paper, we propose our solution that serves LLMs by integrating vLLM, Slurm and Kubernetes on the supercomputer \textit{RAMSES}. The initial benchmark indicates that the proposed architecture scales efficiently for 100, 500 and 1000 concurrent requests, incurring only an overhead of approximately 500 ms in terms of end-to-end latency.

</details>


### [4] [MemFine: Memory-Aware Fine-Grained Scheduling for MoE Training](https://arxiv.org/abs/2511.21431)
*Lu Zhao,Rong Shi,Shaoqing Zhang,Yueqiang Chen,Baoguo He,Hongfeng Sun,Ziqing Yin,Shangchao Su,Zhiyan Cui,Liang Dong,Xiyuan Li,Lingbin Wang,Jianwei He,Jiesong Ma,Weikang Huang,Jianglei Tong,Dongdong Gao,Jian Zhang,Hong Tian*

Main category: cs.DC

TL;DR: MemFine是一个内存感知的细粒度调度框架，用于解决MoE模型训练中的内存瓶颈问题，通过分块重计算策略减少48.03%的激活内存并提升4.42%的吞吐量。


<details>
  <summary>Details</summary>
Motivation: 大规模混合专家模型训练面临严重的内存瓶颈，由于动态令牌路由导致的负载不平衡使得GPU内存溢出，限制了模型的可扩展性。现有负载平衡方法会牺牲模型精度且在内存受限硬件上失效。

Method: MemFine将令牌分布和专家计算分解为可管理的块，采用分块重计算策略，通过理论内存模型动态优化内存效率和吞吐量之间的平衡。

Result: 实验表明，MemFine相比基于完全重计算的基线方法，减少了48.03%的激活内存，提升了4.42%的吞吐量，能够在内存受限的GPU上实现稳定的大规模MoE训练。

Conclusion: MemFine框架有效解决了MoE训练中的内存瓶颈问题，实现了内存受限硬件上的稳定大规模训练，平衡了内存效率和训练性能。

Abstract: The training of large-scale Mixture of Experts (MoE) models faces a critical memory bottleneck due to severe load imbalance caused by dynamic token routing. This imbalance leads to memory overflow on GPUs with limited capacity, constraining model scalability. Existing load balancing methods, which cap expert capacity, compromise model accuracy and fail on memory-constrained hardware. To address this, we propose MemFine, a memory-aware fine-grained scheduling framework for MoE training. MemFine decomposes the token distribution and expert computation into manageable chunks and employs a chunked recomputation strategy, dynamically optimized through a theoretical memory model to balance memory efficiency and throughput. Experiments demonstrate that MemFine reduces activation memory by 48.03% and improves throughput by 4.42% compared to full recomputation-based baselines, enabling stable large-scale MoE training on memory-limited GPUs.

</details>


### [5] [Modeling the Effect of Data Redundancy on Speedup in MLFMA Near-Field Computation](https://arxiv.org/abs/2511.21535)
*Morteza Sadeghi*

Main category: cs.DC

TL;DR: 通过引入数据冗余来改善MLFMA中近场算子的GPU性能，减少内存访问分散性，提高空间局部性。验证了在电磁求解器和恒星动力学代码中最高7倍的内核加速，但由于数据重组开销，端到端应用加速限制在1.04倍。


<details>
  <summary>Details</summary>
Motivation: MLFMA中的近场算子在GPU上由于内存局部性差成为性能瓶颈，需要改进内存访问模式。

Method: 引入数据冗余减少内存访问分散性，提出基于局部性度量的分析模型来预测加速趋势，无需硬件特定分析。

Result: 内核速度最高提升7倍，缓存行为改善明显，但由于数据重组开销，整体应用加速仅为1.04倍。模型能可靠捕捉不同问题规模和密度下的性能趋势。

Conclusion: 数据冗余可以提升GPU上P2P算子的性能，前提是局部性收益超过数据移动成本。该技术可最小化代码修改地集成到现有实现中。

Abstract: The near-field (P2P) operator in the Multilevel Fast Multipole Algorithm (MLFMA) is a performance bottleneck on GPUs due to poor memory locality. This work introduces data redundancy to improve spatial locality by reducing memory access dispersion. For validation of results, we propose an analytical model based on a Locality metric that combines data volume and access dispersion to predict speedup trends without hardware-specific profiling. The approach is validated on two MLFMA-based applications: an electromagnetic solver (DBIM-MLFMA) with regular structure, and a stellar dynamics code (PhotoNs-2.0) with irregular particle distribution. Results show up to 7X kernel speedup due to improved cache behavior. However, increased data volume raises overheads in data restructuring, limiting end-to-end application speedup to 1.04X. While the model cannot precisely predict absolute speedups, it reliably captures performance trends across different problem sizes and densities. The technique is injectable into existing implementations with minimal code changes. This work demonstrates that data redundancy can enhance GPU performance for P2P operator, provided locality gains outweigh data movement costs.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [6] [RISC-V Based TinyML Accelerator for Depthwise Separable Convolutions in Edge AI](https://arxiv.org/abs/2511.21232)
*Muhammed Yildirim,Ozcan Ozturk*

Main category: cs.AR

TL;DR: 提出一种融合像素级数据流硬件加速器架构，通过消除中间缓冲区，在边缘AI应用中显著减少数据移动和能耗。


<details>
  <summary>Details</summary>
Motivation: 解决边缘AI和TinyML应用中深度可分离卷积的多阶段设计导致的中间特征图传输能耗和延迟问题，突破内存墙限制。

Method: 设计基于RISC-V处理器的定制功能单元，采用融合像素级数据流，在单个流水线中完成所有DSC阶段的计算，无需中间缓冲区。

Result: 相比传统逐层执行减少87%数据移动，FPGA实现比软件基线加速59.3倍，ASIC合成显示紧凑的面积和功耗特性。

Conclusion: 证实了在TinyML资源限制内实现零缓冲区数据流的可行性，为边缘AI加速器克服内存墙提供了有效策略。

Abstract: The increasing demand for on-device intelligence in Edge AI and TinyML applications requires the efficient execution of modern Convolutional Neural Networks (CNNs). While lightweight architectures like MobileNetV2 employ Depthwise Separable Convolutions (DSC) to reduce computational complexity, their multi-stage design introduces a critical performance bottleneck inherent to layer-by-layer execution: the high energy and latency cost of transferring intermediate feature maps to either large on-chip buffers or off-chip DRAM. To address this memory wall, this paper introduces a novel hardware accelerator architecture that utilizes a fused pixel-wise dataflow. Implemented as a Custom Function Unit (CFU) for a RISC-V processor, our architecture eliminates the need for intermediate buffers entirely, reducing the data movement up to 87\% compared to conventional layer-by-layer execution. It computes a single output pixel to completion across all DSC stages-expansion, depthwise convolution, and projection-by streaming data through a tightly-coupled pipeline without writing to memory. Evaluated on a Xilinx Artix-7 FPGA, our design achieves a speedup of up to 59.3x over the baseline software execution on the RISC-V core. Furthermore, ASIC synthesis projects a compact 0.284 mm$^2$ footprint with 910 mW power at 2 GHz in 28 nm, and a 1.20 mm$^2$ footprint with 233 mW power at 300 MHz in 40 nm. This work confirms the feasibility of a zero-buffer dataflow within a TinyML resource envelope, offering a novel and effective strategy for overcoming the memory wall in edge AI accelerators.

</details>


### [7] [Bombyx: OpenCilk Compilation for FPGA Hardware Acceleration](https://arxiv.org/abs/2511.21346)
*Mohamed Shahawy,Julien de Castelnau,Paolo Ienne*

Main category: cs.AR

TL;DR: Bombyx是一个编译器工具链，将OpenCilk程序转换为Cilk-1风格的中间表示，使CPU导向的任务级并行应用能高效映射到FPGA空间架构上。


<details>
  <summary>Details</summary>
Motivation: 现有系统在FPGA上支持任务级并行时通常使用高级综合创建处理单元，但OpenCilk的隐式任务模型需要昂贵的硬件上下文切换，而Cilk-1的显式延续传递模型更适合FPGA的流式特性。

Method: 开发Bombyx编译器工具链，将OpenCilk程序降级为Cilk-1风格中间表示；支持多种编译目标，包括OpenCilk兼容运行时和可综合处理单元生成器；引入解耦访问-执行优化自动生成高性能处理单元。

Result: Bombyx能够有效映射CPU导向的任务级并行应用到FPGA空间架构，通过解耦访问-执行优化提高了内存-计算重叠和整体吞吐量。

Conclusion: Bombyx通过将OpenCilk程序转换为更适合FPGA的Cilk-1风格表示，实现了任务级并行应用在FPGA上的高效执行，为CPU导向并行应用在空间架构上的部署提供了有效解决方案。

Abstract: Task-level parallelism (TLP) is a widely used approach in software where independent tasks are dynamically created and scheduled at runtime. Recent systems have explored architectural support for TLP on field-programmable gate arrays (FPGAs), often leveraging high-level synthesis (HLS) to create processing elements (PEs). In this paper, we present Bombyx, a compiler toolchain that lowers OpenCilk programs into a Cilk-1-inspired intermediate representation, enabling efficient mapping of CPU-oriented TLP applications to spatial architectures on FPGAs. Unlike OpenCilk's implicit task model, which requires costly context switching in hardware, Cilk-1 adopts explicit continuation-passing - a model that better aligns with the streaming nature of FPGAs. Bombyx supports multiple compilation targets: one is an OpenCilk-compatible runtime for executing Cilk-1-style code using the OpenCilk backend, and another is a synthesizable PE generator designed for HLS tools like Vitis HLS. Additionally, we introduce a decoupled access-execute optimization that enables automatic generation of high-performance PEs, improving memory-compute overlap and overall throughput.

</details>


### [8] [A Jammer-Resilient 2.87 mm$^2$ 1.28 MS/s 310 mW Multi-Antenna Synchronization ASIC in 65 nm](https://arxiv.org/abs/2511.21451)
*Flurin Arquint,Oscar Castañeda,Gian Marti,Christoph Studer*

Main category: cs.AR

TL;DR: 首个抗干扰多天线时间同步ASIC实现，支持单天线发射端与16天线接收端同步，可抵御最多2天线智能干扰器攻击。


<details>
  <summary>Details</summary>
Motivation: 针对无线通信系统中时间同步信号易受干扰攻击的问题，需要开发能够抵御智能干扰的多天线同步解决方案。

Method: 采用多天线处理算法，在65nm工艺下实现ASIC设计，支持16天线接收和单天线发射的同步架构。

Result: 芯片核心面积2.87mm²，功耗310mW，采样率1.28MS/s，成功实现了抗干扰时间同步功能。

Conclusion: 该ASIC验证了多天线处理在抗干扰时间同步中的有效性，为安全无线通信系统提供了硬件实现方案。

Abstract: We present the first ASIC implementation of jammer-resilient multi-antenna time synchronization. The ASIC implements a recent algorithm that mitigates jamming attacks on synchronization signals using multi-antenna processing. Our design supports synchronization between a single-antenna transmitter and a 16-antenna receiver while mitigating smart jammers with up to two transmit antennas. The fabricated 65 nm ASIC has a core area of 2.87 mm$^2$, consumes a power of 310 mW, and supports a sampling rate of 1.28 mega-samples per second (MS/s).

</details>


### [9] [A 0.32 mm$^2$ 100 Mb/s 223 mW ASIC in 22FDX for Joint Jammer Mitigation, Channel Estimation, and SIMO Data Detection](https://arxiv.org/abs/2511.21461)
*Jonas Elmiger,Fabian Stuber,Oscar Castañeda,Gian Marti,Christoph Studer*

Main category: cs.AR

TL;DR: 本文提出首个单输入多输出接收器ASIC，联合执行干扰抑制、信道估计和数据检测，采用MAED算法，在22nm FD-SOI工艺下实现0.32mm²核心面积，吞吐量100Mb/s，功耗223mW。


<details>
  <summary>Details</summary>
Motivation: 开发能够同时处理智能干扰器和扫频干扰器的接收器ASIC，提高在干扰环境下的通信可靠性和性能。

Method: 采用MAED算法，通过非线性优化问题统一干扰估计与消除、信道估计和数据检测，实现空间滤波干扰抑制。

Result: 支持8个接收天线，在22nm FD-SOI工艺下实现0.32mm²核心面积，吞吐量100Mb/s，功耗223mW，相比现有技术提供3倍用户吞吐量和4.5倍面积效率。

Conclusion: 该ASIC在干扰环境下实现了卓越的误码率性能，为抗干扰通信系统提供了高效的硬件解决方案。

Abstract: We present the first single-input multiple-output (SIMO) receiver ASIC that jointly performs jammer mitigation, channel estimation, and data detection. The ASIC implements a recent algorithm called siMultaneous mitigAtion, Estimation, and Detection (MAED). MAED mitigates smart jammers via spatial filtering using a nonlinear optimization problem that unifies jammer estimation and nulling, channel estimation, and data detection to achieve state-of-the-art error-rate performance under jamming. The design supports eight receive antennas and enables mitigation of smart jammers as well as of barrage jammers. The ASIC is fabricated in 22 nm FD-SOI, has a core area of 0.32 mm$^2$, and achieves a throughput of 100 Mb/s at 223 mW, thus delivering 3$\times$ higher per-user throughput and 4.5$\times$ higher area efficiency than the state-of-the-art jammer-resilient detector.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [10] [Supporting Students in Navigating LLM-Generated Insecure Code](https://arxiv.org/abs/2511.20878)
*Jaehwan Park,Kyungchan Lim,Seonhye Park,Doowon Kim*

Main category: cs.CR

TL;DR: Bifröst是一个教育框架，通过在AI辅助开发中模拟不安全代码生成来培养安全意识和批判性评估技能。


<details>
  <summary>Details</summary>
Motivation: 当前AI辅助开发教育强调效率但忽视安全风险，学生缺乏识别和缓解AI生成代码中安全问题的能力。

Method: 开发包含VS Code扩展、对抗性配置LLM生成不安全代码、反馈系统三个组件的教育框架，让学生在受控环境中体验安全风险。

Result: 课堂部署(n=61)显示学生对不安全代码的脆弱性，干预后调查(n=21)表明对LLM输出的怀疑度提高。

Conclusion: Bifröst框架有效提升了学生在AI辅助开发中的安全意识和批判性思维，填补了当前教育的安全空白。

Abstract: The advent of Artificial Intelligence (AI), particularly large language models (LLMs), has revolutionized software development by enabling developers to specify tasks in natural language and receive corresponding code, boosting productivity. However, this shift also introduces security risks, as LLMs may generate insecure code that can be exploited by adversaries. Current educational approaches emphasize efficiency while overlooking these risks, leaving students underprepared to identify and mitigate security issues in AI-assisted workflows.
  To address this gap, we present Bifröst, an educational framework that cultivates security awareness in AI-augmented development. Bifröst integrates (1) a Visual Studio Code extension simulating realistic environments, (2) adversarially configured LLMs that generate insecure code, and (3) a feedback system highlighting vulnerabilities. By immersing students in tasks with compromised LLMs and providing targeted security analysis, Bifröst cultivates critical evaluation skills; classroom deployments (n=61) show vulnerability to insecure code, while a post-intervention survey (n=21) indicates increased skepticism toward LLM outputs.

</details>


### [11] [A Taxonomy of Pix Fraud in Brazil: Attack Methodologies, AI-Driven Amplification, and Defensive Strategies](https://arxiv.org/abs/2511.20902)
*Glener Lanes Pizzolato,Brenda Medeiros Lopes,Claudio Schepke,Diego Kreutz*

Main category: cs.CR

TL;DR: 本文综述了针对巴西央行2020年推出的即时支付系统Pix的攻击方法，识别和分类了影响用户和金融机构的主要欺诈类型，强调了这些技术的演变和日益复杂化。


<details>
  <summary>Details</summary>
Motivation: 研究旨在识别和分类影响Pix用户和金融机构的主要欺诈类型，突出这些攻击技术的演变和日益复杂化。

Method: 采用结构化文献综述与银行行业专业人员的探索性访谈相结合的方法。

Result: 结果显示欺诈方案已从纯粹的社会工程方法演变为整合人为操纵与技术利用的混合策略。

Conclusion: 安全措施必须与攻击方法日益增长的复杂性同步发展，特别强调适应性防御和持续的用户意识教育。

Abstract: This work presents a review of attack methodologies targeting Pix, the instant payment system launched by the Central Bank of Brazil in 2020. The study aims to identify and classify the main types of fraud affecting users and financial institutions, highlighting the evolution and increasing sophistication of these techniques. The methodology combines a structured literature review with exploratory interviews conducted with professionals from the banking sector. The results show that fraud schemes have evolved from purely social engineering approaches to hybrid strategies that integrate human manipulation with technical exploitation. The study concludes that security measures must advance at the same pace as the growing complexity of attack methodologies, with particular emphasis on adaptive defenses and continuous user awareness.

</details>


### [12] [Readout-Side Bypass for Residual Hybrid Quantum-Classical Models](https://arxiv.org/abs/2511.20922)
*Guilin Zhang,Wulan Guo,Ziqi Tan,Hongyang He,Hailong Jiang*

Main category: cs.CR

TL;DR: 提出了一种轻量级残差混合架构，通过将量子特征与原始输入在分类前拼接来绕过测量瓶颈，在中心化和联邦学习设置中均优于纯量子模型和先前的混合模型。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习虽然具有紧凑和表达性强的表示能力，但受到测量瓶颈的限制——狭窄的量子-经典读出通道限制了性能并放大了隐私风险。

Method: 采用轻量级残差混合架构，在量子-经典接口处将量子特征与原始输入进行拼接，然后进行分类，不增加量子复杂度。

Result: 实验显示该模型在中心化和联邦学习设置中均优于纯量子模型和先前的混合模型，相比量子基线准确率提升高达+55%，同时保持低通信成本和增强的隐私鲁棒性。

Conclusion: 该方法为在隐私敏感、资源受限的环境（如联邦边缘学习）中集成量子模型提供了一条实用且近期的可行路径。

Abstract: Quantum machine learning (QML) promises compact and expressive representations, but suffers from the measurement bottleneck - a narrow quantum-to-classical readout that limits performance and amplifies privacy risk. We propose a lightweight residual hybrid architecture that concatenates quantum features with raw inputs before classification, bypassing the bottleneck without increasing quantum complexity. Experiments show our model outperforms pure quantum and prior hybrid models in both centralized and federated settings. It achieves up to +55% accuracy improvement over quantum baselines, while retaining low communication cost and enhanced privacy robustness. Ablation studies confirm the effectiveness of the residual connection at the quantum-classical interface. Our method offers a practical, near-term pathway for integrating quantum models into privacy-sensitive, resource-constrained settings like federated edge learning.

</details>


### [13] [Road Network-Aware Personalized Trajectory Protection with Differential Privacy under Spatiotemporal Correlations](https://arxiv.org/abs/2511.21020)
*Minghui Min,Jiahui Liu,Mingge Cao,Shiyin Li,Hongliang Zhang,Miao Pan,Zhu Han*

Main category: cs.CR

TL;DR: 本文提出了一种个性化轨迹隐私保护机制PTPPM，通过结合地理不可区分性和失真隐私，让用户自定义隐私偏好，并基于位置敏感性分配隐私预算，在保护隐私的同时维持服务质量。


<details>
  <summary>Details</summary>
Motivation: 位置服务为用户带来便利但存在隐私风险，攻击者可通过时空相关性推断敏感信息。由于用户对位置数据的敏感性因停留时间、访问频率等因素而异，需要个性化的隐私保护方案。

Method: 结合地理不可区分性和失真隐私构建保护位置集；提出个性化隐私预算分配算法PPBA，基于轨迹数据评估位置敏感性；引入Permute-and-Flip机制生成扰动位置以最小化扰动距离。

Result: 仿真结果表明，该机制优于现有基准方法，在满足用户服务质量要求的同时提供更优的隐私保护。

Conclusion: PTPPM机制能够有效保护用户轨迹隐私，通过个性化隐私预算分配和位置扰动策略，在隐私保护和服务质量之间实现良好平衡。

Abstract: Location-Based Services (LBSs) offer significant convenience to mobile users but pose significant privacy risks, as attackers can infer sensitive personal information through spatiotemporal correlations in user trajectories. Since users' sensitivity to location data varies based on factors such as stay duration, access frequency, and semantic sensitivity, implementing personalized privacy protection is imperative. This paper proposes a Personalized Trajectory Privacy Protection Mechanism (PTPPM) to address these challenges. Our approach begins by modeling an attacker's knowledge of a user's trajectory spatiotemporal correlations, which enables the attacker to identify possible location sets and disregard low-probability location sets. To combat this, we integrate geo-indistinguishability with distortion privacy, allowing users to customize their privacy preferences through a configurable privacy budget and expected inference error bound. This approach provides the theoretical framework for constructing a Protection Location Set (PLS) that obscures users' actual locations. Additionally, we introduce a Personalized Privacy Budget Allocation Algorithm (PPBA), which assesses the sensitivity of locations based on trajectory data and allocates privacy budgets accordingly. This algorithm considers factors such as location semantics and road network constraints. Furthermore, we propose a Permute-and-Flip mechanism that generates perturbed locations while minimizing perturbation distance, thus balancing privacy protection and Quality of Service (QoS). Simulation results demonstrate that our mechanism outperforms existing benchmarks, offering superior privacy protection while maintaining user QoS requirements.

</details>


### [14] [CAHS-Attack: CLIP-Aware Heuristic Search Attack Method for Stable Diffusion](https://arxiv.org/abs/2511.21180)
*Shuhan Xia,Jing Dai,Hui Ouyang,Yadong Shang,Dongxiao Zhao,Peipei Li*

Main category: cs.CR

TL;DR: 本文提出CAHS-Attack方法，这是一种基于CLIP感知启发式搜索的攻击方法，用于发现扩散模型在对抗性提示下的脆弱性。该方法结合蒙特卡洛树搜索进行细粒度后缀优化，利用约束遗传算法预选高潜力对抗提示作为根节点，并在每次模拟中保留最具语义破坏性的结果以实现高效局部搜索。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在面对对抗性提示时表现出显著的脆弱性，增强攻击能力对于发现此类漏洞和构建更鲁棒的生成系统至关重要。现有方法通常依赖模型梯度的白盒访问或手工制作的提示工程，这在现实世界部署中不可行。

Method: CAHS-Attack方法整合蒙特卡洛树搜索进行细粒度后缀优化，使用约束遗传算法预选高潜力对抗提示作为根节点，并在每次模拟中保留最具语义破坏性的结果以实现高效局部搜索。

Result: 大量实验表明，该方法在不同语义的短提示和长提示上都实现了最先进的攻击性能。此外，研究发现SD模型的脆弱性可归因于其基于CLIP的文本编码器的固有脆弱性。

Conclusion: 这表明当前文本到图像流水线存在根本性的安全风险，需要关注CLIP文本编码器的安全性问题。

Abstract: Diffusion models exhibit notable fragility when faced with adversarial prompts, and strengthening attack capabilities is crucial for uncovering such vulnerabilities and building more robust generative systems. Existing works often rely on white-box access to model gradients or hand-crafted prompt engineering, which is infeasible in real-world deployments due to restricted access or poor attack effect. In this paper, we propose CAHS-Attack , a CLIP-Aware Heuristic Search attack method. CAHS-Attack integrates Monte Carlo Tree Search (MCTS) to perform fine-grained suffix optimization, leveraging a constrained genetic algorithm to preselect high-potential adversarial prompts as root nodes, and retaining the most semantically disruptive outcome at each simulation rollout for efficient local search. Extensive experiments demonstrate that our method achieves state-of-the-art attack performance across both short and long prompts of varying semantics. Furthermore, we find that the fragility of SD models can be attributed to the inherent vulnerability of their CLIP-based text encoders, suggesting a fundamental security risk in current text-to-image pipelines.

</details>


### [15] [AuthenLoRA: Entangling Stylization with Imperceptible Watermarks for Copyright-Secure LoRA Adapters](https://arxiv.org/abs/2511.21216)
*Fangming Shi,Li Li,Kejiang Chen,Guorui Feng,Xinpeng Zhang*

Main category: cs.CR

TL;DR: AuthenLoRA是一个统一的水印框架，通过在LoRA训练过程中嵌入不可感知的追踪水印来解决扩散模型定制中的版权保护问题，同时保持风格化质量。


<details>
  <summary>Details</summary>
Motivation: 现有的水印技术要么针对基础模型，要么验证LoRA模块本身，但无法将水印传播到生成的图像中，存在可追溯性空白。此外，为基础模型设计的可追溯性水印与风格化不紧密耦合，通常会导致视觉质量下降或高误检率。

Method: AuthenLoRA采用双目标优化策略，联合学习目标风格分布和水印引起的分布偏移，确保使用带水印LoRA生成的任何图像都可靠地携带水印。设计了扩展的LoRA架构以增强多尺度适应，并引入零消息正则化机制来显著降低水印验证中的误检率。

Result: 大量实验表明，AuthenLoRA实现了高保真风格化、鲁棒的水印传播，与现有方法相比显著降低了误检率。

Conclusion: AuthenLoRA提供了一个有效的解决方案，能够在保持风格化质量的同时，为LoRA定制的扩散模型提供可靠的水印追踪能力。

Abstract: Low-Rank Adaptation (LoRA) offers an efficient paradigm for customizing diffusion models, but its ease of redistribution raises concerns over unauthorized use and the generation of untraceable content. Existing watermarking techniques either target base models or verify LoRA modules themselves, yet they fail to propagate watermarks to generated images, leaving a critical gap in traceability. Moreover, traceability watermarking designed for base models is not tightly coupled with stylization and often introduces visual degradation or high false-positive detection rates. To address these limitations, we propose AuthenLoRA, a unified watermarking framework that embeds imperceptible, traceable watermarks directly into the LoRA training process while preserving stylization quality. AuthenLoRA employs a dual-objective optimization strategy that jointly learns the target style distribution and the watermark-induced distribution shift, ensuring that any image generated with the watermarked LoRA reliably carries the watermark. We further design an expanded LoRA architecture for enhanced multi-scale adaptation and introduce a zero-message regularization mechanism that substantially reduces false positives during watermark verification. Extensive experiments demonstrate that AuthenLoRA achieves high-fidelity stylization, robust watermark propagation, and significantly lower false-positive rates compared with existing approaches. Open-source implementation is available at: https://github.com/ShiFangming0823/AuthenLoRA

</details>


### [16] [Empirical Assessment of the Code Comprehension Effort Needed to Attack Programs Protected with Obfuscation](https://arxiv.org/abs/2511.21301)
*Leonardo Regano,Daniele Canavese,Cataldo Basile,Marco Torchiano*

Main category: cs.CR

TL;DR: 本文通过控制实验评估软件混淆技术的有效性，研究混淆对代码理解任务的影响，并探索复杂度指标与攻击成功率的关联。


<details>
  <summary>Details</summary>
Motivation: 软件混淆技术被广泛采用但其有效性缺乏系统评估，需要实证研究来验证混淆技术在延迟代码理解和防止逆向工程方面的实际效果。

Method: 采用控制实验方法，让硕士生对经过混淆处理的应用程序执行代码理解任务，评估单层和多层混淆技术对理解难度的影响。

Result: 实验首次评估了多层混淆技术叠加的效果，提供了客观指标与攻击成功率之间相关性的实验证据，填补了客观与主观评估方法之间的空白。

Conclusion: 混淆技术确实能有效延迟代码理解，复杂度指标可以预测保护效果，研究为软件保护评估开辟了新方向，指出了需要进一步分析的重要方面。

Abstract: Evaluating the effectiveness of software protection is crucial for selecting the most effective methods to safeguard assets within software applications. Obfuscation involves techniques that deliberately modify software to make it more challenging to understand and reverse-engineer, while maintaining its original functionality. Although obfuscation is widely adopted, its effectiveness remains largely unexplored and unthoroughly evaluated. This paper presents a controlled experiment involving Master's students performing code comprehension tasks on applications hardened with obfuscation. The experiment's goals are to assess the effectiveness of obfuscation in delaying code comprehension by attackers and to determine whether complexity metrics can accurately predict the impact of these protections on success rates and durations of code comprehension tasks. The study is the first to evaluate the effect of layering multiple obfuscation techniques on a single piece of protected code. It also provides experimental evidence of the correlation between objective metrics of the attacked code and the likelihood of a successful attack, bridging the gap between objective and subjective approaches to estimating potency. Finally, the paper highlights significant aspects that warrant additional analysis and opens new avenues for further experiments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [17] [Minimizing Hyperbolic Embedding Distortion with LLM-Guided Hierarchy Restructuring](https://arxiv.org/abs/2511.20679)
*Melika Ayoughi,Pascal Mettes,Paul Groth*

Main category: cs.AI

TL;DR: 本文研究使用大型语言模型自动重构层次结构以优化双曲嵌入质量，提出基于提示的方法来转换现有层次结构，实验表明LLM重构的层次结构在多个标准嵌入质量指标上表现更好。


<details>
  <summary>Details</summary>
Motivation: 双曲嵌入的质量与输入层次结构紧密相关，而最优双曲嵌入需要高分支因子和单继承。为了帮助知识工程师重组层次知识，研究LLM是否能够自动重构层次结构以满足这些标准。

Method: 提出基于提示的方法，使用大型语言模型在已知双曲嵌入期望标准的指导下转换现有层次结构。

Result: 在16个不同层次结构上的实验表明，LLM重构的层次结构在多个标准嵌入质量指标上一致产生更高质量的双曲嵌入。

Conclusion: LLM引导的层次结构重构能够实现可解释的重组，为知识工程师提供理由，并提高双曲嵌入质量。

Abstract: Hyperbolic geometry is an effective geometry for embedding hierarchical data structures. Hyperbolic learning has therefore become increasingly prominent in machine learning applications where data is hierarchically organized or governed by hierarchical semantics, ranging from recommendation systems to computer vision. The quality of hyperbolic embeddings is tightly coupled to the structure of the input hierarchy, which is often derived from knowledge graphs or ontologies. Recent work has uncovered that for an optimal hyperbolic embedding, a high branching factor and single inheritance are key, while embedding algorithms are robust to imbalance and hierarchy size. To assist knowledge engineers in reorganizing hierarchical knowledge, this paper investigates whether Large Language Models (LLMs) have the ability to automatically restructure hierarchies to meet these criteria. We propose a prompt-based approach to transform existing hierarchies using LLMs, guided by known desiderata for hyperbolic embeddings. Experiments on 16 diverse hierarchies show that LLM-restructured hierarchies consistently yield higher-quality hyperbolic embeddings across several standard embedding quality metrics. Moreover, we show how LLM-guided hierarchy restructuring enables explainable reorganizations, providing justifications to knowledge engineers.

</details>


### [18] [AssurAI: Experience with Constructing Korean Socio-cultural Datasets to Discover Potential Risks of Generative AI](https://arxiv.org/abs/2511.20686)
*Chae-Gyun Lim,Seung-Ho Han,EunYoung Byun,Jeongyun Han,Soohyun Cho,Eojin Joo,Heehyeon Kim,Sieun Kim,Juhoon Lee,Hyunsoo Lee,Dongkun Lee,Jonghwan Hyeon,Yechan Hwang,Young-Jun Lee,Kyeongryul Lee,Minhyeong An,Hyunjun Ahn,Jeongwoo Son,Junho Park,Donggyu Yoon,Taehyung Kim,Jeemin Kim,Dasom Choi,Kwangyoung Lee,Hyunseung Lim,Yeohyun Jung,Jongok Hong,Sooyohn Nam,Joonyoung Park,Sungmin Na,Yubin Choi,Jeanne Choi,Yoojin Hong,Sueun Jang,Youngseok Seo,Somin Park,Seoungung Jo,Wonhye Chae,Yeeun Jo,Eunyoung Kim,Joyce Jiyoung Whang,HwaJung Hong,Joseph Seering,Uichin Lee,Juho Kim,Sunna Choi,Seokyeon Ko,Taeho Kim,Kyunghoon Kim,Myungsik Ha,So Jung Lee,Jemin Hwang,JoonHo Kwak,Ho-Jin Choi*

Main category: cs.AI

TL;DR: AssurAI是一个针对韩语多模态生成AI安全评估的质量控制数据集，包含11,480个实例，涵盖文本、图像、视频和音频四种模态，专门设计用于评估韩国社会文化背景下的AI风险。


<details>
  <summary>Details</summary>
Motivation: 当前的安全数据集主要是英语中心化的，无法捕捉非英语社会文化背景（如韩语）中的特定风险，且通常仅限于文本模态，因此需要开发专门针对韩语多模态环境的安全评估数据集。

Method: 定义了35个不同的AI风险因素分类法，通过多学科专家组调整现有框架；采用两阶段构建过程（专家引导的种子生成和众包扩展）、三重独立标注和迭代式专家红队测试循环来确保数据质量。

Result: 构建并发布了AssurAI数据集，包含11,480个实例，涵盖四种模态；试点研究验证了该数据集在评估最新LLM安全性方面的有效性。

Conclusion: AssurAI数据集能够有效评估生成AI在韩语环境中的安全性，为韩国社区开发更安全可靠的生成AI系统提供了重要资源。

Abstract: The rapid evolution of generative AI necessitates robust safety evaluations. However, current safety datasets are predominantly English-centric, failing to capture specific risks in non-English, socio-cultural contexts such as Korean, and are often limited to the text modality. To address this gap, we introduce AssurAI, a new quality-controlled Korean multimodal dataset for evaluating the safety of generative AI. First, we define a taxonomy of 35 distinct AI risk factors, adapted from established frameworks by a multidisciplinary expert group to cover both universal harms and relevance to the Korean socio-cultural context. Second, leveraging this taxonomy, we construct and release AssurAI, a large-scale Korean multimodal dataset comprising 11,480 instances across text, image, video, and audio. Third, we apply the rigorous quality control process used to ensure data integrity, featuring a two-phase construction (i.e., expert-led seeding and crowdsourced scaling), triple independent annotation, and an iterative expert red-teaming loop. Our pilot study validates AssurAI's effectiveness in assessing the safety of recent LLMs. We release AssurAI to the public to facilitate the development of safer and more reliable generative AI systems for the Korean community.

</details>


### [19] [$A^2Flow:$ Automating Agentic Workflow Generation via Self-Adaptive Abstraction Operators](https://arxiv.org/abs/2511.20693)
*Mingming Zhao,Xiaokang Wei,Yuanqi Shao,Kaiwen Zhou,Lin Yang,Siwei Rao,Junhui Zhan,Zhitang Chen*

Main category: cs.AI

TL;DR: A²Flow是一个基于自适应抽象算子的全自动智能体工作流生成框架，通过三阶段算子提取过程自动生成可重用的执行算子，无需手动预定义，在性能和资源效率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法严重依赖手动预定义算子，限制了智能体工作流设计的泛化性和可扩展性，需要开发完全自动化的框架来解决这一问题。

Method: 采用三阶段算子提取过程：1）基于案例的初始算子生成；2）算子聚类和初步抽象；3）深度提取抽象执行算子。同时引入算子记忆机制来增强工作流搜索。

Result: 在通用和具身基准测试中，A²Flow实现了2.4%和19.3%的平均性能提升，并将资源使用量减少了37%，优于现有最先进方法。

Conclusion: A²Flow通过完全自动化的算子提取和工作流生成，显著提升了智能体工作流设计的效率和性能，为自动化智能体系统开发提供了有效解决方案。

Abstract: Large language models (LLMs) have shown strong potential in automating the design of agentic workflows. However, existing methods still rely heavily on manually predefined operators, limiting generalization and scalability. To address this issue, we propose $A^2Flow$, a fully automated framework for agentic workflow generation based on self-adaptive abstraction operators. $A^2Flow$ employs a three-stage operator extraction process: 1) Case-based Initial Operator Generation: leveraging expert demonstrations and LLM reasoning to generate case-specific operators; 2) Operator Clustering and Preliminary Abstraction: grouping similar operators across tasks to form preliminary abstractions; and 3) Deep Extraction for Abstract Execution Operators: applying long chain-of-thought prompting and multi-path reasoning to derive compact and generalizable execution operators. These operators serve as reusable building blocks for workflow construction without manual predefinition. Furthermore, we enhance node-level workflow search with an operator memory mechanism, which retains historical outputs to enrich context and improve decision-making. Experiments on general and embodied benchmarks show that $A^2Flow$ achieves a 2.4\% and 19.3\% average performance improvement and reduces resource usage by 37\% over state-of-the-art baselines. Homepage:https://github.com/pandawei-ele/A2FLOW

</details>


### [20] [Reasoning With a Star: A Heliophysics Dataset and Benchmark for Agentic Scientific Reasoning](https://arxiv.org/abs/2511.20694)
*Kevin Lee,Russell Spiewak,James Walsh*

Main category: cs.AI

TL;DR: 本文提出了一个名为'Reasoning With a Star'的日球物理学数据集和基准测试方法，用于评估大型语言模型在科学推理方面的能力，包括物理假设、单位一致性和科学格式要求。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在日球物理学科学推理中的挑战，包括物理假设整合、单位一致性维护和科学格式提供，而不仅仅是事实回忆。

Method: 构建基于NASA和UCAR Living With a Star暑期学校问题集的数据集，采用程序化评分器检查预测结果，包括单位感知数值容差、符号等价性和模式验证，并比较单次提示和四种多智能体模式。

Result: 发现通过系统工程原则分解工作流程在需要演绎推理而非纯归纳回忆的问题上表现优于直接提示方法。

Conclusion: 多智能体模式和系统工程方法能够有效提升大型语言模型在复杂科学推理任务中的表现，特别是在需要演绎推理的场景下。

Abstract: Scientific reasoning through Large Language Models in heliophysics involves more than just recalling facts: it requires incorporating physical assumptions, maintaining consistent units, and providing clear scientific formats through coordinated approaches. To address these challenges, we present Reasoning With a Star, a newly contributed heliophysics dataset applicable to reasoning; we also provide an initial benchmarking approach. Our data are constructed from National Aeronautics and Space Administration & University Corporation for Atmospheric Research Living With a Star summer school problem sets and compiled into a readily consumable question-and-answer structure with question contexts, reasoning steps, expected answer type, ground-truth targets, format hints, and metadata. A programmatic grader checks the predictions using unit-aware numerical tolerance, symbolic equivalence, and schema validation. We benchmark a single-shot baseline and four multi-agent patterns, finding that decomposing workflows through systems engineering principles outperforms direct prompting on problems requiring deductive reasoning rather than pure inductive recall.

</details>


### [21] [A Brief History of Digital Twin Technology](https://arxiv.org/abs/2511.20695)
*Yunqi Zhang,Kuangyu Shi,Biao Li*

Main category: cs.AI

TL;DR: 数字孪生技术从NASA航天器模拟发展而来，现已在医疗领域实现转型应用，通过整合影像、生物传感器和计算模型创建患者特异性虚拟副本，支持诊断、治疗规划和药物开发，但仍面临互操作性、数据隐私等挑战。


<details>
  <summary>Details</summary>
Motivation: 推动医疗从被动治疗向预测性、预防性和个性化医学转变，利用数字孪生技术提升医疗诊断和治疗效果。

Method: 整合医学影像、生物传感器和计算模型，创建动态数据驱动的患者特异性虚拟副本，通过实时数据流持续更新并实现双向交互。

Result: 代表性应用包括预测心律失常治疗结果的心脏数字孪生、跟踪肿瘤进展和优化放疗的肿瘤学数字孪生，以及加速药物发现的药理学数字孪生。

Conclusion: 尽管面临挑战，但可解释AI、联邦学习和统一监管框架等新兴解决方案为未来发展提供前景，多器官数字孪生、基因组学整合和伦理治理将是确保技术成功应用的关键。

Abstract: Emerging from NASA's spacecraft simulations in the 1960s, digital twin technology has advanced through industrial adoption to spark a healthcare transformation. A digital twin is a dynamic, data-driven virtual counterpart of a physical system, continuously updated through real-time data streams and capable of bidirectional interaction. In medicine, digital twin integrates imaging, biosensors, and computational models to generate patient-specific simulations that support diagnosis, treatment planning, and drug development. Representative applications include cardiac digital twin for predicting arrhythmia treatment outcomes, oncology digital twin for tracking tumor progression and optimizing radiotherapy, and pharmacological digital twin for accelerating drug discovery. Despite rapid progress, major challenges, including interoperability, data privacy, and model fidelity, continue to limit widespread clinical integration. Emerging solutions such as explainable AI, federated learning, and harmonized regulatory frameworks offer promising pathways forward. Looking ahead, advances in multi-organ digital twin, genomics integration, and ethical governance will be essential to ensure that digital twin shifts healthcare from reactive treatment to predictive, preventive, and truly personalized medicine.

</details>


### [22] [Cross Domain Evaluation of Multimodal Chain-of-Thought Reasoning of different datasets into the Amazon CoT Framework](https://arxiv.org/abs/2511.20701)
*Nitya Tiwari,Parv Maheshwari,Vidisha Agarwal*

Main category: cs.AI

TL;DR: 本文对多模态思维链推理进行了综合分析，评估其在A-OKVQA、OKVQA和ChartQA数据集上的有效性，发现虽然视觉集成能减少推理幻觉，但思维链推理效果在不同问题类型间差异显著。


<details>
  <summary>Details</summary>
Motivation: 探索多模态思维链推理在不同领域的泛化能力，特别是在需要广泛常识和世界知识的任务中，而不仅仅是科学推理。

Method: 采用Zhang等人提出的两阶段框架，将推理生成与答案推断分离，通过门控融合机制集成视觉特征与基于T5的语言模型，并进行系统消融研究。

Result: 视觉集成显著减少了推理生成中的幻觉，但思维链推理的有效性在不同问题类型间差异很大，常识推理尤其具有挑战性。

Conclusion: 为研究人员实现多模态推理系统提供了实用见解，并确定了跨领域泛化改进的关键方向。

Abstract: While recent work has extended CoT to multimodal settings, achieving state-of-the-art results on science question answering benchmarks like ScienceQA, the generalizability of these approaches across diverse domains remains underexplored. This work presents a comprehensive analysis of Multimodal Chain-of-Thought (Multimodal-CoT) reasoning, evaluating its effectiveness on the A-OKVQA, OKVQA and ChartQA datasets, which requires broad commonsense and world knowledge beyond scientific reasoning. We implement the two-stage framework proposed by Zhang et al. [3], which separates rationale generation from answer inference and integrates vision features through a gated fusion mechanism with T5-based language models. Through systematic ablation studies, we analyze the contributions of vision features, rationale quality, and architectural choices. Our findings reveal that while vision integration significantly reduces hallucination in rationale generation, the effectiveness of CoT reasoning varies substantially across question types, with commonsense reasoning presenting particular challenges. This work provides practical insights for researchers implementing multimodal reasoning systems and identifies key areas for future improvement in cross-domain generalization.

</details>


### [23] [Representation Interventions Enable Lifelong Unstructured Knowledge Control](https://arxiv.org/abs/2511.20892)
*Xuyuan Liu,Zhengzhang Chen,Xinshuai Dong,Yanchi Liu,Xujiang Zhao,Shengyu Chen,Haoyu Wang,Yujun Yan,Haifeng Chen*

Main category: cs.AI

TL;DR: RILKE是一种在表示空间进行干预的知识控制方法，能够在不重新训练的情况下高效更新LLM的知识，支持大规模终身知识编辑，同时保持模型通用能力。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型知识过时或错误的问题，避免昂贵的重新训练，特别是在终身学习场景下处理复杂非结构化知识的多重编辑需求。

Method: 在模型表示空间进行干预，学习抗释义和编辑局部化的模块，将每个更新限制在低维子空间以减少干扰，推理时通过查询自适应路由器选择合适模块。

Result: 在LLaMA和Qwen模型的知识编辑基准测试中，RILKE具有高编辑成功率、强释义泛化能力，能保持通用效用且内存开销适中。

Conclusion: RILKE是LLM终身知识控制的有效且可扩展解决方案，能够在表示空间实现细粒度知识控制。

Abstract: Large language models (LLMs) often produce incorrect or outdated content. Updating their knowledge efficiently and accurately without costly retraining is a major challenge. This problem is especially hard for complex, unstructured knowledge in a lifelong setting, where many edits must coexist without interference. We introduce RILKE (Representation Intervention for Lifelong KnowledgE Control), a robust and scalable method that treats knowledge control as interventions within the model's representation space. Leveraging representation-space expressiveness, we identify two properties enabling RILKE to deliver fine-grained control over complex, unstructured knowledge while maintaining general utility with frozen base weights. During training, RILKE learns paraphrase-robust and edit-localized modules that limit each update to a low-dimensional subspace to minimize cross-edit interference. In inference, a query-adaptive router selects the appropriate module to guide the model's generation. In evaluation on knowledge editing benchmarks with LLaMA and Qwen models, RILKE is scalable to large-scale datasets, demonstrating high edit success, strong paraphrase generalization, and preserving general utility with modest memory overhead. These results show RILKE is an effective and scalable solution for lifelong knowledge control in LLMs.

</details>


### [24] [ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction](https://arxiv.org/abs/2511.20937)
*Qineng Wang,Wenlong Huang,Yu Zhou,Hang Yin,Tianwei Bao,Jianwen Lyu,Weiyu Liu,Ruohan Zhang,Jiajun Wu,Li Fei-Fei,Manling Li*

Main category: cs.AI

TL;DR: ENACT是一个评估具身认知的基准测试，通过视觉问答形式评估模型从第一人称交互中建模世界的能力，包含前向世界建模和逆向世界建模两个任务。


<details>
  <summary>Details</summary>
Motivation: 探索现代视觉语言模型是否表现出具身认知的迹象，即智能是否源于传感器运动交互而非被动观察。

Method: 将具身认知评估构建为部分可观察马尔可夫决策过程，使用从机器人仿真中合成的问答对，包含前向世界建模（给定动作重排观察序列）和逆向世界建模（给定观察重排动作序列）两个任务。

Result: 实验发现前沿视觉语言模型与人类之间存在性能差距，且随着交互时间跨度增加而扩大；模型在逆向任务上表现更好，并表现出人类中心偏见，如偏好右手动作、当相机参数或视角偏离人类视觉时性能下降。

Conclusion: 现代视觉语言模型在具身认知方面仍存在局限性，需要进一步发展以更好地模拟人类与世界交互的能力。

Abstract: Embodied cognition argues that intelligence arises from sensorimotor interaction rather than passive observation. It raises an intriguing question: do modern vision-language models (VLMs), trained largely in a disembodied manner, exhibit signs of embodied cognition? We introduce ENACT, a benchmark that casts evaluation of embodied cognition as world modeling from egocentric interaction in a visual question answering (VQA) format. Framed as a partially observable Markov decision process (POMDP) whose actions are scene graph changes, ENACT comprises two complementary sequence reordering tasks: forward world modeling (reorder shuffled observations given actions) and inverse world modeling (reorder shuffled actions given observations). While conceptually simple, solving these tasks implicitly demands capabilities central to embodied cognition-affordance recognition, action-effect reasoning, embodied awareness, and interactive, long-horizon memory from partially observable egocentric input, while avoiding low-level image synthesis that could confound the evaluation. We provide a scalable pipeline that synthesizes QA pairs from robotics simulation (BEHAVIOR) and evaluates models on 8,972 QA pairs spanning long-horizon home-scale activities. Experiments reveal a performance gap between frontier VLMs and humans that widens with interaction horizon. Models consistently perform better on the inverse task than the forward one and exhibit anthropocentric biases, including a preference for right-handed actions and degradation when camera intrinsics or viewpoints deviate from human vision. Website at https://enact-embodied-cognition.github.io/.

</details>


### [25] [Improving Procedural Skill Explanations via Constrained Generation: A Symbolic-LLM Hybrid Architecture](https://arxiv.org/abs/2511.20942)
*Rahul Dass,Thomas Bowlin,Zebing Li,Xiao Jin,Ashok Goel*

Main category: cs.AI

TL;DR: Ivy是一个AI教练系统，通过结合符号化的任务-方法-知识模型和生成解释层，提供结构化的多步骤解释，以改进程序技能学习中的教学解释质量。


<details>
  <summary>Details</summary>
Motivation: 在程序技能学习中，教学解释需要传达步骤背后的因果、目标导向和组合逻辑，而大型语言模型通常产生流畅但浅层的响应，缺乏这种结构。

Method: Ivy将符号化的任务-方法-知识模型与生成解释层相结合，TMK模型编码因果转换、目标层次和问题分解，并在明确的结构边界内指导LLM构建解释。

Result: 与GPT和检索增强GPT基线相比，Ivy在三个推理维度上通过专家和独立注释评估，结果显示符号约束持续提高了对"如何"和"为什么"问题解释的结构质量。

Conclusion: 这项研究展示了一种可扩展的AI教育方法，通过符号约束增强了AI生成解释在教学教练系统中的教育价值。

Abstract: In procedural skill learning, instructional explanations must convey not just steps, but the causal, goal-directed, and compositional logic behind them. Large language models (LLMs) often produce fluent yet shallow responses that miss this structure. We present Ivy, an AI coaching system that delivers structured, multi-step explanations by combining symbolic Task-Method-Knowledge (TMK) models with a generative interpretation layer-an LLM that constructs explanations while being constrained by TMK structure. TMK encodes causal transitions, goal hierarchies, and problem decompositions, and guides the LLM within explicit structural bounds. We evaluate Ivy against responses against GPT and retrieval-augmented GPT baselines using expert and independent annotations across three inferential dimensions. Results show that symbolic constraints consistently improve the structural quality of explanations for "how" and "why" questions. This study demonstrates a scalable AI for education approach that strengthens the pedagogical value of AI-generated explanations in intelligent coaching systems.

</details>


### [26] [ICPO: Intrinsic Confidence-Driven Group Relative Preference Optimization for Efficient Reinforcement Learning](https://arxiv.org/abs/2511.21005)
*Jinpeng Wang,Chao Li,Ting Ye,Mengyuan Zhang,Wei Liu,Jian Luan*

Main category: cs.AI

TL;DR: 本文提出ICPO方法，通过利用LLM生成不同响应的概率来反映其推理过程的自评估，结合偏好优势分数和可验证奖励来改进强化学习训练。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法存在粗粒度奖励、奖励噪声和低效探索等问题，导致训练不稳定和熵崩溃，需要更有效的优化方法。

Method: 提出ICPO方法，通过比较同一输入提示下多个响应的相对生成概率计算偏好优势分数，并将其与可验证奖励结合来指导探索过程。

Result: 在四个通用领域基准和三个数学基准上的综合实验表明，ICPO相比GRPO能稳定提升推理能力。

Conclusion: ICPO方法能有效缓解粗粒度奖励和奖励噪声问题，抑制过度自信错误，增强被低估高质量响应的相对优势，防止模型对特定策略过拟合，促进更彻底的探索。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) demonstrates significant potential in enhancing the reasoning capabilities of Large Language Models (LLMs). However, existing RLVR methods are often constrained by issues such as coarse-grained rewards, reward noise, and inefficient exploration, which lead to unstable training and entropy collapse. To address this challenge, we propose the Intrinsic Confidence-Driven Group Relative Preference Optimization method (ICPO). The intuition behind it lies in the fact that the probabilities of an LLM generating different responses can inherently and directly reflect its self-assessment of the reasoning process. Inspired by the idea of preference modeling, ICPO calculates a preference advantage score for each response by comparing the relative generation probabilities of multiple responses under the same input prompt, and integrates this score with verifiable rewards to guide the exploration process. We have discovered that the preference advantage score not only alleviates the issues of coarse-grained rewards and reward noise but also effectively curbs overconfident errors, enhances the relative superiority of undervalued high-quality responses, and prevents the model from overfitting to specific strategies, thereby facilitating more thorough exploration. Comprehensive experiments across four general-domain benchmarks and three mathematical benchmarks demonstrate that ICPO steadily boosts reasoning compared to GRPO.

</details>


### [27] [Causality Without Causal Models](https://arxiv.org/abs/2511.21260)
*Joseph Y. Halpern,Rafael Pass*

Main category: cs.AI

TL;DR: 本文抽象了Halpern和Pearl的因果定义，提取其关键特征，使其能够应用于任何定义反事实的模型，从而扩展了因果关系的应用范围和处理能力。


<details>
  <summary>Details</summary>
Motivation: Halpern和Pearl的因果定义局限于因果模型，无法处理涉及析取、否定、信念和嵌套反事实的复杂情况，需要更通用的定义框架。

Method: 通过抽象化Halpern-Pearl定义的关键特征，构建一个适用于任何反事实定义模型的通用因果定义框架。

Result: 新定义不仅能在更广泛的模型中使用（包括允许回溯的模型），还能处理复杂逻辑公式的因果关系，并扩展到解释的定义。

Conclusion: 抽象化方法扩展了因果定义的应用范围，提供了对因果模型更深层次的理解，并为解释概念提供了通用定义框架。

Abstract: Perhaps the most prominent current definition of (actual) causality is due to Halpern and Pearl.  It is defined using causal models (also known as structural equations models).  We abstract the definition, extracting its key features, so that it can be applied to any other model where counterfactuals are defined. By abstracting the definition, we gain a number of benefits. Not only can we apply the definition in a wider range of models, including ones that allow, for example, backtracking, but we can apply the definition to determine if A is a cause of B  even if A and B are formulas involving disjunctions, negations, beliefs, and nested counterfactuals (none of which can be handled by the Halpern-Pearl definition). Moreover, we can extend the ideas to getting an abstract definition of explanation that can be applied beyond causal models. Finally, we gain a deeper understanding of features of the definition  even in causal models.

</details>


### [28] [New Hybrid Heuristics for Pseudo-Boolean Propagation](https://arxiv.org/abs/2511.21417)
*Mia Müßig,Jan Johannsen*

Main category: cs.AI

TL;DR: 本文介绍了伪布尔求解中混合单元传播策略的新启发式方法，能够显著超越当前RoundingSAT求解器中的方法。


<details>
  <summary>Details</summary>
Motivation: 当前伪布尔求解中最成功的单元传播策略是观察字面量方案与计数方法的混合模式，但需要改进其决策启发式以提高性能。

Method: 提出了新的启发式方法用于混合决策，结合观察字面量方案和计数方法。

Result: 新启发式方法能够显著超越当前RoundingSAT求解器中的方法。

Conclusion: 新提出的混合决策启发式方法在伪布尔求解中具有显著性能优势。

Abstract: In pseudo-boolean solving the currently most successful unit propagation strategy is a hybrid mode combining the watched literal scheme with the counting method. This short paper introduces new heuristics for this hybrid decision, which are able to drastically outperform the current method in the RoundingSAT solver.

</details>


### [29] [SpatialBench: Benchmarking Multimodal Large Language Models for Spatial Cognition](https://arxiv.org/abs/2511.21471)
*Peiran Xu,Sudong Wang,Yao Zhu,Jianing Li,Yunjian Zhang*

Main category: cs.AI

TL;DR: 提出了一个分层空间认知框架，将空间智能分解为从基础观察到高级规划的五个渐进复杂层次，并构建了SpatialBench基准来系统评估多模态大语言模型的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准往往过度简化空间认知，将其简化为单一维度指标，无法捕捉空间能力的层次结构和相互依赖性。

Method: 构建分层空间认知框架，将空间智能分解为五个认知层次，并开发SpatialBench基准，包含15个任务，同时引入能力导向的统一评估指标。

Result: 实验发现模型在不同认知层次上表现分层：感知基础能力强，但在符号推理、因果推断和规划方面仍有局限；人类测试显示人类进行选择性、目标导向的抽象，而MLLMs倾向于过度关注表面细节。

Conclusion: 建立了首个系统测量MLLMs分层空间认知的框架，为未来空间智能系统奠定了基础。

Abstract: Spatial cognition is fundamental to real-world multimodal intelligence, allowing models to effectively interact with the physical environment. While multimodal large language models (MLLMs) have made significant strides, existing benchmarks often oversimplify spatial cognition, reducing it to a single-dimensional metric, which fails to capture the hierarchical structure and interdependence of spatial abilities. To address this gap, we propose a hierarchical spatial cognition framework that decomposes spatial intelligence into five progressively complex levels from basic observation to high-level planning. Building upon this taxonomy, we construct SpatialBench, a large-scale, fine-grained benchmark covering 15 tasks aligned with these cognitive levels. To provide a unified evaluation across heterogeneous tasks, we further introduce a high-level capability-oriented metric that reliably assesses a model's overall spatial reasoning ability. Extensive experiments over massive MLLMs reveal distinct performance stratification across cognitive levels: models exhibit strong perceptual grounding yet remain limited in symbolic reasoning, causal inference, and planning. Additional human tests demonstrate that humans perform selective, goal-directed abstraction, while MLLMs tend to over-attend to surface details without coherent spatial intent. Our work establishes the first systematic framework for measuring hierarchical spatial cognition in MLLMs, laying the foundation for future spatially intelligent systems.

</details>


### [30] [Pessimistic Verification for Open Ended Math Questions](https://arxiv.org/abs/2511.21522)
*Yanxing Huang,Zihan Tang,Zejin Lin,Peng Li,Yang Liu*

Main category: cs.AI

TL;DR: 提出悲观验证方法，通过并行构建多个验证流程来检测数学证明中的错误，显著提升验证性能且计算资源消耗低。


<details>
  <summary>Details</summary>
Motivation: 现有验证性能受限于错误检测能力，需要更有效的验证方法来提高数学问题的可靠性。

Method: 设计悲观验证变体，为同一证明构建多个并行验证流程，只要任一验证报告错误即判定证明不正确。

Result: 该方法在多个数学验证基准上显著提升性能，令牌效率超过扩展长链思维，且发现多数假阴性源于数据集标注错误。

Conclusion: 悲观验证能有效提升语言模型数学输出的可靠性，对实现长视野数学任务至关重要，有助于增强语言模型的数学能力。

Abstract: The key limitation of the verification performance lies in the ability of error detection. With this intuition we designed several variants of pessimistic verification, which are simple workflows that could significantly improve the verification of open-ended math questions. In pessimistic verification we construct multiple parallel verifications for the same proof, and the proof is deemed incorrect if any one of them reports an error. This simple technique significantly improves the performance across many math verification benchmarks without incurring substantial computational resources. Its token efficiency even surpassed extended long-CoT in test-time scaling. Our case studies further indicate that the majority of false negatives in stronger models are actually caused by annotation errors in the original dataset, so our method's performance is in fact underestimated. Self-verification for mathematical problems can effectively improve the reliability and performance of language model outputs, and it also plays a critical role in enabling long-horizon mathematical tasks. We believe that research on pessimistic verification will help enhance the mathematical capabilities of language models across a wide range of tasks.

</details>


### [31] [Self-Transparency Failures in Expert-Persona LLMs: A Large-Scale Behavioral Audit](https://arxiv.org/abs/2511.21569)
*Alex Diep*

Main category: cs.AI

TL;DR: 该研究审计了16个开源模型在专业角色下的AI身份披露行为，发现模型在不同领域存在显著的透明度不一致，某些模型在推理优化后反而降低了自我透明度。


<details>
  <summary>Details</summary>
Motivation: 研究动机是确保语言模型在专业高风险领域中能够可靠披露其AI身份，防止用户因错误信任模型能力边界而受到伤害。

Method: 采用共同花园设计，对16个参数量从4B到671B的开源模型进行了19,200次试验，使用贝叶斯验证和Rogan-Gladen修正来确保测量误差的鲁棒性。

Result: 模型在不同专业角色下表现出显著的透明度差异：金融顾问角色初始披露率为30.8%，而神经外科医生角色仅为3.5%。模型身份比参数数量更能预测行为，推理优化在某些模型中主动抑制了自我透明度。

Conclusion: 透明度反映的是训练因素而非模型规模，组织不能假设安全属性会转移到部署环境中，需要刻意设计行为和进行经验验证。

Abstract: If a language model cannot reliably disclose its AI identity in expert contexts, users cannot trust its competence boundaries. This study examines self-transparency in models assigned professional personas within high-stakes domains where false expertise risks user harm. Using a common-garden design, sixteen open-weight models (4B--671B parameters) were audited across 19,200 trials. Models exhibited sharp domain-specific inconsistency: a Financial Advisor persona elicited 30.8% disclosure initially, while a Neurosurgeon persona elicited only 3.5%. This creates preconditions for a "Reverse Gell-Mann Amnesia" effect, where transparency in some domains leads users to overgeneralize trust to contexts where disclosure fails. Disclosure ranged from 2.8% to 73.6%, with a 14B model reaching 61.4% while a 70B produced just 4.1%. Model identity predicted behavior better than parameter count ($ΔR_{adj}^{2} = 0.359$ vs 0.018). Reasoning optimization actively suppressed self-transparency in some models, with reasoning variants showing up to 48.4% lower disclosure than base counterparts. Bayesian validation with Rogan--Gladen correction confirmed robustness to measurement error ($κ= 0.908$). These findings demonstrate transparency reflects training factors rather than scale. Organizations cannot assume safety properties transfer to deployment contexts, requiring deliberate behavior design and empirical verification.

</details>


### [32] [From Prediction to Foresight: The Role of AI in Designing Responsible Futures](https://arxiv.org/abs/2511.21570)
*Maria Perez-Ortiz*

Main category: cs.AI

TL;DR: 本文提出"负责任计算前瞻"概念，探讨人本人工智能和计算模型在负责任前瞻中的作用，建立该新领域的基本原则，并介绍正在塑造该领域的AI驱动前瞻工具。


<details>
  <summary>Details</summary>
Motivation: 在技术快速发展和全球挑战日益复杂的时代，负责任前瞻已成为政策制定者应对未来不确定性和塑造未来的重要框架。需要将AI作为支持工具融入前瞻实践，以应对21世纪的重大挑战。

Method: 建立负责任计算前瞻的基本原则，开发AI驱动的前瞻工具，结合模拟和情景分析来增强政策制定者应对不确定性的能力。

Result: AI与模拟和情景分析结合，能够增强政策制定者应对不确定性、评估风险和制定可持续、有韧性未来战略的能力。

Conclusion: AI将在负责任、以人为本的前瞻中扮演支持性工具的角色，补充而非替代政策制定者的判断，实现主动塑造有韧性和道德健全的未来。需要将AI深思熟虑地融入前瞻实践中。

Abstract: In an era marked by rapid technological advancements and complex global challenges, responsible foresight has emerged as an essential framework for policymakers aiming to navigate future uncertainties and shape the future. Responsible foresight entails the ethical anticipation of emerging opportunities and risks, with a focus on fostering proactive, sustainable, and accountable future design. This paper coins the term "responsible computational foresight", examining the role of human-centric artificial intelligence and computational modeling in advancing responsible foresight, establishing a set of foundational principles for this new field and presenting a suite of AI-driven foresight tools currently shaping it. AI, particularly in conjunction with simulations and scenario analysis, enhances policymakers' ability to address uncertainty, evaluate risks, and devise strategies geared toward sustainable, resilient futures. However, responsible foresight extends beyond mere technical forecasting; it demands a nuanced understanding of the interdependencies within social, environmental, economic and political systems, alongside a commitment to ethical, long-term decision-making that supports human intelligence. We argue that AI will play a role as a supportive tool in responsible, human-centered foresight, complementing rather than substituting policymaker judgment to enable the proactive shaping of resilient and ethically sound futures. This paper advocates for the thoughtful integration of AI into foresight practices to empower policymakers and communities as they confront the grand challenges of the 21st century.

</details>

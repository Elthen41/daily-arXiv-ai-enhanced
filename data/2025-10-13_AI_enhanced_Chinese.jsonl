{"id": "2510.08940", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.08940", "abs": "https://arxiv.org/abs/2510.08940", "authors": ["Abel Beyene", "Zhongpan Wu", "Yunus Dawji", "Karim Hammad", "Ebrahim Ghafar-Zadeh", "Sebastian Magierowski"], "title": "A High-Efficiency SoC for Next-Generation Mobile DNA Sequencing", "comment": null, "summary": "Hand-sized Deoxyribonucleic acid (DNA) sequencing machines are of growing\nimportance in several life sciences fields as their small footprints enable a\nbroader range of use cases than their larger, stationary counterparts. However,\nas currently designed, they lack sufficient embedded computing to process the\nlarge volume of measurements generated by their internal sensory system. As a\nconsequence, they rely on external devices for additional processing\ncapability. This dependence on external processing places a significant\ncommunication burden on the sequencer's embedded electronics. Moreover, it also\nprevents a truly mobile solution for sequencing in real-time. Anticipating\nnext-generation machines that include suitably advanced processing, we present\na System-on-Chip (SoC) fabricated in 22-nm complementary metal-oxide\nsemiconductor (CMOS). Our design, based on a general-purpose reduced\ninstruction set computing (RISC-V) core, also includes accelerators for DNA\ndetection that allow our system to demonstrate a 13X performance improvement\nover commercial embedded multicore processors combined with a near 3000X boost\nin energy efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eRISC-V\u6838\u5fc3\u768422nm CMOS SoC\u8bbe\u8ba1\uff0c\u7528\u4e8e\u624b\u6301DNA\u6d4b\u5e8f\u673a\uff0c\u901a\u8fc7\u4e13\u7528\u52a0\u901f\u5668\u5b9e\u73b0\u4e8613\u500d\u6027\u80fd\u63d0\u5347\u548c\u8fd13000\u500d\u80fd\u6548\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u624b\u6301DNA\u6d4b\u5e8f\u673a\u7f3a\u4e4f\u8db3\u591f\u7684\u5d4c\u5165\u5f0f\u8ba1\u7b97\u80fd\u529b\u5904\u7406\u5927\u91cf\u6d4b\u91cf\u6570\u636e\uff0c\u4f9d\u8d56\u5916\u90e8\u8bbe\u5907\u5904\u7406\u5bfc\u81f4\u901a\u4fe1\u8d1f\u62c5\u91cd\u4e14\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u79fb\u52a8\u5b9e\u65f6\u6d4b\u5e8f\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u901a\u7528RISC-V\u6838\u5fc3\u7684SoC\uff0c\u96c6\u6210\u4e86DNA\u68c0\u6d4b\u4e13\u7528\u52a0\u901f\u5668\uff0c\u91c7\u752822nm CMOS\u5de5\u827a\u5236\u9020\u3002", "result": "\u76f8\u6bd4\u5546\u7528\u5d4c\u5165\u5f0f\u591a\u6838\u5904\u7406\u5668\uff0c\u7cfb\u7edf\u6027\u80fd\u63d0\u534713\u500d\uff0c\u80fd\u6548\u63d0\u5347\u8fd13000\u500d\u3002", "conclusion": "\u8be5SoC\u8bbe\u8ba1\u4e3a\u4e0b\u4e00\u4ee3\u624b\u6301DNA\u6d4b\u5e8f\u673a\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u3001\u9ad8\u80fd\u6548\u7684\u5d4c\u5165\u5f0f\u5904\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u771f\u6b63\u7684\u79fb\u52a8\u5b9e\u65f6\u6d4b\u5e8f\u3002"}}
{"id": "2510.09010", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.09010", "abs": "https://arxiv.org/abs/2510.09010", "authors": ["Yipu Zhang", "Chaofang Ma", "Jinming Ge", "Lin Jiang", "Jiang Xu", "Wei Zhang"], "title": "HERO: Hardware-Efficient RL-based Optimization Framework for NeRF Quantization", "comment": "Accepted by ASPDAC 2026", "summary": "Neural Radiance Field (NeRF) has emerged as a promising 3D reconstruction\nmethod, delivering high-quality results for AR/VR applications. While\nquantization methods and hardware accelerators have been proposed to enhance\nNeRF's computational efficiency, existing approaches face crucial limitations.\nCurrent quantization methods operate without considering hardware architecture,\nresulting in sub-optimal solutions within the vast design space encompassing\naccuracy, latency, and model size. Additionally, existing NeRF accelerators\nheavily rely on human experts to explore this design space, making the\noptimization process time-consuming, inefficient, and unlikely to discover\noptimal solutions. To address these challenges, we introduce HERO, a\nreinforcement learning framework performing hardware-aware quantization for\nNeRF. Our framework integrates a NeRF accelerator simulator to generate\nreal-time hardware feedback, enabling fully automated adaptation to hardware\nconstraints. Experimental results demonstrate that HERO achieves 1.31-1.33\n$\\times$ better latency, 1.29-1.33 $\\times$ improved cost efficiency, and a\nmore compact model size compared to CAQ, a previous state-of-the-art NeRF\nquantization framework. These results validate our framework's capability to\neffectively navigate the complex design space between hardware and algorithm\nrequirements, discovering superior quantization policies for NeRF\nimplementation. Code is available at https://github.com/ypzhng/HERO.", "AI": {"tldr": "HERO\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u786c\u4ef6\u611f\u77e5\u91cf\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316NeRF\u76843D\u91cd\u5efa\u6027\u80fd\uff0c\u901a\u8fc7\u96c6\u6210NeRF\u52a0\u901f\u5668\u6a21\u62df\u5668\u5b9e\u73b0\u81ea\u52a8\u5316\u786c\u4ef6\u7ea6\u675f\u9002\u5e94\u3002", "motivation": "\u73b0\u6709NeRF\u91cf\u5316\u65b9\u6cd5\u672a\u8003\u8651\u786c\u4ef6\u67b6\u6784\uff0c\u5bfc\u81f4\u5728\u7cbe\u5ea6\u3001\u5ef6\u8fdf\u548c\u6a21\u578b\u5927\u5c0f\u7684\u8bbe\u8ba1\u7a7a\u95f4\u4e2d\u96be\u4ee5\u627e\u5230\u6700\u4f18\u89e3\uff1b\u73b0\u6709\u52a0\u901f\u5668\u4f9d\u8d56\u4eba\u5de5\u4e13\u5bb6\u63a2\u7d22\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u6548\u7387\u4f4e\u4e0b\u4e14\u96be\u4ee5\u53d1\u73b0\u6700\u4f18\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u96c6\u6210NeRF\u52a0\u901f\u5668\u6a21\u62df\u5668\u751f\u6210\u5b9e\u65f6\u786c\u4ef6\u53cd\u9988\uff0c\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u786c\u4ef6\u7ea6\u675f\u9002\u5e94\u3002", "result": "\u76f8\u6bd4\u4e4b\u524d\u6700\u5148\u8fdb\u7684NeRF\u91cf\u5316\u6846\u67b6CAQ\uff0cHERO\u5b9e\u73b0\u4e861.31-1.33\u500d\u7684\u5ef6\u8fdf\u6539\u5584\u30011.29-1.33\u500d\u7684\u6210\u672c\u6548\u7387\u63d0\u5347\uff0c\u4ee5\u53ca\u66f4\u7d27\u51d1\u7684\u6a21\u578b\u5927\u5c0f\u3002", "conclusion": "HERO\u80fd\u591f\u6709\u6548\u5bfc\u822a\u786c\u4ef6\u4e0e\u7b97\u6cd5\u9700\u6c42\u4e4b\u95f4\u7684\u590d\u6742\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u4e3aNeRF\u5b9e\u73b0\u53d1\u73b0\u66f4\u4f18\u7684\u91cf\u5316\u7b56\u7565\u3002"}}
{"id": "2510.09339", "categories": ["cs.AR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2510.09339", "abs": "https://arxiv.org/abs/2510.09339", "authors": ["Sebastian Magierowski", "Zhongpan Wu", "Abel Beyene", "Karim Hammad"], "title": "Sequencing on Silicon: AI SoC Design for Mobile Genomics at the Edge", "comment": null, "summary": "Miniature DNA sequencing hardware has begun to succeed in mobile contexts,\ndriving demand for efficient machine learning at the edge. This domain\nleverages deep learning techniques familiar from speech and time-series\nanalysis for both low-level signal processing and high-level genomic\ninterpretation. Unlike audio, however, nanopore sequencing presents raw data\nrates over 100X higher, requiring more aggressive compute and memory handling.\nIn this paper, we present a CMOS system-on-chip (SoC) designed for mobile\ngenetic analysis. Our approach combines a multi-core RISC-V processor with\ntightly coupled accelerators for deep learning and bioinformatics. A\nhardware/software co-design strategy enables energy-efficient operation across\na heterogeneous compute fabric, targeting real-time, on-device genome analysis.\nThis work exemplifies the integration of deep learning, edge computing, and\ndomain-specific hardware to advance next-generation mobile genomics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u79fb\u52a8\u57fa\u56e0\u5206\u6790\u7684CMOS\u7247\u4e0a\u7cfb\u7edf\uff0c\u7ed3\u5408\u591a\u6838RISC-V\u5904\u7406\u5668\u4e0e\u6df1\u5ea6\u5b66\u4e60\u52a0\u901f\u5668\uff0c\u5b9e\u73b0\u5b9e\u65f6\u8bbe\u5907\u7aef\u57fa\u56e0\u7ec4\u5206\u6790\u3002", "motivation": "\u968f\u7740\u5fae\u578bDNA\u6d4b\u5e8f\u786c\u4ef6\u5728\u79fb\u52a8\u73af\u5883\u4e2d\u7684\u6210\u529f\u5e94\u7528\uff0c\u5bf9\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u9ad8\u6548\u673a\u5668\u5b66\u4e60\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\u3002\u7eb3\u7c73\u5b54\u6d4b\u5e8f\u4ea7\u751f\u6bd4\u97f3\u9891\u9ad8100\u500d\u4ee5\u4e0a\u7684\u539f\u59cb\u6570\u636e\u901f\u7387\uff0c\u9700\u8981\u66f4\u6fc0\u8fdb\u7684\u7b97\u529b\u548c\u5185\u5b58\u5904\u7406\u80fd\u529b\u3002", "method": "\u91c7\u7528\u786c\u4ef6/\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u7b56\u7565\uff0c\u5c06\u591a\u6838RISC-V\u5904\u7406\u5668\u4e0e\u7d27\u5bc6\u8026\u5408\u7684\u6df1\u5ea6\u5b66\u4e60\u548c\u751f\u7269\u4fe1\u606f\u5b66\u52a0\u901f\u5668\u96c6\u6210\u5728CMOS SoC\u4e2d\uff0c\u901a\u8fc7\u5f02\u6784\u8ba1\u7b97\u67b6\u6784\u5b9e\u73b0\u80fd\u6548\u4f18\u5316\u3002", "result": "\u5f00\u53d1\u51fa\u4e13\u4e3a\u79fb\u52a8\u57fa\u56e0\u5206\u6790\u8bbe\u8ba1\u7684SoC\u7cfb\u7edf\uff0c\u80fd\u591f\u5728\u8bbe\u5907\u7aef\u5b9e\u73b0\u5b9e\u65f6\u57fa\u56e0\u7ec4\u5206\u6790\uff0c\u6ee1\u8db3\u7eb3\u7c73\u5b54\u6d4b\u5e8f\u7684\u9ad8\u6570\u636e\u901f\u7387\u9700\u6c42\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u6df1\u5ea6\u5b66\u4e60\u3001\u8fb9\u7f18\u8ba1\u7b97\u548c\u9886\u57df\u4e13\u7528\u786c\u4ef6\u7684\u96c6\u6210\uff0c\u63a8\u52a8\u4e86\u4e0b\u4e00\u4ee3\u79fb\u52a8\u57fa\u56e0\u7ec4\u5b66\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.08842", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.08842", "abs": "https://arxiv.org/abs/2510.08842", "authors": ["Molang Wu", "Zhao Zhang"], "title": "Maple: A Multi-agent System for Portable Deep Learning across Clusters", "comment": null, "summary": "Training deep learning (DL) models across Graphics Processing Unit (GPU)\nclusters is technically challenging. One aspect is that users have to compose\ncommand lines to adapt to the heterogeneous launchers, schedulers, affinity\noptions, DL framework arguments, and environment variables. Composing correct\ncommand lines is error-prone and can easily frustrate users, impeding research\nor wasting resources. In this work, we present Maple, a multi-agent system that\ngenerates correct DL command lines with users' natural language input. Maple\nconsists of four agents with the functionalities of information extraction,\ntemplate retrieval, command line verification, and error correction. We\nevaluate Maple on nine GPU clusters across national computing centers in the\nU.S., five representative deep learning model families, and four commonly used\nparallel DL training paradigms. Our experiments also cover schedulers of SLURM\nand PBS and heterogeneous architectures, such as NVIDIA A100/H200 GPUs and\nIntel Max series GPUs. Maple achieves 92.0% accuracy in generating command\nlines across the 567 test cases. Leverage multiple language models with an\naggregated size of 10B parameters, Maple delivers comparable performance to the\nstate-of-the-art models of GPT-5, Claude, and Gemini. Together, these results\nhighlight Maple's practical value in enabling portable and scalable distributed\nDL across heterogeneous HPC environments.", "AI": {"tldr": "Maple\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u751f\u6210\u6b63\u786e\u7684\u6df1\u5ea6\u5b66\u4e60\u547d\u4ee4\uff0c\u89e3\u51b3\u4e86\u5728\u5f02\u6784GPU\u96c6\u7fa4\u4e0a\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u65f6\u547d\u4ee4\u884c\u914d\u7f6e\u7684\u590d\u6742\u6027\u3002", "motivation": "\u5728GPU\u96c6\u7fa4\u4e0a\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u9762\u4e34\u6280\u672f\u6311\u6218\uff0c\u7528\u6237\u9700\u8981\u9002\u5e94\u5f02\u6784\u542f\u52a8\u5668\u3001\u8c03\u5ea6\u5668\u3001\u4eb2\u548c\u6027\u9009\u9879\u3001\u6846\u67b6\u53c2\u6570\u548c\u73af\u5883\u53d8\u91cf\u7b49\uff0c\u624b\u52a8\u7f16\u5199\u547d\u4ee4\u884c\u5bb9\u6613\u51fa\u9519\u4e14\u8017\u65f6\uff0c\u963b\u788d\u7814\u7a76\u8fdb\u5c55\u548c\u6d6a\u8d39\u8d44\u6e90\u3002", "method": "Maple\u91c7\u7528\u56db\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5305\u62ec\u4fe1\u606f\u63d0\u53d6\u3001\u6a21\u677f\u68c0\u7d22\u3001\u547d\u4ee4\u884c\u9a8c\u8bc1\u548c\u9519\u8bef\u4fee\u6b63\u529f\u80fd\uff0c\u5229\u7528\u591a\u4e2a\u8bed\u8a00\u6a21\u578b\uff08\u603b\u8ba110B\u53c2\u6570\uff09\u751f\u6210\u6b63\u786e\u7684\u6df1\u5ea6\u5b66\u4e60\u547d\u4ee4\u3002", "result": "\u57289\u4e2a\u7f8e\u56fd\u56fd\u5bb6\u8ba1\u7b97\u4e2d\u5fc3\u7684GPU\u96c6\u7fa4\u30015\u4e2a\u4ee3\u8868\u6027\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5bb6\u65cf\u548c4\u79cd\u5e38\u7528\u5e76\u884c\u8bad\u7ec3\u8303\u5f0f\u7684567\u4e2a\u6d4b\u8bd5\u6848\u4f8b\u4e2d\uff0cMaple\u5b9e\u73b0\u4e8692.0%\u7684\u547d\u4ee4\u884c\u751f\u6210\u51c6\u786e\u7387\uff0c\u6027\u80fd\u4e0eGPT-5\u3001Claude\u548cGemini\u7b49\u6700\u5148\u8fdb\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "Maple\u5728\u5f02\u6784\u9ad8\u6027\u80fd\u8ba1\u7b97\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u53ef\u79fb\u690d\u548c\u53ef\u6269\u5c55\u7684\u5206\u5e03\u5f0f\u6df1\u5ea6\u5b66\u4e60\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.08700", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.08700", "abs": "https://arxiv.org/abs/2510.08700", "authors": ["Zhuolun Li", "Haluk Sonmezler", "Faiza Shirazi", "Febin Shaji", "Tymoteusz Mroczkowski", "Dexter Lardner", "Matthew Alain Camus", "Evangelos Pournaras"], "title": "Are Voters Willing to Collectively Secure Elections? Unraveling a Practical Blockchain Voting System", "comment": null, "summary": "Ensuring ballot secrecy is critical for fair and trustworthy electronic\nvoting systems, yet achieving strong secrecy guarantees in decentralized,\nlarge-scale elections remains challenging. This paper proposes the concept of\ncollectively secure voting, in which voters themselves can opt in as secret\nholders to protect ballot secrecy. A practical blockchain-based collectively\nsecure voting system is designed and implemented. Our design strikes a balance\nbetween strong confidentiality guarantees and real-world applicability. The\nproposed system combines threshold cryptography and smart contracts to ensure\nballots remain confidential during voting, while all protocol steps remain\ntransparent and verifiable. Voters can use the system without prior blockchain\nknowledge through an intuitive user interface that hides underlying complexity.\nTo evaluate this approach, a user testing is conducted. Results show a high\nwillingness to act as secret holders, reliable participation in share release,\nand high security confidence in the proposed system. The findings demonstrate\nthat voters can collectively maintain secrecy and that such a practical\ndeployment is feasible.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u96c6\u4f53\u5b89\u5168\u6295\u7968\u7cfb\u7edf\uff0c\u901a\u8fc7\u8ba9\u9009\u6c11\u81ea\u613f\u6210\u4e3a\u79d8\u5bc6\u6301\u6709\u8005\u6765\u4fdd\u62a4\u9009\u7968\u9690\u79c1\uff0c\u7ed3\u5408\u9608\u503c\u5bc6\u7801\u5b66\u548c\u667a\u80fd\u5408\u7ea6\u5b9e\u73b0\u5f3a\u4fdd\u5bc6\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002", "motivation": "\u89e3\u51b3\u53bb\u4e2d\u5fc3\u5316\u5927\u89c4\u6a21\u9009\u4e3e\u4e2d\u5b9e\u73b0\u5f3a\u9009\u7968\u4fdd\u5bc6\u6027\u7684\u6311\u6218\uff0c\u786e\u4fdd\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u96c6\u4f53\u5b89\u5168\u6295\u7968\u7cfb\u7edf\uff0c\u7ed3\u5408\u9608\u503c\u5bc6\u7801\u5b66\u548c\u667a\u80fd\u5408\u7ea6\uff0c\u63d0\u4f9b\u76f4\u89c2\u7528\u6237\u754c\u9762\u9690\u85cf\u5e95\u5c42\u590d\u6742\u6027\u3002", "result": "\u7528\u6237\u6d4b\u8bd5\u663e\u793a\u9009\u6c11\u9ad8\u5ea6\u613f\u610f\u62c5\u4efb\u79d8\u5bc6\u6301\u6709\u8005\uff0c\u53ef\u9760\u53c2\u4e0e\u4efd\u989d\u91ca\u653e\uff0c\u5e76\u5bf9\u7cfb\u7edf\u5b89\u5168\u6027\u6709\u9ad8\u5ea6\u4fe1\u5fc3\u3002", "conclusion": "\u9009\u6c11\u80fd\u591f\u96c6\u4f53\u7ef4\u62a4\u9009\u7968\u4fdd\u5bc6\u6027\uff0c\u8fd9\u79cd\u5b9e\u9645\u90e8\u7f72\u662f\u53ef\u884c\u7684\uff0c\u5728\u5f3a\u4fdd\u5bc6\u4fdd\u8bc1\u548c\u73b0\u5b9e\u9002\u7528\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861\u3002"}}
{"id": "2510.08874", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08874", "abs": "https://arxiv.org/abs/2510.08874", "authors": ["Benjamin Brock", "Renato Golin"], "title": "Slicing Is All You Need: Towards A Universal One-Sided Algorithm for Distributed Matrix Multiplication", "comment": null, "summary": "Many important applications across science, data analytics, and AI workloads\ndepend on distributed matrix multiplication. Prior work has developed a large\narray of algorithms suitable for different problem sizes and partitionings\nincluding 1D, 2D, 1.5D, and 2.5D algorithms. A limitation of current work is\nthat existing algorithms are limited to a subset of partitionings. Multiple\nalgorithm implementations are required to support the full space of possible\npartitionings. If no algorithm implementation is available for a particular set\nof partitionings, one or more operands must be redistributed, increasing\ncommunication costs. This paper presents a universal one-sided algorithm for\ndistributed matrix multiplication that supports all combinations of\npartitionings and replication factors. Our algorithm uses slicing (index\narithmetic) to compute the sets of overlapping tiles that must be multiplied\ntogether. This list of local matrix multiplies can then either be executed\ndirectly, or reordered and lowered to an optimized IR to maximize overlap. We\nimplement our algorithm using a high-level C++-based PGAS programming framework\nthat performs direct GPU-to-GPU communication using intra-node interconnects.\nWe evaluate performance for a wide variety of partitionings and replication\nfactors, finding that our work is competitive with PyTorch DTensor, a highly\noptimized distributed tensor library targeting AI models.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u7528\u7684\u5355\u8fb9\u5206\u5e03\u5f0f\u77e9\u9635\u4e58\u6cd5\u7b97\u6cd5\uff0c\u652f\u6301\u6240\u6709\u5206\u533a\u548c\u590d\u5236\u56e0\u5b50\u7ec4\u5408\uff0c\u901a\u8fc7\u5207\u7247\u8ba1\u7b97\u91cd\u53e0\u74e6\u7247\u7684\u4e58\u6cd5\u96c6\u5408\uff0c\u6027\u80fd\u4e0ePyTorch DTensor\u76f8\u5f53\u3002", "motivation": "\u73b0\u6709\u5206\u5e03\u5f0f\u77e9\u9635\u4e58\u6cd5\u7b97\u6cd5\u4ec5\u652f\u6301\u90e8\u5206\u5206\u533a\u65b9\u5f0f\uff0c\u9700\u8981\u591a\u4e2a\u7b97\u6cd5\u5b9e\u73b0\u6765\u652f\u6301\u5168\u90e8\u5206\u533a\u7ec4\u5408\uff0c\u5f53\u6ca1\u6709\u5bf9\u5e94\u7b97\u6cd5\u65f6\u9700\u91cd\u65b0\u5206\u5e03\u64cd\u4f5c\u6570\uff0c\u589e\u52a0\u901a\u4fe1\u6210\u672c\u3002", "method": "\u4f7f\u7528\u5207\u7247\uff08\u7d22\u5f15\u7b97\u672f\uff09\u8ba1\u7b97\u9700\u8981\u76f8\u4e58\u7684\u91cd\u53e0\u74e6\u7247\u96c6\u5408\uff0c\u7136\u540e\u76f4\u63a5\u6267\u884c\u6216\u91cd\u65b0\u6392\u5e8f\u5e76\u964d\u4f4e\u5230\u4f18\u5316IR\u4ee5\u6700\u5927\u5316\u91cd\u53e0\u3002\u57fa\u4e8e\u9ad8\u7ea7C++ PGAS\u7f16\u7a0b\u6846\u67b6\u5b9e\u73b0\uff0c\u4f7f\u7528GPU\u5230GPU\u76f4\u63a5\u901a\u4fe1\u3002", "result": "\u5728\u5404\u79cd\u5206\u533a\u548c\u590d\u5236\u56e0\u5b50\u914d\u7f6e\u4e0b\u8bc4\u4f30\u6027\u80fd\uff0c\u53d1\u73b0\u4e0e\u9488\u5bf9AI\u6a21\u578b\u4f18\u5316\u7684PyTorch DTensor\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "\u63d0\u51fa\u7684\u901a\u7528\u5355\u8fb9\u7b97\u6cd5\u80fd\u591f\u652f\u6301\u6240\u6709\u5206\u533a\u548c\u590d\u5236\u56e0\u5b50\u7ec4\u5408\uff0c\u907f\u514d\u4e86\u64cd\u4f5c\u6570\u91cd\u65b0\u5206\u5e03\u7684\u9700\u6c42\uff0c\u5728\u6027\u80fd\u4e0a\u5177\u6709\u7ade\u4e89\u529b\u3002"}}
{"id": "2510.08725", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.08725", "abs": "https://arxiv.org/abs/2510.08725", "authors": ["Gorjan Alagic", "Chen Bai", "Christian Majenz", "Kaiyan Shi"], "title": "Post-Quantum Security of Block Cipher Constructions", "comment": null, "summary": "Block ciphers are versatile cryptographic ingredients that are used in a wide\nrange of applications ranging from secure Internet communications to disk\nencryption. While post-quantum security of public-key cryptography has received\nsignificant attention, the case of symmetric-key cryptography (and block\nciphers in particular) remains a largely unexplored topic. In this work, we set\nthe foundations for a theory of post-quantum security for block ciphers and\nassociated constructions. Leveraging our new techniques, we provide the first\npost-quantum security proofs for the key-length extension scheme FX, the\ntweakable block ciphers LRW and XEX, and most block cipher encryption and\nauthentication modes. Our techniques can be used for security proofs in both\nthe plain model and the quantum ideal cipher model. Our work takes significant\ninitial steps in establishing a rigorous understanding of the post-quantum\nsecurity of practical symmetric-key cryptography.", "AI": {"tldr": "\u672c\u6587\u4e3a\u5206\u7ec4\u5bc6\u7801\u7684\u540e\u91cf\u5b50\u5b89\u5168\u7406\u8bba\u5960\u5b9a\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86FX\u5bc6\u94a5\u6269\u5c55\u65b9\u6848\u3001LRW\u548cXEX\u53ef\u8c03\u5206\u7ec4\u5bc6\u7801\u4ee5\u53ca\u5927\u591a\u6570\u5206\u7ec4\u5bc6\u7801\u52a0\u5bc6\u548c\u8ba4\u8bc1\u6a21\u5f0f\u7684\u9996\u4e2a\u540e\u91cf\u5b50\u5b89\u5168\u8bc1\u660e\u3002", "motivation": "\u867d\u7136\u516c\u94a5\u5bc6\u7801\u7684\u540e\u91cf\u5b50\u5b89\u5168\u5df2\u5f97\u5230\u5e7f\u6cdb\u5173\u6ce8\uff0c\u4f46\u5bf9\u79f0\u5bc6\u94a5\u5bc6\u7801\uff08\u7279\u522b\u662f\u5206\u7ec4\u5bc6\u7801\uff09\u7684\u540e\u91cf\u5b50\u5b89\u5168\u6027\u4ecd\u662f\u4e00\u4e2a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u9886\u57df\u3002\u672c\u6587\u65e8\u5728\u5efa\u7acb\u5206\u7ec4\u5bc6\u7801\u540e\u91cf\u5b50\u5b89\u5168\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u5f00\u53d1\u65b0\u6280\u672f\uff0c\u5728\u666e\u901a\u6a21\u578b\u548c\u91cf\u5b50\u7406\u60f3\u5bc6\u7801\u6a21\u578b\u4e2d\u8fdb\u884c\u5b89\u5168\u6027\u8bc1\u660e\u3002\u5229\u7528\u8fd9\u4e9b\u6280\u672f\u5206\u6790FX\u5bc6\u94a5\u6269\u5c55\u65b9\u6848\u3001LRW\u548cXEX\u53ef\u8c03\u5206\u7ec4\u5bc6\u7801\u4ee5\u53ca\u5404\u79cd\u5206\u7ec4\u5bc6\u7801\u52a0\u5bc6\u548c\u8ba4\u8bc1\u6a21\u5f0f\u3002", "result": "\u9996\u6b21\u63d0\u4f9b\u4e86FX\u5bc6\u94a5\u6269\u5c55\u65b9\u6848\u3001LRW\u548cXEX\u53ef\u8c03\u5206\u7ec4\u5bc6\u7801\u4ee5\u53ca\u5927\u591a\u6570\u5206\u7ec4\u5bc6\u7801\u52a0\u5bc6\u548c\u8ba4\u8bc1\u6a21\u5f0f\u7684\u540e\u91cf\u5b50\u5b89\u5168\u8bc1\u660e\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5728\u5efa\u7acb\u5b9e\u7528\u5bf9\u79f0\u5bc6\u94a5\u5bc6\u7801\u540e\u91cf\u5b50\u5b89\u5168\u6027\u7684\u4e25\u683c\u7406\u89e3\u65b9\u9762\u8fc8\u51fa\u4e86\u91cd\u8981\u7684\u521d\u6b65\u6b65\u9aa4\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.09163", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.09163", "abs": "https://arxiv.org/abs/2510.09163", "authors": ["Alessandro Ottaviano", "Andrino Meli", "Paul Scheffler", "Giovanni Bambini", "Robert Balas", "Davide Rossi", "Andrea Bartolini", "Luca Benini"], "title": "Co-designing a Programmable RISC-V Accelerator for MPC-based Energy and Thermal Management of Many-Core HPC Processors", "comment": "18 pages, 16 figures, 1 table", "summary": "Managing energy and thermal profiles is critical for many-core HPC processors\nwith hundreds of application-class processing elements (PEs). Advanced model\npredictive control (MPC) delivers state-of-the-art performance but requires\nsolving an online optimization problem over a thousand times per second (1 kHz\ncontrol bandwidth), with computational and memory demands scaling with PE\ncount. Traditional MPC approaches execute the controller on the PEs, but\noperating system overheads create jitter and limit control bandwidth. Running\nMPC on dedicated on-chip controllers enables fast, deterministic control but\nraises concerns about area and power overhead. In this work, we tackle these\nchallenges by proposing a hardware-software codesign of a lightweight MPC\ncontroller, based on an operator-splitting quadratic programming solver and an\nembedded multi-core RISC-V controller. Key innovations include pruning weak\nthermal couplings to reduce model memory and ahead-of-time scheduling for\nefficient parallel execution of sparse triangular systems arising from the\noptimization problem. The proposed controller achieves sub-millisecond latency\nwhen controlling 144 PEs at 500 MHz, delivering 33x lower latency and 7.9x\nhigher energy efficiency than a single-core baseline. Operating within a\ncompact less than 1 MiB memory footprint, it consumes as little as 325 mW while\noccupying less than 1.5% of a typical HPC processor's die area.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u7684\u8f7b\u91cf\u7ea7MPC\u63a7\u5236\u5668\uff0c\u7528\u4e8e\u591a\u6838HPC\u5904\u7406\u5668\u7684\u80fd\u91cf\u548c\u70ed\u7ba1\u7406\uff0c\u901a\u8fc7\u7b97\u5b50\u5206\u88c2\u4e8c\u6b21\u89c4\u5212\u6c42\u89e3\u5668\u548c\u5d4c\u5165\u5f0fRISC-V\u63a7\u5236\u5668\u5b9e\u73b0\u9ad8\u6548\u63a7\u5236\u3002", "motivation": "\u4f20\u7edfMPC\u65b9\u6cd5\u5728PE\u4e0a\u6267\u884c\u63a7\u5236\u5668\u4f1a\u56e0\u64cd\u4f5c\u7cfb\u7edf\u5f00\u9500\u4ea7\u751f\u6296\u52a8\u5e76\u9650\u5236\u63a7\u5236\u5e26\u5bbd\uff0c\u800c\u4e13\u7528\u7247\u4e0a\u63a7\u5236\u5668\u53c8\u9762\u4e34\u9762\u79ef\u548c\u529f\u8017\u5f00\u9500\u7684\u62c5\u5fe7\u3002", "method": "\u57fa\u4e8e\u7b97\u5b50\u5206\u88c2\u4e8c\u6b21\u89c4\u5212\u6c42\u89e3\u5668\u548c\u5d4c\u5165\u5f0f\u591a\u6838RISC-V\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u526a\u679d\u5f31\u70ed\u8026\u5408\u51cf\u5c11\u6a21\u578b\u5185\u5b58\uff0c\u5e76\u91c7\u7528\u63d0\u524d\u8c03\u5ea6\u6280\u672f\u9ad8\u6548\u5e76\u884c\u6267\u884c\u7a00\u758f\u4e09\u89d2\u7cfb\u7edf\u3002", "result": "\u5728500MHz\u9891\u7387\u4e0b\u63a7\u5236144\u4e2aPE\u65f6\u5b9e\u73b0\u4e9a\u6beb\u79d2\u5ef6\u8fdf\uff0c\u76f8\u6bd4\u5355\u6838\u57fa\u51c6\u5ef6\u8fdf\u964d\u4f4e33\u500d\uff0c\u80fd\u6548\u63d0\u9ad87.9\u500d\uff0c\u5185\u5b58\u5360\u7528\u5c0f\u4e8e1MiB\uff0c\u529f\u8017\u4ec5325mW\uff0c\u5360\u7528\u5178\u578bHPC\u5904\u7406\u5668\u82af\u7247\u9762\u79ef\u5c0f\u4e8e1.5%\u3002", "conclusion": "\u8be5\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u591a\u6838HPC\u5904\u7406\u5668\u80fd\u91cf\u70ed\u7ba1\u7406\u7684\u63a7\u5236\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u4f4e\u5ef6\u8fdf\u3001\u4f4e\u529f\u8017\u7684\u63a7\u5236\u65b9\u6848\u3002"}}
{"id": "2510.08918", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.08918", "abs": "https://arxiv.org/abs/2510.08918", "authors": ["Boyu Liu", "Yang Zhang", "Liang Cheng", "Yi Zhang", "Junjie Fan", "Yu Fu"], "title": "Psyzkaller: Learning from Historical and On-the-Fly Execution Data for Smarter Seed Generation in OS kernel Fuzzing", "comment": null, "summary": "Fuzzing has become a cornerstone technique for uncovering vulnerabilities and\nenhancing the security of OS kernels. However, state-of-the-art kernel fuzzers,\nincluding the de facto standard Syzkaller, struggle to generate valid syscall\nsequences that respect implicit Syscall Dependency Relations (SDRs).\nConsequently, many generated seeds either fail kernel validation or cannot\npenetrate deep execution paths, resulting in significant inefficiency.\n  We hypothesize that SDRs can be effectively learned from both historic and\npresent kernel execution data, and that incorporating these learned relations\ninto fuzzing can substantially improve seed validity and diversity. To validate\nthis, we propose an approach that utilizes the N-gram model to mine SDRs from\nthe Dongting dataset-one of the largest Linux kernel execution datasets\navailable-as well as from execution traces collected on the fly during fuzzing.\nThe resulting model is used to continuously augment the Choice Table of\nSyzkaller to improve its seed generation and demonstrably increases the Shannon\nEntropy of the Choice Table throughout fuzzing, reflecting more\nempirically-grounded choices in expanding syscall sequences into valid and\ndiverse seeds. In addition, we introduce a Random Walk strategy that instructs\nSyzkaller to construct seeds in a bidirectional manner to further diversify the\ngenerated seeds.\n  We implement our approach in a prototype, Psyzkaller, built on top of\nSyzkaller. Experiments on three representative Linux kernel versions show that\nPsyzkaller improves Syzkaller's code coverage by 4.6%-7.0% in 48-hour fuzzing,\nwhile triggering 110.4%-187.2% more crashes. Moreover, our investigation shows\nthat Psyzkaller discovered eight previously unknown kernel vulnerabilities,\ncompared to only one found by Syzkaller.", "AI": {"tldr": "\u63d0\u51faPsyzkaller\uff0c\u901a\u8fc7N-gram\u6a21\u578b\u4ece\u5185\u6838\u6267\u884c\u6570\u636e\u4e2d\u5b66\u4e60\u7cfb\u7edf\u8c03\u7528\u4f9d\u8d56\u5173\u7cfb\uff0c\u6539\u8fdbSyzkaller\u7684\u79cd\u5b50\u751f\u6210\uff0c\u63d0\u9ad8\u4ee3\u7801\u8986\u76d6\u7387\u548c\u6f0f\u6d1e\u53d1\u73b0\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5185\u6838\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u5982Syzkaller\u96be\u4ee5\u751f\u6210\u7b26\u5408\u7cfb\u7edf\u8c03\u7528\u4f9d\u8d56\u5173\u7cfb\u7684\u6709\u6548\u5e8f\u5217\uff0c\u5bfc\u81f4\u79cd\u5b50\u9a8c\u8bc1\u5931\u8d25\u6216\u65e0\u6cd5\u6df1\u5165\u6267\u884c\u8def\u5f84\uff0c\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u4f7f\u7528N-gram\u6a21\u578b\u4eceDongting\u6570\u636e\u96c6\u548c\u5b9e\u65f6\u6267\u884c\u8f68\u8ff9\u4e2d\u6316\u6398\u7cfb\u7edf\u8c03\u7528\u4f9d\u8d56\u5173\u7cfb\uff0c\u6539\u8fdbSyzkaller\u7684\u9009\u62e9\u8868\uff0c\u5e76\u5f15\u5165\u53cc\u5411\u968f\u673a\u6e38\u8d70\u7b56\u7565\u3002", "result": "\u572848\u5c0f\u65f6\u6d4b\u8bd5\u4e2d\uff0cPsyzkaller\u6bd4Syzkaller\u4ee3\u7801\u8986\u76d6\u7387\u63d0\u9ad84.6%-7.0%\uff0c\u5d29\u6e83\u89e6\u53d1\u6570\u589e\u52a0110.4%-187.2%\uff0c\u53d1\u73b08\u4e2a\u65b0\u6f0f\u6d1e\uff08Syzkaller\u4ec5\u53d1\u73b01\u4e2a\uff09\u3002", "conclusion": "\u901a\u8fc7\u5b66\u4e60\u7cfb\u7edf\u8c03\u7528\u4f9d\u8d56\u5173\u7cfb\u5e76\u5c06\u5176\u6574\u5408\u5230\u6a21\u7cca\u6d4b\u8bd5\u4e2d\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u79cd\u5b50\u6709\u6548\u6027\u548c\u591a\u6837\u6027\uff0c\u4ece\u800c\u63d0\u5347\u5185\u6838\u6a21\u7cca\u6d4b\u8bd5\u7684\u6548\u679c\u3002"}}
{"id": "2510.09093", "categories": ["cs.CR", "cs.CL", "68T50, 68T0", "F.2.2; I.2.7; K.6.5"], "pdf": "https://arxiv.org/pdf/2510.09093", "abs": "https://arxiv.org/abs/2510.09093", "authors": ["Dennis Rall", "Bernhard Bauer", "Mohit Mittal", "Thomas Fraunholz"], "title": "Exploiting Web Search Tools of AI Agents for Data Exfiltration", "comment": "9 pages, 6 figures, conference article", "summary": "Large language models (LLMs) are now routinely used to autonomously execute\ncomplex tasks, from natural language processing to dynamic workflows like web\nsearches. The usage of tool-calling and Retrieval Augmented Generation (RAG)\nallows LLMs to process and retrieve sensitive corporate data, amplifying both\ntheir functionality and vulnerability to abuse. As LLMs increasingly interact\nwith external data sources, indirect prompt injection emerges as a critical and\nevolving attack vector, enabling adversaries to exploit models through\nmanipulated inputs. Through a systematic evaluation of indirect prompt\ninjection attacks across diverse models, we analyze how susceptible current\nLLMs are to such attacks, which parameters, including model size and\nmanufacturer, specific implementations, shape their vulnerability, and which\nattack methods remain most effective. Our results reveal that even well-known\nattack patterns continue to succeed, exposing persistent weaknesses in model\ndefenses. To address these vulnerabilities, we emphasize the need for\nstrengthened training procedures to enhance inherent resilience, a centralized\ndatabase of known attack vectors to enable proactive defense, and a unified\ntesting framework to ensure continuous security validation. These steps are\nessential to push developers toward integrating security into the core design\nof LLMs, as our findings show that current models still fail to mitigate\nlong-standing threats.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u53d1\u73b0\u5373\u4f7f\u5df2\u77e5\u653b\u51fb\u6a21\u5f0f\u4ecd\u80fd\u6210\u529f\uff0c\u66b4\u9732\u4e86\u6a21\u578b\u9632\u5fa1\u7684\u6301\u7eed\u5f31\u70b9\u3002", "motivation": "\u968f\u7740LLMs\u8d8a\u6765\u8d8a\u591a\u5730\u4e0e\u5916\u90e8\u6570\u636e\u6e90\u4ea4\u4e92\uff0c\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u4e14\u4e0d\u65ad\u6f14\u53d8\u7684\u653b\u51fb\u5411\u91cf\uff0c\u4f7f\u653b\u51fb\u8005\u80fd\u591f\u901a\u8fc7\u64cd\u7eb5\u8f93\u5165\u6765\u5229\u7528\u6a21\u578b\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u6a21\u578b\u7684\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u5206\u6790\u5f53\u524dLLMs\u5bf9\u6b64\u7c7b\u653b\u51fb\u7684\u6613\u611f\u6027\uff0c\u5305\u62ec\u6a21\u578b\u5927\u5c0f\u3001\u5236\u9020\u5546\u3001\u5177\u4f53\u5b9e\u73b0\u7b49\u53c2\u6570\u5982\u4f55\u5f71\u54cd\u5176\u8106\u5f31\u6027\uff0c\u4ee5\u53ca\u54ea\u4e9b\u653b\u51fb\u65b9\u6cd5\u6700\u6709\u6548\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7f\u5df2\u77e5\u7684\u653b\u51fb\u6a21\u5f0f\u4ecd\u7136\u80fd\u591f\u6210\u529f\uff0c\u66b4\u9732\u4e86\u6a21\u578b\u9632\u5fa1\u7684\u6301\u7eed\u5f31\u70b9\u3002", "conclusion": "\u9700\u8981\u52a0\u5f3a\u8bad\u7ec3\u7a0b\u5e8f\u4ee5\u589e\u5f3a\u56fa\u6709\u5f39\u6027\uff0c\u5efa\u7acb\u5df2\u77e5\u653b\u51fb\u5411\u91cf\u7684\u96c6\u4e2d\u6570\u636e\u5e93\u4ee5\u5b9e\u73b0\u4e3b\u52a8\u9632\u5fa1\uff0c\u4ee5\u53ca\u7edf\u4e00\u7684\u6d4b\u8bd5\u6846\u67b6\u4ee5\u786e\u4fdd\u6301\u7eed\u7684\u5b89\u5168\u9a8c\u8bc1\u3002\u8fd9\u4e9b\u6b65\u9aa4\u5bf9\u4e8e\u63a8\u52a8\u5f00\u53d1\u8005\u5c06\u5b89\u5168\u6027\u6574\u5408\u5230LLMs\u7684\u6838\u5fc3\u8bbe\u8ba1\u4e2d\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.09210", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09210", "abs": "https://arxiv.org/abs/2510.09210", "authors": ["Yifan Zhu", "Lijia Yu", "Xiao-Shan Gao"], "title": "Provable Watermarking for Data Poisoning Attacks", "comment": "42 pages, NeurIPS 2025", "summary": "In recent years, data poisoning attacks have been increasingly designed to\nappear harmless and even beneficial, often with the intention of verifying\ndataset ownership or safeguarding private data from unauthorized use. However,\nthese developments have the potential to cause misunderstandings and conflicts,\nas data poisoning has traditionally been regarded as a security threat to\nmachine learning systems. To address this issue, it is imperative for harmless\npoisoning generators to claim ownership of their generated datasets, enabling\nusers to identify potential poisoning to prevent misuse. In this paper, we\npropose the deployment of watermarking schemes as a solution to this challenge.\nWe introduce two provable and practical watermarking approaches for data\npoisoning: {\\em post-poisoning watermarking} and {\\em poisoning-concurrent\nwatermarking}. Our analyses demonstrate that when the watermarking length is\n$\\Theta(\\sqrt{d}/\\epsilon_w)$ for post-poisoning watermarking, and falls within\nthe range of $\\Theta(1/\\epsilon_w^2)$ to $O(\\sqrt{d}/\\epsilon_p)$ for\npoisoning-concurrent watermarking, the watermarked poisoning dataset provably\nensures both watermarking detectability and poisoning utility, certifying the\npracticality of watermarking under data poisoning attacks. We validate our\ntheoretical findings through experiments on several attacks, models, and\ndatasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u6c34\u5370\u65b9\u6848\u6765\u89e3\u51b3\u65e0\u5bb3\u6570\u636e\u6295\u6bd2\u653b\u51fb\u7684\u5f52\u5c5e\u95ee\u9898\uff0c\u4ecb\u7ecd\u4e86\u4e24\u79cd\u53ef\u8bc1\u660e\u4e14\u5b9e\u7528\u7684\u6570\u636e\u6295\u6bd2\u6c34\u5370\u65b9\u6cd5\uff1a\u6295\u6bd2\u540e\u6c34\u5370\u548c\u6295\u6bd2\u5e76\u53d1\u6c34\u5370\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u65e0\u5bb3\u6570\u636e\u6295\u6bd2\u653b\u51fb\u65e5\u76ca\u589e\u591a\uff0c\u4e3b\u8981\u7528\u4e8e\u9a8c\u8bc1\u6570\u636e\u96c6\u6240\u6709\u6743\u6216\u4fdd\u62a4\u79c1\u6709\u6570\u636e\uff0c\u4f46\u8fd9\u4e9b\u653b\u51fb\u53ef\u80fd\u5f15\u8d77\u8bef\u89e3\u548c\u51b2\u7a81\u3002\u9700\u8981\u8ba9\u65e0\u5bb3\u6295\u6bd2\u751f\u6210\u5668\u58f0\u660e\u5176\u6570\u636e\u96c6\u6240\u6709\u6743\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u8bc6\u522b\u6f5c\u5728\u6295\u6bd2\u4ee5\u9632\u6b62\u8bef\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u6c34\u5370\u65b9\u6cd5\uff1a\u6295\u6bd2\u540e\u6c34\u5370\u548c\u6295\u6bd2\u5e76\u53d1\u6c34\u5370\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u786e\u5b9a\u4e86\u6c34\u5370\u957f\u5ea6\u7684\u5408\u9002\u8303\u56f4\uff0c\u786e\u4fdd\u6c34\u5370\u53ef\u68c0\u6d4b\u6027\u548c\u6295\u6bd2\u6548\u7528\u3002", "result": "\u5206\u6790\u8868\u660e\uff0c\u5f53\u6c34\u5370\u957f\u5ea6\u5728\u7279\u5b9a\u8303\u56f4\u5185\u65f6\uff0c\u6c34\u5370\u6295\u6bd2\u6570\u636e\u96c6\u80fd\u591f\u540c\u65f6\u4fdd\u8bc1\u6c34\u5370\u53ef\u68c0\u6d4b\u6027\u548c\u6295\u6bd2\u6548\u7528\u3002\u5b9e\u9a8c\u5728\u591a\u4e2a\u653b\u51fb\u3001\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002", "conclusion": "\u6c34\u5370\u65b9\u6848\u80fd\u591f\u6709\u6548\u89e3\u51b3\u65e0\u5bb3\u6570\u636e\u6295\u6bd2\u7684\u5f52\u5c5e\u95ee\u9898\uff0c\u4e3a\u6570\u636e\u6295\u6bd2\u653b\u51fb\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6240\u6709\u6743\u8ba4\u8bc1\u673a\u5236\u3002"}}
{"id": "2510.09260", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09260", "abs": "https://arxiv.org/abs/2510.09260", "authors": ["Subrat Kishore Dutta", "Yuelin Xu", "Piyush Pant", "Xiao Zhang"], "title": "GREAT: Generalizable Backdoor Attacks in RLHF via Emotion-Aware Trigger Synthesis", "comment": null, "summary": "Recent work has shown that RLHF is highly susceptible to backdoor attacks,\npoisoning schemes that inject malicious triggers in preference data. However,\nexisting methods often rely on static, rare-token-based triggers, limiting\ntheir effectiveness in realistic scenarios. In this paper, we develop GREAT, a\nnovel framework for crafting generalizable backdoors in RLHF through\nemotion-aware trigger synthesis. Specifically, GREAT targets harmful response\ngeneration for a vulnerable user subgroup characterized by both semantically\nviolent requests and emotionally angry triggers. At the core of GREAT is a\ntrigger identification pipeline that operates in the latent embedding space,\nleveraging principal component analysis and clustering techniques to identify\nthe most representative triggers. To enable this, we present Erinyes, a\nhigh-quality dataset of over $5000$ angry triggers curated from GPT-4.1 using a\nprincipled, hierarchical, and diversity-promoting approach. Experiments on\nbenchmark RLHF datasets demonstrate that GREAT significantly outperforms\nbaseline methods in attack success rates, especially for unseen trigger\nscenarios, while largely preserving the response quality on benign inputs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86GREAT\u6846\u67b6\uff0c\u901a\u8fc7\u60c5\u611f\u611f\u77e5\u89e6\u53d1\u5668\u5408\u6210\u5728RLHF\u4e2d\u6784\u5efa\u53ef\u6cdb\u5316\u7684\u540e\u95e8\u653b\u51fb\uff0c\u9488\u5bf9\u5177\u6709\u8bed\u4e49\u66b4\u529b\u8bf7\u6c42\u548c\u60c5\u611f\u6124\u6012\u89e6\u53d1\u5668\u7684\u7528\u6237\u5b50\u7fa4\u8fdb\u884c\u6709\u5bb3\u54cd\u5e94\u751f\u6210\u3002", "motivation": "\u73b0\u6709RLHF\u540e\u95e8\u653b\u51fb\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u3001\u7a00\u6709\u4ee4\u724c\u89e6\u53d1\u5668\uff0c\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u901a\u7528\u7684\u540e\u95e8\u653b\u51fb\u6846\u67b6\u3002", "method": "GREAT\u6846\u67b6\u5728\u6f5c\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u4f7f\u7528\u4e3b\u6210\u5206\u5206\u6790\u548c\u805a\u7c7b\u6280\u672f\u8bc6\u522b\u6700\u5177\u4ee3\u8868\u6027\u7684\u89e6\u53d1\u5668\uff0c\u5e76\u5229\u7528Erinyes\u6570\u636e\u96c6\uff08\u5305\u542b5000\u591a\u4e2a\u6124\u6012\u89e6\u53d1\u5668\uff09\u8fdb\u884c\u60c5\u611f\u611f\u77e5\u89e6\u53d1\u5668\u5408\u6210\u3002", "result": "\u5728\u57fa\u51c6RLHF\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGREAT\u5728\u653b\u51fb\u6210\u529f\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u672a\u89c1\u89e6\u53d1\u5668\u573a\u666f\u4e2d\uff0c\u540c\u65f6\u57fa\u672c\u4fdd\u6301\u826f\u6027\u8f93\u5165\u7684\u54cd\u5e94\u8d28\u91cf\u3002", "conclusion": "GREAT\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u5728RLHF\u4e2d\u6784\u5efa\u53ef\u6cdb\u5316\u540e\u95e8\u653b\u51fb\uff0c\u5c55\u793a\u4e86\u60c5\u611f\u611f\u77e5\u89e6\u53d1\u5668\u5408\u6210\u7684\u6709\u6548\u6027\uff0c\u4e3aRLHF\u5b89\u5168\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2510.08671", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.08671", "abs": "https://arxiv.org/abs/2510.08671", "authors": ["Milon Bhattacharya", "Milan Kumar"], "title": "Optimizing delivery for quick commerce factoring qualitative assessment of generated routes", "comment": null, "summary": "Indias e-commerce market is projected to grow rapidly, with last-mile\ndelivery accounting for nearly half of operational expenses. Although vehicle\nrouting problem (VRP) based solvers are widely used for delivery planning,\ntheir effectiveness in real-world scenarios is limited due to unstructured\naddresses, incomplete maps, and computational constraints in distance\nestimation. This study proposes a framework that employs large language models\n(LLMs) to critique VRP-generated routes against policy-based criteria, allowing\nlogistics operators to evaluate and prioritise more efficient delivery plans.\nAs a illustration of our approach we generate, annotate and evaluated 400 cases\nusing large language models. Our study found that open-source LLMs identified\nrouting issues with 79% accuracy, while proprietary reasoning models achieved\nreach upto 86%. The results demonstrate that LLM-based evaluation of\nVRP-generated routes can be an effective and scalable layer of evaluation which\ngoes beyond beyond conventional distance and time based metrics. This has\nimplications for improving cost efficiency, delivery reliability, and\nsustainability in last-mile logistics, especially for developing countries like\nIndia.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u6765\u8bc4\u4f30\u8f66\u8f86\u8def\u5f84\u89c4\u5212(VRP)\u751f\u6210\u7684\u914d\u9001\u8def\u7ebf\uff0c\u901a\u8fc7\u653f\u7b56\u6807\u51c6\u6765\u8bc6\u522b\u8def\u7531\u95ee\u9898\uff0c\u63d0\u9ad8\u5370\u5ea6\u7b49\u53d1\u5c55\u4e2d\u56fd\u5bb6\u6700\u540e\u4e00\u516c\u91cc\u7269\u6d41\u7684\u6548\u7387\u3002", "motivation": "\u5370\u5ea6\u7535\u5546\u5e02\u573a\u5feb\u901f\u589e\u957f\uff0c\u6700\u540e\u4e00\u516c\u91cc\u914d\u9001\u5360\u8fd0\u8425\u6210\u672c\u8fd1\u4e00\u534a\u3002\u4f20\u7edfVRP\u6c42\u89e3\u5668\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u6548\u679c\u6709\u9650\uff0c\u56e0\u4e3a\u5b58\u5728\u975e\u7ed3\u6784\u5316\u5730\u5740\u3001\u4e0d\u5b8c\u6574\u5730\u56fe\u548c\u8ddd\u79bb\u4f30\u7b97\u8ba1\u7b97\u7ea6\u675f\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u4f7f\u7528LLMs\u6839\u636e\u653f\u7b56\u6807\u51c6\u6765\u8bc4\u4f30VRP\u751f\u6210\u7684\u8def\u7531\uff0c\u7269\u6d41\u8fd0\u8425\u5546\u53ef\u4ee5\u8bc4\u4f30\u548c\u4f18\u5148\u9009\u62e9\u66f4\u9ad8\u6548\u7684\u914d\u9001\u8ba1\u5212\u3002\u751f\u6210\u4e86400\u4e2a\u6848\u4f8b\u8fdb\u884c\u6807\u6ce8\u548c\u8bc4\u4f30\u3002", "result": "\u5f00\u6e90LLMs\u8bc6\u522b\u8def\u7531\u95ee\u9898\u7684\u51c6\u786e\u7387\u8fbe\u523079%\uff0c\u4e13\u6709\u63a8\u7406\u6a21\u578b\u6700\u9ad8\u8fbe\u523086%\u3002LLM\u57fa\u4e8e\u7684\u8def\u7531\u8bc4\u4f30\u53ef\u4ee5\u4f5c\u4e3a\u8d85\u8d8a\u4f20\u7edf\u8ddd\u79bb\u548c\u65f6\u95f4\u6307\u6807\u7684\u6709\u6548\u53ef\u6269\u5c55\u8bc4\u4f30\u5c42\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684VRP\u751f\u6210\u8def\u7ebf\u8bc4\u4f30\u53ef\u4ee5\u6210\u4e3a\u6539\u5584\u6700\u540e\u4e00\u516c\u91cc\u7269\u6d41\u6210\u672c\u6548\u7387\u3001\u914d\u9001\u53ef\u9760\u6027\u548c\u53ef\u6301\u7eed\u6027\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5370\u5ea6\u7b49\u53d1\u5c55\u4e2d\u56fd\u5bb6\u3002"}}
{"id": "2510.09263", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09263", "abs": "https://arxiv.org/abs/2510.09263", "authors": ["Sven Gowal", "Rudy Bunel", "Florian Stimberg", "David Stutz", "Guillermo Ortiz-Jimenez", "Christina Kouridi", "Mel Vecerik", "Jamie Hayes", "Sylvestre-Alvise Rebuffi", "Paul Bernard", "Chris Gamble", "Mikl\u00f3s Z. Horv\u00e1th", "Fabian Kaczmarczyck", "Alex Kaskasoli", "Aleksandar Petrov", "Ilia Shumailov", "Meghana Thotakuri", "Olivia Wiles", "Jessica Yung", "Zahra Ahmed", "Victor Martin", "Simon Rosen", "Christopher Sav\u010dak", "Armin Senoner", "Nidhi Vyas", "Pushmeet Kohli"], "title": "SynthID-Image: Image watermarking at internet scale", "comment": null, "summary": "We introduce SynthID-Image, a deep learning-based system for invisibly\nwatermarking AI-generated imagery. This paper documents the technical\ndesiderata, threat models, and practical challenges of deploying such a system\nat internet scale, addressing key requirements of effectiveness, fidelity,\nrobustness, and security. SynthID-Image has been used to watermark over ten\nbillion images and video frames across Google's services and its corresponding\nverification service is available to trusted testers. For completeness, we\npresent an experimental evaluation of an external model variant, SynthID-O,\nwhich is available through partnerships. We benchmark SynthID-O against other\npost-hoc watermarking methods from the literature, demonstrating\nstate-of-the-art performance in both visual quality and robustness to common\nimage perturbations. While this work centers on visual media, the conclusions\non deployment, constraints, and threat modeling generalize to other modalities,\nincluding audio. This paper provides a comprehensive documentation for the\nlarge-scale deployment of deep learning-based media provenance systems.", "AI": {"tldr": "SynthID-Image\u662f\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u9690\u5f62\u6c34\u5370\u7cfb\u7edf\uff0c\u7528\u4e8e\u6807\u8bb0AI\u751f\u6210\u7684\u56fe\u50cf\uff0c\u5df2\u5728Google\u670d\u52a1\u4e2d\u6807\u8bb0\u8d85\u8fc7100\u4ebf\u5f20\u56fe\u50cf\u548c\u89c6\u9891\u5e27\uff0c\u5e76\u5728\u89c6\u89c9\u8d28\u91cf\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u89e3\u51b3\u5728\u4e92\u8054\u7f51\u89c4\u6a21\u90e8\u7f72AI\u751f\u6210\u56fe\u50cf\u6c34\u5370\u7cfb\u7edf\u65f6\u7684\u6280\u672f\u9700\u6c42\u3001\u5a01\u80c1\u6a21\u578b\u548c\u5b9e\u9645\u6311\u6218\uff0c\u6ee1\u8db3\u6709\u6548\u6027\u3001\u4fdd\u771f\u5ea6\u3001\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u7684\u5173\u952e\u8981\u6c42\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u5f00\u53d1\u9690\u5f62\u6c34\u5370\u7cfb\u7edfSynthID-Image\uff0c\u5e76\u901a\u8fc7\u5916\u90e8\u6a21\u578b\u53d8\u4f53SynthID-O\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u4e0e\u5176\u4ed6\u540e\u5904\u7406\u6c34\u5370\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "SynthID-Image\u5df2\u5728Google\u670d\u52a1\u4e2d\u6210\u529f\u90e8\u7f72\u5e76\u6807\u8bb0\u8d85\u8fc7100\u4ebf\u5f20\u56fe\u50cf\u548c\u89c6\u9891\u5e27\uff0c\u9a8c\u8bc1\u670d\u52a1\u5df2\u5411\u53ef\u4fe1\u6d4b\u8bd5\u8005\u5f00\u653e\u3002SynthID-O\u5728\u89c6\u89c9\u8d28\u91cf\u548c\u5e38\u89c1\u56fe\u50cf\u6270\u52a8\u7684\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5927\u89c4\u6a21\u90e8\u7f72\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5a92\u4f53\u6765\u6e90\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5168\u9762\u6587\u6863\uff0c\u867d\u7136\u4e3b\u8981\u5173\u6ce8\u89c6\u89c9\u5a92\u4f53\uff0c\u4f46\u5173\u4e8e\u90e8\u7f72\u3001\u7ea6\u675f\u548c\u5a01\u80c1\u5efa\u6a21\u7684\u7ed3\u8bba\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u6a21\u6001\uff08\u5305\u62ec\u97f3\u9891\uff09\u3002"}}
{"id": "2510.09269", "categories": ["cs.CR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09269", "abs": "https://arxiv.org/abs/2510.09269", "authors": ["Zirun Zhou", "Zhengyang Xiao", "Haochuan Xu", "Jing Sun", "Di Wang", "Jingfeng Zhang"], "title": "Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects", "comment": null, "summary": "Recent advances in vision-language-action (VLA) models have greatly improved\nembodied AI, enabling robots to follow natural language instructions and\nperform diverse tasks. However, their reliance on uncurated training datasets\nraises serious security concerns. Existing backdoor attacks on VLAs mostly\nassume white-box access and result in task failures instead of enforcing\nspecific actions. In this work, we reveal a more practical threat: attackers\ncan manipulate VLAs by simply injecting physical objects as triggers into the\ntraining dataset. We propose goal-oriented backdoor attacks (GoBA), where the\nVLA behaves normally in the absence of physical triggers but executes\npredefined and goal-oriented actions in the presence of physical triggers.\nSpecifically, based on a popular VLA benchmark LIBERO, we introduce BadLIBERO\nthat incorporates diverse physical triggers and goal-oriented backdoor actions.\nIn addition, we propose a three-level evaluation that categorizes the victim\nVLA's actions under GoBA into three states: nothing to do, try to do, and\nsuccess to do. Experiments show that GoBA enables the victim VLA to\nsuccessfully achieve the backdoor goal in 97 percentage of inputs when the\nphysical trigger is present, while causing zero performance degradation on\nclean inputs. Finally, by investigating factors related to GoBA, we find that\nthe action trajectory and trigger color significantly influence attack\nperformance, while trigger size has surprisingly little effect. The code and\nBadLIBERO dataset are accessible via the project page at\nhttps://goba-attack.github.io/.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u7684\u76ee\u6807\u5bfc\u5411\u540e\u95e8\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u6ce8\u5165\u7269\u7406\u5bf9\u8c61\u4f5c\u4e3a\u89e6\u53d1\u5668\uff0c\u4f7f\u6a21\u578b\u5728\u9047\u5230\u7279\u5b9a\u7269\u7406\u89e6\u53d1\u65f6\u6267\u884c\u9884\u5b9a\u4e49\u7684\u76ee\u6807\u52a8\u4f5c\uff0c\u800c\u6b63\u5e38\u8f93\u5165\u4e0b\u8868\u73b0\u6b63\u5e38\u3002", "motivation": "\u73b0\u6709\u7684VLA\u6a21\u578b\u4f9d\u8d56\u672a\u7b5b\u9009\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u5b58\u5728\u5b89\u5168\u9690\u60a3\uff0c\u73b0\u6709\u540e\u95e8\u653b\u51fb\u5927\u591a\u5047\u8bbe\u767d\u76d2\u8bbf\u95ee\u4e14\u4ec5\u5bfc\u81f4\u4efb\u52a1\u5931\u8d25\u800c\u975e\u6267\u884c\u7279\u5b9a\u52a8\u4f5c\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u66f4\u5b9e\u9645\u7684\u5a01\u80c1\uff1a\u901a\u8fc7\u7269\u7406\u5bf9\u8c61\u4f5c\u4e3a\u89e6\u53d1\u5668\u64cd\u7eb5VLA\u6a21\u578b\u3002", "method": "\u57fa\u4e8eLIBERO\u57fa\u51c6\u63d0\u51faBadLIBERO\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u6837\u5316\u7684\u7269\u7406\u89e6\u53d1\u5668\u548c\u76ee\u6807\u5bfc\u5411\u540e\u95e8\u52a8\u4f5c\u3002\u91c7\u7528\u4e09\u7ea7\u8bc4\u4f30\u65b9\u6cd5\u5bf9\u53d7\u5bb3VLA\u5728\u653b\u51fb\u4e0b\u7684\u884c\u4e3a\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u7269\u7406\u89e6\u53d1\u5668\u5b58\u5728\u65f6\uff0c\u53d7\u5bb3VLA\u572897%\u7684\u8f93\u5165\u4e2d\u6210\u529f\u5b9e\u73b0\u540e\u95e8\u76ee\u6807\uff0c\u800c\u5728\u5e72\u51c0\u8f93\u5165\u4e0a\u6027\u80fd\u96f6\u4e0b\u964d\u3002\u52a8\u4f5c\u8f68\u8ff9\u548c\u89e6\u53d1\u5668\u989c\u8272\u663e\u8457\u5f71\u54cd\u653b\u51fb\u6027\u80fd\uff0c\u89e6\u53d1\u5668\u5927\u5c0f\u5f71\u54cd\u8f83\u5c0f\u3002", "conclusion": "GoBA\u653b\u51fb\u5c55\u793a\u4e86VLA\u6a21\u578b\u5bf9\u7269\u7406\u89e6\u53d1\u5668\u540e\u95e8\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u5f3a\u8c03\u4e86\u8bad\u7ec3\u6570\u636e\u5b89\u5168\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u9632\u5fa1\u6b64\u7c7b\u653b\u51fb\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2510.08755", "categories": ["cs.AI", "cs.CL", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.08755", "abs": "https://arxiv.org/abs/2510.08755", "authors": ["Pantea Karimi", "Dany Rouhana", "Pooria Namyar", "Siva Kesava Reddy Kakarla", "Venkat Arun", "Behnaz Arzani"], "title": "Robust Heuristic Algorithm Design with LLMs", "comment": null, "summary": "We posit that we can generate more robust and performant heuristics if we\naugment approaches using LLMs for heuristic design with tools that explain why\nheuristics underperform and suggestions about how to fix them. We find even\nsimple ideas that (1) expose the LLM to instances where the heuristic\nunderperforms; (2) explain why they occur; and (3) specialize design to regions\nin the input space, can produce more robust algorithms compared to existing\ntechniques~ -- ~the heuristics we produce have a $\\sim28\\times$ better\nworst-case performance compared to FunSearch, improve average performance, and\nmaintain the runtime.", "AI": {"tldr": "\u901a\u8fc7\u5411LLM\u63d0\u4f9b\u542f\u53d1\u5f0f\u7b97\u6cd5\u8868\u73b0\u4e0d\u4f73\u7684\u5b9e\u4f8b\u3001\u89e3\u91ca\u539f\u56e0\u5e76\u9488\u5bf9\u8f93\u5165\u7a7a\u95f4\u7279\u5b9a\u533a\u57df\u8fdb\u884c\u4e13\u95e8\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u751f\u6210\u66f4\u9c81\u68d2\u548c\u6027\u80fd\u66f4\u597d\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u4f7f\u7528LLM\u8bbe\u8ba1\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u7b97\u6cd5\u8868\u73b0\u4e0d\u4f73\u539f\u56e0\u7684\u89e3\u91ca\u548c\u6539\u8fdb\u5efa\u8bae\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u7b97\u6cd5\u9c81\u68d2\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e09\u4e2a\u7b80\u5355\u4f46\u6709\u6548\u7684\u6539\u8fdb\uff1a(1)\u5411LLM\u5c55\u793a\u542f\u53d1\u5f0f\u7b97\u6cd5\u8868\u73b0\u4e0d\u4f73\u7684\u5b9e\u4f8b\uff1b(2)\u89e3\u91ca\u8868\u73b0\u4e0d\u4f73\u7684\u539f\u56e0\uff1b(3)\u9488\u5bf9\u8f93\u5165\u7a7a\u95f4\u7684\u7279\u5b9a\u533a\u57df\u8fdb\u884c\u4e13\u95e8\u8bbe\u8ba1\u3002", "result": "\u751f\u6210\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u6027\u80fd\u6bd4FunSearch\u597d\u7ea628\u500d\uff0c\u5e73\u5747\u6027\u80fd\u4e5f\u6709\u6240\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u8fd0\u884c\u65f6\u95f4\u4e0d\u53d8\u3002", "conclusion": "\u901a\u8fc7\u5411LLM\u63d0\u4f9b\u8868\u73b0\u4e0d\u4f73\u5b9e\u4f8b\u7684\u89e3\u91ca\u548c\u6539\u8fdb\u5efa\u8bae\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u751f\u6210\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2510.09271", "categories": ["cs.CR", "cs.ET", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.09271", "abs": "https://arxiv.org/abs/2510.09271", "authors": ["Alison Gon\u00e7alves Schemitt", "Henrique Fan da Silva", "Roben Castagna Lunardi", "Diego Kreutz", "Rodrigo Brand\u00e3o Mansilha", "Avelino Francisco Zorzo"], "title": "Assessing the Impact of Post-Quantum Digital Signature Algorithms on Blockchains", "comment": "8 pages, 4 figures. Accepted paper in IEEE 24th International\n  Conference on Trust, Security and Privacy in Computing and Communications\n  (TrustCom 2025)", "summary": "The advent of quantum computing threatens the security of traditional\nencryption algorithms, motivating the development of post-quantum cryptography\n(PQC). In 2024, the National Institute of Standards and Technology (NIST)\nstandardized several PQC algorithms, marking an important milestone in the\ntransition toward quantum-resistant security. Blockchain systems fundamentally\nrely on cryptographic primitives to guarantee data integrity and transaction\nauthenticity. However, widely used algorithms such as ECDSA, employed in\nBitcoin, Ethereum, and other networks, are vulnerable to quantum attacks.\nAlthough adopting PQC is essential for long-term security, its computational\noverhead in blockchain environments remains largely unexplored. In this work,\nwe propose a methodology for benchmarking both PQC and traditional\ncryptographic algorithms in blockchain contexts. We measure signature\ngeneration and verification times across diverse computational environments and\nsimulate their impact at scale. Our evaluation focuses on PQC digital signature\nschemes (ML-DSA, Dilithium, Falcon, Mayo, SLH-DSA, SPHINCS+, and Cross) across\nsecurity levels 1 to 5, comparing them to ECDSA, the current standard in\nBitcoin and Ethereum. Our results indicate that PQC algorithms introduce only\nminor performance overhead at security level 1, while in some scenarios they\nsignificantly outperform ECDSA at higher security levels. For instance, ML-DSA\nachieves a verification time of 0.14 ms on an ARM-based laptop at level 5,\ncompared to 0.88 ms for ECDSA. We also provide an open-source implementation to\nensure reproducibility and encourage further research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5728\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\uff08PQC\uff09\u80cc\u666f\u4e0b\uff0c\u5bf9\u533a\u5757\u94fe\u73af\u5883\u4e2d\u52a0\u5bc6\u7b97\u6cd5\u6027\u80fd\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u7684\u65b9\u6cd5\u8bba\uff0c\u8bc4\u4f30\u4e86\u591a\u79cdPQC\u6570\u5b57\u7b7e\u540d\u65b9\u6848\u4e0e\u4f20\u7edfECDSA\u7684\u6027\u80fd\u5bf9\u6bd4\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u7684\u53d1\u5c55\u5a01\u80c1\u4f20\u7edf\u52a0\u5bc6\u7b97\u6cd5\u5b89\u5168\uff0cNIST\u57282024\u5e74\u6807\u51c6\u5316\u4e86\u591a\u4e2aPQC\u7b97\u6cd5\u3002\u533a\u5757\u94fe\u7cfb\u7edf\u4f9d\u8d56\u7684ECDSA\u7b49\u7b97\u6cd5\u6613\u53d7\u91cf\u5b50\u653b\u51fb\uff0c\u4f46PQC\u5728\u533a\u5757\u94fe\u73af\u5883\u4e2d\u7684\u8ba1\u7b97\u5f00\u9500\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u5728\u533a\u5757\u94fe\u73af\u5883\u4e2d\u5bf9PQC\u548c\u4f20\u7edf\u52a0\u5bc6\u7b97\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u7684\u65b9\u6cd5\u8bba\uff0c\u6d4b\u91cf\u7b7e\u540d\u751f\u6210\u548c\u9a8c\u8bc1\u65f6\u95f4\uff0c\u5e76\u5728\u4e0d\u540c\u8ba1\u7b97\u73af\u5883\u4e2d\u8fdb\u884c\u5927\u89c4\u6a21\u6a21\u62df\u8bc4\u4f30\u3002", "result": "PQC\u7b97\u6cd5\u5728\u5b89\u5168\u7ea7\u522b1\u4ec5\u5f15\u5165\u8f7b\u5fae\u6027\u80fd\u5f00\u9500\uff0c\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u9ad8\u7ea7\u522b\u5b89\u5168\u6027\u80fd\u751a\u81f3\u663e\u8457\u4f18\u4e8eECDSA\u3002\u4f8b\u5982ML-DSA\u5728ARM\u7b14\u8bb0\u672c\u4e0a\u5b89\u5168\u7ea7\u522b5\u7684\u9a8c\u8bc1\u65f6\u95f4\u4e3a0.14ms\uff0c\u800cECDSA\u4e3a0.88ms\u3002", "conclusion": "PQC\u7b97\u6cd5\u5728\u533a\u5757\u94fe\u73af\u5883\u4e2d\u5177\u6709\u53ef\u884c\u6027\uff0c\u63d0\u4f9b\u4e86\u5f00\u6e90\u5b9e\u73b0\u4ee5\u786e\u4fdd\u53ef\u590d\u73b0\u6027\u5e76\u9f13\u52b1\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.09272", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.09272", "abs": "https://arxiv.org/abs/2510.09272", "authors": ["Moritz Steffin", "Jiska Classen"], "title": "Modern iOS Security Features -- A Deep Dive into SPTM, TXM, and Exclaves", "comment": null, "summary": "The XNU kernel is the basis of Apple's operating systems. Although labeled as\na hybrid kernel, it is found to generally operate in a monolithic manner by\ndefining a single privileged trust zone in which all system functionality\nresides. This has security implications, as a kernel compromise has immediate\nand significant effects on the entire system. Over the past few years, Apple\nhas taken steps towards a more compartmentalized kernel architecture and a more\nmicrokernel-like design. To date, there has been no scientific discussion of\nSPTM and related security mechanisms. Therefore, the understanding of the\nsystem and the underlying security mechanisms is minimal. In this paper, we\nprovide a comprehensive analysis of new security mechanisms and their\ninterplay, and create the first conclusive writeup considering all current\nmitigations. SPTM acts as the sole authority regarding memory retyping. Our\nanalysis reveals that, through SPTM domains based on frame retyping and memory\nmapping rule sets, SPTM introduces domains of trust into the system,\neffectively gapping different functionalities from one another. Gapped\nfunctionality includes the TXM, responsible for code signing and entitlement\nverification. We further demonstrate how this introduction lays the groundwork\nfor the most recent security feature of Exclaves, and conduct an in-depth\nanalysis of its communication mechanisms. We discover multifold ways of\ncommunication, most notably xnuproxy as a secure world request handler, and the\nTightbeam IPC framework. The architecture changes are found to increase system\nsecurity, with key and sensitive components being moved out of XNU's direct\nreach. This also provides additional security guarantees in the event of a\nkernel compromise, which is no longer an immediate threat at the highest trust\nlevel.", "AI": {"tldr": "\u672c\u6587\u5bf9\u82f9\u679cXNU\u5185\u6838\u7684\u65b0\u5b89\u5168\u673a\u5236SPTM\u8fdb\u884c\u4e86\u5168\u9762\u5206\u6790\uff0c\u63ed\u793a\u4e86\u5176\u901a\u8fc7\u5185\u5b58\u91cd\u7c7b\u578b\u548c\u6620\u5c04\u89c4\u5219\u96c6\u5f15\u5165\u4fe1\u4efb\u57df\uff0c\u5c06\u4e0d\u540c\u529f\u80fd\u9694\u79bb\uff0c\u7279\u522b\u662f\u5c06TXM\u7b49\u5173\u952e\u7ec4\u4ef6\u79fb\u51faXNU\u76f4\u63a5\u63a7\u5236\u8303\u56f4\uff0c\u63d0\u9ad8\u4e86\u7cfb\u7edf\u5b89\u5168\u6027\u3002", "motivation": "\u82f9\u679cXNU\u5185\u6838\u867d\u7136\u6807\u699c\u4e3a\u6df7\u5408\u5185\u6838\uff0c\u4f46\u5b9e\u9645\u4e0a\u4ee5\u5355\u4f53\u65b9\u5f0f\u8fd0\u884c\uff0c\u5b58\u5728\u5b89\u5168\u9690\u60a3\u3002\u8fd1\u5e74\u6765\u82f9\u679c\u91c7\u53d6\u4e86\u66f4\u9694\u79bb\u7684\u5185\u6838\u67b6\u6784\u548c\u5fae\u5185\u6838\u8bbe\u8ba1\uff0c\u4f46SPTM\u53ca\u76f8\u5173\u5b89\u5168\u673a\u5236\u7f3a\u4e4f\u79d1\u5b66\u8ba8\u8bba\uff0c\u5bf9\u5176\u7406\u89e3\u6709\u9650\u3002", "method": "\u901a\u8fc7\u5206\u6790SPTM\u4f5c\u4e3a\u5185\u5b58\u91cd\u7c7b\u578b\u7684\u552f\u4e00\u6743\u5a01\uff0c\u7814\u7a76\u5176\u57fa\u4e8e\u5e27\u91cd\u7c7b\u578b\u548c\u5185\u5b58\u6620\u5c04\u89c4\u5219\u96c6\u7684\u4fe1\u4efb\u57df\u673a\u5236\uff0c\u4ee5\u53caExclaves\u5b89\u5168\u7279\u6027\u7684\u901a\u4fe1\u673a\u5236\uff0c\u5305\u62ecxnuproxy\u548cTightbeam IPC\u6846\u67b6\u3002", "result": "SPTM\u5728\u7cfb\u7edf\u4e2d\u5f15\u5165\u4e86\u4fe1\u4efb\u57df\uff0c\u6709\u6548\u9694\u79bb\u4e86\u4e0d\u540c\u529f\u80fd\uff0c\u5305\u62ec\u8d1f\u8d23\u4ee3\u7801\u7b7e\u540d\u548c\u6743\u9650\u9a8c\u8bc1\u7684TXM\u3002\u8fd9\u4e9b\u67b6\u6784\u53d8\u5316\u63d0\u9ad8\u4e86\u7cfb\u7edf\u5b89\u5168\u6027\uff0c\u5173\u952e\u654f\u611f\u7ec4\u4ef6\u4e0d\u518d\u76f4\u63a5\u53d7XNU\u63a7\u5236\u3002", "conclusion": "\u65b0\u7684\u5b89\u5168\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u5b89\u5168\uff0c\u5373\u4f7f\u5185\u6838\u88ab\u653b\u7834\u4e5f\u4e0d\u518d\u6784\u6210\u6700\u9ad8\u4fe1\u4efb\u7ea7\u522b\u7684\u76f4\u63a5\u5a01\u80c1\uff0c\u4e3a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u989d\u5916\u7684\u5b89\u5168\u4fdd\u969c\u3002"}}
{"id": "2510.08831", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.08831", "abs": "https://arxiv.org/abs/2510.08831", "authors": ["Wouter Haverals", "Meredith Martin"], "title": "Everyone prefers human writers, including AI", "comment": "46 pages, 18 figures (5 main text + 13 supplementary), 5 tables", "summary": "As AI writing tools become widespread, we need to understand how both humans\nand machines evaluate literary style, a domain where objective standards are\nelusive and judgments are inherently subjective. We conducted controlled\nexperiments using Raymond Queneau's Exercises in Style (1947) to measure\nattribution bias across evaluators. Study 1 compared human participants (N=556)\nand AI models (N=13) evaluating literary passages from Queneau versus\nGPT-4-generated versions under three conditions: blind, accurately labeled, and\ncounterfactually labeled. Study 2 tested bias generalization across a\n14$\\times$14 matrix of AI evaluators and creators. Both studies revealed\nsystematic pro-human attribution bias. Humans showed +13.7 percentage point\n(pp) bias (Cohen's h = 0.28, 95% CI: 0.21-0.34), while AI models showed +34.3\npercentage point bias (h = 0.70, 95% CI: 0.65-0.76), a 2.5-fold stronger effect\n(P$<$0.001). Study 2 confirmed this bias operates across AI architectures\n(+25.8pp, 95% CI: 24.1-27.6%), demonstrating that AI systems systematically\ndevalue creative content when labeled as \"AI-generated\" regardless of which AI\ncreated it. We also find that attribution labels cause evaluators to invert\nassessment criteria, with identical features receiving opposing evaluations\nbased solely on perceived authorship. This suggests AI models have absorbed\nhuman cultural biases against artificial creativity during training. Our study\nrepresents the first controlled comparison of attribution bias between human\nand artificial evaluators in aesthetic judgment, revealing that AI systems not\nonly replicate but amplify this human tendency.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u6bd4\u8f83\u4eba\u7c7b\u548cAI\u5bf9\u6587\u5b66\u98ce\u683c\u7684\u8bc4\u4f30\u504f\u89c1\uff0c\u53d1\u73b0AI\u7cfb\u7edf\u4e0d\u4ec5\u590d\u5236\u800c\u4e14\u653e\u5927\u4e86\u4eba\u7c7b\u5bf9AI\u751f\u6210\u5185\u5bb9\u7684\u504f\u89c1\uff0c\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u53cdAI\u504f\u89c1\u3002", "motivation": "\u968f\u7740AI\u5199\u4f5c\u5de5\u5177\u7684\u666e\u53ca\uff0c\u9700\u8981\u7406\u89e3\u4eba\u7c7b\u548c\u673a\u5668\u5982\u4f55\u8bc4\u4f30\u6587\u5b66\u98ce\u683c\u8fd9\u4e00\u4e3b\u89c2\u9886\u57df\uff0c\u7279\u522b\u662f\u8bc4\u4f30\u4e2d\u7684\u5f52\u56e0\u504f\u89c1\u95ee\u9898\u3002", "method": "\u7814\u7a761\u6bd4\u8f83556\u540d\u4eba\u7c7b\u53c2\u4e0e\u8005\u548c13\u4e2aAI\u6a21\u578b\u5bf9Queneau\u539f\u4f5c\u4e0eGPT-4\u751f\u6210\u7248\u672c\u7684\u8bc4\u4f30\uff1b\u7814\u7a762\u6d4b\u8bd514\u00d714\u77e9\u9635\u7684AI\u8bc4\u4f30\u8005\u548c\u521b\u5efa\u8005\u4e4b\u95f4\u7684\u504f\u89c1\u6cdb\u5316\u3002", "result": "\u4eba\u7c7b\u8868\u73b0\u51fa+13.7\u767e\u5206\u70b9\u7684\u504f\u89c1\uff0cAI\u6a21\u578b\u8868\u73b0\u51fa+34.3\u767e\u5206\u70b9\u7684\u504f\u89c1\uff08\u662f\u4eba\u7c7b\u76842.5\u500d\uff09\u3002AI\u7cfb\u7edf\u5728\u6807\u8bb0\u4e3a'AI\u751f\u6210'\u65f6\u7cfb\u7edf\u6027\u5730\u8d2c\u4f4e\u521b\u610f\u5185\u5bb9\u3002", "conclusion": "AI\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5438\u6536\u4e86\u4eba\u7c7b\u5bf9\u4eba\u5de5\u521b\u9020\u529b\u7684\u6587\u5316\u504f\u89c1\uff0c\u4e0d\u4ec5\u590d\u5236\u800c\u4e14\u653e\u5927\u4e86\u8fd9\u79cd\u504f\u89c1\uff0c\u5bfc\u81f4\u8bc4\u4f30\u6807\u51c6\u57fa\u4e8e\u611f\u77e5\u4f5c\u8005\u8eab\u4efd\u800c\u53cd\u8f6c\u3002"}}
{"id": "2510.09433", "categories": ["cs.CR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2510.09433", "abs": "https://arxiv.org/abs/2510.09433", "authors": ["Raffaele Cristodaro", "Benjamin Kramer", "Claudio J. Tessone"], "title": "Clustering Deposit and Withdrawal Activity in Tornado Cash: A Cross-Chain Analysis", "comment": null, "summary": "Tornado Cash is a decentralised mixer that uses cryptographic techniques to\nsever the on-chain trail between depositors and withdrawers. In practice,\nhowever, its anonymity can be undermined by user behaviour and operational\nquirks. We conduct the first cross-chain empirical study of Tornado Cash\nactivity on Ethereum, BNB Smart Chain, and Polygon, introducing three\nclustering heuristics-(i) address-reuse, (ii) transactional-linkage, and (iii)\na novel first-in-first-out (FIFO) temporal-matching rule. Together, these\nheuristics reconnect deposits to withdrawals and deanonymise a substantial\nshare of recipients. Our analysis shows that 5.1 - 12.6% of withdrawals can\nalready be traced to their originating deposits through address reuse and\ntransactional linkage heuristics. Adding our novel First-In-First-Out (FIFO)\ntemporal-matching heuristic lifts the linkage rate by a further 15 - 22\npercentage points. Statistical tests confirm that these FIFO matches are highly\nunlikely to occur by chance. Comparable leakage across Ethereum, BNB Smart\nChain, and Polygon indicates chain-agnostic user misbehaviour, rather than\nchain-specific protocol flaws. These results expose how quickly cryptographic\nguarantees can unravel in everyday use, underscoring the need for both\ndisciplined user behaviour and privacy-aware protocol design. In total, our\nheuristics link over $2.3 billion in Tornado Cash withdrawals to identifiable\ndeposits, exposing significant cracks in practical anonymity.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf9Tornado Cash\u5728\u4ee5\u592a\u574a\u3001BNB\u667a\u80fd\u94fe\u548cPolygon\u4e0a\u7684\u6d3b\u52a8\u8fdb\u884c\u4e86\u9996\u6b21\u8de8\u94fe\u5b9e\u8bc1\u5206\u6790\uff0c\u901a\u8fc7\u4e09\u79cd\u805a\u7c7b\u542f\u53d1\u5f0f\u65b9\u6cd5\uff08\u5730\u5740\u590d\u7528\u3001\u4ea4\u6613\u94fe\u63a5\u548cFIFO\u65f6\u95f4\u5339\u914d\uff09\u6210\u529f\u5c06\u5927\u91cf\u63d0\u73b0\u4e0e\u5b58\u6b3e\u91cd\u65b0\u5173\u8054\uff0c\u66b4\u9732\u4e86\u5b9e\u9645\u533f\u540d\u6027\u7684\u663e\u8457\u7f3a\u9677\u3002", "motivation": "\u5c3d\u7ba1Tornado Cash\u4f7f\u7528\u52a0\u5bc6\u6280\u672f\u5207\u65ad\u5b58\u6b3e\u8005\u548c\u63d0\u73b0\u8005\u4e4b\u95f4\u7684\u94fe\u4e0a\u75d5\u8ff9\uff0c\u4f46\u7528\u6237\u884c\u4e3a\u548c\u64cd\u4f5c\u7279\u6027\u53ef\u80fd\u524a\u5f31\u5176\u533f\u540d\u6027\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u63ed\u793a\u5b9e\u9645\u4f7f\u7528\u4e2d\u7684\u533f\u540d\u6027\u6f0f\u6d1e\u3002", "method": "\u5f15\u5165\u4e09\u79cd\u805a\u7c7b\u542f\u53d1\u5f0f\u65b9\u6cd5\uff1a(i)\u5730\u5740\u590d\u7528\u542f\u53d1\u5f0f\uff0c(ii)\u4ea4\u6613\u94fe\u63a5\u542f\u53d1\u5f0f\uff0c(iii)\u65b0\u9896\u7684\u5148\u8fdb\u5148\u51fa(FIFO)\u65f6\u95f4\u5339\u914d\u89c4\u5219\u3002\u8fd9\u4e9b\u65b9\u6cd5\u5171\u540c\u7528\u4e8e\u91cd\u65b0\u5173\u8054\u5b58\u6b3e\u548c\u63d0\u73b0\u3002", "result": "\u4ec5\u901a\u8fc7\u5730\u5740\u590d\u7528\u548c\u4ea4\u6613\u94fe\u63a5\u542f\u53d1\u5f0f\u5c31\u80fd\u8ffd\u8e2a5.1-12.6%\u7684\u63d0\u73b0\u5230\u539f\u59cb\u5b58\u6b3e\uff0c\u52a0\u5165FIFO\u65f6\u95f4\u5339\u914d\u542f\u53d1\u5f0f\u540e\u5173\u8054\u7387\u518d\u63d0\u9ad815-22\u4e2a\u767e\u5206\u70b9\u3002\u7edf\u8ba1\u6d4b\u8bd5\u8bc1\u5b9e\u8fd9\u4e9bFIFO\u5339\u914d\u6781\u4e0d\u53ef\u80fd\u662f\u5076\u7136\u53d1\u751f\u3002\u603b\u8ba1\u5173\u8054\u4e86\u8d85\u8fc723\u4ebf\u7f8e\u5143\u7684Tornado Cash\u63d0\u73b0\u5230\u53ef\u8bc6\u522b\u5b58\u6b3e\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u52a0\u5bc6\u4fdd\u8bc1\u5728\u65e5\u5e38\u4f7f\u7528\u4e2d\u53ef\u80fd\u8fc5\u901f\u5931\u6548\uff0c\u5f3a\u8c03\u4e86\u89c4\u8303\u7528\u6237\u884c\u4e3a\u548c\u9690\u79c1\u611f\u77e5\u534f\u8bae\u8bbe\u8ba1\u7684\u5fc5\u8981\u6027\u3002\u8de8\u94fe\u53ef\u6bd4\u8f83\u7684\u6cc4\u9732\u8868\u660e\u8fd9\u662f\u94fe\u65e0\u5173\u7684\u7528\u6237\u4e0d\u5f53\u884c\u4e3a\uff0c\u800c\u975e\u7279\u5b9a\u94fe\u7684\u534f\u8bae\u7f3a\u9677\u3002"}}
{"id": "2510.08847", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.08847", "abs": "https://arxiv.org/abs/2510.08847", "authors": ["Allison Sihan Jia", "Daniel Huang", "Nikhil Vytla", "Nirvika Choudhury", "John C Mitchell", "Anupam Datta"], "title": "What Is Your Agent's GPA? A Framework for Evaluating Agent Goal-Plan-Action Alignment", "comment": null, "summary": "We introduce the Agent GPA (Goal-Plan-Action) framework: an evaluation\nparadigm based on an agent's operational loop of setting goals, devising plans,\nand executing actions. The framework includes five evaluation metrics: Goal\nFulfillment, Logical Consistency, Execution Efficiency, Plan Quality, and Plan\nAdherence. Logical Consistency checks that an agent's actions are consistent\nwith its prior actions. Execution Efficiency checks whether the agent executes\nin the most efficient way to achieve its goal. Plan Quality checks whether an\nagent's plans are aligned with its goals; Plan Adherence checks if an agent's\nactions are aligned with its plan; and Goal Fulfillment checks that agent's\nfinal outcomes match the stated goals. Our experimental results on two\nbenchmark datasets - the public TRAIL/GAIA dataset and an internal dataset for\na production-grade data agent - show that this framework (a) provides a\nsystematic way to cover a broad range of agent failures, including all agent\nerrors on the TRAIL/GAIA benchmark dataset; (b) supports LLM-judges that\nexhibit strong agreement with human annotation, covering 80% to over 95%\nerrors; and (c) localizes errors with 86% agreement to enable targeted\nimprovement of agent performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86Agent GPA\uff08\u76ee\u6807-\u8ba1\u5212-\u884c\u52a8\uff09\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u4e94\u4e2a\u8bc4\u4f30\u6307\u6807\uff1a\u76ee\u6807\u5b9e\u73b0\u3001\u903b\u8f91\u4e00\u81f4\u6027\u3001\u6267\u884c\u6548\u7387\u3001\u8ba1\u5212\u8d28\u91cf\u548c\u8ba1\u5212\u9075\u5faa\u3002\u8be5\u6846\u67b6\u80fd\u7cfb\u7edf\u6027\u5730\u8986\u76d6\u5e7f\u6cdb\u7684\u667a\u80fd\u4f53\u5931\u8d25\u60c5\u51b5\uff0c\u652f\u6301LLM\u8bc4\u4f30\u5668\u4e0e\u4eba\u5de5\u6807\u6ce8\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5e76\u80fd\u51c6\u786e\u5b9a\u4f4d\u9519\u8bef\u4ee5\u6539\u8fdb\u667a\u80fd\u4f53\u6027\u80fd\u3002", "motivation": "\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u6027\u7684\u8bc4\u4f30\u8303\u5f0f\u6765\u8bc4\u4f30\u667a\u80fd\u4f53\u7684\u64cd\u4f5c\u5faa\u73af\uff08\u8bbe\u5b9a\u76ee\u6807\u3001\u5236\u5b9a\u8ba1\u5212\u3001\u6267\u884c\u884c\u52a8\uff09\uff0c\u4ee5\u5168\u9762\u8986\u76d6\u667a\u80fd\u4f53\u7684\u5404\u79cd\u5931\u8d25\u6a21\u5f0f\u3002", "method": "\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u76ee\u6807-\u8ba1\u5212-\u884c\u52a8\u64cd\u4f5c\u5faa\u73af\u6784\u5efa\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u4e94\u4e2a\u6838\u5fc3\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u5728TRAIL/GAIA\u516c\u5f00\u6570\u636e\u96c6\u548c\u751f\u4ea7\u7ea7\u6570\u636e\u667a\u80fd\u4f53\u7684\u5185\u90e8\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a\u8be5\u6846\u67b6\u80fd\u8986\u76d6TRAIL/GAIA\u57fa\u51c6\u6570\u636e\u96c6\u4e2d\u7684\u6240\u6709\u667a\u80fd\u4f53\u9519\u8bef\uff1bLLM\u8bc4\u4f30\u5668\u4e0e\u4eba\u5de5\u6807\u6ce8\u7684\u4e00\u81f4\u6027\u8fbe\u523080%-95%\u4ee5\u4e0a\uff1b\u9519\u8bef\u5b9a\u4f4d\u51c6\u786e\u7387\u8fbe\u523086%\u3002", "conclusion": "Agent GPA\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u548c\u8bca\u65ad\u667a\u80fd\u4f53\u6027\u80fd\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u548c\u5b9a\u4f4d\u5404\u79cd\u7c7b\u578b\u7684\u667a\u80fd\u4f53\u5931\u8d25\uff0c\u4e3a\u667a\u80fd\u4f53\u6027\u80fd\u7684\u9488\u5bf9\u6027\u6539\u8fdb\u63d0\u4f9b\u4e86\u6709\u529b\u652f\u6301\u3002"}}
{"id": "2510.09443", "categories": ["cs.CR", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.09443", "abs": "https://arxiv.org/abs/2510.09443", "authors": ["Raffaele Cristodaro", "Benjamin Kramer", "Claudio J. Tessone"], "title": "The Impact of Sanctions on decentralised Privacy Tools: A Case Study of Tornado Cash", "comment": null, "summary": "This paper investigates the impact of sanctions on Tornado Cash, a smart\ncontract protocol designed to enhance transaction privacy. Following the U.S.\nDepartment of the Treasury's sanctions against Tornado Cash in August 2022,\nplatform activity declined sharply. We document a significant and sustained\nreduction in transaction volume, user diversity, and overall protocol\nutilization after the sanctions were imposed. Our analysis draws on transaction\ndata from three major blockchains: Ethereum, BNB Smart Chain, and Polygon. We\nfurther examine developments following the partial lifting and eventual removal\nof sanctions by the U.S. Office of Foreign Assets Control (OFAC) in March 2025.\nAlthough activity partially recovered, the rebound remained limited. The\nTornado Cash case illustrates how regulatory interventions can affect\ndecentralized protocols, while also highlighting the challenges of fully\nenforcing such measures in decentralized environments.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7f8e\u56fd\u5bf9Tornado Cash\u7684\u5236\u88c1\u5f71\u54cd\uff0c\u53d1\u73b0\u57282022\u5e748\u6708\u5236\u88c1\u5b9e\u65bd\u540e\uff0c\u8be5\u9690\u79c1\u534f\u8bae\u7684\u4ea4\u6613\u91cf\u3001\u7528\u6237\u591a\u6837\u6027\u548c\u6574\u4f53\u4f7f\u7528\u7387\u663e\u8457\u4e0b\u964d\uff0c\u5c3d\u7ba12025\u5e743\u6708\u5236\u88c1\u90e8\u5206\u89e3\u9664\u540e\u6d3b\u52a8\u6709\u6240\u6062\u590d\uff0c\u4f46\u53cd\u5f39\u6709\u9650\u3002", "motivation": "\u7814\u7a76\u76d1\u7ba1\u5e72\u9884\u5bf9\u53bb\u4e2d\u5fc3\u5316\u534f\u8bae\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u7f8e\u56fd\u8d22\u653f\u90e8\u5bf9Tornado Cash\u7684\u5236\u88c1\u5982\u4f55\u5f71\u54cd\u8be5\u9690\u79c1\u589e\u5f3a\u534f\u8bae\u7684\u8fd0\u4f5c\u3002", "method": "\u57fa\u4e8e\u4ee5\u592a\u574a\u3001BNB\u667a\u80fd\u94fe\u548cPolygon\u4e09\u5927\u533a\u5757\u94fe\u7684\u4ea4\u6613\u6570\u636e\u8fdb\u884c\u5206\u6790\uff0c\u8ffd\u8e2a\u5236\u88c1\u524d\u540e\u7684\u5e73\u53f0\u6d3b\u52a8\u53d8\u5316\u3002", "result": "\u5236\u88c1\u5bfc\u81f4Tornado Cash\u7684\u4ea4\u6613\u91cf\u3001\u7528\u6237\u591a\u6837\u6027\u548c\u534f\u8bae\u4f7f\u7528\u7387\u663e\u8457\u4e14\u6301\u7eed\u4e0b\u964d\uff1b\u5236\u88c1\u90e8\u5206\u89e3\u9664\u540e\u6d3b\u52a8\u4ec5\u90e8\u5206\u6062\u590d\uff0c\u53cd\u5f39\u6709\u9650\u3002", "conclusion": "Tornado Cash\u6848\u4f8b\u8868\u660e\u76d1\u7ba1\u5e72\u9884\u80fd\u591f\u5f71\u54cd\u53bb\u4e2d\u5fc3\u5316\u534f\u8bae\uff0c\u4f46\u4e5f\u51f8\u663e\u4e86\u5728\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\u4e2d\u5b8c\u5168\u6267\u884c\u6b64\u7c7b\u63aa\u65bd\u7684\u6311\u6218\u3002"}}
{"id": "2510.08867", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.08867", "abs": "https://arxiv.org/abs/2510.08867", "authors": ["Gaurav Sahu", "Hugo Larochelle", "Laurent Charlin", "Christopher Pal"], "title": "ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review", "comment": null, "summary": "Peer review is the cornerstone of scientific publishing, yet it suffers from\ninconsistencies, reviewer subjectivity, and scalability challenges. We\nintroduce ReviewerToo, a modular framework for studying and deploying\nAI-assisted peer review to complement human judgment with systematic and\nconsistent assessments. ReviewerToo supports systematic experiments with\nspecialized reviewer personas and structured evaluation criteria, and can be\npartially or fully integrated into real conference workflows. We validate\nReviewerToo on a carefully curated dataset of 1,963 paper submissions from ICLR\n2025, where our experiments with the gpt-oss-120b model achieves 81.8% accuracy\nfor the task of categorizing a paper as accept/reject compared to 83.9% for the\naverage human reviewer. Additionally, ReviewerToo-generated reviews are rated\nas higher quality than the human average by an LLM judge, though still trailing\nthe strongest expert contributions. Our analysis highlights domains where AI\nreviewers excel (e.g., fact-checking, literature coverage) and where they\nstruggle (e.g., assessing methodological novelty and theoretical\ncontributions), underscoring the continued need for human expertise. Based on\nthese findings, we propose guidelines for integrating AI into peer-review\npipelines, showing how AI can enhance consistency, coverage, and fairness while\nleaving complex evaluative judgments to domain experts. Our work provides a\nfoundation for systematic, hybrid peer-review systems that scale with the\ngrowth of scientific publishing.", "AI": {"tldr": "ReviewerToo\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u7814\u7a76\u548c\u90e8\u7f72AI\u8f85\u52a9\u540c\u884c\u8bc4\u5ba1\uff0c\u5728ICLR 2025\u6570\u636e\u96c6\u4e0a\u8fbe\u523081.8%\u7684\u63a5\u53d7/\u62d2\u7edd\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u63a5\u8fd1\u4eba\u7c7b\u8bc4\u5ba1\u5458\u768483.9%\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u540c\u884c\u8bc4\u5ba1\u5b58\u5728\u7684\u4e0d\u4e00\u81f4\u6027\u3001\u8bc4\u5ba1\u5458\u4e3b\u89c2\u6027\u548c\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u901a\u8fc7AI\u8f85\u52a9\u6765\u8865\u5145\u4eba\u7c7b\u5224\u65ad\u3002", "method": "\u5f00\u53d1ReviewerToo\u6846\u67b6\uff0c\u652f\u6301\u4e13\u95e8\u7684\u8bc4\u5ba1\u5458\u89d2\u8272\u548c\u7ed3\u6784\u5316\u8bc4\u4f30\u6807\u51c6\uff0c\u5728ICLR 2025\u76841,963\u7bc7\u8bba\u6587\u63d0\u4ea4\u4e0a\u8fdb\u884c\u9a8c\u8bc1\uff0c\u4f7f\u7528gpt-oss-120b\u6a21\u578b\u3002", "result": "AI\u8bc4\u5ba1\u5458\u5728\u4e8b\u5b9e\u6838\u67e5\u548c\u6587\u732e\u8986\u76d6\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u8bc4\u4f30\u65b9\u6cd5\u65b0\u9896\u6027\u548c\u7406\u8bba\u8d21\u732e\u65b9\u9762\u4ecd\u6709\u56f0\u96be\uff1bAI\u751f\u6210\u7684\u8bc4\u5ba1\u8d28\u91cf\u9ad8\u4e8e\u4eba\u7c7b\u5e73\u5747\u6c34\u5e73\uff0c\u4f46\u4ecd\u843d\u540e\u4e8e\u6700\u5f3a\u4e13\u5bb6\u3002", "conclusion": "AI\u53ef\u4ee5\u589e\u5f3a\u540c\u884c\u8bc4\u5ba1\u7684\u4e00\u81f4\u6027\u3001\u8986\u76d6\u8303\u56f4\u548c\u516c\u5e73\u6027\uff0c\u4f46\u590d\u6742\u8bc4\u4f30\u4ecd\u9700\u9886\u57df\u4e13\u5bb6\uff1b\u63d0\u51fa\u4e86\u5c06AI\u6574\u5408\u5230\u540c\u884c\u8bc4\u5ba1\u6d41\u7a0b\u7684\u6307\u5357\uff0c\u4e3a\u6df7\u5408\u8bc4\u5ba1\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2510.08872", "categories": ["cs.AI", "cs.GT", "cs.HC", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.08872", "abs": "https://arxiv.org/abs/2510.08872", "authors": ["Siqi Zhu", "David Zhang", "Pedro Cisneros-Velarde", "Jiaxuan You"], "title": "GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare", "comment": "31 pages, 6 figures", "summary": "Large Language Models (LLMs) have achieved remarkable progress in reasoning,\nyet sometimes produce responses that are suboptimal for users in tasks such as\nwriting, information seeking, or providing practical guidance. Conventional\nalignment practices typically assume that maximizing model reward also\nmaximizes user welfare, but this assumption frequently fails in practice:\nmodels may over-clarify or generate overly verbose reasoning when users prefer\nconcise answers. Such behaviors resemble the prisoner's dilemma, where\nindividually rational choices lead to socially suboptimal outcomes. The\nfundamental challenge is the lack of a principled decision making mechanism\nthat mutually benefits both the LLM and the user. We propose Game-Theoretic\nAlignment (GTAlign), an alignment framework that integrates game-theoretic\ndecision making into both reasoning and training. During reasoning, the model\nexplicitly treats user-LLM interaction as a strategic game: it constructs\npayoff matrices within its reasoning chain to estimate welfare for both itself\nand the user, and then selects actions that are mutually beneficial. During\ntraining, we introduce a mutual welfare reward that reinforces cooperative\nresponses, aligning model behavior with socially efficient outcomes. In\naddition, we introduce an inference technique that leverages game-theoretic\nreasoning to dynamically adapt LLM's response when pricing policies of LLM\nservice change. Extensive experiments demonstrate that GTAlign substantially\nimproves reasoning efficiency, answer quality, and mutual welfare compared to\nbaselines across diverse tasks. The code is available at\nhttps://github.com/ulab-uiuc/GTAlign .", "AI": {"tldr": "GTAlign\u662f\u4e00\u4e2a\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5c06\u7528\u6237-LLM\u4ea4\u4e92\u5efa\u6a21\u4e3a\u6218\u7565\u6e38\u620f\uff0c\u5e76\u5728\u8bad\u7ec3\u4e2d\u5f15\u5165\u76f8\u4e92\u798f\u5229\u5956\u52b1\uff0c\u6765\u4f18\u5316LLM\u7684\u54cd\u5e94\u8d28\u91cf\u548c\u793e\u4f1a\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u5bf9\u9f50\u65b9\u6cd5\u5047\u8bbe\u6700\u5927\u5316\u6a21\u578b\u5956\u52b1\u7b49\u540c\u4e8e\u6700\u5927\u5316\u7528\u6237\u798f\u5229\uff0c\u4f46\u5b9e\u8df5\u4e2dLLM\u53ef\u80fd\u4ea7\u751f\u8fc7\u4e8e\u5197\u957f\u6216\u6b21\u4f18\u7684\u54cd\u5e94\uff0c\u7c7b\u4f3c\u4e8e\u56da\u5f92\u56f0\u5883\u4e2d\u7684\u793e\u4f1a\u6b21\u4f18\u7ed3\u679c\u3002", "method": "\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6784\u5efa\u6536\u76ca\u77e9\u9635\u8bc4\u4f30\u53cc\u65b9\u798f\u5229\uff0c\u9009\u62e9\u4e92\u5229\u884c\u52a8\uff1b\u5728\u8bad\u7ec3\u4e2d\u5f15\u5165\u76f8\u4e92\u798f\u5229\u5956\u52b1\u5f3a\u5316\u5408\u4f5c\u54cd\u5e94\uff1b\u8fd8\u5305\u542b\u57fa\u4e8e\u535a\u5f08\u8bba\u63a8\u7406\u7684\u52a8\u6001\u9002\u5e94\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u8868\u660eGTAlign\u5728\u591a\u6837\u5316\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\u3001\u7b54\u6848\u8d28\u91cf\u548c\u76f8\u4e92\u798f\u5229\u3002", "conclusion": "GTAlign\u901a\u8fc7\u535a\u5f08\u8bba\u51b3\u7b56\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86LLM\u5bf9\u9f50\u4e2d\u7684\u793e\u4f1a\u6548\u7387\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7528\u6237\u548c\u6a21\u578b\u7684\u53cc\u8d62\u3002"}}
{"id": "2510.08931", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08931", "abs": "https://arxiv.org/abs/2510.08931", "authors": ["Ashish Kattamuri", "Harshwardhan Fartale", "Arpita Vats", "Rahul Raja", "Ishita Prasad"], "title": "RADAR: Mechanistic Pathways for Detecting Data Contamination in LLM Evaluation", "comment": "NeurIPS 2025 Workshop on Evaluating the Evolving LLM Lifecycle:\n  Benchmarks, Emergent Abilities, and Scaling", "summary": "Data contamination poses a significant challenge to reliable LLM evaluation,\nwhere models may achieve high performance by memorizing training data rather\nthan demonstrating genuine reasoning capabilities. We introduce RADAR (Recall\nvs. Reasoning Detection through Activation Representation), a novel framework\nthat leverages mechanistic interpretability to detect contamination by\ndistinguishing recall-based from reasoning-based model responses. RADAR\nextracts 37 features spanning surface-level confidence trajectories and deep\nmechanistic properties including attention specialization, circuit dynamics,\nand activation flow patterns. Using an ensemble of classifiers trained on these\nfeatures, RADAR achieves 93\\% accuracy on a diverse evaluation set, with\nperfect performance on clear cases and 76.7\\% accuracy on challenging ambiguous\nexamples. This work demonstrates the potential of mechanistic interpretability\nfor advancing LLM evaluation beyond traditional surface-level metrics.", "AI": {"tldr": "RADAR\u662f\u4e00\u4e2a\u901a\u8fc7\u673a\u5236\u53ef\u89e3\u91ca\u6027\u68c0\u6d4bLLM\u6570\u636e\u6c61\u67d3\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u533a\u5206\u57fa\u4e8e\u8bb0\u5fc6\u548c\u57fa\u4e8e\u63a8\u7406\u7684\u6a21\u578b\u54cd\u5e94\uff0c\u4f7f\u752837\u4e2a\u7279\u5f81\u5b9e\u73b093%\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u6570\u636e\u6c61\u67d3\u5bf9\u53ef\u9760\u7684LLM\u8bc4\u4f30\u6784\u6210\u91cd\u5927\u6311\u6218\uff0c\u6a21\u578b\u53ef\u80fd\u901a\u8fc7\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\u800c\u975e\u5c55\u793a\u771f\u6b63\u63a8\u7406\u80fd\u529b\u6765\u83b7\u5f97\u9ad8\u6027\u80fd\u8868\u73b0\u3002", "method": "RADAR\u63d0\u53d637\u4e2a\u7279\u5f81\uff0c\u6db5\u76d6\u8868\u9762\u7ea7\u7f6e\u4fe1\u5ea6\u8f68\u8ff9\u548c\u6df1\u5c42\u673a\u5236\u7279\u6027\uff0c\u5305\u62ec\u6ce8\u610f\u529b\u4e13\u4e1a\u5316\u3001\u7535\u8def\u52a8\u6001\u548c\u6fc0\u6d3b\u6d41\u6a21\u5f0f\uff0c\u4f7f\u7528\u8fd9\u4e9b\u7279\u5f81\u7684\u5206\u7c7b\u5668\u96c6\u6210\u8fdb\u884c\u68c0\u6d4b\u3002", "result": "RADAR\u5728\u591a\u6837\u5316\u8bc4\u4f30\u96c6\u4e0a\u8fbe\u523093%\u7684\u51c6\u786e\u7387\uff0c\u5728\u6e05\u6670\u6848\u4f8b\u4e0a\u8868\u73b0\u5b8c\u7f8e\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u6a21\u7cca\u793a\u4f8b\u4e0a\u8fbe\u523076.7%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u673a\u5236\u53ef\u89e3\u91ca\u6027\u5728\u8d85\u8d8a\u4f20\u7edf\u8868\u9762\u7ea7\u6307\u6807\u63a8\u8fdbLLM\u8bc4\u4f30\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.08945", "categories": ["cs.AI", "I.7.5; I.2.1; I.2.8; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.08945", "abs": "https://arxiv.org/abs/2510.08945", "authors": ["Samuel Hildebrand", "Curtis Taylor", "Sean Oesch", "James M Ghawaly Jr", "Amir Sadovnik", "Ryan Shivers", "Brandon Schreiber", "Kevin Kurian"], "title": "FATHOMS-RAG: A Framework for the Assessment of Thinking and Observation in Multimodal Systems that use Retrieval Augmented Generation", "comment": null, "summary": "Retrieval-augmented generation (RAG) has emerged as a promising paradigm for\nimproving factual accuracy in large language models (LLMs). We introduce a\nbenchmark designed to evaluate RAG pipelines as a whole, evaluating a\npipeline's ability to ingest, retrieve, and reason about several modalities of\ninformation, differentiating it from existing benchmarks that focus on\nparticular aspects such as retrieval. We present (1) a small, human-created\ndataset of 93 questions designed to evaluate a pipeline's ability to ingest\ntextual data, tables, images, and data spread across these modalities in one or\nmore documents; (2) a phrase-level recall metric for correctness; (3) a\nnearest-neighbor embedding classifier to identify potential pipeline\nhallucinations; (4) a comparative evaluation of 2 pipelines built with\nopen-source retrieval mechanisms and 4 closed-source foundation models; and (5)\na third-party human evaluation of the alignment of our correctness and\nhallucination metrics. We find that closed-source pipelines significantly\noutperform open-source pipelines in both correctness and hallucination metrics,\nwith wider performance gaps in questions relying on multimodal and\ncross-document information. Human evaluation of our metrics showed average\nagreement of 4.62 for correctness and 4.53 for hallucination detection on a 1-5\nLikert scale (5 indicating \"strongly agree\").", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7ba1\u9053\u7684\u57fa\u51c6\uff0c\u5305\u62ec\u591a\u6a21\u6001\u4fe1\u606f\u5904\u7406\u80fd\u529b\u8bc4\u4f30\u3001\u77ed\u8bed\u7ea7\u53ec\u56de\u6307\u6807\u3001\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5e76\u5bf9\u5f00\u6e90\u548c\u95ed\u6e90\u7cfb\u7edf\u8fdb\u884c\u4e86\u6bd4\u8f83\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u68c0\u7d22\u7b49\u7279\u5b9a\u65b9\u9762\uff0c\u7f3a\u4e4f\u5bf9RAG\u7ba1\u9053\u6574\u4f53\u80fd\u529b\u7684\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u591a\u6a21\u6001\u4fe1\u606f\u5904\u7406\u80fd\u529b\u3002", "method": "\u521b\u5efa\u4e8693\u4e2a\u95ee\u9898\u7684\u6570\u636e\u96c6\u8bc4\u4f30\u6587\u672c\u3001\u8868\u683c\u3001\u56fe\u50cf\u7b49\u591a\u6a21\u6001\u4fe1\u606f\u5904\u7406\uff1b\u63d0\u51fa\u77ed\u8bed\u7ea7\u53ec\u56de\u6307\u6807\u548c\u6700\u8fd1\u90bb\u5d4c\u5165\u5206\u7c7b\u5668\u68c0\u6d4b\u5e7b\u89c9\uff1b\u6bd4\u8f83\u4e862\u4e2a\u5f00\u6e90\u548c4\u4e2a\u95ed\u6e90\u7cfb\u7edf\u3002", "result": "\u95ed\u6e90\u7ba1\u9053\u5728\u6b63\u786e\u6027\u548c\u5e7b\u89c9\u68c0\u6d4b\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5f00\u6e90\u7ba1\u9053\uff0c\u7279\u522b\u662f\u5728\u591a\u6a21\u6001\u548c\u8de8\u6587\u6863\u95ee\u9898\u4e0a\uff1b\u4eba\u5de5\u8bc4\u4f30\u663e\u793a\u6307\u6807\u4e0e\u4eba\u7c7b\u5224\u65ad\u9ad8\u5ea6\u4e00\u81f4\uff084.62/5\u548c4.53/5\uff09\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u51c6\u80fd\u591f\u6709\u6548\u8bc4\u4f30RAG\u7ba1\u9053\u7684\u6574\u4f53\u6027\u80fd\uff0c\u95ed\u6e90\u7cfb\u7edf\u5728\u591a\u6a21\u6001\u4fe1\u606f\u5904\u7406\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u8bc4\u4f30\u6307\u6807\u4e0e\u4eba\u7c7b\u5224\u65ad\u5177\u6709\u826f\u597d\u4e00\u81f4\u6027\u3002"}}
{"id": "2510.08958", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.08958", "abs": "https://arxiv.org/abs/2510.08958", "authors": ["Zirui Liao"], "title": "EcphoryRAG: Re-Imagining Knowledge-Graph RAG via Human Associative Memory", "comment": null, "summary": "Cognitive neuroscience research indicates that humans leverage cues to\nactivate entity-centered memory traces (engrams) for complex, multi-hop\nrecollection. Inspired by this mechanism, we introduce EcphoryRAG, an\nentity-centric knowledge graph RAG framework. During indexing, EcphoryRAG\nextracts and stores only core entities with corresponding metadata, a\nlightweight approach that reduces token consumption by up to 94\\% compared to\nother structured RAG systems. For retrieval, the system first extracts cue\nentities from queries, then performs a scalable multi-hop associative search\nacross the knowledge graph. Crucially, EcphoryRAG dynamically infers implicit\nrelations between entities to populate context, enabling deep reasoning without\nexhaustive pre-enumeration of relationships. Extensive evaluations on the\n2WikiMultiHop, HotpotQA, and MuSiQue benchmarks demonstrate that EcphoryRAG\nsets a new state-of-the-art, improving the average Exact Match (EM) score from\n0.392 to 0.474 over strong KG-RAG methods like HippoRAG. These results validate\nthe efficacy of the entity-cue-multi-hop retrieval paradigm for complex\nquestion answering.", "AI": {"tldr": "EcphoryRAG\u662f\u4e00\u4e2a\u57fa\u4e8e\u5b9e\u4f53\u4e2d\u5fc3\u77e5\u8bc6\u56fe\u8c31\u7684RAG\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u53d6\u548c\u5b58\u50a8\u6838\u5fc3\u5b9e\u4f53\u53ca\u5176\u5143\u6570\u636e\uff0c\u5728\u7d22\u5f15\u9636\u6bb5\u51cf\u5c1194%\u7684token\u6d88\u8017\u3002\u68c0\u7d22\u65f6\u901a\u8fc7\u63d0\u53d6\u67e5\u8be2\u4e2d\u7684\u7ebf\u7d22\u5b9e\u4f53\uff0c\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u8fdb\u884c\u53ef\u6269\u5c55\u7684\u591a\u8df3\u5173\u8054\u641c\u7d22\uff0c\u5e76\u52a8\u6001\u63a8\u65ad\u5b9e\u4f53\u95f4\u7684\u9690\u542b\u5173\u7cfb\u6765\u586b\u5145\u4e0a\u4e0b\u6587\uff0c\u5b9e\u73b0\u6df1\u5ea6\u63a8\u7406\u3002", "motivation": "\u53d7\u4eba\u7c7b\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\uff0c\u4eba\u7c7b\u5229\u7528\u7ebf\u7d22\u6fc0\u6d3b\u5b9e\u4f53\u4e2d\u5fc3\u8bb0\u5fc6\u75d5\u8ff9\u8fdb\u884c\u590d\u6742\u591a\u8df3\u56de\u5fc6\u3002\u4f5c\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u4e2a\u7c7b\u4f3c\u7684\u5b9e\u4f53\u4e2d\u5fc3\u77e5\u8bc6\u56fe\u8c31RAG\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7d22\u5f15\u548c\u52a8\u6001\u5173\u7cfb\u63a8\u65ad\u6765\u63d0\u5347\u590d\u6742\u95ee\u7b54\u6027\u80fd\u3002", "method": "1. \u7d22\u5f15\u9636\u6bb5\u4ec5\u63d0\u53d6\u548c\u5b58\u50a8\u6838\u5fc3\u5b9e\u4f53\u53ca\u5176\u5143\u6570\u636e\uff1b2. \u68c0\u7d22\u9636\u6bb5\u63d0\u53d6\u67e5\u8be2\u4e2d\u7684\u7ebf\u7d22\u5b9e\u4f53\uff1b3. \u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u8fdb\u884c\u591a\u8df3\u5173\u8054\u641c\u7d22\uff1b4. \u52a8\u6001\u63a8\u65ad\u5b9e\u4f53\u95f4\u7684\u9690\u542b\u5173\u7cfb\u6765\u586b\u5145\u4e0a\u4e0b\u6587\u3002", "result": "\u57282WikiMultiHop\u3001HotpotQA\u548cMuSiQue\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEcphoryRAG\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u5c06\u5e73\u5747\u7cbe\u786e\u5339\u914d\u5206\u6570\u4ece0.392\u63d0\u5347\u52300.474\uff0c\u76f8\u6bd4HippoRAG\u7b49\u5f3aKG-RAG\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u5b9e\u4f53-\u7ebf\u7d22-\u591a\u8df3\u68c0\u7d22\u8303\u5f0f\u5728\u590d\u6742\u95ee\u7b54\u4efb\u52a1\u4e2d\u5177\u6709\u663e\u8457\u6548\u679c\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.08959", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08959", "abs": "https://arxiv.org/abs/2510.08959", "authors": ["Jinxin Shi", "Zongsheng Cao", "Runmin Ma", "Yusong Hu", "Jie Zhou", "Xin Li", "Lei Bai", "Liang He", "Bo Zhang"], "title": "DualResearch: Entropy-Gated Dual-Graph Retrieval for Answer Reconstruction", "comment": "16 pages, 6 figures, 5 tables, Under Review", "summary": "The deep-research framework orchestrates external tools to perform complex,\nmulti-step scientific reasoning that exceeds the native limits of a single\nlarge language model. However, it still suffers from context pollution, weak\nevidentiary support, and brittle execution paths. To address these issues, we\npropose DualResearch, a retrieval and fusion framework that matches the\nepistemic structure of tool-intensive reasoning by jointly modeling two\ncomplementary graphs: a breadth semantic graph that encodes stable background\nknowledge, and a depth causal graph that captures execution provenance. Each\ngraph has a layer-native relevance function, seed-anchored semantic diffusion\nfor breadth, and causal-semantic path matching with reliability weighting for\ndepth. To reconcile their heterogeneity and query-dependent uncertainty,\nDualResearch converts per-layer path evidence into answer distributions and\nfuses them in log space via an entropy-gated rule with global calibration. The\nfusion up-weights the more certain channel and amplifies agreement. As a\ncomplement to deep-research systems, DualResearch compresses lengthy multi-tool\nexecution logs into a concise reasoning graph, and we show that it can\nreconstruct answers stably and effectively. On the scientific reasoning\nbenchmarks HLE and GPQA, DualResearch achieves competitive performance. Using\nlog files from the open-source system InternAgent, its accuracy improves by\n7.7% on HLE and 6.06% on GPQA.", "AI": {"tldr": "DualResearch\u662f\u4e00\u4e2a\u68c0\u7d22\u548c\u878d\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u5efa\u6a21\u5e7f\u5ea6\u8bed\u4e49\u56fe\u548c\u6df1\u5ea6\u56e0\u679c\u56fe\u6765\u89e3\u51b3\u6df1\u5ea6\u7814\u7a76\u6846\u67b6\u4e2d\u7684\u4e0a\u4e0b\u6587\u6c61\u67d3\u3001\u8bc1\u636e\u652f\u6301\u8584\u5f31\u548c\u6267\u884c\u8def\u5f84\u8106\u5f31\u7b49\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79d1\u5b66\u63a8\u7406\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u7814\u7a76\u6846\u67b6\u867d\u7136\u80fd\u591f\u534f\u8c03\u5916\u90e8\u5de5\u5177\u8fdb\u884c\u590d\u6742\u7684\u591a\u6b65\u9aa4\u79d1\u5b66\u63a8\u7406\uff0c\u4f46\u4ecd\u5b58\u5728\u4e0a\u4e0b\u6587\u6c61\u67d3\u3001\u8bc1\u636e\u652f\u6301\u8584\u5f31\u548c\u6267\u884c\u8def\u5f84\u8106\u5f31\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faDualResearch\u6846\u67b6\uff0c\u8054\u5408\u5efa\u6a21\u4e24\u4e2a\u4e92\u8865\u56fe\uff1a\u5e7f\u5ea6\u8bed\u4e49\u56fe\u7f16\u7801\u7a33\u5b9a\u7684\u80cc\u666f\u77e5\u8bc6\uff0c\u6df1\u5ea6\u56e0\u679c\u56fe\u6355\u83b7\u6267\u884c\u6765\u6e90\u3002\u6bcf\u4e2a\u56fe\u90fd\u6709\u5c42\u539f\u751f\u76f8\u5173\u6027\u51fd\u6570\uff0c\u5e7f\u5ea6\u4f7f\u7528\u79cd\u5b50\u951a\u5b9a\u7684\u8bed\u4e49\u6269\u6563\uff0c\u6df1\u5ea6\u4f7f\u7528\u56e0\u679c\u8bed\u4e49\u8def\u5f84\u5339\u914d\u548c\u53ef\u9760\u6027\u52a0\u6743\u3002\u901a\u8fc7\u71b5\u95e8\u63a7\u89c4\u5219\u5728log\u7a7a\u95f4\u878d\u5408\u7b54\u6848\u5206\u5e03\u3002", "result": "\u5728\u79d1\u5b66\u63a8\u7406\u57fa\u51c6HLE\u548cGPQA\u4e0a\u8868\u73b0\u51fa\u7ade\u4e89\u529b\u3002\u4f7f\u7528\u5f00\u6e90\u7cfb\u7edfInternAgent\u7684\u65e5\u5fd7\u6587\u4ef6\uff0c\u5728HLE\u4e0a\u7684\u51c6\u786e\u7387\u63d0\u9ad8\u4e867.7%\uff0c\u5728GPQA\u4e0a\u63d0\u9ad8\u4e866.06%\u3002", "conclusion": "DualResearch\u4f5c\u4e3a\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u7684\u8865\u5145\uff0c\u80fd\u591f\u5c06\u5197\u957f\u7684\u591a\u5de5\u5177\u6267\u884c\u65e5\u5fd7\u538b\u7f29\u4e3a\u7b80\u6d01\u7684\u63a8\u7406\u56fe\uff0c\u7a33\u5b9a\u6709\u6548\u5730\u91cd\u6784\u7b54\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79d1\u5b66\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2510.08987", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08987", "abs": "https://arxiv.org/abs/2510.08987", "authors": ["Qixiang Yin", "Huanjin Yao", "Jianghao Chen", "Jiaxing Huang", "Zhicheng Zhao", "Fei Su"], "title": "Tiny-R1V: Lightweight Multimodal Unified Reasoning Model via Model Merging", "comment": "Technical report, Code will be available at\n  https://github.com/buptyqx/Tiny-R1V", "summary": "Although Multimodal Large Language Models (MLLMs) have demonstrated\nremarkable capabilities across diverse tasks, they encounter numerous\nchallenges in terms of reasoning efficiency, such as large model size,\noverthinking, and compromised accuracy in lightweight scenarios. However,\nresearch on the reasoning capabilities of lightweight MLLMs is quite lacking.\nTo this end, we propose Tiny-R1V, a novel lightweight 3B model that achieves\nfaster inference and higher accuracy via a two-stage optimization, while\nunifying multimodal reasoning across multiple tasks and using fewer tokens. In\nthe first stage, Tiny-R1V introduces Length-Informed Relative Policy\nOptimization (LIPO), a novel reinforcement learning method, to train each\nreasoning model. The LIPO is designed to dynamically adjusts advantages of\nresponses within groups, that is, by prioritizing concise yet high-quality\nresponses to encourage the generation of shorter and more accurate response. In\nthe second stage, we propose Adaptive Model Merging (AMM), a training-free\nmodel merging method that merges multiple specialist models into a unified\narchitecture. Specifically, AMM adaptively adjusts the weights of task vectors\nand robustly optimizes the merged vectors via a novel gradient projection\nregularization loss function, thus mitigating redundant conflicts between them.\nExtensive evaluations on ten widely-used reasoning benchmarks covering\nmathematics, structured data (charts, tables, documents), OCR, and general\ncapabilities showcase the superior performance of Tiny-R1V, enabling\nlightweight models to excel in diverse multimodal reasoning tasks.", "AI": {"tldr": "Tiny-R1V\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u76843B\u53c2\u6570\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u4f18\u5316\u5b9e\u73b0\u66f4\u5feb\u7684\u63a8\u7406\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u7edf\u4e00\u4e86\u591a\u4efb\u52a1\u591a\u6a21\u6001\u63a8\u7406\uff0c\u540c\u65f6\u4f7f\u7528\u66f4\u5c11\u7684token\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u6548\u7387\u65b9\u9762\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u5982\u6a21\u578b\u89c4\u6a21\u5927\u3001\u8fc7\u5ea6\u601d\u8003\u4ee5\u53ca\u5728\u8f7b\u91cf\u7ea7\u573a\u666f\u4e0b\u51c6\u786e\u6027\u53d7\u635f\u3002\u7136\u800c\uff0c\u5173\u4e8e\u8f7b\u91cf\u7ea7MLLM\u63a8\u7406\u80fd\u529b\u7684\u7814\u7a76\u76f8\u5f53\u7f3a\u4e4f\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u4f18\u5316\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u5f15\u5165LIPO\uff08\u957f\u5ea6\u611f\u77e5\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff09\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u52a8\u6001\u8c03\u6574\u7ec4\u5185\u54cd\u5e94\u4f18\u52bf\uff0c\u4f18\u5148\u8003\u8651\u7b80\u6d01\u9ad8\u8d28\u91cf\u54cd\u5e94\uff1b\u7b2c\u4e8c\u9636\u6bb5\u63d0\u51faAMM\uff08\u81ea\u9002\u5e94\u6a21\u578b\u5408\u5e76\uff09\uff0c\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u5c06\u591a\u4e2a\u4e13\u5bb6\u6a21\u578b\u5408\u5e76\u4e3a\u7edf\u4e00\u67b6\u6784\uff0c\u901a\u8fc7\u68af\u5ea6\u6295\u5f71\u6b63\u5219\u5316\u635f\u5931\u51fd\u6570\u81ea\u9002\u5e94\u8c03\u6574\u4efb\u52a1\u5411\u91cf\u6743\u91cd\u3002", "result": "\u5728\u5341\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff08\u6db5\u76d6\u6570\u5b66\u3001\u7ed3\u6784\u5316\u6570\u636e\u3001OCR\u548c\u901a\u7528\u80fd\u529b\uff09\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86Tiny-R1V\u7684\u5353\u8d8a\u6027\u80fd\u3002", "conclusion": "Tiny-R1V\u4f7f\u8f7b\u91cf\u7ea7\u6a21\u578b\u80fd\u591f\u5728\u591a\u6837\u5316\u7684\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u63a8\u7406\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2510.09011", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.09011", "abs": "https://arxiv.org/abs/2510.09011", "authors": ["Yincen Qu", "Huan Xiao", "Feng Li", "Hui Zhou", "Xiangying Dai"], "title": "TripScore: Benchmarking and rewarding real-world travel planning with fine-grained evaluation", "comment": null, "summary": "Travel planning is a valuable yet complex task that poses significant\nchallenges even for advanced large language models (LLMs). While recent\nbenchmarks have advanced in evaluating LLMs' planning capabilities, they often\nfall short in evaluating feasibility, reliability, and engagement of travel\nplans. We introduce a comprehensive benchmark for travel planning that unifies\nfine-grained criteria into a single reward, enabling direct comparison of plan\nquality and seamless integration with reinforcement learning (RL). Our\nevaluator achieves moderate agreement with travel-expert annotations (60.75\\%)\nand outperforms multiple LLM-as-judge baselines. We further release a\nlarge-scale dataset of 4,870 queries including 219 real-world, free-form\nrequests for generalization to authentic user intent. Using this benchmark, we\nconduct extensive experiments across diverse methods and LLMs, including\ntest-time computation, neuro-symbolic approaches, supervised fine-tuning, and\nRL via GRPO. Across base models, RL generally improves itinerary feasibility\nover prompt-only and supervised baselines, yielding higher unified reward\nscores.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u65c5\u884c\u89c4\u5212\u57fa\u51c6\uff0c\u901a\u8fc7\u5c06\u7ec6\u7c92\u5ea6\u6807\u51c6\u6574\u5408\u4e3a\u5355\u4e00\u5956\u52b1\u6765\u8bc4\u4f30LLM\u7684\u89c4\u5212\u80fd\u529b\uff0c\u5e76\u53d1\u5e03\u4e86\u5305\u542b4870\u4e2a\u67e5\u8be2\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5f3a\u5316\u5b66\u4e60\u5728\u63d0\u9ad8\u884c\u7a0b\u53ef\u884c\u6027\u65b9\u9762\u4f18\u4e8e\u63d0\u793a\u5de5\u7a0b\u548c\u76d1\u7763\u5b66\u4e60\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5728\u8bc4\u4f30LLM\u65c5\u884c\u89c4\u5212\u80fd\u529b\u65f6\uff0c\u5f80\u5f80\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u8ba1\u5212\u7684\u53ef\u884c\u6027\u3001\u53ef\u9760\u6027\u548c\u53c2\u4e0e\u5ea6\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u4e86\u7edf\u4e00\u7684\u65c5\u884c\u89c4\u5212\u57fa\u51c6\uff0c\u5c06\u7ec6\u7c92\u5ea6\u6807\u51c6\u6574\u5408\u4e3a\u5355\u4e00\u5956\u52b1\uff1b\u521b\u5efa\u4e86\u5305\u542b4870\u4e2a\u67e5\u8be2\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff1b\u4f7f\u7528\u591a\u79cd\u65b9\u6cd5\uff08\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u3001\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u3001\u76d1\u7763\u5fae\u8c03\u3001GRPO\u5f3a\u5316\u5b66\u4e60\uff09\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u8bc4\u4f30\u5668\u4e0e\u65c5\u884c\u4e13\u5bb6\u6ce8\u91ca\u8fbe\u5230\u4e8660.75%\u7684\u4e00\u81f4\u6027\uff0c\u4f18\u4e8e\u591a\u4e2aLLM\u4f5c\u4e3a\u8bc4\u5224\u57fa\u51c6\uff1b\u5f3a\u5316\u5b66\u4e60\u5728\u63d0\u9ad8\u884c\u7a0b\u53ef\u884c\u6027\u65b9\u9762\u4f18\u4e8e\u63d0\u793a\u5de5\u7a0b\u548c\u76d1\u7763\u5b66\u4e60\uff0c\u83b7\u5f97\u4e86\u66f4\u9ad8\u7684\u7edf\u4e00\u5956\u52b1\u5206\u6570\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u4e00\u57fa\u51c6\u80fd\u591f\u6709\u6548\u8bc4\u4f30LLM\u7684\u65c5\u884c\u89c4\u5212\u80fd\u529b\uff0c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u63d0\u9ad8\u89c4\u5212\u8d28\u91cf\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u4e3a\u672a\u6765\u65c5\u884c\u89c4\u5212\u7cfb\u7edf\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2510.09021", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09021", "abs": "https://arxiv.org/abs/2510.09021", "authors": ["Hamed Mahdavi", "Pouria Mahdavinia", "Samira Malek", "Pegah Mohammadipour", "Alireza Hashemi", "Majid Daliri", "Alireza Farhadi", "Amir Khasahmadi", "Niloofar Mireshghallah", "Vasant Honavar"], "title": "RefGrader: Automated Grading of Mathematical Competition Proofs using Agentic Workflows", "comment": null, "summary": "State-of-the-art (SOTA) LLMs have progressed from struggling on proof-based\nOlympiad problems to solving most of the IMO 2025 problems, with leading\nsystems reportedly handling 5 of 6 problems. Given this progress, we assess how\nwell these models can grade proofs: detecting errors, judging their severity,\nand assigning fair scores beyond binary correctness. We study proof-analysis\ncapabilities using a corpus of 90 Gemini 2.5 Pro-generated solutions that we\ngrade on a 1-4 scale with detailed error annotations, and on MathArena solution\nsets for IMO/USAMO 2025 scored on a 0-7 scale. Our analysis shows that models\ncan reliably flag incorrect (including subtly incorrect) solutions but exhibit\ncalibration gaps in how partial credit is assigned. To address this, we\nintroduce agentic workflows that extract and analyze reference solutions and\nautomatically derive problem-specific rubrics for a multi-step grading process.\nWe instantiate and compare different design choices for the grading workflows,\nand evaluate their trade-offs. Across our annotated corpus and MathArena, our\nproposed workflows achieve higher agreement with human grades and more\nconsistent handling of partial credit across metrics. We release all code,\ndata, and prompts/logs to facilitate future research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc4\u4f30\u4e86\u5148\u8fdbLLMs\u5728\u6570\u5b66\u8bc1\u660e\u8bc4\u5206\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u80fd\u53ef\u9760\u8bc6\u522b\u9519\u8bef\u8bc1\u660e\u4f46\u5728\u90e8\u5206\u5f97\u5206\u5206\u914d\u4e0a\u5b58\u5728\u6821\u51c6\u5dee\u8ddd\uff0c\u4e3a\u6b64\u63d0\u51fa\u4e86\u57fa\u4e8e\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\u7684\u591a\u6b65\u9aa4\u8bc4\u5206\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4e0e\u4eba\u7c7b\u8bc4\u5206\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u968f\u7740SOTA LLMs\u5728\u89e3\u51b3\u5965\u6797\u5339\u514b\u6570\u5b66\u95ee\u9898\u65b9\u9762\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff08\u80fd\u89e3\u51b3IMO 2025\u7684\u5927\u90e8\u5206\u95ee\u9898\uff09\uff0c\u9700\u8981\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u5728\u8bc1\u660e\u8bc4\u5206\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5305\u62ec\u9519\u8bef\u68c0\u6d4b\u3001\u4e25\u91cd\u6027\u5224\u65ad\u548c\u516c\u5e73\u5206\u6570\u5206\u914d\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u4e8c\u5143\u6b63\u786e\u6027\u5224\u65ad\u3002", "method": "\u4f7f\u7528\u5305\u542b90\u4e2aGemini 2.5 Pro\u751f\u6210\u89e3\u51b3\u65b9\u6848\u7684\u8bed\u6599\u5e93\uff08\u63091-4\u5206\u5236\u8bc4\u5206\u5e76\u5e26\u6709\u8be6\u7ec6\u9519\u8bef\u6807\u6ce8\uff09\u548cMathArena\u7684IMO/USAMO 2025\u89e3\u51b3\u65b9\u6848\u96c6\uff08\u63090-7\u5206\u5236\u8bc4\u5206\uff09\uff0c\u5f15\u5165\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\u6765\u63d0\u53d6\u548c\u5206\u6790\u53c2\u8003\u89e3\u51b3\u65b9\u6848\uff0c\u81ea\u52a8\u63a8\u5bfc\u95ee\u9898\u7279\u5b9a\u7684\u8bc4\u5206\u6807\u51c6\uff0c\u5b9e\u73b0\u591a\u6b65\u9aa4\u8bc4\u5206\u8fc7\u7a0b\u3002", "result": "\u5206\u6790\u663e\u793a\u6a21\u578b\u80fd\u53ef\u9760\u6807\u8bb0\u9519\u8bef\uff08\u5305\u62ec\u7ec6\u5fae\u9519\u8bef\uff09\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5728\u90e8\u5206\u5f97\u5206\u5206\u914d\u4e0a\u5b58\u5728\u6821\u51c6\u5dee\u8ddd\u3002\u63d0\u51fa\u7684\u5de5\u4f5c\u6d41\u7a0b\u5728\u6807\u6ce8\u8bed\u6599\u5e93\u548cMathArena\u4e0a\u90fd\u5b9e\u73b0\u4e86\u4e0e\u4eba\u7c7b\u8bc4\u5206\u66f4\u9ad8\u7684\u534f\u8bae\u4e00\u81f4\u6027\uff0c\u5e76\u5728\u90e8\u5206\u5f97\u5206\u5904\u7406\u4e0a\u66f4\u52a0\u4e00\u81f4\u3002", "conclusion": "\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\u80fd\u6709\u6548\u63d0\u9ad8LLMs\u5728\u6570\u5b66\u8bc1\u660e\u8bc4\u5206\u65b9\u9762\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u90e8\u5206\u5f97\u5206\u5206\u914d\u7684\u4e00\u81f4\u6027\u65b9\u9762\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u4ee3\u7801\u3001\u6570\u636e\u548c\u63d0\u793a/\u65e5\u5fd7\u8d44\u6e90\u3002"}}
{"id": "2510.09037", "categories": ["cs.AI", "cs.PL", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.09037", "abs": "https://arxiv.org/abs/2510.09037", "authors": ["Sicheol Sung", "Joonghyuk Hahn", "Yo-Sub Han"], "title": "Repairing Regex Vulnerabilities via Localization-Guided Instructions", "comment": "14 pages, 4 figures, 4 tables", "summary": "Regular expressions (regexes) are foundational to modern computing for\ncritical tasks like input validation and data parsing, yet their ubiquity\nexposes systems to regular expression denial of service (ReDoS), a\nvulnerability requiring automated repair methods. Current approaches, however,\nare hampered by a trade-off. Symbolic, rule-based system are precise but fails\nto repair unseen or complex vulnerability patterns. Conversely, large language\nmodels (LLMs) possess the necessary generalizability but are unreliable for\ntasks demanding strict syntactic and semantic correctness. We resolve this\nimpasse by introducing a hybrid framework, localized regex repair (LRR),\ndesigned to harness LLM generalization while enforcing reliability. Our core\ninsight is to decouple problem identification from the repair process. First, a\ndeterministic, symbolic module localizes the precise vulnerable subpattern,\ncreating a constrained and tractable problem space. Then, the LLM invoked to\ngenerate a semantically equivalent fix for this isolated segment. This combined\narchitecture successfully resolves complex repair cases intractable for\nrule-based repair while avoiding the semantic errors of LLM-only approaches.\nOur work provides a validated methodology for solving such problems in\nautomated repair, improving the repair rate by 15.4%p over the\nstate-of-the-art. Our code is available at https://github.com/cdltlehf/LRR.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6846\u67b6LRR\uff0c\u7ed3\u5408\u7b26\u53f7\u6a21\u5757\u548cLLM\u6765\u4fee\u590d\u6b63\u5219\u8868\u8fbe\u5f0f\u62d2\u7edd\u670d\u52a1\u6f0f\u6d1e\uff0c\u5728\u4fdd\u6301\u8bed\u4e49\u6b63\u786e\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u4fee\u590d\u7387", "motivation": "\u6b63\u5219\u8868\u8fbe\u5f0f\u5728\u73b0\u4ee3\u8ba1\u7b97\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5b58\u5728ReDoS\u6f0f\u6d1e\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u6743\u8861\uff1a\u57fa\u4e8e\u7b26\u53f7\u89c4\u5219\u7684\u65b9\u6cd5\u7cbe\u786e\u4f46\u65e0\u6cd5\u4fee\u590d\u590d\u6742\u6a21\u5f0f\uff0cLLM\u5177\u6709\u6cdb\u5316\u80fd\u529b\u4f46\u7f3a\u4e4f\u53ef\u9760\u6027", "method": "LRR\u6df7\u5408\u6846\u67b6\uff1a\u9996\u5148\u4f7f\u7528\u786e\u5b9a\u6027\u7b26\u53f7\u6a21\u5757\u5b9a\u4f4d\u6613\u53d7\u653b\u51fb\u7684\u5b50\u6a21\u5f0f\uff0c\u7136\u540e\u8c03\u7528LLM\u4e3a\u9694\u79bb\u7684\u7247\u6bb5\u751f\u6210\u8bed\u4e49\u7b49\u6548\u7684\u4fee\u590d", "result": "\u6210\u529f\u89e3\u51b3\u4e86\u57fa\u4e8e\u89c4\u5219\u4fee\u590d\u65e0\u6cd5\u5904\u7406\u7684\u590d\u6742\u4fee\u590d\u6848\u4f8b\uff0c\u540c\u65f6\u907f\u514d\u4e86\u7eafLLM\u65b9\u6cd5\u7684\u8bed\u4e49\u9519\u8bef\uff0c\u4fee\u590d\u7387\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u63d0\u9ad8\u4e8615.4%", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u81ea\u52a8\u4fee\u590d\u95ee\u9898\u63d0\u4f9b\u4e86\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u65b9\u6cd5\u8bba\uff0c\u901a\u8fc7\u89e3\u8026\u95ee\u9898\u8bc6\u522b\u548c\u4fee\u590d\u8fc7\u7a0b\uff0c\u5728\u5229\u7528LLM\u6cdb\u5316\u80fd\u529b\u7684\u540c\u65f6\u786e\u4fdd\u53ef\u9760\u6027"}}
{"id": "2510.09049", "categories": ["cs.AI", "cs.SE", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.09049", "abs": "https://arxiv.org/abs/2510.09049", "authors": ["Joonghyuk Hahn", "Soohan Lim", "Yo-Sub Han"], "title": "MEC$^3$O: Multi-Expert Consensus for Code Time Complexity Prediction", "comment": "24 pages, 11 figures, 10 tables", "summary": "Predicting the complexity of source code is essential for software\ndevelopment and algorithm analysis. Recently, Baik et al. (2025) introduced\nCodeComplex for code time complexity prediction. The paper shows that LLMs\nwithout fine-tuning struggle with certain complexity classes. This suggests\nthat no single LLM excels at every class, but rather each model shows\nadvantages in certain classes. We propose MEC$^3$O, a multi-expert consensus\nsystem, which extends the multi-agent debate frameworks. MEC$^3$O assigns LLMs\nto complexity classes based on their performance and provides them with\nclass-specialized instructions, turning them into experts. These experts engage\nin structured debates, and their predictions are integrated through a weighted\nconsensus mechanism. Our expertise assignments to LLMs effectively handle\nDegeneration-of-Thought, reducing reliance on a separate judge model, and\npreventing convergence to incorrect majority opinions. Experiments on\nCodeComplex show that MEC$^3$O outperforms the open-source baselines, achieving\nat least 10% higher accuracy and macro-F1 scores. It also surpasses GPT-4o-mini\nin macro-F1 scores on average and demonstrates competitive on-par F1 scores to\nGPT-4o and GPT-o4-mini on average. This demonstrates the effectiveness of\nmulti-expert debates and weight consensus strategy to generate the final\npredictions. Our code and data is available at\nhttps://github.com/suhanmen/MECO.", "AI": {"tldr": "MEC\u00b3O\u662f\u4e00\u4e2a\u591a\u4e13\u5bb6\u5171\u8bc6\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06LLMs\u5206\u914d\u5230\u7279\u5b9a\u590d\u6742\u5ea6\u7c7b\u522b\u5e76\u8ba9\u5b83\u4eec\u8fdb\u884c\u7ed3\u6784\u5316\u8fa9\u8bba\uff0c\u7ed3\u5408\u52a0\u6743\u5171\u8bc6\u673a\u5236\u6765\u9884\u6d4b\u4ee3\u7801\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u5728CodeComplex\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u5f00\u6e90\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709LLMs\u5728\u4ee3\u7801\u65f6\u95f4\u590d\u6742\u5ea6\u9884\u6d4b\u4e2d\u8868\u73b0\u4e0d\u5747\u8861\uff0c\u6ca1\u6709\u5355\u4e00\u6a21\u578b\u5728\u6240\u6709\u590d\u6742\u5ea6\u7c7b\u522b\u4e0a\u90fd\u8868\u73b0\u4f18\u5f02\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6574\u5408\u4e0d\u540c\u6a21\u578b\u4f18\u52bf\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faMEC\u00b3O\u591a\u4e13\u5bb6\u5171\u8bc6\u7cfb\u7edf\uff1a1\uff09\u57fa\u4e8e\u6027\u80fd\u5c06LLMs\u5206\u914d\u5230\u7279\u5b9a\u590d\u6742\u5ea6\u7c7b\u522b\uff1b2\uff09\u63d0\u4f9b\u7c7b\u522b\u4e13\u4e1a\u5316\u6307\u4ee4\uff1b3\uff09\u4e13\u5bb6\u8fdb\u884c\u7ed3\u6784\u5316\u8fa9\u8bba\uff1b4\uff09\u901a\u8fc7\u52a0\u6743\u5171\u8bc6\u673a\u5236\u6574\u5408\u9884\u6d4b\u7ed3\u679c\u3002", "result": "\u5728CodeComplex\u6570\u636e\u96c6\u4e0a\uff0cMEC\u00b3O\u6bd4\u5f00\u6e90\u57fa\u7ebf\u6a21\u578b\u51c6\u786e\u7387\u548cmacro-F1\u5206\u6570\u81f3\u5c11\u63d0\u9ad810%\uff0c\u5728macro-F1\u5206\u6570\u4e0a\u5e73\u5747\u8d85\u8fc7GPT-4o-mini\uff0c\u4e0eGPT-4o\u548cGPT-o4-mini\u7684F1\u5206\u6570\u76f8\u5f53\u3002", "conclusion": "\u591a\u4e13\u5bb6\u8fa9\u8bba\u548c\u52a0\u6743\u5171\u8bc6\u7b56\u7565\u80fd\u6709\u6548\u751f\u6210\u6700\u7ec8\u9884\u6d4b\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u4ee3\u7801\u590d\u6742\u5ea6\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.09133", "categories": ["cs.AI", "cs.LG", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.09133", "abs": "https://arxiv.org/abs/2510.09133", "authors": ["Hao Zeng", "Jianguo Huang", "Bingyi Jing", "Hongxin Wei", "Bo An"], "title": "PAC Reasoning: Controlling the Performance Loss for Efficient Reasoning", "comment": null, "summary": "Large reasoning models (LRMs) have achieved remarkable progress in complex\nproblem-solving tasks. Despite this success, LRMs typically suffer from high\ncomputational costs during deployment, highlighting a need for efficient\ninference. A popular direction of efficiency improvement is to switch the LRM\nbetween thinking and nonthinking modes dynamically. However, such approaches\noften introduce additional reasoning errors and lack statistical guarantees for\nthe performance loss, which are critical for high-stakes applications. In this\nwork, we propose Probably Approximately Correct (PAC) reasoning that controls\nthe performance loss under the user-specified performance loss tolerance. In\nparticular, we construct an upper confidence bound on the performance loss,\nformulated as a monotone function of the uncertainty score, and subsequently\ndetermine a threshold for switching to the nonthinking model. Theoretically,\nusing the threshold to switch between the thinking and nonthinking modes\nensures bounded performance loss in a distribution-free manner. Our\ncomprehensive experiments on reasoning benchmarks show that the proposed method\ncan save computational budgets and control the user-specified performance loss.", "AI": {"tldr": "\u63d0\u51faPAC\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f6e\u4fe1\u4e0a\u754c\u63a7\u5236\u6027\u80fd\u635f\u5931\uff0c\u5728\u7528\u6237\u6307\u5b9a\u7684\u6027\u80fd\u635f\u5931\u5bb9\u5fcd\u5ea6\u4e0b\u52a8\u6001\u5207\u6362\u601d\u8003\u4e0e\u975e\u601d\u8003\u6a21\u5f0f\u4ee5\u8282\u7701\u8ba1\u7b97\u6210\u672c", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u95ee\u9898\u89e3\u51b3\u4e2d\u8868\u73b0\u51fa\u8272\u4f46\u90e8\u7f72\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u52a8\u6001\u5207\u6362\u65b9\u6cd5\u5b58\u5728\u989d\u5916\u63a8\u7406\u9519\u8bef\u4e14\u7f3a\u4e4f\u6027\u80fd\u635f\u5931\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u96be\u4ee5\u5e94\u7528\u4e8e\u9ad8\u98ce\u9669\u573a\u666f", "method": "\u6784\u5efa\u6027\u80fd\u635f\u5931\u7684\u5355\u8c03\u51fd\u6570\u7f6e\u4fe1\u4e0a\u754c\uff0c\u786e\u5b9a\u5207\u6362\u5230\u975e\u601d\u8003\u6a21\u578b\u7684\u9608\u503c\uff0c\u4ee5\u5206\u5e03\u65e0\u5173\u65b9\u5f0f\u786e\u4fdd\u6709\u754c\u6027\u80fd\u635f\u5931", "result": "\u5728\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u80fd\u8282\u7701\u8ba1\u7b97\u9884\u7b97\u5e76\u63a7\u5236\u7528\u6237\u6307\u5b9a\u7684\u6027\u80fd\u635f\u5931", "conclusion": "PAC\u63a8\u7406\u65b9\u6cd5\u4e3a\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u80fd\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c"}}
{"id": "2510.09162", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.09162", "abs": "https://arxiv.org/abs/2510.09162", "authors": ["Emma Kondrup", "Anne Imouza"], "title": "Dr. Bias: Social Disparities in AI-Powered Medical Guidance", "comment": null, "summary": "With the rapid progress of Large Language Models (LLMs), the general public\nnow has easy and affordable access to applications capable of answering most\nhealth-related questions in a personalized manner. These LLMs are increasingly\nproving to be competitive, and now even surpass professionals in some medical\ncapabilities. They hold particular promise in low-resource settings,\nconsidering they provide the possibility of widely accessible, quasi-free\nhealthcare support. However, evaluations that fuel these motivations highly\nlack insights into the social nature of healthcare, oblivious to health\ndisparities between social groups and to how bias may translate into\nLLM-generated medical advice and impact users. We provide an exploratory\nanalysis of LLM answers to a series of medical questions spanning key clinical\ndomains, where we simulate these questions being asked by several patient\nprofiles that vary in sex, age range, and ethnicity. By comparing natural\nlanguage features of the generated responses, we show that, when LLMs are used\nfor medical advice generation, they generate responses that systematically\ndiffer between social groups. In particular, Indigenous and intersex patients\nreceive advice that is less readable and more complex. We observe these trends\namplify when intersectional groups are considered. Considering the increasing\ntrust individuals place in these models, we argue for higher AI literacy and\nfor the urgent need for investigation and mitigation by AI developers to ensure\nthese systemic differences are diminished and do not translate to unjust\npatient support. Our code is publicly available on GitHub.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u6027\u5206\u6790\u4e86LLM\u5728\u751f\u6210\u533b\u7597\u5efa\u8bae\u65f6\u5bf9\u4e0d\u540c\u793e\u4f1a\u7fa4\u4f53\uff08\u57fa\u4e8e\u6027\u522b\u3001\u5e74\u9f84\u3001\u79cd\u65cf\uff09\u7684\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u53d1\u73b0\u571f\u8457\u548c\u53cc\u6027\u60a3\u8005\u83b7\u5f97\u7684\u5efa\u8bae\u53ef\u8bfb\u6027\u66f4\u5dee\u3001\u66f4\u590d\u6742\uff0c\u4ea4\u53c9\u7fa4\u4f53\u4e2d\u8fd9\u79cd\u8d8b\u52bf\u66f4\u52a0\u660e\u663e\u3002", "motivation": "\u968f\u7740LLM\u5728\u533b\u7597\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u662f\u5426\u8003\u8651\u533b\u7597\u7684\u793e\u4f1a\u6027\u672c\u8d28\uff0c\u7279\u522b\u662f\u5065\u5eb7\u5dee\u5f02\u548c\u793e\u4f1a\u504f\u89c1\u5982\u4f55\u5f71\u54cdLLM\u751f\u6210\u7684\u533b\u7597\u5efa\u8bae\u3002", "method": "\u901a\u8fc7\u6a21\u62df\u4e0d\u540c\u60a3\u8005\u6863\u6848\uff08\u6027\u522b\u3001\u5e74\u9f84\u3001\u79cd\u65cf\uff09\u5411LLM\u63d0\u51fa\u4e00\u7cfb\u5217\u533b\u7597\u95ee\u9898\uff0c\u6bd4\u8f83\u751f\u6210\u56de\u7b54\u7684\u81ea\u7136\u8bed\u8a00\u7279\u5f81\u3002", "result": "LLM\u751f\u6210\u7684\u533b\u7597\u5efa\u8bae\u5728\u4e0d\u540c\u793e\u4f1a\u7fa4\u4f53\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u571f\u8457\u548c\u53cc\u6027\u60a3\u8005\u83b7\u5f97\u7684\u5efa\u8bae\u53ef\u8bfb\u6027\u66f4\u4f4e\u3001\u66f4\u590d\u6742\uff0c\u4ea4\u53c9\u7fa4\u4f53\u4e2d\u5dee\u5f02\u66f4\u52a0\u660e\u663e\u3002", "conclusion": "\u9274\u4e8e\u7528\u6237\u5bf9LLM\u7684\u4fe1\u4efb\u5ea6\u589e\u52a0\uff0c\u9700\u8981\u63d0\u9ad8AI\u7d20\u517b\uff0c\u5e76\u547c\u5401AI\u5f00\u53d1\u8005\u7d27\u6025\u8c03\u67e5\u548c\u7f13\u89e3\u8fd9\u4e9b\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u786e\u4fdd\u516c\u5e73\u7684\u60a3\u8005\u652f\u6301\u3002"}}
{"id": "2510.09223", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09223", "abs": "https://arxiv.org/abs/2510.09223", "authors": ["Mubaris Nadeem", "Madjid Fathi"], "title": "Comparing Knowledge Source Integration Methods for Optimizing Healthcare Knowledge Fusion in Rescue Operation", "comment": "Conference Paper for 2024 IEEE 7th International Conference on\n  Industrial Cyber-Physical Systems (ICPS), KIRETT Project, University of\n  Siegen, Germany", "summary": "In the field of medicine and healthcare, the utilization of medical\nexpertise, based on medical knowledge combined with patients' health\ninformation is a life-critical challenge for patients and health professionals.\nThe within-laying complexity and variety form the need for a united approach to\ngather, analyze, and utilize existing knowledge of medical treatments, and\nmedical operations to provide the ability to present knowledge for the means of\naccurate patient-driven decision-making. One way to achieve this is the fusion\nof multiple knowledge sources in healthcare. It provides health professionals\nthe opportunity to select from multiple contextual aligned knowledge sources\nwhich enables the support for critical decisions. This paper presents multiple\nconceptual models for knowledge fusion in the field of medicine, based on a\nknowledge graph structure. It will evaluate, how knowledge fusion can be\nenabled and presents how to integrate various knowledge sources into the\nknowledge graph for rescue operations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7ed3\u6784\u7684\u533b\u5b66\u77e5\u8bc6\u878d\u5408\u6982\u5ff5\u6a21\u578b\uff0c\u65e8\u5728\u6574\u5408\u591a\u79cd\u533b\u7597\u77e5\u8bc6\u6e90\u4ee5\u652f\u6301\u7cbe\u51c6\u7684\u60a3\u8005\u9a71\u52a8\u51b3\u7b56\u5236\u5b9a\u3002", "motivation": "\u533b\u7597\u9886\u57df\u9700\u8981\u7edf\u4e00\u65b9\u6cd5\u6765\u6536\u96c6\u3001\u5206\u6790\u548c\u5229\u7528\u73b0\u6709\u533b\u5b66\u77e5\u8bc6\uff0c\u4ee5\u652f\u6301\u5173\u952e\u51b3\u7b56\u5236\u5b9a\u3002\u533b\u7597\u77e5\u8bc6\u7684\u590d\u6742\u6027\u548c\u591a\u6837\u6027\u8981\u6c42\u878d\u5408\u591a\u79cd\u77e5\u8bc6\u6e90\uff0c\u4e3a\u533b\u7597\u4e13\u4e1a\u4eba\u5458\u63d0\u4f9b\u591a\u60c5\u5883\u5bf9\u9f50\u7684\u77e5\u8bc6\u9009\u62e9\u3002", "method": "\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7ed3\u6784\u5f00\u53d1\u591a\u4e2a\u6982\u5ff5\u6a21\u578b\uff0c\u8bc4\u4f30\u77e5\u8bc6\u878d\u5408\u7684\u5b9e\u73b0\u65b9\u5f0f\uff0c\u5c55\u793a\u5982\u4f55\u5c06\u5404\u79cd\u77e5\u8bc6\u6e90\u6574\u5408\u5230\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7528\u4e8e\u6551\u63f4\u64cd\u4f5c\u3002", "result": "\u63d0\u51fa\u4e86\u652f\u6301\u77e5\u8bc6\u878d\u5408\u7684\u6982\u5ff5\u6a21\u578b\u6846\u67b6\uff0c\u80fd\u591f\u96c6\u6210\u591a\u79cd\u533b\u7597\u77e5\u8bc6\u6e90\uff0c\u4e3a\u533b\u7597\u51b3\u7b56\u63d0\u4f9b\u652f\u6301\u3002", "conclusion": "\u77e5\u8bc6\u56fe\u8c31\u4e3a\u57fa\u7840\u7684\u878d\u5408\u65b9\u6cd5\u4e3a\u533b\u7597\u9886\u57df\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u77e5\u8bc6\u6574\u5408\u9014\u5f84\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u533b\u7597\u51b3\u7b56\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2510.09227", "categories": ["cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2510.09227", "abs": "https://arxiv.org/abs/2510.09227", "authors": ["Hyundong Jin", "Joonghyuk Hahn", "Yo-Sub Han"], "title": "RegexPSPACE: A Benchmark for Evaluating LLM Reasoning on PSPACE-complete Regex Problems", "comment": null, "summary": "Large language models (LLMs) show strong performance across natural language\nprocessing (NLP), mathematical reasoning, and programming, and recent large\nreasoning models (LRMs) further emphasize explicit reasoning. Yet their\ncomputational limits, particularly spatial complexity constrained by finite\ncontext windows, remain poorly understood. While recent works often focus on\nproblems within the NP complexity class, we push the boundary by introducing a\nnovel benchmark grounded in two PSPACE-complete regular expression (regex)\nproblems: equivalence decision (RegexEQ) and minimization (RegexMin).\nPSPACE-complete problems serve as a more rigorous standard for assessing\ncomputational capacity, as their solutions require massive search space\nexploration. We perform a double-exponential space exploration to construct a\nlabeled dataset of over a million regex instances with a sound filtering\nprocess to build the benchmark. We conduct extensive evaluations on 6 LLMs and\n5 LRMs of varying scales, revealing common failure patterns such as verbosity\nand repetition. With its well-defined structure and quantitative evaluation\nmetrics, this work presents the first empirical investigation into the spatial\ncomputational limitations of LLMs and LRMs, offering a new framework for\nevaluating their advanced reasoning capabilities. Our code is available at\nhttps://github.com/hyundong98/RegexPSPACE .", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8ePSPACE\u5b8c\u5168\u6b63\u5219\u8868\u8fbe\u5f0f\u95ee\u9898\u7684\u65b0\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5927\u63a8\u7406\u6a21\u578b\u7684\u7a7a\u95f4\u8ba1\u7b97\u9650\u5236\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u5728\u5904\u7406\u9700\u8981\u5927\u89c4\u6a21\u641c\u7d22\u7a7a\u95f4\u63a2\u7d22\u95ee\u9898\u65f6\u7684\u5e38\u89c1\u5931\u8d25\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8NP\u590d\u6742\u5ea6\u7c7b\u5185\u7684\u95ee\u9898\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5927\u63a8\u7406\u6a21\u578b\u5728\u7a7a\u95f4\u590d\u6742\u5ea6\u65b9\u9762\u7684\u8ba1\u7b97\u9650\u5236\u4ecd\u672a\u88ab\u5145\u5206\u7406\u89e3\uff0c\u7279\u522b\u662f\u53d7\u9650\u4e8e\u6709\u9650\u4e0a\u4e0b\u6587\u7a97\u53e3\u7684\u95ee\u9898\u3002PSPACE\u5b8c\u5168\u95ee\u9898\u4f5c\u4e3a\u66f4\u4e25\u683c\u7684\u6807\u51c6\uff0c\u80fd\u591f\u66f4\u597d\u5730\u8bc4\u4f30\u6a21\u578b\u7684\u8ba1\u7b97\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u53cc\u91cd\u6307\u6570\u7a7a\u95f4\u63a2\u7d22\u6784\u5efa\u4e86\u5305\u542b\u8d85\u8fc7100\u4e07\u4e2a\u6b63\u5219\u8868\u8fbe\u5f0f\u5b9e\u4f8b\u7684\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u5e76\u91c7\u7528\u4e25\u683c\u8fc7\u6ee4\u8fc7\u7a0b\u5efa\u7acb\u57fa\u51c6\u3002\u5bf96\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u548c5\u4e2a\u5927\u63a8\u7406\u6a21\u578b\u8fdb\u884c\u4e86\u5e7f\u6cdb\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u63ed\u793a\u4e86\u6a21\u578b\u5728\u5904\u7406PSPACE\u5b8c\u5168\u6b63\u5219\u8868\u8fbe\u5f0f\u95ee\u9898\u65f6\u7684\u5e38\u89c1\u5931\u8d25\u6a21\u5f0f\uff0c\u5982\u5197\u957f\u548c\u91cd\u590d\u3002\u8fd9\u662f\u9996\u6b21\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5927\u63a8\u7406\u6a21\u578b\u7a7a\u95f4\u8ba1\u7b97\u9650\u5236\u7684\u5b9e\u8bc1\u7814\u7a76\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5927\u63a8\u7406\u6a21\u578b\u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7PSPACE\u5b8c\u5168\u95ee\u9898\u63ed\u793a\u4e86\u5b83\u4eec\u7684\u7a7a\u95f4\u8ba1\u7b97\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2510.09338", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09338", "abs": "https://arxiv.org/abs/2510.09338", "authors": ["Joachim Diederich"], "title": "Localist LLMs -- A Mathematical Framework for Dynamic Locality Control", "comment": null, "summary": "We present a novel framework for training large language models with\ncontinuously adjustable internal representations that span the full spectrum\nfrom localist (interpretable, rule-based) to distributed (generalizable,\nefficient) encodings. The key innovation is a locality dial, a tunable\nparameter that dynamically controls the degree of localization during both\ntraining and inference without requiring model retraining. This is achieved\nthrough group sparsity penalties on attention mechanisms, information-theoretic\nanchor design, and dynamic rule injection. We provide rigorous mathematical\nproofs establishing explicit threshold conditions under which attention\nprovably concentrates on semantically relevant blocks, with exponential bounds\non attention entropy and pointer fidelity. Specifically, we prove that when\ngroup sparsity penalties exceed certain threshold values, the model's attention\nmechanisms concentrate on semantically relevant blocks, achieving low entropy\nand high fidelity with negligible error. This framework enables practitioners\nto continuously interpolate between interpretable and high-performance modes,\nsupporting applications in regulated domains requiring both transparency and\ncapability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u8c03\u8282\u7684\u5c40\u90e8\u6027\u53c2\u6570\u5728\u5c40\u90e8\u5316\uff08\u53ef\u89e3\u91ca\uff09\u548c\u5206\u5e03\u5f0f\uff08\u9ad8\u6548\uff09\u8868\u793a\u4e4b\u95f4\u8fde\u7eed\u5207\u6362\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9700\u8981\u900f\u660e\u5ea6\u7684\u53d7\u76d1\u7ba1\u9886\u57df\u4e2d\uff0c\u540c\u65f6\u6ee1\u8db3\u53ef\u89e3\u91ca\u6027\u548c\u9ad8\u6027\u80fd\u7684\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u7ec4\u7a00\u758f\u60e9\u7f5a\u3001\u4fe1\u606f\u8bba\u951a\u70b9\u8bbe\u8ba1\u548c\u52a8\u6001\u89c4\u5219\u6ce8\u5165\uff0c\u901a\u8fc7\u5c40\u90e8\u6027\u53c2\u6570\u52a8\u6001\u63a7\u5236\u8868\u793a\u7684\u5c40\u90e8\u5316\u7a0b\u5ea6\u3002", "result": "\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u6570\u5b66\u8bc1\u660e\uff0c\u5efa\u7acb\u4e86\u6ce8\u610f\u529b\u96c6\u4e2d\u5728\u8bed\u4e49\u76f8\u5173\u5757\u4e0a\u7684\u660e\u786e\u9608\u503c\u6761\u4ef6\uff0c\u5177\u6709\u6307\u6570\u7ea7\u7684\u6ce8\u610f\u529b\u71b5\u548c\u6307\u9488\u4fdd\u771f\u5ea6\u754c\u9650\u3002", "conclusion": "\u8be5\u6846\u67b6\u4f7f\u4ece\u4e1a\u8005\u80fd\u591f\u5728\u53ef\u89e3\u91ca\u548c\u9ad8\u6027\u80fd\u6a21\u5f0f\u4e4b\u95f4\u8fde\u7eed\u63d2\u503c\uff0c\u652f\u6301\u9700\u8981\u900f\u660e\u5ea6\u548c\u80fd\u529b\u7684\u53d7\u76d1\u7ba1\u9886\u57df\u5e94\u7528\u3002"}}
{"id": "2510.09340", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.09340", "abs": "https://arxiv.org/abs/2510.09340", "authors": ["Davide Maltoni", "Matteo Ferrara"], "title": "Toward Mechanistic Explanation of Deductive Reasoning in Language Models", "comment": null, "summary": "Recent large language models have demonstrated relevant capabilities in\nsolving problems that require logical reasoning; however, the corresponding\ninternal mechanisms remain largely unexplored. In this paper, we show that a\nsmall language model can solve a deductive reasoning task by learning the\nunderlying rules (rather than operating as a statistical learner). A low-level\nexplanation of its internal representations and computational circuits is then\nprovided. Our findings reveal that induction heads play a central role in the\nimplementation of the rule completion and rule chaining steps involved in the\nlogical inference required by the task.", "AI": {"tldr": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u5b66\u4e60\u5e95\u5c42\u89c4\u5219\uff08\u800c\u975e\u7edf\u8ba1\u5b66\u4e60\uff09\u89e3\u51b3\u6f14\u7ece\u63a8\u7406\u4efb\u52a1\uff0c\u7814\u7a76\u53d1\u73b0\u5f52\u7eb3\u5934\u5728\u89c4\u5219\u5b8c\u6210\u548c\u89c4\u5219\u94fe\u5f0f\u63a8\u7406\u4e2d\u8d77\u6838\u5fc3\u4f5c\u7528\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u903b\u8f91\u63a8\u7406\u95ee\u9898\u7684\u5185\u90e8\u673a\u5236\uff0c\u76ee\u524d\u76f8\u5173\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u4f7f\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u6f14\u7ece\u63a8\u7406\u4efb\u52a1\uff0c\u5206\u6790\u5176\u5185\u90e8\u8868\u793a\u548c\u8ba1\u7b97\u7535\u8def\uff0c\u91cd\u70b9\u5173\u6ce8\u5f52\u7eb3\u5934\u7684\u4f5c\u7528\u3002", "result": "\u53d1\u73b0\u5f52\u7eb3\u5934\u5728\u5b9e\u73b0\u903b\u8f91\u63a8\u7406\u6240\u9700\u7684\u89c4\u5219\u5b8c\u6210\u548c\u89c4\u5219\u94fe\u5f0f\u6b65\u9aa4\u4e2d\u53d1\u6325\u6838\u5fc3\u4f5c\u7528\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u7684\u5185\u90e8\u5de5\u4f5c\u673a\u5236\uff0c\u7279\u522b\u662f\u5f52\u7eb3\u5934\u5728\u89c4\u5219\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2510.09373", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09373", "abs": "https://arxiv.org/abs/2510.09373", "authors": ["Augustin Delecluse", "Pierre Schaus", "Pascal Van Hentenryck"], "title": "Sequence Variables: A Constraint Programming Computational Domain for Routing and Sequencing", "comment": null, "summary": "Constraint Programming (CP) offers an intuitive, declarative framework for\nmodeling Vehicle Routing Problems (VRP), yet classical CP models based on\nsuccessor variables cannot always deal with optional visits or insertion based\nheuristics. To address these limitations, this paper formalizes sequence\nvariables within CP. Unlike the classical successor models, this computational\ndomain handle optional visits and support insertion heuristics, including\ninsertion-based Large Neighborhood Search. We provide a clear definition of\ntheir domain, update operations, and introduce consistency levels for\nconstraints on this domain. An implementation is described with the underlying\ndata structures required for integrating sequence variables into existing\ntrail-based CP solvers. Furthermore, global constraints specifically designed\nfor sequence variables and vehicle routing are introduced. Finally, the\neffectiveness of sequence variables is demonstrated by simplifying problem\nmodeling and achieving competitive computational performance on the Dial-a-Ride\nProblem.", "AI": {"tldr": "\u672c\u6587\u5728\u7ea6\u675f\u7f16\u7a0b\u4e2d\u5f62\u5f0f\u5316\u4e86\u5e8f\u5217\u53d8\u91cf\uff0c\u4ee5\u89e3\u51b3\u7ecf\u5178\u540e\u7ee7\u53d8\u91cf\u6a21\u578b\u5728\u5904\u7406\u53ef\u9009\u8bbf\u95ee\u548c\u63d2\u5165\u542f\u53d1\u5f0f\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u76f4\u89c2\u7684\u5efa\u6a21\u6846\u67b6\u3002", "motivation": "\u7ecf\u5178\u7ea6\u675f\u7f16\u7a0b\u6a21\u578b\u57fa\u4e8e\u540e\u7ee7\u53d8\u91cf\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u53ef\u9009\u8bbf\u95ee\u6216\u57fa\u4e8e\u63d2\u5165\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u8fd9\u9650\u5236\u4e86\u5728\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5f62\u5f0f\u5316\u5e8f\u5217\u53d8\u91cf\u7684\u5b9a\u4e49\u3001\u57df\u3001\u66f4\u65b0\u64cd\u4f5c\u548c\u4e00\u81f4\u6027\u7ea7\u522b\uff1b\u5b9e\u73b0\u5e95\u5c42\u6570\u636e\u7ed3\u6784\u4ee5\u96c6\u6210\u5230\u73b0\u6709CP\u6c42\u89e3\u5668\u4e2d\uff1b\u8bbe\u8ba1\u4e13\u95e8\u7528\u4e8e\u5e8f\u5217\u53d8\u91cf\u548c\u8f66\u8f86\u8def\u5f84\u7684\u5168\u5c40\u7ea6\u675f\u3002", "result": "\u5e8f\u5217\u53d8\u91cf\u7b80\u5316\u4e86\u95ee\u9898\u5efa\u6a21\uff0c\u5e76\u5728Dial-a-Ride\u95ee\u9898\u4e0a\u5b9e\u73b0\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u8ba1\u7b97\u6027\u80fd\u3002", "conclusion": "\u5e8f\u5217\u53d8\u91cf\u4e3a\u7ea6\u675f\u7f16\u7a0b\u4e2d\u7684\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5efa\u6a21\u80fd\u529b\uff0c\u80fd\u591f\u5904\u7406\u53ef\u9009\u8bbf\u95ee\u5e76\u652f\u6301\u63d2\u5165\u542f\u53d1\u5f0f\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u6548\u679c\u3002"}}
{"id": "2510.09551", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09551", "abs": "https://arxiv.org/abs/2510.09551", "authors": ["Gavriel Di Nepi", "Federico Siciliano", "Fabrizio Silvestri"], "title": "Titans Revisited: A Lightweight Reimplementation and Critical Analysis of a Test-Time Memory Model", "comment": null, "summary": "By the end of 2024, Google researchers introduced Titans: Learning at Test\nTime, a neural memory model achieving strong empirical results across multiple\ntasks. However, the lack of publicly available code and ambiguities in the\noriginal description hinder reproducibility. In this work, we present a\nlightweight reimplementation of Titans and conduct a comprehensive evaluation\non Masked Language Modeling, Time Series Forecasting, and Recommendation tasks.\nOur results reveal that Titans does not always outperform established baselines\ndue to chunking. However, its Neural Memory component consistently improves\nperformance compared to attention-only models. These findings confirm the\nmodel's innovative potential while highlighting its practical limitations and\nraising questions for future research.", "AI": {"tldr": "\u672c\u6587\u5bf9Google\u7684Titans\u6a21\u578b\u8fdb\u884c\u4e86\u8f7b\u91cf\u7ea7\u590d\u73b0\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u53d1\u73b0Titans\u5e76\u4e0d\u603b\u662f\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u4f46\u5176\u795e\u7ecf\u8bb0\u5fc6\u7ec4\u4ef6\u76f8\u6bd4\u4ec5\u4f7f\u7528\u6ce8\u610f\u529b\u7684\u6a21\u578b\u80fd\u6301\u7eed\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u7531\u4e8eGoogle\u7684Titans\u6a21\u578b\u7f3a\u4e4f\u516c\u5f00\u4ee3\u7801\u4e14\u539f\u59cb\u63cf\u8ff0\u5b58\u5728\u6a21\u7cca\u6027\uff0c\u963b\u788d\u4e86\u53ef\u590d\u73b0\u6027\uff0c\u56e0\u6b64\u4f5c\u8005\u51b3\u5b9a\u8fdb\u884c\u590d\u73b0\u548c\u8bc4\u4f30\u3002", "method": "\u4f5c\u8005\u5bf9Titans\u6a21\u578b\u8fdb\u884c\u4e86\u8f7b\u91cf\u7ea7\u590d\u73b0\uff0c\u5e76\u5728\u63a9\u7801\u8bed\u8a00\u5efa\u6a21\u3001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u548c\u63a8\u8350\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u7531\u4e8e\u5206\u5757\u5904\u7406\u7684\u539f\u56e0\uff0cTitans\u5e76\u4e0d\u603b\u662f\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\uff0c\u4f46\u5176\u795e\u7ecf\u8bb0\u5fc6\u7ec4\u4ef6\u76f8\u6bd4\u4ec5\u4f7f\u7528\u6ce8\u610f\u529b\u7684\u6a21\u578b\u80fd\u6301\u7eed\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8bc1\u5b9e\u4e86Titans\u6a21\u578b\u7684\u521b\u65b0\u6f5c\u529b\uff0c\u540c\u65f6\u4e5f\u63ed\u793a\u4e86\u5176\u5b9e\u9645\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u51fa\u4e86\u95ee\u9898\u3002"}}
{"id": "2510.09567", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.09567", "abs": "https://arxiv.org/abs/2510.09567", "authors": ["Jacopo Tagliabue", "Ciro Greco"], "title": "Safe, Untrusted, \"Proof-Carrying\" AI Agents: toward the agentic lakehouse", "comment": "IEEE Big Data, Workshop on Secure and Safe AI Agents for Big Data\n  Infrastructures", "summary": "Data lakehouses run sensitive workloads, where AI-driven automation raises\nconcerns about trust, correctness, and governance. We argue that API-first,\nprogrammable lakehouses provide the right abstractions for safe-by-design,\nagentic workflows. Using Bauplan as a case study, we show how data branching\nand declarative environments extend naturally to agents, enabling\nreproducibility and observability while reducing the attack surface. We present\na proof-of-concept in which agents repair data pipelines using correctness\nchecks inspired by proof-carrying code. Our prototype demonstrates that\nuntrusted AI agents can operate safely on production data and outlines a path\ntoward a fully agentic lakehouse.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAPI\u4f18\u5148\u3001\u53ef\u7f16\u7a0b\u7684\u6570\u636e\u6e56\u4ed3\u4e3aAI\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u63d0\u4f9b\u5b89\u5168\u8bbe\u8ba1\u62bd\u8c61\uff0c\u901a\u8fc7\u6570\u636e\u5206\u652f\u548c\u58f0\u660e\u5f0f\u73af\u5883\u5b9e\u73b0\u53ef\u590d\u73b0\u6027\u548c\u53ef\u89c2\u6d4b\u6027\uff0c\u51cf\u5c11\u653b\u51fb\u9762\u3002", "motivation": "\u6570\u636e\u6e56\u4ed3\u8fd0\u884c\u654f\u611f\u5de5\u4f5c\u8d1f\u8f7d\uff0cAI\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u5f15\u53d1\u4e86\u5173\u4e8e\u4fe1\u4efb\u3001\u6b63\u786e\u6027\u548c\u6cbb\u7406\u7684\u62c5\u5fe7\u3002", "method": "\u4f7f\u7528Bauplan\u4f5c\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u6570\u636e\u5206\u652f\u548c\u58f0\u660e\u5f0f\u73af\u5883\u5982\u4f55\u81ea\u7136\u6269\u5c55\u5230\u667a\u80fd\u4f53\uff0c\u5b9e\u73b0\u53ef\u590d\u73b0\u6027\u548c\u53ef\u89c2\u6d4b\u6027\u3002\u63d0\u51fa\u57fa\u4e8e\u8bc1\u660e\u643a\u5e26\u4ee3\u7801\u601d\u60f3\u7684\u6b63\u786e\u6027\u68c0\u67e5\u6982\u5ff5\u9a8c\u8bc1\uff0c\u8ba9\u667a\u80fd\u4f53\u4fee\u590d\u6570\u636e\u7ba1\u9053\u3002", "result": "\u539f\u578b\u6f14\u793a\u8868\u660e\u4e0d\u53d7\u4fe1\u4efb\u7684AI\u667a\u80fd\u4f53\u53ef\u4ee5\u5728\u751f\u4ea7\u6570\u636e\u4e0a\u5b89\u5168\u64cd\u4f5c\uff0c\u5e76\u52fe\u52d2\u51fa\u5b8c\u5168\u667a\u80fd\u4f53\u5316\u6e56\u4ed3\u7684\u5b9e\u73b0\u8def\u5f84\u3002", "conclusion": "API\u4f18\u5148\u3001\u53ef\u7f16\u7a0b\u7684\u6e56\u4ed3\u67b6\u6784\u4e3a\u5b89\u5168\u8bbe\u8ba1\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u5408\u9002\u7684\u62bd\u8c61\uff0c\u80fd\u591f\u5b9e\u73b0\u751f\u4ea7\u73af\u5883\u4e2dAI\u667a\u80fd\u4f53\u7684\u5b89\u5168\u64cd\u4f5c\u3002"}}
{"id": "2510.09580", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09580", "abs": "https://arxiv.org/abs/2510.09580", "authors": ["Margarita Belova", "Jiaxin Xiao", "Shikhar Tuli", "Niraj K. Jha"], "title": "GraphMERT: Efficient and Scalable Distillation of Reliable Knowledge Graphs from Unstructured Data", "comment": null, "summary": "Researchers have pursued neurosymbolic artificial intelligence (AI)\napplications for nearly three decades because symbolic components provide\nabstraction while neural components provide generalization. Thus, a marriage of\nthe two components can lead to rapid advancements in AI. Yet, the field has not\nrealized this promise since most neurosymbolic AI frameworks fail to scale. In\naddition, the implicit representations and approximate reasoning of neural\napproaches limit interpretability and trust. Knowledge graphs (KGs), a\ngold-standard representation of explicit semantic knowledge, can address the\nsymbolic side. However, automatically deriving reliable KGs from text corpora\nhas remained an open problem. We address these challenges by introducing\nGraphMERT, a tiny graphical encoder-only model that distills high-quality KGs\nfrom unstructured text corpora and its own internal representations. GraphMERT\nand its equivalent KG form a modular neurosymbolic stack: neural learning of\nabstractions; symbolic KGs for verifiable reasoning. GraphMERT + KG is the\nfirst efficient and scalable neurosymbolic model to achieve state-of-the-art\nbenchmark accuracy along with superior symbolic representations relative to\nbaselines.\n  Concretely, we target reliable domain-specific KGs that are both (1) factual\n(with provenance) and (2) valid (ontology-consistent relations with\ndomain-appropriate semantics). When a large language model (LLM), e.g.,\nQwen3-32B, generates domain-specific KGs, it falls short on reliability due to\nprompt sensitivity, shallow domain expertise, and hallucinated relations. On\ntext obtained from PubMed papers on diabetes, our 80M-parameter GraphMERT\nyields a KG with a 69.8% FActScore; a 32B-parameter baseline LLM yields a KG\nthat achieves only 40.2% FActScore. The GraphMERT KG also attains a higher\nValidityScore of 68.8%, versus 43.0% for the LLM baseline.", "AI": {"tldr": "GraphMERT\u662f\u4e00\u4e2a\u5c0f\u578b\u56fe\u5f62\u7f16\u7801\u5668\u6a21\u578b\uff0c\u901a\u8fc7\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u8bed\u6599\u5e93\u53ca\u5176\u5185\u90e8\u8868\u793a\u4e2d\u63d0\u53d6\u9ad8\u8d28\u91cf\u77e5\u8bc6\u56fe\u8c31\uff0c\u89e3\u51b3\u4e86\u795e\u7ecf\u7b26\u53f7AI\u7684\u53ef\u6269\u5c55\u6027\u548c\u53ef\u89e3\u91ca\u6027\u95ee\u9898\u3002", "motivation": "\u795e\u7ecf\u7b26\u53f7AI\u9886\u57df\u8fd1\u4e09\u5341\u5e74\u6765\u672a\u80fd\u5b9e\u73b0\u5176\u6f5c\u529b\uff0c\u4e3b\u8981\u56e0\u4e3a\u73b0\u6709\u6846\u67b6\u96be\u4ee5\u6269\u5c55\uff0c\u4e14\u795e\u7ecf\u65b9\u6cd5\u7684\u9690\u5f0f\u8868\u793a\u548c\u8fd1\u4f3c\u63a8\u7406\u9650\u5236\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u3002\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u663e\u5f0f\u8bed\u4e49\u77e5\u8bc6\u7684\u9ec4\u91d1\u6807\u51c6\u8868\u793a\u53ef\u4ee5\u89e3\u51b3\u7b26\u53f7\u65b9\u9762\u7684\u95ee\u9898\uff0c\u4f46\u4ece\u6587\u672c\u8bed\u6599\u5e93\u81ea\u52a8\u63a8\u5bfc\u53ef\u9760\u7684\u77e5\u8bc6\u56fe\u8c31\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002", "method": "\u5f15\u5165GraphMERT\uff0c\u4e00\u4e2a\u5fae\u5c0f\u7684\u56fe\u5f62\u7f16\u7801\u5668\u6a21\u578b\uff0c\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u8bed\u6599\u5e93\u53ca\u5176\u5185\u90e8\u8868\u793a\u4e2d\u63d0\u53d6\u9ad8\u8d28\u91cf\u77e5\u8bc6\u56fe\u8c31\u3002GraphMERT\u53ca\u5176\u7b49\u6548\u77e5\u8bc6\u56fe\u8c31\u5f62\u6210\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u795e\u7ecf\u7b26\u53f7\u5806\u6808\uff1a\u795e\u7ecf\u5b66\u4e60\u62bd\u8c61\uff1b\u7b26\u53f7\u77e5\u8bc6\u56fe\u8c31\u7528\u4e8e\u53ef\u9a8c\u8bc1\u63a8\u7406\u3002", "result": "\u5728PubMed\u7cd6\u5c3f\u75c5\u8bba\u6587\u6587\u672c\u4e0a\uff0c80M\u53c2\u6570\u7684GraphMERT\u751f\u6210\u7684\u77e5\u8bc6\u56fe\u8c31\u8fbe\u523069.8%\u7684FActScore\uff0c\u800c32B\u53c2\u6570\u7684\u57fa\u7ebfLLM\u4ec5\u8fbe\u523040.2%\u3002GraphMERT\u77e5\u8bc6\u56fe\u8c31\u8fd8\u83b7\u5f9768.8%\u7684ValidityScore\uff0c\u800cLLM\u57fa\u7ebf\u4e3a43.0%\u3002", "conclusion": "GraphMERT + KG\u662f\u7b2c\u4e00\u4e2a\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\uff0c\u5728\u5b9e\u73b0\u6700\u5148\u8fdb\u57fa\u51c6\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u76f8\u5bf9\u4e8e\u57fa\u7ebf\u5177\u6709\u4f18\u8d8a\u7684\u7b26\u53f7\u8868\u793a\u80fd\u529b\u3002"}}
{"id": "2510.09595", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09595", "abs": "https://arxiv.org/abs/2510.09595", "authors": ["Kaijian Zou", "Aaron Xiong", "Yunxiang Zhang", "Frederick Zhang", "Yueqi Ren", "Jirong Yang", "Ayoung Lee", "Shitanshu Bhushan", "Lu Wang"], "title": "LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?", "comment": null, "summary": "Competitive programming problems increasingly serve as valuable benchmarks to\nevaluate the coding capabilities of large language models (LLMs) due to their\ncomplexity and ease of verification. Yet, current coding benchmarks face\nlimitations such as lack of exceptionally challenging problems, insufficient\ntest case coverage, reliance on online platform APIs that limit accessibility.\nTo address these issues, we introduce LiveOIBench, a comprehensive benchmark\nfeaturing 403 expert-curated Olympiad-level competitive programming problems,\neach with an average of 60 expert-designed test cases. The problems are sourced\ndirectly from 72 official Informatics Olympiads in different regions conducted\nbetween 2023 and 2025. LiveOIBench distinguishes itself through four key\nfeatures: (1) meticulously curated high-quality tasks with detailed subtask\nrubrics and extensive private test cases; (2) direct integration of elite\ncontestant performance data to enable informative comparison against\ntop-performing humans; (3) planned continuous, contamination-free updates from\nnewly released Olympiad problems; and (4) a self-contained evaluation system\nfacilitating offline and easy-to-reproduce assessments. Benchmarking 32 popular\ngeneral-purpose and reasoning LLMs, we find that GPT-5 achieves a notable\n81.76th percentile, a strong result that nonetheless falls short of top human\ncontestant performance, who usually place above 90th. In contrast, among\nopen-weight reasoning models, GPT-OSS-120B achieves only a 60th percentile,\nunderscoring significant capability disparities from frontier closed models.\nDetailed analyses indicate that robust reasoning models prioritize precise\nproblem analysis over excessive exploration, suggesting future models should\nemphasize structured analysis and minimize unnecessary exploration. All data,\ncode, and leaderboard results will be made publicly available on our website.", "AI": {"tldr": "LiveOIBench\u662f\u4e00\u4e2a\u5305\u542b403\u4e2a\u5965\u6797\u5339\u514b\u7ea7\u7f16\u7a0b\u7ade\u8d5b\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5177\u6709\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u7528\u4f8b\u548c\u4eba\u7c7b\u8868\u73b0\u5bf9\u6bd4\uff0c\u8bc4\u4f30\u663e\u793aGPT-5\u8fbe\u523081.76\u767e\u5206\u4f4d\u4f46\u4ecd\u843d\u540e\u4e8e\u9876\u5c16\u4eba\u7c7b\u9009\u624b\u3002", "motivation": "\u5f53\u524d\u7f16\u7a0b\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u7f3a\u4e4f\u9ad8\u96be\u5ea6\u95ee\u9898\u3001\u6d4b\u8bd5\u7528\u4f8b\u4e0d\u8db3\u3001\u4f9d\u8d56\u5728\u7ebf\u5e73\u53f0API\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u5de5\u5177\u6765\u6d4b\u8bd5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7f16\u7a0b\u80fd\u529b\u3002", "method": "\u4ece72\u4e2a\u5b98\u65b9\u4fe1\u606f\u5b66\u5965\u6797\u5339\u514b\u7ade\u8d5b\u4e2d\u6536\u96c6403\u4e2a\u4e13\u5bb6\u7b56\u5212\u7684\u95ee\u9898\uff0c\u6bcf\u4e2a\u95ee\u9898\u5e73\u574760\u4e2a\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5efa\u7acb\u5305\u542b\u8be6\u7ec6\u5b50\u4efb\u52a1\u8bc4\u5206\u548c\u79c1\u6709\u6d4b\u8bd5\u7528\u4f8b\u7684\u8bc4\u4f30\u7cfb\u7edf\u3002", "result": "GPT-5\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523081.76\u767e\u5206\u4f4d\uff0c\u800c\u5f00\u6e90\u6a21\u578bGPT-OSS-120B\u4ec5\u8fbe\u523060\u767e\u5206\u4f4d\uff0c\u663e\u793a\u4e0e\u524d\u6cbf\u95ed\u6e90\u6a21\u578b\u7684\u663e\u8457\u80fd\u529b\u5dee\u8ddd\u3002", "conclusion": "\u5f3a\u5927\u7684\u63a8\u7406\u6a21\u578b\u5e94\u4f18\u5148\u7cbe\u786e\u7684\u95ee\u9898\u5206\u6790\u800c\u975e\u8fc7\u5ea6\u63a2\u7d22\uff0c\u672a\u6765\u6a21\u578b\u5e94\u5f3a\u8c03\u7ed3\u6784\u5316\u5206\u6790\u5e76\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u63a2\u7d22\u3002"}}

{"id": "2512.09088", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09088", "abs": "https://arxiv.org/abs/2512.09088", "authors": ["Adrian Ryser", "Florian Allwein", "Tim Schlippe"], "title": "Calibrated Trust in Dealing with LLM Hallucinations: A Qualitative Study", "comment": null, "summary": "Hallucinations are outputs by Large Language Models (LLMs) that are factually incorrect yet appear plausible [1]. This paper investigates how such hallucinations influence users' trust in LLMs and users' interaction with LLMs. To explore this in everyday use, we conducted a qualitative study with 192 participants. Our findings show that hallucinations do not result in blanket mistrust but instead lead to context-sensitive trust calibration. Building on the calibrated trust model by Lee & See [2] and Afroogh et al.'s trust-related factors [3], we confirm expectancy [3], [4], prior experience [3], [4], [5], and user expertise & domain knowledge [3], [4] as userrelated (human) trust factors, and identify intuition as an additional factor relevant for hallucination detection. Additionally, we found that trust dynamics are further influenced by contextual factors, particularly perceived risk [3] and decision stakes [6]. Consequently, we validate the recursive trust calibration process proposed by Bl\u00f6baum [7] and extend it by including intuition as a user-related trust factor. Based on these insights, we propose practical recommendations for responsible and reflective LLM use.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ea7\u751f\u7684\u5e7b\u89c9\u5982\u4f55\u5f71\u54cd\u7528\u6237\u4fe1\u4efb\uff0c\u53d1\u73b0\u5e7b\u89c9\u4e0d\u4f1a\u5bfc\u81f4\u5168\u9762\u4e0d\u4fe1\u4efb\uff0c\u800c\u662f\u5f15\u53d1\u60c5\u5883\u654f\u611f\u7684\u4fe1\u4efb\u6821\u51c6\uff0c\u5e76\u8bc6\u522b\u4e86\u76f4\u89c9\u4f5c\u4e3a\u65b0\u7684\u7528\u6237\u76f8\u5173\u4fe1\u4efb\u56e0\u7d20\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ea7\u751f\u7684\u5e7b\u89c9\uff08\u4e8b\u5b9e\u9519\u8bef\u4f46\u770b\u4f3c\u5408\u7406\uff09\u5982\u4f55\u5f71\u54cd\u7528\u6237\u5bf9LLM\u7684\u4fe1\u4efb\u4ee5\u53ca\u7528\u6237\u4e0eLLM\u7684\u4e92\u52a8\uff0c\u7406\u89e3\u5728\u65e5\u5e38\u4f7f\u7528\u4e2d\u5e7b\u89c9\u5bf9\u4fe1\u4efb\u52a8\u6001\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u5b9a\u6027\u7814\u7a76\u65b9\u6cd5\uff0c\u5bf9192\u540d\u53c2\u4e0e\u8005\u8fdb\u884c\u7814\u7a76\uff0c\u57fa\u4e8eLee & See\u7684\u6821\u51c6\u4fe1\u4efb\u6a21\u578b\u548cAfroogh\u7b49\u4eba\u7684\u4fe1\u4efb\u76f8\u5173\u56e0\u7d20\u6846\u67b6\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5e7b\u89c9\u4e0d\u4f1a\u5bfc\u81f4\u5168\u9762\u4e0d\u4fe1\u4efb\uff0c\u800c\u662f\u5f15\u53d1\u60c5\u5883\u654f\u611f\u7684\u4fe1\u4efb\u6821\u51c6\uff1b\u786e\u8ba4\u4e86\u671f\u671b\u3001\u5148\u524d\u7ecf\u9a8c\u3001\u7528\u6237\u4e13\u4e1a\u77e5\u8bc6\u548c\u9886\u57df\u77e5\u8bc6\u4f5c\u4e3a\u7528\u6237\u76f8\u5173\u4fe1\u4efb\u56e0\u7d20\uff0c\u5e76\u8bc6\u522b\u76f4\u89c9\u4f5c\u4e3a\u5e7b\u89c9\u68c0\u6d4b\u7684\u989d\u5916\u56e0\u7d20\uff1b\u4fe1\u4efb\u52a8\u6001\u8fd8\u53d7\u5230\u611f\u77e5\u98ce\u9669\u548c\u51b3\u7b56\u98ce\u9669\u7b49\u60c5\u5883\u56e0\u7d20\u7684\u5f71\u54cd\u3002", "conclusion": "\u9a8c\u8bc1\u4e86Bl\u00f6baum\u63d0\u51fa\u7684\u9012\u5f52\u4fe1\u4efb\u6821\u51c6\u8fc7\u7a0b\uff0c\u5e76\u901a\u8fc7\u7eb3\u5165\u76f4\u89c9\u4f5c\u4e3a\u7528\u6237\u76f8\u5173\u4fe1\u4efb\u56e0\u7d20\u6269\u5c55\u4e86\u8be5\u6a21\u578b\uff1b\u57fa\u4e8e\u7814\u7a76\u53d1\u73b0\u63d0\u51fa\u4e86\u8d1f\u8d23\u4efb\u548c\u53cd\u601d\u6027\u4f7f\u7528LLM\u7684\u5b9e\u8df5\u5efa\u8bae\u3002"}}
{"id": "2512.09114", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.09114", "abs": "https://arxiv.org/abs/2512.09114", "authors": ["Pamela Gupta"], "title": "AI TIPS 2.0: A Comprehensive Framework for Operationalizing AI Governance", "comment": "47 pages", "summary": "The deployment of AI systems faces three critical governance challenges that current frameworks fail to adequately address. First, organizations struggle with inadequate risk assessment at the use case level, exemplified by the Humana class action lawsuit and other high impact cases where an AI system deployed to production exhibited both significant bias and high error rates, resulting in improper healthcare claim denials. Each AI use case presents unique risk profiles requiring tailored governance, yet most frameworks provide one size fits all guidance. Second, existing frameworks like ISO 42001 and NIST AI RMF remain at high conceptual levels, offering principles without actionable controls, leaving practitioners unable to translate governance requirements into specific technical implementations. Third, organizations lack mechanisms for operationalizing governance at scale, with no systematic approach to embed trustworthy AI practices throughout the development lifecycle, measure compliance quantitatively, or provide role-appropriate visibility from boards to data scientists. We present AI TIPS, Artificial Intelligence Trust-Integrated Pillars for Sustainability 2.0, update to the comprehensive operational framework developed in 2019,four years before NIST's AI Risk Management Framework, that directly addresses these challenges.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86AI TIPS\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5f53\u524dAI\u6cbb\u7406\u6846\u67b6\u7684\u4e09\u4e2a\u5173\u952e\u7f3a\u9677\uff1a\u7f3a\u4e4f\u9488\u5bf9\u5177\u4f53\u7528\u4f8b\u7684\u98ce\u9669\u8bc4\u4f30\u3001\u8fc7\u4e8e\u6982\u5ff5\u5316\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u63a7\u5236\u3001\u4ee5\u53ca\u7f3a\u5c11\u89c4\u6a21\u5316\u5b9e\u65bd\u673a\u5236\u3002", "motivation": "\u5f53\u524dAI\u6cbb\u7406\u6846\u67b6\u5b58\u5728\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a1) \u7ec4\u7ec7\u5728\u7528\u4f8b\u5c42\u9762\u7f3a\u4e4f\u5145\u5206\u7684\u98ce\u9669\u8bc4\u4f30\u80fd\u529b\uff0c\u5982Humana\u96c6\u4f53\u8bc9\u8bbc\u6848\u6240\u793a\uff1b2) \u73b0\u6709\u6846\u67b6\u5982ISO 42001\u548cNIST AI RMF\u505c\u7559\u5728\u6982\u5ff5\u5c42\u9762\uff0c\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u7684\u63a7\u5236\u63aa\u65bd\uff1b3) \u7ec4\u7ec7\u7f3a\u4e4f\u89c4\u6a21\u5316\u5b9e\u65bd\u6cbb\u7406\u7684\u673a\u5236\uff0c\u65e0\u6cd5\u5c06\u53ef\u4fe1AI\u5b9e\u8df5\u5d4c\u5165\u6574\u4e2a\u5f00\u53d1\u751f\u547d\u5468\u671f\u3002", "method": "\u63d0\u51fa\u4e86AI TIPS\uff08\u4eba\u5de5\u667a\u80fd\u4fe1\u4efb\u96c6\u6210\u652f\u67f1\u53ef\u6301\u7eed\u60272.0\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u5bf92019\u5e74\u5f00\u53d1\u7684\u5168\u9762\u64cd\u4f5c\u6846\u67b6\u7684\u66f4\u65b0\uff0c\u6bd4NIST\u7684AI\u98ce\u9669\u7ba1\u7406\u6846\u67b6\u65e9\u56db\u5e74\u3002\u8be5\u6846\u67b6\u76f4\u63a5\u9488\u5bf9\u4e0a\u8ff0\u6311\u6218\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u66f4\u65b0\u7684\u64cd\u4f5c\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5f53\u524dAI\u6cbb\u7406\u7684\u7f3a\u9677\uff0c\u4f46\u6458\u8981\u4e2d\u672a\u63d0\u4f9b\u5177\u4f53\u7684\u5b9e\u65bd\u7ed3\u679c\u6216\u8bc4\u4f30\u6570\u636e\u3002", "conclusion": "AI TIPS\u6846\u67b6\u4e3a\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u89e3\u51b3\u5f53\u524dAI\u6cbb\u7406\u6311\u6218\u7684\u5b9e\u7528\u65b9\u6cd5\uff0c\u5305\u62ec\u9488\u5bf9\u5177\u4f53\u7528\u4f8b\u7684\u98ce\u9669\u8bc4\u4f30\u3001\u53ef\u64cd\u4f5c\u7684\u63a7\u5236\u63aa\u65bd\u4ee5\u53ca\u89c4\u6a21\u5316\u5b9e\u65bd\u673a\u5236\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6846\u67b6\u7684\u7a7a\u767d\u3002"}}
{"id": "2512.09117", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09117", "abs": "https://arxiv.org/abs/2512.09117", "authors": ["Luciano Floridi", "Yiyang Jia", "Fernando Tohm\u00e9"], "title": "A Categorical Analysis of Large Language Models and Why LLMs Circumvent the Symbol Grounding Problem", "comment": null, "summary": "This paper presents a formal, categorical framework for analysing how humans and large language models (LLMs) transform content into truth-evaluated propositions about a state space of possible worlds W , in order to argue that LLMs do not solve but circumvent the symbol grounding problem.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u7684\u8303\u7574\u8bba\u6846\u67b6\uff0c\u5206\u6790\u4eba\u7c7b\u548cLLM\u5982\u4f55\u5c06\u5185\u5bb9\u8f6c\u5316\u4e3a\u5173\u4e8e\u53ef\u80fd\u4e16\u754c\u72b6\u6001\u7a7a\u95f4\u7684\u771f\u503c\u547d\u9898\uff0c\u8bba\u8bc1LLM\u5e76\u672a\u89e3\u51b3\u800c\u662f\u7ed5\u8fc7\u4e86\u7b26\u53f7\u63a5\u5730\u95ee\u9898", "motivation": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u4e0e\u4eba\u7c7b\u5728\u7b26\u53f7\u63a5\u5730\u95ee\u9898\u4e0a\u7684\u672c\u8d28\u5dee\u5f02\uff0c\u7406\u89e3LLM\u5982\u4f55\u5904\u7406\u8bed\u4e49\u548c\u771f\u503c\u547d\u9898", "method": "\u4f7f\u7528\u8303\u7574\u8bba\u7684\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u5206\u6790\u4eba\u7c7b\u548cLLM\u5c06\u5185\u5bb9\u8f6c\u5316\u4e3a\u5173\u4e8e\u53ef\u80fd\u4e16\u754c\u72b6\u6001\u7a7a\u95f4W\u7684\u771f\u503c\u547d\u9898\u7684\u8fc7\u7a0b", "result": "LLM\u5e76\u672a\u771f\u6b63\u89e3\u51b3\u7b26\u53f7\u63a5\u5730\u95ee\u9898\uff0c\u800c\u662f\u901a\u8fc7\u4e0d\u540c\u7684\u673a\u5236\u7ed5\u8fc7\u4e86\u8be5\u95ee\u9898", "conclusion": "LLM\u4e0e\u4eba\u7c7b\u5728\u7b26\u53f7\u63a5\u5730\u673a\u5236\u4e0a\u5b58\u5728\u6839\u672c\u5dee\u5f02\uff0cLLM\u7684\"\u7406\u89e3\"\u65b9\u5f0f\u4e0d\u540c\u4e8e\u4eba\u7c7b\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u7ecf\u9a8c\u7684\u7b26\u53f7\u63a5\u5730\u8fc7\u7a0b"}}
{"id": "2512.09142", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09142", "abs": "https://arxiv.org/abs/2512.09142", "authors": ["Sergio Burdisso", "S\u00e9verin Baroudi", "Yanis Labrak", "David Grunert", "Pawel Cyrta", "Yiyang Chen", "Srikanth Madikeri", "Esa\u00fa Villatoro-Tello", "Thomas Schaaf", "Ricard Marxer", "Petr Motlicek"], "title": "SDialog: A Python Toolkit for End-to-End Agent Building, User Simulation, Dialog Generation, and Evaluation", "comment": "Pre-print submitted to EACL System Demonstration (under review)", "summary": "We present SDialog, an MIT-licensed open-source Python toolkit that unifies dialog generation, evaluation and mechanistic interpretability into a single end-to-end framework for building and analyzing LLM-based conversational agents. Built around a standardized \\texttt{Dialog} representation, SDialog provides: (1) persona-driven multi-agent simulation with composable orchestration for controlled, synthetic dialog generation, (2) comprehensive evaluation combining linguistic metrics, LLM-as-a-judge and functional correctness validators, (3) mechanistic interpretability tools for activation inspection and steering via feature ablation and induction, and (4) audio generation with full acoustic simulation including 3D room modeling and microphone effects. The toolkit integrates with all major LLM backends, enabling mixed-backend experiments under a unified API. By coupling generation, evaluation, and interpretability in a dialog-centric architecture, SDialog enables researchers to build, benchmark and understand conversational systems more systematically.", "AI": {"tldr": "SDialog\u662f\u4e00\u4e2a\u5f00\u6e90Python\u5de5\u5177\u5305\uff0c\u5c06\u5bf9\u8bdd\u751f\u6210\u3001\u8bc4\u4f30\u548c\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7edf\u4e00\u5230\u7aef\u5230\u7aef\u6846\u67b6\u4e2d\uff0c\u7528\u4e8e\u6784\u5efa\u548c\u5206\u6790\u57fa\u4e8eLLM\u7684\u5bf9\u8bdd\u7cfb\u7edf\u3002", "motivation": "\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u6846\u67b6\u6765\u6784\u5efa\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u7406\u89e3\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u5c06\u751f\u6210\u3001\u8bc4\u4f30\u548c\u53ef\u89e3\u91ca\u6027\u529f\u80fd\u96c6\u6210\u5230\u7edf\u4e00\u7684\u5bf9\u8bdd\u4e2d\u5fc3\u67b6\u6784\u4e2d\u3002", "method": "\u57fa\u4e8e\u6807\u51c6\u5316\u7684Dialog\u8868\u793a\uff0c\u63d0\u4f9b\uff1a1\uff09\u89d2\u8272\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u6a21\u62df\u4e0e\u53ef\u7ec4\u5408\u7f16\u6392\uff1b2\uff09\u7ed3\u5408\u8bed\u8a00\u6307\u6807\u3001LLM\u4f5c\u4e3a\u8bc4\u5224\u548c\u529f\u80fd\u6b63\u786e\u6027\u9a8c\u8bc1\u7684\u7efc\u5408\u8bc4\u4f30\uff1b3\uff09\u901a\u8fc7\u7279\u5f81\u6d88\u878d\u548c\u8bf1\u5bfc\u8fdb\u884c\u6fc0\u6d3b\u68c0\u67e5\u548c\u5f15\u5bfc\u7684\u673a\u5236\u53ef\u89e3\u91ca\u6027\u5de5\u5177\uff1b4\uff09\u5305\u542b3D\u623f\u95f4\u5efa\u6a21\u548c\u9ea6\u514b\u98ce\u6548\u679c\u7684\u5b8c\u6574\u58f0\u5b66\u6a21\u62df\u97f3\u9891\u751f\u6210\u3002", "result": "SDialog\u5de5\u5177\u5305\u96c6\u6210\u4e86\u6240\u6709\u4e3b\u8981LLM\u540e\u7aef\uff0c\u652f\u6301\u7edf\u4e00API\u4e0b\u7684\u6df7\u5408\u540e\u7aef\u5b9e\u9a8c\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u66f4\u7cfb\u7edf\u5730\u6784\u5efa\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u7406\u89e3\u5bf9\u8bdd\u7cfb\u7edf\u3002", "conclusion": "SDialog\u901a\u8fc7\u5c06\u751f\u6210\u3001\u8bc4\u4f30\u548c\u53ef\u89e3\u91ca\u6027\u8026\u5408\u5230\u5bf9\u8bdd\u4e2d\u5fc3\u67b6\u6784\u4e2d\uff0c\u4e3a\u6784\u5efa\u548c\u5206\u6790\u57fa\u4e8eLLM\u7684\u5bf9\u8bdd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u3001\u7cfb\u7edf\u5316\u7684\u5f00\u6e90\u6846\u67b6\u3002"}}
{"id": "2512.09049", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09049", "abs": "https://arxiv.org/abs/2512.09049", "authors": ["Gandham Sai Santhosh", "Siddhartha Sanjay Naik", "Ritwik Badola", "Chester Rebeiro"], "title": "EMMap: A Systematic Framework for Spatial EMFI Mapping and Fault Classification on Microcontrollers", "comment": null, "summary": "Electromagnetic Fault Injection (EMFI) is a powerful technique for inducing bit flips and instruction-level perturbations on microcontrollers, yet existing literature lacks a unified methodology for systematically mapping spatial sensitivity and classifying resulting fault behaviors. Building on insights from O'Flynn and Kuhnapfel et al., we introduce a platform-agnostic framework for Spatial EMFI Mapping and Fault Classification, aimed at understanding how spatial probe position influences fault outcomes. We present pilot experiments on three representative microcontroller targets including the Xtensa LX6 (ESP32) and two ChipWhisper boards not as definitive evaluations, but as illustrative demonstrations of how the proposed methodology can be applied in practice. These preliminary observations motivate a generalized and reproducible workflow that researchers can adopt when analyzing EMFI susceptibility across diverse embedded architectures.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5e73\u53f0\u65e0\u5173\u7684\u7535\u78c1\u6545\u969c\u6ce8\u5165\u7a7a\u95f4\u6620\u5c04\u4e0e\u6545\u969c\u5206\u7c7b\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u5206\u6790\u5fae\u63a7\u5236\u5668\u5bf9\u7535\u78c1\u6545\u969c\u7684\u7a7a\u95f4\u654f\u611f\u6027", "motivation": "\u73b0\u6709\u6587\u732e\u7f3a\u4e4f\u7edf\u4e00\u7684\u65b9\u6cd5\u6765\u7cfb\u7edf\u6620\u5c04\u7535\u78c1\u6545\u969c\u6ce8\u5165\u7684\u7a7a\u95f4\u654f\u611f\u6027\u548c\u5206\u7c7b\u6545\u969c\u884c\u4e3a\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u91cd\u590d\u7684\u5de5\u4f5c\u6d41\u7a0b\u6765\u5206\u6790\u4e0d\u540c\u5d4c\u5165\u5f0f\u67b6\u6784\u7684EMFI\u654f\u611f\u6027", "method": "\u57fa\u4e8eO'Flynn\u548cKuhnapfel\u7b49\u4eba\u7684\u89c1\u89e3\uff0c\u5f00\u53d1\u5e73\u53f0\u65e0\u5173\u7684\u7a7a\u95f4EMFI\u6620\u5c04\u548c\u6545\u969c\u5206\u7c7b\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u4e2a\u4ee3\u8868\u6027\u5fae\u63a7\u5236\u5668\uff08\u5305\u62ecXtensa LX6\u548c\u4e24\u4e2aChipWhisper\u677f\uff09\u8fdb\u884c\u8bd5\u70b9\u5b9e\u9a8c\u6f14\u793a", "result": "\u521d\u6b65\u5b9e\u9a8c\u5c55\u793a\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u5de5\u4f5c\u6d41\u7a0b\u6765\u5206\u6790\u4e0d\u540c\u5d4c\u5165\u5f0f\u67b6\u6784\u7684EMFI\u654f\u611f\u6027", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7cfb\u7edf\u7814\u7a76\u7535\u78c1\u6545\u969c\u6ce8\u5165\u7684\u7a7a\u95f4\u654f\u611f\u6027\u63d0\u4f9b\u4e86\u901a\u7528\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u7814\u7a76\u4eba\u5458\u5728\u4e0d\u540c\u5d4c\u5165\u5f0f\u67b6\u6784\u4e0a\u5206\u6790EMFI\u6f0f\u6d1e"}}
{"id": "2512.09277", "categories": ["cs.DC", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.09277", "abs": "https://arxiv.org/abs/2512.09277", "authors": ["Yanpeng Yu", "Haiyue Ma", "Krish Agarwal", "Nicolai Oswald", "Qijing Huang", "Hugo Linsenmaier", "Chunhui Mei", "Ritchie Zhao", "Ritika Borkar", "Bita Darvish Rouhani", "David Nellans", "Ronny Krashinsky", "Anurag Khandelwal"], "title": "Efficient MoE Serving in the Memory-Bound Regime: Balance Activated Experts, Not Tokens", "comment": null, "summary": "Expert Parallelism (EP) permits Mixture of Experts (MoE) models to scale beyond a single GPU. To address load imbalance across GPUs in EP, existing approaches aim to balance the number of tokens each GPU processes. Surprisingly, we find that this objective degrades performance rather than improving it when processing is memory-bound - a common occurrence in MoE serving, especially in the decode phase. Our analysis reveals that balancing the number of tokens processed per GPU increases the number of activated experts, exacerbating memory pressure in the memory-bound regime.\n  We propose Minimum Expert Token ROuting, a novel token-routing algorithm for high-performance expert-parallel MoE serving in the memory-bound regime that balances the number of activated experts per GPU rather than token counts. METRO achieves near-optimal routing quality with minimal computational overhead by jointly optimizing algorithmic efficiency and leveraging the GPU's parallel processing power. To guarantee routing quality, METRO also employs a novel allGather scheme to gather global top-k knowledge, which has minimal overhead compared to conventional allToAll. Our evaluation of METRO against EPLB on both real systems (vLLM over 8 A100 GPUs) and a proprietary simulator (8-16 B200 GPUs) shows that METRO reduces decode latency by 11 - 22%, and total token throughput by 3 - 21% for Qwen3 and DeepSeek-V3 serving, where prefill and decode phases are co-deployed. In addition, by trading latency headroom for throughput, METRO improves decode throughput by up to 4.11x over EPLB at a fixed decode SLO.", "AI": {"tldr": "METRO\u662f\u4e00\u79cd\u9488\u5bf9\u5185\u5b58\u53d7\u9650\u573a\u666f\u7684MoE\u6a21\u578b\u4e13\u5bb6\u5e76\u884c\u670d\u52a1\u8def\u7531\u7b97\u6cd5\uff0c\u901a\u8fc7\u5e73\u8861GPU\u6fc0\u6d3b\u4e13\u5bb6\u6570\u91cf\u800c\u975e\u4ee4\u724c\u6570\u91cf\uff0c\u663e\u8457\u964d\u4f4e\u89e3\u7801\u5ef6\u8fdf\u5e76\u63d0\u5347\u541e\u5410\u91cf\u3002", "motivation": "\u73b0\u6709\u4e13\u5bb6\u5e76\u884c\u65b9\u6cd5\u901a\u8fc7\u5e73\u8861\u5404GPU\u5904\u7406\u7684\u4ee4\u724c\u6570\u91cf\u6765\u89e3\u51b3\u8d1f\u8f7d\u4e0d\u5747\u8861\u95ee\u9898\uff0c\u4f46\u5728\u5185\u5b58\u53d7\u9650\u7684MoE\u670d\u52a1\u573a\u666f\uff08\u7279\u522b\u662f\u89e3\u7801\u9636\u6bb5\uff09\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53cd\u800c\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u56e0\u4e3a\u5b83\u589e\u52a0\u4e86\u6fc0\u6d3b\u4e13\u5bb6\u6570\u91cf\uff0c\u52a0\u5267\u4e86\u5185\u5b58\u538b\u529b\u3002", "method": "\u63d0\u51faMETRO\uff08Minimum Expert Token ROuting\uff09\u7b97\u6cd5\uff0c\u5728\u5185\u5b58\u53d7\u9650\u573a\u666f\u4e0b\u5e73\u8861\u5404GPU\u6fc0\u6d3b\u7684\u4e13\u5bb6\u6570\u91cf\u800c\u975e\u4ee4\u724c\u6570\u91cf\uff1b\u91c7\u7528\u65b0\u9896\u7684allGather\u65b9\u6848\u6536\u96c6\u5168\u5c40top-k\u4fe1\u606f\uff0c\u76f8\u6bd4\u4f20\u7edfallToAll\u5f00\u9500\u66f4\u5c0f\uff1b\u8054\u5408\u4f18\u5316\u7b97\u6cd5\u6548\u7387\u548cGPU\u5e76\u884c\u5904\u7406\u80fd\u529b\u3002", "result": "\u5728\u771f\u5b9e\u7cfb\u7edf\uff08vLLM over 8 A100 GPUs\uff09\u548c\u4e13\u6709\u6a21\u62df\u5668\uff088-16 B200 GPUs\uff09\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4EPLB\uff1a\u89e3\u7801\u5ef6\u8fdf\u964d\u4f4e11-22%\uff0c\u603b\u4ee4\u724c\u541e\u5410\u91cf\u63d0\u53473-21%\uff08Qwen3\u548cDeepSeek-V3\u670d\u52a1\uff09\uff1b\u5728\u56fa\u5b9a\u89e3\u7801SLO\u4e0b\uff0c\u89e3\u7801\u541e\u5410\u91cf\u6700\u9ad8\u63d0\u53474.11\u500d\u3002", "conclusion": "\u5728\u5185\u5b58\u53d7\u9650\u7684MoE\u670d\u52a1\u573a\u666f\u4e2d\uff0c\u5e73\u8861\u6fc0\u6d3b\u4e13\u5bb6\u6570\u91cf\u6bd4\u5e73\u8861\u4ee4\u724c\u6570\u91cf\u66f4\u6709\u6548\uff1bMETRO\u7b97\u6cd5\u901a\u8fc7\u4f18\u5316\u8def\u7531\u7b56\u7565\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4e3a\u4e13\u5bb6\u5e76\u884c\u670d\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u4f18\u5316\u65b9\u5411\u3002"}}
{"id": "2512.09340", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.09340", "abs": "https://arxiv.org/abs/2512.09340", "authors": ["Chethana Prasad Kabgere"], "title": "Visual Categorization Across Minds and Models: Cognitive Analysis of Human Labeling and Neuro-Symbolic Integration", "comment": "12 pages, 3 figures. Research manuscript based on the final project for CS6795 (Introduction to Cognitive Science), Georgia Tech", "summary": "Understanding how humans and AI systems interpret ambiguous visual stimuli offers critical insight into the nature of perception, reasoning, and decision-making. This paper examines image labeling performance across human participants and deep neural networks, focusing on low-resolution, perceptually degraded stimuli. Drawing from computational cognitive science, cognitive architectures, and connectionist-symbolic hybrid models, we contrast human strategies such as analogical reasoning, shape-based recognition, and confidence modulation with AI's feature-based processing. Grounded in Marr's tri-level hypothesis, Simon's bounded rationality, and Thagard's frameworks of representation and emotion, we analyze participant responses in relation to Grad-CAM visualizations of model attention. Human behavior is further interpreted through cognitive principles modeled in ACT-R and Soar, revealing layered and heuristic decision strategies under uncertainty. Our findings highlight key parallels and divergences between biological and artificial systems in representation, inference, and confidence calibration. The analysis motivates future neuro-symbolic architectures that unify structured symbolic reasoning with connectionist representations. Such architectures, informed by principles of embodiment, explainability, and cognitive alignment, offer a path toward AI systems that are not only performant but also interpretable and cognitively grounded.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9\u6bd4\u4eba\u7c7b\u548cAI\u7cfb\u7edf\u5728\u6a21\u7cca\u89c6\u89c9\u523a\u6fc0\u4e0b\u7684\u56fe\u50cf\u6807\u6ce8\u8868\u73b0\uff0c\u5206\u6790\u4e24\u8005\u5728\u611f\u77e5\u3001\u63a8\u7406\u548c\u51b3\u7b56\u65b9\u9762\u7684\u5f02\u540c\uff0c\u4e3a\u6784\u5efa\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\u63d0\u4f9b\u8ba4\u77e5\u79d1\u5b66\u57fa\u7840\u3002", "motivation": "\u7814\u7a76\u4eba\u7c7b\u4e0eAI\u7cfb\u7edf\u5982\u4f55\u89e3\u91ca\u6a21\u7cca\u89c6\u89c9\u523a\u6fc0\uff0c\u6df1\u5165\u4e86\u89e3\u611f\u77e5\u3001\u63a8\u7406\u548c\u51b3\u7b56\u7684\u672c\u8d28\uff0c\u4e3a\u5f00\u53d1\u66f4\u53ef\u89e3\u91ca\u3001\u8ba4\u77e5\u5bf9\u9f50\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u7ed3\u5408\u8ba1\u7b97\u8ba4\u77e5\u79d1\u5b66\u3001\u8ba4\u77e5\u67b6\u6784\u548c\u8fde\u63a5\u4e3b\u4e49-\u7b26\u53f7\u6df7\u5408\u6a21\u578b\uff0c\u5bf9\u6bd4\u4eba\u7c7b\u7b56\u7565\uff08\u7c7b\u6bd4\u63a8\u7406\u3001\u5f62\u72b6\u8bc6\u522b\u3001\u7f6e\u4fe1\u5ea6\u8c03\u8282\uff09\u4e0eAI\u7684\u7279\u5f81\u5904\u7406\uff1b\u57fa\u4e8eMarr\u7684\u4e09\u5c42\u6b21\u5047\u8bbe\u3001Simon\u7684\u6709\u9650\u7406\u6027\u548cThagard\u7684\u8868\u5f81\u4e0e\u60c5\u611f\u6846\u67b6\uff0c\u5206\u6790\u53c2\u4e0e\u8005\u53cd\u5e94\u4e0eGrad-CAM\u53ef\u89c6\u5316\u6a21\u578b\u6ce8\u610f\u529b\uff1b\u901a\u8fc7ACT-R\u548cSoar\u8ba4\u77e5\u67b6\u6784\u89e3\u91ca\u4eba\u7c7b\u884c\u4e3a\u3002", "result": "\u63ed\u793a\u4e86\u751f\u7269\u4e0e\u4eba\u5de5\u7cfb\u7edf\u5728\u8868\u5f81\u3001\u63a8\u7406\u548c\u7f6e\u4fe1\u5ea6\u6821\u51c6\u65b9\u9762\u7684\u5173\u952e\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\u6027\uff1b\u4eba\u7c7b\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u91c7\u7528\u5206\u5c42\u548c\u542f\u53d1\u5f0f\u51b3\u7b56\u7b56\u7565\u3002", "conclusion": "\u5206\u6790\u4e3a\u672a\u6765\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\u63d0\u4f9b\u4e86\u52a8\u673a\uff0c\u8fd9\u7c7b\u67b6\u6784\u5c06\u7ed3\u6784\u5316\u7b26\u53f7\u63a8\u7406\u4e0e\u8fde\u63a5\u4e3b\u4e49\u8868\u5f81\u76f8\u7edf\u4e00\uff0c\u57fa\u4e8e\u5177\u8eab\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8ba4\u77e5\u5bf9\u9f50\u539f\u5219\uff0c\u6709\u671b\u5f00\u53d1\u51fa\u65e2\u9ad8\u6548\u53c8\u53ef\u89e3\u91ca\u3001\u8ba4\u77e5\u57fa\u7840\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2512.09150", "categories": ["cs.CR", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.09150", "abs": "https://arxiv.org/abs/2512.09150", "authors": ["Anirudh Nakra", "Nayeeb Rashid", "Chau-Wai Wong", "Min Wu"], "title": "Exposing Vulnerabilities in Counterfeit Prevention Systems Utilizing Physically Unclonable Surface Features", "comment": "15 pages; This work builds on arXiv:2408.02221 [cs.CR]", "summary": "Counterfeit products pose significant risks to public health and safety through infiltrating untrusted supply chains. Among numerous anti-counterfeiting techniques, leveraging inherent, unclonable microscopic irregularities of paper surfaces is an accurate and cost-effective solution. Prior work of this approach has focused on enabling ubiquitous acquisition of these physically unclonable features (PUFs). However, we will show that existing authentication methods relying on paper surface PUFs may be vulnerable to adversaries, resulting in a gap between technological feasibility and secure real-world deployment. This gap is investigated through formalizing an operational framework for paper-PUF-based authentication. Informed by this framework, we reveal system-level vulnerabilities across both physical and digital domains, designing physical denial-of-service and digital forgery attacks to disrupt proper authentication. The effectiveness of the designed attacks underscores the strong need for security countermeasures for reliable and resilient authentication based on paper PUFs. The proposed framework further facilitates a comprehensive, stage-by-stage security analysis, guiding the design of future counterfeit prevention systems. This analysis delves into potential attack strategies, offering a foundational understanding of how various system components, such as physical features and verification processes, might be exploited by adversaries.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u57fa\u4e8e\u7eb8\u5f20\u8868\u9762\u7269\u7406\u4e0d\u53ef\u514b\u9686\u7279\u5f81(PUF)\u7684\u9632\u4f2a\u8ba4\u8bc1\u7cfb\u7edf\u5b58\u5728\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u64cd\u4f5c\u6846\u67b6\u6765\u63ed\u793a\u7269\u7406\u548c\u6570\u5b57\u9886\u57df\u7684\u7cfb\u7edf\u7ea7\u8106\u5f31\u6027\uff0c\u5e76\u8bbe\u8ba1\u4e86\u653b\u51fb\u65b9\u6cd5\u6765\u9a8c\u8bc1\u8fd9\u4e9b\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7eb8\u5f20\u8868\u9762\u5fae\u89c2\u4e0d\u89c4\u5219\u6027\u7684\u9632\u4f2a\u8ba4\u8bc1\u65b9\u6cd5\u867d\u7136\u51c6\u786e\u4e14\u6210\u672c\u6548\u76ca\u9ad8\uff0c\u4f46\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u53ef\u80fd\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\u3002\u8bba\u6587\u65e8\u5728\u63ed\u793a\u8fd9\u4e9b\u7cfb\u7edf\u5728\u7269\u7406\u548c\u6570\u5b57\u9886\u57df\u7684\u8106\u5f31\u6027\uff0c\u586b\u8865\u6280\u672f\u53ef\u884c\u6027\u4e0e\u5b89\u5168\u5b9e\u9645\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "1. \u5f62\u5f0f\u5316\u57fa\u4e8e\u7eb8\u5f20PUF\u7684\u8ba4\u8bc1\u64cd\u4f5c\u6846\u67b6\uff1b2. \u57fa\u4e8e\u8be5\u6846\u67b6\u5206\u6790\u7cfb\u7edf\u7ea7\u6f0f\u6d1e\uff1b3. \u8bbe\u8ba1\u7269\u7406\u62d2\u7edd\u670d\u52a1\u548c\u6570\u5b57\u4f2a\u9020\u653b\u51fb\u6765\u9a8c\u8bc1\u6f0f\u6d1e\uff1b4. \u8fdb\u884c\u5206\u9636\u6bb5\u7684\u5b89\u5168\u5206\u6790\u3002", "result": "\u8bbe\u8ba1\u7684\u653b\u51fb\u65b9\u6cd5\u6709\u6548\u8bc1\u660e\u4e86\u73b0\u6709\u7eb8\u5f20PUF\u8ba4\u8bc1\u7cfb\u7edf\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u5b89\u5168\u5bf9\u7b56\u6765\u786e\u4fdd\u57fa\u4e8e\u7eb8\u5f20PUF\u7684\u8ba4\u8bc1\u7684\u53ef\u9760\u6027\u548c\u97e7\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u5168\u9762\u7684\u5206\u9636\u6bb5\u5b89\u5168\u5206\u6790\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u6307\u5bfc\u672a\u6765\u9632\u4f2a\u7cfb\u7edf\u7684\u8bbe\u8ba1\uff0c\u6df1\u5165\u63a2\u8ba8\u4e86\u6f5c\u5728\u653b\u51fb\u7b56\u7565\uff0c\u4e3a\u7406\u89e3\u7cfb\u7edf\u5404\u7ec4\u4ef6\u5982\u4f55\u88ab\u653b\u51fb\u8005\u5229\u7528\u63d0\u4f9b\u4e86\u57fa\u7840\u7406\u89e3\u3002"}}
{"id": "2512.09309", "categories": ["cs.DC", "cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.09309", "abs": "https://arxiv.org/abs/2512.09309", "authors": ["Zihao Ding", "Mufeng Zhu", "Zhongze Tang", "Sheng Wei", "Yao Liu"], "title": "A Distributed Framework for Privacy-Enhanced Vision Transformers on the Edge", "comment": "16 pages, 7 figures. Published in the Proceedings of the Tenth ACM/IEEE Symposium on Edge Computing (SEC '25), Dec 3-6, 2025, Washington, D.C., USA", "summary": "Nowadays, visual intelligence tools have become ubiquitous, offering all kinds of convenience and possibilities. However, these tools have high computational requirements that exceed the capabilities of resource-constrained mobile and wearable devices. While offloading visual data to the cloud is a common solution, it introduces significant privacy vulnerabilities during transmission and server-side computation. To address this, we propose a novel distributed, hierarchical offloading framework for Vision Transformers (ViTs) that addresses these privacy challenges by design. Our approach uses a local trusted edge device, such as a mobile phone or an Nvidia Jetson, as the edge orchestrator. This orchestrator partitions the user's visual data into smaller portions and distributes them across multiple independent cloud servers. By design, no single external server possesses the complete image, preventing comprehensive data reconstruction. The final data merging and aggregation computation occurs exclusively on the user's trusted edge device. We apply our framework to the Segment Anything Model (SAM) as a practical case study, which demonstrates that our method substantially enhances content privacy over traditional cloud-based approaches. Evaluations show our framework maintains near-baseline segmentation performance while substantially reducing the risk of content reconstruction and user data exposure. Our framework provides a scalable, privacy-preserving solution for vision tasks in the edge-cloud continuum.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9Vision Transformers\u7684\u5206\u5e03\u5f0f\u5206\u5c42\u5378\u8f7d\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u53ef\u4fe1\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5206\u5272\u89c6\u89c9\u6570\u636e\u5e76\u5206\u53d1\u5230\u591a\u4e2a\u72ec\u7acb\u4e91\u670d\u52a1\u5668\uff0c\u9632\u6b62\u4efb\u4f55\u5355\u4e00\u670d\u52a1\u5668\u83b7\u53d6\u5b8c\u6574\u56fe\u50cf\uff0c\u4ece\u800c\u4fdd\u62a4\u9690\u79c1\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u667a\u80fd\u5de5\u5177\u8ba1\u7b97\u9700\u6c42\u9ad8\uff0c\u8d85\u51fa\u79fb\u52a8\u548c\u53ef\u7a7f\u6234\u8bbe\u5907\u80fd\u529b\uff0c\u800c\u5c06\u6570\u636e\u5378\u8f7d\u5230\u4e91\u7aef\u4f1a\u5e26\u6765\u4f20\u8f93\u548c\u670d\u52a1\u5668\u7aef\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002", "method": "\u4f7f\u7528\u672c\u5730\u53ef\u4fe1\u8fb9\u7f18\u8bbe\u5907\uff08\u5982\u624b\u673a\u6216Nvidia Jetson\uff09\u4f5c\u4e3a\u8fb9\u7f18\u534f\u8c03\u5668\uff0c\u5c06\u7528\u6237\u89c6\u89c9\u6570\u636e\u5206\u5272\u6210\u5c0f\u5757\u5e76\u5206\u53d1\u5230\u591a\u4e2a\u72ec\u7acb\u4e91\u670d\u52a1\u5668\uff0c\u6700\u7ec8\u5408\u5e76\u548c\u805a\u5408\u8ba1\u7b97\u4ec5\u5728\u53ef\u4fe1\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8fdb\u884c\u3002", "result": "\u4ee5Segment Anything Model\u4e3a\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u63a5\u8fd1\u57fa\u7ebf\u5206\u5272\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5bb9\u91cd\u5efa\u548c\u7528\u6237\u6570\u636e\u66b4\u9732\u7684\u98ce\u9669\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8fb9\u7f18-\u4e91\u8fde\u7eed\u4f53\u4e2d\u7684\u89c6\u89c9\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u8bbe\u8ba1\u9632\u6b62\u4efb\u4f55\u5355\u4e00\u5916\u90e8\u670d\u52a1\u5668\u83b7\u53d6\u5b8c\u6574\u56fe\u50cf\u3002"}}
{"id": "2512.09304", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.09304", "abs": "https://arxiv.org/abs/2512.09304", "authors": ["Siyuan Ma", "Jiajun Hu", "Jeeho Ryoo", "Aman Arora", "Lizy Kurian John"], "title": "RACAM: Enhancing DRAM with Reuse-Aware Computation and Automated Mapping for ML Inference", "comment": null, "summary": "In-DRAM Processing-In-Memory (DRAM-PIM) has emerged as a promising approach to accelerate memory-intensive workloads by mitigating data transfer overhead between DRAM and the host processor. Bit-serial DRAM-PIM architectures, further enhance efficiency by supporting runtime variable data precision, which is critical for emerging workloads, such as large language model (LLM) inference. However, existing works still have major limitations: lack of data reuse, significant amounts of redundant data transfer, and insufficient support for workload mapping. To address these issues, we propose RACAM, the first in-DRAM bit-serial architecture which uses dedicated locality buffers, bit-serial PEs, popcount reduction units and broadcast units to enable data reuse and alleviate redundant data transfers. Furthermore, a workload mapping mechanism is proposed to fully explore the massive parallelism of DRAM architecture and identify the best mapping scheme of a given workload. We evaluate RACAM against GPUs and the state-of-the-art, in-DRAM PIM system, Proteus, across end-to-end LLM inferences. RACAM achieves 9x to 102x speedup over GPUs and 233x higher performance per mm2 compared to Proteus in case of GPT3.", "AI": {"tldr": "RACAM\u662f\u4e00\u79cd\u65b0\u578b\u7684DRAM\u5185\u5b58\u8ba1\u7b97\u67b6\u6784\uff0c\u901a\u8fc7\u4e13\u7528\u7f13\u51b2\u5668\u3001\u4f4d\u4e32\u884c\u5904\u7406\u5355\u5143\u548c\u5e7f\u64ad\u5355\u5143\u89e3\u51b3\u73b0\u6709DRAM-PIM\u67b6\u6784\u7684\u6570\u636e\u91cd\u7528\u4e0d\u8db3\u3001\u5197\u4f59\u6570\u636e\u4f20\u8f93\u548c\u5de5\u4f5c\u8d1f\u8f7d\u6620\u5c04\u95ee\u9898\uff0c\u5728LLM\u63a8\u7406\u4e2d\u76f8\u6bd4GPU\u548c\u73b0\u6709PIM\u7cfb\u7edf\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709DRAM-PIM\u67b6\u6784\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u7f3a\u4e4f\u6570\u636e\u91cd\u7528\u3001\u5927\u91cf\u5197\u4f59\u6570\u636e\u4f20\u8f93\u3001\u4ee5\u53ca\u5de5\u4f5c\u8d1f\u8f7d\u6620\u5c04\u652f\u6301\u4e0d\u8db3\u3002\u8fd9\u4e9b\u95ee\u9898\u9650\u5236\u4e86\u5185\u5b58\u8ba1\u7b97\u67b6\u6784\u5728\u5904\u7406\u65b0\u5174\u5de5\u4f5c\u8d1f\u8f7d\uff08\u5982\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff09\u65f6\u7684\u6548\u7387\u548c\u6027\u80fd\u3002", "method": "\u63d0\u51faRACAM\u67b6\u6784\uff0c\u5305\u542b\uff1a1\uff09\u4e13\u7528\u5c40\u90e8\u6027\u7f13\u51b2\u533a\u5b9e\u73b0\u6570\u636e\u91cd\u7528\uff1b2\uff09\u4f4d\u4e32\u884c\u5904\u7406\u5355\u5143\u652f\u6301\u8fd0\u884c\u65f6\u53ef\u53d8\u6570\u636e\u7cbe\u5ea6\uff1b3\uff09popcount\u5f52\u7ea6\u5355\u5143\u548c\u5e7f\u64ad\u5355\u5143\u51cf\u5c11\u5197\u4f59\u6570\u636e\u4f20\u8f93\uff1b4\uff09\u5de5\u4f5c\u8d1f\u8f7d\u6620\u5c04\u673a\u5236\u5145\u5206\u5229\u7528DRAM\u67b6\u6784\u7684\u5927\u89c4\u6a21\u5e76\u884c\u6027\uff0c\u4e3a\u7ed9\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u627e\u5230\u6700\u4f73\u6620\u5c04\u65b9\u6848\u3002", "result": "\u5728\u7aef\u5230\u7aefLLM\u63a8\u7406\u8bc4\u4f30\u4e2d\uff0cRACAM\u76f8\u6bd4GPU\u5b9e\u73b09\u500d\u5230102\u500d\u7684\u52a0\u901f\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684DRAM-PIM\u7cfb\u7edfProteus\uff0c\u5728GPT3\u63a8\u7406\u4e2d\u5b9e\u73b0\u6bcf\u5e73\u65b9\u6beb\u7c73233\u500d\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "RACAM\u901a\u8fc7\u521b\u65b0\u7684\u67b6\u6784\u8bbe\u8ba1\u89e3\u51b3\u4e86\u73b0\u6709DRAM-PIM\u7cfb\u7edf\u7684\u5173\u952e\u9650\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5185\u5b58\u8ba1\u7b97\u5728\u5904\u7406\u5927\u8bed\u8a00\u6a21\u578b\u7b49\u65b0\u5174\u5de5\u4f5c\u8d1f\u8f7d\u65f6\u7684\u6027\u80fd\u548c\u80fd\u6548\uff0c\u4e3a\u672a\u6765\u5185\u5b58\u8ba1\u7b97\u67b6\u6784\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u65b9\u5411\u3002"}}
{"id": "2512.09233", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09233", "abs": "https://arxiv.org/abs/2512.09233", "authors": ["Alan T. Sherman", "Jeremy J. Romanik Romano", "Edward Zieglar", "Enis Golaszewski", "Jonathan D. Fuchs", "William E. Byrd"], "title": "Analysis of the Security Design, Engineering, and Implementation of the SecureDNA System", "comment": "A shorter version of this paper will appear in the Proceedings of the Network and Distributed System Security Symposium (NDSS) 2026 published by the Internet Society", "summary": "We analyze security aspects of the SecureDNA system regarding its system design, engineering, and implementation. This system enables DNA synthesizers to screen order requests against a database of hazards. By applying novel cryptography, the system aims to keep order requests and the database of hazards secret. Discerning the detailed operation of the system in part from source code (Version 1.0.8), our analysis examines key management, certificate infrastructure, authentication, and rate-limiting mechanisms. We also perform the first formal-methods analysis of the mutual authentication, basic request, and exemption-handling protocols.\n  Without breaking the cryptography, our main finding is that SecureDNA's custom mutual authentication protocol SCEP achieves only one-way authentication: the hazards database and keyservers never learn with whom they communicate. This structural weakness violates the principle of defense in depth and enables an adversary to circumvent rate limits that protect the secrecy of the hazards database, if the synthesizer connects with a malicious or corrupted keyserver or hashed database. We point out an additional structural weakness that also violates the principle of defense in depth: inadequate cryptographic bindings prevent the system from detecting if responses, within a TLS channel, from the hazards database were modified. Consequently, if a synthesizer were to reconnect with the database over the same TLS session, an adversary could replay and swap responses from the database without breaking TLS. Although the SecureDNA implementation does not allow such reconnections, it would be stronger security engineering to avoid the underlying structural weakness. We identify these vulnerabilities and suggest and verify mitigations, including adding strong bindings. Software Version 1.1.0 fixes SCEP with our proposed SCEP+ protocol.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u5206\u6790\u4e86SecureDNA\u7cfb\u7edf\u7684\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u5176\u81ea\u5b9a\u4e49\u7684SCEP\u534f\u8bae\u4ec5\u5b9e\u73b0\u5355\u5411\u8ba4\u8bc1\uff0c\u5b58\u5728\u7ed3\u6784\u6027\u5f31\u70b9\uff0c\u5141\u8bb8\u653b\u51fb\u8005\u7ed5\u8fc7\u901f\u7387\u9650\u5236\u5e76\u7be1\u6539\u6570\u636e\u5e93\u54cd\u5e94\uff0c\u5efa\u8bae\u4e86\u4fee\u590d\u65b9\u6848\u3002", "motivation": "SecureDNA\u7cfb\u7edf\u65e8\u5728\u901a\u8fc7\u65b0\u578b\u5bc6\u7801\u5b66\u4fdd\u62a4DNA\u5408\u6210\u8ba2\u5355\u8bf7\u6c42\u548c\u5371\u9669\u6570\u636e\u5e93\u7684\u673a\u5bc6\u6027\uff0c\u4f46\u9700\u8981\u9a8c\u8bc1\u5176\u7cfb\u7edf\u8bbe\u8ba1\u3001\u5de5\u7a0b\u5b9e\u73b0\u548c\u534f\u8bae\u7684\u5b89\u5168\u6027\uff0c\u7279\u522b\u662f\u5173\u952e\u7ba1\u7406\u3001\u8bc1\u4e66\u57fa\u7840\u8bbe\u65bd\u3001\u8ba4\u8bc1\u548c\u901f\u7387\u9650\u5236\u673a\u5236\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6e90\u4ee3\u7801\uff08\u7248\u672c1.0.8\uff09\uff0c\u68c0\u67e5\u5173\u952e\u7ba1\u7406\u3001\u8bc1\u4e66\u57fa\u7840\u8bbe\u65bd\u3001\u8ba4\u8bc1\u548c\u901f\u7387\u9650\u5236\u673a\u5236\uff1b\u9996\u6b21\u5bf9\u76f8\u4e92\u8ba4\u8bc1\u3001\u57fa\u672c\u8bf7\u6c42\u548c\u8c41\u514d\u5904\u7406\u534f\u8bae\u8fdb\u884c\u5f62\u5f0f\u5316\u65b9\u6cd5\u5206\u6790\u3002", "result": "\u4e3b\u8981\u53d1\u73b0SecureDNA\u7684\u81ea\u5b9a\u4e49\u76f8\u4e92\u8ba4\u8bc1\u534f\u8baeSCEP\u4ec5\u5b9e\u73b0\u5355\u5411\u8ba4\u8bc1\uff0c\u6570\u636e\u5e93\u548c\u5bc6\u94a5\u670d\u52a1\u5668\u65e0\u6cd5\u8bc6\u522b\u901a\u4fe1\u5bf9\u8c61\uff1b\u5b58\u5728\u7ed3\u6784\u6027\u5f31\u70b9\uff0c\u5141\u8bb8\u653b\u51fb\u8005\u7ed5\u8fc7\u4fdd\u62a4\u6570\u636e\u5e93\u673a\u5bc6\u6027\u7684\u901f\u7387\u9650\u5236\uff1b\u5b58\u5728\u52a0\u5bc6\u7ed1\u5b9a\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u53ef\u80fd\u5bfc\u81f4\u54cd\u5e94\u88ab\u7be1\u6539\u3002", "conclusion": "SecureDNA\u7cfb\u7edf\u5b58\u5728\u4e25\u91cd\u7684\u5b89\u5168\u8bbe\u8ba1\u7f3a\u9677\uff0c\u8fdd\u53cd\u4e86\u6df1\u5ea6\u9632\u5fa1\u539f\u5219\uff1b\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u4fee\u590d\u65b9\u6848\uff0c\u5305\u62ec\u6dfb\u52a0\u5f3a\u7ed1\u5b9a\uff1b\u8f6f\u4ef6\u7248\u672c1.1.0\u5df2\u4f7f\u7528\u5efa\u8bae\u7684SCEP+\u534f\u8bae\u4fee\u590d\u4e86SCEP\u95ee\u9898\u3002"}}
{"id": "2512.09331", "categories": ["cs.DC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.09331", "abs": "https://arxiv.org/abs/2512.09331", "authors": ["Nam Anh Dang", "Ben Landrum", "Ken Birman"], "title": "Passing the Baton: High Throughput Distributed Disk-Based Vector Search with BatANN", "comment": "12 pages, 14 figures, submitted to VLDB 2026", "summary": "Vector search underpins modern information-retrieval systems, including retrieval-augmented generation (RAG) pipelines and search engines over unstructured text and images. As datasets scale to billions of vectors, disk-based vector search has emerged as a practical solution. However, looking to the future, we need to anticipate datasets too large for any single server. We present BatANN, a distributed disk-based approximate nearest neighbor (ANN) system that retains the logarithmic search efficiency of a single global graph while achieving near-linear throughput scaling in the number of servers. Our core innovation is that when accessing a neighborhood which is stored on another machine, we send the full state of the query to the other machine to continue executing there for improved locality. On 100M- and 1B-point datasets at 0.95 recall using 10 servers, BatANN achieves 6.21-6.49x and 2.5-5.10x the throughput of the scatter-gather baseline, respectively, while maintaining mean latency below 6 ms. Moreover, we get these results on standard TCP. To our knowledge, BatANN is the first open-source distributed disk-based vector search system to operate over a single global graph.", "AI": {"tldr": "BatANN\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u78c1\u76d8\u5411\u91cf\u641c\u7d22\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06\u67e5\u8be2\u72b6\u6001\u53d1\u9001\u5230\u6570\u636e\u6240\u5728\u673a\u5668\u6267\u884c\uff0c\u5728\u4fdd\u6301\u5355\u673a\u5bf9\u6570\u641c\u7d22\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u8fd1\u7ebf\u6027\u541e\u5410\u6269\u5c55\u3002", "motivation": "\u968f\u7740\u6570\u636e\u96c6\u6269\u5c55\u5230\u6570\u5341\u4ebf\u5411\u91cf\uff0c\u78c1\u76d8\u5411\u91cf\u641c\u7d22\u6210\u4e3a\u5b9e\u7528\u65b9\u6848\uff0c\u4f46\u672a\u6765\u9700\u8981\u5904\u7406\u5355\u4e2a\u670d\u52a1\u5668\u65e0\u6cd5\u5bb9\u7eb3\u7684\u8d85\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u56e0\u6b64\u9700\u8981\u5206\u5e03\u5f0f\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6838\u5fc3\u521b\u65b0\u662f\u5f53\u8bbf\u95ee\u5b58\u50a8\u5728\u53e6\u4e00\u53f0\u673a\u5668\u4e0a\u7684\u90bb\u57df\u65f6\uff0c\u5c06\u67e5\u8be2\u7684\u5b8c\u6574\u72b6\u6001\u53d1\u9001\u5230\u8be5\u673a\u5668\u7ee7\u7eed\u6267\u884c\uff0c\u63d0\u9ad8\u5c40\u90e8\u6027\u3002\u7cfb\u7edf\u57fa\u4e8e\u5355\u4e2a\u5168\u5c40\u56fe\uff0c\u5728\u6807\u51c6TCP\u4e0a\u8fd0\u884c\u3002", "result": "\u57281\u4ebf\u548c10\u4ebf\u70b9\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u752810\u53f0\u670d\u52a1\u5668\u8fbe\u52300.95\u53ec\u56de\u7387\u65f6\uff0c\u541e\u5410\u91cf\u5206\u522b\u6bd4scatter-gather\u57fa\u7ebf\u63d0\u9ad86.21-6.49\u500d\u548c2.5-5.10\u500d\uff0c\u5e73\u5747\u5ef6\u8fdf\u4f4e\u4e8e6\u6beb\u79d2\u3002", "conclusion": "BatANN\u662f\u9996\u4e2a\u57fa\u4e8e\u5355\u4e2a\u5168\u5c40\u56fe\u7684\u5f00\u6e90\u5206\u5e03\u5f0f\u78c1\u76d8\u5411\u91cf\u641c\u7d22\u7cfb\u7edf\uff0c\u5728\u4fdd\u6301\u5bf9\u6570\u641c\u7d22\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u8fd1\u7ebf\u6027\u541e\u5410\u6269\u5c55\uff0c\u4e3a\u8d85\u5927\u89c4\u6a21\u5411\u91cf\u641c\u7d22\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.09427", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09427", "abs": "https://arxiv.org/abs/2512.09427", "authors": ["Guoqiang Zou", "Wanyu Wang", "Hao Zheng", "Longxiang Yin", "Yinhe Han"], "title": "ODMA: On-Demand Memory Allocation Framework for LLM Serving on LPDDR-Class Accelerators", "comment": "10 pages, 5 figures", "summary": "Serving large language models (LLMs) on accelerators with poor random-access bandwidth (e.g., LPDDR5-based) is limited by current memory managers. Static pre-allocation wastes memory, while fine-grained paging (e.g., PagedAttention) is ill-suited due to high random-access costs. Existing HBM-centric solutions do not exploit the characteristics of random-access-constrained memory (RACM) accelerators like Cambricon MLU370. We present ODMA, an on-demand memory allocation framework for RACM. ODMA addresses distribution drift and heavy-tailed requests by coupling a lightweight length predictor with dynamic bucket partitioning and a large-bucket safeguard. Boundaries are periodically updated from live traces to maximize utilization. On Alpaca and Google-NQ, ODMA improves prediction accuracy of prior work significantly (e.g., from 82.68% to 93.36%). Serving DeepSeek-R1-Distill-Qwen-7B on Cambricon MLU370-X4, ODMA raises memory utilization from 55.05% to 72.45% and improves RPS and TPS by 29% and 27% over static baselines. This demonstrates that hardware-aware allocation unlocks efficient LLM serving on RACM platforms.", "AI": {"tldr": "ODMA\u662f\u4e00\u4e2a\u9488\u5bf9\u968f\u673a\u8bbf\u95ee\u53d7\u9650\u5185\u5b58\uff08RACM\uff09\u52a0\u901f\u5668\u7684\u6309\u9700\u5185\u5b58\u5206\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u957f\u5ea6\u9884\u6d4b\u5668\u3001\u52a8\u6001\u6876\u5206\u533a\u548c\u5927\u6876\u4fdd\u62a4\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347LLM\u5728RACM\u5e73\u53f0\u4e0a\u7684\u670d\u52a1\u6548\u7387\u3002", "motivation": "\u5728\u968f\u673a\u8bbf\u95ee\u5e26\u5bbd\u53d7\u9650\u7684\u52a0\u901f\u5668\uff08\u5982\u57fa\u4e8eLPDDR5\u7684Cambricon MLU370\uff09\u4e0a\u670d\u52a1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u73b0\u6709\u5185\u5b58\u7ba1\u7406\u65b9\u6848\u5b58\u5728\u5c40\u9650\uff1a\u9759\u6001\u9884\u5206\u914d\u6d6a\u8d39\u5185\u5b58\uff0c\u7ec6\u7c92\u5ea6\u5206\u9875\uff08\u5982PagedAttention\uff09\u56e0\u9ad8\u968f\u673a\u8bbf\u95ee\u6210\u672c\u800c\u4e0d\u9002\u7528\uff0c\u73b0\u6709HBM\u4e3a\u4e2d\u5fc3\u7684\u89e3\u51b3\u65b9\u6848\u65e0\u6cd5\u5145\u5206\u5229\u7528RACM\u52a0\u901f\u5668\u7279\u6027\u3002", "method": "ODMA\u6846\u67b6\u7ed3\u5408\u8f7b\u91cf\u7ea7\u957f\u5ea6\u9884\u6d4b\u5668\u4e0e\u52a8\u6001\u6876\u5206\u533a\u548c\u5927\u6876\u4fdd\u62a4\u673a\u5236\uff0c\u901a\u8fc7\u4ece\u5b9e\u65f6\u8ddf\u8e2a\u4e2d\u5b9a\u671f\u66f4\u65b0\u8fb9\u754c\u6765\u6700\u5927\u5316\u5185\u5b58\u5229\u7528\u7387\uff0c\u89e3\u51b3\u4e86\u5206\u5e03\u6f02\u79fb\u548c\u91cd\u5c3e\u8bf7\u6c42\u95ee\u9898\u3002", "result": "\u5728Alpaca\u548cGoogle-NQ\u6570\u636e\u96c6\u4e0a\uff0cODMA\u5c06\u9884\u6d4b\u51c6\u786e\u7387\u4ece82.68%\u63d0\u5347\u81f393.36%\uff1b\u5728Cambricon MLU370-X4\u4e0a\u670d\u52a1DeepSeek-R1-Distill-Qwen-7B\u6a21\u578b\u65f6\uff0c\u5185\u5b58\u5229\u7528\u7387\u4ece55.05%\u63d0\u5347\u81f372.45%\uff0cRPS\u548cTPS\u5206\u522b\u6bd4\u9759\u6001\u57fa\u7ebf\u63d0\u9ad829%\u548c27%\u3002", "conclusion": "\u786c\u4ef6\u611f\u77e5\u7684\u5185\u5b58\u5206\u914d\u80fd\u591f\u89e3\u9501RACM\u5e73\u53f0\u4e0a\u9ad8\u6548\u7684LLM\u670d\u52a1\uff0cODMA\u6846\u67b6\u901a\u8fc7\u9488\u5bf9RACM\u7279\u6027\u7684\u4f18\u5316\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5185\u5b58\u5229\u7528\u7387\u548c\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2512.09566", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.09566", "abs": "https://arxiv.org/abs/2512.09566", "authors": ["Junkai Ji", "Zhangfan Yang", "Dong Xu", "Ruibin Bai", "Jianqiang Li", "Tingjun Hou", "Zexuan Zhu"], "title": "Toward Closed-loop Molecular Discovery via Language Model, Property Alignment and Strategic Search", "comment": "21 pages, 5 figures", "summary": "Drug discovery is a time-consuming and expensive process, with traditional high-throughput and docking-based virtual screening hampered by low success rates and limited scalability. Recent advances in generative modelling, including autoregressive, diffusion, and flow-based approaches, have enabled de novo ligand design beyond the limits of enumerative screening. Yet these models often suffer from inadequate generalization, limited interpretability, and an overemphasis on binding affinity at the expense of key pharmacological properties, thereby restricting their translational utility. Here we present Trio, a molecular generation framework integrating fragment-based molecular language modeling, reinforcement learning, and Monte Carlo tree search, for effective and interpretable closed-loop targeted molecular design. Through the three key components, Trio enables context-aware fragment assembly, enforces physicochemical and synthetic feasibility, and guides a balanced search between the exploration of novel chemotypes and the exploitation of promising intermediates within protein binding pockets. Experimental results show that Trio reliably achieves chemically valid and pharmacologically enhanced ligands, outperforming state-of-the-art approaches with improved binding affinity (+7.85%), drug-likeness (+11.10%) and synthetic accessibility (+12.05%), while expanding molecular diversity more than fourfold.", "AI": {"tldr": "Trio\u662f\u4e00\u4e2a\u6574\u5408\u4e86\u57fa\u4e8e\u7247\u6bb5\u7684\u5206\u5b50\u8bed\u8a00\u5efa\u6a21\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7684\u5206\u5b50\u751f\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u95ed\u73af\u9776\u5411\u5206\u5b50\u8bbe\u8ba1\uff0c\u5728\u7ed3\u5408\u4eb2\u548c\u529b\u3001\u7c7b\u836f\u6027\u548c\u5408\u6210\u53ef\u884c\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u836f\u7269\u53d1\u73b0\u65b9\u6cd5\u8017\u65f6\u6602\u8d35\u4e14\u6210\u529f\u7387\u4f4e\uff0c\u73b0\u6709\u7684\u751f\u6210\u6a21\u578b\u5b58\u5728\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3001\u53ef\u89e3\u91ca\u6027\u6709\u9650\u3001\u8fc7\u5ea6\u5f3a\u8c03\u7ed3\u5408\u4eb2\u548c\u529b\u800c\u5ffd\u89c6\u5173\u952e\u836f\u7406\u5b66\u7279\u6027\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "method": "Trio\u6846\u67b6\u6574\u5408\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1) \u57fa\u4e8e\u7247\u6bb5\u7684\u5206\u5b50\u8bed\u8a00\u5efa\u6a21\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u7247\u6bb5\u7ec4\u88c5\uff1b2) \u5f3a\u5316\u5b66\u4e60\u786e\u4fdd\u7269\u7406\u5316\u5b66\u548c\u5408\u6210\u53ef\u884c\u6027\uff1b3) \u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u5e73\u8861\u65b0\u9896\u5316\u5b66\u578b\u63a2\u7d22\u548c\u86cb\u767d\u8d28\u7ed3\u5408\u53e3\u888b\u4e2d\u6709\u524d\u666f\u4e2d\u95f4\u4f53\u7684\u5229\u7528\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTrio\u53ef\u9760\u5730\u751f\u6210\u5316\u5b66\u6709\u6548\u4e14\u836f\u7406\u5b66\u589e\u5f3a\u7684\u914d\u4f53\uff0c\u5728\u7ed3\u5408\u4eb2\u548c\u529b\uff08+7.85%\uff09\u3001\u7c7b\u836f\u6027\uff08+11.10%\uff09\u548c\u5408\u6210\u53ef\u884c\u6027\uff08+12.05%\uff09\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u540c\u65f6\u5c06\u5206\u5b50\u591a\u6837\u6027\u6269\u5c55\u8d85\u8fc7\u56db\u500d\u3002", "conclusion": "Trio\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u95ed\u73af\u9776\u5411\u5206\u5b50\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u7247\u6bb5\u7ec4\u88c5\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff0c\u5728\u4fdd\u6301\u5316\u5b66\u6709\u6548\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u836f\u7406\u5b66\u7279\u6027\uff0c\u4e3a\u836f\u7269\u53d1\u73b0\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2512.09472", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.09472", "abs": "https://arxiv.org/abs/2512.09472", "authors": ["Chiheng Lou", "Sheng Qi", "Rui Kang", "Yong Zhang", "Chen Sun", "Pengcheng Wang", "Bingyang Liu", "Xuanzhe Liu", "Xin Jin"], "title": "WarmServe: Enabling One-for-Many GPU Prewarming for Multi-LLM Serving", "comment": null, "summary": "Deploying multiple models within shared GPU clusters is promising for improving resource efficiency in large language model (LLM) serving. Existing multi-LLM serving systems optimize GPU utilization at the cost of worse inference performance, especially time-to-first-token (TTFT). We identify the root cause of such compromise as their unawareness of future workload characteristics. In contrast, recent analysis on real-world traces has shown the high periodicity and long-term predictability of LLM serving workloads.\n  We propose universal GPU workers to enable one-for-many GPU prewarming that loads models with knowledge of future workloads. Based on universal GPU workers, we design and build WarmServe, a multi-LLM serving system that (1) mitigates cluster-wide prewarming interference by adopting an evict-aware model placement strategy, (2) prepares universal GPU workers in advance by proactive prewarming, and (3) manages GPU memory with a zero-overhead memory switching mechanism. Evaluation under real-world datasets shows that WarmServe improves TTFT by up to 50.8$\\times$ compared to the state-of-the-art autoscaling-based system, while being capable of serving up to 2.5$\\times$ more requests compared to the GPU-sharing system.", "AI": {"tldr": "WarmServe\u662f\u4e00\u4e2a\u591aLLM\u670d\u52a1\u7cfb\u7edf\uff0c\u901a\u8fc7\u9884\u77e5\u672a\u6765\u5de5\u4f5c\u8d1f\u8f7d\u7279\u5f81\u7684GPU\u9884\u70ed\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u9996\u4ee4\u724c\u65f6\u95f4\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8d44\u6e90\u5229\u7528\u7387\u3002", "motivation": "\u73b0\u6709\u591aLLM\u670d\u52a1\u7cfb\u7edf\u5728\u63d0\u9ad8GPU\u5229\u7528\u7387\u7684\u540c\u65f6\u727a\u7272\u4e86\u63a8\u7406\u6027\u80fd\uff0c\u7279\u522b\u662f\u9996\u4ee4\u724c\u65f6\u95f4\u3002\u7814\u7a76\u53d1\u73b0\u771f\u5b9e\u4e16\u754c\u5de5\u4f5c\u8d1f\u8f7d\u5177\u6709\u9ad8\u5ea6\u5468\u671f\u6027\u548c\u957f\u671f\u53ef\u9884\u6d4b\u6027\uff0c\u8fd9\u4e3a\u89e3\u51b3\u6027\u80fd\u4e0e\u6548\u7387\u7684\u6743\u8861\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002", "method": "\u63d0\u51fa\u901a\u7528GPU\u5de5\u4f5c\u5668\u5b9e\u73b0\u4e00\u5bf9\u591aGPU\u9884\u70ed\uff1b\u8bbe\u8ba1WarmServe\u7cfb\u7edf\uff1a1)\u91c7\u7528\u9a71\u9010\u611f\u77e5\u6a21\u578b\u653e\u7f6e\u7b56\u7565\u51cf\u5c11\u96c6\u7fa4\u9884\u70ed\u5e72\u6270\uff1b2)\u901a\u8fc7\u4e3b\u52a8\u9884\u70ed\u63d0\u524d\u51c6\u5907\u901a\u7528GPU\u5de5\u4f5c\u5668\uff1b3)\u4f7f\u7528\u96f6\u5f00\u9500\u5185\u5b58\u5207\u6362\u673a\u5236\u7ba1\u7406GPU\u5185\u5b58\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u8bc4\u4f30\u4e2d\uff0cWarmServe\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u81ea\u52a8\u7f29\u653e\u7cfb\u7edf\u5c06TTFT\u63d0\u5347\u9ad8\u8fbe50.8\u500d\uff0c\u540c\u65f6\u76f8\u6bd4GPU\u5171\u4eab\u7cfb\u7edf\u80fd\u591f\u670d\u52a1\u591a\u8fbe2.5\u500d\u7684\u8bf7\u6c42\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u5de5\u4f5c\u8d1f\u8f7d\u7684\u53ef\u9884\u6d4b\u6027\u8fdb\u884c\u667a\u80fd\u9884\u70ed\uff0cWarmServe\u6210\u529f\u89e3\u51b3\u4e86\u591aLLM\u670d\u52a1\u4e2d\u6027\u80fd\u4e0e\u8d44\u6e90\u6548\u7387\u7684\u6743\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u9996\u4ee4\u724c\u65f6\u95f4\u6539\u8fdb\u548c\u66f4\u9ad8\u7684\u8bf7\u6c42\u670d\u52a1\u80fd\u529b\u3002"}}
{"id": "2512.09321", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09321", "abs": "https://arxiv.org/abs/2512.09321", "authors": ["Ruiqi Wang", "Yuqi Jia", "Neil Zhenqiang Gong"], "title": "ObliInjection: Order-Oblivious Prompt Injection Attack to LLM Agents with Multi-source Data", "comment": "To appear in NDSS 2026", "summary": "Prompt injection attacks aim to contaminate the input data of an LLM to mislead it into completing an attacker-chosen task instead of the intended task. In many applications and agents, the input data originates from multiple sources, with each source contributing a segment of the overall input. In these multi-source scenarios, an attacker may control only a subset of the sources and contaminate the corresponding segments, but typically does not know the order in which the segments are arranged within the input. Existing prompt injection attacks either assume that the entire input data comes from a single source under the attacker's control or ignore the uncertainty in the ordering of segments from different sources. As a result, their success is limited in domains involving multi-source data.\n  In this work, we propose ObliInjection, the first prompt injection attack targeting LLM applications and agents with multi-source input data. ObliInjection introduces two key technical innovations: the order-oblivious loss, which quantifies the likelihood that the LLM will complete the attacker-chosen task regardless of how the clean and contaminated segments are ordered; and the orderGCG algorithm, which is tailored to minimize the order-oblivious loss and optimize the contaminated segments. Comprehensive experiments across three datasets spanning diverse application domains and twelve LLMs demonstrate that ObliInjection is highly effective, even when only one out of 6-100 segments in the input data is contaminated.", "AI": {"tldr": "ObliInjection\uff1a\u9996\u4e2a\u9488\u5bf9\u591a\u6e90\u8f93\u5165LLM\u5e94\u7528\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u901a\u8fc7\u987a\u5e8f\u65e0\u5173\u635f\u5931\u548corderGCG\u7b97\u6cd5\u4f18\u5316\u6c61\u67d3\u7247\u6bb5\uff0c\u5373\u4f7f\u4ec5\u6c61\u67d36-100\u4e2a\u7247\u6bb5\u4e2d\u76841\u4e2a\u4e5f\u80fd\u9ad8\u6548\u653b\u51fb", "motivation": "\u73b0\u6709\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u5047\u8bbe\u653b\u51fb\u8005\u63a7\u5236\u5168\u90e8\u8f93\u5165\u6216\u5ffd\u7565\u591a\u6e90\u8f93\u5165\u7684\u987a\u5e8f\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u591a\u6e90\u6570\u636e\u573a\u666f\u4e2d\u6548\u679c\u6709\u9650\u3002\u9700\u8981\u5f00\u53d1\u80fd\u5e94\u5bf9\u591a\u6e90\u8f93\u5165\u987a\u5e8f\u4e0d\u786e\u5b9a\u6027\u7684\u653b\u51fb\u65b9\u6cd5", "method": "\u63d0\u51faObliInjection\u653b\u51fb\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u6280\u672f\uff1a1) \u987a\u5e8f\u65e0\u5173\u635f\u5931\u51fd\u6570\uff0c\u91cf\u5316LLM\u5b8c\u6210\u653b\u51fb\u8005\u6307\u5b9a\u4efb\u52a1\u7684\u53ef\u80fd\u6027\uff08\u65e0\u8bba\u5e72\u51c0\u548c\u6c61\u67d3\u7247\u6bb5\u7684\u6392\u5217\u987a\u5e8f\uff09\uff1b2) orderGCG\u7b97\u6cd5\uff0c\u4e13\u95e8\u7528\u4e8e\u6700\u5c0f\u5316\u987a\u5e8f\u65e0\u5173\u635f\u5931\u5e76\u4f18\u5316\u6c61\u67d3\u7247\u6bb5", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u5e94\u7528\u9886\u57df\u7684\u6570\u636e\u96c6\u548c12\u4e2aLLM\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cObliInjection\u975e\u5e38\u6709\u6548\uff0c\u5373\u4f7f\u8f93\u5165\u6570\u636e\u4e2d6-100\u4e2a\u7247\u6bb5\u4e2d\u53ea\u67091\u4e2a\u88ab\u6c61\u67d3\u4e5f\u80fd\u6210\u529f\u653b\u51fb", "conclusion": "ObliInjection\u662f\u9996\u4e2a\u9488\u5bf9\u591a\u6e90\u8f93\u5165LLM\u5e94\u7528\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u901a\u8fc7\u987a\u5e8f\u65e0\u5173\u635f\u5931\u548corderGCG\u7b97\u6cd5\u89e3\u51b3\u4e86\u591a\u6e90\u8f93\u5165\u987a\u5e8f\u4e0d\u786e\u5b9a\u6027\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u6210\u529f\u7387"}}
{"id": "2512.09727", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09727", "abs": "https://arxiv.org/abs/2512.09727", "authors": ["Junlin Xiao", "Victor-Alexandru Darvariu", "Bruno Lacerda", "Nick Hawes"], "title": "Gaussian Process Aggregation for Root-Parallel Monte Carlo Tree Search with Continuous Actions", "comment": null, "summary": "Monte Carlo Tree Search is a cornerstone algorithm for online planning, and its root-parallel variant is widely used when wall clock time is limited but best performance is desired. In environments with continuous action spaces, how to best aggregate statistics from different threads is an important yet underexplored question. In this work, we introduce a method that uses Gaussian Process Regression to obtain value estimates for promising actions that were not trialed in the environment. We perform a systematic evaluation across 6 different domains, demonstrating that our approach outperforms existing aggregation strategies while requiring a modest increase in inference time.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u6765\u805a\u5408\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u591a\u7ebf\u7a0bMCTS\u7edf\u8ba1\u4fe1\u606f\u7684\u65b9\u6cd5\uff0c\u57286\u4e2a\u4e0d\u540c\u9886\u57df\u4e2d\u90fd\u4f18\u4e8e\u73b0\u6709\u805a\u5408\u7b56\u7565\u3002", "motivation": "\u5728\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u4e2d\uff0c\u5f53\u8ba1\u7b97\u65f6\u95f4\u6709\u9650\u4f46\u9700\u8981\u6700\u4f73\u6027\u80fd\u65f6\uff0c\u5982\u4f55\u6709\u6548\u805a\u5408\u4e0d\u540c\u7ebf\u7a0b\u7684\u7edf\u8ba1\u4fe1\u606f\u662f\u4e00\u4e2a\u91cd\u8981\u4f46\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u65b9\u6cd5\uff0c\u4e3a\u672a\u5728\u73af\u5883\u4e2d\u8bd5\u9a8c\u8fc7\u7684\u6709\u524d\u666f\u52a8\u4f5c\u83b7\u53d6\u4ef7\u503c\u4f30\u8ba1\uff0c\u4ece\u800c\u6539\u8fdb\u591a\u7ebf\u7a0bMCTS\u4e2d\u7684\u7edf\u8ba1\u4fe1\u606f\u805a\u5408\u3002", "result": "\u57286\u4e2a\u4e0d\u540c\u9886\u57df\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u805a\u5408\u7b56\u7565\uff0c\u540c\u65f6\u4ec5\u9700\u9002\u5ea6\u7684\u63a8\u7406\u65f6\u95f4\u589e\u52a0\u3002", "conclusion": "\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u4e3a\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u7684\u591a\u7ebf\u7a0bMCTS\u7edf\u8ba1\u805a\u5408\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u6027\u80fd\u63d0\u5347\u548c\u8ba1\u7b97\u5f00\u9500\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2512.09568", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.09568", "abs": "https://arxiv.org/abs/2512.09568", "authors": ["Zhi Zhao", "Hang Xiao", "Wei Rang"], "title": "PHWSOA: A Pareto-based Hybrid Whale-Seagull Scheduling for Multi-Objective Tasks in Cloud Computing", "comment": "24 pages,5 figures", "summary": "Task scheduling is a critical research challenge in cloud computing, a transformative technology widely adopted across industries. Although numerous scheduling solutions exist, they predominantly optimize singular or limited metrics such as execution time or resource utilization often neglecting the need for comprehensive multi-objective optimization. To bridge this gap, this paper proposes the Pareto-based Hybrid Whale-Seagull Optimization Algorithm (PHWSOA). This algorithm synergistically combines the strengths of the Whale Optimization Algorithm (WOA) and the Seagull Optimization Algorithm (SOA), specifically mitigating WOA's limitations in local exploitation and SOA's constraints in global exploration. Leveraging Pareto dominance principles, PHWSOA simultaneously optimizes three key objectives: makespan, virtual machine (VM) load balancing, and economic cost. Key enhancements include: Halton sequence initialization for superior population diversity, a Pareto-guided mutation mechanism to avert premature convergence, and parallel processing for accelerated convergence. Furthermore, a dynamic VM load redistribution mechanism is integrated to improve load balancing during task execution. Extensive experiments conducted on the CloudSim simulator, utilizing real-world workload traces from NASA-iPSC and HPC2N, demonstrate that PHWSOA delivers substantial performance gains. Specifically, it achieves up to a 72.1% reduction in makespan, a 36.8% improvement in VM load balancing, and 23.5% cost savings. These results substantially outperform baseline methods including WOA, GA, PEWOA, and GCWOA underscoring PHWSOA's strong potential for enabling efficient resource management in practical cloud environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e15\u7d2f\u6258\u7684\u6df7\u5408\u9cb8\u9c7c-\u6d77\u9e25\u4f18\u5316\u7b97\u6cd5(PHWSOA)\uff0c\u7528\u4e8e\u4e91\u73af\u5883\u4e2d\u7684\u591a\u76ee\u6807\u4efb\u52a1\u8c03\u5ea6\uff0c\u540c\u65f6\u4f18\u5316\u6267\u884c\u65f6\u95f4\u3001\u865a\u62df\u673a\u8d1f\u8f7d\u5e73\u8861\u548c\u7ecf\u6d4e\u6210\u672c\u4e09\u4e2a\u5173\u952e\u6307\u6807\u3002", "motivation": "\u4e91\u8ba1\u7b97\u4e2d\u7684\u4efb\u52a1\u8c03\u5ea6\u662f\u4e00\u4e2a\u5173\u952e\u7814\u7a76\u6311\u6218\uff0c\u73b0\u6709\u8c03\u5ea6\u65b9\u6848\u5927\u591a\u53ea\u4f18\u5316\u5355\u4e00\u6216\u6709\u9650\u6307\u6807\uff08\u5982\u6267\u884c\u65f6\u95f4\u6216\u8d44\u6e90\u5229\u7528\u7387\uff09\uff0c\u7f3a\u4e4f\u5168\u9762\u7684\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\uff0c\u9700\u8981\u540c\u65f6\u8003\u8651\u6267\u884c\u65f6\u95f4\u3001\u8d1f\u8f7d\u5e73\u8861\u548c\u7ecf\u6d4e\u6210\u672c\u7b49\u591a\u4e2a\u76ee\u6807\u3002", "method": "\u63d0\u51faPHWSOA\u7b97\u6cd5\uff0c\u7ed3\u5408\u9cb8\u9c7c\u4f18\u5316\u7b97\u6cd5(WOA)\u548c\u6d77\u9e25\u4f18\u5316\u7b97\u6cd5(SOA)\u7684\u4f18\u52bf\uff0c\u5f25\u8865WOA\u7684\u5c40\u90e8\u5f00\u53d1\u80fd\u529b\u548cSOA\u7684\u5168\u5c40\u63a2\u7d22\u80fd\u529b\u4e0d\u8db3\u3002\u91c7\u7528Halton\u5e8f\u5217\u521d\u59cb\u5316\u63d0\u9ad8\u79cd\u7fa4\u591a\u6837\u6027\uff0c\u5e15\u7d2f\u6258\u5f15\u5bfc\u7684\u53d8\u5f02\u673a\u5236\u9632\u6b62\u65e9\u719f\u6536\u655b\uff0c\u5e76\u884c\u5904\u7406\u52a0\u901f\u6536\u655b\uff0c\u5e76\u96c6\u6210\u52a8\u6001\u865a\u62df\u673a\u8d1f\u8f7d\u91cd\u5206\u914d\u673a\u5236\u6539\u5584\u8d1f\u8f7d\u5e73\u8861\u3002", "result": "\u5728CloudSim\u6a21\u62df\u5668\u4e0a\u4f7f\u7528NASA-iPSC\u548cHPC2N\u7684\u771f\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u8fdb\u884c\u5b9e\u9a8c\uff0cPHWSOA\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff08WOA\u3001GA\u3001PEWOA\u3001GCWOA\uff09\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff1a\u6267\u884c\u65f6\u95f4\u51cf\u5c11\u9ad8\u8fbe72.1%\uff0c\u865a\u62df\u673a\u8d1f\u8f7d\u5e73\u8861\u6539\u558436.8%\uff0c\u6210\u672c\u8282\u7ea623.5%\u3002", "conclusion": "PHWSOA\u7b97\u6cd5\u5728\u4e91\u4efb\u52a1\u8c03\u5ea6\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u591a\u76ee\u6807\u4f18\u5316\u80fd\u529b\uff0c\u80fd\u591f\u540c\u65f6\u663e\u8457\u6539\u5584\u6267\u884c\u65f6\u95f4\u3001\u8d1f\u8f7d\u5e73\u8861\u548c\u7ecf\u6d4e\u6210\u672c\uff0c\u4e3a\u5b9e\u9645\u4e91\u73af\u5883\u4e2d\u7684\u9ad8\u6548\u8d44\u6e90\u7ba1\u7406\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.09409", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09409", "abs": "https://arxiv.org/abs/2512.09409", "authors": ["Kyle Habib", "Vladislav Kapitsyn", "Giovanni Mazzeo", "Faisal Mehrban"], "title": "Proof of Trusted Execution: A Consensus Paradigm for Deterministic Blockchain Finality", "comment": "Submitted to Middleware 2026 Conference", "summary": "Current blockchain consensus protocols -- notably, Proof of Work (PoW) and Proof of Stake (PoS) -- deliver global agreement but exhibit structural constraints. PoW anchors security in heavy computation, inflating energy use and imposing high confirmation latency. PoS improves efficiency but introduces stake concentration, long-range and \"nothing-at-stake\" vulnerabilities, and a hard performance ceiling shaped by slot times and multi-round committee voting. In this paper, we propose Proof of Trusted Execution (PoTE), a consensus paradigm where agreement emerges from verifiable execution rather than replicated re-execution. Validators operate inside heterogeneous VM-based TEEs, each running the same canonical program whose measurement is publicly recorded, and each producing vendor-backed attestations that bind the enclave code hash to the block contents. Because the execution is deterministic and the proposer is uniquely derived from public randomness, PoTE avoids forks, eliminates slot.time bottlenecks, and commits blocks in a single round of verification. We present the design of a PoTE consensus client, describe our reference implementation, and evaluate its performance against the stringent throughput requirements of the Trillion decentralized exchange.", "AI": {"tldr": "\u63d0\u51faPoTE\u5171\u8bc6\u534f\u8bae\uff0c\u5229\u7528\u53ef\u4fe1\u6267\u884c\u73af\u5883\u66ff\u4ee3\u4f20\u7edfPoW/PoS\uff0c\u901a\u8fc7\u53ef\u9a8c\u8bc1\u6267\u884c\u800c\u975e\u91cd\u590d\u6267\u884c\u5b9e\u73b0\u5171\u8bc6\uff0c\u6d88\u9664\u5206\u53c9\u548c\u65f6\u9699\u74f6\u9888\uff0c\u5b9e\u73b0\u5355\u8f6e\u9a8c\u8bc1\u786e\u8ba4\u3002", "motivation": "\u5f53\u524d\u533a\u5757\u94fe\u5171\u8bc6\u534f\u8bae\u5b58\u5728\u7ed3\u6784\u6027\u9650\u5236\uff1aPoW\u80fd\u8017\u9ad8\u3001\u786e\u8ba4\u5ef6\u8fdf\u5927\uff1bPoS\u5b58\u5728\u6743\u76ca\u96c6\u4e2d\u3001\u957f\u7a0b\u653b\u51fb\u3001\"\u65e0\u5229\u5bb3\u5173\u7cfb\"\u6f0f\u6d1e\uff0c\u4e14\u6027\u80fd\u53d7\u65f6\u9699\u65f6\u95f4\u548c\u591a\u8f6e\u59d4\u5458\u4f1a\u6295\u7968\u9650\u5236\u3002", "method": "\u63d0\u51faPoTE\uff08Proof of Trusted Execution\uff09\u5171\u8bc6\u8303\u5f0f\uff0c\u9a8c\u8bc1\u8005\u5728\u5f02\u6784VM-based TEEs\u4e2d\u8fd0\u884c\u76f8\u540c\u89c4\u8303\u7a0b\u5e8f\uff0c\u7a0b\u5e8f\u6d4b\u91cf\u503c\u516c\u5f00\u8bb0\u5f55\uff0c\u4ea7\u751f\u4f9b\u5e94\u5546\u652f\u6301\u7684\u8bc1\u660e\uff0c\u5c06\u9694\u79bb\u533a\u4ee3\u7801\u54c8\u5e0c\u4e0e\u533a\u5757\u5185\u5bb9\u7ed1\u5b9a\u3002\u6267\u884c\u662f\u786e\u5b9a\u6027\u7684\uff0c\u63d0\u8bae\u8005\u4ece\u516c\u5171\u968f\u673a\u6027\u552f\u4e00\u6d3e\u751f\u3002", "result": "PoTE\u907f\u514d\u5206\u53c9\uff0c\u6d88\u9664\u65f6\u9699\u65f6\u95f4\u74f6\u9888\uff0c\u5728\u5355\u8f6e\u9a8c\u8bc1\u4e2d\u63d0\u4ea4\u533a\u5757\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86PoTE\u5171\u8bc6\u5ba2\u6237\u7aef\u3002", "conclusion": "PoTE\u901a\u8fc7\u57fa\u4e8e\u53ef\u4fe1\u6267\u884c\u73af\u5883\u7684\u53ef\u9a8c\u8bc1\u6267\u884c\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5171\u8bc6\u534f\u8bae\u7684\u7ed3\u6784\u6027\u9650\u5236\uff0c\u4e3a\u9ad8\u541e\u5410\u91cf\u5e94\u7528\uff08\u5982Trillion\u53bb\u4e2d\u5fc3\u5316\u4ea4\u6613\u6240\uff09\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.09664", "categories": ["cs.DC", "cs.CV", "cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2512.09664", "abs": "https://arxiv.org/abs/2512.09664", "authors": ["Antonio Terpin", "Alan Bonomi", "Francesco Banelli", "Raffaello D'Andrea"], "title": "SynthPix: A lightspeed PIV images generator", "comment": "Code: https://github.com/antonioterpin/synthpix", "summary": "We describe SynthPix, a synthetic image generator for Particle Image Velocimetry (PIV) with a focus on performance and parallelism on accelerators, implemented in JAX. SynthPix supports the same configuration parameters as existing tools but achieves a throughput several orders of magnitude higher in image-pair generation per second. SynthPix was developed to enable the training of data-hungry reinforcement learning methods for flow estimation and for reducing the iteration times during the development of fast flow estimation methods used in recent active fluids control studies with real-time PIV feedback. We believe SynthPix to be useful for the fluid dynamics community, and in this paper we describe the main ideas behind this software package.", "AI": {"tldr": "SynthPix\u662f\u57fa\u4e8eJAX\u5b9e\u73b0\u7684\u9ad8\u6027\u80fd\u5e76\u884cPIV\u5408\u6210\u56fe\u50cf\u751f\u6210\u5668\uff0c\u541e\u5410\u91cf\u6bd4\u73b0\u6709\u5de5\u5177\u9ad8\u51e0\u4e2a\u6570\u91cf\u7ea7", "motivation": "\u4e3a\u6570\u636e\u9965\u6e34\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8bad\u7ec3\u63d0\u4f9b\u652f\u6301\uff0c\u5e76\u7f29\u77ed\u5feb\u901f\u6d41\u573a\u4f30\u8ba1\u65b9\u6cd5\u7684\u5f00\u53d1\u8fed\u4ee3\u65f6\u95f4\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5b9e\u65f6PIV\u53cd\u9988\u7684\u4e3b\u52a8\u6d41\u4f53\u63a7\u5236\u7814\u7a76\u4e2d", "method": "\u4f7f\u7528JAX\u6846\u67b6\u5728\u52a0\u901f\u5668\u4e0a\u5b9e\u73b0\u5e76\u884c\u5316\uff0c\u652f\u6301\u4e0e\u73b0\u6709\u5de5\u5177\u76f8\u540c\u7684\u914d\u7f6e\u53c2\u6570\uff0c\u4f46\u901a\u8fc7\u786c\u4ef6\u52a0\u901f\u5b9e\u73b0\u66f4\u9ad8\u7684\u6027\u80fd", "result": "\u5b9e\u73b0\u4e86\u6bcf\u79d2\u56fe\u50cf\u5bf9\u751f\u6210\u541e\u5410\u91cf\u6bd4\u73b0\u6709\u5de5\u5177\u9ad8\u51e0\u4e2a\u6570\u91cf\u7ea7\u7684\u6027\u80fd\u63d0\u5347", "conclusion": "SynthPix\u5bf9\u6d41\u4f53\u52a8\u529b\u5b66\u793e\u533a\u5177\u6709\u5b9e\u7528\u4ef7\u503c\uff0c\u80fd\u591f\u652f\u6301\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u548c\u5feb\u901f\u6d41\u573a\u4f30\u8ba1\u65b9\u6cd5\u7684\u5f00\u53d1"}}
{"id": "2512.09829", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.09829", "abs": "https://arxiv.org/abs/2512.09829", "authors": ["Khurram Khalil", "Muhammad Mahad Khaliq", "Khaza Anuarul Hoque"], "title": "RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning", "comment": "Accepted in the IEEE DATE 2026 conference", "summary": "The massive scale of modern AI accelerators presents critical challenges to traditional fault assessment methodologies, which face prohibitive computational costs and provide poor coverage of critical failure modes. This paper introduces RIFT (Reinforcement Learning-guided Intelligent Fault Targeting), a scalable framework that automates the discovery of minimal, high-impact fault scenarios for efficient design-time fault assessment. RIFT transforms the complex search for worst-case faults into a sequential decision-making problem, combining hybrid sensitivity analysis for search space pruning with reinforcement learning to intelligently generate minimal, high-impact test suites. Evaluated on billion-parameter Large Language Model (LLM) workloads using NVIDIA A100 GPUs, RIFT achieves a \\textbf{2.2$\\times$} fault assessment speedup over evolutionary methods and reduces the required test vector volume by over \\textbf{99\\%} compared to random fault injection, all while achieving \\textbf{superior fault coverage}. The proposed framework also provides actionable data to enable intelligent hardware protection strategies, demonstrating that RIFT-guided selective error correction code provides a \\textbf{12.8$\\times$} improvement in \\textbf{cost-effectiveness} (coverage per unit area) compared to uniform triple modular redundancy protection. RIFT automatically generates UVM-compliant verification artifacts, ensuring its findings are directly actionable and integrable into commercial RTL verification workflows.", "AI": {"tldr": "RIFT\u6846\u67b6\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u81ea\u52a8\u53d1\u73b0\u6700\u5c0f\u5316\u9ad8\u5f71\u54cd\u6545\u969c\u573a\u666f\uff0c\u52a0\u901fAI\u52a0\u901f\u5668\u6545\u969c\u8bc4\u4f30\uff0c\u76f8\u6bd4\u8fdb\u5316\u65b9\u6cd5\u63d0\u901f2.2\u500d\uff0c\u76f8\u6bd4\u968f\u673a\u6545\u969c\u6ce8\u5165\u51cf\u5c1199%\u6d4b\u8bd5\u5411\u91cf\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u597d\u7684\u6545\u969c\u8986\u76d6\u7387\u3002", "motivation": "\u73b0\u4ee3AI\u52a0\u901f\u5668\u89c4\u6a21\u5e9e\u5927\uff0c\u4f20\u7edf\u6545\u969c\u8bc4\u4f30\u65b9\u6cd5\u9762\u4e34\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u548c\u5173\u952e\u6545\u969c\u6a21\u5f0f\u8986\u76d6\u7387\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u6846\u67b6\u6765\u53d1\u73b0\u6700\u5c0f\u5316\u9ad8\u5f71\u54cd\u6545\u969c\u573a\u666f\u3002", "method": "RIFT\u5c06\u590d\u6742\u7684\u6700\u574f\u60c5\u51b5\u6545\u969c\u641c\u7d22\u8f6c\u5316\u4e3a\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\uff0c\u7ed3\u5408\u6df7\u5408\u7075\u654f\u5ea6\u5206\u6790\u8fdb\u884c\u641c\u7d22\u7a7a\u95f4\u526a\u679d\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u751f\u6210\u6700\u5c0f\u5316\u9ad8\u5f71\u54cd\u6d4b\u8bd5\u5957\u4ef6\uff0c\u5e76\u81ea\u52a8\u751f\u6210UVM\u517c\u5bb9\u7684\u9a8c\u8bc1\u5de5\u4ef6\u3002", "result": "\u5728\u57fa\u4e8eNVIDIA A100 GPU\u7684\u5341\u4ebf\u53c2\u6570\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u4f5c\u8d1f\u8f7d\u8bc4\u4f30\u4e2d\uff0cRIFT\u76f8\u6bd4\u8fdb\u5316\u65b9\u6cd5\u5b9e\u73b02.2\u500d\u6545\u969c\u8bc4\u4f30\u52a0\u901f\uff0c\u76f8\u6bd4\u968f\u673a\u6545\u969c\u6ce8\u5165\u51cf\u5c1199%\u4ee5\u4e0a\u6d4b\u8bd5\u5411\u91cf\uff0c\u540c\u65f6\u83b7\u5f97\u66f4\u4f18\u7684\u6545\u969c\u8986\u76d6\u7387\u3002RIFT\u5f15\u5bfc\u7684\u9009\u62e9\u6027\u9519\u8bef\u6821\u6b63\u7801\u76f8\u6bd4\u7edf\u4e00\u4e09\u6a21\u5197\u4f59\u4fdd\u62a4\u5728\u6210\u672c\u6548\u76ca\u4e0a\u63d0\u534712.8\u500d\u3002", "conclusion": "RIFT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u53d1\u73b0\u6700\u5c0f\u5316\u9ad8\u5f71\u54cd\u6545\u969c\u573a\u666f\uff0c\u663e\u8457\u52a0\u901fAI\u52a0\u901f\u5668\u7684\u6545\u969c\u8bc4\u4f30\u8fc7\u7a0b\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6570\u636e\u652f\u6301\u667a\u80fd\u786c\u4ef6\u4fdd\u62a4\u7b56\u7565\uff0c\u5e76\u53ef\u76f4\u63a5\u96c6\u6210\u5230\u5546\u4e1aRTL\u9a8c\u8bc1\u5de5\u4f5c\u6d41\u4e2d\u3002"}}
{"id": "2512.09442", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09442", "abs": "https://arxiv.org/abs/2512.09442", "authors": ["Xiaoxiao Chi", "Xuyun Zhang", "Yan Wang", "Hongsheng Hu", "Wanchun Dou"], "title": "Reference Recommendation based Membership Inference Attack against Hybrid-based Recommender Systems", "comment": "This paper has been accepted by AAAI 2026", "summary": "Recommender systems have been widely deployed across various domains such as e-commerce and social media, and intelligently suggest items like products and potential friends to users based on their preferences and interaction history, which are often privacy-sensitive. Recent studies have revealed that recommender systems are prone to membership inference attacks (MIAs), where an attacker aims to infer whether or not a user's data has been used for training a target recommender system. However, existing MIAs fail to exploit the unique characteristic of recommender systems, and therefore are only applicable to mixed recommender systems consisting of two recommendation algorithms. This leaves a gap in investigating MIAs against hybrid-based recommender systems where the same algorithm utilizing user-item historical interactions and attributes of users and items serves and produces personalised recommendations. To investigate how the personalisation in hybrid-based recommender systems influences MIA, we propose a novel metric-based MIA. Specifically, we leverage the characteristic of personalisation to obtain reference recommendation for any target users. Then, a relative membership metric is proposed to exploit a target user's historical interactions, target recommendation, and reference recommendation to infer the membership of the target user's data. Finally, we theoretically and empirically demonstrate the efficacy of the proposed metric-based MIA on hybrid-based recommender systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u6df7\u5408\u63a8\u8350\u7cfb\u7edf\u7684\u6210\u5458\u63a8\u65ad\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u4e2a\u6027\u5316\u63a8\u8350\u7279\u6027\u6765\u63a8\u65ad\u7528\u6237\u6570\u636e\u662f\u5426\u88ab\u7528\u4e8e\u8bad\u7ec3\u63a8\u8350\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709\u6210\u5458\u63a8\u65ad\u653b\u51fb\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u63a8\u8350\u7cfb\u7edf\u7684\u72ec\u7279\u7279\u6027\uff0c\u4ec5\u9002\u7528\u4e8e\u5305\u542b\u4e24\u79cd\u63a8\u8350\u7b97\u6cd5\u7684\u6df7\u5408\u63a8\u8350\u7cfb\u7edf\uff0c\u800c\u65e0\u6cd5\u6709\u6548\u653b\u51fb\u57fa\u4e8e\u76f8\u540c\u7b97\u6cd5\u5229\u7528\u7528\u6237-\u7269\u54c1\u5386\u53f2\u4ea4\u4e92\u548c\u5c5e\u6027\u7684\u6df7\u5408\u63a8\u8350\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5ea6\u91cf\u7684\u6210\u5458\u63a8\u65ad\u653b\u51fb\u65b9\u6cd5\uff1a\u5229\u7528\u4e2a\u6027\u5316\u7279\u6027\u4e3a\u4efb\u4f55\u76ee\u6807\u7528\u6237\u83b7\u53d6\u53c2\u8003\u63a8\u8350\uff0c\u7136\u540e\u63d0\u51fa\u76f8\u5bf9\u6210\u5458\u5ea6\u91cf\uff0c\u5229\u7528\u76ee\u6807\u7528\u6237\u7684\u5386\u53f2\u4ea4\u4e92\u3001\u76ee\u6807\u63a8\u8350\u548c\u53c2\u8003\u63a8\u8350\u6765\u63a8\u65ad\u7528\u6237\u6570\u636e\u7684\u6210\u5458\u8eab\u4efd\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u8bc1\u5206\u6790\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u5ea6\u91cf\u7684\u6210\u5458\u63a8\u65ad\u653b\u51fb\u5728\u6df7\u5408\u63a8\u8350\u7cfb\u7edf\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u6df7\u5408\u63a8\u8350\u7cfb\u7edf\u6210\u5458\u63a8\u65ad\u653b\u51fb\u7684\u7a7a\u767d\uff0c\u63ed\u793a\u4e86\u4e2a\u6027\u5316\u63a8\u8350\u5bf9\u9690\u79c1\u5b89\u5168\u7684\u5f71\u54cd\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u7684\u9690\u79c1\u4fdd\u62a4\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2512.09685", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.09685", "abs": "https://arxiv.org/abs/2512.09685", "authors": ["Zeyu Zhang", "Haiying Shen"], "title": "Straggler Tolerant and Resilient DL Training on Homogeneous GPUs", "comment": null, "summary": "Despite the popularity of homogeneous GPU-based deep learning (DL) training, the prevalence, causes and impact of stragglers and the effectiveness of existing straggler mitigation approaches are still not well understood in this scenario due to limited research on these questions. To fill this gap, we conducted comprehensive experiments and found that stragglers remain widespread due to CPU and bandwidth usage imbalances. Additionally, existing mitigation methods that switch from synchronous stochastic gradient descent (SSGD) to asynchronous SGD (ASGD) may not improve Time-To-Accuracy (TTA) and can even generate more stragglers due to its higher resource consumption. To address these newly found problems, we propose the Straggler Tolerant And Resilient DL training system (STAR). STAR includes new synchronization modes that group workers for each parameter updating. It has a heuristic and an ML method to choose the optimal synchronization mode for minimizing TTA, and reallocates resources to support the selected mode while minimizing the impact on co-located jobs. Moreover, it proactively prevents stragglers by avoiding overloading the CPU and bandwidth resources in allocating PSs (which consume high CPU and bandwidth) and in gradient transmission. Our trace-driven evaluation on AWS shows that STAR generates 48-84% and 51-70% lower TTA than state-of-the-art systems in the PS and all-reduce architectures, respectively, while maintaining the converged accuracy of SSGD. The code for STAR is open-sourced.", "AI": {"tldr": "STAR\u7cfb\u7edf\u901a\u8fc7\u65b0\u7684\u540c\u6b65\u6a21\u5f0f\u548c\u8d44\u6e90\u91cd\u5206\u914d\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86GPU\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u4e2d\u7684straggler\u95ee\u9898\uff0c\u76f8\u6bd4\u73b0\u6709\u7cfb\u7edf\u663e\u8457\u964d\u4f4e\u4e86\u8bad\u7ec3\u65f6\u95f4\u3002", "motivation": "\u5c3d\u7ba1GPU\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u5f88\u6d41\u884c\uff0c\u4f46straggler\u7684\u666e\u904d\u6027\u3001\u539f\u56e0\u548c\u5f71\u54cd\u4ee5\u53ca\u73b0\u6709\u7f13\u89e3\u65b9\u6cd5\u7684\u6709\u6548\u6027\u4ecd\u672a\u5f97\u5230\u5145\u5206\u7406\u89e3\u3002\u7814\u7a76\u53d1\u73b0straggler\u4ecd\u7136\u666e\u904d\u5b58\u5728\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u540c\u6b65\u8f6c\u5f02\u6b65SGD\uff09\u53ef\u80fd\u65e0\u6cd5\u6539\u5584\u8bad\u7ec3\u65f6\u95f4\u751a\u81f3\u4ea7\u751f\u66f4\u591astraggler\u3002", "method": "\u63d0\u51faSTAR\u7cfb\u7edf\uff0c\u5305\u62ec\uff1a1\uff09\u65b0\u7684\u540c\u6b65\u6a21\u5f0f\uff0c\u5c06worker\u5206\u7ec4\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\uff1b2\uff09\u542f\u53d1\u5f0f\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u9009\u62e9\u6700\u4f18\u540c\u6b65\u6a21\u5f0f\u4ee5\u6700\u5c0f\u5316\u8bad\u7ec3\u65f6\u95f4\uff1b3\uff09\u8d44\u6e90\u91cd\u5206\u914d\u652f\u6301\u6240\u9009\u6a21\u5f0f\u540c\u65f6\u6700\u5c0f\u5316\u5bf9\u5171\u5b58\u4f5c\u4e1a\u7684\u5f71\u54cd\uff1b4\uff09\u4e3b\u52a8\u9884\u9632straggler\uff0c\u907f\u514dCPU\u548c\u5e26\u5bbd\u8d44\u6e90\u8fc7\u8f7d\u3002", "result": "\u5728AWS\u4e0a\u7684trace\u9a71\u52a8\u8bc4\u4f30\u663e\u793a\uff0cSTAR\u5728PS\u67b6\u6784\u4e2d\u964d\u4f4e\u8bad\u7ec3\u65f6\u95f448-84%\uff0c\u5728all-reduce\u67b6\u6784\u4e2d\u964d\u4f4e51-70%\uff0c\u540c\u65f6\u4fdd\u6301\u540c\u6b65SGD\u7684\u6536\u655b\u7cbe\u5ea6\u3002", "conclusion": "STAR\u7cfb\u7edf\u901a\u8fc7\u521b\u65b0\u7684\u540c\u6b65\u6a21\u5f0f\u548c\u8d44\u6e90\u7ba1\u7406\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u4e2d\u7684straggler\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7cbe\u5ea6\u3002"}}
{"id": "2512.09831", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.SI"], "pdf": "https://arxiv.org/pdf/2512.09831", "abs": "https://arxiv.org/abs/2512.09831", "authors": ["Chainarong Amornbunchornvej"], "title": "Interpretation as Linear Transformation: A Cognitive-Geometric Model of Belief and Meaning", "comment": "The first draft of cognitive geometry model", "summary": "This paper develops a geometric framework for modeling belief, motivation, and influence across cognitively heterogeneous agents. Each agent is represented by a personalized value space, a vector space encoding the internal dimensions through which the agent interprets and evaluates meaning. Beliefs are formalized as structured vectors-abstract beings-whose transmission is mediated by linear interpretation maps. A belief survives communication only if it avoids the null spaces of these maps, yielding a structural criterion for intelligibility, miscommunication, and belief death.\n  Within this framework, I show how belief distortion, motivational drift, counterfactual evaluation, and the limits of mutual understanding arise from purely algebraic constraints. A central result-\"the No-Null-Space Leadership Condition\"-characterizes leadership as a property of representational reachability rather than persuasion or authority. More broadly, the model explains how abstract beings can propagate, mutate, or disappear as they traverse diverse cognitive geometries.\n  The account unifies insights from conceptual spaces, social epistemology, and AI value alignment by grounding meaning preservation in structural compatibility rather than shared information or rationality. I argue that this cognitive-geometric perspective clarifies the epistemic boundaries of influence in both human and artificial systems, and offers a general foundation for analyzing belief dynamics across heterogeneous agents.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u51e0\u4f55\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21\u8ba4\u77e5\u5f02\u8d28\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u4fe1\u5ff5\u3001\u52a8\u673a\u548c\u5f71\u54cd\u3002\u901a\u8fc7\u4e2a\u6027\u5316\u4ef7\u503c\u7a7a\u95f4\u8868\u793a\u667a\u80fd\u4f53\uff0c\u4fe1\u5ff5\u88ab\u5f62\u5f0f\u5316\u4e3a\u7ed3\u6784\u5316\u5411\u91cf\uff0c\u5176\u4f20\u64ad\u53d7\u7ebf\u6027\u89e3\u91ca\u6620\u5c04\u8c03\u8282\u3002\u4fe1\u5ff5\u53ea\u6709\u5728\u907f\u514d\u8fd9\u4e9b\u6620\u5c04\u7684\u96f6\u7a7a\u95f4\u65f6\u624d\u80fd\u5b58\u6d3b\uff0c\u8fd9\u4e3a\u53ef\u7406\u89e3\u6027\u3001\u8bef\u89e3\u548c\u4fe1\u5ff5\u6d88\u4ea1\u63d0\u4f9b\u4e86\u7ed3\u6784\u6027\u6807\u51c6\u3002", "motivation": "\u8be5\u7814\u7a76\u7684\u52a8\u673a\u662f\u5efa\u7acb\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u5206\u6790\u8ba4\u77e5\u5f02\u8d28\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u4fe1\u5ff5\u52a8\u6001\u3002\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5171\u4eab\u4fe1\u606f\u6216\u7406\u6027\u5047\u8bbe\uff0c\u800c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7ed3\u6784\u517c\u5bb9\u6027\u6765\u7406\u89e3\u610f\u4e49\u4fdd\u5b58\uff0c\u4ece\u800c\u7edf\u4e00\u6982\u5ff5\u7a7a\u95f4\u3001\u793e\u4f1a\u8ba4\u8bc6\u8bba\u548cAI\u4ef7\u503c\u5bf9\u9f50\u7684\u89c1\u89e3\u3002", "method": "\u65b9\u6cd5\u57fa\u4e8e\u51e0\u4f55\u6846\u67b6\uff1a\u6bcf\u4e2a\u667a\u80fd\u4f53\u7531\u4e2a\u6027\u5316\u4ef7\u503c\u7a7a\u95f4\uff08\u5411\u91cf\u7a7a\u95f4\uff09\u8868\u793a\uff0c\u7f16\u7801\u5176\u89e3\u91ca\u548c\u8bc4\u4f30\u610f\u4e49\u7684\u5185\u90e8\u7ef4\u5ea6\u3002\u4fe1\u5ff5\u88ab\u5f62\u5f0f\u5316\u4e3a\u7ed3\u6784\u5316\u5411\u91cf\uff08\u62bd\u8c61\u5b58\u5728\uff09\uff0c\u5176\u4f20\u64ad\u901a\u8fc7\u7ebf\u6027\u89e3\u91ca\u6620\u5c04\u8fdb\u884c\u8c03\u8282\u3002\u4fe1\u5ff5\u5b58\u6d3b\u7684\u6761\u4ef6\u662f\u907f\u514d\u8fd9\u4e9b\u6620\u5c04\u7684\u96f6\u7a7a\u95f4\u3002\u901a\u8fc7\u4ee3\u6570\u7ea6\u675f\u5206\u6790\u4fe1\u5ff5\u626d\u66f2\u3001\u52a8\u673a\u6f02\u79fb\u3001\u53cd\u4e8b\u5b9e\u8bc4\u4f30\u548c\u76f8\u4e92\u7406\u89e3\u7684\u9650\u5236\u3002", "result": "\u4e3b\u8981\u7ed3\u679c\u5305\u62ec\uff1a1\uff09\u4fe1\u5ff5\u5b58\u6d3b\u7684\u7ed3\u6784\u6027\u6807\u51c6\uff1b2\uff09\"\u65e0\u96f6\u7a7a\u95f4\u9886\u5bfc\u6761\u4ef6\"\uff0c\u5c06\u9886\u5bfc\u529b\u5b9a\u4e49\u4e3a\u8868\u5f81\u53ef\u8fbe\u6027\u800c\u975e\u8bf4\u670d\u6216\u6743\u5a01\u7684\u5c5e\u6027\uff1b3\uff09\u89e3\u91ca\u62bd\u8c61\u5b58\u5728\u5982\u4f55\u5728\u591a\u6837\u8ba4\u77e5\u51e0\u4f55\u4e2d\u4f20\u64ad\u3001\u53d8\u5f02\u6216\u6d88\u5931\u7684\u6a21\u578b\uff1b4\uff09\u4ece\u7eaf\u4ee3\u6570\u7ea6\u675f\u63a8\u5bfc\u51fa\u4fe1\u5ff5\u626d\u66f2\u3001\u52a8\u673a\u6f02\u79fb\u7b49\u73b0\u8c61\u3002", "conclusion": "\u8be5\u8ba4\u77e5\u51e0\u4f55\u89c6\u89d2\u901a\u8fc7\u5c06\u610f\u4e49\u4fdd\u5b58\u5efa\u7acb\u5728\u7ed3\u6784\u517c\u5bb9\u6027\u800c\u975e\u5171\u4eab\u4fe1\u606f\u6216\u7406\u6027\u57fa\u7840\u4e0a\uff0c\u6f84\u6e05\u4e86\u4eba\u7c7b\u548c\u4eba\u5de5\u7cfb\u7edf\u4e2d\u5f71\u54cd\u7684\u8ba4\u77e5\u8fb9\u754c\u3002\u4e3a\u5206\u6790\u5f02\u8d28\u667a\u80fd\u4f53\u95f4\u7684\u4fe1\u5ff5\u52a8\u6001\u63d0\u4f9b\u4e86\u901a\u7528\u57fa\u7840\uff0c\u7edf\u4e00\u4e86\u6982\u5ff5\u7a7a\u95f4\u3001\u793e\u4f1a\u8ba4\u8bc6\u8bba\u548cAI\u4ef7\u503c\u5bf9\u9f50\u7684\u89c1\u89e3\u3002"}}
{"id": "2512.09710", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.09710", "abs": "https://arxiv.org/abs/2512.09710", "authors": ["Hagit Attiya", "Panagiota Fatourou", "Eleftherios Kosmas", "Yuanhao Wei"], "title": "Recoverable Lock-Free Locks", "comment": null, "summary": "This paper presents the first transformation that introduces both lock-freedom and recoverability. Our transformation starts with a lock-based implementation, and provides a recoverable, lock-free substitution to lock acquire and lock release operations. The transformation supports nested locks for generality and ensures recoverability without jeopardising the correctness of the lock-based implementation it is applied on.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u540c\u65f6\u5b9e\u73b0\u65e0\u9501\u6027\u548c\u53ef\u6062\u590d\u6027\u7684\u8f6c\u6362\u65b9\u6cd5\uff0c\u5c06\u57fa\u4e8e\u9501\u7684\u5b9e\u73b0\u8f6c\u6362\u4e3a\u53ef\u6062\u590d\u7684\u65e0\u9501\u5b9e\u73b0", "motivation": "\u73b0\u6709\u7cfb\u7edf\u901a\u5e38\u9700\u8981\u5728\u65e0\u9501\u6027\u548c\u53ef\u6062\u590d\u6027\u4e4b\u95f4\u505a\u51fa\u6743\u8861\uff0c\u7f3a\u4e4f\u540c\u65f6\u5177\u5907\u8fd9\u4e24\u79cd\u7279\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002\u57fa\u4e8e\u9501\u7684\u5b9e\u73b0\u867d\u7136\u5e38\u89c1\uff0c\u4f46\u5728\u6545\u969c\u6062\u590d\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u4ece\u57fa\u4e8e\u9501\u7684\u5b9e\u73b0\u51fa\u53d1\uff0c\u63d0\u4f9b\u5bf9\u9501\u83b7\u53d6\u548c\u9501\u91ca\u653e\u64cd\u4f5c\u7684\u53ef\u6062\u590d\u3001\u65e0\u9501\u66ff\u4ee3\u65b9\u6848\u3002\u8be5\u8f6c\u6362\u652f\u6301\u5d4c\u5957\u9501\u4ee5\u589e\u5f3a\u901a\u7528\u6027\uff0c\u5e76\u786e\u4fdd\u53ef\u6062\u590d\u6027\u800c\u4e0d\u635f\u5bb3\u539f\u6709\u57fa\u4e8e\u9501\u5b9e\u73b0\u7684\u6b63\u786e\u6027\u3002", "result": "\u9996\u6b21\u5b9e\u73b0\u4e86\u540c\u65f6\u5177\u5907\u65e0\u9501\u6027\u548c\u53ef\u6062\u590d\u6027\u7684\u8f6c\u6362\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u539f\u6709\u57fa\u4e8e\u9501\u5b9e\u73b0\u6b63\u786e\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u63d0\u4f9b\u6545\u969c\u6062\u590d\u80fd\u529b\u3002", "conclusion": "\u8be5\u8f6c\u6362\u65b9\u6cd5\u586b\u8865\u4e86\u540c\u65f6\u5b9e\u73b0\u65e0\u9501\u6027\u548c\u53ef\u6062\u590d\u6027\u7684\u6280\u672f\u7a7a\u767d\uff0c\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u3001\u9ad8\u6027\u80fd\u7684\u5e76\u53d1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2512.09895", "categories": ["cs.AI", "cs.DL"], "pdf": "https://arxiv.org/pdf/2512.09895", "abs": "https://arxiv.org/abs/2512.09895", "authors": ["Jane Greenberg", "Scott McClellan", "Addy Ireland", "Robert Sammarco", "Colton Gerber", "Christopher B. Rauch", "Mat Kelly", "John Kunze", "Yuan An", "Eric Toberer"], "title": "Human-in-the-Loop and AI: Crowdsourcing Metadata Vocabulary for Materials Science", "comment": "Metadata and Semantics Research Conference 2025, 14 pages, 7 figures", "summary": "Metadata vocabularies are essential for advancing FAIR and FARR data principles, but their development constrained by limited human resources and inconsistent standardization practices. This paper introduces MatSci-YAMZ, a platform that integrates artificial intelligence (AI) and human-in-the-loop (HILT), including crowdsourcing, to support metadata vocabulary development. The paper reports on a proof-of-concept use case evaluating the AI-HILT model in materials science, a highly interdisciplinary domain Six (6) participants affiliated with the NSF Institute for Data-Driven Dynamical Design (ID4) engaged with the MatSci-YAMZ plaform over several weeks, contributing term definitions and providing examples to prompt the AI-definitions refinement. Nineteen (19) AI-generated definitions were successfully created, with iterative feedback loops demonstrating the feasibility of AI-HILT refinement. Findings confirm the feasibility AI-HILT model highlighting 1) a successful proof of concept, 2) alignment with FAIR and open-science principles, 3) a research protocol to guide future studies, and 4) the potential for scalability across domains. Overall, MatSci-YAMZ's underlying model has the capacity to enhance semantic transparency and reduce time required for consensus building and metadata vocabulary development.", "AI": {"tldr": "MatSci-YAMZ\u662f\u4e00\u4e2a\u7ed3\u5408\u4eba\u5de5\u667a\u80fd\u548c\u4f17\u5305\u4eba\u673a\u4ea4\u4e92\u7684\u5e73\u53f0\uff0c\u7528\u4e8e\u652f\u6301\u6750\u6599\u79d1\u5b66\u9886\u57df\u7684\u5143\u6570\u636e\u8bcd\u6c47\u5f00\u53d1\uff0c\u901a\u8fc76\u540d\u53c2\u4e0e\u8005\u7684\u6982\u5ff5\u9a8c\u8bc1\u8bc1\u660e\u4e86\u5176\u53ef\u884c\u6027\u3002", "motivation": "\u5143\u6570\u636e\u8bcd\u6c47\u5bf9\u63a8\u8fdbFAIR\u548cFARR\u6570\u636e\u539f\u5219\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u53d1\u5c55\u53d7\u5230\u4eba\u529b\u8d44\u6e90\u6709\u9650\u548c\u6807\u51c6\u5316\u5b9e\u8df5\u4e0d\u4e00\u81f4\u7684\u5236\u7ea6\u3002", "method": "\u5f00\u53d1\u4e86MatSci-YAMZ\u5e73\u53f0\uff0c\u6574\u5408\u4eba\u5de5\u667a\u80fd\u548c\u4eba\u673a\u4ea4\u4e92\uff08\u5305\u62ec\u4f17\u5305\uff09\uff0c\u5728\u6750\u6599\u79d1\u5b66\u9886\u57df\u8fdb\u884c\u6982\u5ff5\u9a8c\u8bc1\uff0c6\u540d\u53c2\u4e0e\u8005\u901a\u8fc7\u63d0\u4f9b\u672f\u8bed\u5b9a\u4e49\u548c\u793a\u4f8b\u6765\u4fc3\u8fdbAI\u5b9a\u4e49\u7684\u7cbe\u70bc\u3002", "result": "\u6210\u529f\u751f\u6210\u4e8619\u4e2aAI\u5b9a\u4e49\uff0c\u8fed\u4ee3\u53cd\u9988\u5faa\u73af\u8bc1\u660e\u4e86AI-HILT\u7cbe\u70bc\u7684\u53ef\u884c\u6027\uff0c\u786e\u8ba4\u4e86\u8be5\u6a21\u578b\u7684\u53ef\u884c\u6027\uff0c\u5305\u62ec\u6210\u529f\u7684\u6982\u5ff5\u9a8c\u8bc1\u3001\u4e0eFAIR\u548c\u5f00\u653e\u79d1\u5b66\u539f\u5219\u7684\u4e00\u81f4\u6027\u3001\u6307\u5bfc\u672a\u6765\u7814\u7a76\u7684\u7814\u7a76\u534f\u8bae\u4ee5\u53ca\u8de8\u9886\u57df\u6269\u5c55\u7684\u6f5c\u529b\u3002", "conclusion": "MatSci-YAMZ\u7684\u57fa\u7840\u6a21\u578b\u80fd\u591f\u589e\u5f3a\u8bed\u4e49\u900f\u660e\u5ea6\uff0c\u51cf\u5c11\u5171\u8bc6\u6784\u5efa\u548c\u5143\u6570\u636e\u8bcd\u6c47\u5f00\u53d1\u6240\u9700\u7684\u65f6\u95f4\u3002"}}
{"id": "2512.09549", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09549", "abs": "https://arxiv.org/abs/2512.09549", "authors": ["Jonathan Evertz", "Niklas Risse", "Nicolai Neuer", "Andreas M\u00fcller", "Philipp Normann", "Gaetano Sapia", "Srishti Gupta", "David Pape", "Soumya Shaw", "Devansh Srivastav", "Christian Wressnegger", "Erwin Quiring", "Thorsten Eisenhofer", "Daniel Arp", "Lea Sch\u00f6nherr"], "title": "Chasing Shadows: Pitfalls in LLM Security Research", "comment": "About to appear at NDSS'26", "summary": "Large language models (LLMs) are increasingly prevalent in security research. Their unique characteristics, however, introduce challenges that undermine established paradigms of reproducibility, rigor, and evaluation. Prior work has identified common pitfalls in traditional machine learning research, but these studies predate the advent of LLMs. In this paper, we identify \\emph{nine} common pitfalls that have become (more) relevant with the emergence of LLMs and that can compromise the validity of research involving them. These pitfalls span the entire computation process, from data collection, pre-training, and fine-tuning to prompting and evaluation.\n  We assess the prevalence of these pitfalls across all 72 peer-reviewed papers published at leading Security and Software Engineering venues between 2023 and 2024. We find that every paper contains at least one pitfall, and each pitfall appears in multiple papers. Yet only 15.7\\% of the present pitfalls were explicitly discussed, suggesting that the majority remain unrecognized. To understand their practical impact, we conduct four empirical case studies showing how individual pitfalls can mislead evaluation, inflate performance, or impair reproducibility. Based on our findings, we offer actionable guidelines to support the community in future work.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc6\u522b\u4e86LLM\u5b89\u5168\u7814\u7a76\u4e2d9\u4e2a\u5e38\u89c1\u9677\u9631\uff0c\u5206\u6790\u4e8672\u7bc7\u9876\u4f1a\u8bba\u6587\u53d1\u73b0\u6bcf\u7bc7\u81f3\u5c11\u5b58\u5728\u4e00\u4e2a\u9677\u9631\uff0c\u4ec515.7%\u88ab\u660e\u786e\u8ba8\u8bba\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u8fd9\u4e9b\u9677\u9631\u5982\u4f55\u8bef\u5bfc\u8bc4\u4f30\u3001\u5938\u5927\u6027\u80fd\u6216\u635f\u5bb3\u53ef\u590d\u73b0\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b89\u5168\u7814\u7a76\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u5176\u72ec\u7279\u7279\u6027\u6311\u6218\u4e86\u73b0\u6709\u7684\u53ef\u590d\u73b0\u6027\u3001\u4e25\u8c28\u6027\u548c\u8bc4\u4f30\u8303\u5f0f\u3002\u5148\u524d\u7814\u7a76\u8bc6\u522b\u4e86\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7814\u7a76\u7684\u5e38\u89c1\u9677\u9631\uff0c\u4f46\u8fd9\u4e9b\u7814\u7a76\u65e9\u4e8eLLM\u65f6\u4ee3\u3002\u672c\u6587\u65e8\u5728\u8bc6\u522bLLM\u7814\u7a76\u4e2d\u65b0\u51fa\u73b0\u6216\u66f4\u76f8\u5173\u7684\u9677\u9631\u3002", "method": "1. \u8bc6\u522b\u4e869\u4e2a\u8d2f\u7a7f\u6574\u4e2a\u8ba1\u7b97\u8fc7\u7a0b\uff08\u4ece\u6570\u636e\u6536\u96c6\u3001\u9884\u8bad\u7ec3\u3001\u5fae\u8c03\u5230\u63d0\u793a\u548c\u8bc4\u4f30\uff09\u7684\u5e38\u89c1\u9677\u9631\uff1b2. \u5206\u6790\u4e862023-2024\u5e74\u9876\u7ea7\u5b89\u5168\u548c\u8f6f\u4ef6\u5de5\u7a0b\u4f1a\u8bae\u53d1\u8868\u768472\u7bc7\u540c\u884c\u8bc4\u5ba1\u8bba\u6587\uff1b3. \u8fdb\u884c\u4e864\u4e2a\u5b9e\u8bc1\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u5355\u4e2a\u9677\u9631\u5982\u4f55\u8bef\u5bfc\u8bc4\u4f30\u3001\u5938\u5927\u6027\u80fd\u6216\u635f\u5bb3\u53ef\u590d\u73b0\u6027\u3002", "result": "1. \u6240\u670972\u7bc7\u8bba\u6587\u90fd\u81f3\u5c11\u5305\u542b\u4e00\u4e2a\u8bc6\u522b\u51fa\u7684\u9677\u9631\uff1b2. \u6bcf\u4e2a\u9677\u9631\u90fd\u5728\u591a\u7bc7\u8bba\u6587\u4e2d\u51fa\u73b0\uff1b3. \u4ec5\u670915.7%\u7684\u73b0\u6709\u9677\u9631\u88ab\u660e\u786e\u8ba8\u8bba\uff0c\u5927\u591a\u6570\u672a\u88ab\u8bc6\u522b\uff1b4. \u6848\u4f8b\u7814\u7a76\u8868\u660e\u8fd9\u4e9b\u9677\u9631\u786e\u5b9e\u4f1a\u8bef\u5bfc\u8bc4\u4f30\u3001\u5938\u5927\u6027\u80fd\u6216\u635f\u5bb3\u53ef\u590d\u73b0\u6027\u3002", "conclusion": "LLM\u5b89\u5168\u7814\u7a76\u4e2d\u666e\u904d\u5b58\u5728\u672a\u88ab\u5145\u5206\u8ba4\u8bc6\u7684\u9677\u9631\uff0c\u8fd9\u4e9b\u9677\u9631\u53ef\u80fd\u4e25\u91cd\u5f71\u54cd\u7814\u7a76\u6709\u6548\u6027\u3002\u57fa\u4e8e\u7814\u7a76\u53d1\u73b0\uff0c\u8bba\u6587\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5357\u6765\u652f\u6301\u793e\u533a\u672a\u6765\u7684\u5de5\u4f5c\uff0c\u63d0\u9ad8\u7814\u7a76\u7684\u4e25\u8c28\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2512.09897", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.09897", "abs": "https://arxiv.org/abs/2512.09897", "authors": ["Haoye Lu", "Pavan Seshadri", "Kaheer Suleman"], "title": "SCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments", "comment": null, "summary": "Long-term planning in complex, text-based environments presents significant challenges due to open-ended action spaces, ambiguous observations, and sparse feedback. Recent research suggests that large language models (LLMs) encode rich semantic knowledge about the world, which can be valuable for guiding agents in high-level reasoning and planning across both embodied and purely textual settings. However, existing approaches often depend heavily on querying LLMs during training and inference, making them computationally expensive and difficult to deploy efficiently. In addition, these methods typically employ a pretrained, unaltered LLM whose parameters remain fixed throughout training, providing no opportunity for adaptation to the target task. To address these limitations, we introduce SCOPE (Subgoal-COnditioned Pretraining for Efficient planning), a one-shot hierarchical planner that leverages LLM-generated subgoals only at initialization to pretrain a lightweight student model. Unlike prior approaches that distill LLM knowledge by repeatedly prompting the model to adaptively generate subgoals during training, our method derives subgoals directly from example trajectories. This design removes the need for repeated LLM queries, significantly improving efficiency, though at the cost of reduced explainability and potentially suboptimal subgoals. Despite their suboptimality, our results on the TextCraft environment show that LLM-generated subgoals can still serve as a strong starting point for hierarchical goal decomposition in text-based planning tasks. Compared to the LLM-based hierarchical agent ADaPT (Prasad et al., 2024), which achieves a 0.52 success rate, our method reaches 0.56 and reduces inference time from 164.4 seconds to just 3.0 seconds.", "AI": {"tldr": "SCOPE\u662f\u4e00\u79cd\u4e00\u6b21\u6027\u5206\u5c42\u89c4\u5212\u5668\uff0c\u5229\u7528LLM\u751f\u6210\u7684\u5b50\u76ee\u6807\u4ec5\u5728\u521d\u59cb\u5316\u65f6\u9884\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u5b66\u751f\u6a21\u578b\uff0c\u663e\u8457\u63d0\u9ad8\u6548\u7387\u4f46\u727a\u7272\u4e86\u89e3\u91ca\u6027", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u89c4\u5212\u65b9\u6cd5\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u90e8\u7f72\u56f0\u96be\u7684\u95ee\u9898\uff0c\u4e14\u901a\u5e38\u4f7f\u7528\u56fa\u5b9a\u53c2\u6570\u7684\u9884\u8bad\u7ec3LLM\uff0c\u65e0\u6cd5\u9488\u5bf9\u76ee\u6807\u4efb\u52a1\u8fdb\u884c\u9002\u914d\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u5229\u7528LLM\u7684\u8bed\u4e49\u77e5\u8bc6\u8fdb\u884c\u6587\u672c\u73af\u5883\u4e2d\u7684\u957f\u671f\u89c4\u5212\u3002", "method": "\u63d0\u51faSCOPE\u65b9\u6cd5\uff1a1\uff09\u4ec5\u5728\u521d\u59cb\u5316\u9636\u6bb5\u4f7f\u7528LLM\u751f\u6210\u5b50\u76ee\u6807\uff1b2\uff09\u4ece\u793a\u4f8b\u8f68\u8ff9\u4e2d\u76f4\u63a5\u63a8\u5bfc\u5b50\u76ee\u6807\uff1b3\uff09\u4f7f\u7528\u8fd9\u4e9b\u5b50\u76ee\u6807\u9884\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u5b66\u751f\u6a21\u578b\uff1b4\uff09\u907f\u514d\u8bad\u7ec3\u548c\u63a8\u7406\u671f\u95f4\u91cd\u590d\u67e5\u8be2LLM\uff0c\u663e\u8457\u63d0\u9ad8\u6548\u7387\u3002", "result": "\u5728TextCraft\u73af\u5883\u4e2d\uff0cSCOPE\u8fbe\u52300.56\u7684\u6210\u529f\u7387\uff0c\u4f18\u4e8eADaPT\u76840.52\uff1b\u63a8\u7406\u65f6\u95f4\u4ece164.4\u79d2\u5927\u5e45\u51cf\u5c11\u52303.0\u79d2\uff0c\u6548\u7387\u63d0\u5347\u663e\u8457\u3002", "conclusion": "\u5c3d\u7ba1LLM\u751f\u6210\u7684\u5b50\u76ee\u6807\u53ef\u80fd\u4e0d\u662f\u6700\u4f18\u7684\uff0c\u4f46\u4ecd\u80fd\u4e3a\u6587\u672c\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u5206\u5c42\u76ee\u6807\u5206\u89e3\u63d0\u4f9b\u826f\u597d\u7684\u8d77\u70b9\u3002SCOPE\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2512.09769", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09769", "abs": "https://arxiv.org/abs/2512.09769", "authors": ["Hanzhou Wu", "Yige Wang"], "title": "Defining Cost Function of Steganography with Large Language Models", "comment": "https://scholar.google.com/citations?hl=en&user=IdiF7M0AAAAJ", "summary": "In this paper, we make the first attempt towards defining cost function of steganography with large language models (LLMs), which is totally different from previous works that rely heavily on expert knowledge or require large-scale datasets for cost learning. To achieve this goal, a two-stage strategy combining LLM-guided program synthesis with evolutionary search is applied in the proposed method. In the first stage, a certain number of cost functions in the form of computer program are synthesized from LLM responses to structured prompts. These cost functions are then evaluated with pretrained steganalysis models so that candidate cost functions suited to steganography can be collected. In the second stage, by retraining a steganalysis model for each candidate cost function, the optimal cost function(s) can be determined according to the detection accuracy. This two-stage strategy is performed by an iterative fashion so that the best cost function can be collected at the last iteration. Experiments show that the proposed method enables LLMs to design new cost functions of steganography that significantly outperform existing works in terms of resisting steganalysis tools, which verifies the superiority of the proposed method. To the best knowledge of the authors, this is the first work applying LLMs to the design of advanced cost function of steganography, which presents a novel perspective for steganography design and may shed light on further research.", "AI": {"tldr": "\u9996\u6b21\u63d0\u51fa\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8bbe\u8ba1\u9690\u5199\u6210\u672c\u51fd\u6570\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u7b56\u7565\uff08LLM\u5f15\u5bfc\u7684\u7a0b\u5e8f\u5408\u6210+\u8fdb\u5316\u641c\u7d22\uff09\u81ea\u52a8\u751f\u6210\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6210\u672c\u51fd\u6570", "motivation": "\u4f20\u7edf\u9690\u5199\u6210\u672c\u51fd\u6570\u8bbe\u8ba1\u4e25\u91cd\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\u6216\u9700\u8981\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8fdb\u884c\u5b66\u4e60\uff0c\u672c\u6587\u9996\u6b21\u5c1d\u8bd5\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u8bbe\u8ba1\u9690\u5199\u6210\u672c\u51fd\u6570\uff0c\u63d0\u4f9b\u5168\u65b0\u7684\u8bbe\u8ba1\u89c6\u89d2", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u7b56\u7565\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u4eceLLM\u54cd\u5e94\u4e2d\u5408\u6210\u8ba1\u7b97\u673a\u7a0b\u5e8f\u5f62\u5f0f\u7684\u6210\u672c\u51fd\u6570\uff0c\u5e76\u7528\u9884\u8bad\u7ec3\u7684\u9690\u5199\u5206\u6790\u6a21\u578b\u8bc4\u4f30\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4e3a\u6bcf\u4e2a\u5019\u9009\u6210\u672c\u51fd\u6570\u91cd\u65b0\u8bad\u7ec3\u9690\u5199\u5206\u6790\u6a21\u578b\uff0c\u6839\u636e\u68c0\u6d4b\u51c6\u786e\u7387\u786e\u5b9a\u6700\u4f18\u6210\u672c\u51fd\u6570\uff0c\u901a\u8fc7\u8fed\u4ee3\u65b9\u5f0f\u6267\u884c", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u8bbe\u8ba1\u7684\u6210\u672c\u51fd\u6570\u5728\u62b5\u6297\u9690\u5199\u5206\u6790\u5de5\u5177\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5de5\u4f5c\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5c06LLM\u5e94\u7528\u4e8e\u9ad8\u7ea7\u9690\u5199\u6210\u672c\u51fd\u6570\u8bbe\u8ba1\u7684\u5de5\u4f5c\uff0c\u4e3a\u9690\u5199\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u53ef\u80fd\u542f\u53d1\u8fdb\u4e00\u6b65\u7814\u7a76"}}
{"id": "2512.09872", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09872", "abs": "https://arxiv.org/abs/2512.09872", "authors": ["Khurram Khalil", "Khaza Anuarul Hoque"], "title": "FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning", "comment": "Accepted in IEEE HOST 2026", "summary": "Generative Artificial Intelligence models, such as Large Language Models (LLMs) and Large Vision Models (VLMs), exhibit state-of-the-art performance but remain vulnerable to hardware-based threats, specifically bit-flip attacks (BFAs). Existing BFA discovery methods lack generalizability and struggle to scale, often failing to analyze the vast parameter space and complex interdependencies of modern foundation models in a reasonable time. This paper proposes FlipLLM, a reinforcement learning (RL) architecture-agnostic framework that formulates BFA discovery as a sequential decision-making problem. FlipLLM combines sensitivity-guided layer pruning with Q-learning to efficiently identify minimal, high-impact bit sets that can induce catastrophic failure. We demonstrate the effectiveness and generalizability of FlipLLM by applying it to a diverse set of models, including prominent text-only LLMs (GPT-2 Large, LLaMA 3.1 8B, and DeepSeek-V2 7B), VLMs such as LLaVA 1.6, and datasets, such as MMLU, MMLU-Pro, VQAv2, and TextVQA. Our results show that FlipLLM can identify critical bits that are vulnerable to BFAs up to 2.5x faster than SOTA methods. We demonstrate that flipping the FlipLLM-identified bits plummets the accuracy of LLaMA 3.1 8B from 69.9% to ~0.2%, and for LLaVA's VQA score from 78% to almost 0%, by flipping as few as 5 and 7 bits, respectively. Further analysis reveals that applying standard hardware protection mechanisms, such as ECC SECDED, to the FlipLLM-identified bit locations completely mitigates the BFA impact, demonstrating the practical value of our framework in guiding hardware-level defenses. FlipLLM offers the first scalable and adaptive methodology for exploring the BFA vulnerability of both language and multimodal foundation models, paving the way for comprehensive hardware-security evaluation.", "AI": {"tldr": "FlipLLM\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4f4d\u7ffb\u8f6c\u653b\u51fb\u6f0f\u6d1e\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u901f\u5ea6\u63d0\u53472.5\u500d\uff0c\u5e76\u80fd\u6307\u5bfc\u786c\u4ef6\u9632\u62a4\u673a\u5236\u7684\u8bbe\u8ba1\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u5f0fAI\u6a21\u578b\uff08\u5982LLMs\u548cVLMs\uff09\u867d\u7136\u6027\u80fd\u4f18\u5f02\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u786c\u4ef6\u5c42\u9762\u7684\u4f4d\u7ffb\u8f6c\u653b\u51fb\u3002\u73b0\u6709\u7684BFA\u53d1\u73b0\u65b9\u6cd5\u7f3a\u4e4f\u901a\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u96be\u4ee5\u5206\u6790\u73b0\u4ee3\u57fa\u7840\u6a21\u578b\u7684\u5e9e\u5927\u53c2\u6570\u7a7a\u95f4\u548c\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u63d0\u51faFlipLLM\u6846\u67b6\uff0c\u5c06BFA\u53d1\u73b0\u5efa\u6a21\u4e3a\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\uff0c\u7ed3\u5408\u654f\u611f\u5ea6\u5f15\u5bfc\u7684\u5c42\u526a\u679d\u548cQ\u5b66\u4e60\u7b97\u6cd5\uff0c\u9ad8\u6548\u8bc6\u522b\u6700\u5c0f\u4f46\u5f71\u54cd\u6700\u5927\u7684\u4f4d\u96c6\u5408\u3002", "result": "FlipLLM\u5728\u591a\u79cd\u6a21\u578b\u4e0a\u9a8c\u8bc1\u6709\u6548\uff1aLLaMA 3.1 8B\u51c6\u786e\u7387\u4ece69.9%\u964d\u81f30.2%\uff08\u4ec5\u7ffb\u8f6c5\u4f4d\uff09\uff0cLLaVA\u7684VQA\u5206\u6570\u4ece78%\u964d\u81f3\u63a5\u8fd10%\uff08\u4ec5\u7ffb\u8f6c7\u4f4d\uff09\u3002\u76f8\u6bd4SOTA\u65b9\u6cd5\u5feb2.5\u500d\uff0c\u4e14\u8bc6\u522b\u51fa\u7684\u5173\u952e\u4f4d\u5e94\u7528ECC SECDED\u7b49\u786c\u4ef6\u4fdd\u62a4\u673a\u5236\u53ef\u5b8c\u5168\u7f13\u89e3\u653b\u51fb\u5f71\u54cd\u3002", "conclusion": "FlipLLM\u4e3a\u8bed\u8a00\u548c\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u9996\u4e2a\u53ef\u6269\u5c55\u3001\u81ea\u9002\u5e94\u7684BFA\u6f0f\u6d1e\u5206\u6790\u65b9\u6cd5\uff0c\u4e3a\u5168\u9762\u7684\u786c\u4ef6\u5b89\u5168\u8bc4\u4f30\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u5177\u6709\u6307\u5bfc\u786c\u4ef6\u7ea7\u9632\u5fa1\u7684\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2512.09883", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09883", "abs": "https://arxiv.org/abs/2512.09883", "authors": ["Daniel Gibert", "Felip Many\u00e0"], "title": "ByteShield: Adversarially Robust End-to-End Malware Detection through Byte Masking", "comment": null, "summary": "Research has proven that end-to-end malware detectors are vulnerable to adversarial attacks. In response, the research community has proposed defenses based on randomized and (de)randomized smoothing. However, these techniques remain susceptible to attacks that insert large adversarial payloads. To address these limitations, we propose a novel defense mechanism designed to harden end-to-end malware detectors by leveraging masking at the byte level. This mechanism operates by generating multiple masked versions of the input file, independently classifying each version, and then applying a threshold-based voting mechanism to produce the final classification. Key to this defense is a deterministic masking strategy that systematically strides a mask across the entire input file. Unlike randomized smoothing defenses, which randomly mask or delete bytes, this structured approach ensures coverage of the file over successive versions. In the best-case scenario, this strategy fully occludes the adversarial payload, effectively neutralizing its influence on the model's decision. In the worst-case scenario, it partially occludes the adversarial payload, reducing its impact on the model's predictions. By occluding the adversarial payload in one or more masked versions, this defense ensures that some input versions remain representative of the file's original intent, allowing the voting mechanism to suppress the influence of the adversarial payload. Results achieved on the EMBER and BODMAS datasets demonstrate the suitability of our defense, outperforming randomized and (de)randomized smoothing defenses against adversarial examples generated with a wide range of functionality-preserving manipulations while maintaining high accuracy on clean examples.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5b57\u8282\u7ea7\u63a9\u7801\u7684\u65b0\u578b\u9632\u5fa1\u673a\u5236\uff0c\u901a\u8fc7\u751f\u6210\u591a\u4e2a\u63a9\u7801\u7248\u672c\u7684\u6587\u4ef6\u3001\u72ec\u7acb\u5206\u7c7b\u6bcf\u4e2a\u7248\u672c\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u9608\u503c\u7684\u6295\u7968\u673a\u5236\u6765\u589e\u5f3a\u7aef\u5230\u7aef\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u5668\u5bf9\u6297\u5bf9\u6297\u6027\u653b\u51fb\u7684\u80fd\u529b\u3002", "motivation": "\u7aef\u5230\u7aef\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u5668\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u73b0\u6709\u7684\u968f\u673a\u5316\u548c\u53bb\u968f\u673a\u5316\u5e73\u6ed1\u9632\u5fa1\u6280\u672f\u4ecd\u7136\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u63d2\u5165\u5927\u578b\u5bf9\u6297\u6027\u8f7d\u8377\u7684\u653b\u51fb\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u7684\u9632\u5fa1\u673a\u5236\u3002", "method": "\u91c7\u7528\u786e\u5b9a\u6027\u63a9\u7801\u7b56\u7565\uff0c\u5728\u5b57\u8282\u7ea7\u522b\u5bf9\u8f93\u5165\u6587\u4ef6\u8fdb\u884c\u7cfb\u7edf\u6027\u7684\u63a9\u7801\u5904\u7406\uff0c\u751f\u6210\u591a\u4e2a\u63a9\u7801\u7248\u672c\u3002\u6bcf\u4e2a\u7248\u672c\u72ec\u7acb\u5206\u7c7b\uff0c\u7136\u540e\u901a\u8fc7\u57fa\u4e8e\u9608\u503c\u7684\u6295\u7968\u673a\u5236\u4ea7\u751f\u6700\u7ec8\u5206\u7c7b\u7ed3\u679c\u3002", "result": "\u5728EMBER\u548cBODMAS\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u9632\u5fa1\u673a\u5236\u4f18\u4e8e\u968f\u673a\u5316\u548c\u53bb\u968f\u673a\u5316\u5e73\u6ed1\u9632\u5fa1\uff0c\u80fd\u591f\u6709\u6548\u62b5\u5fa1\u591a\u79cd\u529f\u80fd\u4fdd\u6301\u64cd\u4f5c\u751f\u6210\u7684\u5bf9\u6297\u6837\u672c\uff0c\u540c\u65f6\u5728\u5e72\u51c0\u6837\u672c\u4e0a\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u5b57\u8282\u7ea7\u63a9\u7801\u9632\u5fa1\u673a\u5236\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u63a9\u7801\u7b56\u7565\u548c\u6295\u7968\u673a\u5236\uff0c\u80fd\u591f\u6709\u6548\u4e2d\u548c\u5bf9\u6297\u6027\u8f7d\u8377\u7684\u5f71\u54cd\uff0c\u4e3a\u7aef\u5230\u7aef\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u5668\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5bf9\u6297\u6027\u653b\u51fb\u9632\u5fa1\u80fd\u529b\u3002"}}

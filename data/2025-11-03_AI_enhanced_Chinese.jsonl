{"id": "2510.26852", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26852", "abs": "https://arxiv.org/abs/2510.26852", "authors": ["Lingyue Fu", "Xin Ding", "Yaoming Zhu", "Shao Zhang", "Lin Qiu", "Weiwen Liu", "Weinan Zhang", "Xuezhi Cao", "Xunliang Cai", "Jiaxin Ding", "Yong Yu"], "title": "CATArena: Evaluation of LLM Agents through Iterative Tournament Competitions", "comment": null, "summary": "Large Language Model (LLM) agents have evolved from basic text generation to\nautonomously completing complex tasks through interaction with external tools.\nHowever, current benchmarks mainly assess end-to-end performance in fixed\nscenarios, restricting evaluation to specific skills and suffering from score\nsaturation and growing dependence on expert annotation as agent capabilities\nimprove. In this work, we emphasize the importance of learning ability,\nincluding both self-improvement and peer-learning, as a core driver for agent\nevolution toward human-level intelligence. We propose an iterative, competitive\npeer-learning framework, which allows agents to refine and optimize their\nstrategies through repeated interactions and feedback, thereby systematically\nevaluating their learning capabilities. To address the score saturation issue\nin current benchmarks, we introduce CATArena, a tournament-style evaluation\nplatform featuring four diverse board and card games with open-ended scoring.\nBy providing tasks without explicit upper score limits, CATArena enables\ncontinuous and dynamic evaluation of rapidly advancing agent capabilities.\nExperimental results and analyses involving both minimal and commercial code\nagents demonstrate that CATArena provides reliable, stable, and scalable\nbenchmarking for core agent abilities, particularly learning ability and\nstrategy coding.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CATArena\u8bc4\u4f30\u5e73\u53f0\uff0c\u901a\u8fc7\u56db\u6b3e\u68cb\u724c\u6e38\u620f\u7684\u65e0\u4e0a\u9650\u8bc4\u5206\u7cfb\u7edf\u6765\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u7684\u5b66\u4e60\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u5206\u6570\u9971\u548c\u95ee\u9898\u3002", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u8bc4\u4f30\u56fa\u5b9a\u573a\u666f\u4e0b\u7684\u7aef\u5230\u7aef\u6027\u80fd\uff0c\u5b58\u5728\u5206\u6570\u9971\u548c\u3001\u5bf9\u4e13\u5bb6\u6807\u6ce8\u4f9d\u8d56\u6027\u5f3a\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u667a\u80fd\u4f53\u7684\u5b66\u4e60\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u8fed\u4ee3\u5f0f\u7ade\u4e89\u6027\u540c\u4f34\u5b66\u4e60\u6846\u67b6\uff0c\u8ba9\u667a\u80fd\u4f53\u901a\u8fc7\u91cd\u590d\u4ea4\u4e92\u548c\u53cd\u9988\u4f18\u5316\u7b56\u7565\uff1b\u5f00\u53d1CATArena\u5e73\u53f0\uff0c\u5305\u542b\u56db\u6b3e\u5f00\u653e\u5f0f\u8bc4\u5206\u7684\u68cb\u724c\u6e38\u620f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eCATArena\u80fd\u591f\u53ef\u9760\u3001\u7a33\u5b9a\u3001\u53ef\u6269\u5c55\u5730\u8bc4\u4f30\u667a\u80fd\u4f53\u6838\u5fc3\u80fd\u529b\uff0c\u7279\u522b\u662f\u5b66\u4e60\u80fd\u529b\u548c\u7b56\u7565\u7f16\u7801\u80fd\u529b\u3002", "conclusion": "CATArena\u5e73\u53f0\u4e3a\u8bc4\u4f30\u5feb\u901f\u53d1\u5c55\u7684\u667a\u80fd\u4f53\u80fd\u529b\u63d0\u4f9b\u4e86\u6301\u7eed\u52a8\u6001\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7279\u522b\u5173\u6ce8\u5b66\u4e60\u80fd\u529b\u8fd9\u4e00\u6838\u5fc3\u9a71\u52a8\u529b\u3002"}}
{"id": "2510.26913", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.26913", "abs": "https://arxiv.org/abs/2510.26913", "authors": ["Junyi Shen", "Noppanat Wadlom", "Lingfeng Zhou", "Dequan Wang", "Xu Miao", "Lei Fang", "Yao Lu"], "title": "FlowMesh: A Service Fabric for Composable LLM Workflows", "comment": null, "summary": "AI deployment increasingly resembles a pipeline of data transformation,\nfine-tuning, and agent interactions rather than a monolithic LLM job; recent\nexamples include RLHF/RLAIF training and agentic workflows. To cope with this\nshift, we propose FlowMesh, a multi-tenant service fabric that executes and\noptimizes these workloads as one shared service instead of isolated pipelines.\nIt decomposes workflows into fine-grained operators with recorded lineage,\nenabling de-duplication of work across users and batching requests on the same\nhardware while preserving per-workflow provenance. A global control plane\nmaintains a cluster-wide pool of ready operators and uses a single utility\nfunction to pick both the batch and the worker, balancing throughput, cost, and\ndata locality on heterogeneous GPUs. The data plane is an elastic fleet of\nstateless workers backed by a content-addressable store, enabling rapid,\nautomatic scale-out, safe retry after preemption, and portability across\nmanaged clusters such as Kubernetes and geo-distributed GPU marketplaces such\nas Vast.ai. Compared with baseline solutions, FlowMesh achieves up to 3.8x cost\nreduction and 2.0x lower energy usage, provides a similar or better latency\nprofile, and remains efficient under dynamic and failure-prone conditions.", "AI": {"tldr": "FlowMesh\u662f\u4e00\u4e2a\u591a\u79df\u6237\u670d\u52a1\u67b6\u6784\uff0c\u5c06AI\u5de5\u4f5c\u8d1f\u8f7d\u4f5c\u4e3a\u5171\u4eab\u670d\u52a1\u6267\u884c\u548c\u4f18\u5316\uff0c\u800c\u975e\u9694\u79bb\u7684\u6d41\u6c34\u7ebf\u3002\u5b83\u901a\u8fc7\u5206\u89e3\u5de5\u4f5c\u6d41\u4e3a\u7ec6\u7c92\u5ea6\u7b97\u5b50\u3001\u8bb0\u5f55\u6570\u636e\u8840\u7f18\u3001\u8de8\u7528\u6237\u53bb\u91cd\u548c\u786c\u4ef6\u6279\u5904\u7406\u8bf7\u6c42\uff0c\u5b9e\u73b0\u6210\u672c\u964d\u4f4e3.8\u500d\u3001\u80fd\u8017\u964d\u4f4e2.0\u500d\uff0c\u5e76\u5728\u52a8\u6001\u548c\u6545\u969c\u6761\u4ef6\u4e0b\u4fdd\u6301\u9ad8\u6548\u3002", "motivation": "AI\u90e8\u7f72\u8d8a\u6765\u8d8a\u50cf\u6570\u636e\u8f6c\u6362\u3001\u5fae\u8c03\u548c\u667a\u80fd\u4f53\u4ea4\u4e92\u7684\u6d41\u6c34\u7ebf\uff0c\u800c\u975e\u5355\u4e00\u7684LLM\u4efb\u52a1\u3002\u4e3a\u5e94\u5bf9\u8fd9\u4e00\u8f6c\u53d8\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6267\u884c\u548c\u4f18\u5316\u8fd9\u4e9b\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5171\u4eab\u670d\u52a1\u67b6\u6784\u3002", "method": "\u5c06\u5de5\u4f5c\u6d41\u5206\u89e3\u4e3a\u7ec6\u7c92\u5ea6\u7b97\u5b50\u5e76\u8bb0\u5f55\u8840\u7f18\uff1b\u4f7f\u7528\u5168\u5c40\u63a7\u5236\u5e73\u9762\u7ef4\u62a4\u96c6\u7fa4\u8303\u56f4\u5185\u7684\u7b97\u5b50\u6c60\uff0c\u901a\u8fc7\u5355\u4e00\u6548\u7528\u51fd\u6570\u9009\u62e9\u6279\u6b21\u548c\u5de5\u4f5c\u8282\u70b9\uff1b\u6570\u636e\u5e73\u9762\u91c7\u7528\u65e0\u72b6\u6001\u5de5\u4f5c\u8282\u70b9\u548c\u5185\u5bb9\u5bfb\u5740\u5b58\u50a8\uff0c\u652f\u6301\u5f39\u6027\u6269\u5c55\u3001\u5b89\u5168\u91cd\u8bd5\u548c\u8de8\u96c6\u7fa4\u53ef\u79fb\u690d\u6027\u3002", "result": "\u4e0e\u57fa\u7ebf\u89e3\u51b3\u65b9\u6848\u76f8\u6bd4\uff0cFlowMesh\u5b9e\u73b0\u9ad8\u8fbe3.8\u500d\u7684\u6210\u672c\u964d\u4f4e\u548c2.0\u500d\u7684\u80fd\u8017\u964d\u4f4e\uff0c\u63d0\u4f9b\u76f8\u4f3c\u6216\u66f4\u597d\u7684\u5ef6\u8fdf\u7279\u6027\uff0c\u5728\u52a8\u6001\u548c\u6545\u969c\u6761\u4ef6\u4e0b\u4fdd\u6301\u9ad8\u6548\u3002", "conclusion": "FlowMesh\u901a\u8fc7\u591a\u79df\u6237\u670d\u52a1\u67b6\u6784\u6709\u6548\u4f18\u5316AI\u5de5\u4f5c\u8d1f\u8f7d\u6267\u884c\uff0c\u663e\u8457\u964d\u4f4e\u6210\u672c\u3001\u80fd\u8017\uff0c\u5e76\u4fdd\u6301\u9ad8\u6027\u80fd\u548c\u53ef\u9760\u6027\uff0c\u9002\u7528\u4e8eKubernetes\u548c\u5206\u5e03\u5f0fGPU\u5e02\u573a\u7b49\u73af\u5883\u3002"}}
{"id": "2510.26989", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.26989", "abs": "https://arxiv.org/abs/2510.26989", "authors": ["Agorakis Bompotas", "Konstantinos Koutras", "Nikitas Rigas Kalogeropoulos", "Panagiotis Kechagias", "Dimitra Gariza", "Athanasios P. Kalogeras", "Christos Alexakos"], "title": "SUSTAINABLE Platform: Seamless Smart Farming Integration Towards Agronomy Automation", "comment": "Accepted for presentation to 11th IEEE International Smart Cities\n  Conference (ISC2 2025)", "summary": "The global agricultural sector is undergoing a transformative shift, driven\nby increasing food demands, climate variability and the need for sustainable\npractices. SUSTAINABLE is a smart farming platform designed to integrate IoT,\nAI, satellite imaging, and role-based task orchestration to enable efficient,\ntraceable, and sustainable agriculture with a pilot usecase in viticulture.\nThis paper explores current smart agriculture solutions, presents a comparative\nevaluation, and introduces SUSTAINABLE's key features, including satellite\nindex integration, real-time environmental data, and role-aware task management\ntailored to Mediterranean vineyards.", "AI": {"tldr": "SUSTAINABLE\u662f\u4e00\u4e2a\u667a\u80fd\u519c\u4e1a\u5e73\u53f0\uff0c\u6574\u5408\u7269\u8054\u7f51\u3001\u4eba\u5de5\u667a\u80fd\u3001\u536b\u661f\u6210\u50cf\u548c\u57fa\u4e8e\u89d2\u8272\u7684\u4efb\u52a1\u7f16\u6392\uff0c\u65e8\u5728\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u8ffd\u6eaf\u548c\u53ef\u6301\u7eed\u7684\u519c\u4e1a\uff0c\u5e76\u4ee5\u8461\u8404\u79cd\u690d\u4e3a\u8bd5\u70b9\u7528\u4f8b\u3002", "motivation": "\u5168\u7403\u519c\u4e1a\u90e8\u95e8\u9762\u4e34\u65e5\u76ca\u589e\u957f\u7684\u7cae\u98df\u9700\u6c42\u3001\u6c14\u5019\u591a\u53d8\u6027\u548c\u53ef\u6301\u7eed\u5b9e\u8df5\u9700\u6c42\uff0c\u9700\u8981\u8fdb\u884c\u8f6c\u578b\u3002", "method": "\u6574\u5408\u7269\u8054\u7f51\u3001\u4eba\u5de5\u667a\u80fd\u3001\u536b\u661f\u6210\u50cf\u548c\u57fa\u4e8e\u89d2\u8272\u7684\u4efb\u52a1\u7f16\u6392\uff0c\u7279\u522b\u9488\u5bf9\u5730\u4e2d\u6d77\u8461\u8404\u56ed\u8fdb\u884c\u536b\u661f\u6307\u6570\u96c6\u6210\u3001\u5b9e\u65f6\u73af\u5883\u6570\u636e\u548c\u89d2\u8272\u611f\u77e5\u4efb\u52a1\u7ba1\u7406\u3002", "result": "\u63d0\u51fa\u4e86SUSTAINABLE\u5e73\u53f0\u7684\u5173\u952e\u7279\u6027\uff0c\u5305\u62ec\u536b\u661f\u6307\u6570\u96c6\u6210\u3001\u5b9e\u65f6\u73af\u5883\u6570\u636e\u548c\u89d2\u8272\u611f\u77e5\u4efb\u52a1\u7ba1\u7406\u3002", "conclusion": "SUSTAINABLE\u5e73\u53f0\u4e3a\u519c\u4e1a\u63d0\u4f9b\u4e86\u4e00\u79cd\u667a\u80fd\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u652f\u6301\u9ad8\u6548\u3001\u53ef\u8ffd\u6eaf\u548c\u53ef\u6301\u7eed\u7684\u519c\u4e1a\u751f\u4ea7\u3002"}}
{"id": "2510.27257", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.27257", "abs": "https://arxiv.org/abs/2510.27257", "authors": ["Mengshi Qi", "Jiaxuan Peng", "Jie Zhang", "Juan Zhu", "Yong Li", "Huadong Ma"], "title": "Synergistic Tensor and Pipeline Parallelism", "comment": null, "summary": "In the machine learning system, the hybrid model parallelism combining tensor\nparallelism (TP) and pipeline parallelism (PP) has become the dominant solution\nfor distributed training of Large Language Models~(LLMs) and Multimodal LLMs\n(MLLMs). However, TP introduces significant collective communication overheads,\nwhile PP suffers from synchronization inefficiencies such as pipeline bubbles.\nExisting works primarily address these challenges from isolated perspectives,\nfocusing either on overlapping TP communication or on flexible PP scheduling to\nmitigate pipeline bubbles. In this paper, we propose a new synergistic tensor\nand pipeline parallelism schedule that simultaneously reduces both types of\nbubbles. Our proposed schedule decouples the forward and backward passes in PP\ninto fine-grained computation units, which are then braided to form a composite\ncomputation sequence. This compositional structure enables near-complete\nelimination of TP-related bubbles. Building upon this structure, we further\ndesign the PP schedule to minimize PP bubbles. Experimental results demonstrate\nthat our approach improves training throughput by up to 12% for LLMs and 16%\nfor MLLMs compared to existing scheduling methods. Our source code is avaiable\nat https://github.com/MICLAB-BUPT/STP.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u534f\u540c\u5f20\u91cf\u548c\u6d41\u6c34\u7ebf\u5e76\u884c\u8c03\u5ea6\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u524d\u5411\u548c\u540e\u5411\u4f20\u64ad\u89e3\u8026\u4e3a\u7ec6\u7c92\u5ea6\u8ba1\u7b97\u5355\u5143\u5e76\u4ea4\u7ec7\u7f16\u6392\uff0c\u540c\u65f6\u51cf\u5c11TP\u901a\u4fe1\u5f00\u9500\u548cPP\u6d41\u6c34\u7ebf\u6c14\u6ce1\uff0c\u663e\u8457\u63d0\u5347LLM\u548cMLLM\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u6df7\u5408\u5e76\u884c\u65b9\u6848\u4e2d\uff0c\u5f20\u91cf\u5e76\u884c(TP)\u5e26\u6765\u5927\u91cf\u96c6\u4f53\u901a\u4fe1\u5f00\u9500\uff0c\u6d41\u6c34\u7ebf\u5e76\u884c(PP)\u5b58\u5728\u540c\u6b65\u6548\u7387\u4f4e\u4e0b\u7684\u6d41\u6c34\u7ebf\u6c14\u6ce1\u95ee\u9898\u3002\u73b0\u6709\u5de5\u4f5c\u591a\u4ece\u5b64\u7acb\u89d2\u5ea6\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7f3a\u4e4f\u534f\u540c\u4f18\u5316\u3002", "method": "\u5c06PP\u4e2d\u7684\u524d\u5411\u548c\u540e\u5411\u4f20\u64ad\u89e3\u8026\u4e3a\u7ec6\u7c92\u5ea6\u8ba1\u7b97\u5355\u5143\uff0c\u901a\u8fc7\u4ea4\u7ec7\u7f16\u6392\u5f62\u6210\u590d\u5408\u8ba1\u7b97\u5e8f\u5217\uff0c\u5b9e\u73b0TP\u76f8\u5173\u6c14\u6ce1\u7684\u8fd1\u4e4e\u5b8c\u5168\u6d88\u9664\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u8bbe\u8ba1PP\u8c03\u5ea6\u4ee5\u6700\u5c0f\u5316PP\u6c14\u6ce1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u73b0\u6709\u8c03\u5ea6\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5bf9LLM\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u5347\u8fbe12%\uff0c\u5bf9MLLM\u63d0\u5347\u8fbe16%\u3002", "conclusion": "\u63d0\u51fa\u7684\u534f\u540c\u5f20\u91cf\u548c\u6d41\u6c34\u7ebf\u5e76\u884c\u8c03\u5ea6\u80fd\u6709\u6548\u540c\u65f6\u51cf\u5c11\u4e24\u79cd\u7c7b\u578b\u7684\u6c14\u6ce1\uff0c\u663e\u8457\u63d0\u5347\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2510.26847", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.26847", "abs": "https://arxiv.org/abs/2510.26847", "authors": ["Shaked Zychlinski", "Yuval Kainan"], "title": "Broken-Token: Filtering Obfuscated Prompts by Counting Characters-Per-Token", "comment": "16 pages, 9 figures", "summary": "Large Language Models (LLMs) are susceptible to jailbreak attacks where\nmalicious prompts are disguised using ciphers and character-level encodings to\nbypass safety guardrails. While these guardrails often fail to interpret the\nencoded content, the underlying models can still process the harmful\ninstructions. We introduce CPT-Filtering, a novel, model-agnostic with\nnegligible-costs and near-perfect accuracy guardrail technique that aims to\nmitigate these attacks by leveraging the intrinsic behavior of Byte-Pair\nEncoding (BPE) tokenizers. Our method is based on the principle that\ntokenizers, trained on natural language, represent out-of-distribution text,\nsuch as ciphers, using a significantly higher number of shorter tokens. Our\ntechnique uses a simple yet powerful artifact of using language models: the\naverage number of Characters Per Token (CPT) in the text. This approach is\nmotivated by the high compute cost of modern methods - relying on added modules\nsuch as dedicated LLMs or perplexity models. We validate our approach across a\nlarge dataset of over 100,000 prompts, testing numerous encoding schemes with\nseveral popular tokenizers. Our experiments demonstrate that a simple CPT\nthreshold robustly identifies encoded text with high accuracy, even for very\nshort inputs. CPT-Filtering provides a practical defense layer that can be\nimmediately deployed for real-time text filtering and offline data curation.", "AI": {"tldr": "CPT-Filtering\u662f\u4e00\u79cd\u65b0\u9896\u7684\u6a21\u578b\u65e0\u5173\u9632\u62a4\u6280\u672f\uff0c\u5229\u7528BPE\u5206\u8bcd\u5668\u7684\u5185\u5728\u7279\u6027\u6765\u68c0\u6d4b\u548c\u8fc7\u6ee4\u4f7f\u7528\u5bc6\u7801\u548c\u5b57\u7b26\u7ea7\u7f16\u7801\u7684\u8d8a\u72f1\u653b\u51fb\uff0c\u5177\u6709\u4f4e\u6210\u672c\u548c\u9ad8\u51c6\u786e\u7387\u7684\u7279\u70b9\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u4f7f\u7528\u5bc6\u7801\u548c\u5b57\u7b26\u7ea7\u7f16\u7801\u7684\u8d8a\u72f1\u653b\u51fb\uff0c\u8fd9\u4e9b\u653b\u51fb\u80fd\u7ed5\u8fc7\u5b89\u5168\u9632\u62a4\u673a\u5236\u3002\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u8981\u989d\u5916\u7684LLM\u6216\u56f0\u60d1\u5ea6\u6a21\u578b\u3002", "method": "\u57fa\u4e8eBPE\u5206\u8bcd\u5668\u5728\u81ea\u7136\u8bed\u8a00\u8bad\u7ec3\u4e2d\u7684\u7279\u6027\uff1a\u5bf9\u4e8e\u5206\u5e03\u5916\u6587\u672c\uff08\u5982\u5bc6\u7801\uff09\uff0c\u5206\u8bcd\u5668\u4f1a\u4f7f\u7528\u66f4\u591a\u66f4\u77ed\u7684token\u3002\u901a\u8fc7\u8ba1\u7b97\u6587\u672c\u4e2d\u5e73\u5747\u6bcf\u4e2atoken\u7684\u5b57\u7b26\u6570\uff08CPT\uff09\u6765\u8bc6\u522b\u7f16\u7801\u6587\u672c\u3002", "result": "\u5728\u8d85\u8fc710\u4e07\u4e2a\u63d0\u793a\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u6d4b\u8bd5\u4e86\u591a\u79cd\u7f16\u7801\u65b9\u6848\u548c\u6d41\u884c\u5206\u8bcd\u5668\u3002\u5b9e\u9a8c\u8868\u660e\u7b80\u5355\u7684CPT\u9608\u503c\u80fd\u9ad8\u7cbe\u5ea6\u5730\u8bc6\u522b\u7f16\u7801\u6587\u672c\uff0c\u5373\u4f7f\u5bf9\u4e8e\u975e\u5e38\u77ed\u7684\u8f93\u5165\u4e5f\u6709\u6548\u3002", "conclusion": "CPT-Filtering\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u9632\u5fa1\u5c42\uff0c\u53ef\u7acb\u5373\u90e8\u7f72\u7528\u4e8e\u5b9e\u65f6\u6587\u672c\u8fc7\u6ee4\u548c\u79bb\u7ebf\u6570\u636e\u6574\u7406\uff0c\u5177\u6709\u6a21\u578b\u65e0\u5173\u3001\u6210\u672c\u6781\u4f4e\u548c\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2510.27009", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.27009", "abs": "https://arxiv.org/abs/2510.27009", "authors": ["Jared Junkin", "Samuel Nathanson"], "title": "Causal Masking on Spatial Data: An Information-Theoretic Case for Learning Spatial Datasets with Unimodal Language Models", "comment": "8 pages, NeurIPS 2025", "summary": "Language models are traditionally designed around causal masking. In domains\nwith spatial or relational structure, causal masking is often viewed as\ninappropriate, and sequential linearizations are instead used. Yet the question\nof whether it is viable to accept the information loss introduced by causal\nmasking on nonsequential data has received little direct study, in part because\nfew domains offer both spatial and sequential representations of the same\ndataset. In this work, we investigate this issue in the domain of chess, which\nnaturally supports both representations. We train language models with\nbidirectional and causal self-attention mechanisms on both spatial\n(board-based) and sequential (move-based) data. Our results show that models\ntrained on spatial board states - \\textit{even with causal masking} -\nconsistently achieve stronger playing strength than models trained on\nsequential data. While our experiments are conducted on chess, our results are\nmethodological and may have broader implications: applying causal masking to\nspatial data is a viable procedure for training unimodal LLMs on spatial data,\nand in some domains is even preferable to sequentialization.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u68cb\u76d8\u72b6\u6001\u6570\u636e\u4e0a\u4f7f\u7528\u56e0\u679c\u63a9\u7801\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u5176\u68cb\u529b\u8868\u73b0\u4f18\u4e8e\u5728\u987a\u5e8f\u79fb\u52a8\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u8ba4\u4e3a\u56e0\u679c\u63a9\u7801\u4e0d\u9002\u7528\u4e8e\u7a7a\u95f4\u6570\u636e\u7684\u89c2\u70b9\u3002", "motivation": "\u63a2\u8ba8\u5728\u5177\u6709\u7a7a\u95f4\u6216\u5173\u7cfb\u7ed3\u6784\u7684\u9886\u57df\u4e2d\uff0c\u63a5\u53d7\u56e0\u679c\u63a9\u7801\u5e26\u6765\u7684\u4fe1\u606f\u635f\u5931\u662f\u5426\u53ef\u884c\uff0c\u4ee5\u53ca\u662f\u5426\u6bd4\u987a\u5e8f\u7ebf\u6027\u5316\u65b9\u6cd5\u66f4\u4f18\u3002", "method": "\u5728\u56fd\u9645\u8c61\u68cb\u9886\u57df\u8bad\u7ec3\u5177\u6709\u53cc\u5411\u548c\u56e0\u679c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u5206\u522b\u4f7f\u7528\u7a7a\u95f4\uff08\u68cb\u76d8\u72b6\u6001\uff09\u548c\u987a\u5e8f\uff08\u79fb\u52a8\u5e8f\u5217\uff09\u6570\u636e\u3002", "result": "\u5728\u7a7a\u95f4\u68cb\u76d8\u72b6\u6001\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\uff08\u5373\u4f7f\u4f7f\u7528\u56e0\u679c\u63a9\u7801\uff09\u59cb\u7ec8\u6bd4\u5728\u987a\u5e8f\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u5177\u6709\u66f4\u5f3a\u7684\u68cb\u529b\u3002", "conclusion": "\u5c06\u56e0\u679c\u63a9\u7801\u5e94\u7528\u4e8e\u7a7a\u95f4\u6570\u636e\u662f\u8bad\u7ec3\u5355\u6a21\u6001LLM\u7684\u53ef\u884c\u65b9\u6cd5\uff0c\u5728\u67d0\u4e9b\u9886\u57df\u751a\u81f3\u4f18\u4e8e\u987a\u5e8f\u5316\u65b9\u6cd5\u3002"}}
{"id": "2510.26941", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26941", "abs": "https://arxiv.org/abs/2510.26941", "authors": ["Seif Ikbarieh", "Maanak Gupta", "Elmahedi Mahalal"], "title": "LLM-based Multi-class Attack Analysis and Mitigation Framework in IoT/IIoT Networks", "comment": null, "summary": "The Internet of Things has expanded rapidly, transforming communication and\noperations across industries but also increasing the attack surface and\nsecurity breaches. Artificial Intelligence plays a key role in securing IoT,\nenabling attack detection, attack behavior analysis, and mitigation suggestion.\nDespite advancements, evaluations remain purely qualitative, and the lack of a\nstandardized, objective benchmark for quantitatively measuring AI-based attack\nanalysis and mitigation hinders consistent assessment of model effectiveness.\nIn this work, we propose a hybrid framework combining Machine Learning (ML) for\nmulti-class attack detection with Large Language Models (LLMs) for attack\nbehavior analysis and mitigation suggestion. After benchmarking several ML and\nDeep Learning (DL) classifiers on the Edge-IIoTset and CICIoT2023 datasets, we\napplied structured role-play prompt engineering with Retrieval-Augmented\nGeneration (RAG) to guide ChatGPT-o3 and DeepSeek-R1 in producing detailed,\ncontext-aware responses. We introduce novel evaluation metrics for quantitative\nassessment to guide us and an ensemble of judge LLMs, namely ChatGPT-4o,\nDeepSeek-V3, Mixtral 8x7B Instruct, Gemini 2.5 Flash, Meta Llama 4, TII Falcon\nH1 34B Instruct, xAI Grok 3, and Claude 4 Sonnet, to independently evaluate the\nresponses. Results show that Random Forest has the best detection model, and\nChatGPT-o3 outperformed DeepSeek-R1 in attack analysis and mitigation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u8fdb\u884c\u591a\u7c7b\u653b\u51fb\u68c0\u6d4b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u653b\u51fb\u884c\u4e3a\u5206\u6790\u548c\u7f13\u89e3\u5efa\u8bae\u7684\u6df7\u5408\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u4e86\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u6765\u91cf\u5316\u8bc4\u4f30AI\u6a21\u578b\u5728\u7269\u8054\u7f51\u5b89\u5168\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u7269\u8054\u7f51\u7684\u5feb\u901f\u53d1\u5c55\u6269\u5927\u4e86\u653b\u51fb\u9762\u548c\u5b89\u5168\u6f0f\u6d1e\uff0c\u867d\u7136\u4eba\u5de5\u667a\u80fd\u5728\u4fdd\u62a4\u7269\u8054\u7f51\u5b89\u5168\u65b9\u9762\u53d1\u6325\u7740\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u73b0\u6709\u8bc4\u4f30\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u5ba2\u89c2\u57fa\u51c6\u6765\u5b9a\u91cf\u8861\u91cf\u57fa\u4e8eAI\u7684\u653b\u51fb\u5206\u6790\u548c\u7f13\u89e3\u6548\u679c\u3002", "method": "\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u8fdb\u884c\u591a\u7c7b\u653b\u51fb\u68c0\u6d4b\uff0c\u4f7f\u7528\u7ed3\u6784\u5316\u89d2\u8272\u626e\u6f14\u63d0\u793a\u5de5\u7a0b\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u6307\u5bfcChatGPT-o3\u548cDeepSeek-R1\u751f\u6210\u8be6\u7ec6\u7684\u60c5\u5883\u611f\u77e5\u54cd\u5e94\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u548c\u6cd5\u5b98LLM\u96c6\u5408\u8fdb\u884c\u72ec\u7acb\u8bc4\u4f30\u3002", "result": "\u968f\u673a\u68ee\u6797\u8868\u73b0\u51fa\u6700\u4f73\u68c0\u6d4b\u6027\u80fd\uff0cChatGPT-o3\u5728\u653b\u51fb\u5206\u6790\u548c\u7f13\u89e3\u65b9\u9762\u4f18\u4e8eDeepSeek-R1\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u6846\u67b6\u548c\u91cf\u5316\u8bc4\u4f30\u65b9\u6cd5\u4e3aAI\u5728\u7269\u8054\u7f51\u5b89\u5168\u4e2d\u7684\u6709\u6548\u6027\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u57fa\u51c6\uff0c\u8bc1\u660e\u4e86\u673a\u5668\u5b66\u4e60\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u5728\u7269\u8054\u7f51\u5b89\u5168\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.26985", "categories": ["cs.AR", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.26985", "abs": "https://arxiv.org/abs/2510.26985", "authors": ["Mostafa Darvishi"], "title": "Practical Timing Closure in FPGA and ASIC Designs: Methods, Challenges, and Case Studies", "comment": "5 figures, 3 tables", "summary": "This paper presents an in-depth analysis of timing closure challenges and\nconstraints in Field Programmable Gate Arrays (FPGAs) and Application Specific\nIntegrated Circuits (ASICs). We examine core timing principles, architectural\ndistinctions, and design methodologies influencing timing behavior in both\ntechnologies. A case study comparing the Xilinx Kintex UltraScale+ FPGA\n(XCKU040) with a 7nm ASIC highlights practical timing analysis and performance\ntrade-offs. Experimental results show ASICs achieve superior timing of 45ps\nsetup and 35ps hold, while modern FPGAs remain competitive with 180ps setup and\n120ps hold times, validating their suitability for high-performance designs.", "AI": {"tldr": "\u672c\u6587\u6df1\u5165\u5206\u6790\u4e86FPGA\u548cASIC\u4e2d\u7684\u65f6\u5e8f\u6536\u655b\u6311\u6218\u4e0e\u7ea6\u675f\uff0c\u901a\u8fc7\u6bd4\u8f83Xilinx Kintex UltraScale+ FPGA\u548c7nm ASIC\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u4e24\u79cd\u6280\u672f\u7684\u65f6\u5e8f\u5206\u6790\u548c\u6027\u80fd\u6743\u8861\u3002", "motivation": "\u7814\u7a76FPGA\u548cASIC\u5728\u65f6\u5e8f\u6536\u655b\u65b9\u9762\u7684\u6838\u5fc3\u6311\u6218\u548c\u7ea6\u675f\uff0c\u7406\u89e3\u4e24\u79cd\u6280\u672f\u67b6\u6784\u5dee\u5f02\u5bf9\u65f6\u5e8f\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u4e3a\u9ad8\u6027\u80fd\u8bbe\u8ba1\u63d0\u4f9b\u65f6\u5e8f\u5206\u6790\u6307\u5bfc\u3002", "method": "\u5206\u6790\u6838\u5fc3\u65f6\u5e8f\u539f\u7406\u3001\u67b6\u6784\u5dee\u5f02\u548c\u8bbe\u8ba1\u65b9\u6cd5\u5b66\uff0c\u901a\u8fc7XCKU040 FPGA\u4e0e7nm ASIC\u7684\u6848\u4f8b\u7814\u7a76\u8fdb\u884c\u5b9e\u9645\u65f6\u5e8f\u5206\u6790\u548c\u6027\u80fd\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aASIC\u5b9e\u73b0\u66f4\u4f18\u7684\u65f6\u5e8f\u6027\u80fd\uff08\u5efa\u7acb\u65f6\u95f445ps\uff0c\u4fdd\u6301\u65f6\u95f435ps\uff09\uff0c\u800c\u73b0\u4ee3FPGA\u4ecd\u5177\u6709\u7ade\u4e89\u529b\uff08\u5efa\u7acb\u65f6\u95f4180ps\uff0c\u4fdd\u6301\u65f6\u95f4120ps\uff09\uff0c\u9a8c\u8bc1\u4e86FPGA\u5728\u9ad8\u6027\u80fd\u8bbe\u8ba1\u4e2d\u7684\u9002\u7528\u6027\u3002", "conclusion": "ASIC\u5728\u65f6\u5e8f\u6027\u80fd\u65b9\u9762\u4f18\u4e8eFPGA\uff0c\u4f46\u73b0\u4ee3FPGA\u4ecd\u80fd\u6ee1\u8db3\u9ad8\u6027\u80fd\u8bbe\u8ba1\u8981\u6c42\uff0c\u4e3a\u8bbe\u8ba1\u9009\u62e9\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u4f9d\u636e\u3002"}}
{"id": "2510.27042", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.27042", "abs": "https://arxiv.org/abs/2510.27042", "authors": ["Michael Kleinman", "Matthew Trager", "Alessandro Achille", "Wei Xia", "Stefano Soatto"], "title": "e1: Learning Adaptive Control of Reasoning Effort", "comment": null, "summary": "Increasing the thinking budget of AI models can significantly improve\naccuracy, but not all questions warrant the same amount of reasoning. Users may\nprefer to allocate different amounts of reasoning effort depending on how they\nvalue output quality versus latency and cost. To leverage this tradeoff\neffectively, users need fine-grained control over the amount of thinking used\nfor a particular query, but few approaches enable such control. Existing\nmethods require users to specify the absolute number of desired tokens, but\nthis requires knowing the difficulty of the problem beforehand to appropriately\nset the token budget for a query. To address these issues, we propose Adaptive\nEffort Control, a self-adaptive reinforcement learning method that trains\nmodels to use a user-specified fraction of tokens relative to the current\naverage chain-of-thought length for each query. This approach eliminates\ndataset- and phase-specific tuning while producing better cost-accuracy\ntradeoff curves compared to standard methods. Users can dynamically adjust the\ncost-accuracy trade-off through a continuous effort parameter specified at\ninference time. We observe that the model automatically learns to allocate\nresources proportionally to the task difficulty and, across model scales\nranging from 1.5B to 32B parameters, our approach enables approximately 3x\nreduction in chain-of-thought length while maintaining or improving performance\nrelative to the base model used for RL training.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u52aa\u529b\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\u4f7f\u7528\u7528\u6237\u6307\u5b9a\u7684\u76f8\u5bf9\u601d\u7ef4\u9884\u7b97\u6bd4\u4f8b\uff0c\u5b9e\u73b0\u52a8\u6001\u6210\u672c-\u51c6\u786e\u6027\u6743\u8861\u63a7\u5236\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u601d\u7ef4\u94fe\u957f\u5ea6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u7528\u6237\u9884\u5148\u6307\u5b9a\u7edd\u5bf9token\u6570\u91cf\uff0c\u4f46\u7528\u6237\u96be\u4ee5\u4e8b\u5148\u77e5\u9053\u95ee\u9898\u96be\u5ea6\u6765\u5408\u7406\u8bbe\u7f6etoken\u9884\u7b97\u3002\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u7684\u63a7\u5236\u673a\u5236\u6765\u5e73\u8861\u8f93\u51fa\u8d28\u91cf\u4e0e\u5ef6\u8fdf\u6210\u672c\u3002", "method": "\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u52aa\u529b\u63a7\u5236\u65b9\u6cd5\uff0c\u8bad\u7ec3\u6a21\u578b\u4f7f\u7528\u76f8\u5bf9\u4e8e\u5f53\u524d\u5e73\u5747\u601d\u7ef4\u94fe\u957f\u5ea6\u7684\u7528\u6237\u6307\u5b9a\u6bd4\u4f8btoken\uff0c\u65e0\u9700\u6570\u636e\u96c6\u548c\u9636\u6bb5\u7279\u5b9a\u8c03\u4f18\u3002", "result": "\u57281.5B\u523032B\u53c2\u6570\u89c4\u6a21\u7684\u6a21\u578b\u4e0a\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u7ea63\u500d\u7684\u601d\u7ef4\u94fe\u957f\u5ea6\u51cf\u5c11\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u6539\u5584\u76f8\u5bf9\u4e8eRL\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "\u81ea\u9002\u5e94\u52aa\u529b\u63a7\u5236\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u601d\u7ef4\u9884\u7b97\u63a7\u5236\u7684\u96be\u9898\uff0c\u901a\u8fc7\u8fde\u7eed\u52aa\u529b\u53c2\u6570\u5b9e\u73b0\u52a8\u6001\u6210\u672c-\u51c6\u786e\u6027\u6743\u8861\uff0c\u6a21\u578b\u81ea\u52a8\u5b66\u4e60\u6309\u4efb\u52a1\u96be\u5ea6\u6bd4\u4f8b\u5206\u914d\u8d44\u6e90\u3002"}}
{"id": "2510.27317", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.27317", "abs": "https://arxiv.org/abs/2510.27317", "authors": ["Shuyi Chen", "Panagiotis Oikonomou", "Zhengchang Hua", "Nikos Tziritas", "Karim Djemame", "Nan Zhang", "Georgios Theodoropoulos"], "title": "Dynamic Service Scheduling and Resource Management in Energy-Harvesting Multi-access Edge Computing", "comment": "Accepted by the 21st IEEE International Conference on Green Computing\n  and Communications (GreenCom 2025)", "summary": "Multi-access Edge Computing (MEC) delivers low-latency services by hosting\napplications near end-users. To promote sustainability, these systems are\nincreasingly integrated with renewable Energy Harvesting (EH) technologies,\nenabling operation where grid electricity is unavailable. However, balancing\nthe intermittent nature of harvested energy with dynamic user demand presents a\nsignificant resource allocation challenge. This work proposes an online\nstrategy for an MEC system powered exclusively by EH to address this trade-off.\nOur strategy dynamically schedules computational tasks with dependencies and\ngoverns energy consumption through real-time decisions on server frequency\nscaling and service module migration. Experiments using real-world datasets\ndemonstrate our algorithm's effectiveness in efficiently utilizing harvested\nenergy while maintaining low service latency.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u7ebf\u7b56\u7565\uff0c\u7528\u4e8e\u5b8c\u5168\u7531\u80fd\u91cf\u6536\u96c6\u4f9b\u7535\u7684\u591a\u63a5\u5165\u8fb9\u7f18\u8ba1\u7b97\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u5ea6\u8ba1\u7b97\u4efb\u52a1\u548c\u7ba1\u7406\u80fd\u8017\u6765\u5e73\u8861\u95f4\u6b47\u6027\u80fd\u6e90\u4f9b\u5e94\u4e0e\u52a8\u6001\u7528\u6237\u9700\u6c42\u3002", "motivation": "\u591a\u63a5\u5165\u8fb9\u7f18\u8ba1\u7b97\u7cfb\u7edf\u4e0e\u53ef\u518d\u751f\u80fd\u6e90\u6536\u96c6\u6280\u672f\u7ed3\u5408\uff0c\u5728\u65e0\u7535\u7f51\u4f9b\u7535\u533a\u57df\u8fd0\u884c\uff0c\u4f46\u95f4\u6b47\u6027\u80fd\u6e90\u4f9b\u5e94\u4e0e\u52a8\u6001\u7528\u6237\u9700\u6c42\u4e4b\u95f4\u7684\u5e73\u8861\u662f\u4e00\u4e2a\u91cd\u8981\u6311\u6218\u3002", "method": "\u63d0\u51fa\u5728\u7ebf\u7b56\u7565\uff0c\u52a8\u6001\u8c03\u5ea6\u5177\u6709\u4f9d\u8d56\u5173\u7cfb\u7684\u8ba1\u7b97\u4efb\u52a1\uff0c\u901a\u8fc7\u5b9e\u65f6\u51b3\u7b56\u670d\u52a1\u5668\u9891\u7387\u8c03\u6574\u548c\u670d\u52a1\u6a21\u5757\u8fc1\u79fb\u6765\u7ba1\u7406\u80fd\u8017\u3002", "result": "\u4f7f\u7528\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u5728\u6709\u6548\u5229\u7528\u6536\u96c6\u80fd\u91cf\u7684\u540c\u65f6\u4fdd\u6301\u4f4e\u670d\u52a1\u5ef6\u8fdf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b56\u7565\u80fd\u591f\u6709\u6548\u89e3\u51b3\u80fd\u91cf\u6536\u96c6\u4f9b\u7535\u7684\u8fb9\u7f18\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u6311\u6218\u3002"}}
{"id": "2510.27070", "categories": ["cs.AR", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.27070", "abs": "https://arxiv.org/abs/2510.27070", "authors": ["Dong Tong"], "title": "Descriptor-Based Object-Aware Memory Systems: A Comprehensive Review", "comment": null, "summary": "The security and efficiency of modern computing systems are fundamentally\nundermined by the absence of a native architectural mechanism to propagate\nhigh-level program semantics, such as object identity, bounds, and lifetime,\nacross the hardware/software interface. This paper presents a comprehensive\nsurvey of the architectural paradigm designed to bridge this semantic gap:\ndescriptor-based, object-aware memory systems. By elevating the descriptor to a\nfirst-class architectural abstraction, this paradigm enables hardware to\ndynamically acquire and enforce the rich semantics of software-defined objects.\nThis survey systematically charts the evolution and current landscape of this\napproach. We establish the foundational concepts of memory objects and\ndescriptors and introduce a novel taxonomy of descriptor addressing modes,\nproviding a structured framework for analyzing and comparing diverse\nimplementations. Our unified analysis reveals how this paradigm holistically\naddresses the intertwined challenges of memory protection, management, and\nprocessing. As a culminating case study, we re-examine the CentroID model,\ndemonstrating how its hybrid tagged-pointer encoding and descriptor processing\nmechanisms embody the path toward practical and efficient object-aware designs.\nFinally, we outline how the explicit cross-layer communication of object\nsemantics provides a foundational research direction for next-generation cache\nhierarchies, unified virtual memory, and even 128-bit architectures.", "AI": {"tldr": "\u672c\u6587\u5bf9\u57fa\u4e8e\u63cf\u8ff0\u7b26\u7684\u5bf9\u8c61\u611f\u77e5\u5185\u5b58\u7cfb\u7edf\u8fdb\u884c\u4e86\u5168\u9762\u8c03\u67e5\uff0c\u8be5\u67b6\u6784\u8303\u5f0f\u65e8\u5728\u5f25\u5408\u786c\u4ef6/\u8f6f\u4ef6\u63a5\u53e3\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\uff0c\u901a\u8fc7\u5c06\u63cf\u8ff0\u7b26\u63d0\u5347\u4e3a\u4e00\u7ea7\u67b6\u6784\u62bd\u8c61\uff0c\u4f7f\u786c\u4ef6\u80fd\u591f\u52a8\u6001\u83b7\u53d6\u548c\u6267\u884c\u8f6f\u4ef6\u5b9a\u4e49\u5bf9\u8c61\u7684\u4e30\u5bcc\u8bed\u4e49\u3002", "motivation": "\u73b0\u4ee3\u8ba1\u7b97\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\u56e0\u7f3a\u4e4f\u539f\u751f\u67b6\u6784\u673a\u5236\u6765\u4f20\u64ad\u9ad8\u7ea7\u7a0b\u5e8f\u8bed\u4e49\uff08\u5982\u5bf9\u8c61\u8eab\u4efd\u3001\u8fb9\u754c\u548c\u751f\u547d\u5468\u671f\uff09\u800c\u53d7\u5230\u6839\u672c\u6027\u635f\u5bb3\u3002", "method": "\u5efa\u7acb\u4e86\u5185\u5b58\u5bf9\u8c61\u548c\u63cf\u8ff0\u7b26\u7684\u57fa\u7840\u6982\u5ff5\uff0c\u5f15\u5165\u4e86\u63cf\u8ff0\u7b26\u5bfb\u5740\u6a21\u5f0f\u7684\u65b0\u5206\u7c7b\u6cd5\uff0c\u63d0\u4f9b\u4e86\u5206\u6790\u548c\u6bd4\u8f83\u4e0d\u540c\u5b9e\u73b0\u7684\u7ed3\u6784\u5316\u6846\u67b6\u3002\u4ee5CentroID\u6a21\u578b\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u5176\u6df7\u5408\u6807\u8bb0\u6307\u9488\u7f16\u7801\u548c\u63cf\u8ff0\u7b26\u5904\u7406\u673a\u5236\u3002", "result": "\u7edf\u4e00\u5206\u6790\u63ed\u793a\u4e86\u8be5\u8303\u5f0f\u5982\u4f55\u5168\u9762\u89e3\u51b3\u5185\u5b58\u4fdd\u62a4\u3001\u7ba1\u7406\u548c\u5904\u7406\u76f8\u4e92\u4ea4\u7ec7\u7684\u6311\u6218\u3002", "conclusion": "\u660e\u786e\u7684\u5bf9\u8c61\u8bed\u4e49\u8de8\u5c42\u901a\u4fe1\u4e3a\u4e0b\u4e00\u4ee3\u7f13\u5b58\u5c42\u6b21\u7ed3\u6784\u3001\u7edf\u4e00\u865a\u62df\u5185\u5b58\u751a\u81f3128\u4f4d\u67b6\u6784\u63d0\u4f9b\u4e86\u57fa\u7840\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2510.27351", "categories": ["cs.DC", "65Y05, 65Y10, 90C59, 68T20"], "pdf": "https://arxiv.org/pdf/2510.27351", "abs": "https://arxiv.org/abs/2510.27351", "authors": ["Milena Veneva"], "title": "ML-Based Optimum Sub-system Size Heuristic for the GPU Implementation of the Tridiagonal Partition Method", "comment": "10 pages, 6 figures, 4 tables, DLCP conference 2025, Moscow, Russia", "summary": "This paper presents a machine learning (ML)-based heuristic for finding the\noptimum sub-system size for the CUDA implementation of the parallel partition\nalgorithm. Computational experiments for different system of linear algebraic\nequation (SLAE) sizes are conducted, and the optimum sub-system size for each\nof them is found empirically. To estimate a model for the sub-system size, we\nperform the k-nearest neighbors (kNN) classification method. Statistical\nanalysis of the results is done. By comparing the predicted values with the\nactual data, the algorithm is deemed to be acceptably good. Next, the heuristic\nis expanded to work for the recursive parallel partition algorithm as well. An\nalgorithm for determining the optimum sub-system size for each recursive step\nis formulated. A kNN model for predicting the optimum number of recursive steps\nfor a particular SLAE size is built.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u7528\u4e8e\u5bfb\u627e\u5e76\u884c\u5206\u533a\u7b97\u6cd5CUDA\u5b9e\u73b0\u4e2d\u7684\u6700\u4f18\u5b50\u7cfb\u7edf\u5927\u5c0f\u3002\u901a\u8fc7k\u8fd1\u90bb\u5206\u7c7b\u65b9\u6cd5\u5efa\u7acb\u9884\u6d4b\u6a21\u578b\uff0c\u5e76\u5c06\u8be5\u65b9\u6cd5\u6269\u5c55\u5230\u9012\u5f52\u5e76\u884c\u5206\u533a\u7b97\u6cd5\u4e2d\u3002", "motivation": "\u4e3a\u4e86\u5728CUDA\u5b9e\u73b0\u7684\u5e76\u884c\u5206\u533a\u7b97\u6cd5\u4e2d\u627e\u5230\u6700\u4f18\u7684\u5b50\u7cfb\u7edf\u5927\u5c0f\uff0c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u907f\u514d\u901a\u8fc7\u7ecf\u9a8c\u65b9\u6cd5\u786e\u5b9a\u53c2\u6570\u7684\u4f4e\u6548\u6027\u3002", "method": "\u5bf9\u4e0d\u540c\u89c4\u6a21\u7684\u7ebf\u6027\u4ee3\u6570\u65b9\u7a0b\u7ec4\u8fdb\u884c\u8ba1\u7b97\u5b9e\u9a8c\uff0c\u901a\u8fc7k\u8fd1\u90bb\u5206\u7c7b\u65b9\u6cd5\u5efa\u7acb\u5b50\u7cfb\u7edf\u5927\u5c0f\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u5e76\u5c06\u8be5\u65b9\u6cd5\u6269\u5c55\u5230\u9012\u5f52\u5e76\u884c\u5206\u533a\u7b97\u6cd5\u4e2d\uff0c\u6784\u5efa\u9012\u5f52\u6b65\u6570\u9884\u6d4b\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u6bd4\u8f83\u9884\u6d4b\u503c\u4e0e\u5b9e\u9645\u6570\u636e\uff0c\u7b97\u6cd5\u8868\u73b0\u826f\u597d\uff0c\u80fd\u591f\u6709\u6548\u9884\u6d4b\u6700\u4f18\u5b50\u7cfb\u7edf\u5927\u5c0f\u548c\u9012\u5f52\u6b65\u6570\u3002", "conclusion": "\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u9884\u6d4b\u5e76\u884c\u5206\u533a\u7b97\u6cd5\u7684\u6700\u4f18\u53c2\u6570\u914d\u7f6e\uff0c\u4e3aCUDA\u5b9e\u73b0\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u53c2\u6570\u9009\u62e9\u5de5\u5177\u3002"}}
{"id": "2510.27190", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.27190", "abs": "https://arxiv.org/abs/2510.27190", "authors": ["Dominik Schwarz"], "title": "Unvalidated Trust: Cross-Stage Vulnerabilities in Large Language Model Architectures", "comment": "178 pages, mechanism-centered taxonomy of 41 LLM risk patterns,\n  extensive appendix with experiment prompts and consolidation tables. Full\n  traces available to reviewers and affected providers", "summary": "As Large Language Models (LLMs) are increasingly integrated into automated,\nmulti-stage pipelines, risk patterns that arise from unvalidated trust between\nprocessing stages become a practical concern. This paper presents a\nmechanism-centered taxonomy of 41 recurring risk patterns in commercial LLMs.\nThe analysis shows that inputs are often interpreted non-neutrally and can\ntrigger implementation-shaped responses or unintended state changes even\nwithout explicit commands. We argue that these behaviors constitute\narchitectural failure modes and that string-level filtering alone is\ninsufficient. To mitigate such cross-stage vulnerabilities, we recommend\nzero-trust architectural principles, including provenance enforcement, context\nsealing, and plan revalidation, and we introduce \"Countermind\" as a conceptual\nblueprint for implementing these defenses.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b41\u79cd\u5546\u4e1a\u5927\u8bed\u8a00\u6a21\u578b\u91cd\u590d\u98ce\u9669\u6a21\u5f0f\u7684\u673a\u5236\u4e2d\u5fc3\u5206\u7c7b\u6cd5\uff0c\u63ed\u793a\u4e86\u8f93\u5165\u88ab\u975e\u4e2d\u7acb\u89e3\u91ca\u3001\u89e6\u53d1\u5b9e\u73b0\u5f62\u54cd\u5e94\u6216\u610f\u5916\u72b6\u6001\u53d8\u5316\u7b49\u95ee\u9898\uff0c\u5efa\u8bae\u91c7\u7528\u96f6\u4fe1\u4efb\u67b6\u6784\u539f\u5219\u6765\u7f13\u89e3\u8de8\u9636\u6bb5\u6f0f\u6d1e\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u96c6\u6210\u5230\u81ea\u52a8\u5316\u591a\u9636\u6bb5\u7ba1\u9053\u4e2d\uff0c\u5904\u7406\u9636\u6bb5\u95f4\u672a\u7ecf\u9a8c\u8bc1\u7684\u4fe1\u4efb\u6240\u4ea7\u751f\u7684\u98ce\u9669\u6a21\u5f0f\u6210\u4e3a\u5b9e\u9645\u95ee\u9898\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u8bc6\u522b\u548c\u89e3\u51b3\u8fd9\u4e9b\u67b6\u6784\u6027\u6545\u969c\u6a21\u5f0f\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u673a\u5236\u4e2d\u5fc3\u7684\u5206\u7c7b\u6cd5\u6765\u8bc6\u522b41\u79cd\u91cd\u590d\u98ce\u9669\u6a21\u5f0f\uff0c\u5206\u6790\u8f93\u5165\u7684\u975e\u4e2d\u7acb\u89e3\u91ca\u548c\u610f\u5916\u54cd\u5e94\u884c\u4e3a\uff0c\u5e76\u63d0\u51fa\u96f6\u4fe1\u4efb\u67b6\u6784\u539f\u5219\uff08\u5305\u62ec\u6765\u6e90\u9a8c\u8bc1\u3001\u4e0a\u4e0b\u6587\u5bc6\u5c01\u548c\u8ba1\u5212\u91cd\u65b0\u9a8c\u8bc1\uff09\u4f5c\u4e3a\u9632\u5fa1\u63aa\u65bd\u3002", "result": "\u5206\u6790\u8868\u660e\u8f93\u5165\u7ecf\u5e38\u88ab\u975e\u4e2d\u7acb\u89e3\u91ca\uff0c\u5373\u4f7f\u6ca1\u6709\u660e\u786e\u6307\u4ee4\u4e5f\u53ef\u80fd\u89e6\u53d1\u5b9e\u73b0\u5f62\u54cd\u5e94\u6216\u610f\u5916\u72b6\u6001\u53d8\u5316\uff0c\u5b57\u7b26\u4e32\u7ea7\u8fc7\u6ee4\u4e0d\u8db3\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u67b6\u6784\u6027\u6545\u969c\u6a21\u5f0f\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u67b6\u6784\u6027\u6545\u969c\u6a21\u5f0f\uff0c\u9700\u8981\u91c7\u7528\u96f6\u4fe1\u4efb\u67b6\u6784\u539f\u5219\uff08\u5982\u6765\u6e90\u9a8c\u8bc1\u3001\u4e0a\u4e0b\u6587\u5bc6\u5c01\u548c\u8ba1\u5212\u91cd\u65b0\u9a8c\u8bc1\uff09\u6765\u7f13\u89e3\u8de8\u9636\u6bb5\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86\"Countermind\"\u4f5c\u4e3a\u5b9e\u65bd\u8fd9\u4e9b\u9632\u5fa1\u7684\u6982\u5ff5\u84dd\u56fe\u3002"}}
{"id": "2510.27275", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.27275", "abs": "https://arxiv.org/abs/2510.27275", "authors": ["Kathrin Grosse", "Nico Ebert"], "title": "Prevalence of Security and Privacy Risk-Inducing Usage of AI-based Conversational Agents", "comment": "10 pages, 3 figures, 5 tables, under submission", "summary": "Recent improvement gains in large language models (LLMs) have lead to\neveryday usage of AI-based Conversational Agents (CAs). At the same time, LLMs\nare vulnerable to an array of threats, including jailbreaks and, for example,\ncausing remote code execution when fed specific inputs. As a result, users may\nunintentionally introduce risks, for example, by uploading malicious files or\ndisclosing sensitive information. However, the extent to which such user\nbehaviors occur and thus potentially facilitate exploits remains largely\nunclear. To shed light on this issue, we surveyed a representative sample of\n3,270 UK adults in 2024 using Prolific. A third of these use CA services such\nas ChatGPT or Gemini at least once a week. Of these ``regular users'', up to a\nthird exhibited behaviors that may enable attacks, and a fourth have tried\njailbreaking (often out of understandable reasons such as curiosity, fun or\ninformation seeking). Half state that they sanitize data and most participants\nreport not sharing sensitive data. However, few share very sensitive data such\nas passwords. The majority are unaware that their data can be used to train\nmodels and that they can opt-out. Our findings suggest that current academic\nthreat models manifest in the wild, and mitigations or guidelines for the\nsecure usage of CAs should be developed. In areas critical to security and\nprivacy, CAs must be equipped with effective AI guardrails to prevent, for\nexample, revealing sensitive information to curious employees. Vendors need to\nincrease efforts to prevent the entry of sensitive data, and to create\ntransparency with regard to data usage policies and settings.", "AI": {"tldr": "\u5bf93270\u540d\u82f1\u56fd\u6210\u5e74\u4eba\u7684\u8c03\u67e5\u663e\u793a\uff0c\u4e09\u5206\u4e4b\u4e00\u7684AI\u5bf9\u8bdd\u52a9\u624b\u5e38\u89c4\u7528\u6237\u5b58\u5728\u53ef\u80fd\u5f15\u53d1\u653b\u51fb\u7684\u884c\u4e3a\uff0c\u56db\u5206\u4e4b\u4e00\u5c1d\u8bd5\u8fc7\u8d8a\u72f1\uff0c\u5927\u591a\u6570\u7528\u6237\u4e0d\u4e86\u89e3\u6570\u636e\u4f7f\u7528\u653f\u7b56\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u666e\u53ca\uff0c\u7528\u6237\u53ef\u80fd\u65e0\u610f\u4e2d\u5f15\u5165\u5b89\u5168\u98ce\u9669\uff0c\u4f46\u6b64\u7c7b\u7528\u6237\u884c\u4e3a\u7684\u5b9e\u9645\u53d1\u751f\u7a0b\u5ea6\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "2024\u5e74\u901a\u8fc7Prolific\u5e73\u53f0\u5bf93270\u540d\u82f1\u56fd\u6210\u5e74\u4eba\u8fdb\u884c\u4ee3\u8868\u6027\u62bd\u6837\u8c03\u67e5\u3002", "result": "\u4e09\u5206\u4e4b\u4e00\u7684\u5e38\u89c4\u7528\u6237\u8868\u73b0\u51fa\u53ef\u80fd\u5f15\u53d1\u653b\u51fb\u7684\u884c\u4e3a\uff1b\u56db\u5206\u4e4b\u4e00\u5c1d\u8bd5\u8fc7\u8d8a\u72f1\uff1b\u534a\u6570\u7528\u6237\u8868\u793a\u4f1a\u6e05\u7406\u6570\u636e\uff1b\u5927\u591a\u6570\u7528\u6237\u4e0d\u4e86\u89e3\u6570\u636e\u53ef\u7528\u4e8e\u8bad\u7ec3\u6a21\u578b\u4e14\u53ef\u9000\u51fa\u3002", "conclusion": "\u5f53\u524d\u5b66\u672f\u5a01\u80c1\u6a21\u578b\u5728\u73b0\u5b9e\u4e2d\u5b58\u5728\uff0c\u9700\u8981\u5f00\u53d1\u5b89\u5168\u4f7f\u7528\u6307\u5357\uff0c\u4f9b\u5e94\u5546\u9700\u52a0\u5f3a\u654f\u611f\u6570\u636e\u9632\u62a4\u5e76\u63d0\u9ad8\u6570\u636e\u4f7f\u7528\u653f\u7b56\u7684\u900f\u660e\u5ea6\u3002"}}
{"id": "2510.27346", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.27346", "abs": "https://arxiv.org/abs/2510.27346", "authors": ["Wenjie Liu", "Panos Papadimitratos"], "title": "Coordinated Position Falsification Attacks and Countermeasures for Location-Based Services", "comment": null, "summary": "With the rise of location-based service (LBS) applications that rely on\nterrestrial and satellite infrastructures (e.g., GNSS and crowd-sourced Wi-Fi,\nBluetooth, cellular, and IP databases) for positioning, ensuring their\nintegrity and security is paramount. However, we demonstrate that these\napplications are susceptible to low-cost attacks (less than $50), including\nWi-Fi spoofing combined with GNSS jamming, as well as more sophisticated\ncoordinated location spoofing. These attacks manipulate position data to\ncontrol or undermine LBS functionality, leading to user scams or service\nmanipulation. Therefore, we propose a countermeasure to detect and thwart such\nattacks by utilizing readily available, redundant positioning information from\noff-the-shelf platforms. Our method extends the receiver autonomous integrity\nmonitoring (RAIM) framework by incorporating opportunistic information,\nincluding data from onboard sensors and terrestrial infrastructure signals,\nand, naturally, GNSS. We theoretically show that the fusion of heterogeneous\nsignals improves resilience against sophisticated adversaries on multiple\nfronts. Experimental evaluations show the effectiveness of the proposed scheme\nin improving detection accuracy by 62% at most compared to baseline schemes and\nrestoring accurate positioning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u68c0\u6d4b\u548c\u963b\u6b62\u4f4e\u6210\u672c\u4f4d\u7f6e\u6b3a\u9a97\u653b\u51fb\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u591a\u79cd\u5b9a\u4f4d\u4fe1\u53f7\uff08\u5305\u62ecGNSS\u3001\u4f20\u611f\u5668\u548c\u5730\u9762\u57fa\u7840\u8bbe\u65bd\u4fe1\u53f7\uff09\u6765\u589e\u5f3a\u4f4d\u7f6e\u670d\u52a1\u7684\u5b8c\u6574\u6027\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u4f4d\u7f6e\u670d\u52a1\uff08LBS\uff09\u5e94\u7528\u7684\u666e\u53ca\uff0c\u786e\u4fdd\u5176\u5b8c\u6574\u6027\u548c\u5b89\u5168\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7cfb\u7edf\u5bb9\u6613\u53d7\u5230\u4f4e\u6210\u672c\u653b\u51fb\uff08\u5982Wi-Fi\u6b3a\u9a97\u7ed3\u5408GNSS\u5e72\u6270\uff09\uff0c\u8fd9\u4e9b\u653b\u51fb\u4f1a\u64cd\u7eb5\u4f4d\u7f6e\u6570\u636e\uff0c\u5bfc\u81f4\u7528\u6237\u6b3a\u8bc8\u6216\u670d\u52a1\u64cd\u63a7\u3002", "method": "\u6269\u5c55\u4e86\u63a5\u6536\u673a\u81ea\u4e3b\u5b8c\u6574\u6027\u76d1\u6d4b\uff08RAIM\uff09\u6846\u67b6\uff0c\u6574\u5408\u4e86\u673a\u4f1a\u6027\u4fe1\u606f\uff0c\u5305\u62ec\u6765\u81ea\u673a\u8f7d\u4f20\u611f\u5668\u3001\u5730\u9762\u57fa\u7840\u8bbe\u65bd\u4fe1\u53f7\u4ee5\u53caGNSS\u7684\u6570\u636e\u3002\u901a\u8fc7\u878d\u5408\u5f02\u6784\u4fe1\u53f7\u6765\u63d0\u9ad8\u5bf9\u590d\u6742\u653b\u51fb\u7684\u62b5\u5fa1\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6848\u76f8\u6bd4\uff0c\u6240\u63d0\u65b9\u6848\u6700\u591a\u53ef\u5c06\u68c0\u6d4b\u51c6\u786e\u7387\u63d0\u9ad862%\uff0c\u5e76\u80fd\u6062\u590d\u51c6\u786e\u7684\u5b9a\u4f4d\u3002", "conclusion": "\u901a\u8fc7\u878d\u5408\u591a\u79cd\u5b9a\u4f4d\u4fe1\u53f7\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u548c\u963b\u6b62\u4f4d\u7f6e\u6b3a\u9a97\u653b\u51fb\uff0c\u663e\u8457\u63d0\u9ad8\u4f4d\u7f6e\u670d\u52a1\u7684\u5b8c\u6574\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2510.27485", "categories": ["cs.CR", "cs.OS", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.27485", "abs": "https://arxiv.org/abs/2510.27485", "authors": ["Ben Fiedler", "Samuel Gruetter", "Timothy Roscoe"], "title": "Sockeye: a language for analyzing hardware documentation", "comment": null, "summary": "Systems programmers have to consolidate the ever growing hardware mess\npresent on modern System-on-Chips (SoCs). Correctly programming a multitude of\ncomponents, providing functionality but also security, is a difficult problem:\nsemantics of individual units are described in English prose, descriptions are\noften underspecified, and prone to inaccuracies. Rigorous statements about\nplatform security are often impossible.\n  We introduce a domain-specific language to describe hardware semantics,\nassumptions about software behavior, and desired security properties. We then\ncreate machine-readable specifications for a diverse set of eight SoCs from\ntheir reference manuals, and formally prove their (in-)security. In addition to\nsecurity proofs about memory confidentiality and integrity, we discover a\nhandful of documentation errors. Finally, our analysis also revealed a\nvulnerability on a real-world server chip. Our tooling offers system\nintegrators a way of formally describing security properties for entire SoCs,\nand means to prove them or find counterexamples to them.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u6765\u63cf\u8ff0\u786c\u4ef6\u8bed\u4e49\u3001\u8f6f\u4ef6\u884c\u4e3a\u5047\u8bbe\u548c\u5b89\u5168\u5c5e\u6027\uff0c\u5bf98\u4e2aSoC\u521b\u5efa\u673a\u5668\u53ef\u8bfb\u89c4\u8303\u5e76\u5f62\u5f0f\u5316\u8bc1\u660e\u5176\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u6587\u6863\u9519\u8bef\u548c\u771f\u5b9e\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u4ee3SoC\u786c\u4ef6\u590d\u6742\u6027\u9ad8\uff0c\u7ec4\u4ef6\u8bed\u4e49\u63cf\u8ff0\u4e0d\u7cbe\u786e\u4e14\u6613\u51fa\u9519\uff0c\u96be\u4ee5\u5bf9\u5e73\u53f0\u5b89\u5168\u505a\u51fa\u4e25\u683c\u58f0\u660e\u3002", "method": "\u5f00\u53d1\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u63cf\u8ff0\u786c\u4ef6\u8bed\u4e49\u3001\u8f6f\u4ef6\u884c\u4e3a\u5047\u8bbe\u548c\u5b89\u5168\u5c5e\u6027\uff0c\u4e3a8\u4e2a\u4e0d\u540cSoC\u521b\u5efa\u673a\u5668\u53ef\u8bfb\u89c4\u8303\u5e76\u8fdb\u884c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002", "result": "\u6210\u529f\u8bc1\u660e\u5185\u5b58\u673a\u5bc6\u6027\u548c\u5b8c\u6574\u6027\u5b89\u5168\u5c5e\u6027\uff0c\u53d1\u73b0\u591a\u4e2a\u6587\u6863\u9519\u8bef\uff0c\u5e76\u5728\u771f\u5b9e\u670d\u52a1\u5668\u82af\u7247\u4e2d\u53d1\u73b0\u6f0f\u6d1e\u3002", "conclusion": "\u8be5\u5de5\u5177\u4e3a\u7cfb\u7edf\u96c6\u6210\u5546\u63d0\u4f9b\u5f62\u5f0f\u5316\u63cf\u8ff0SoC\u5b89\u5168\u5c5e\u6027\u5e76\u8bc1\u660e\u6216\u53d1\u73b0\u53cd\u4f8b\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.27343", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.27343", "abs": "https://arxiv.org/abs/2510.27343", "authors": ["Ali Norouzifar", "Wil van der Aalst"], "title": "Discriminative Rule Learning for Outcome-Guided Process Model Discovery", "comment": "The paper will be published as part of the CoopIS 2025 conference\n  proceedings", "summary": "Event logs extracted from information systems offer a rich foundation for\nunderstanding and improving business processes. In many real-world\napplications, it is possible to distinguish between desirable and undesirable\nprocess executions, where desirable traces reflect efficient or compliant\nbehavior, and undesirable ones may involve inefficiencies, rule violations,\ndelays, or resource waste. This distinction presents an opportunity to guide\nprocess discovery in a more outcome-aware manner. Discovering a single process\nmodel without considering outcomes can yield representations poorly suited for\nconformance checking and performance analysis, as they fail to capture critical\nbehavioral differences. Moreover, prioritizing one behavior over the other may\nobscure structural distinctions vital for understanding process outcomes. By\nlearning interpretable discriminative rules over control-flow features, we\ngroup traces with similar desirability profiles and apply process discovery\nseparately within each group. This results in focused and interpretable models\nthat reveal the drivers of both desirable and undesirable executions. The\napproach is implemented as a publicly available tool and it is evaluated on\nmultiple real-life event logs, demonstrating its effectiveness in isolating and\nvisualizing critical process patterns.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ed3\u679c\u611f\u77e5\u7684\u8fc7\u7a0b\u53d1\u73b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u533a\u5206\u7406\u60f3\u548c\u4e0d\u7406\u60f3\u7684\u8fc7\u7a0b\u6267\u884c\u8f68\u8ff9\uff0c\u5206\u522b\u5b66\u4e60\u53ef\u89e3\u91ca\u7684\u5224\u522b\u89c4\u5219\uff0c\u4ece\u800c\u751f\u6210\u66f4\u805a\u7126\u548c\u53ef\u89e3\u91ca\u7684\u8fc7\u7a0b\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u8fc7\u7a0b\u53d1\u73b0\u65b9\u6cd5\u4e0d\u8003\u8651\u6267\u884c\u7ed3\u679c\uff0c\u5bfc\u81f4\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u7406\u60f3\u548c\u4e0d\u7406\u60f3\u884c\u4e3a\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u5f02\uff0c\u4e0d\u9002\u5408\u4e00\u81f4\u6027\u68c0\u67e5\u548c\u6027\u80fd\u5206\u6790\u3002\u533a\u5206\u8fd9\u4e24\u79cd\u884c\u4e3a\u6709\u52a9\u4e8e\u7406\u89e3\u8fc7\u7a0b\u7ed3\u679c\u7684\u5173\u952e\u9a71\u52a8\u56e0\u7d20\u3002", "method": "\u901a\u8fc7\u5b66\u4e60\u63a7\u5236\u6d41\u7279\u5f81\u4e0a\u7684\u53ef\u89e3\u91ca\u5224\u522b\u89c4\u5219\uff0c\u5c06\u5177\u6709\u76f8\u4f3c\u7406\u60f3\u6027\u7279\u5f81\u7684\u8f68\u8ff9\u5206\u7ec4\uff0c\u7136\u540e\u5728\u6bcf\u4e2a\u7ec4\u5185\u5206\u522b\u5e94\u7528\u8fc7\u7a0b\u53d1\u73b0\u6280\u672f\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u771f\u5b9e\u4e8b\u4ef6\u65e5\u5fd7\u4e0a\u5f97\u5230\u9a8c\u8bc1\uff0c\u80fd\u591f\u6709\u6548\u5206\u79bb\u548c\u53ef\u89c6\u5316\u5173\u952e\u8fc7\u7a0b\u6a21\u5f0f\uff0c\u751f\u6210\u66f4\u805a\u7126\u548c\u53ef\u89e3\u91ca\u7684\u8fc7\u7a0b\u6a21\u578b\u3002", "conclusion": "\u7ed3\u679c\u611f\u77e5\u7684\u8fc7\u7a0b\u53d1\u73b0\u65b9\u6cd5\u80fd\u591f\u63ed\u793a\u7406\u60f3\u548c\u4e0d\u7406\u60f3\u6267\u884c\u7684\u5173\u952e\u9a71\u52a8\u56e0\u7d20\uff0c\u4e3a\u8fc7\u7a0b\u6539\u8fdb\u63d0\u4f9b\u66f4\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u5e76\u5df2\u5b9e\u73b0\u4e3a\u516c\u5f00\u53ef\u7528\u7684\u5de5\u5177\u3002"}}
{"id": "2510.27353", "categories": ["cs.AI", "I.2.8; F.2.2"], "pdf": "https://arxiv.org/pdf/2510.27353", "abs": "https://arxiv.org/abs/2510.27353", "authors": ["Julien Herrmann", "Guillaume Pallez"], "title": "An In-depth Study of LLM Contributions to the Bin Packing Problem", "comment": "15 pages, 13 figures", "summary": "Recent studies have suggested that Large Language Models (LLMs) could provide\ninteresting ideas contributing to mathematical discovery. This claim was\nmotivated by reports that LLM-based genetic algorithms produced heuristics\noffering new insights into the online bin packing problem under uniform and\nWeibull distributions. In this work, we reassess this claim through a detailed\nanalysis of the heuristics produced by LLMs, examining both their behavior and\ninterpretability. Despite being human-readable, these heuristics remain largely\nopaque even to domain experts. Building on this analysis, we propose a new\nclass of algorithms tailored to these specific bin packing instances. The\nderived algorithms are significantly simpler, more efficient, more\ninterpretable, and more generalizable, suggesting that the considered instances\nare themselves relatively simple. We then discuss the limitations of the claim\nregarding LLMs' contribution to this problem, which appears to rest on the\nmistaken assumption that the instances had previously been studied. Our\nfindings instead emphasize the need for rigorous validation and\ncontextualization when assessing the scientific value of LLM-generated outputs.", "AI": {"tldr": "\u5bf9LLM\u5728\u6570\u5b66\u53d1\u73b0\u4e2d\u8d21\u732e\u7684\u91cd\u65b0\u8bc4\u4f30\uff0c\u53d1\u73b0LLM\u751f\u6210\u7684\u88c5\u7bb1\u95ee\u9898\u542f\u53d1\u5f0f\u7b97\u6cd5\u867d\u7136\u53ef\u8bfb\u4f46\u96be\u4ee5\u89e3\u91ca\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u66f4\u7b80\u5355\u3001\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u65b0\u7b97\u6cd5\uff0c\u5e76\u6307\u51fa\u9700\u8981\u66f4\u4e25\u8c28\u5730\u8bc4\u4f30LLM\u751f\u6210\u5185\u5bb9\u7684\u79d1\u5b66\u4ef7\u503c\u3002", "motivation": "\u91cd\u65b0\u8bc4\u4f30LLM\u5728\u6570\u5b66\u53d1\u73b0\u4e2d\u7684\u8d21\u732e\uff0c\u7279\u522b\u662f\u9488\u5bf9\u88c5\u7bb1\u95ee\u9898\u4e2dLLM\u751f\u6210\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u8be6\u7ec6\u5206\u6790LLM\u751f\u6210\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u884c\u4e3a\uff0c\u63d0\u51fa\u9488\u5bf9\u7279\u5b9a\u88c5\u7bb1\u95ee\u9898\u5b9e\u4f8b\u7684\u65b0\u7b97\u6cd5\u7c7b\u522b\uff0c\u5e76\u8fdb\u884c\u6bd4\u8f83\u9a8c\u8bc1\u3002", "result": "\u63d0\u51fa\u7684\u65b0\u7b97\u6cd5\u6bd4LLM\u751f\u6210\u7684\u7b97\u6cd5\u66f4\u7b80\u5355\u3001\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u4e14\u66f4\u5177\u6cdb\u5316\u6027\uff0c\u8868\u660e\u539f\u95ee\u9898\u5b9e\u4f8b\u672c\u8eab\u76f8\u5bf9\u7b80\u5355\u3002", "conclusion": "LLM\u5728\u6570\u5b66\u53d1\u73b0\u4e2d\u7684\u8d21\u732e\u9700\u8981\u66f4\u4e25\u8c28\u7684\u9a8c\u8bc1\u548c\u60c5\u5883\u5316\u8bc4\u4f30\uff0c\u5f53\u524d\u58f0\u79f0\u53ef\u80fd\u57fa\u4e8e\u5bf9\u95ee\u9898\u5b9e\u4f8b\u7814\u7a76\u7a0b\u5ea6\u7684\u9519\u8bef\u5047\u8bbe\u3002"}}
{"id": "2510.27629", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.27629", "abs": "https://arxiv.org/abs/2510.27629", "authors": ["Boyi Wei", "Zora Che", "Nathaniel Li", "Udari Madhushani Sehwag", "Jasper G\u00f6tting", "Samira Nedungadi", "Julian Michael", "Summer Yue", "Dan Hendrycks", "Peter Henderson", "Zifan Wang", "Seth Donoughe", "Mantas Mazeika"], "title": "Best Practices for Biorisk Evaluations on Open-Weight Bio-Foundation Models", "comment": "17 Pages, 5 figures", "summary": "Open-weight bio-foundation models present a dual-use dilemma. While holding\ngreat promise for accelerating scientific research and drug development, they\ncould also enable bad actors to develop more deadly bioweapons. To mitigate the\nrisk posed by these models, current approaches focus on filtering biohazardous\ndata during pre-training. However, the effectiveness of such an approach\nremains unclear, particularly against determined actors who might fine-tune\nthese models for malicious use. To address this gap, we propose \\eval, a\nframework to evaluate the robustness of procedures that are intended to reduce\nthe dual-use capabilities of bio-foundation models. \\eval assesses models'\nvirus understanding through three lenses, including sequence modeling,\nmutational effects prediction, and virulence prediction. Our results show that\ncurrent filtering practices may not be particularly effective: Excluded\nknowledge can be rapidly recovered in some cases via fine-tuning, and exhibits\nbroader generalizability in sequence modeling. Furthermore, dual-use signals\nmay already reside in the pretrained representations, and can be elicited via\nsimple linear probing. These findings highlight the challenges of data\nfiltering as a standalone procedure, underscoring the need for further research\ninto robust safety and security strategies for open-weight bio-foundation\nmodels.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6846\u67b6\u6765\u6d4b\u8bd5\u751f\u7269\u57fa\u7840\u6a21\u578b\u7684\u53cc\u91cd\u7528\u9014\u98ce\u9669\u7f13\u89e3\u63aa\u65bd\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u5f53\u524d\u7684\u6570\u636e\u8fc7\u6ee4\u65b9\u6cd5\u53ef\u80fd\u4e0d\u591f\u6709\u6548\uff0c\u88ab\u6392\u9664\u7684\u77e5\u8bc6\u53ef\u4ee5\u901a\u8fc7\u5fae\u8c03\u5feb\u901f\u6062\u590d\uff0c\u4e14\u53cc\u91cd\u7528\u9014\u4fe1\u53f7\u53ef\u80fd\u5df2\u7ecf\u5b58\u5728\u4e8e\u9884\u8bad\u7ec3\u8868\u793a\u4e2d\u3002", "motivation": "\u5f00\u653e\u6743\u91cd\u7684\u751f\u7269\u57fa\u7840\u6a21\u578b\u5b58\u5728\u53cc\u91cd\u7528\u9014\u56f0\u5883\uff0c\u65e2\u53ef\u80fd\u52a0\u901f\u79d1\u5b66\u7814\u7a76\uff0c\u4e5f\u53ef\u80fd\u88ab\u6076\u610f\u884c\u4e3a\u8005\u7528\u4e8e\u5f00\u53d1\u751f\u7269\u6b66\u5668\u3002\u5f53\u524d\u57fa\u4e8e\u9884\u8bad\u7ec3\u6570\u636e\u8fc7\u6ee4\u7684\u98ce\u9669\u7f13\u89e3\u65b9\u6cd5\u6709\u6548\u6027\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u63d0\u51fa\u4e86\\eval\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u6a21\u578b\u5bf9\u75c5\u6bd2\u7684\u7406\u89e3\uff1a\u5e8f\u5217\u5efa\u6a21\u3001\u7a81\u53d8\u6548\u5e94\u9884\u6d4b\u548c\u6bd2\u529b\u9884\u6d4b\uff0c\u6d4b\u8bd5\u6570\u636e\u8fc7\u6ee4\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5f53\u524d\u8fc7\u6ee4\u5b9e\u8df5\u6548\u679c\u6709\u9650\uff1a\u88ab\u6392\u9664\u7684\u77e5\u8bc6\u53ef\u4ee5\u901a\u8fc7\u5fae\u8c03\u5feb\u901f\u6062\u590d\uff0c\u5728\u5e8f\u5217\u5efa\u6a21\u4e2d\u8868\u73b0\u51fa\u66f4\u5e7f\u6cdb\u7684\u6cdb\u5316\u80fd\u529b\uff1b\u53cc\u91cd\u7528\u9014\u4fe1\u53f7\u53ef\u80fd\u5df2\u5b58\u5728\u4e8e\u9884\u8bad\u7ec3\u8868\u793a\u4e2d\uff0c\u53ef\u901a\u8fc7\u7b80\u5355\u7684\u7ebf\u6027\u63a2\u6d4b\u63d0\u53d6\u3002", "conclusion": "\u6570\u636e\u8fc7\u6ee4\u4f5c\u4e3a\u72ec\u7acb\u7a0b\u5e8f\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5f00\u653e\u6743\u91cd\u751f\u7269\u57fa\u7840\u6a21\u578b\u7684\u9c81\u68d2\u5b89\u5168\u548c\u9632\u62a4\u7b56\u7565\u3002"}}
{"id": "2510.27383", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.27383", "abs": "https://arxiv.org/abs/2510.27383", "authors": ["Yueyang Wang", "Mehmet Dogar", "Gustav Markkula"], "title": "Realistic pedestrian-driver interaction modelling using multi-agent RL with human perceptual-motor constraints", "comment": null, "summary": "Modelling pedestrian-driver interactions is critical for understanding human\nroad user behaviour and developing safe autonomous vehicle systems. Existing\napproaches often rely on rule-based logic, game-theoretic models, or\n'black-box' machine learning methods. However, these models typically lack\nflexibility or overlook the underlying mechanisms, such as sensory and motor\nconstraints, which shape how pedestrians and drivers perceive and act in\ninteractive scenarios. In this study, we propose a multi-agent reinforcement\nlearning (RL) framework that integrates both visual and motor constraints of\npedestrian and driver agents. Using a real-world dataset from an unsignalised\npedestrian crossing, we evaluate four model variants, one without constraints,\ntwo with either motor or visual constraints, and one with both, across\nbehavioural metrics of interaction realism. Results show that the combined\nmodel with both visual and motor constraints performs best. Motor constraints\nlead to smoother movements that resemble human speed adjustments during\ncrossing interactions. The addition of visual constraints introduces perceptual\nuncertainty and field-of-view limitations, leading the agents to exhibit more\ncautious and variable behaviour, such as less abrupt deceleration. In this\ndata-limited setting, our model outperforms a supervised behavioural cloning\nmodel, demonstrating that our approach can be effective without large training\ndatasets. Finally, our framework accounts for individual differences by\nmodelling parameters controlling the human constraints as population-level\ndistributions, a perspective that has not been explored in previous work on\npedestrian-vehicle interaction modelling. Overall, our work demonstrates that\nmulti-agent RL with human constraints is a promising modelling approach for\nsimulating realistic road user interactions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u89c6\u89c9\u548c\u8fd0\u52a8\u7ea6\u675f\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u884c\u4eba-\u9a7e\u9a76\u5458\u4ea4\u4e92\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u65e0\u4fe1\u53f7\u4eba\u884c\u6a2a\u9053\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u7ea6\u675f\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u57fa\u4e8e\u89c4\u5219\u7684\u903b\u8f91\u3001\u535a\u5f08\u8bba\u6a21\u578b\u6216'\u9ed1\u76d2'\u673a\u5668\u5b66\u4e60\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\u4e14\u5ffd\u89c6\u4e86\u611f\u77e5\u548c\u8fd0\u52a8\u7ea6\u675f\u7b49\u5e95\u5c42\u673a\u5236\u5bf9\u884c\u4eba-\u9a7e\u9a76\u5458\u4ea4\u4e92\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u96c6\u6210\u884c\u4eba\u548c\u9a7e\u9a76\u5458\u667a\u80fd\u4f53\u7684\u89c6\u89c9\u4e0e\u8fd0\u52a8\u7ea6\u675f\uff0c\u8bc4\u4f30\u56db\u79cd\u6a21\u578b\u53d8\u4f53\uff1a\u65e0\u7ea6\u675f\u3001\u4ec5\u8fd0\u52a8\u7ea6\u675f\u3001\u4ec5\u89c6\u89c9\u7ea6\u675f\u3001\u4e24\u8005\u7686\u6709\u3002", "result": "\u540c\u65f6\u5305\u542b\u89c6\u89c9\u548c\u8fd0\u52a8\u7ea6\u675f\u7684\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002\u8fd0\u52a8\u7ea6\u675f\u4ea7\u751f\u66f4\u5e73\u6ed1\u7684\u8fd0\u52a8\uff0c\u7c7b\u4f3c\u4eba\u7c7b\u5728\u7a7f\u8d8a\u4ea4\u4e92\u4e2d\u7684\u901f\u5ea6\u8c03\u6574\uff1b\u89c6\u89c9\u7ea6\u675f\u5f15\u5165\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u89c6\u91ce\u9650\u5236\uff0c\u4f7f\u667a\u80fd\u4f53\u8868\u73b0\u51fa\u66f4\u8c28\u614e\u548c\u53ef\u53d8\u7684\u884c\u4e3a\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u4eba\u7c7b\u7ea6\u675f\u662f\u6a21\u62df\u771f\u5b9e\u9053\u8def\u7528\u6237\u4ea4\u4e92\u7684\u6709\u524d\u666f\u5efa\u6a21\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u5c0f\u6570\u636e\u96c6\u60c5\u51b5\u4e0b\u6709\u6548\u5de5\u4f5c\uff0c\u5e76\u901a\u8fc7\u5efa\u6a21\u7ea6\u675f\u53c2\u6570\u4e3a\u7fa4\u4f53\u7ea7\u5206\u5e03\u6765\u8003\u8651\u4e2a\u4f53\u5dee\u5f02\u3002"}}
{"id": "2510.27419", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.27419", "abs": "https://arxiv.org/abs/2510.27419", "authors": ["Tian Liang", "Wenxiang Jiao", "Zhiwei He", "Jiahao Xu", "Haitao Mi", "Dong Yu"], "title": "DeepCompress: A Dual Reward Strategy for Dynamically Exploring and Compressing Reasoning Chains", "comment": "Work in progress", "summary": "Large Reasoning Models (LRMs) have demonstrated impressive capabilities but\nsuffer from cognitive inefficiencies like ``overthinking'' simple problems and\n``underthinking'' complex ones. While existing methods that use supervised\nfine-tuning~(SFT) or reinforcement learning~(RL) with token-length rewards can\nimprove efficiency, they often do so at the cost of accuracy. This paper\nintroduces \\textbf{DeepCompress}, a novel framework that simultaneously\nenhances both the accuracy and efficiency of LRMs. We challenge the prevailing\napproach of consistently favoring shorter reasoning paths, showing that longer\nresponses can contain a broader range of correct solutions for difficult\nproblems. DeepCompress employs an adaptive length reward mechanism that\ndynamically classifies problems as ``Simple'' or ``Hard'' in real-time based on\nthe model's evolving capability. It encourages shorter, more efficient\nreasoning for ``Simple'' problems while promoting longer, more exploratory\nthought chains for ``Hard'' problems. This dual-reward strategy enables the\nmodel to autonomously adjust its Chain-of-Thought (CoT) length, compressing\nreasoning for well-mastered problems and extending it for those it finds\nchallenging. Experimental results on challenging mathematical benchmarks show\nthat DeepCompress consistently outperforms baseline methods, achieving superior\naccuracy while significantly improving token efficiency.", "AI": {"tldr": "DeepCompress\u662f\u4e00\u4e2a\u65b0\u9896\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u957f\u5ea6\u5956\u52b1\u673a\u5236\u540c\u65f6\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u9488\u5bf9\u7b80\u5355\u95ee\u9898\u9f13\u52b1\u77ed\u63a8\u7406\u8def\u5f84\uff0c\u5bf9\u56f0\u96be\u95ee\u9898\u4fc3\u8fdb\u957f\u63a8\u7406\u8def\u5f84\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5b58\u5728\u8ba4\u77e5\u6548\u7387\u95ee\u9898\uff1a\u5bf9\u7b80\u5355\u95ee\u9898\"\u8fc7\u5ea6\u601d\u8003\"\uff0c\u5bf9\u590d\u6742\u95ee\u9898\"\u601d\u8003\u4e0d\u8db3\"\u3002\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u76d1\u7763\u5fae\u8c03\u6216\u5e26\u4ee4\u724c\u957f\u5ea6\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u6765\u63d0\u9ad8\u6548\u7387\uff0c\u4f46\u5f80\u5f80\u4ee5\u727a\u7272\u51c6\u786e\u6027\u4e3a\u4ee3\u4ef7\u3002", "method": "DeepCompress\u91c7\u7528\u81ea\u9002\u5e94\u957f\u5ea6\u5956\u52b1\u673a\u5236\uff0c\u57fa\u4e8e\u6a21\u578b\u5b9e\u65f6\u6f14\u5316\u7684\u80fd\u529b\u52a8\u6001\u5c06\u95ee\u9898\u5206\u7c7b\u4e3a\"\u7b80\u5355\"\u6216\"\u56f0\u96be\"\u3002\u5bf9\u7b80\u5355\u95ee\u9898\u9f13\u52b1\u66f4\u77ed\u3001\u66f4\u9ad8\u6548\u7684\u63a8\u7406\uff0c\u5bf9\u56f0\u96be\u95ee\u9898\u4fc3\u8fdb\u66f4\u957f\u3001\u66f4\u5177\u63a2\u7d22\u6027\u7684\u601d\u7ef4\u94fe\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDeepCompress\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u663e\u8457\u63d0\u9ad8\u4ee4\u724c\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u51c6\u786e\u6027\u3002", "conclusion": "DeepCompress\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u63a8\u7406\u94fe\u957f\u5ea6\uff0c\u80fd\u591f\u540c\u65f6\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u8bc1\u660e\u4e86\u9488\u5bf9\u4e0d\u540c\u96be\u5ea6\u95ee\u9898\u91c7\u7528\u4e0d\u540c\u63a8\u7406\u7b56\u7565\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.27448", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.27448", "abs": "https://arxiv.org/abs/2510.27448", "authors": ["Yuhao Zhang", "Dingxin Hu", "Tinghao Yu", "Hao Liu", "Yiting Liu"], "title": "GeoFM: Enhancing Geometric Reasoning of MLLMs via Synthetic Data Generation through Formal Language", "comment": null, "summary": "Multi-modal Large Language Models (MLLMs) have gained significant attention\nin both academia and industry for their capabilities in handling multi-modal\ntasks. However, these models face challenges in mathematical geometric\nreasoning due to the scarcity of high-quality geometric data. To address this\nissue, synthetic geometric data has become an essential strategy. Current\nmethods for generating synthetic geometric data involve rephrasing or expanding\nexisting problems and utilizing predefined rules and templates to create\ngeometric images and problems. However, these approaches often produce data\nthat lacks diversity or is prone to noise. Additionally, the geometric images\nsynthesized by existing methods tend to exhibit limited variation and deviate\nsignificantly from authentic geometric diagrams. To overcome these limitations,\nwe propose GeoFM, a novel method for synthesizing geometric data. GeoFM uses\nformal languages to explore combinations of conditions within metric space,\ngenerating high-fidelity geometric problems that differ from the originals\nwhile ensuring correctness through a symbolic engine. Experimental results show\nthat our synthetic data significantly outperforms existing methods. The model\ntrained with our data surpass the proprietary GPT-4o model by 18.7\\% on\ngeometry problem-solving tasks in MathVista and by 16.5\\% on GeoQA.\nAdditionally, it exceeds the performance of a leading open-source model by\n5.7\\% on MathVista and by 2.7\\% on GeoQA.", "AI": {"tldr": "GeoFM\u662f\u4e00\u79cd\u65b0\u7684\u51e0\u4f55\u6570\u636e\u5408\u6210\u65b9\u6cd5\uff0c\u4f7f\u7528\u5f62\u5f0f\u8bed\u8a00\u5728\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u63a2\u7d22\u6761\u4ef6\u7ec4\u5408\uff0c\u901a\u8fc7\u7b26\u53f7\u5f15\u64ce\u786e\u4fdd\u6b63\u786e\u6027\uff0c\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u5728\u51e0\u4f55\u95ee\u9898\u89e3\u51b3\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u51e0\u4f55\u63a8\u7406\u65b9\u9762\u9762\u4e34\u9ad8\u8d28\u91cf\u51e0\u4f55\u6570\u636e\u7a00\u7f3a\u7684\u6311\u6218\uff0c\u73b0\u6709\u5408\u6210\u51e0\u4f55\u6570\u636e\u65b9\u6cd5\u751f\u6210\u7684\u6570\u636e\u7f3a\u4e4f\u591a\u6837\u6027\u3001\u566a\u58f0\u591a\uff0c\u4e14\u51e0\u4f55\u56fe\u50cf\u53d8\u5316\u6709\u9650\u3001\u4e0e\u771f\u5b9e\u51e0\u4f55\u56fe\u5dee\u5f02\u5927\u3002", "method": "\u63d0\u51faGeoFM\u65b9\u6cd5\uff0c\u4f7f\u7528\u5f62\u5f0f\u8bed\u8a00\u5728\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u63a2\u7d22\u6761\u4ef6\u7ec4\u5408\uff0c\u751f\u6210\u9ad8\u4fdd\u771f\u51e0\u4f55\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u7b26\u53f7\u5f15\u64ce\u786e\u4fdd\u6b63\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4f7f\u7528GeoFM\u5408\u6210\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u5728MathVista\u51e0\u4f55\u95ee\u9898\u89e3\u51b3\u4efb\u52a1\u4e0a\u6bd4GPT-4o\u9ad8\u51fa18.7%\uff0c\u5728GeoQA\u4e0a\u9ad8\u51fa16.5%\uff1b\u5728\u5f00\u6e90\u6a21\u578b\u4e0a\u5206\u522b\u9ad8\u51fa5.7%\u548c2.7%\u3002", "conclusion": "GeoFM\u65b9\u6cd5\u80fd\u6709\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u591a\u6837\u5316\u7684\u51e0\u4f55\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u51e0\u4f55\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002"}}
{"id": "2510.27568", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.27568", "abs": "https://arxiv.org/abs/2510.27568", "authors": ["Ali Asgarov", "Umid Suleymanov", "Aadyant Khatri"], "title": "SIGMA: Search-Augmented On-Demand Knowledge Integration for Agentic Mathematical Reasoning", "comment": "Short Paper - Under Review", "summary": "Solving mathematical reasoning problems requires not only accurate access to\nrelevant knowledge but also careful, multi-step thinking. However, current\nretrieval-augmented models often rely on a single perspective, follow\ninflexible search strategies, and struggle to effectively combine information\nfrom multiple sources. We introduce SIGMA (Search-Augmented On-Demand Knowledge\nIntegration for AGentic Mathematical reAsoning), a unified framework that\norchestrates specialized agents to independently reason, perform targeted\nsearches, and synthesize findings through a moderator mechanism. Each agent\ngenerates hypothetical passages to optimize retrieval for its analytic\nperspective, ensuring knowledge integration is both context-sensitive and\ncomputation-efficient. When evaluated on challenging benchmarks such as\nMATH500, AIME, and PhD-level science QA GPQA, SIGMA consistently outperforms\nboth open- and closed-source systems, achieving an absolute performance\nimprovement of 7.4%. Our results demonstrate that multi-agent, on-demand\nknowledge integration significantly enhances both reasoning accuracy and\nefficiency, offering a scalable approach for complex, knowledge-intensive\nproblem-solving. We will release the code upon publication.", "AI": {"tldr": "SIGMA\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u68c0\u7d22\u589e\u5f3a\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u8c03\u4e13\u95e8\u667a\u80fd\u4f53\u8fdb\u884c\u72ec\u7acb\u63a8\u7406\u3001\u5b9a\u5411\u641c\u7d22\u548c\u7ed3\u679c\u5408\u6210\uff0c\u663e\u8457\u63d0\u5347\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u68c0\u7d22\u589e\u5f3a\u6a21\u578b\u5b58\u5728\u5355\u89c6\u89d2\u4f9d\u8d56\u3001\u641c\u7d22\u7b56\u7565\u4e0d\u7075\u6d3b\u3001\u591a\u6e90\u4fe1\u606f\u6574\u5408\u56f0\u96be\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u590d\u6742\u7684\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u3002", "method": "\u5f15\u5165SIGMA\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u95e8\u667a\u80fd\u4f53\u72ec\u7acb\u63a8\u7406\u5e76\u751f\u6210\u5047\u8bbe\u6027\u6bb5\u843d\u4f18\u5316\u68c0\u7d22\uff0c\u4f7f\u7528\u534f\u8c03\u673a\u5236\u6574\u5408\u591a\u667a\u80fd\u4f53\u53d1\u73b0\uff0c\u5b9e\u73b0\u4e0a\u4e0b\u6587\u654f\u611f\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u77e5\u8bc6\u96c6\u6210\u3002", "result": "\u5728MATH500\u3001AIME\u548cGPQA\u7b49\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSIGMA\u6301\u7eed\u4f18\u4e8e\u5f00\u6e90\u548c\u95ed\u6e90\u7cfb\u7edf\uff0c\u7edd\u5bf9\u6027\u80fd\u63d0\u53477.4%\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u6309\u9700\u77e5\u8bc6\u96c6\u6210\u80fd\u663e\u8457\u63d0\u5347\u63a8\u7406\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u4e3a\u590d\u6742\u77e5\u8bc6\u5bc6\u96c6\u578b\u95ee\u9898\u89e3\u51b3\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.27623", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.27623", "abs": "https://arxiv.org/abs/2510.27623", "authors": ["Qiusi Zhan", "Hyeonjeong Ha", "Rui Yang", "Sirui Xu", "Hanyang Chen", "Liang-Yan Gui", "Yu-Xiong Wang", "Huan Zhang", "Heng Ji", "Daniel Kang"], "title": "Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning", "comment": null, "summary": "Multimodal large language models (MLLMs) have advanced embodied agents by\nenabling direct perception, reasoning, and planning task-oriented actions from\nvisual inputs. However, such vision driven embodied agents open a new attack\nsurface: visual backdoor attacks, where the agent behaves normally until a\nvisual trigger appears in the scene, then persistently executes an\nattacker-specified multi-step policy. We introduce BEAT, the first framework to\ninject such visual backdoors into MLLM-based embodied agents using objects in\nthe environments as triggers. Unlike textual triggers, object triggers exhibit\nwide variation across viewpoints and lighting, making them difficult to implant\nreliably. BEAT addresses this challenge by (1) constructing a training set that\nspans diverse scenes, tasks, and trigger placements to expose agents to trigger\nvariability, and (2) introducing a two-stage training scheme that first applies\nsupervised fine-tuning (SFT) and then our novel Contrastive Trigger Learning\n(CTL). CTL formulates trigger discrimination as preference learning between\ntrigger-present and trigger-free inputs, explicitly sharpening the decision\nboundaries to ensure precise backdoor activation. Across various embodied agent\nbenchmarks and MLLMs, BEAT achieves attack success rates up to 80%, while\nmaintaining strong benign task performance, and generalizes reliably to\nout-of-distribution trigger placements. Notably, compared to naive SFT, CTL\nboosts backdoor activation accuracy up to 39% under limited backdoor data.\nThese findings expose a critical yet unexplored security risk in MLLM-based\nembodied agents, underscoring the need for robust defenses before real-world\ndeployment.", "AI": {"tldr": "BEAT\u662f\u9996\u4e2a\u9488\u5bf9MLLM\u9a71\u52a8\u7684\u5177\u8eab\u667a\u80fd\u4f53\u7684\u89c6\u89c9\u540e\u95e8\u653b\u51fb\u6846\u67b6\uff0c\u4f7f\u7528\u73af\u5883\u4e2d\u7684\u7269\u4f53\u4f5c\u4e3a\u89e6\u53d1\u6761\u4ef6\uff0c\u80fd\u591f\u5728\u89e6\u53d1\u6761\u4ef6\u51fa\u73b0\u65f6\u6301\u7eed\u6267\u884c\u653b\u51fb\u8005\u6307\u5b9a\u7684\u591a\u6b65\u7b56\u7565\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b(MLLM)\u9a71\u52a8\u7684\u5177\u8eab\u667a\u80fd\u4f53\u867d\u7136\u5b9e\u73b0\u4e86\u4ece\u89c6\u89c9\u8f93\u5165\u76f4\u63a5\u611f\u77e5\u3001\u63a8\u7406\u548c\u89c4\u5212\u4efb\u52a1\u5bfc\u5411\u52a8\u4f5c\u7684\u80fd\u529b\uff0c\u4f46\u4e5f\u5f00\u542f\u4e86\u65b0\u7684\u653b\u51fb\u9762\uff1a\u89c6\u89c9\u540e\u95e8\u653b\u51fb\u3002\u5f53\u573a\u666f\u4e2d\u51fa\u73b0\u89c6\u89c9\u89e6\u53d1\u6761\u4ef6\u65f6\uff0c\u667a\u80fd\u4f53\u4f1a\u6301\u7eed\u6267\u884c\u653b\u51fb\u8005\u6307\u5b9a\u7684\u7b56\u7565\u3002", "method": "BEAT\u901a\u8fc7(1)\u6784\u5efa\u8de8\u8d8a\u591a\u6837\u5316\u573a\u666f\u3001\u4efb\u52a1\u548c\u89e6\u53d1\u6761\u4ef6\u653e\u7f6e\u7684\u8bad\u7ec3\u96c6\u6765\u66b4\u9732\u667a\u80fd\u4f53\u4e8e\u89e6\u53d1\u6761\u4ef6\u53d8\u5316\uff1b(2)\u5f15\u5165\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6848\uff1a\u9996\u5148\u5e94\u7528\u76d1\u7763\u5fae\u8c03(SFT)\uff0c\u7136\u540e\u4f7f\u7528\u65b0\u9896\u7684\u5bf9\u6bd4\u89e6\u53d1\u5b66\u4e60(CTL)\uff0c\u5c06\u89e6\u53d1\u6761\u4ef6\u5224\u522b\u5efa\u6a21\u4e3a\u89e6\u53d1\u6761\u4ef6\u5b58\u5728\u548c\u4e0d\u5b58\u5728\u8f93\u5165\u4e4b\u95f4\u7684\u504f\u597d\u5b66\u4e60\u3002", "result": "\u5728\u5404\u79cd\u5177\u8eab\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u548cMLLM\u4e0a\uff0cBEAT\u5b9e\u73b0\u4e86\u9ad8\u8fbe80%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u5927\u7684\u826f\u6027\u4efb\u52a1\u6027\u80fd\uff0c\u5e76\u80fd\u53ef\u9760\u5730\u6cdb\u5316\u5230\u5206\u5e03\u5916\u89e6\u53d1\u6761\u4ef6\u653e\u7f6e\u3002\u4e0e\u6734\u7d20SFT\u76f8\u6bd4\uff0cCTL\u5728\u6709\u9650\u540e\u95e8\u6570\u636e\u4e0b\u5c06\u540e\u95e8\u6fc0\u6d3b\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe39%\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u63ed\u793a\u4e86MLLM\u9a71\u52a8\u7684\u5177\u8eab\u667a\u80fd\u4f53\u4e2d\u4e00\u4e2a\u5173\u952e\u4f46\u672a\u88ab\u63a2\u7d22\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5f3a\u8c03\u4e86\u5728\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\u524d\u9700\u8981\u5f3a\u5927\u7684\u9632\u5fa1\u63aa\u65bd\u3002"}}
{"id": "2510.27628", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.27628", "abs": "https://arxiv.org/abs/2510.27628", "authors": ["Sebastian Benthall", "Andrew Clark"], "title": "Validity Is What You Need", "comment": null, "summary": "While AI agents have long been discussed and studied in computer science,\ntoday's Agentic AI systems are something new. We consider other definitions of\nAgentic AI and propose a new realist definition. Agentic AI is a software\ndelivery mechanism, comparable to software as a service (SaaS), which puts an\napplication to work autonomously in a complex enterprise setting. Recent\nadvances in large language models (LLMs) as foundation models have driven\nexcitement in Agentic AI. We note, however, that Agentic AI systems are\nprimarily applications, not foundations, and so their success depends on\nvalidation by end users and principal stakeholders. The tools and techniques\nneeded by the principal users to validate their applications are quite\ndifferent from the tools and techniques used to evaluate foundation models.\nIronically, with good validation measures in place, in many cases the\nfoundation models can be replaced with much simpler, faster, and more\ninterpretable models that handle core logic. When it comes to Agentic AI,\nvalidity is what you need. LLMs are one option that might achieve it.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Agentic AI\u7684\u65b0\u73b0\u5b9e\u4e3b\u4e49\u5b9a\u4e49\uff0c\u5c06\u5176\u89c6\u4e3a\u5728\u590d\u6742\u4f01\u4e1a\u73af\u5883\u4e2d\u81ea\u4e3b\u5de5\u4f5c\u7684\u8f6f\u4ef6\u4ea4\u4ed8\u673a\u5236\uff0c\u5f3a\u8c03\u5176\u6210\u529f\u4f9d\u8d56\u4e8e\u7ec8\u7aef\u7528\u6237\u548c\u4e3b\u8981\u5229\u76ca\u76f8\u5173\u8005\u7684\u9a8c\u8bc1\uff0c\u800c\u975e\u4ec5\u4ec5\u4f9d\u8d56\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0cAgentic AI\u7cfb\u7edf\u5f15\u8d77\u4e86\u5e7f\u6cdb\u5173\u6ce8\uff0c\u4f46\u73b0\u6709\u5b9a\u4e49\u4e0d\u591f\u51c6\u786e\u3002\u4f5c\u8005\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u66f4\u73b0\u5b9e\u7684\u5b9a\u4e49\uff0c\u5f3a\u8c03Agentic AI\u4e3b\u8981\u662f\u5e94\u7528\u7a0b\u5e8f\u800c\u975e\u57fa\u7840\u6a21\u578b\uff0c\u5176\u6210\u529f\u5173\u952e\u5728\u4e8e\u7528\u6237\u9a8c\u8bc1\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83Agentic AI\u4e0e\u8f6f\u4ef6\u5373\u670d\u52a1(SaaS)\u7684\u76f8\u4f3c\u6027\uff0c\u63d0\u51fa\u65b0\u7684\u73b0\u5b9e\u4e3b\u4e49\u5b9a\u4e49\uff0c\u5e76\u5206\u6790\u9a8c\u8bc1\u5de5\u5177\u4e0e\u57fa\u7840\u6a21\u578b\u8bc4\u4f30\u5de5\u5177\u7684\u533a\u522b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u5efa\u7acb\u826f\u597d\u9a8c\u8bc1\u673a\u5236\u7684\u60c5\u51b5\u4e0b\uff0c\u8bb8\u591aAgentic AI\u7cfb\u7edf\u53ef\u4ee5\u7528\u66f4\u7b80\u5355\u3001\u5feb\u901f\u548c\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u66ff\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u5904\u7406\u6838\u5fc3\u903b\u8f91\u3002", "conclusion": "Agentic AI\u7684\u6210\u529f\u5173\u952e\u5728\u4e8e\u6709\u6548\u6027\u9a8c\u8bc1\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ea\u662f\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u7684\u53ef\u80fd\u9009\u9879\u4e4b\u4e00\uff0c\u800c\u975e\u5fc5\u9700\u7ec4\u4ef6\u3002"}}
{"id": "2510.27630", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.27630", "abs": "https://arxiv.org/abs/2510.27630", "authors": ["Dayuan Fu", "Yunze Wu", "Xiaojie Cai", "Lyumanshan Ye", "Shijie Xia", "Zhen Huang", "Weiye Si", "Tianze Xu", "Jie Sun", "Keyu Li", "Mohan Jiang", "Junfei Wang", "Qishuo Hua", "Pengrui Lu", "Yang Xiao", "Pengfei Liu"], "title": "Interaction as Intelligence Part II: Asynchronous Human-Agent Rollout for Long-Horizon Task Training", "comment": null, "summary": "Large Language Model (LLM) agents have recently shown strong potential in\ndomains such as automated coding, deep research, and graphical user interface\nmanipulation. However, training them to succeed on long-horizon,\ndomain-specialized tasks remains challenging. Current methods primarily fall\ninto two categories. The first relies on dense human annotations through\nbehavior cloning, which is prohibitively expensive for long-horizon tasks that\ncan take days or months. The second depends on outcome-driven sampling, which\noften collapses due to the rarity of valid positive trajectories on\ndomain-specialized tasks. We introduce Apollo, a sampling framework that\nintegrates asynchronous human guidance with action-level data filtering.\nInstead of requiring annotators to shadow every step, Apollo allows them to\nintervene only when the agent drifts from a promising trajectory, by providing\nprior knowledge, strategic advice, etc. This lightweight design makes it\npossible to sustain interactions for over 30 hours and produces valuable\ntrajectories at a lower cost. Apollo then applies supervision control to filter\nout sub-optimal actions and prevent error propagation. Together, these\ncomponents enable reliable and effective data collection in long-horizon\nenvironments. To demonstrate the effectiveness of Apollo, we evaluate it using\nInnovatorBench. Our experiments show that when applied to train the GLM-4.5\nmodel on InnovatorBench, Apollo achieves more than a 50% improvement over the\nuntrained baseline and a 28% improvement over a variant trained without human\ninteraction. These results highlight the critical role of human-in-the-loop\nsampling and the robustness of Apollo's design in handling long-horizon,\ndomain-specialized tasks.", "AI": {"tldr": "Apollo\u662f\u4e00\u4e2a\u96c6\u6210\u5f02\u6b65\u4eba\u7c7b\u6307\u5bfc\u4e0e\u52a8\u4f5c\u7ea7\u6570\u636e\u8fc7\u6ee4\u7684\u91c7\u6837\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3LLM\u667a\u80fd\u4f53\u5904\u7406\u957f\u5468\u671f\u3001\u9886\u57df\u4e13\u4e1a\u5316\u4efb\u52a1\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u8bad\u7ec3LLM\u667a\u80fd\u4f53\u7684\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u57fa\u4e8e\u884c\u4e3a\u514b\u9686\u7684\u65b9\u6cd5\u9700\u8981\u5bc6\u96c6\u7684\u4eba\u5de5\u6807\u6ce8\uff0c\u6210\u672c\u8fc7\u9ad8\uff1b\u57fa\u4e8e\u7ed3\u679c\u9a71\u52a8\u7684\u91c7\u6837\u65b9\u6cd5\u5728\u9886\u57df\u4e13\u4e1a\u5316\u4efb\u52a1\u4e2d\u5bb9\u6613\u5931\u8d25\uff0c\u56e0\u4e3a\u6709\u6548\u6b63\u8f68\u8ff9\u7a00\u5c11\u3002", "method": "Apollo\u6846\u67b6\u7ed3\u5408\u5f02\u6b65\u4eba\u7c7b\u6307\u5bfc\u548c\u52a8\u4f5c\u7ea7\u6570\u636e\u8fc7\u6ee4\uff0c\u5141\u8bb8\u4eba\u7c7b\u53ea\u5728\u667a\u80fd\u4f53\u504f\u79bb\u6b63\u786e\u8f68\u8ff9\u65f6\u8fdb\u884c\u5e72\u9884\uff0c\u63d0\u4f9b\u5148\u9a8c\u77e5\u8bc6\u548c\u7b56\u7565\u5efa\u8bae\uff0c\u7136\u540e\u901a\u8fc7\u76d1\u7763\u63a7\u5236\u8fc7\u6ee4\u6b21\u4f18\u52a8\u4f5c\u9632\u6b62\u9519\u8bef\u4f20\u64ad\u3002", "result": "\u5728InnovatorBench\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528Apollo\u8bad\u7ec3\u7684GLM-4.5\u6a21\u578b\u76f8\u6bd4\u672a\u8bad\u7ec3\u57fa\u7ebf\u63d0\u5347\u4e8650%\u4ee5\u4e0a\uff0c\u76f8\u6bd4\u65e0\u4eba\u4ea4\u4e92\u8bad\u7ec3\u53d8\u4f53\u63d0\u5347\u4e8628%\u3002", "conclusion": "Apollo\u8bc1\u660e\u4e86\u4eba\u7c7b\u5728\u73af\u91c7\u6837\u5728\u957f\u5468\u671f\u3001\u9886\u57df\u4e13\u4e1a\u5316\u4efb\u52a1\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5176\u8bbe\u8ba1\u5728\u5904\u7406\u8fd9\u7c7b\u4efb\u52a1\u65f6\u5177\u6709\u9c81\u68d2\u6027\u3002"}}

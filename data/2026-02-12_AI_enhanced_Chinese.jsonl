{"id": "2602.10367", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10367", "abs": "https://arxiv.org/abs/2602.10367", "authors": ["Zhiling Yan", "Dingjie Song", "Zhe Fang", "Yisheng Ji", "Xiang Li", "Quanzheng Li", "Lichao Sun"], "title": "LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation", "comment": null, "summary": "The deployment of Large Language Models (LLMs) in high-stakes clinical settings demands rigorous and reliable evaluation. However, existing medical benchmarks remain static, suffering from two critical limitations: (1) data contamination, where test sets inadvertently leak into training corpora, leading to inflated performance estimates; and (2) temporal misalignment, failing to capture the rapid evolution of medical knowledge. Furthermore, current evaluation metrics for open-ended clinical reasoning often rely on either shallow lexical overlap (e.g., ROUGE) or subjective LLM-as-a-Judge scoring, both inadequate for verifying clinical correctness. To bridge these gaps, we introduce LiveMedBench, a continuously updated, contamination-free, and rubric-based benchmark that weekly harvests real-world clinical cases from online medical communities, ensuring strict temporal separation from model training data. We propose a Multi-Agent Clinical Curation Framework that filters raw data noise and validates clinical integrity against evidence-based medical principles. For evaluation, we develop an Automated Rubric-based Evaluation Framework that decomposes physician responses into granular, case-specific criteria, achieving substantially stronger alignment with expert physicians than LLM-as-a-Judge. To date, LiveMedBench comprises 2,756 real-world cases spanning 38 medical specialties and multiple languages, paired with 16,702 unique evaluation criteria. Extensive evaluation of 38 LLMs reveals that even the best-performing model achieves only 39.2%, and 84% of models exhibit performance degradation on post-cutoff cases, confirming pervasive data contamination risks. Error analysis further identifies contextual application-not factual knowledge-as the dominant bottleneck, with 35-48% of failures stemming from the inability to tailor medical knowledge to patient-specific constraints.", "AI": {"tldr": "LiveMedBench\u662f\u4e00\u4e2a\u6301\u7eed\u66f4\u65b0\u7684\u3001\u65e0\u6570\u636e\u6c61\u67d3\u7684\u3001\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u6bcf\u5468\u4ece\u5728\u7ebf\u533b\u7597\u793e\u533a\u6536\u96c6\u771f\u5b9e\u4e34\u5e8a\u6848\u4f8b\uff0c\u89e3\u51b3\u73b0\u6709\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u7684\u6570\u636e\u6c61\u67d3\u548c\u65f6\u95f4\u9519\u4f4d\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u81ea\u52a8\u5316\u7684\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a1) \u6570\u636e\u6c61\u67d3\u95ee\u9898\uff0c\u6d4b\u8bd5\u96c6\u65e0\u610f\u4e2d\u6cc4\u9732\u5230\u8bad\u7ec3\u8bed\u6599\u4e2d\uff0c\u5bfc\u81f4\u6027\u80fd\u4f30\u8ba1\u865a\u9ad8\uff1b2) \u65f6\u95f4\u9519\u4f4d\u95ee\u9898\uff0c\u65e0\u6cd5\u6355\u6349\u533b\u5b66\u77e5\u8bc6\u7684\u5feb\u901f\u6f14\u53d8\u3002\u6b64\u5916\uff0c\u5f53\u524d\u5f00\u653e\u5f0f\u4e34\u5e8a\u63a8\u7406\u7684\u8bc4\u4f30\u6307\u6807\u8981\u4e48\u4f9d\u8d56\u6d45\u5c42\u8bcd\u6c47\u91cd\u53e0\uff0c\u8981\u4e48\u4f9d\u8d56\u4e3b\u89c2\u7684LLM-as-a-Judge\u8bc4\u5206\uff0c\u90fd\u4e0d\u8db3\u4ee5\u9a8c\u8bc1\u4e34\u5e8a\u6b63\u786e\u6027\u3002", "method": "1) \u5f15\u5165LiveMedBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bcf\u5468\u4ece\u5728\u7ebf\u533b\u7597\u793e\u533a\u6536\u96c6\u771f\u5b9e\u4e34\u5e8a\u6848\u4f8b\uff0c\u786e\u4fdd\u4e0e\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u7684\u4e25\u683c\u65f6\u95f4\u5206\u79bb\uff1b2) \u63d0\u51fa\u591a\u667a\u80fd\u4f53\u4e34\u5e8a\u7b5b\u9009\u6846\u67b6\uff0c\u8fc7\u6ee4\u539f\u59cb\u6570\u636e\u566a\u58f0\u5e76\u6839\u636e\u5faa\u8bc1\u533b\u5b66\u539f\u5219\u9a8c\u8bc1\u4e34\u5e8a\u5b8c\u6574\u6027\uff1b3) \u5f00\u53d1\u81ea\u52a8\u5316\u7684\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u533b\u751f\u56de\u7b54\u5206\u89e3\u4e3a\u7ec6\u7c92\u5ea6\u7684\u3001\u75c5\u4f8b\u7279\u5b9a\u7684\u6807\u51c6\u3002", "result": "LiveMedBench\u76ee\u524d\u5305\u542b2,756\u4e2a\u771f\u5b9e\u4e16\u754c\u75c5\u4f8b\uff0c\u6db5\u76d638\u4e2a\u533b\u5b66\u4e13\u4e1a\u548c\u591a\u79cd\u8bed\u8a00\uff0c\u914d\u670916,702\u4e2a\u72ec\u7279\u7684\u8bc4\u4f30\u6807\u51c6\u3002\u5bf938\u4e2aLLM\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0c\u5373\u4f7f\u8868\u73b0\u6700\u597d\u7684\u6a21\u578b\u4e5f\u53ea\u8fbe\u523039.2%\u7684\u51c6\u786e\u7387\uff0c84%\u7684\u6a21\u578b\u5728\u622a\u6b62\u65e5\u671f\u540e\u7684\u75c5\u4f8b\u4e0a\u8868\u73b0\u51fa\u6027\u80fd\u4e0b\u964d\uff0c\u8bc1\u5b9e\u4e86\u666e\u904d\u5b58\u5728\u7684\u6570\u636e\u6c61\u67d3\u98ce\u9669\u3002\u9519\u8bef\u5206\u6790\u8fdb\u4e00\u6b65\u8bc6\u522b\u51fa\u4e0a\u4e0b\u6587\u5e94\u7528\uff08\u800c\u975e\u4e8b\u5b9e\u77e5\u8bc6\uff09\u662f\u4e3b\u8981\u74f6\u9888\uff0c35-48%\u7684\u5931\u8d25\u6e90\u4e8e\u65e0\u6cd5\u5c06\u533b\u5b66\u77e5\u8bc6\u9002\u5e94\u4e8e\u60a3\u8005\u7279\u5b9a\u7684\u7ea6\u675f\u3002", "conclusion": "LiveMedBench\u4e3a\u4e34\u5e8aLLM\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u4e2a\u52a8\u6001\u3001\u65e0\u6c61\u67d3\u3001\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728\u4e34\u5e8a\u63a8\u7406\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5c06\u533b\u5b66\u77e5\u8bc6\u9002\u5e94\u4e8e\u5177\u4f53\u60a3\u8005\u60c5\u5883\u7684\u80fd\u529b\u4e0d\u8db3\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u66f4\u7a33\u5065\u7684\u4e34\u5e8aAI\u7cfb\u7edf\u9700\u8981\u5173\u6ce8\u4e0a\u4e0b\u6587\u5e94\u7528\u80fd\u529b\u800c\u975e\u4ec5\u4ec5\u4e8b\u5b9e\u77e5\u8bc6\u3002"}}
{"id": "2602.10458", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10458", "abs": "https://arxiv.org/abs/2602.10458", "authors": ["Yansong Qu", "Zihao Sheng", "Zilin Huang", "Jiancong Chen", "Yuhao Luo", "Tianyi Wang", "Yiheng Feng", "Samuel Labi", "Sikai Chen"], "title": "Found-RL: foundation model-enhanced reinforcement learning for autonomous driving", "comment": "39 pages", "summary": "Reinforcement Learning (RL) has emerged as a dominant paradigm for end-to-end autonomous driving (AD). However, RL suffers from sample inefficiency and a lack of semantic interpretability in complex scenarios. Foundation Models, particularly Vision-Language Models (VLMs), can mitigate this by offering rich, context-aware knowledge, yet their high inference latency hinders deployment in high-frequency RL training loops. To bridge this gap, we present Found-RL, a platform tailored to efficiently enhance RL for AD using foundation models. A core innovation is the asynchronous batch inference framework, which decouples heavy VLM reasoning from the simulation loop, effectively resolving latency bottlenecks to support real-time learning. We introduce diverse supervision mechanisms: Value-Margin Regularization (VMR) and Advantage-Weighted Action Guidance (AWAG) to effectively distill expert-like VLM action suggestions into the RL policy. Additionally, we adopt high-throughput CLIP for dense reward shaping. We address CLIP's dynamic blindness via Conditional Contrastive Action Alignment, which conditions prompts on discretized speed/command and yields a normalized, margin-based bonus from context-specific action-anchor scoring. Found-RL provides an end-to-end pipeline for fine-tuned VLM integration and shows that a lightweight RL model can achieve near-VLM performance compared with billion-parameter VLMs while sustaining real-time inference (approx. 500 FPS). Code, data, and models will be publicly available at https://github.com/ys-qu/found-rl.", "AI": {"tldr": "Found-RL\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3a\u81ea\u52a8\u9a7e\u9a76\u8bbe\u8ba1\u7684\u5f3a\u5316\u5b66\u4e60\u5e73\u53f0\uff0c\u901a\u8fc7\u5f02\u6b65\u6279\u91cf\u63a8\u7406\u6846\u67b6\u5c06\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u9ad8\u6548\u96c6\u6210\u5230RL\u8bad\u7ec3\u4e2d\uff0c\u89e3\u51b3\u4e86VLM\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\uff0c\u4f7f\u8f7b\u91cf\u7ea7RL\u6a21\u578b\u80fd\u8fbe\u5230\u63a5\u8fd1VLM\u7684\u6027\u80fd\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u5b58\u5728\u6837\u672c\u6548\u7387\u4f4e\u548c\u8bed\u4e49\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u800c\u57fa\u7840\u6a21\u578b\uff08\u7279\u522b\u662f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff09\u867d\u7136\u80fd\u63d0\u4f9b\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u77e5\u8bc6\uff0c\u4f46\u5176\u9ad8\u63a8\u7406\u5ef6\u8fdf\u963b\u788d\u4e86\u5728\u9ad8\u9891RL\u8bad\u7ec3\u5faa\u73af\u4e2d\u7684\u90e8\u7f72\u3002", "method": "1. \u5f02\u6b65\u6279\u91cf\u63a8\u7406\u6846\u67b6\uff1a\u5c06\u7e41\u91cd\u7684VLM\u63a8\u7406\u4e0e\u4eff\u771f\u5faa\u73af\u89e3\u8026\uff0c\u89e3\u51b3\u5ef6\u8fdf\u74f6\u9888\uff1b2. \u591a\u6837\u5316\u76d1\u7763\u673a\u5236\uff1a\u5305\u62ec\u4ef7\u503c\u8fb9\u9645\u6b63\u5219\u5316\u548c\u4f18\u52bf\u52a0\u6743\u52a8\u4f5c\u6307\u5bfc\uff0c\u5c06VLM\u4e13\u5bb6\u52a8\u4f5c\u5efa\u8bae\u84b8\u998f\u5230RL\u7b56\u7565\u4e2d\uff1b3. \u9ad8\u541e\u5410\u91cfCLIP\u7528\u4e8e\u5bc6\u96c6\u5956\u52b1\u5851\u9020\uff1b4. \u6761\u4ef6\u5bf9\u6bd4\u52a8\u4f5c\u5bf9\u9f50\uff1a\u901a\u8fc7\u57fa\u4e8e\u79bb\u6563\u5316\u901f\u5ea6/\u547d\u4ee4\u7684\u6761\u4ef6\u63d0\u793a\u89e3\u51b3CLIP\u7684\u52a8\u6001\u76f2\u70b9\u95ee\u9898\u3002", "result": "Found-RL\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u5fae\u8c03VLM\u96c6\u6210\u7ba1\u9053\uff0c\u8f7b\u91cf\u7ea7RL\u6a21\u578b\u80fd\u591f\u8fbe\u5230\u63a5\u8fd1\u5341\u4ebf\u53c2\u6570VLM\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u65f6\u63a8\u7406\uff08\u7ea6500 FPS\uff09\u3002", "conclusion": "Found-RL\u6210\u529f\u5730\u5c06\u57fa\u7840\u6a21\u578b\u7684\u9ad8\u8d28\u91cf\u77e5\u8bc6\u4e0e\u5f3a\u5316\u5b66\u4e60\u7684\u9ad8\u6548\u8bad\u7ec3\u76f8\u7ed3\u5408\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e2\u5177\u6709\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u53c8\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.10467", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10467", "abs": "https://arxiv.org/abs/2602.10467", "authors": ["Jihwan Oh", "Murad Aghazada", "Yooju Shin", "Se-Young Yun", "Taehyeon Kim"], "title": "MERIT Feedback Elicits Better Bargaining in LLM Negotiators", "comment": "Preprint. arXiv admin note: substantial text overlap with arXiv:2505.22998", "summary": "Bargaining is often regarded as a logical arena rather than an art or a matter of intuition, yet Large Language Models (LLMs) still struggle to navigate it due to limited strategic depth and difficulty adapting to complex human factors. Current benchmarks rarely capture this limitation. To bridge this gap, we present an utility feedback centric framework. Our contributions are: (i) AgoraBench, a new benchmark spanning nine challenging settings (e.g., deception, monopoly) that supports diverse strategy modeling; (ii) human-aligned, economically grounded metrics derived from utility theory. This is operationalized via agent utility, negotiation power, and acquisition ratio that implicitly measure how well the negotiation aligns with human preference and (iii) a human preference grounded dataset with learning pipeline that strengthens LLMs' bargaining ability through both prompting and finetuning. Empirical results indicate that baseline LLM strategies often diverge from human preferences, while our mechanism substantially improves negotiation performance, yielding deeper strategic behavior and stronger opponent awareness.", "AI": {"tldr": "\u63d0\u51fa\u4e86AgoraBench\u57fa\u51c6\u6d4b\u8bd5\u548c\u57fa\u4e8e\u6548\u7528\u53cd\u9988\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u7684\u6307\u6807\u548c\u6570\u636e\u96c6\u589e\u5f3aLLM\u7684\u8c08\u5224\u80fd\u529b", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8c08\u5224\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u7f3a\u4e4f\u6218\u7565\u6df1\u5ea6\u548c\u9002\u5e94\u590d\u6742\u4eba\u7c7b\u56e0\u7d20\u7684\u80fd\u529b\uff0c\u800c\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u5145\u5206\u6355\u6349\u8fd9\u4e9b\u5c40\u9650\u6027", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u6548\u7528\u53cd\u9988\u7684\u6846\u67b6\uff0c\u5305\u62ec\uff1a1\uff09AgoraBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d69\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u573a\u666f\uff1b2\uff09\u57fa\u4e8e\u6548\u7528\u7406\u8bba\u7684\u4eba\u7c7b\u5bf9\u9f50\u7ecf\u6d4e\u6307\u6807\uff1b3\uff09\u57fa\u4e8e\u4eba\u7c7b\u504f\u597d\u7684\u6570\u636e\u96c6\u548c\u5b66\u4e60\u6d41\u7a0b", "result": "\u57fa\u7ebfLLM\u7b56\u7565\u5e38\u504f\u79bb\u4eba\u7c7b\u504f\u597d\uff0c\u800c\u63d0\u51fa\u7684\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u8c08\u5224\u6027\u80fd\uff0c\u4ea7\u751f\u4e86\u66f4\u6df1\u5c42\u7684\u6218\u7565\u884c\u4e3a\u548c\u66f4\u5f3a\u7684\u5bf9\u624b\u610f\u8bc6", "conclusion": "\u901a\u8fc7\u6548\u7528\u53cd\u9988\u6846\u67b6\u3001\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\u548c\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u589e\u5f3aLLM\u7684\u8c08\u5224\u80fd\u529b\uff0c\u4f7f\u5176\u66f4\u63a5\u8fd1\u4eba\u7c7b\u8c08\u5224\u884c\u4e3a"}}
{"id": "2602.10218", "categories": ["cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10218", "abs": "https://arxiv.org/abs/2602.10218", "authors": ["Chenhui Deng", "Zhongzhi Yu", "Guan-Ting Liu", "Nathaniel Pinckney", "Haoxing Ren"], "title": "ACE-RTL: When Agentic Context Evolution Meets RTL-Specialized LLMs", "comment": null, "summary": "Recent advances in large language models (LLMs) have sparked growing interest in applying them to hardware design automation, particularly for accurate RTL code generation. Prior efforts follow two largely independent paths: (i) training domain-adapted RTL models to internalize hardware semantics, (ii) developing agentic systems that leverage frontier generic LLMs guided by simulation feedback. However, these two paths exhibit complementary strengths and weaknesses. In this work, we present ACE-RTL that unifies both directions through Agentic Context Evolution (ACE). ACE-RTL integrates an RTL-specialized LLM, trained on a large-scale dataset of 1.7 million RTL samples, with a frontier reasoning LLM through three synergistic components: the generator, reflector, and coordinator. These components iteratively refine RTL code toward functional correctness. We further introduce a parallel scaling strategy that significantly reduces the number of iterations required to reach correct solutions. On the Comprehensive Verilog Design Problems (CVDP) benchmark, ACE-RTL achieves up to a 44.87% pass rate improvement over 14 competitive baselines while requiring only four iterations on average.", "AI": {"tldr": "ACE-RTL\u7edf\u4e00\u4e86\u786c\u4ef6\u8bbe\u8ba1\u81ea\u52a8\u5316\u7684\u4e24\u79cd\u4e3b\u6d41\u65b9\u6cd5\uff0c\u901a\u8fc7Agentic Context Evolution\u7ed3\u5408\u4e13\u7528RTL\u6a21\u578b\u548c\u524d\u6cbf\u63a8\u7406LLM\uff0c\u663e\u8457\u63d0\u5347Verilog\u4ee3\u7801\u751f\u6210\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u786c\u4ef6\u8bbe\u8ba1\u81ea\u52a8\u5316\u65b9\u6cd5\u5b58\u5728\u4e24\u79cd\u72ec\u7acb\u8def\u5f84\uff1a\u8bad\u7ec3\u9886\u57df\u9002\u5e94\u7684RTL\u6a21\u578b\u548c\u57fa\u4e8e\u4eff\u771f\u53cd\u9988\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4e24\u8005\u5404\u6709\u4f18\u7f3a\u70b9\u4f46\u7f3a\u4e4f\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u63d0\u51faACE-RTL\u6846\u67b6\uff0c\u96c6\u6210\u5728170\u4e07RTL\u6837\u672c\u4e0a\u8bad\u7ec3\u7684\u4e13\u7528LLM\u548c\u524d\u6cbf\u63a8\u7406LLM\uff0c\u901a\u8fc7\u751f\u6210\u5668\u3001\u53cd\u5c04\u5668\u548c\u534f\u8c03\u5668\u4e09\u4e2a\u534f\u540c\u7ec4\u4ef6\u8fed\u4ee3\u4f18\u5316RTL\u4ee3\u7801\uff0c\u5e76\u5f15\u5165\u5e76\u884c\u6269\u5c55\u7b56\u7565\u51cf\u5c11\u8fed\u4ee3\u6b21\u6570\u3002", "result": "\u5728CVDP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cACE-RTL\u76f8\u6bd414\u4e2a\u7ade\u4e89\u57fa\u7ebf\u63d0\u534744.87%\u7684\u901a\u8fc7\u7387\uff0c\u5e73\u5747\u4ec5\u97004\u6b21\u8fed\u4ee3\u5373\u53ef\u8fbe\u5230\u6b63\u786e\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "ACE-RTL\u6210\u529f\u7edf\u4e00\u4e86\u786c\u4ef6\u8bbe\u8ba1\u81ea\u52a8\u5316\u7684\u4e24\u79cd\u4e3b\u6d41\u65b9\u6cd5\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u4e0a\u4e0b\u6587\u6f14\u5316\u663e\u8457\u63d0\u5347\u4e86RTL\u4ee3\u7801\u751f\u6210\u7684\u529f\u80fd\u6b63\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2602.10485", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10485", "abs": "https://arxiv.org/abs/2602.10485", "authors": ["Zhenhe Cui", "Huaxiang Xia", "Hangjun Shen", "Kailun Luo", "Yong He", "Wei Liang"], "title": "Abstraction Generation for Generalized Planning with Pretrained Large Language Models", "comment": null, "summary": "Qualitative Numerical Planning (QNP) serves as an important abstraction model for generalized planning (GP), which aims to compute general plans that solve multiple instances at once. Recent works show that large language models (LLMs) can function as generalized planners. This work investigates whether LLMs can serve as QNP abstraction generators for GP problems and how to fix abstractions via automated debugging. We propose a prompt protocol: input a GP domain and training tasks to LLMs, prompting them to generate abstract features and further abstract the initial state, action set, and goal into QNP problems. An automated debugging method is designed to detect abstraction errors, guiding LLMs to fix abstractions. Experiments demonstrate that under properly guided by automated debugging, some LLMs can generate useful QNP abstractions.", "AI": {"tldr": "LLMs\u80fd\u591f\u751f\u6210\u7528\u4e8e\u5e7f\u4e49\u89c4\u5212\u7684\u5b9a\u6027\u6570\u503c\u89c4\u5212\u62bd\u8c61\uff0c\u7ed3\u5408\u81ea\u52a8\u8c03\u8bd5\u65b9\u6cd5\u53ef\u4ee5\u4fee\u6b63\u62bd\u8c61\u9519\u8bef", "motivation": "\u7814\u7a76LLMs\u662f\u5426\u80fd\u591f\u4f5c\u4e3aQNP\u62bd\u8c61\u751f\u6210\u5668\u6765\u89e3\u51b3\u5e7f\u4e49\u89c4\u5212\u95ee\u9898\uff0c\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u81ea\u52a8\u8c03\u8bd5\u6765\u4fee\u6b63\u62bd\u8c61", "method": "\u63d0\u51fa\u63d0\u793a\u534f\u8bae\uff1a\u8f93\u5165GP\u9886\u57df\u548c\u8bad\u7ec3\u4efb\u52a1\u7ed9LLMs\uff0c\u8ba9\u5b83\u4eec\u751f\u6210\u62bd\u8c61\u7279\u5f81\u5e76\u5c06\u521d\u59cb\u72b6\u6001\u3001\u52a8\u4f5c\u96c6\u548c\u76ee\u6807\u62bd\u8c61\u4e3aQNP\u95ee\u9898\uff1b\u8bbe\u8ba1\u81ea\u52a8\u8c03\u8bd5\u65b9\u6cd5\u6765\u68c0\u6d4b\u62bd\u8c61\u9519\u8bef\u5e76\u6307\u5bfcLLMs\u4fee\u6b63", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u81ea\u52a8\u8c03\u8bd5\u7684\u9002\u5f53\u6307\u5bfc\u4e0b\uff0c\u4e00\u4e9bLLMs\u80fd\u591f\u751f\u6210\u6709\u7528\u7684QNP\u62bd\u8c61", "conclusion": "LLMs\u53ef\u4ee5\u4f5c\u4e3aQNP\u62bd\u8c61\u751f\u6210\u5668\uff0c\u7ed3\u5408\u81ea\u52a8\u8c03\u8bd5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u751f\u6210\u548c\u4fee\u6b63\u62bd\u8c61\uff0c\u4e3a\u5e7f\u4e49\u89c4\u5212\u95ee\u9898\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.10254", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.10254", "abs": "https://arxiv.org/abs/2602.10254", "authors": ["Hanyuan Gao", "Xiaoxuan Yang"], "title": "Area-Efficient In-Memory Computing for Mixture-of-Experts via Multiplexing and Caching", "comment": "Accepted by ISCAS 2026", "summary": "Mixture-of-Experts (MoE) layers activate a subset of model weights, dubbed experts, to improve model performance. MoE is particularly promising for deployment on process-in-memory (PIM) architectures, because PIM can naturally fit experts separately and provide great benefits for energy efficiency. However, PIM chips often suffer from large area overhead, especially in the peripheral circuits. In this paper, we propose an area-efficient in-memory computing architecture for MoE transformers. First, to reduce area, we propose a crossbar-level multiplexing strategy that exploits MoE sparsity: experts are deployed on crossbars and multiple crossbars share the same peripheral circuits. Second, we propose expert grouping and group-wise scheduling methods to alleviate the load imbalance and contention overhead caused by sharing. In addition, to address the problem that the expert choice router requires access to all hidden states during generation, we propose a gate-output (GO)cache to store necessary results and bypass expensive additional computation. Experiments show that our approaches improve the area efficiency of the MoE part by up to 2.2x compared to a SOTA architecture. During generation, the cache improves performance and energy efficiency by 4.2x and 10.1x, respectively, compared to the baseline when generating 8 tokens. The total performance density achieves 15.6 GOPS/W/mm2. The code is open source at https://github.com/superstarghy/MoEwithPIM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411MoE\u53d8\u538b\u5668\u7684\u9762\u79ef\u9ad8\u6548\u5b58\u5185\u8ba1\u7b97\u67b6\u6784\uff0c\u901a\u8fc7\u4ea4\u53c9\u5f00\u5173\u7ea7\u590d\u7528\u3001\u4e13\u5bb6\u5206\u7ec4\u8c03\u5ea6\u548c\u95e8\u8f93\u51fa\u7f13\u5b58\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9762\u79ef\u6548\u7387\u548c\u751f\u6210\u6027\u80fd\u3002", "motivation": "MoE\u5c42\u901a\u8fc7\u6fc0\u6d3b\u90e8\u5206\u4e13\u5bb6\u6743\u91cd\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u7279\u522b\u9002\u5408\u5b58\u5185\u8ba1\u7b97\u67b6\u6784\u90e8\u7f72\uff0c\u4f46\u73b0\u6709PIM\u82af\u7247\u5b58\u5728\u9762\u79ef\u5f00\u9500\u5927\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5916\u56f4\u7535\u8def\u5360\u7528\u8fc7\u591a\u9762\u79ef\u3002", "method": "1) \u63d0\u51fa\u4ea4\u53c9\u5f00\u5173\u7ea7\u590d\u7528\u7b56\u7565\uff0c\u5229\u7528MoE\u7a00\u758f\u6027\u8ba9\u591a\u4e2a\u4ea4\u53c9\u5f00\u5173\u5171\u4eab\u5916\u56f4\u7535\u8def\uff1b2) \u63d0\u51fa\u4e13\u5bb6\u5206\u7ec4\u548c\u7ec4\u7ea7\u8c03\u5ea6\u65b9\u6cd5\u7f13\u89e3\u5171\u4eab\u5e26\u6765\u7684\u8d1f\u8f7d\u4e0d\u5e73\u8861\u548c\u4e89\u7528\u5f00\u9500\uff1b3) \u8bbe\u8ba1\u95e8\u8f93\u51fa\u7f13\u5b58\u5b58\u50a8\u5fc5\u8981\u7ed3\u679c\uff0c\u907f\u514d\u751f\u6210\u9636\u6bb5\u8bbf\u95ee\u6240\u6709\u9690\u85cf\u72b6\u6001\u7684\u5f00\u9500\u3002", "result": "MoE\u90e8\u5206\u9762\u79ef\u6548\u7387\u76f8\u6bd4SOTA\u67b6\u6784\u63d0\u53472.2\u500d\uff1b\u751f\u62108\u4e2atoken\u65f6\uff0c\u7f13\u5b58\u4f7f\u6027\u80fd\u548c\u80fd\u6548\u5206\u522b\u63d0\u53474.2\u500d\u548c10.1\u500d\uff1b\u603b\u4f53\u6027\u80fd\u5bc6\u5ea6\u8fbe\u523015.6 GOPS/W/mm\u00b2\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3aMoE\u53d8\u538b\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u9762\u79ef\u9ad8\u6548\u7684\u5b58\u5185\u8ba1\u7b97\u67b6\u6784\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u590d\u7528\u7b56\u7565\u3001\u8c03\u5ea6\u65b9\u6cd5\u548c\u7f13\u5b58\u673a\u5236\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u786c\u4ef6\u5f00\u9500\u3002"}}
{"id": "2602.10583", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10583", "abs": "https://arxiv.org/abs/2602.10583", "authors": ["Bo Xue", "Yunchong Song", "Fanghao Shao", "Xuekai Zhu", "Lin Chen", "Luoyi Fu", "Xinbing Wang", "Zhouhan Lin"], "title": "Flow of Spans: Generalizing Language Models to Dynamic Span-Vocabulary via GFlowNets", "comment": "Published as a conference paper at ICLR 2026", "summary": "Standard autoregressive language models generate text token-by-token from a fixed vocabulary, inducing a tree-structured state space when viewing token sampling as an action, which limits flexibility and expressiveness. Recent work introduces dynamic vocabulary by sampling retrieved text spans but overlooks that the same sentence can be composed of spans of varying lengths, lacking explicit modeling of the directed acyclic graph (DAG) state space. This leads to restricted exploration of compositional paths and is biased toward the chosen path. Generative Flow Networks (GFlowNets) are powerful for efficient exploring and generalizing over state spaces, particularly those with a DAG structure. However, prior GFlowNets-based language models operate at the token level and remain confined to tree-structured spaces, limiting their potential. In this work, we propose Flow of SpanS (FOSS), a principled GFlowNets framework for span generation. FoSS constructs a dynamic span vocabulary by segmenting the retrieved text flexibly, ensuring a DAG-structured state space, which allows GFlowNets to explore diverse compositional paths and improve generalization. With specialized reward models, FoSS generates diverse, high-quality text. Empirically, FoSS improves MAUVE scores by up to 12.5% over Transformer on text generation and achieves 3.5% gains on knowledge-intensive tasks, consistently outperforming state-of-the-art methods. Scaling experiments further demonstrate FoSS benefits from larger models, more data, and richer retrieval corpora, retaining its advantage over strong baselines.", "AI": {"tldr": "FoSS\u63d0\u51fa\u57fa\u4e8eGFlowNets\u7684\u8de8\u5ea6\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8de8\u5ea6\u8bcd\u6c47\u548cDAG\u72b6\u6001\u7a7a\u95f4\u63d0\u5347\u6587\u672c\u751f\u6210\u7684\u591a\u6837\u6027\u548c\u8d28\u91cf", "motivation": "\u4f20\u7edf\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u57fa\u4e8e\u56fa\u5b9a\u8bcd\u6c47\u7684token\u7ea7\u751f\u6210\u5f62\u6210\u6811\u72b6\u72b6\u6001\u7a7a\u95f4\uff0c\u9650\u5236\u4e86\u7075\u6d3b\u6027\u548c\u8868\u8fbe\u80fd\u529b\u3002\u73b0\u6709\u52a8\u6001\u8bcd\u6c47\u65b9\u6cd5\u867d\u7136\u5f15\u5165\u68c0\u7d22\u6587\u672c\u8de8\u5ea6\uff0c\u4f46\u5ffd\u7565\u4e86\u540c\u4e00\u53e5\u5b50\u53ef\u7531\u4e0d\u540c\u957f\u5ea6\u8de8\u5ea6\u7ec4\u5408\u7684\u53ef\u80fd\u6027\uff0c\u7f3a\u4e4f\u5bf9DAG\u72b6\u6001\u7a7a\u95f4\u7684\u663e\u5f0f\u5efa\u6a21\uff0c\u5bfc\u81f4\u7ec4\u5408\u8def\u5f84\u63a2\u7d22\u53d7\u9650\u548c\u8def\u5f84\u9009\u62e9\u504f\u5dee\u3002", "method": "\u63d0\u51faFlow of SpanS (FoSS)\u6846\u67b6\uff1a1) \u901a\u8fc7\u7075\u6d3b\u5206\u5272\u68c0\u7d22\u6587\u672c\u6784\u5efa\u52a8\u6001\u8de8\u5ea6\u8bcd\u6c47\uff1b2) \u786e\u4fdd\u5f62\u6210DAG\u7ed3\u6784\u7684\u72b6\u6001\u7a7a\u95f4\uff1b3) \u5229\u7528GFlowNets\u63a2\u7d22\u591a\u6837\u7ec4\u5408\u8def\u5f84\uff1b4) \u7ed3\u5408\u4e13\u7528\u5956\u52b1\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u6587\u672c\u3002", "result": "FoSS\u5728\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e0a\u6bd4Transformer\u63d0\u5347MAUVE\u5206\u6570\u8fbe12.5%\uff0c\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u83b7\u5f973.5%\u7684\u589e\u76ca\uff0c\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u3002\u6269\u5c55\u5b9e\u9a8c\u8868\u660eFoSS\u53d7\u76ca\u4e8e\u66f4\u5927\u6a21\u578b\u3001\u66f4\u591a\u6570\u636e\u548c\u66f4\u4e30\u5bcc\u7684\u68c0\u7d22\u8bed\u6599\u5e93\u3002", "conclusion": "FoSS\u901a\u8fc7\u5c06GFlowNets\u5e94\u7528\u4e8e\u8de8\u5ea6\u751f\u6210\uff0c\u6784\u5efaDAG\u72b6\u6001\u7a7a\u95f4\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u7ec4\u5408\u8def\u5f84\u63a2\u7d22\u548c\u6cdb\u5316\u65b9\u9762\u7684\u9650\u5236\uff0c\u4e3a\u6587\u672c\u751f\u6210\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u3001\u591a\u6837\u4e14\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.10654", "categories": ["cs.AR", "cs.FL"], "pdf": "https://arxiv.org/pdf/2602.10654", "abs": "https://arxiv.org/abs/2602.10654", "authors": ["Derek Christ", "Thomas Zimmermann", "Philippe Barbie", "Dmitri Saberi", "Yao Yin", "Matthias Jung"], "title": "DRAMPyML: A Formal Description of DRAM Protocols with Timed Petri Nets", "comment": null, "summary": "The JEDEC committee defines various domain-specific DRAM standards. These standards feature increasingly complex and evolving protocol specifications, which are detailed in timing diagrams and command tables. Understanding these protocols is becoming progressively challenging as new features and complex device hierarchies are difficult to comprehend without an expressive model. While each JEDEC standard features a simplified state machine, this state machine fails to reflect the parallel operation of memory banks.\n  In this paper, we present an evolved modeling approach based on timed Petri nets and Python. This model provides a more accurate representation of DRAM protocols, making them easier to understand and directly executable, which enables the evaluation of interesting metrics and the verification of controller RTL models, DRAM logic and memory simulators.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65f6\u95f4Petri\u7f51\u548cPython\u7684DRAM\u534f\u8bae\u5efa\u6a21\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3JEDEC\u6807\u51c6\u4e2d\u7b80\u5316\u72b6\u6001\u673a\u65e0\u6cd5\u53cd\u6620\u5185\u5b58\u5e93\u5e76\u884c\u64cd\u4f5c\u7684\u95ee\u9898\uff0c\u4f7f\u534f\u8bae\u66f4\u6613\u7406\u89e3\u5e76\u53ef\u6267\u884c\u9a8c\u8bc1\u3002", "motivation": "JEDEC\u5b9a\u4e49\u7684DRAM\u6807\u51c6\u534f\u8bae\u65e5\u76ca\u590d\u6742\uff0c\u65f6\u5e8f\u56fe\u548c\u547d\u4ee4\u8868\u96be\u4ee5\u7406\u89e3\uff0c\u7279\u522b\u662f\u65b0\u7279\u6027\u548c\u590d\u6742\u8bbe\u5907\u5c42\u6b21\u7ed3\u6784\u3002\u73b0\u6709\u7684\u7b80\u5316\u72b6\u6001\u673a\u65e0\u6cd5\u53cd\u6620\u5185\u5b58\u5e93\u7684\u5e76\u884c\u64cd\u4f5c\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u65f6\u95f4Petri\u7f51\u548cPython\u7684\u5efa\u6a21\u65b9\u6cd5\uff0c\u6784\u5efa\u66f4\u51c6\u786e\u7684DRAM\u534f\u8bae\u6a21\u578b\u3002\u8be5\u6a21\u578b\u53ef\u76f4\u63a5\u6267\u884c\uff0c\u652f\u6301\u534f\u8bae\u9a8c\u8bc1\u548c\u6027\u80fd\u8bc4\u4f30\u3002", "result": "\u63d0\u51fa\u7684\u5efa\u6a21\u65b9\u6cd5\u80fd\u591f\u66f4\u51c6\u786e\u5730\u8868\u793aDRAM\u534f\u8bae\uff0c\u4f7f\u534f\u8bae\u66f4\u6613\u4e8e\u7406\u89e3\uff0c\u5e76\u652f\u6301\u76f4\u63a5\u6267\u884c\u9a8c\u8bc1\u63a7\u5236\u5668RTL\u6a21\u578b\u3001DRAM\u903b\u8f91\u548c\u5185\u5b58\u6a21\u62df\u5668\uff0c\u8fd8\u80fd\u8bc4\u4f30\u76f8\u5173\u6027\u80fd\u6307\u6807\u3002", "conclusion": "\u57fa\u4e8e\u65f6\u95f4Petri\u7f51\u548cPython\u7684\u5efa\u6a21\u65b9\u6cd5\u4e3aDRAM\u534f\u8bae\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u3001\u53ef\u6267\u884c\u7684\u8868\u793a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u72b6\u6001\u673a\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u6709\u52a9\u4e8e\u534f\u8bae\u7406\u89e3\u3001\u9a8c\u8bc1\u548c\u6027\u80fd\u8bc4\u4f30\u3002"}}
{"id": "2602.10246", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10246", "abs": "https://arxiv.org/abs/2602.10246", "authors": ["Mayur Akewar", "Sandeep Madireddy", "Dongsheng Luo", "Janki Bhimani"], "title": "KORAL: Knowledge Graph Guided LLM Reasoning for SSD Operational Analysis", "comment": null, "summary": "Solid State Drives (SSDs) are critical to datacenters, consumer platforms, and mission-critical systems. Yet diagnosing their performance and reliability is difficult because data are fragmented and time-disjoint, and existing methods demand large datasets and expert input while offering only limited insights. Degradation arises not only from shifting workloads and evolving architectures but also from environmental factors such as temperature, humidity, and vibration. We present KORAL, a knowledge driven reasoning framework that integrates Large Language Models (LLMs) with a structured Knowledge Graph (KG) to generate insights into SSD operations. Unlike traditional approaches that require extensive expert input and large datasets, KORAL generates a Data KG from fragmented telemetry and integrates a Literature KG that already organizes knowledge from literature, reports, and traces. This turns unstructured sources into a queryable graph and telemetry into structured knowledge, and both the Graphs guide the LLM to deliver evidence-based, explainable analysis aligned with the domain vocabulary and constraints. Evaluation using real production traces shows that the KORAL delivers expert-level diagnosis and recommendations, supported by grounded explanations that improve reasoning transparency, guide operator decisions, reduce manual effort, and provide actionable insights to improve service quality. To our knowledge, this is the first end-to-end system that combines LLMs and KGs for full-spectrum SSD reasoning including Descriptive, Predictive, Prescriptive, and What-if analysis. We release the generated SSD-specific KG to advance reproducible research in knowledge-based storage system analysis. GitHub Repository: https://github.com/Damrl-lab/KORAL", "AI": {"tldr": "KORAL\u662f\u4e00\u4e2a\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u77e5\u8bc6\u56fe\u8c31\u7684SSD\u8bca\u65ad\u6846\u67b6\uff0c\u80fd\u4ece\u788e\u7247\u5316\u6570\u636e\u751f\u6210\u4e13\u5bb6\u7ea7\u5206\u6790\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u3002", "motivation": "SSD\u6027\u80fd\u4e0e\u53ef\u9760\u6027\u8bca\u65ad\u56f0\u96be\uff0c\u6570\u636e\u788e\u7247\u5316\u4e14\u65f6\u95f4\u4e0d\u8fde\u7eed\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6570\u636e\u96c6\u548c\u4e13\u5bb6\u8f93\u5165\uff0c\u4f46\u53ea\u80fd\u63d0\u4f9b\u6709\u9650\u6d1e\u5bdf\u3002\u6027\u80fd\u9000\u5316\u4e0d\u4ec5\u6765\u81ea\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5316\u548c\u67b6\u6784\u6f14\u8fdb\uff0c\u8fd8\u53d7\u6e29\u5ea6\u3001\u6e7f\u5ea6\u3001\u632f\u52a8\u7b49\u73af\u5883\u56e0\u7d20\u5f71\u54cd\u3002", "method": "\u63d0\u51faKORAL\u6846\u67b6\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u7ed3\u5408\u3002\u4ece\u788e\u7247\u5316\u9065\u6d4b\u6570\u636e\u751f\u6210\u6570\u636e\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e76\u96c6\u6210\u5df2\u7ec4\u7ec7\u6587\u732e\u3001\u62a5\u544a\u548c\u8ddf\u8e2a\u6570\u636e\u7684\u6587\u732e\u77e5\u8bc6\u56fe\u8c31\u3002\u5c06\u975e\u7ed3\u6784\u5316\u6e90\u8f6c\u5316\u4e3a\u53ef\u67e5\u8be2\u56fe\uff0c\u9065\u6d4b\u6570\u636e\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u77e5\u8bc6\uff0c\u4e24\u8005\u5171\u540c\u6307\u5bfcLLM\u63d0\u4f9b\u57fa\u4e8e\u8bc1\u636e\u3001\u53ef\u89e3\u91ca\u7684\u5206\u6790\u3002", "result": "\u4f7f\u7528\u771f\u5b9e\u751f\u4ea7\u8ddf\u8e2a\u6570\u636e\u8bc4\u4f30\u663e\u793a\uff0cKORAL\u80fd\u63d0\u4f9b\u4e13\u5bb6\u7ea7\u8bca\u65ad\u548c\u5efa\u8bae\uff0c\u652f\u6301\u57fa\u4e8e\u8bc1\u636e\u7684\u89e3\u91ca\uff0c\u63d0\u9ad8\u63a8\u7406\u900f\u660e\u5ea6\uff0c\u6307\u5bfc\u64cd\u4f5c\u5458\u51b3\u7b56\uff0c\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\uff0c\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u4ee5\u6539\u5584\u670d\u52a1\u8d28\u91cf\u3002", "conclusion": "KORAL\u662f\u9996\u4e2a\u7ed3\u5408LLM\u548cKG\u5b9e\u73b0\u5168\u8c31SSD\u63a8\u7406\uff08\u63cf\u8ff0\u6027\u3001\u9884\u6d4b\u6027\u3001\u89c4\u8303\u6027\u3001\u5047\u8bbe\u5206\u6790\uff09\u7684\u7aef\u5230\u7aef\u7cfb\u7edf\u3002\u53d1\u5e03SSD\u7279\u5b9a\u77e5\u8bc6\u56fe\u8c31\u4ee5\u63a8\u8fdb\u57fa\u4e8e\u77e5\u8bc6\u7684\u5b58\u50a8\u7cfb\u7edf\u5206\u6790\u7684\u53ef\u91cd\u590d\u7814\u7a76\u3002"}}
{"id": "2602.10598", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10598", "abs": "https://arxiv.org/abs/2602.10598", "authors": ["Shuai Han", "Mehdi Dastani", "Shihan Wang"], "title": "Neuro-symbolic Action Masking for Deep Reinforcement Learning", "comment": null, "summary": "Deep reinforcement learning (DRL) may explore infeasible actions during training and execution. Existing approaches assume a symbol grounding function that maps high-dimensional states to consistent symbolic representations and a manually specified action masking techniques to constrain actions. In this paper, we propose Neuro-symbolic Action Masking (NSAM), a novel framework that automatically learn symbolic models, which are consistent with given domain constraints of high-dimensional states, in a minimally supervised manner during the DRL process. Based on the learned symbolic model of states, NSAM learns action masks that rules out infeasible actions. NSAM enables end-to-end integration of symbolic reasoning and deep policy optimization, where improvements in symbolic grounding and policy learning mutually reinforce each other. We evaluate NSAM on multiple domains with constraints, and experimental results demonstrate that NSAM significantly improves sample efficiency of DRL agent while substantially reducing constraint violations.", "AI": {"tldr": "NSAM\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u52a8\u4f5c\u5c4f\u853d\u6846\u67b6\uff0c\u80fd\u81ea\u52a8\u5b66\u4e60\u4e0e\u9ad8\u7ef4\u72b6\u6001\u7ea6\u675f\u4e00\u81f4\u7684\u7b26\u53f7\u6a21\u578b\uff0c\u5728DRL\u8bad\u7ec3\u4e2d\u51cf\u5c11\u4e0d\u53ef\u884c\u52a8\u4f5c\u63a2\u7d22\u5e76\u63d0\u9ad8\u6837\u672c\u6548\u7387", "motivation": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u8bad\u7ec3\u548c\u6267\u884c\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u63a2\u7d22\u4e0d\u53ef\u884c\u7684\u52a8\u4f5c\u3002\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u624b\u52a8\u6307\u5b9a\u7b26\u53f7\u63a5\u5730\u51fd\u6570\u548c\u52a8\u4f5c\u5c4f\u853d\u6280\u672f\uff0c\u9650\u5236\u4e86\u65b9\u6cd5\u7684\u81ea\u52a8\u5316\u7a0b\u5ea6\u548c\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u7b26\u53f7\u52a8\u4f5c\u5c4f\u853d\uff08NSAM\uff09\u6846\u67b6\uff0c\u5728\u6700\u5c0f\u76d1\u7763\u4e0b\u81ea\u52a8\u5b66\u4e60\u4e0e\u9886\u57df\u7ea6\u675f\u4e00\u81f4\u7684\u7b26\u53f7\u6a21\u578b\uff0c\u57fa\u4e8e\u5b66\u4e60\u7684\u7b26\u53f7\u72b6\u6001\u6a21\u578b\u751f\u6210\u52a8\u4f5c\u5c4f\u853d\uff0c\u6392\u9664\u4e0d\u53ef\u884c\u52a8\u4f5c\uff0c\u5b9e\u73b0\u7b26\u53f7\u63a8\u7406\u4e0e\u6df1\u5ea6\u7b56\u7565\u4f18\u5316\u7684\u7aef\u5230\u7aef\u96c6\u6210\u3002", "result": "\u5728\u591a\u4e2a\u7ea6\u675f\u9886\u57df\u8bc4\u4f30NSAM\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eNSAM\u663e\u8457\u63d0\u9ad8\u4e86DRL\u667a\u80fd\u4f53\u7684\u6837\u672c\u6548\u7387\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4e86\u7ea6\u675f\u8fdd\u53cd\u3002", "conclusion": "NSAM\u901a\u8fc7\u81ea\u52a8\u5b66\u4e60\u7b26\u53f7\u6a21\u578b\u548c\u52a8\u4f5c\u5c4f\u853d\uff0c\u5b9e\u73b0\u4e86\u7b26\u53f7\u63a8\u7406\u4e0e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u6709\u6548\u96c6\u6210\uff0c\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u5b89\u5168\u6027\uff0c\u4e3a\u7ea6\u675f\u73af\u5883\u4e0b\u7684\u667a\u80fd\u4f53\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2602.10790", "categories": ["cs.AR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.10790", "abs": "https://arxiv.org/abs/2602.10790", "authors": ["Paula Carolina Lozano Duarte", "Sule Ozev", "Mehdi Tahoori"], "title": "Fault Tolerant Design of IGZO-based Binary Search ADCs", "comment": "Accepted for publication at the 27th International Symposium on Quality Electronic Design (ISQED'26), April 8-10, 2026", "summary": "Thin-film technologies such as Indium Gallium Zinc Oxide (IGZO) enable Flexible Electronics (FE) for emerging applications in wearable sensing, personal health monitoring, and large-area systems. Analog-to-digital converters (ADCs) serve as critical sensor interfaces in these systems. Yet, their vulnerability to manufacturing defects remains poorly understood despite unipolar technologies' inherently high defect densities and process variations compared to mature CMOS technologies. We present a hierarchical fault injection framework to characterize defect sensitivity in Binary Search ADCs implemented in n-type only technologies. Our methodology combines transistor-level defect characterization with system-level fault propagation analysis, enabling efficient exploration of both single and multiple fault scenarios across the conversion hierarchy. The framework identifies critical fault-sensitive circuit components and enables selective redundancy strategies targeting only the most sensitive components. The resulting defect-tolerant designs improve fault coverage from 60% to 92% under single-fault injections and from 34% to 77.6% under multi-fault injection, while incurring only 4.2% area overhead and 6% power increase. While validated on IGZO-TFTs, the methodology applies to all emerging unipolar technologies.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u6545\u969c\u6ce8\u5165\u6846\u67b6\u5206\u6790IGZO\u67d4\u6027\u7535\u5b50\u4e2dADC\u7684\u7f3a\u9677\u654f\u611f\u6027\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u5197\u4f59\u7b56\u7565\u5c06\u6545\u969c\u8986\u76d6\u7387\u4ece60%\u63d0\u5347\u81f392%\uff0c\u9762\u79ef\u5f00\u9500\u4ec54.2%", "motivation": "IGZO\u7b49\u8584\u819c\u6280\u672f\u867d\u80fd\u5b9e\u73b0\u67d4\u6027\u7535\u5b50\uff0c\u4f46\u5176\u5355\u6781\u6027\u6280\u672f\u76f8\u6bd4\u6210\u719fCMOS\u5177\u6709\u66f4\u9ad8\u7684\u7f3a\u9677\u5bc6\u5ea6\u548c\u5de5\u827a\u53d8\u5316\uff0c\u800cADC\u4f5c\u4e3a\u5173\u952e\u4f20\u611f\u5668\u63a5\u53e3\u7684\u5236\u9020\u7f3a\u9677\u654f\u611f\u6027\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3", "method": "\u63d0\u51fa\u5206\u5c42\u6545\u969c\u6ce8\u5165\u6846\u67b6\uff0c\u7ed3\u5408\u6676\u4f53\u7ba1\u7ea7\u7f3a\u9677\u8868\u5f81\u548c\u7cfb\u7edf\u7ea7\u6545\u969c\u4f20\u64ad\u5206\u6790\uff0c\u9ad8\u6548\u63a2\u7d22\u8f6c\u6362\u5c42\u6b21\u4e2d\u7684\u5355\u6545\u969c\u548c\u591a\u6545\u969c\u573a\u666f\uff0c\u8bc6\u522b\u5173\u952e\u6545\u969c\u654f\u611f\u7535\u8def\u7ec4\u4ef6", "result": "\u7f3a\u9677\u5bb9\u5fcd\u8bbe\u8ba1\u5c06\u5355\u6545\u969c\u6ce8\u5165\u4e0b\u7684\u6545\u969c\u8986\u76d6\u7387\u4ece60%\u63d0\u5347\u81f392%\uff0c\u591a\u6545\u969c\u6ce8\u5165\u4e0b\u4ece34%\u63d0\u5347\u81f377.6%\uff0c\u4ec5\u5e26\u67654.2%\u7684\u9762\u79ef\u5f00\u9500\u548c6%\u7684\u529f\u8017\u589e\u52a0", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u9002\u7528\u4e8eIGZO-TFTs\u9a8c\u8bc1\uff0c\u8fd8\u53ef\u63a8\u5e7f\u5230\u6240\u6709\u65b0\u5174\u5355\u6781\u6027\u6280\u672f\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u5197\u4f59\u7b56\u7565\u6709\u6548\u63d0\u5347\u67d4\u6027\u7535\u5b50\u7cfb\u7edf\u4e2dADC\u7684\u53ef\u9760\u6027"}}
{"id": "2602.10262", "categories": ["cs.DC", "cs.AR"], "pdf": "https://arxiv.org/pdf/2602.10262", "abs": "https://arxiv.org/abs/2602.10262", "authors": ["Aaron Jarmusch", "Connor Vitz", "Sunita Chandrasekaran"], "title": "Execution-Centric Characterization of FP8 Matrix Cores, Asynchronous Execution, and Structured Sparsity on AMD MI300A", "comment": null, "summary": "The AMD MI300A APU integrates CDNA3 GPUs with high-bandwidth memory and advanced accelerator features: FP8 matrix cores, asynchronous compute engines (ACE), and 2:4 structured sparsity. These capabilities are increasingly relied upon by modern HPC and HPC-AI workloads, yet their execution characteristics and system-level implications remain insufficiently understood. In this paper, we present an execution-centric characterization of FP8 matrix execution, ACE concurrency, and structured sparsity on MI300A using targeted microbenchmarks. We quantify occupancy thresholds, fairness, throughput trade-offs under concurrent execution, and context-dependent sparsity benefits. We evaluate representative case studies - transformer-style, concurrent, and mixed-precision kernels - to show how these effects translate into application-level performance and predictability. Our results provide practical guidance for occupancy-aware scheduling, concurrency decisions, and sparsity enablement on MI300A-class unified nodes.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5fae\u57fa\u51c6\u6d4b\u8bd5\u5bf9AMD MI300A APU\u7684FP8\u77e9\u9635\u6267\u884c\u3001\u5f02\u6b65\u8ba1\u7b97\u5f15\u64ce\u5e76\u53d1\u6027\u548c\u7ed3\u6784\u5316\u7a00\u758f\u6027\u8fdb\u884c\u6267\u884c\u4e2d\u5fc3\u5316\u8868\u5f81\uff0c\u91cf\u5316\u4e86\u5360\u7528\u7387\u9608\u503c\u3001\u516c\u5e73\u6027\u3001\u5e76\u53d1\u6267\u884c\u4e0b\u7684\u541e\u5410\u91cf\u6743\u8861\u4ee5\u53ca\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u7a00\u758f\u6027\u4f18\u52bf\uff0c\u4e3aMI300A\u7c7b\u7edf\u4e00\u8282\u70b9\u7684\u5360\u7528\u611f\u77e5\u8c03\u5ea6\u3001\u5e76\u53d1\u51b3\u7b56\u548c\u7a00\u758f\u6027\u542f\u7528\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002", "motivation": "AMD MI300A APU\u96c6\u6210\u4e86CDNA3 GPU\u3001\u9ad8\u5e26\u5bbd\u5185\u5b58\u548c\u5148\u8fdb\u52a0\u901f\u5668\u7279\u6027\uff08FP8\u77e9\u9635\u6838\u5fc3\u3001\u5f02\u6b65\u8ba1\u7b97\u5f15\u64ce\u30012:4\u7ed3\u6784\u5316\u7a00\u758f\u6027\uff09\u3002\u8fd9\u4e9b\u529f\u80fd\u88ab\u73b0\u4ee3HPC\u548cHPC-AI\u5de5\u4f5c\u8d1f\u8f7d\u65e5\u76ca\u4f9d\u8d56\uff0c\u4f46\u5176\u6267\u884c\u7279\u6027\u548c\u7cfb\u7edf\u7ea7\u5f71\u54cd\u4ecd\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002", "method": "\u4f7f\u7528\u9488\u5bf9\u6027\u5fae\u57fa\u51c6\u6d4b\u8bd5\u5bf9MI300A\u8fdb\u884c\u6267\u884c\u4e2d\u5fc3\u5316\u8868\u5f81\uff0c\u91cf\u5316FP8\u77e9\u9635\u6267\u884c\u3001ACE\u5e76\u53d1\u6027\u548c\u7ed3\u6784\u5316\u7a00\u758f\u6027\u7684\u6027\u80fd\u7279\u5f81\u3002\u8bc4\u4f30\u4ee3\u8868\u6027\u6848\u4f8b\u7814\u7a76\uff0c\u5305\u62ectransformer\u98ce\u683c\u3001\u5e76\u53d1\u548c\u6df7\u5408\u7cbe\u5ea6\u5185\u6838\uff0c\u4ee5\u5c55\u793a\u8fd9\u4e9b\u6548\u5e94\u5982\u4f55\u8f6c\u5316\u4e3a\u5e94\u7528\u7ea7\u6027\u80fd\u548c\u53ef\u9884\u6d4b\u6027\u3002", "result": "\u91cf\u5316\u4e86\u5360\u7528\u7387\u9608\u503c\u3001\u516c\u5e73\u6027\u3001\u5e76\u53d1\u6267\u884c\u4e0b\u7684\u541e\u5410\u91cf\u6743\u8861\u4ee5\u53ca\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u7a00\u758f\u6027\u4f18\u52bf\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u8fd9\u4e9b\u6548\u5e94\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8868\u73b0\uff0c\u4e3aMI300A\u7c7b\u7cfb\u7edf\u7684\u6027\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3aMI300A\u7c7b\u7edf\u4e00\u8282\u70b9\u7684\u5360\u7528\u611f\u77e5\u8c03\u5ea6\u3001\u5e76\u53d1\u51b3\u7b56\u548c\u7a00\u758f\u6027\u542f\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u4f18\u5316\u73b0\u4ee3HPC\u548cHPC-AI\u5de5\u4f5c\u8d1f\u8f7d\u5728\u5148\u8fdbAPU\u67b6\u6784\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2602.10625", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.10625", "abs": "https://arxiv.org/abs/2602.10625", "authors": ["Nanxu Gong", "Haotian Li", "Sixun Dong", "Jianxun Lian", "Yanjie Fu", "Xing Xie"], "title": "To Think or Not To Think, That is The Question for Large Reasoning Models in Theory of Mind Tasks", "comment": null, "summary": "Theory of Mind (ToM) assesses whether models can infer hidden mental states such as beliefs, desires, and intentions, which is essential for natural social interaction. Although recent progress in Large Reasoning Models (LRMs) has boosted step-by-step inference in mathematics and coding, it is still underexplored whether this benefit transfers to socio-cognitive skills. We present a systematic study of nine advanced Large Language Models (LLMs), comparing reasoning models with non-reasoning models on three representative ToM benchmarks. The results show that reasoning models do not consistently outperform non-reasoning models and sometimes perform worse. A fine-grained analysis reveals three insights. First, slow thinking collapses: accuracy significantly drops as responses grow longer, and larger reasoning budgets hurt performance. Second, moderate and adaptive reasoning benefits performance: constraining reasoning length mitigates failure, while distinct success patterns demonstrate the necessity of dynamic adaptation. Third, option matching shortcut: when multiple choice options are removed, reasoning models improve markedly, indicating reliance on option matching rather than genuine deduction. We also design two intervention approaches: Slow-to-Fast (S2F) adaptive reasoning and Think-to-Match (T2M) shortcut prevention to further verify and mitigate the problems. With all results, our study highlights the advancement of LRMs in formal reasoning (e.g., math, code) cannot be fully transferred to ToM, a typical task in social reasoning. We conclude that achieving robust ToM requires developing unique capabilities beyond existing reasoning methods.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u5fc3\u7406\u7406\u8bba\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u63a8\u7406\u80fd\u529b\u65e0\u6cd5\u5b8c\u5168\u8fc1\u79fb\u5230\u793e\u4f1a\u8ba4\u77e5\u9886\u57df\uff0c\u5b58\u5728\u6162\u601d\u8003\u5d29\u6e83\u3001\u9009\u9879\u5339\u914d\u6377\u5f84\u7b49\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u7b49\u9886\u57df\u7684\u9010\u6b65\u63a8\u7406\u80fd\u529b\u6709\u6240\u63d0\u5347\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u8fd9\u79cd\u4f18\u52bf\u662f\u5426\u80fd\u8fc1\u79fb\u5230\u793e\u4f1a\u8ba4\u77e5\u6280\u80fd\uff08\u5982\u5fc3\u7406\u7406\u8bba\uff09\u4e0a\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u8bc4\u4f30\u63a8\u7406\u6a21\u578b\u5728\u5fc3\u7406\u7406\u8bba\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u5bf99\u4e2a\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u7814\u7a76\uff0c\u6bd4\u8f83\u63a8\u7406\u6a21\u578b\u4e0e\u975e\u63a8\u7406\u6a21\u578b\u5728\u4e09\u4e2a\u4ee3\u8868\u6027\u5fc3\u7406\u7406\u8bba\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8868\u73b0\u3002\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5206\u6790\u63ed\u793a\u6027\u80fd\u5dee\u5f02\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e24\u79cd\u5e72\u9884\u65b9\u6cd5\uff1a\u6162\u5230\u5feb\u81ea\u9002\u5e94\u63a8\u7406\u548c\u601d\u8003\u5230\u5339\u914d\u6377\u5f84\u9884\u9632\u3002", "result": "\u63a8\u7406\u6a21\u578b\u5728\u5fc3\u7406\u7406\u8bba\u4efb\u52a1\u4e0a\u5e76\u4e0d\u603b\u662f\u4f18\u4e8e\u975e\u63a8\u7406\u6a21\u578b\uff0c\u6709\u65f6\u8868\u73b0\u66f4\u5dee\u3002\u5206\u6790\u53d1\u73b0\uff1a1\uff09\u6162\u601d\u8003\u5d29\u6e83\uff1a\u56de\u7b54\u8d8a\u957f\u51c6\u786e\u7387\u8d8a\u4f4e\uff0c\u66f4\u5927\u7684\u63a8\u7406\u9884\u7b97\u53cd\u800c\u635f\u5bb3\u6027\u80fd\uff1b2\uff09\u9002\u5ea6\u81ea\u9002\u5e94\u63a8\u7406\u6709\u76ca\uff1a\u9650\u5236\u63a8\u7406\u957f\u5ea6\u53ef\u7f13\u89e3\u5931\u8d25\uff0c\u4e0d\u540c\u6210\u529f\u6a21\u5f0f\u663e\u793a\u9700\u8981\u52a8\u6001\u9002\u5e94\uff1b3\uff09\u9009\u9879\u5339\u914d\u6377\u5f84\uff1a\u79fb\u9664\u591a\u9879\u9009\u62e9\u9009\u9879\u540e\u63a8\u7406\u6a21\u578b\u8868\u73b0\u663e\u8457\u6539\u5584\uff0c\u8868\u660e\u5176\u4f9d\u8d56\u9009\u9879\u5339\u914d\u800c\u975e\u771f\u6b63\u63a8\u7406\u3002", "conclusion": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u5f62\u5f0f\u63a8\u7406\uff08\u5982\u6570\u5b66\u3001\u7f16\u7a0b\uff09\u65b9\u9762\u7684\u8fdb\u6b65\u65e0\u6cd5\u5b8c\u5168\u8fc1\u79fb\u5230\u5fc3\u7406\u7406\u8bba\u8fd9\u79cd\u5178\u578b\u7684\u793e\u4f1a\u63a8\u7406\u4efb\u52a1\u4e0a\u3002\u5b9e\u73b0\u7a33\u5065\u7684\u5fc3\u7406\u7406\u8bba\u9700\u8981\u5f00\u53d1\u8d85\u8d8a\u73b0\u6709\u63a8\u7406\u65b9\u6cd5\u7684\u72ec\u7279\u80fd\u529b\u3002"}}
{"id": "2602.11016", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11016", "abs": "https://arxiv.org/abs/2602.11016", "authors": ["Jinxin Yu", "Yudong Pan", "Mengdi Wang", "Huawei Li", "Yinhe Han", "Xiaowei Li", "Ying Wang"], "title": "From Buffers to Registers: Unlocking Fine-Grained FlashAttention with Hybrid-Bonded 3D NPU Co-Design", "comment": "Accepted to DATE 2026", "summary": "Transformer-based models dominate modern AI workloads but exacerbate memory bottlenecks due to their quadratic attention complexity and ever-growing model sizes. Existing accelerators, such as Groq and Cerebras, mitigate off-chip traffic with large on-chip caches, while algorithmic innovations such as FlashAttention fuse operators to avoid materializing large attention matrices. However, as off-chip traffic decreases, our measurements show that on-chip SRAM accesses account for over 60% of energy in long-sequence workloads, making cache access the new bottleneck. We propose 3D-Flow, a hybrid-bonded, 3D-stacked spatial accelerator that enables register-to-register communication across vertically partitioned PE tiers. Unlike 2D multi-array architectures limited by NoC-based router-to-router transfers, 3D-Flow leverages sub-10 um vertical TSVs to sustain cycle-level operator pipelining with minimal overhead. On top of this architecture, we design 3D-FlashAttention, a fine-grained scheduling method that balances latency across tiers, forming a bubble-free vertical dataflow without on-chip SRAM roundtrips. Evaluations on Transformer workloads (OPT and QWEN models) show that our 3D spatial accelerator reduces 46-93% energy consumption and achieves 1.4x-7.6x speedups compared to state-of-the-art 2D and 3D designs.", "AI": {"tldr": "\u63d0\u51fa3D-Flow\uff1a\u4e00\u79cd\u57fa\u4e8e3D\u5806\u53e0\u7684\u7a7a\u95f4\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u5782\u76f4\u5206\u5c42\u7684PE\u5c42\u95f4\u5bc4\u5b58\u5668\u5230\u5bc4\u5b58\u5668\u901a\u4fe1\uff0c\u89e3\u51b3Transformer\u6a21\u578b\u4e2d\u7247\u4e0aSRAM\u8bbf\u95ee\u6210\u4e3a\u65b0\u74f6\u9888\u7684\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u80fd\u8017\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "Transformer\u6a21\u578b\u867d\u7136\u4e3b\u5bfc\u73b0\u4ee3AI\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u4f46\u5176\u4e8c\u6b21\u6ce8\u610f\u529b\u590d\u6742\u5ea6\u548c\u4e0d\u65ad\u589e\u957f\u7684\u6a21\u578b\u5c3a\u5bf8\u52a0\u5267\u4e86\u5185\u5b58\u74f6\u9888\u3002\u73b0\u6709\u52a0\u901f\u5668\uff08\u5982Groq\u548cCerebras\uff09\u901a\u8fc7\u5927\u5bb9\u91cf\u7247\u4e0a\u7f13\u5b58\u51cf\u5c11\u7247\u5916\u6d41\u91cf\uff0c\u7b97\u6cd5\u521b\u65b0\uff08\u5982FlashAttention\uff09\u907f\u514d\u751f\u6210\u5927\u578b\u6ce8\u610f\u529b\u77e9\u9635\u3002\u7136\u800c\uff0c\u968f\u7740\u7247\u5916\u6d41\u91cf\u51cf\u5c11\uff0c\u7247\u4e0aSRAM\u8bbf\u95ee\u5728\u957f\u5e8f\u5217\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u5360\u80fd\u801760%\u4ee5\u4e0a\uff0c\u6210\u4e3a\u65b0\u7684\u74f6\u9888\u3002", "method": "\u63d0\u51fa3D-Flow\uff1a\u91c7\u7528\u6df7\u5408\u952e\u54083D\u5806\u53e0\u7684\u7a7a\u95f4\u52a0\u901f\u5668\uff0c\u652f\u6301\u5782\u76f4\u5206\u5c42\u7684\u5904\u7406\u5355\u5143\uff08PE\uff09\u5c42\u95f4\u5bc4\u5b58\u5668\u5230\u5bc4\u5b58\u5668\u901a\u4fe1\u3002\u76f8\u6bd4\u53d7\u9650\u4e8eNoC\u8def\u7531\u5668\u95f4\u4f20\u8f93\u76842D\u591a\u9635\u5217\u67b6\u6784\uff0c3D-Flow\u5229\u7528\u4e9a10\u5fae\u7c73\u5782\u76f4TSV\u7ef4\u6301\u5468\u671f\u7ea7\u7b97\u5b50\u6d41\u6c34\u7ebf\uff0c\u5f00\u9500\u6700\u5c0f\u3002\u5728\u6b64\u57fa\u7840\u4e0a\u8bbe\u8ba13D-FlashAttention\uff1a\u4e00\u79cd\u7ec6\u7c92\u5ea6\u8c03\u5ea6\u65b9\u6cd5\uff0c\u5e73\u8861\u5404\u5c42\u5ef6\u8fdf\uff0c\u5f62\u6210\u65e0\u6c14\u6ce1\u5782\u76f4\u6570\u636e\u6d41\uff0c\u907f\u514d\u7247\u4e0aSRAM\u5f80\u8fd4\u8bbf\u95ee\u3002", "result": "\u5728Transformer\u5de5\u4f5c\u8d1f\u8f7d\uff08OPT\u548cQWEN\u6a21\u578b\uff09\u8bc4\u4f30\u4e2d\uff0c3D\u7a7a\u95f4\u52a0\u901f\u5668\u76f8\u6bd4\u6700\u5148\u8fdb\u76842D\u548c3D\u8bbe\u8ba1\uff0c\u80fd\u8017\u964d\u4f4e46-93%\uff0c\u901f\u5ea6\u63d0\u53471.4-7.6\u500d\u3002", "conclusion": "3D-Flow\u901a\u8fc7\u5782\u76f4\u5806\u53e0\u67b6\u6784\u548c\u5bc4\u5b58\u5668\u5230\u5bc4\u5b58\u5668\u901a\u4fe1\uff0c\u6709\u6548\u89e3\u51b3\u4e86Transformer\u52a0\u901f\u5668\u4e2d\u7247\u4e0aSRAM\u8bbf\u95ee\u6210\u4e3a\u4e3b\u8981\u80fd\u8017\u74f6\u9888\u7684\u95ee\u9898\uff0c\u4e3a\u957f\u5e8f\u5217AI\u5de5\u4f5c\u8d1f\u8f7d\u63d0\u4f9b\u4e86\u9ad8\u6548\u8282\u80fd\u7684\u786c\u4ef6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.10378", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10378", "abs": "https://arxiv.org/abs/2602.10378", "authors": ["Elliot L. Epstein", "Rajat Vadiraj Dwaraknath", "John Winnicki"], "title": "Flash-SD-KDE: Accelerating SD-KDE with Tensor Cores", "comment": "11 pages", "summary": "Score-debiased kernel density estimation (SD-KDE) achieves improved asymptotic convergence rates over classical KDE, but its use of an empirical score has made it significantly slower in practice. We show that by re-ordering the SD-KDE computation to expose matrix-multiplication structure, Tensor Cores can be used to accelerate the GPU implementation. On a 32k-sample 16-dimensional problem, our approach runs up to $47\\times$ faster than a strong SD-KDE GPU baseline and $3{,}300\\times$ faster than scikit-learn's KDE. On a larger 1M-sample 16-dimensional task evaluated on 131k queries, Flash-SD-KDE completes in $2.3$ s on a single GPU, making score-debiased density estimation practical at previously infeasible scales.", "AI": {"tldr": "Flash-SD-KDE\u901a\u8fc7\u91cd\u65b0\u7ec4\u7ec7\u8ba1\u7b97\u7ed3\u6784\u5229\u7528Tensor Cores\u52a0\u901fGPU\u5b9e\u73b0\uff0c\u572832k\u6837\u672c16\u7ef4\u95ee\u9898\u4e0a\u6bd4\u57fa\u7ebf\u5feb47\u500d\uff0c\u57281M\u6837\u672c\u4efb\u52a1\u4e0a2.3\u79d2\u5b8c\u6210\uff0c\u4f7f\u5206\u6570\u53bb\u504f\u5bc6\u5ea6\u4f30\u8ba1\u8fbe\u5230\u5b9e\u7528\u89c4\u6a21\u3002", "motivation": "\u5206\u6570\u53bb\u504f\u6838\u5bc6\u5ea6\u4f30\u8ba1(SD-KDE)\u867d\u7136\u6bd4\u7ecf\u5178KDE\u6709\u66f4\u597d\u7684\u6e10\u8fd1\u6536\u655b\u7387\uff0c\u4f46\u7531\u4e8e\u4f7f\u7528\u7ecf\u9a8c\u5206\u6570\uff0c\u5b9e\u9645\u8ba1\u7b97\u901f\u5ea6\u663e\u8457\u8f83\u6162\uff0c\u9650\u5236\u4e86\u5176\u5728\u5927\u89c4\u6a21\u95ee\u9898\u4e0a\u7684\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u91cd\u65b0\u7ec4\u7ec7SD-KDE\u8ba1\u7b97\u4ee5\u66b4\u9732\u77e9\u9635\u4e58\u6cd5\u7ed3\u6784\uff0c\u5229\u7528GPU\u7684Tensor Cores\u8fdb\u884c\u52a0\u901f\uff0c\u5f00\u53d1\u4e86Flash-SD-KDE\u5b9e\u73b0\u3002", "result": "\u572832k\u6837\u672c16\u7ef4\u95ee\u9898\u4e0a\uff0c\u6bd4\u5f3aSD-KDE GPU\u57fa\u7ebf\u5feb47\u500d\uff0c\u6bd4scikit-learn\u7684KDE\u5feb3300\u500d\uff1b\u57281M\u6837\u672c16\u7ef4\u4efb\u52a1\u4e0a\uff08131k\u67e5\u8be2\uff09\uff0c\u5355GPU\u4ec5\u97002.3\u79d2\u5b8c\u6210\u3002", "conclusion": "Flash-SD-KDE\u4f7f\u5206\u6570\u53bb\u504f\u5bc6\u5ea6\u4f30\u8ba1\u5728\u4ee5\u524d\u4e0d\u53ef\u884c\u7684\u89c4\u6a21\u4e0a\u53d8\u5f97\u5b9e\u7528\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2602.10134", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.10134", "abs": "https://arxiv.org/abs/2602.10134", "authors": ["Zhiyu Sun", "Minrui Luo", "Yu Wang", "Zhili Chen", "Tianxing He"], "title": "Reverse-Engineering Model Editing on Language Models", "comment": null, "summary": "Large language models (LLMs) are pretrained on corpora containing trillions of tokens and, therefore, inevitably memorize sensitive information. Locate-then-edit methods, as a mainstream paradigm of model editing, offer a promising solution by modifying model parameters without retraining. However, in this work, we reveal a critical vulnerability of this paradigm: the parameter updates inadvertently serve as a side channel, enabling attackers to recover the edited data. We propose a two-stage reverse-engineering attack named \\textit{KSTER} (\\textbf{K}ey\\textbf{S}paceRecons\\textbf{T}ruction-then-\\textbf{E}ntropy\\textbf{R}eduction) that leverages the low-rank structure of these updates. First, we theoretically show that the row space of the update matrix encodes a ``fingerprint\" of the edited subjects, enabling accurate subject recovery via spectral analysis. Second, we introduce an entropy-based prompt recovery attack that reconstructs the semantic context of the edit. Extensive experiments on multiple LLMs demonstrate that our attacks can recover edited data with high success rates. Furthermore, we propose \\textit{subspace camouflage}, a defense strategy that obfuscates the update fingerprint with semantic decoys. This approach effectively mitigates reconstruction risks without compromising editing utility. Our code is available at https://github.com/reanatom/EditingAtk.git.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63ed\u793a\u4e86\u4e3b\u6d41\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u7684\u4e00\u4e2a\u5173\u952e\u5b89\u5168\u6f0f\u6d1e\uff1a\u53c2\u6570\u66f4\u65b0\u4f1a\u65e0\u610f\u4e2d\u6210\u4e3a\u4fa7\u4fe1\u9053\uff0c\u4f7f\u653b\u51fb\u8005\u80fd\u591f\u6062\u590d\u88ab\u7f16\u8f91\u7684\u6570\u636e\u3002\u4f5c\u8005\u63d0\u51fa\u4e86KSTER\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5b50\u7a7a\u95f4\u4f2a\u88c5\u9632\u5fa1\u7b56\u7565\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f1a\u8bb0\u5fc6\u654f\u611f\u4fe1\u606f\uff0c\u5b9a\u4f4d-\u7f16\u8f91\u65b9\u6cd5\u4f5c\u4e3a\u4e3b\u6d41\u6a21\u578b\u7f16\u8f91\u8303\u5f0f\uff0c\u901a\u8fc7\u4fee\u6539\u6a21\u578b\u53c2\u6570\u800c\u4e0d\u91cd\u65b0\u8bad\u7ec3\u6765\u4fdd\u62a4\u9690\u79c1\u3002\u7136\u800c\uff0c\u4f5c\u8005\u53d1\u73b0\u8fd9\u79cd\u65b9\u6cd5\u7684\u53c2\u6570\u66f4\u65b0\u4f1a\u65e0\u610f\u4e2d\u6210\u4e3a\u4fa7\u4fe1\u9053\uff0c\u4f7f\u653b\u51fb\u8005\u80fd\u591f\u6062\u590d\u88ab\u7f16\u8f91\u7684\u6570\u636e\uff0c\u8fd9\u6784\u6210\u4e86\u4e25\u91cd\u7684\u5b89\u5168\u5a01\u80c1\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u9636\u6bb5\u9006\u5411\u5de5\u7a0b\u653b\u51fbKSTER\uff1a1\uff09\u5229\u7528\u66f4\u65b0\u77e9\u9635\u7684\u4f4e\u79e9\u7ed3\u6784\uff0c\u901a\u8fc7\u8c31\u5206\u6790\u4ece\u66f4\u65b0\u77e9\u9635\u7684\u884c\u7a7a\u95f4\u6062\u590d\u7f16\u8f91\u4e3b\u9898\uff1b2\uff09\u57fa\u4e8e\u71b5\u7684\u63d0\u793a\u6062\u590d\u653b\u51fb\uff0c\u91cd\u5efa\u7f16\u8f91\u7684\u8bed\u4e49\u4e0a\u4e0b\u6587\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u5b50\u7a7a\u95f4\u4f2a\u88c5\u9632\u5fa1\u7b56\u7565\uff0c\u901a\u8fc7\u8bed\u4e49\u8bf1\u9975\u6df7\u6dc6\u66f4\u65b0\u6307\u7eb9\u3002", "result": "\u5728\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cKSTER\u653b\u51fb\u80fd\u591f\u4ee5\u9ad8\u6210\u529f\u7387\u6062\u590d\u88ab\u7f16\u8f91\u7684\u6570\u636e\u3002\u5b50\u7a7a\u95f4\u4f2a\u88c5\u9632\u5fa1\u7b56\u7565\u5728\u4e0d\u5f71\u54cd\u7f16\u8f91\u6548\u7528\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u91cd\u5efa\u98ce\u9669\u3002", "conclusion": "\u5b9a\u4f4d-\u7f16\u8f91\u65b9\u6cd5\u5b58\u5728\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u53c2\u6570\u66f4\u65b0\u4f1a\u6cc4\u9732\u88ab\u7f16\u8f91\u7684\u6570\u636e\u3002KSTER\u653b\u51fb\u5c55\u793a\u4e86\u8fd9\u79cd\u5a01\u80c1\u7684\u73b0\u5b9e\u6027\uff0c\u800c\u5b50\u7a7a\u95f4\u4f2a\u88c5\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u9632\u5fa1\u673a\u5236\uff0c\u4e3a\u5b89\u5168\u6a21\u578b\u7f16\u8f91\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2602.10635", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10635", "abs": "https://arxiv.org/abs/2602.10635", "authors": ["Keane Ong", "Sabri Boughorbel", "Luwei Xiao", "Chanakya Ekbote", "Wei Dai", "Ao Qu", "Jingyao Wu", "Rui Mao", "Ehsan Hoque", "Erik Cambria", "Gianmarco Mengaldo", "Paul Pu Liang"], "title": "OmniSapiens: A Foundation Model for Social Behavior Processing via Heterogeneity-Aware Relative Policy Optimization", "comment": null, "summary": "To develop socially intelligent AI, existing approaches typically model human behavioral dimensions (e.g., affective, cognitive, or social attributes) in isolation. Although useful, task-specific modeling often increases training costs and limits generalization across behavioral settings. Recent reasoning RL methods facilitate training a single unified model across multiple behavioral tasks, but do not explicitly address learning across different heterogeneous behavioral data. To address this gap, we introduce Heterogeneity-Aware Relative Policy Optimization (HARPO), an RL method that balances leaning across heterogeneous tasks and samples. This is achieved by modulating advantages to ensure that no single task or sample carries disproportionate influence during policy optimization. Using HARPO, we develop and release Omnisapiens-7B 2.0, a foundation model for social behavior processing. Relative to existing behavioral foundation models, Omnisapiens-7B 2.0 achieves the strongest performance across behavioral tasks, with gains of up to +16.85% and +9.37% on multitask and held-out settings respectively, while producing more explicit and robust reasoning traces. We also validate HARPO against recent RL methods, where it achieves the most consistently strong performance across behavioral tasks.", "AI": {"tldr": "HARPO\u65b9\u6cd5\u901a\u8fc7\u8c03\u8282\u4f18\u52bf\u51fd\u6570\u5e73\u8861\u5f02\u6784\u4efb\u52a1\u548c\u6837\u672c\u7684\u5b66\u4e60\uff0c\u8bad\u7ec3\u51faOmnisapiens-7B 2.0\u793e\u4ea4\u884c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5b64\u7acb\u5730\u5efa\u6a21\u4eba\u7c7b\u884c\u4e3a\u7ef4\u5ea6\uff08\u60c5\u611f\u3001\u8ba4\u77e5\u6216\u793e\u4f1a\u5c5e\u6027\uff09\uff0c\u4efb\u52a1\u7279\u5b9a\u5efa\u6a21\u589e\u52a0\u4e86\u8bad\u7ec3\u6210\u672c\u5e76\u9650\u5236\u4e86\u8de8\u884c\u4e3a\u8bbe\u7f6e\u7684\u6cdb\u5316\u80fd\u529b\u3002\u867d\u7136\u6700\u8fd1\u7684\u63a8\u7406RL\u65b9\u6cd5\u652f\u6301\u5728\u591a\u4e2a\u884c\u4e3a\u4efb\u52a1\u4e0a\u8bad\u7ec3\u7edf\u4e00\u6a21\u578b\uff0c\u4f46\u672a\u660e\u786e\u89e3\u51b3\u8de8\u5f02\u6784\u884c\u4e3a\u6570\u636e\u7684\u5b66\u4e60\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5f02\u6784\u611f\u77e5\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08HARPO\uff09\uff0c\u8fd9\u662f\u4e00\u79cdRL\u65b9\u6cd5\uff0c\u901a\u8fc7\u8c03\u8282\u4f18\u52bf\u51fd\u6570\u6765\u786e\u4fdd\u5728\u7b56\u7565\u4f18\u5316\u8fc7\u7a0b\u4e2d\u6ca1\u6709\u4efb\u4f55\u5355\u4e2a\u4efb\u52a1\u6216\u6837\u672c\u4ea7\u751f\u4e0d\u6210\u6bd4\u4f8b\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u5e73\u8861\u8de8\u5f02\u6784\u4efb\u52a1\u548c\u6837\u672c\u7684\u5b66\u4e60\u3002", "result": "\u4f7f\u7528HARPO\u5f00\u53d1\u4e86Omnisapiens-7B 2.0\u793e\u4ea4\u884c\u4e3a\u5904\u7406\u57fa\u7840\u6a21\u578b\u3002\u76f8\u5bf9\u4e8e\u73b0\u6709\u884c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u5728\u591a\u4efb\u52a1\u548c\u4fdd\u7559\u8bbe\u7f6e\u4e0a\u5206\u522b\u5b9e\u73b0\u4e86\u9ad8\u8fbe+16.85%\u548c+9.37%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u4ea7\u751f\u66f4\u660e\u786e\u548c\u9c81\u68d2\u7684\u63a8\u7406\u8f68\u8ff9\u3002HARPO\u5728\u884c\u4e3a\u4efb\u52a1\u4e0a\u4e5f\u6bd4\u6700\u8fd1\u7684RL\u65b9\u6cd5\u8868\u73b0\u66f4\u4e00\u81f4\u3002", "conclusion": "HARPO\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u5f02\u6784\u884c\u4e3a\u6570\u636e\u5b66\u4e60\u7684\u95ee\u9898\uff0c\u8bad\u7ec3\u51fa\u7684Omnisapiens-7B 2.0\u6a21\u578b\u5728\u793e\u4ea4\u884c\u4e3a\u5904\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u5f00\u53d1\u793e\u4f1a\u667a\u80fdAI\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.10486", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.10486", "abs": "https://arxiv.org/abs/2602.10486", "authors": ["Vijay K. Garg", "Rohan Garg"], "title": "Computing Least Fixed Points with Overwrite Semantics in Parallel and Distributed Systems", "comment": null, "summary": "We present methods to compute least fixed points of multiple monotone inflationary functions in parallel and distributed settings. While the classic Knaster-Tarski theorem addresses a single function with sequential iteration, modern computing systems require parallel execution with overwrite semantics, non-atomic updates, and stale reads. We prove three convergence theorems under progressively relaxed synchronization: (1) Interleaving semantics with fair scheduling, (2) Parallel execution with update-only-on-change semantics (processes write only on those coordinates whose values change), and (3) Distributed execution with bounded staleness (updates propagate within $T$ rounds) and $i$-locality (each process modifies only its own component).\n  Our approach differs from prior work in fundamental ways: Cousot-Cousot's chaotic iteration uses join-based merges that preserve information. Instead, we use coordinate-wise overwriting. Bertsekas's asynchronous methods assume contractions. We use coordinate-wise overwriting with structural constraints (locality, bounded staleness) instead. Applications include parallel and distributed algorithms for the transitive closure, stable marriage, shortest paths, and fair division with subsidy problems. Our results provide the first exact least-fixed-point convergence guarantees for overwrite-based parallel updates without join operations or contraction assumptions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u5728\u5e76\u884c\u548c\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u8ba1\u7b97\u591a\u4e2a\u5355\u8c03\u81a8\u80c0\u51fd\u6570\u6700\u5c0f\u4e0d\u52a8\u70b9\u7684\u65b9\u6cd5\uff0c\u9488\u5bf9\u8986\u76d6\u8bed\u4e49\u3001\u975e\u539f\u5b50\u66f4\u65b0\u548c\u8fc7\u65f6\u8bfb\u53d6\u7b49\u73b0\u4ee3\u8ba1\u7b97\u7279\u6027\uff0c\u8bc1\u660e\u4e86\u4e09\u79cd\u6e10\u8fdb\u653e\u677e\u540c\u6b65\u6761\u4ef6\u4e0b\u7684\u6536\u655b\u5b9a\u7406\u3002", "motivation": "\u7ecf\u5178Knaster-Tarski\u5b9a\u7406\u5904\u7406\u5355\u51fd\u6570\u987a\u5e8f\u8fed\u4ee3\uff0c\u800c\u73b0\u4ee3\u8ba1\u7b97\u7cfb\u7edf\u9700\u8981\u5e76\u884c\u6267\u884c\uff0c\u5177\u6709\u8986\u76d6\u8bed\u4e49\u3001\u975e\u539f\u5b50\u66f4\u65b0\u548c\u8fc7\u65f6\u8bfb\u53d6\u7b49\u7279\u70b9\u3002\u73b0\u6709\u65b9\u6cd5\u5982Cousot-Cousot\u7684\u6df7\u6c8c\u8fed\u4ee3\u4f7f\u7528\u57fa\u4e8e\u8fde\u63a5\u7684\u5408\u5e76\u64cd\u4f5c\uff0cBertsekas\u7684\u5f02\u6b65\u65b9\u6cd5\u5047\u8bbe\u6536\u7f29\u6761\u4ef6\uff0c\u90fd\u4e0d\u9002\u7528\u4e8e\u8986\u76d6\u8bed\u4e49\u7684\u5e76\u884c\u66f4\u65b0\u573a\u666f\u3002", "method": "\u91c7\u7528\u5750\u6807\u8986\u76d6\u65b9\u6cd5\uff08\u800c\u975e\u8fde\u63a5\u5408\u5e76\uff09\uff0c\u5728\u4e09\u79cd\u6e10\u8fdb\u653e\u677e\u7684\u540c\u6b65\u6761\u4ef6\u4e0b\u8bc1\u660e\u6536\u655b\u6027\uff1a1\uff09\u4ea4\u9519\u8bed\u4e49\u4e0e\u516c\u5e73\u8c03\u5ea6\uff1b2\uff09\u4ec5\u5f53\u503c\u53d8\u5316\u65f6\u66f4\u65b0\u7684\u5e76\u884c\u6267\u884c\uff1b3\uff09\u5177\u6709\u6709\u9650\u8fc7\u65f6\u6027\uff08\u66f4\u65b0\u5728T\u8f6e\u5185\u4f20\u64ad\uff09\u548ci-\u5c40\u90e8\u6027\uff08\u6bcf\u4e2a\u8fdb\u7a0b\u53ea\u4fee\u6539\u81ea\u8eab\u7ec4\u4ef6\uff09\u7684\u5206\u5e03\u5f0f\u6267\u884c\u3002", "result": "\u8bc1\u660e\u4e86\u4e09\u79cd\u6536\u655b\u5b9a\u7406\uff0c\u4e3a\u8986\u76d6\u8bed\u4e49\u7684\u5e76\u884c\u66f4\u65b0\u63d0\u4f9b\u4e86\u9996\u4e2a\u7cbe\u786e\u7684\u6700\u5c0f\u4e0d\u52a8\u70b9\u6536\u655b\u4fdd\u8bc1\uff0c\u65e0\u9700\u8fde\u63a5\u64cd\u4f5c\u6216\u6536\u7f29\u5047\u8bbe\u3002\u5e94\u7528\u5305\u62ec\u4f20\u9012\u95ed\u5305\u3001\u7a33\u5b9a\u5a5a\u59fb\u3001\u6700\u77ed\u8def\u5f84\u548c\u5e26\u8865\u8d34\u7684\u516c\u5e73\u5206\u914d\u7b49\u5e76\u884c\u5206\u5e03\u5f0f\u7b97\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u4e3a\u57fa\u4e8e\u8986\u76d6\u7684\u5e76\u884c\u66f4\u65b0\u63d0\u4f9b\u4e86\u7cbe\u786e\u7684\u6700\u5c0f\u4e0d\u52a8\u70b9\u6536\u655b\u4fdd\u8bc1\uff0c\u586b\u8865\u4e86\u7ecf\u5178\u4e0d\u52a8\u70b9\u7406\u8bba\u4e0e\u73b0\u4ee3\u5e76\u884c\u5206\u5e03\u5f0f\u8ba1\u7b97\u9700\u6c42\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u4e3a\u76f8\u5173\u7b97\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.10699", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10699", "abs": "https://arxiv.org/abs/2602.10699", "authors": ["Jie Jiang", "Yangru Huang", "Zeyu Wang", "Changping Wang", "Yuling Xiong", "Jun Zhang", "Huan Yu"], "title": "Spend Search Where It Pays: Value-Guided Structured Sampling and Optimization for Generative Recommendation", "comment": null, "summary": "Generative recommendation via autoregressive models has unified retrieval and ranking into a single conditional generation framework. However, fine-tuning these models with Reinforcement Learning (RL) often suffers from a fundamental probability-reward mismatch. Conventional likelihood-dominated decoding (e.g., beam search) exhibits a myopic bias toward locally probable prefixes, which causes two critical failures: (1) insufficient exploration, where high-reward items in low-probability branches are prematurely pruned and rarely sampled, and (2) advantage compression, where trajectories sharing high-probability prefixes receive highly correlated rewards with low within-group variance, yielding a weak comparative signal for RL. To address these challenges, we propose V-STAR, a Value-guided Sampling and Tree-structured Advantage Reinforcement framework. V-STAR forms a self-evolving loop via two synergistic components. First, a Value-Guided Efficient Decoding (VED) is developed to identify decisive nodes and selectively deepen high-potential prefixes. This improves exploration efficiency without exhaustive tree search. Second, we propose Sibling-GRPO, which exploits the induced tree topology to compute sibling-relative advantages and concentrates learning signals on decisive branching decisions. Extensive experiments on both offline and online datasets demonstrate that V-STAR outperforms state-of-the-art baselines, delivering superior accuracy and candidate-set diversity under strict latency constraints.", "AI": {"tldr": "V-STAR\u6846\u67b6\u901a\u8fc7\u4ef7\u503c\u5f15\u5bfc\u91c7\u6837\u548c\u6811\u72b6\u4f18\u52bf\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u751f\u6210\u5f0f\u63a8\u8350\u4e2dRL\u8bad\u7ec3\u7684\u6982\u7387-\u5956\u52b1\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u63d0\u5347\u63a2\u7d22\u6548\u7387\u548c\u591a\u6837\u6027", "motivation": "\u751f\u6210\u5f0f\u63a8\u8350\u7684\u81ea\u56de\u5f52\u6a21\u578b\u5728RL\u5fae\u8c03\u4e2d\u5b58\u5728\u6982\u7387-\u5956\u52b1\u4e0d\u5339\u914d\u95ee\u9898\uff1a\u4f20\u7edf\u57fa\u4e8e\u4f3c\u7136\u7684\u89e3\u7801\uff08\u5982\u675f\u641c\u7d22\uff09\u5bf9\u5c40\u90e8\u6982\u7387\u9ad8\u7684\u524d\u7f00\u5b58\u5728\u77ed\u89c6\u504f\u89c1\uff0c\u5bfc\u81f4\u63a2\u7d22\u4e0d\u8db3\uff08\u9ad8\u5956\u52b1\u4f46\u4f4e\u6982\u7387\u5206\u652f\u88ab\u8fc7\u65e9\u526a\u679d\uff09\u548c\u4f18\u52bf\u538b\u7f29\uff08\u5171\u4eab\u9ad8\u6982\u7387\u524d\u7f00\u7684\u8f68\u8ff9\u5956\u52b1\u9ad8\u5ea6\u76f8\u5173\uff0c\u65b9\u5dee\u4f4e\uff0cRL\u4fe1\u53f7\u5f31\uff09", "method": "\u63d0\u51faV-STAR\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u534f\u540c\u7ec4\u4ef6\uff1a1\uff09\u4ef7\u503c\u5f15\u5bfc\u9ad8\u6548\u89e3\u7801\uff08VED\uff09\uff0c\u8bc6\u522b\u51b3\u7b56\u8282\u70b9\u5e76\u9009\u62e9\u6027\u52a0\u6df1\u9ad8\u6f5c\u529b\u524d\u7f00\uff0c\u63d0\u5347\u63a2\u7d22\u6548\u7387\uff1b2\uff09Sibling-GRPO\uff0c\u5229\u7528\u8bf1\u5bfc\u7684\u6811\u62d3\u6251\u8ba1\u7b97\u5144\u5f1f\u76f8\u5bf9\u4f18\u52bf\uff0c\u5c06\u5b66\u4e60\u4fe1\u53f7\u96c6\u4e2d\u5728\u51b3\u7b56\u5206\u652f\u51b3\u7b56\u4e0a", "result": "\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cV-STAR\u5728\u4e25\u683c\u5ef6\u8fdf\u7ea6\u675f\u4e0b\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63d0\u4f9b\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u5019\u9009\u96c6\u591a\u6837\u6027", "conclusion": "V-STAR\u901a\u8fc7\u4ef7\u503c\u5f15\u5bfc\u91c7\u6837\u548c\u6811\u72b6\u4f18\u52bf\u5f3a\u5316\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u4e2dRL\u8bad\u7ec3\u7684\u6982\u7387-\u5956\u52b1\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u63a2\u7d22\u6548\u7387\u548c\u6027\u80fd\u8868\u73b0"}}
{"id": "2602.11088", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2602.11088", "abs": "https://arxiv.org/abs/2602.11088", "authors": ["Abhishek Saini", "Haolin Jiang", "Hang Liu"], "title": "Vulnerabilities in Partial TEE-Shielded LLM Inference with Precomputed Noise", "comment": null, "summary": "The deployment of large language models (LLMs) on third-party devices requires new ways to protect model intellectual property. While Trusted Execution Environments (TEEs) offer a promising solution, their performance limits can lead to a critical compromise: using a precomputed, static secret basis to accelerate cryptographic operations. We demonstrate that this mainstream design pattern introduces a classic cryptographic flaw, the reuse of secret keying material, into the system's protocol. We prove its vulnerability with two distinct attacks: First, our attack on a model confidentiality system achieves a full confidentiality break by recovering its secret permutations and model weights. Second, our integrity attack completely bypasses the integrity checks of systems like Soter and TSQP. We demonstrate the practicality of our attacks against state-of-the-art LLMs, recovering a layer's secrets from a LLaMA-3 8B model in about 6 minutes and showing the attack scales to compromise 405B-parameter LLMs across a variety of configurations.", "AI": {"tldr": "\u4e3b\u6d41TEE\u52a0\u901f\u8bbe\u8ba1\u4e2d\u7684\u9759\u6001\u5bc6\u94a5\u91cd\u7528\u6f0f\u6d1e\u5bfc\u81f4LLM\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u7cfb\u7edf\u88ab\u5b8c\u5168\u653b\u7834\uff0c\u5305\u62ec\u6a21\u578b\u6743\u91cd\u6062\u590d\u548c\u5b8c\u6574\u6027\u68c0\u67e5\u7ed5\u8fc7", "motivation": "\u7b2c\u4e09\u65b9\u8bbe\u5907\u90e8\u7f72LLM\u9700\u8981\u4fdd\u62a4\u6a21\u578b\u77e5\u8bc6\u4ea7\u6743\uff0cTEE\u867d\u7136\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5176\u6027\u80fd\u9650\u5236\u5bfc\u81f4\u8bbe\u8ba1\u4e2d\u4f7f\u7528\u9884\u8ba1\u7b97\u7684\u9759\u6001\u5bc6\u94a5\u57fa\u7840\u6765\u52a0\u901f\u52a0\u5bc6\u64cd\u4f5c\uff0c\u8fd9\u79cd\u4e3b\u6d41\u8bbe\u8ba1\u6a21\u5f0f\u5f15\u5165\u4e86\u7ecf\u5178\u7684\u5bc6\u7801\u5b66\u6f0f\u6d1e", "method": "\u901a\u8fc7\u4e24\u79cd\u4e0d\u540c\u7684\u653b\u51fb\u65b9\u5f0f\uff1a1\uff09\u9488\u5bf9\u6a21\u578b\u4fdd\u5bc6\u7cfb\u7edf\u7684\u653b\u51fb\uff0c\u901a\u8fc7\u6062\u590d\u5176\u79d8\u5bc6\u7f6e\u6362\u548c\u6a21\u578b\u6743\u91cd\u5b9e\u73b0\u5b8c\u5168\u4fdd\u5bc6\u7834\u574f\uff1b2\uff09\u5b8c\u6574\u6027\u653b\u51fb\uff0c\u5b8c\u5168\u7ed5\u8fc7Soter\u548cTSQP\u7b49\u7cfb\u7edf\u7684\u5b8c\u6574\u6027\u68c0\u67e5", "result": "\u653b\u51fb\u5177\u6709\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u9488\u5bf9\u6700\u5148\u8fdb\u7684LLM\uff0c\u5728\u7ea66\u5206\u949f\u5185\u6062\u590dLLaMA-3 8B\u6a21\u578b\u4e00\u5c42\u7684\u79d8\u5bc6\uff0c\u5e76\u5c55\u793a\u653b\u51fb\u53ef\u6269\u5c55\u5230\u5728\u5404\u79cd\u914d\u7f6e\u4e0b\u653b\u7834405B\u53c2\u6570\u7684LLM", "conclusion": "\u4e3b\u6d41TEE\u52a0\u901f\u8bbe\u8ba1\u4e2d\u7684\u9759\u6001\u5bc6\u94a5\u91cd\u7528\u6a21\u5f0f\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u548c\u8bbe\u8ba1\u66f4\u5b89\u5168\u7684LLM\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u65b9\u6848"}}
{"id": "2602.10729", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.10729", "abs": "https://arxiv.org/abs/2602.10729", "authors": ["Youhe Jiang", "Fangcheng Fu", "Eiko Yoneki"], "title": "BOute: Cost-Efficient LLM Serving with Heterogeneous LLMs and GPUs via Multi-Objective Bayesian Optimization", "comment": "MLSys 2026", "summary": "The rapid growth of large language model (LLM) deployments has made cost-efficient serving systems essential. Recent efforts to enhance system cost-efficiency adopt two main perspectives: (i) An algorithmic perspective that exploits heterogeneous model capabilities to route simpler queries to lower-cost models and complex queries to higher-cost models (i.e., heterogeneous query routing); and (ii) a systems perspective that utilizes heterogeneous GPU resources as cost-effective alternatives to homogeneous high-end GPUs (i.e., heterogeneous model deployment). However, algorithm-system co-design for cost-efficient LLM serving necessitates sophisticated management: (i) Determining optimal query routing strategies under latency and quality requirements, (ii) configuring model deployment across heterogeneous GPUs with appropriate resource allocation and parallelism strategies, and (iii) co-optimizing routing and deployment decisions to maximize overall system performance. To address these challenges, we present BOute, a quality-aware scheduling system that jointly exploits heterogeneous model and GPU capabilities for cost-efficient LLM serving. BOute employs a multi-objective Bayesian optimization (MOBO) framework to co-optimize the routing strategy and model deployment, thereby maximizing the cost-efficiency of the serving system while guaranteeing response quality. Evaluation results demonstrate that BOute outperforms state-of-the-art LLM serving systems by up to 157% and 59% on average under identical cost budgets and quality requirements, or reducing serving costs by 15%-61% (38% on average) while maintaining the same performance targets, validating its effectiveness in achieving cost-efficient LLM serving.", "AI": {"tldr": "BOute\u662f\u4e00\u4e2a\u8d28\u91cf\u611f\u77e5\u8c03\u5ea6\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u5229\u7528\u5f02\u6784\u6a21\u578b\u548cGPU\u80fd\u529b\uff0c\u4f7f\u7528\u591a\u76ee\u6807\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\u5171\u540c\u4f18\u5316\u8def\u7531\u7b56\u7565\u548c\u6a21\u578b\u90e8\u7f72\uff0c\u5b9e\u73b0\u6210\u672c\u9ad8\u6548\u7684LLM\u670d\u52a1\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u7684\u5feb\u901f\u589e\u957f\uff0c\u9700\u8981\u6210\u672c\u9ad8\u6548\u7684\u670d\u52a1\u7cfb\u7edf\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4ece\u7b97\u6cd5\u89d2\u5ea6\u5229\u7528\u5f02\u6784\u6a21\u578b\u80fd\u529b\u8fdb\u884c\u67e5\u8be2\u8def\u7531\uff0c\u8981\u4e48\u4ece\u7cfb\u7edf\u89d2\u5ea6\u5229\u7528\u5f02\u6784GPU\u8d44\u6e90\u8fdb\u884c\u6a21\u578b\u90e8\u7f72\uff0c\u4f46\u7f3a\u4e4f\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u6765\u6700\u5927\u5316\u6574\u4f53\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u63d0\u51faBOute\u7cfb\u7edf\uff0c\u91c7\u7528\u591a\u76ee\u6807\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\uff0c\u5171\u540c\u4f18\u5316\u8def\u7531\u7b56\u7565\u548c\u6a21\u578b\u90e8\u7f72\u914d\u7f6e\u3002\u7cfb\u7edf\u9700\u8981\u786e\u5b9a\u5728\u5ef6\u8fdf\u548c\u8d28\u91cf\u8981\u6c42\u4e0b\u7684\u6700\u4f18\u67e5\u8be2\u8def\u7531\u7b56\u7565\uff0c\u5728\u5f02\u6784GPU\u4e0a\u914d\u7f6e\u6a21\u578b\u90e8\u7f72\uff0c\u5e76\u534f\u540c\u4f18\u5316\u8def\u7531\u548c\u90e8\u7f72\u51b3\u7b56\u3002", "result": "\u5728\u76f8\u540c\u6210\u672c\u9884\u7b97\u548c\u8d28\u91cf\u8981\u6c42\u4e0b\uff0cBOute\u6bd4\u6700\u5148\u8fdb\u7684LLM\u670d\u52a1\u7cfb\u7edf\u6027\u80fd\u63d0\u5347\u6700\u9ad8157%\uff0c\u5e73\u574759%\uff1b\u6216\u5728\u4fdd\u6301\u76f8\u540c\u6027\u80fd\u76ee\u6807\u4e0b\uff0c\u670d\u52a1\u6210\u672c\u964d\u4f4e15%-61%\uff0c\u5e73\u574738%\u3002", "conclusion": "BOute\u901a\u8fc7\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\uff0c\u6709\u6548\u5b9e\u73b0\u4e86\u6210\u672c\u9ad8\u6548\u7684LLM\u670d\u52a1\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.10142", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.10142", "abs": "https://arxiv.org/abs/2602.10142", "authors": ["Molly Campbell", "Ajay Kumar Shrestha"], "title": "Privacy by Voice: Modeling Youth Privacy-Protective Behavior in Smart Voice Assistants", "comment": "To appear in the IEEE ICAIIC 2026 proceedings", "summary": "Smart Voice Assistants (SVAs) are deeply embedded in the lives of youth, yet the mechanisms driving the privacy-protective behaviors among young users remain poorly understood. This study investigates how Canadian youth (aged 16-24) negotiate privacy with SVAs by developing and testing a structural model grounded in five key constructs: perceived privacy risks (PPR), perceived benefits (PPBf), algorithmic transparency and trust (ATT), privacy self-efficacy (PSE), and privacy-protective behaviors (PPB). A cross-sectional survey of N=469 youth was analyzed using partial least squares structural equation modeling. Results reveal that PSE is the strongest predictor of PPB, while the effect of ATT on PPB is fully mediated by PSE. This identifies a critical efficacy gap, where youth's confidence must first be built up for them to act. The model confirms that PPBf directly discourages protective action, yet also indirectly fosters it by slightly boosting self-efficacy. These findings empirically validate and extend earlier qualitative work, quantifying how policy overload and hidden controls erode the self-efficacy necessary for protective action. This study contributes an evidence-based pathway from perception to action and translates it into design imperatives that empower young digital citizens without sacrificing the utility of SVAs.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\u5206\u6790\u52a0\u62ff\u5927\u9752\u5c11\u5e74\uff0816-24\u5c81\uff09\u4e0e\u667a\u80fd\u8bed\u97f3\u52a9\u624b\u7684\u9690\u79c1\u534f\u5546\u673a\u5236\uff0c\u53d1\u73b0\u9690\u79c1\u81ea\u6211\u6548\u80fd\u662f\u9690\u79c1\u4fdd\u62a4\u884c\u4e3a\u7684\u6700\u5f3a\u9884\u6d4b\u56e0\u5b50\uff0c\u800c\u7b97\u6cd5\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u901a\u8fc7\u81ea\u6211\u6548\u80fd\u5b8c\u5168\u4e2d\u4ecb\u5f71\u54cd\u4fdd\u62a4\u884c\u4e3a\u3002", "motivation": "\u667a\u80fd\u8bed\u97f3\u52a9\u624b\u5df2\u6df1\u5ea6\u878d\u5165\u9752\u5c11\u5e74\u751f\u6d3b\uff0c\u4f46\u9752\u5c11\u5e74\u7528\u6237\u9690\u79c1\u4fdd\u62a4\u884c\u4e3a\u7684\u9a71\u52a8\u673a\u5236\u4ecd\u4e0d\u6e05\u695a\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u52a0\u62ff\u5927\u9752\u5c11\u5e74\u5982\u4f55\u4e0e\u667a\u80fd\u8bed\u97f3\u52a9\u624b\u8fdb\u884c\u9690\u79c1\u534f\u5546\uff0c\u7406\u89e3\u4ece\u9690\u79c1\u611f\u77e5\u5230\u4fdd\u62a4\u884c\u52a8\u7684\u5177\u4f53\u8def\u5f84\u3002", "method": "\u57fa\u4e8e\u4e94\u4e2a\u5173\u952e\u6784\u5ff5\uff08\u611f\u77e5\u9690\u79c1\u98ce\u9669\u3001\u611f\u77e5\u5229\u76ca\u3001\u7b97\u6cd5\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u3001\u9690\u79c1\u81ea\u6211\u6548\u80fd\u3001\u9690\u79c1\u4fdd\u62a4\u884c\u4e3a\uff09\u6784\u5efa\u7ed3\u6784\u6a21\u578b\uff0c\u5bf9N=469\u540d\u9752\u5c11\u5e74\u8fdb\u884c\u6a2a\u65ad\u9762\u8c03\u67e5\uff0c\u4f7f\u7528\u504f\u6700\u5c0f\u4e8c\u4e58\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\u8fdb\u884c\u5206\u6790\u3002", "result": "\u9690\u79c1\u81ea\u6211\u6548\u80fd\u662f\u9690\u79c1\u4fdd\u62a4\u884c\u4e3a\u7684\u6700\u5f3a\u9884\u6d4b\u56e0\u5b50\uff1b\u7b97\u6cd5\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u5bf9\u9690\u79c1\u4fdd\u62a4\u884c\u4e3a\u7684\u5f71\u54cd\u5b8c\u5168\u7531\u9690\u79c1\u81ea\u6211\u6548\u80fd\u4e2d\u4ecb\uff1b\u611f\u77e5\u5229\u76ca\u76f4\u63a5\u963b\u788d\u4fdd\u62a4\u884c\u52a8\uff0c\u4f46\u901a\u8fc7\u8f7b\u5fae\u63d0\u5347\u81ea\u6211\u6548\u80fd\u95f4\u63a5\u4fc3\u8fdb\u4fdd\u62a4\u884c\u4e3a\u3002", "conclusion": "\u7814\u7a76\u5b9e\u8bc1\u9a8c\u8bc1\u5e76\u6269\u5c55\u4e86\u65e9\u671f\u5b9a\u6027\u5de5\u4f5c\uff0c\u91cf\u5316\u4e86\u653f\u7b56\u8fc7\u8f7d\u548c\u9690\u85cf\u63a7\u5236\u5982\u4f55\u4fb5\u8680\u4fdd\u62a4\u884c\u52a8\u6240\u9700\u7684\u81ea\u6211\u6548\u80fd\u3002\u7814\u7a76\u8d21\u732e\u4e86\u4ece\u611f\u77e5\u5230\u884c\u52a8\u7684\u5faa\u8bc1\u8def\u5f84\uff0c\u5e76\u8f6c\u5316\u4e3a\u8bbe\u8ba1\u539f\u5219\uff0c\u5728\u4e0d\u727a\u7272\u667a\u80fd\u8bed\u97f3\u52a9\u624b\u5b9e\u7528\u6027\u7684\u524d\u63d0\u4e0b\u8d4b\u80fd\u5e74\u8f7b\u6570\u5b57\u516c\u6c11\u3002"}}
{"id": "2602.10802", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10802", "abs": "https://arxiv.org/abs/2602.10802", "authors": ["Da-Lun Chen", "Prasasthy Balasubramanian", "Lauri Lov\u00e9n", "Susanna Pirttikangas", "Jaakko Sauvola", "Panagiotis Kostakos"], "title": "Integrating Generative AI-enhanced Cognitive Systems in Higher Education: From Stakeholder Perceptions to a Conceptual Framework considering the EU AI Act", "comment": null, "summary": "Many staff and students in higher education have adopted generative artificial intelligence (GenAI) tools in their work and study. GenAI is expected to enhance cognitive systems by enabling personalized learning and streamlining educational services. However, stakeholders perceptions of GenAI in higher education remain divided, shaped by cultural, disciplinary, and institutional contexts. In addition, the EU AI Act requires universities to ensure regulatory compliance when deploying cognitive systems. These developments highlight the need for institutions to engage stakeholders and tailor GenAI integration to their needs while addressing concerns. This study investigates how GenAI is perceived within the disciplines of Information Technology and Electrical Engineering (ITEE). Using a mixed-method approach, we surveyed 61 staff and 37 students at the Faculty of ITEE, University of Oulu. The results reveal both shared and discipline-specific themes, including strong interest in programming support from GenAI and concerns over response quality, privacy, and academic integrity. Drawing from these insights, the study identifies a set of high-level requirements and proposes a conceptual framework for responsible GenAI integration. Disciplinary-specific requirements reinforce the importance of stakeholder engagement when integrating GenAI into higher education. The high-level requirements and the framework provide practical guidance for universities aiming to harness GenAI while addressing stakeholder concerns and ensuring regulatory compliance.", "AI": {"tldr": "\u7814\u7a76\u8c03\u67e5\u4e86\u9ad8\u7b49\u6559\u80b2\u4e2d\u751f\u6210\u5f0fAI\u7684\u611f\u77e5\u5dee\u5f02\uff0c\u7279\u522b\u5173\u6ce8ITEE\u9886\u57df\uff0c\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u8bc6\u522b\u4e86\u5171\u4eab\u548c\u5b66\u79d1\u7279\u5b9a\u7684\u4e3b\u9898\uff0c\u63d0\u51fa\u4e86\u8d1f\u8d23\u4efb\u6574\u5408\u7684\u6846\u67b6\u3002", "motivation": "\u9ad8\u7b49\u6559\u80b2\u4e2d\u751f\u6210\u5f0fAI\u5de5\u5177\u5df2\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u5229\u76ca\u76f8\u5173\u8005\u7684\u770b\u6cd5\u56e0\u6587\u5316\u3001\u5b66\u79d1\u548c\u5236\u5ea6\u80cc\u666f\u800c\u5f02\u3002\u6b27\u76dfAI\u6cd5\u6848\u8981\u6c42\u5927\u5b66\u786e\u4fdd\u8ba4\u77e5\u7cfb\u7edf\u7684\u76d1\u7ba1\u5408\u89c4\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e86\u89e3\u4e0d\u540c\u5b66\u79d1\u5bf9GenAI\u7684\u611f\u77e5\uff0c\u4ee5\u5236\u5b9a\u8d1f\u8d23\u4efb\u7684\u6574\u5408\u7b56\u7565\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u5bf9\u5965\u5362\u5927\u5b66ITEE\u5b66\u9662\u768461\u540d\u6559\u804c\u5458\u5de5\u548c37\u540d\u5b66\u751f\u8fdb\u884c\u4e86\u8c03\u67e5\uff0c\u5206\u6790\u4ed6\u4eec\u5bf9\u751f\u6210\u5f0fAI\u7684\u611f\u77e5\u548c\u6001\u5ea6\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u5171\u4eab\u548c\u5b66\u79d1\u7279\u5b9a\u7684\u4e3b\u9898\uff1aITEE\u9886\u57df\u5bf9GenAI\u5728\u7f16\u7a0b\u652f\u6301\u65b9\u9762\u6709\u5f3a\u70c8\u5174\u8da3\uff0c\u4f46\u4e5f\u5173\u6ce8\u54cd\u5e94\u8d28\u91cf\u3001\u9690\u79c1\u548c\u5b66\u672f\u8bda\u4fe1\u95ee\u9898\u3002\u7814\u7a76\u8bc6\u522b\u4e86\u4e00\u5957\u9ad8\u5c42\u6b21\u8981\u6c42\uff0c\u5e76\u63d0\u51fa\u4e86\u8d1f\u8d23\u4efbGenAI\u6574\u5408\u7684\u6982\u5ff5\u6846\u67b6\u3002", "conclusion": "\u5b66\u79d1\u7279\u5b9a\u7684\u8981\u6c42\u5f3a\u8c03\u4e86\u5728\u9ad8\u7b49\u6559\u80b2\u4e2d\u6574\u5408GenAI\u65f6\u5229\u76ca\u76f8\u5173\u8005\u53c2\u4e0e\u7684\u91cd\u8981\u6027\u3002\u9ad8\u5c42\u6b21\u8981\u6c42\u548c\u6846\u67b6\u4e3a\u5927\u5b66\u5229\u7528GenAI\u540c\u65f6\u89e3\u51b3\u5229\u76ca\u76f8\u5173\u8005\u5173\u5207\u548c\u786e\u4fdd\u76d1\u7ba1\u5408\u89c4\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2602.10148", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10148", "abs": "https://arxiv.org/abs/2602.10148", "authors": ["Yu Yan", "Sheng Sun", "Shengjia Cheng", "Teli Liu", "Mingfeng Li", "Min Liu"], "title": "Red-teaming the Multimodal Reasoning: Jailbreaking Vision-Language Models via Cross-modal Entanglement Attacks", "comment": null, "summary": "Vision-Language Models (VLMs) with multimodal reasoning capabilities are high-value attack targets, given their potential for handling complex multimodal harmful tasks. Mainstream black-box jailbreak attacks on VLMs work by distributing malicious clues across modalities to disperse model attention and bypass safety alignment mechanisms. However, these adversarial attacks rely on simple and fixed image-text combinations that lack attack complexity scalability, limiting their effectiveness for red-teaming VLMs' continuously evolving reasoning capabilities. We propose \\textbf{CrossTALK} (\\textbf{\\underline{Cross}}-modal en\\textbf{\\underline{TA}}ng\\textbf{\\underline{L}}ement attac\\textbf{\\underline{K}}), which is a scalable approach that extends and entangles information clues across modalities to exceed VLMs' trained and generalized safety alignment patterns for jailbreak. Specifically, {knowledge-scalable reframing} extends harmful tasks into multi-hop chain instructions, {cross-modal clue entangling} migrates visualizable entities into images to build multimodal reasoning links, and {cross-modal scenario nesting} uses multimodal contextual instructions to steer VLMs toward detailed harmful outputs. Experiments show our COMET achieves state-of-the-art attack success rate.", "AI": {"tldr": "\u63d0\u51faCrossTALK\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u4fe1\u606f\u7ea0\u7f20\u6765\u7ed5\u8fc7\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u673a\u5236", "motivation": "\u73b0\u6709\u9ed1\u76d2\u8d8a\u72f1\u653b\u51fb\u4f9d\u8d56\u7b80\u5355\u56fa\u5b9a\u7684\u56fe\u50cf-\u6587\u672c\u7ec4\u5408\uff0c\u7f3a\u4e4f\u653b\u51fb\u590d\u6742\u5ea6\u53ef\u6269\u5c55\u6027\uff0c\u96be\u4ee5\u5e94\u5bf9VLM\u4e0d\u65ad\u53d1\u5c55\u7684\u63a8\u7406\u80fd\u529b", "method": "1) \u77e5\u8bc6\u53ef\u6269\u5c55\u91cd\u6784\uff1a\u5c06\u6709\u5bb3\u4efb\u52a1\u6269\u5c55\u4e3a\u591a\u8df3\u94fe\u5f0f\u6307\u4ee4\uff1b2) \u8de8\u6a21\u6001\u7ebf\u7d22\u7ea0\u7f20\uff1a\u5c06\u53ef\u89c6\u5316\u5b9e\u4f53\u8fc1\u79fb\u5230\u56fe\u50cf\u4e2d\u6784\u5efa\u591a\u6a21\u6001\u63a8\u7406\u94fe\u63a5\uff1b3) \u8de8\u6a21\u6001\u573a\u666f\u5d4c\u5957\uff1a\u4f7f\u7528\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u6307\u4ee4\u5f15\u5bfcVLM\u751f\u6210\u8be6\u7ec6\u6709\u5bb3\u8f93\u51fa", "result": "\u5b9e\u9a8c\u8868\u660eCrossTALK\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u653b\u51fb\u6210\u529f\u7387", "conclusion": "\u63d0\u51fa\u7684\u8de8\u6a21\u6001\u7ea0\u7f20\u653b\u51fb\u65b9\u6cd5\u80fd\u591f\u8d85\u8d8aVLM\u8bad\u7ec3\u548c\u6cdb\u5316\u7684\u5b89\u5168\u5bf9\u9f50\u6a21\u5f0f\uff0c\u5b9e\u73b0\u6709\u6548\u7684\u8d8a\u72f1\u653b\u51fb"}}
{"id": "2602.11125", "categories": ["cs.DC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.11125", "abs": "https://arxiv.org/abs/2602.11125", "authors": ["Animesh Maiti", "Abhinav Chakraborty", "Bibhuti Das", "Subhash Bhagat", "Krishnendu Mukhopadhyaya"], "title": "Min-Sum Uniform Coverage Problem by Autonomous Mobile Robots", "comment": null, "summary": "We study the \\textit{min-sum uniform coverage} problem for a swarm of $n$ mobile robots on a given finite line segment and on a circle having finite positive radius, where the circle is given as an input. The robots must coordinate their movements to reach a uniformly spaced configuration that minimizes the total distance traveled by all robots. The robots are autonomous, anonymous, identical, and homogeneous, and operate under the \\textit{Look-Compute-Move} (LCM) model with \\textit{non-rigid} motion controlled by a fair asynchronous scheduler. They are oblivious and silent, possessing neither persistent memory nor a means of explicit communication. In the \\textbf{line-segment setting}, the \\textit{min-sum uniform coverage} problem requires placing the robots at uniformly spaced points along the segment so as to minimize the total distance traveled by all robots. In the \\textbf{circle setting} for this problem, the robots have to arrange themselves uniformly around the given circle to form a regular $n$-gon. There is no fixed orientation or designated starting vertex, and the goal is to minimize the total distance traveled by all the robots. We present a deterministic distributed algorithm that achieves uniform coverage in the line-segment setting with minimum total movement cost. For the circle setting, we characterize all initial configurations for which the \\textit{min-sum uniform coverage} problem is deterministically unsolvable under the considered robot model. For all the other remaining configurations, we provide a deterministic distributed algorithm that achieves uniform coverage while minimizing the total distance traveled. These results characterize the deterministic solvability of min-sum coverage for oblivious robots and achieve optimal cost whenever solvable.", "AI": {"tldr": "\u7814\u7a76\u79fb\u52a8\u673a\u5668\u4eba\u5728\u7ebf\u6bb5\u548c\u5706\u4e0a\u7684\u6700\u5c0f\u603b\u79fb\u52a8\u8ddd\u79bb\u5747\u5300\u8986\u76d6\u95ee\u9898\uff0c\u63d0\u51fa\u786e\u5b9a\u6027\u5206\u5e03\u5f0f\u7b97\u6cd5\u5b9e\u73b0\u6700\u4f18\u6210\u672c\u8986\u76d6", "motivation": "\u7814\u7a76\u81ea\u4e3b\u3001\u533f\u540d\u3001\u540c\u8d28\u7684\u79fb\u52a8\u673a\u5668\u4eba\u5728\u5f02\u6b65\u8c03\u5ea6\u4e0b\u5982\u4f55\u534f\u8c03\u8fd0\u52a8\u4ee5\u8fbe\u5230\u5747\u5300\u5206\u5e03\u914d\u7f6e\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u6240\u6709\u673a\u5668\u4eba\u79fb\u52a8\u7684\u603b\u8ddd\u79bb\u3002\u5728\u7ebf\u6bb5\u548c\u5706\u4e24\u79cd\u51e0\u4f55\u8bbe\u7f6e\u4e0b\uff0c\u63a2\u7d22\u5728\u6709\u9650\u901a\u4fe1\u548c\u8bb0\u5fc6\u7ea6\u675f\u4e0b\u7684\u6700\u4f18\u8986\u76d6\u95ee\u9898\u3002", "method": "\u91c7\u7528Look-Compute-Move\uff08LCM\uff09\u6a21\u578b\uff0c\u673a\u5668\u4eba\u5177\u6709\u975e\u521a\u6027\u8fd0\u52a8\u80fd\u529b\uff0c\u5728\u516c\u5e73\u5f02\u6b65\u8c03\u5ea6\u4e0b\u8fd0\u884c\u3002\u63d0\u51fa\u786e\u5b9a\u6027\u5206\u5e03\u5f0f\u7b97\u6cd5\uff1a\u5728\u7ebf\u6bb5\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u5747\u5300\u95f4\u8ddd\u653e\u7f6e\uff1b\u5728\u5706\u8bbe\u7f6e\u4e2d\uff0c\u9996\u5148\u786e\u5b9a\u4e0d\u53ef\u89e3\u914d\u7f6e\uff0c\u7136\u540e\u4e3a\u5176\u4ed6\u914d\u7f6e\u63d0\u4f9b\u7b97\u6cd5\u5b9e\u73b0\u5747\u5300\u5206\u5e03\u5f62\u6210\u6b63n\u8fb9\u5f62\u3002", "result": "\u5728\u7ebf\u6bb5\u8bbe\u7f6e\u4e2d\uff0c\u7b97\u6cd5\u6210\u529f\u5b9e\u73b0\u6700\u5c0f\u603b\u79fb\u52a8\u6210\u672c\u7684\u5747\u5300\u8986\u76d6\u3002\u5728\u5706\u8bbe\u7f6e\u4e2d\uff0c\u5b8c\u6574\u523b\u753b\u4e86\u786e\u5b9a\u6027\u4e0d\u53ef\u89e3\u7684\u521d\u59cb\u914d\u7f6e\uff0c\u5e76\u4e3a\u6240\u6709\u5176\u4ed6\u914d\u7f6e\u63d0\u4f9b\u4e86\u5b9e\u73b0\u6700\u5c0f\u603b\u79fb\u52a8\u8ddd\u79bb\u7684\u786e\u5b9a\u6027\u5206\u5e03\u5f0f\u7b97\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u5b8c\u6574\u523b\u753b\u4e86\u5728\u8003\u8651\u673a\u5668\u4eba\u6a21\u578b\u4e0b\u6700\u5c0f\u603b\u8ddd\u79bb\u8986\u76d6\u95ee\u9898\u7684\u786e\u5b9a\u6027\u53ef\u89e3\u6027\uff0c\u5e76\u5728\u53ef\u89e3\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u6700\u4f18\u6210\u672c\u3002\u7ed3\u679c\u4e3a\u65e0\u8bb0\u5fc6\u3001\u65e0\u901a\u4fe1\u7684\u673a\u5668\u4eba\u5728\u7ebf\u6bb5\u548c\u5706\u4e0a\u7684\u5747\u5300\u8986\u76d6\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u7528\u7b97\u6cd5\u3002"}}
{"id": "2602.10845", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10845", "abs": "https://arxiv.org/abs/2602.10845", "authors": ["Xuecheng Zou", "Yu Tang", "Bingbing Wang"], "title": "SynergyKGC: Reconciling Topological Heterogeneity in Knowledge Graph Completion via Topology-Aware Synergy", "comment": "10 pages, 5 tables, 7 figures. This work introduces the Active Synergy mechanism and Identity Anchoring for Knowledge Graph Completion. Code: https://github.com/XuechengZou-2001/SynergyKGC-main", "summary": "Knowledge Graph Completion (KGC) fundamentally hinges on the coherent fusion of pre-trained entity semantics with heterogeneous topological structures to facilitate robust relational reasoning. However, existing paradigms encounter a critical \"structural resolution mismatch,\" failing to reconcile divergent representational demands across varying graph densities, which precipitates structural noise interference in dense clusters and catastrophic representation collapse in sparse regions. We present SynergyKGC, an adaptive framework that advances traditional neighbor aggregation to an active Cross-Modal Synergy Expert via relation-aware cross-attention and semantic-intent-driven gating. By coupling a density-dependent Identity Anchoring strategy with a Double-tower Coherent Consistency architecture, SynergyKGC effectively reconciles topological heterogeneity while ensuring representational stability across training and inference phases. Systematic evaluations on two public benchmarks validate the superiority of our method in significantly boosting KGC hit rates, providing empirical evidence for a generalized principle of resilient information integration in non-homogeneous structured data.", "AI": {"tldr": "SynergyKGC\u901a\u8fc7\u8de8\u6a21\u6001\u534f\u540c\u4e13\u5bb6\u548c\u5bc6\u5ea6\u4f9d\u8d56\u7684\u8eab\u4efd\u951a\u5b9a\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4e2d\u7ed3\u6784\u5206\u8fa8\u7387\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u547d\u4e2d\u7387\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u65b9\u6cd5\u9762\u4e34\"\u7ed3\u6784\u5206\u8fa8\u7387\u4e0d\u5339\u914d\"\u95ee\u9898\uff0c\u65e0\u6cd5\u534f\u8c03\u4e0d\u540c\u56fe\u5bc6\u5ea6\u4e0b\u7684\u8868\u793a\u9700\u6c42\uff0c\u5bfc\u81f4\u5bc6\u96c6\u7c07\u4e2d\u7684\u7ed3\u6784\u566a\u58f0\u5e72\u6270\u548c\u7a00\u758f\u533a\u57df\u7684\u8868\u793a\u5d29\u6e83\u3002", "method": "\u63d0\u51faSynergyKGC\u6846\u67b6\uff1a1) \u5c06\u4f20\u7edf\u90bb\u5c45\u805a\u5408\u63d0\u5347\u4e3a\u57fa\u4e8e\u5173\u7cfb\u611f\u77e5\u4ea4\u53c9\u6ce8\u610f\u529b\u548c\u8bed\u4e49\u610f\u56fe\u9a71\u52a8\u95e8\u63a7\u7684\u4e3b\u52a8\u8de8\u6a21\u6001\u534f\u540c\u4e13\u5bb6\uff1b2) \u7ed3\u5408\u5bc6\u5ea6\u4f9d\u8d56\u7684\u8eab\u4efd\u951a\u5b9a\u7b56\u7565\uff1b3) \u91c7\u7528\u53cc\u5854\u4e00\u81f4\u6027\u67b6\u6784\u786e\u4fdd\u8868\u793a\u7a33\u5b9a\u6027\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u7cfb\u7edf\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86KGC\u547d\u4e2d\u7387\uff0c\u4e3a\u975e\u5747\u5300\u7ed3\u6784\u5316\u6570\u636e\u4e2d\u7684\u5f39\u6027\u4fe1\u606f\u6574\u5408\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u8bc1\u636e\u3002", "conclusion": "SynergyKGC\u901a\u8fc7\u81ea\u9002\u5e94\u6846\u67b6\u6709\u6548\u534f\u8c03\u62d3\u6251\u5f02\u8d28\u6027\uff0c\u786e\u4fdd\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u7684\u8868\u793a\u7a33\u5b9a\u6027\uff0c\u4e3a\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4e2d\u7684\u5f39\u6027\u4fe1\u606f\u6574\u5408\u63d0\u4f9b\u4e86\u901a\u7528\u539f\u5219\u3002"}}
{"id": "2602.10465", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.10465", "abs": "https://arxiv.org/abs/2602.10465", "authors": ["Mohan Rajagopalan", "Vinay Rao"], "title": "Authenticated Workflows: A Systems Approach to Protecting Agentic AI", "comment": null, "summary": "Agentic AI systems automate enterprise workflows but existing defenses--guardrails, semantic filters--are probabilistic and routinely bypassed. We introduce authenticated workflows, the first complete trust layer for enterprise agentic AI. Security reduces to protecting four fundamental boundaries: prompts, tools, data, and context. We enforce intent (operations satisfy organizational policies) and integrity (operations are cryptographically authentic) at every boundary crossing, combining cryptographic elimination of attack classes with runtime policy enforcement. This delivers deterministic security--operations either carry valid cryptographic proof or are rejected. We introduce MAPL, an AI-native policy language that expresses agentic constraints dynamically as agents evolve and invocation context changes, scaling as O(log M + N) policies versus O(M x N) rules through hierarchical composition with cryptographic attestations for workflow dependencies. We prove practicality through a universal security runtime integrating nine leading frameworks (MCP, A2A, OpenAI, Claude, LangChain, CrewAI, AutoGen, LlamaIndex, Haystack) through thin adapters requiring zero protocol modifications. Formal proofs establish completeness and soundness. Empirical validation shows 100% recall with zero false positives across 174 test cases, protection against 9 of 10 OWASP Top 10 risks, and complete mitigation of two high impact production CVEs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u4f01\u4e1a\u7ea7\u667a\u80fd\u4f53AI\u7684\u5b8c\u6574\u4fe1\u4efb\u5c42\u2014\u2014\u8ba4\u8bc1\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u4fdd\u62a4\u63d0\u793a\u3001\u5de5\u5177\u3001\u6570\u636e\u548c\u4e0a\u4e0b\u6587\u56db\u4e2a\u8fb9\u754c\uff0c\u7ed3\u5408\u5bc6\u7801\u5b66\u6d88\u9664\u653b\u51fb\u7c7b\u522b\u548c\u8fd0\u884c\u65f6\u7b56\u7565\u6267\u884c\uff0c\u63d0\u4f9b\u786e\u5b9a\u6027\u5b89\u5168\u3002", "motivation": "\u73b0\u6709\u4f01\u4e1a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u7684\u9632\u5fa1\u63aa\u65bd\uff08\u62a4\u680f\u3001\u8bed\u4e49\u8fc7\u6ee4\u5668\uff09\u662f\u6982\u7387\u6027\u7684\uff0c\u7ecf\u5e38\u88ab\u7ed5\u8fc7\uff0c\u7f3a\u4e4f\u53ef\u9760\u7684\u5b89\u5168\u4fdd\u969c\u3002", "method": "\u5f15\u5165\u8ba4\u8bc1\u5de5\u4f5c\u6d41\uff0c\u5728\u56db\u4e2a\u8fb9\u754c\uff08\u63d0\u793a\u3001\u5de5\u5177\u3001\u6570\u636e\u3001\u4e0a\u4e0b\u6587\uff09\u6267\u884c\u610f\u56fe\u548c\u5b8c\u6574\u6027\u9a8c\u8bc1\uff0c\u7ed3\u5408\u5bc6\u7801\u5b66\u8bc1\u660e\u548c\u8fd0\u884c\u65f6\u7b56\u7565\u6267\u884c\u3002\u63d0\u51faMAPL AI\u539f\u751f\u7b56\u7565\u8bed\u8a00\uff0c\u652f\u6301\u52a8\u6001\u7ea6\u675f\u8868\u8fbe\u548c\u5c42\u6b21\u5316\u7ec4\u5408\uff0c\u901a\u8fc7\u8584\u9002\u914d\u5668\u96c6\u6210\u4e5d\u5927\u4e3b\u6d41\u6846\u67b6\u3002", "result": "\u5b9e\u73b0\u786e\u5b9a\u6027\u5b89\u5168\uff1a\u64cd\u4f5c\u8981\u4e48\u643a\u5e26\u6709\u6548\u5bc6\u7801\u5b66\u8bc1\u660e\u88ab\u63a5\u53d7\uff0c\u8981\u4e48\u88ab\u62d2\u7edd\u3002\u5728174\u4e2a\u6d4b\u8bd5\u6848\u4f8b\u4e2d\u8fbe\u5230100%\u53ec\u56de\u7387\u548c\u96f6\u8bef\u62a5\uff0c\u9632\u62a49/10 OWASP Top 10\u98ce\u9669\uff0c\u5b8c\u5168\u7f13\u89e3\u4e24\u4e2a\u9ad8\u5f71\u54cd\u751f\u4ea7CVE\u3002", "conclusion": "\u8ba4\u8bc1\u5de5\u4f5c\u6d41\u4e3a\u4f01\u4e1a\u667a\u80fd\u4f53AI\u63d0\u4f9b\u4e86\u9996\u4e2a\u5b8c\u6574\u7684\u4fe1\u4efb\u5c42\uff0c\u901a\u8fc7\u5bc6\u7801\u5b66\u8bc1\u660e\u548c\u52a8\u6001\u7b56\u7565\u6267\u884c\u5b9e\u73b0\u4e86\u786e\u5b9a\u6027\u5b89\u5168\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u53ef\u884c\u6027\u3002"}}
{"id": "2602.10153", "categories": ["cs.CR", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.10153", "abs": "https://arxiv.org/abs/2602.10153", "authors": ["Ashwin Sreevatsa", "Sebastian Prasanna", "Cody Rushing"], "title": "Basic Legibility Protocols Improve Trusted Monitoring", "comment": null, "summary": "The AI Control research agenda aims to develop control protocols: safety techniques that prevent untrusted AI systems from taking harmful actions during deployment. Because human oversight is expensive, one approach is trusted monitoring, where weaker, trusted models oversee stronger, untrusted models$\\unicode{x2013}$but this often fails when the untrusted model's actions exceed the monitor's comprehension. We introduce legibility protocols, which encourage the untrusted model to take actions that are easier for a monitor to evaluate.\n  We perform control evaluations in the APPS coding setting, where an adversarial agent attempts to write backdoored code without detection. We study legibility protocols that allow the untrusted model to thoroughly document its code with comments$\\unicode{x2013}$in contrast to prior work, which removed comments to prevent deceptive ones. We find that: (i) commenting protocols improve safety without sacrificing task performance relative to comment-removal baselines; (ii) commenting disproportionately benefits honest code, which typically has a natural explanation that resolves monitor suspicion, whereas backdoored code frequently lacks an easy justification; (iii) gains from commenting increase with monitor strength, as stronger monitors better distinguish genuine justifications from only superficially plausible ones.", "AI": {"tldr": "AI\u63a7\u5236\u7814\u7a76\u63d0\u51fa\u53ef\u8bfb\u6027\u534f\u8bae\uff0c\u901a\u8fc7\u8ba9\u4e0d\u53d7\u4fe1\u4efb\u7684AI\u6a21\u578b\u7528\u6ce8\u91ca\u8be6\u7ec6\u8bb0\u5f55\u4ee3\u7801\uff0c\u5e2e\u52a9\u8f83\u5f31\u4f46\u53ef\u4fe1\u7684\u76d1\u63a7\u6a21\u578b\u66f4\u597d\u5730\u8bc4\u4f30\u5176\u884c\u4e3a\uff0c\u5728APPS\u7f16\u7801\u73af\u5883\u4e2d\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\u800c\u4e0d\u727a\u7272\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u53ef\u4fe1\u76d1\u63a7\u65b9\u6cd5\u5728\u4e0d\u53d7\u4fe1\u4efb\u6a21\u578b\u7684\u884c\u4e3a\u8d85\u51fa\u76d1\u63a7\u6a21\u578b\u7406\u89e3\u80fd\u529b\u65f6\u4f1a\u5931\u6548\u3002\u9700\u8981\u5f00\u53d1\u65b0\u7684\u63a7\u5236\u534f\u8bae\uff0c\u4f7f\u4e0d\u53d7\u4fe1\u4efb\u6a21\u578b\u7684\u884c\u4e3a\u5bf9\u76d1\u63a7\u6a21\u578b\u66f4\u6613\u8bc4\u4f30\u3002", "method": "\u5f15\u5165\u53ef\u8bfb\u6027\u534f\u8bae\uff0c\u9f13\u52b1\u4e0d\u53d7\u4fe1\u4efb\u6a21\u578b\u91c7\u53d6\u66f4\u6613\u88ab\u76d1\u63a7\u6a21\u578b\u8bc4\u4f30\u7684\u884c\u52a8\u3002\u5728APPS\u7f16\u7801\u73af\u5883\u4e2d\uff0c\u5141\u8bb8\u4e0d\u53d7\u4fe1\u4efb\u6a21\u578b\u7528\u6ce8\u91ca\u8be6\u7ec6\u8bb0\u5f55\u4ee3\u7801\uff0c\u800c\u4e0d\u662f\u50cf\u5148\u524d\u5de5\u4f5c\u90a3\u6837\u5220\u9664\u6ce8\u91ca\u4ee5\u9632\u6b62\u6b3a\u9a97\u6027\u5185\u5bb9\u3002", "result": "1) \u6ce8\u91ca\u534f\u8bae\u76f8\u6bd4\u5220\u9664\u6ce8\u91ca\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4e0d\u727a\u7272\u4efb\u52a1\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\uff1b2) \u6ce8\u91ca\u5bf9\u8bda\u5b9e\u4ee3\u7801\u7684\u76ca\u5904\u66f4\u5927\uff0c\u56e0\u4e3a\u8bda\u5b9e\u4ee3\u7801\u901a\u5e38\u6709\u81ea\u7136\u7684\u89e3\u91ca\u53ef\u4ee5\u6d88\u9664\u76d1\u63a7\u6000\u7591\uff0c\u800c\u540e\u95e8\u4ee3\u7801\u5f80\u5f80\u7f3a\u4e4f\u5bb9\u6613\u7684\u6b63\u5f53\u7406\u7531\uff1b3) \u6ce8\u91ca\u5e26\u6765\u7684\u6536\u76ca\u968f\u76d1\u63a7\u6a21\u578b\u5f3a\u5ea6\u589e\u52a0\u800c\u589e\u52a0\uff0c\u66f4\u5f3a\u7684\u76d1\u63a7\u6a21\u578b\u80fd\u66f4\u597d\u5730\u533a\u5206\u771f\u6b63\u7684\u6b63\u5f53\u7406\u7531\u548c\u8868\u9762\u5408\u7406\u7684\u7406\u7531\u3002", "conclusion": "\u53ef\u8bfb\u6027\u534f\u8bae\u662f\u6709\u6548\u7684AI\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u9f13\u52b1\u4e0d\u53d7\u4fe1\u4efb\u6a21\u578b\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u884c\u52a8\uff0c\u4f7f\u8f83\u5f31\u4f46\u53ef\u4fe1\u7684\u76d1\u63a7\u6a21\u578b\u80fd\u591f\u66f4\u53ef\u9760\u5730\u8bc4\u4f30\u5176\u884c\u4e3a\uff0c\u5728\u7f16\u7801\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u5b89\u5168\u6027\u548c\u6027\u80fd\u7684\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2602.10885", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10885", "abs": "https://arxiv.org/abs/2602.10885", "authors": ["Leheng Sheng", "Wenchang Ma", "Ruixin Hong", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "Reinforcing Chain-of-Thought Reasoning with Self-Evolving Rubrics", "comment": "21 pages", "summary": "Despite chain-of-thought (CoT) playing crucial roles in LLM reasoning, directly rewarding it is difficult: training a reward model demands heavy human labeling efforts, and static RMs struggle with evolving CoT distributions and reward hacking. These challenges motivate us to seek an autonomous CoT rewarding approach that requires no human annotation efforts and can evolve gradually. Inspired by recent self-evolving training methods, we propose \\textbf{RLCER} (\\textbf{R}einforcement \\textbf{L}earning with \\textbf{C}oT Supervision via Self-\\textbf{E}volving \\textbf{R}ubrics), which enhances the outcome-centric RLVR by rewarding CoTs with self-proposed and self-evolving rubrics. We show that self-proposed and self-evolving rubrics provide reliable CoT supervision signals even without outcome rewards, enabling RLCER to outperform outcome-centric RLVR. Moreover, when used as in-prompt hints, these self-proposed rubrics further improve inference-time performance.", "AI": {"tldr": "RLCER\uff1a\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684\u81ea\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u6211\u63d0\u51fa\u548c\u6f14\u8fdb\u7684\u8bc4\u5206\u6807\u51c6\u6765\u5956\u52b1\u601d\u7ef4\u94fe\u63a8\u7406\u8fc7\u7a0b", "motivation": "\u4f20\u7edf\u601d\u7ef4\u94fe\u5956\u52b1\u65b9\u6cd5\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1\uff09\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6807\u6ce8\uff1b2\uff09\u9759\u6001\u5956\u52b1\u6a21\u578b\u96be\u4ee5\u9002\u5e94\u601d\u7ef4\u94fe\u5206\u5e03\u7684\u52a8\u6001\u53d8\u5316\u4e14\u5bb9\u6613\u53d7\u5230\u5956\u52b1\u653b\u51fb\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u4e14\u80fd\u81ea\u4e3b\u6f14\u8fdb\u7684\u601d\u7ef4\u94fe\u5956\u52b1\u65b9\u6cd5\u3002", "method": "\u63d0\u51faRLCER\uff08\u5f3a\u5316\u5b66\u4e60\u4e0e\u601d\u7ef4\u94fe\u76d1\u7763\u901a\u8fc7\u81ea\u6211\u6f14\u8fdb\u8bc4\u5206\u6807\u51c6\uff09\uff0c\u5728\u7ed3\u679c\u4e2d\u5fc3\u7684RLVR\u57fa\u7840\u4e0a\uff0c\u901a\u8fc7\u81ea\u6211\u63d0\u51fa\u548c\u6f14\u8fdb\u7684\u8bc4\u5206\u6807\u51c6\u6765\u5956\u52b1\u601d\u7ef4\u94fe\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u53ef\u9760\u7684\u601d\u7ef4\u94fe\u76d1\u7763\u4fe1\u53f7\uff0c\u5373\u4f7f\u5728\u6ca1\u6709\u7ed3\u679c\u5956\u52b1\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5de5\u4f5c\u3002", "result": "RLCER\u5728\u6027\u80fd\u4e0a\u8d85\u8d8a\u4e86\u7ed3\u679c\u4e2d\u5fc3\u7684RLVR\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u5f53\u5c06\u8fd9\u4e9b\u81ea\u6211\u63d0\u51fa\u7684\u8bc4\u5206\u6807\u51c6\u4f5c\u4e3a\u63d0\u793a\u4e2d\u7684\u63d0\u793a\u4f7f\u7528\u65f6\uff0c\u8fd8\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u63a8\u7406\u65f6\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u81ea\u6211\u63d0\u51fa\u548c\u6f14\u8fdb\u7684\u8bc4\u5206\u6807\u51c6\u80fd\u591f\u4e3a\u601d\u7ef4\u94fe\u63d0\u4f9b\u6709\u6548\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u5b9e\u73b0\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684\u81ea\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\uff0c\u5e76\u5728\u63a8\u7406\u6027\u80fd\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2602.10964", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10964", "abs": "https://arxiv.org/abs/2602.10964", "authors": ["F. Carichon", "R. Rampa", "G. Farnadi"], "title": "Can LLMs Cook Jamaican Couscous? A Study of Cultural Novelty in Recipe Generation", "comment": "14 pages, 12 figures, conference", "summary": "Large Language Models (LLMs) are increasingly used to generate and shape cultural content, ranging from narrative writing to artistic production. While these models demonstrate impressive fluency and generative capacity, prior work has shown that they also exhibit systematic cultural biases, raising concerns about stereotyping, homogenization, and the erasure of culturally specific forms of expression. Understanding whether LLMs can meaningfully align with diverse cultures beyond the dominant ones remains a critical challenge. In this paper, we study cultural adaptation in LLMs through the lens of cooking recipes, a domain in which culture, tradition, and creativity are tightly intertwined. We build on the \\textit{GlobalFusion} dataset, which pairs human recipes from different countries according to established measures of cultural distance. Using the same country pairs, we generate culturally adapted recipes with multiple LLMs, enabling a direct comparison between human and LLM behavior in cross-cultural content creation. Our analysis shows that LLMs fail to produce culturally representative adaptations. Unlike humans, the divergence of their generated recipes does not correlate with cultural distance. We further provide explanations for this gap. We show that cultural information is weakly preserved in internal model representations, that models inflate novelty in their production by misunderstanding notions such as creativity and tradition, and that they fail to identify adaptation with its associated countries and to ground it in culturally salient elements such as ingredients. These findings highlight fundamental limitations of current LLMs for culturally oriented generation and have important implications for their use in culturally sensitive applications.", "AI": {"tldr": "LLMs\u5728\u6587\u5316\u5185\u5bb9\u751f\u6210\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u6587\u5316\u504f\u89c1\uff0c\u65e0\u6cd5\u6709\u6548\u9002\u5e94\u4e0d\u540c\u6587\u5316\u80cc\u666f\uff0c\u7279\u522b\u662f\u5728\u70f9\u996a\u98df\u8c31\u8fd9\u4e00\u6587\u5316\u654f\u611f\u9886\u57df\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u751f\u6210\u548c\u5851\u9020\u6587\u5316\u5185\u5bb9\uff0c\u4f46\u7814\u7a76\u8868\u660e\u5b83\u4eec\u5b58\u5728\u7cfb\u7edf\u6027\u6587\u5316\u504f\u89c1\uff0c\u53ef\u80fd\u5bfc\u81f4\u523b\u677f\u5370\u8c61\u3001\u540c\u8d28\u5316\u548c\u7279\u5b9a\u6587\u5316\u8868\u8fbe\u5f62\u5f0f\u7684\u6d88\u5931\u3002\u7406\u89e3LLMs\u662f\u5426\u80fd\u8d85\u8d8a\u4e3b\u6d41\u6587\u5316\u800c\u771f\u6b63\u9002\u5e94\u591a\u5143\u6587\u5316\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u901a\u8fc7\u70f9\u996a\u98df\u8c31\u8fd9\u4e00\u6587\u5316\u3001\u4f20\u7edf\u548c\u521b\u9020\u529b\u7d27\u5bc6\u4ea4\u7ec7\u7684\u9886\u57df\u7814\u7a76LLMs\u7684\u6587\u5316\u9002\u5e94\u80fd\u529b\u3002\u4f7f\u7528GlobalFusion\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u6839\u636e\u6587\u5316\u8ddd\u79bb\u6d4b\u91cf\u5c06\u4e0d\u540c\u56fd\u5bb6\u7684\u4eba\u7c7b\u98df\u8c31\u914d\u5bf9\u3002\u4f7f\u7528\u76f8\u540c\u7684\u56fd\u5bb6\u914d\u5bf9\uff0c\u7528\u591a\u4e2aLLMs\u751f\u6210\u6587\u5316\u9002\u5e94\u98df\u8c31\uff0c\u4ece\u800c\u76f4\u63a5\u6bd4\u8f83\u4eba\u7c7b\u548cLLM\u5728\u8de8\u6587\u5316\u5185\u5bb9\u521b\u4f5c\u4e2d\u7684\u884c\u4e3a\u3002", "result": "LLMs\u65e0\u6cd5\u4ea7\u751f\u5177\u6709\u6587\u5316\u4ee3\u8868\u6027\u7684\u9002\u5e94\u5185\u5bb9\u3002\u4e0e\u4eba\u7c7b\u4e0d\u540c\uff0c\u5b83\u4eec\u751f\u6210\u7684\u98df\u8c31\u5dee\u5f02\u4e0e\u6587\u5316\u8ddd\u79bb\u4e0d\u76f8\u5173\u3002\u7814\u7a76\u53d1\u73b0\uff1a\u6587\u5316\u4fe1\u606f\u5728\u6a21\u578b\u5185\u90e8\u8868\u793a\u4e2d\u4fdd\u5b58\u8f83\u5f31\uff1b\u6a21\u578b\u901a\u8fc7\u8bef\u89e3\u521b\u9020\u6027\u548c\u4f20\u7edf\u7b49\u6982\u5ff5\u6765\u5938\u5927\u65b0\u9896\u6027\uff1b\u65e0\u6cd5\u5c06\u9002\u5e94\u5185\u5bb9\u4e0e\u5176\u76f8\u5173\u56fd\u5bb6\u8054\u7cfb\u8d77\u6765\uff0c\u4e5f\u65e0\u6cd5\u5c06\u5176\u5efa\u7acb\u5728\u6587\u5316\u663e\u8457\u5143\u7d20\uff08\u5982\u98df\u6750\uff09\u4e0a\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u6587\u5316\u5bfc\u5411\u7684\u751f\u6210\u65b9\u9762\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\u6027\uff0c\u8fd9\u5bf9\u5b83\u4eec\u5728\u6587\u5316\u654f\u611f\u5e94\u7528\u4e2d\u7684\u4f7f\u7528\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u6765\u786e\u4fddLLMs\u80fd\u591f\u771f\u6b63\u7406\u89e3\u548c\u9002\u5e94\u591a\u5143\u6587\u5316\u8868\u8fbe\u3002"}}
{"id": "2602.10157", "categories": ["cs.CR", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.10157", "abs": "https://arxiv.org/abs/2602.10157", "authors": ["Yunpeng Tan", "Qingyang Li", "Mingxin Yang", "Yannan Hu", "Lei Zhang", "Xinggong Zhang"], "title": "MalMoE: Mixture-of-Experts Enhanced Encrypted Malicious Traffic Detection Under Graph Drift", "comment": "10 pages, 9 figures, accepted by IEEE INFOCOM 2026", "summary": "Encryption has been commonly used in network traffic to secure transmission, but it also brings challenges for malicious traffic detection, due to the invisibility of the packet payload. Graph-based methods are emerging as promising solutions by leveraging multi-host interactions to promote detection accuracy. But most of them face a critical problem: Graph Drift, where the flow statistics or topological information of a graph change over time. To overcome these drawbacks, we propose a graph-assisted encrypted traffic detection system, MalMoE, which applies Mixture of Experts (MoE) to select the best expert model for drift-aware classification. Particularly, we design 1-hop-GNN-like expert models that handle different graph drifts by analyzing graphs with different features. Then, the redesigned gate model conducts expert selection according to the actual drift. MalMoE is trained with a stable two-stage training strategy with data augmentation, which effectively guides the gate on how to perform routing. Experiments on open-source, synthetic, and real-world datasets show that MalMoE can perform precise and real-time detection.", "AI": {"tldr": "MalMoE\uff1a\u57fa\u4e8e\u4e13\u5bb6\u6df7\u5408\u7684\u56fe\u8f85\u52a9\u52a0\u5bc6\u6d41\u91cf\u68c0\u6d4b\u7cfb\u7edf\uff0c\u901a\u8fc7\u9009\u62e9\u6700\u4f73\u4e13\u5bb6\u6a21\u578b\u5e94\u5bf9\u56fe\u6f02\u79fb\u95ee\u9898", "motivation": "\u52a0\u5bc6\u6d41\u91cf\u5728\u4fdd\u969c\u4f20\u8f93\u5b89\u5168\u7684\u540c\u65f6\uff0c\u4f7f\u5f97\u6076\u610f\u6d41\u91cf\u68c0\u6d4b\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u65e0\u6cd5\u67e5\u770b\u6570\u636e\u5305\u6709\u6548\u8f7d\u8377\u3002\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\u867d\u7136\u80fd\u5229\u7528\u591a\u4e3b\u673a\u4ea4\u4e92\u63d0\u9ad8\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u4f46\u5927\u591a\u6570\u9762\u4e34\u56fe\u6f02\u79fb\u95ee\u9898\u2014\u2014\u56fe\u7684\u6d41\u7edf\u8ba1\u6216\u62d3\u6251\u4fe1\u606f\u968f\u65f6\u95f4\u53d8\u5316\u3002", "method": "\u63d0\u51faMalMoE\u7cfb\u7edf\uff0c\u5e94\u7528\u4e13\u5bb6\u6df7\u5408\uff08MoE\uff09\u9009\u62e9\u6700\u4f73\u4e13\u5bb6\u6a21\u578b\u8fdb\u884c\u6f02\u79fb\u611f\u77e5\u5206\u7c7b\u3002\u8bbe\u8ba1\u7c7b\u4f3c1\u8df3GNN\u7684\u4e13\u5bb6\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u6790\u5177\u6709\u4e0d\u540c\u7279\u5f81\u7684\u56fe\u6765\u5904\u7406\u4e0d\u540c\u7684\u56fe\u6f02\u79fb\u3002\u91cd\u65b0\u8bbe\u8ba1\u95e8\u63a7\u6a21\u578b\u6839\u636e\u5b9e\u9645\u6f02\u79fb\u8fdb\u884c\u4e13\u5bb6\u9009\u62e9\u3002\u91c7\u7528\u5e26\u6570\u636e\u589e\u5f3a\u7684\u4e24\u9636\u6bb5\u7a33\u5b9a\u8bad\u7ec3\u7b56\u7565\uff0c\u6709\u6548\u6307\u5bfc\u95e8\u63a7\u8fdb\u884c\u8def\u7531\u9009\u62e9\u3002", "result": "\u5728\u5f00\u6e90\u3001\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMalMoE\u80fd\u591f\u8fdb\u884c\u7cbe\u786e\u4e14\u5b9e\u65f6\u7684\u68c0\u6d4b\u3002", "conclusion": "MalMoE\u901a\u8fc7\u4e13\u5bb6\u6df7\u5408\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u52a0\u5bc6\u6d41\u91cf\u68c0\u6d4b\u4e2d\u7684\u56fe\u6f02\u79fb\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u5b9e\u65f6\u6076\u610f\u6d41\u91cf\u68c0\u6d4b\u3002"}}
{"id": "2602.10161", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.10161", "abs": "https://arxiv.org/abs/2602.10161", "authors": ["Kun Wang", "Zherui Li", "Zhenhong Zhou", "Yitong Zhang", "Yan Mi", "Kun Yang", "Yiming Zhang", "Junhao Dong", "Zhongxiang Sun", "Qiankun Li", "Yang Liu"], "title": "Omni-Safety under Cross-Modality Conflict: Vulnerabilities, Dynamics Mechanisms and Efficient Alignment", "comment": null, "summary": "Omni-modal Large Language Models (OLLMs) greatly expand LLMs' multimodal capabilities but also introduce cross-modal safety risks. However, a systematic understanding of vulnerabilities in omni-modal interactions remains lacking. To bridge this gap, we establish a modality-semantics decoupling principle and construct the AdvBench-Omni dataset, which reveals a significant vulnerability in OLLMs. Mechanistic analysis uncovers a Mid-layer Dissolution phenomenon driven by refusal vector magnitude shrinkage, alongside the existence of a modal-invariant pure refusal direction. Inspired by these insights, we extract a golden refusal vector using Singular Value Decomposition and propose OmniSteer, which utilizes lightweight adapters to modulate intervention intensity adaptively. Extensive experiments show that our method not only increases the Refusal Success Rate against harmful inputs from 69.9% to 91.2%, but also effectively preserves the general capabilities across all modalities. Our code is available at: https://github.com/zhrli324/omni-safety-research.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5168\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e86OmniSteer\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u9ec4\u91d1\u62d2\u7edd\u5411\u91cf\u548c\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u6709\u5bb3\u8f93\u5165\u7684\u62d2\u7edd\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u591a\u6a21\u6001\u901a\u7528\u80fd\u529b\u3002", "motivation": "\u5168\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u6269\u5c55\u4e86\u591a\u6a21\u6001\u80fd\u529b\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u8de8\u6a21\u6001\u5b89\u5168\u98ce\u9669\u3002\u76ee\u524d\u7f3a\u4e4f\u5bf9\u5168\u6a21\u6001\u4ea4\u4e92\u4e2d\u6f0f\u6d1e\u7684\u7cfb\u7edf\u6027\u7406\u89e3\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "1. \u5efa\u7acb\u6a21\u6001-\u8bed\u4e49\u89e3\u8026\u539f\u5219\u5e76\u6784\u5efaAdvBench-Omni\u6570\u636e\u96c6\uff1b2. \u901a\u8fc7\u673a\u5236\u5206\u6790\u53d1\u73b0\u4e2d\u5c42\u89e3\u79bb\u73b0\u8c61\u548c\u6a21\u6001\u4e0d\u53d8\u7684\u7eaf\u62d2\u7edd\u65b9\u5411\uff1b3. \u4f7f\u7528\u5947\u5f02\u503c\u5206\u89e3\u63d0\u53d6\u9ec4\u91d1\u62d2\u7edd\u5411\u91cf\uff1b4. \u63d0\u51faOmniSteer\u65b9\u6cd5\uff0c\u5229\u7528\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u81ea\u9002\u5e94\u8c03\u8282\u5e72\u9884\u5f3a\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5c06\u6709\u5bb3\u8f93\u5165\u7684\u62d2\u7edd\u6210\u529f\u7387\u4ece69.9%\u63d0\u5347\u523091.2%\uff0c\u540c\u65f6\u6709\u6548\u4fdd\u6301\u4e86\u6240\u6709\u6a21\u6001\u7684\u901a\u7528\u80fd\u529b\u3002", "conclusion": "OmniSteer\u65b9\u6cd5\u901a\u8fc7\u7cfb\u7edf\u6027\u5206\u6790\u5168\u6a21\u6001\u6a21\u578b\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5b89\u5168\u589e\u5f3a\u65b9\u6848\uff0c\u5728\u63d0\u5347\u5b89\u5168\u6027\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u591a\u6a21\u6001\u6027\u80fd\u3002"}}
{"id": "2602.10162", "categories": ["cs.CR", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10162", "abs": "https://arxiv.org/abs/2602.10162", "authors": ["Chenhan Xiao", "Yang Weng"], "title": "Limits of Residual-Based Detection for Physically Consistent False Data Injection", "comment": "10 pages, 10 figures", "summary": "False data injection attacks (FDIAs) pose a persistent challenge to AC power system state estimation. In current practice, detection relies primarily on topology-aware residual-based tests that assume malicious measurements can be distinguished from normal operation through physical inconsistency reflected in abnormal residual behavior. This paper shows that this assumption does not always hold: when FDIA scenarios produce manipulated measurements that remain on the measurement manifold induced by AC power flow relations and measurement redundancy, residual-based detectors may fail to distinguish them from nominal data. The resulting detectability limitation is a property of the measurement manifold itself and does not depend on the attacker's detailed knowledge of the physical system model. To make this limitation observable in practice, we present a data-driven constructive mechanism that incorporates the generic functional structure of AC power flow to generate physically consistent, manifold-constrained perturbations, providing a concrete witness of how residual-based detectors can be bypassed. Numerical studies on multiple AC test systems characterize the conditions under which detection becomes challenging and illustrate its failure modes. The results highlight fundamental limits of residual-based detection in AC state estimation and motivate the need for complementary defenses beyond measurement consistency tests.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4e86\u4ea4\u6d41\u7535\u529b\u7cfb\u7edf\u72b6\u6001\u4f30\u8ba1\u4e2d\u57fa\u4e8e\u6b8b\u5dee\u7684\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\uff1a\u5f53\u653b\u51fb\u4ea7\u751f\u7684\u64cd\u7eb5\u6d4b\u91cf\u503c\u4fdd\u6301\u5728\u7531\u4ea4\u6d41\u6f6e\u6d41\u5173\u7cfb\u548c\u6d4b\u91cf\u5197\u4f59\u8bf1\u5bfc\u7684\u6d4b\u91cf\u6d41\u5f62\u4e0a\u65f6\uff0c\u6b8b\u5dee\u68c0\u6d4b\u5668\u53ef\u80fd\u65e0\u6cd5\u5c06\u5176\u4e0e\u6b63\u5e38\u6570\u636e\u533a\u5206\u5f00\u3002", "motivation": "\u5f53\u524d\u5b9e\u8df5\u4e2d\u4e3b\u8981\u4f9d\u8d56\u62d3\u6251\u611f\u77e5\u7684\u6b8b\u5dee\u68c0\u6d4b\u6765\u8bc6\u522b\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5047\u8bbe\u6076\u610f\u6d4b\u91cf\u503c\u53ef\u4ee5\u901a\u8fc7\u7269\u7406\u4e0d\u4e00\u81f4\u6027\u53cd\u6620\u5728\u5f02\u5e38\u6b8b\u5dee\u884c\u4e3a\u4e2d\u88ab\u533a\u5206\u3002\u4f46\u4f5c\u8005\u53d1\u73b0\u8fd9\u4e00\u5047\u8bbe\u5e76\u4e0d\u603b\u662f\u6210\u7acb\uff0c\u9700\u8981\u63ed\u793a\u57fa\u4e8e\u6b8b\u5dee\u68c0\u6d4b\u7684\u6839\u672c\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u6784\u9020\u673a\u5236\uff0c\u7ed3\u5408\u4ea4\u6d41\u6f6e\u6d41\u7684\u901a\u7528\u51fd\u6570\u7ed3\u6784\uff0c\u751f\u6210\u7269\u7406\u4e00\u81f4\u3001\u6d41\u5f62\u7ea6\u675f\u7684\u6270\u52a8\uff0c\u4e3a\u6b8b\u5dee\u68c0\u6d4b\u5668\u5982\u4f55\u88ab\u7ed5\u8fc7\u63d0\u4f9b\u5177\u4f53\u8bc1\u636e\u3002\u5728\u591a\u4e2a\u4ea4\u6d41\u6d4b\u8bd5\u7cfb\u7edf\u4e0a\u8fdb\u884c\u6570\u503c\u7814\u7a76\u3002", "result": "\u6570\u503c\u7814\u7a76\u8868\u660e\uff0c\u5f53\u653b\u51fb\u4ea7\u751f\u7684\u64cd\u7eb5\u6d4b\u91cf\u503c\u4fdd\u6301\u5728\u6d4b\u91cf\u6d41\u5f62\u4e0a\u65f6\uff0c\u6b8b\u5dee\u68c0\u6d4b\u5668\u65e0\u6cd5\u6709\u6548\u68c0\u6d4b\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\u3002\u8fd9\u79cd\u53ef\u68c0\u6d4b\u6027\u9650\u5236\u662f\u6d4b\u91cf\u6d41\u5f62\u672c\u8eab\u7684\u5c5e\u6027\uff0c\u4e0d\u4f9d\u8d56\u4e8e\u653b\u51fb\u8005\u5bf9\u7269\u7406\u7cfb\u7edf\u6a21\u578b\u7684\u8be6\u7ec6\u77e5\u8bc6\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u7a81\u663e\u4e86\u4ea4\u6d41\u72b6\u6001\u4f30\u8ba1\u4e2d\u57fa\u4e8e\u6b8b\u5dee\u68c0\u6d4b\u7684\u6839\u672c\u9650\u5236\uff0c\u8868\u660e\u9700\u8981\u8d85\u8d8a\u6d4b\u91cf\u4e00\u81f4\u6027\u6d4b\u8bd5\u7684\u8865\u5145\u9632\u5fa1\u63aa\u65bd\u3002\u653b\u51fb\u8005\u5373\u4f7f\u4e0d\u4e86\u89e3\u8be6\u7ec6\u7684\u7269\u7406\u7cfb\u7edf\u6a21\u578b\uff0c\u4e5f\u80fd\u6784\u9020\u51fa\u7ed5\u8fc7\u6b8b\u5dee\u68c0\u6d4b\u7684\u865a\u5047\u6570\u636e\u3002"}}
{"id": "2602.10166", "categories": ["cs.CR", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.10166", "abs": "https://arxiv.org/abs/2602.10166", "authors": ["Tatsunori Ono"], "title": "MerkleSpeech: Public-Key Verifiable, Chunk-Localised Speech Provenance via Perceptual Fingerprints and Merkle Commitments", "comment": "16 pages, 4 figures, 3 tables", "summary": "Speech provenance goes beyond detecting whether a watermark is present. Real workflows involve splicing, quoting, trimming, and platform-level transforms that may preserve some regions while altering others. Neural watermarking systems have made strides in robustness and localised detection, but most deployments produce outputs with no third-party verifiable cryptographic proof tying a time segment to an issuer-signed original. Provenance standards like C2PA adopt signed manifests and Merkle-based fragment validation, yet their bindings target encoded assets and break under re-encoding or routine processing.\n  We propose MerkleSpeech, a system for public-key verifiable, chunk-localised speech provenance offering two tiers of assurance. The first, a robust watermark attribution layer (WM-only), survives common distribution transforms and answers \"was this chunk issued by a known party?\". The second, a strict cryptographic integrity layer (MSv1), verifies Merkle inclusion of the chunk's fingerprint under an issuer signature. The system computes perceptual fingerprints over short speech chunks, commits them in a Merkle tree whose root is signed with an issuer key, and embeds a compact in-band watermark payload carrying a random content identifier and chunk metadata sufficient to retrieve Merkle inclusion proofs from a repository. Once the payload is extracted, all subsequent verification steps (signature check, fingerprint recomputation, Merkle inclusion) use only public information. The result is a splice-aware timeline indicating which regions pass each tier and why any given region fails. We describe the protocol, provide pseudocode, and present experiments targeting very low false positive rates under resampling, bandpass filtering, and additive noise, informed by recent audits identifying neural codecs as a major stressor for post-hoc audio watermarks.", "AI": {"tldr": "MerkleSpeech\uff1a\u4e00\u4e2a\u7528\u4e8e\u8bed\u97f3\u6765\u6e90\u9a8c\u8bc1\u7684\u53cc\u5c42\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e86\u9c81\u68d2\u6c34\u5370\u548c\u4e25\u683c\u7684\u5bc6\u7801\u5b66\u5b8c\u6574\u6027\u9a8c\u8bc1\uff0c\u652f\u6301\u7247\u6bb5\u7ea7\u9a8c\u8bc1\u548c\u65f6\u95f4\u7ebf\u5206\u6790\u3002", "motivation": "\u5f53\u524d\u8bed\u97f3\u6765\u6e90\u9a8c\u8bc1\u9762\u4e34\u5b9e\u9645\u5de5\u4f5c\u6d41\u4e2d\u7684\u62fc\u63a5\u3001\u5f15\u7528\u3001\u88c1\u526a\u548c\u5e73\u53f0\u7ea7\u8f6c\u6362\u7b49\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7b2c\u4e09\u65b9\u53ef\u9a8c\u8bc1\u7684\u5bc6\u7801\u5b66\u8bc1\u660e\uff0c\u4e14C2PA\u7b49\u6807\u51c6\u5728\u91cd\u65b0\u7f16\u7801\u6216\u5e38\u89c4\u5904\u7406\u4e0b\u4f1a\u5931\u6548\u3002", "method": "\u7cfb\u7edf\u91c7\u7528\u53cc\u5c42\u9a8c\u8bc1\uff1a1) \u9c81\u68d2\u6c34\u5370\u5f52\u5c5e\u5c42\uff08WM-only\uff09\u7528\u4e8e\u62b5\u6297\u5e38\u89c1\u5206\u53d1\u53d8\u6362\uff1b2) \u4e25\u683c\u5bc6\u7801\u5b66\u5b8c\u6574\u6027\u5c42\uff08MSv1\uff09\u901a\u8fc7Merkle\u6811\u548c\u53d1\u884c\u8005\u7b7e\u540d\u9a8c\u8bc1\u7247\u6bb5\u6307\u7eb9\u3002\u7cfb\u7edf\u8ba1\u7b97\u77ed\u8bed\u97f3\u7247\u6bb5\u7684\u611f\u77e5\u6307\u7eb9\uff0c\u6784\u5efaMerkle\u6811\u5e76\u7b7e\u540d\u6839\u8282\u70b9\uff0c\u5d4c\u5165\u5305\u542b\u5185\u5bb9\u6807\u8bc6\u7b26\u548c\u7247\u6bb5\u5143\u6570\u636e\u7684\u7d27\u51d1\u6c34\u5370\u8f7d\u8377\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u63d0\u4f9b\u62fc\u63a5\u611f\u77e5\u7684\u65f6\u95f4\u7ebf\uff0c\u663e\u793a\u54ea\u4e9b\u533a\u57df\u901a\u8fc7\u5404\u5c42\u9a8c\u8bc1\u4ee5\u53ca\u5931\u8d25\u539f\u56e0\u3002\u5b9e\u9a8c\u9488\u5bf9\u91cd\u91c7\u6837\u3001\u5e26\u901a\u6ee4\u6ce2\u548c\u52a0\u6027\u566a\u58f0\u7b49\u573a\u666f\uff0c\u5b9e\u73b0\u4e86\u6781\u4f4e\u7684\u8bef\u62a5\u7387\uff0c\u7279\u522b\u5173\u6ce8\u4e86\u795e\u7ecf\u7f16\u89e3\u7801\u5668\u5bf9\u540e\u5904\u7406\u6c34\u5370\u7684\u538b\u529b\u3002", "conclusion": "MerkleSpeech\u63d0\u4f9b\u4e86\u4e00\u4e2a\u516c\u5f00\u53ef\u9a8c\u8bc1\u3001\u7247\u6bb5\u672c\u5730\u5316\u7684\u8bed\u97f3\u6765\u6e90\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e86\u9c81\u68d2\u6c34\u5370\u548c\u5bc6\u7801\u5b66\u5b8c\u6574\u6027\u9a8c\u8bc1\uff0c\u80fd\u591f\u5e94\u5bf9\u5b9e\u9645\u5de5\u4f5c\u6d41\u4e2d\u7684\u5404\u79cd\u5904\u7406\u53d8\u6362\u3002"}}
{"id": "2602.10169", "categories": ["cs.CR", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10169", "abs": "https://arxiv.org/abs/2602.10169", "authors": ["Nicolai Maisch", "Shengjian Chen", "Alexander Robertus", "Samed Ajdinovi\u0107", "Armin Lechler", "Alexander Verl", "Oliver Riedel"], "title": "Non-Fungible Blockchain Tokens for Traceable Online-Quality Assurance of Milled Workpieces", "comment": null, "summary": "This work presents a concept and implementation for the secure storage and transfer of quality-relevant data of milled workpieces from online-quality assurance processes enabled by real-time simulation models. It utilises Non-Fungible Tokens (NFT) to securely and interoperably store quality data in the form of an Asset Administration Shell (AAS) on a public Ethereum blockchain. Minted by a custom smart contract, the NFTs reference the metadata saved in the Interplanetary File System (IPFS), allowing new data from additional processing steps to be added in a flexible yet secure manner. The concept enables automated traceability throughout the value chain, minimising the need for time-consuming and costly repetitive manual quality checks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eNFT\u548c\u533a\u5757\u94fe\u7684\u94e3\u524a\u5de5\u4ef6\u8d28\u91cf\u6570\u636e\u5b89\u5168\u5b58\u50a8\u4e0e\u4f20\u8f93\u65b9\u6848\uff0c\u5b9e\u73b0\u8d28\u91cf\u94fe\u81ea\u52a8\u5316\u8ffd\u6eaf", "motivation": "\u89e3\u51b3\u5728\u7ebf\u8d28\u91cf\u4fdd\u8bc1\u8fc7\u7a0b\u4e2d\u94e3\u524a\u5de5\u4ef6\u8d28\u91cf\u76f8\u5173\u6570\u636e\u7684\u5b89\u5168\u5b58\u50a8\u548c\u4f20\u8f93\u95ee\u9898\uff0c\u51cf\u5c11\u8017\u65f6\u4e14\u6210\u672c\u9ad8\u6602\u7684\u91cd\u590d\u4eba\u5de5\u8d28\u91cf\u68c0\u67e5", "method": "\u5229\u7528NFT\u5728\u516c\u5171\u4ee5\u592a\u574a\u533a\u5757\u94fe\u4e0a\u5b89\u5168\u4e92\u64cd\u4f5c\u5730\u5b58\u50a8\u8d44\u4ea7\u7ba1\u7406\u5916\u58f3\u683c\u5f0f\u7684\u8d28\u91cf\u6570\u636e\uff0c\u901a\u8fc7\u81ea\u5b9a\u4e49\u667a\u80fd\u5408\u7ea6\u94f8\u9020NFT\uff0c\u5f15\u7528IPFS\u4e2d\u5b58\u50a8\u7684\u5143\u6570\u636e\uff0c\u652f\u6301\u7075\u6d3b\u6dfb\u52a0\u65b0\u5904\u7406\u6b65\u9aa4\u7684\u6570\u636e", "result": "\u5b9e\u73b0\u4e86\u8d28\u91cf\u6570\u636e\u7684\u5b89\u5168\u5b58\u50a8\u548c\u4f20\u8f93\u7cfb\u7edf\uff0c\u652f\u6301\u6574\u4e2a\u4ef7\u503c\u94fe\u7684\u81ea\u52a8\u5316\u8ffd\u6eaf", "conclusion": "\u8be5\u6982\u5ff5\u4e3a\u5728\u7ebf\u8d28\u91cf\u4fdd\u8bc1\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u5b89\u5168\u3001\u7075\u6d3b\u7684\u8d28\u91cf\u6570\u636e\u7ba1\u7406\u65b9\u6848\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u91cd\u590d\u4eba\u5de5\u8d28\u91cf\u68c0\u67e5\u7684\u9700\u6c42"}}
{"id": "2602.10418", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.10418", "abs": "https://arxiv.org/abs/2602.10418", "authors": ["Weichen Yu", "Ravi Mangal", "Yinyi Luo", "Kai Hu", "Jingxuan He", "Corina S. Pasareanu", "Matt Fredrikson"], "title": "SecCodePRM: A Process Reward Model for Code Security", "comment": "20 pages", "summary": "Large Language Models are rapidly becoming core components of modern software development workflows, yet ensuring code security remains challenging. Existing vulnerability detection pipelines either rely on static analyzers or use LLM/GNN-based detectors trained with coarse program-level supervision. Both families often require complete context, provide sparse end-of-completion feedback, and can degrade as code length grows, making them ill-suited for real-time, prefix-level assessment during interactive coding and streaming generation. We propose SecCodePRM, a security-oriented process reward model that assigns a context-aware, step-level security score along a code trajectory. To train the model, we derive step-level supervision labels from static analyzers and expert annotations, allowing the model to attend more precisely to fine-grained regions associated with inter-procedural vulnerabilities. SecCodePRM has three applications: full-code vulnerability detection (VD), partial-code VD, and secure code generation (CG). For VD, SecCodePRM uses risk-sensitive aggregation that emphasizes high-risk steps; for CG, SecCodePRM supports inference-time scaling by ranking candidate continuations and favoring higher cumulative reward. This design yields dense, real-time feedback that scales to long-horizon generation. Empirically, SecCodePRM outperforms prior approaches in all three settings, while preserving code functional correctness, suggesting improved security without a safety-utility tradeoff.", "AI": {"tldr": "SecCodePRM\u662f\u4e00\u4e2a\u9762\u5411\u5b89\u5168\u7684\u6d41\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u4e3a\u4ee3\u7801\u8f68\u8ff9\u63d0\u4f9b\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6b65\u9aa4\u7ea7\u5b89\u5168\u8bc4\u5206\uff0c\u652f\u6301\u5b9e\u65f6\u6f0f\u6d1e\u68c0\u6d4b\u548c\u5b89\u5168\u4ee3\u7801\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u9759\u6001\u5206\u6790\u5668\uff0c\u8981\u4e48\u4f7f\u7528\u57fa\u4e8eLLM/GNN\u7684\u68c0\u6d4b\u5668\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u5b8c\u6574\u4e0a\u4e0b\u6587\u3001\u63d0\u4f9b\u7a00\u758f\u53cd\u9988\uff0c\u4e14\u968f\u7740\u4ee3\u7801\u957f\u5ea6\u589e\u52a0\u6027\u80fd\u4e0b\u964d\uff0c\u4e0d\u9002\u5408\u4ea4\u4e92\u5f0f\u7f16\u7801\u548c\u6d41\u5f0f\u751f\u6210\u4e2d\u7684\u5b9e\u65f6\u524d\u7f00\u7ea7\u8bc4\u4f30\u3002", "method": "\u63d0\u51faSecCodePRM\u5b89\u5168\u5bfc\u5411\u7684\u6d41\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u4ece\u9759\u6001\u5206\u6790\u5668\u548c\u4e13\u5bb6\u6807\u6ce8\u4e2d\u83b7\u53d6\u6b65\u9aa4\u7ea7\u76d1\u7763\u6807\u7b7e\uff0c\u4f7f\u6a21\u578b\u80fd\u66f4\u7cbe\u786e\u5173\u6ce8\u4e0e\u8de8\u8fc7\u7a0b\u6f0f\u6d1e\u76f8\u5173\u7684\u7ec6\u7c92\u5ea6\u533a\u57df\u3002\u6a21\u578b\u91c7\u7528\u98ce\u9669\u654f\u611f\u805a\u5408\u5f3a\u8c03\u9ad8\u98ce\u9669\u6b65\u9aa4\uff0c\u652f\u6301\u63a8\u7406\u65f6\u6269\u5c55\u901a\u8fc7\u6392\u540d\u5019\u9009\u7ee7\u7eed\u5e76\u9009\u62e9\u66f4\u9ad8\u7d2f\u79ef\u5956\u52b1\u3002", "result": "SecCodePRM\u5728\u4e09\u4e2a\u5e94\u7528\u573a\u666f\uff08\u5b8c\u6574\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u3001\u90e8\u5206\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u3001\u5b89\u5168\u4ee3\u7801\u751f\u6210\uff09\u4e2d\u5747\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u529f\u80fd\u6b63\u786e\u6027\uff0c\u8868\u660e\u5728\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u6ca1\u6709\u6743\u8861\u3002", "conclusion": "SecCodePRM\u63d0\u4f9b\u4e86\u5bc6\u96c6\u7684\u5b9e\u65f6\u53cd\u9988\uff0c\u53ef\u6269\u5c55\u5230\u957f\u65f6\u7a0b\u751f\u6210\uff0c\u6539\u5584\u4e86\u4ee3\u7801\u5b89\u5168\u6027\u800c\u4e0d\u727a\u7272\u529f\u80fd\u6027\uff0c\u4e3a\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u5de5\u4f5c\u6d41\u4e2d\u7684\u5b9e\u65f6\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.10478", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10478", "abs": "https://arxiv.org/abs/2602.10478", "authors": ["Zihao Li", "Hongyi Lu", "Yanan Guo", "Zhenkai Zhang", "Shuai Wang", "Fengwei Zhang"], "title": "GPU-Fuzz: Finding Memory Errors in Deep Learning Frameworks", "comment": null, "summary": "GPU memory errors are a critical threat to deep learning (DL) frameworks, leading to crashes or even security issues. We introduce GPU-Fuzz, a fuzzer locating these issues efficiently by modeling operator parameters as formal constraints. GPU-Fuzz utilizes a constraint solver to generate test cases that systematically probe error-prone boundary conditions in GPU kernels. Applied to PyTorch, TensorFlow, and PaddlePaddle, we uncovered 13 unknown bugs, demonstrating the effectiveness of GPU-Fuzz in finding memory errors.", "AI": {"tldr": "GPU-Fuzz\u662f\u4e00\u4e2a\u9488\u5bf9\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6GPU\u5185\u5b58\u9519\u8bef\u7684\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u7ea6\u675f\u5efa\u6a21\u7b97\u5b50\u53c2\u6570\uff0c\u4f7f\u7528\u7ea6\u675f\u6c42\u89e3\u5668\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5728PyTorch\u3001TensorFlow\u548cPaddlePaddle\u4e2d\u53d1\u73b0\u4e8613\u4e2a\u672a\u77e5\u6f0f\u6d1e\u3002", "motivation": "GPU\u5185\u5b58\u9519\u8bef\u662f\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7684\u5173\u952e\u5a01\u80c1\uff0c\u53ef\u80fd\u5bfc\u81f4\u7cfb\u7edf\u5d29\u6e83\u751a\u81f3\u5b89\u5168\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u9ad8\u6548\u5b9a\u4f4d\u8fd9\u4e9b\u9519\u8bef\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "GPU-Fuzz\u5c06\u7b97\u5b50\u53c2\u6570\u5efa\u6a21\u4e3a\u5f62\u5f0f\u5316\u7ea6\u675f\uff0c\u5229\u7528\u7ea6\u675f\u6c42\u89e3\u5668\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u7cfb\u7edf\u6027\u5730\u63a2\u6d4bGPU\u5185\u6838\u4e2d\u5bb9\u6613\u51fa\u9519\u7684\u8fb9\u754c\u6761\u4ef6\u3002", "result": "\u5728PyTorch\u3001TensorFlow\u548cPaddlePaddle\u4e09\u4e2a\u4e3b\u6d41\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4e2d\u53d1\u73b0\u4e8613\u4e2a\u672a\u77e5\u7684\u5185\u5b58\u9519\u8bef\u6f0f\u6d1e\u3002", "conclusion": "GPU-Fuzz\u80fd\u591f\u6709\u6548\u53d1\u73b0\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4e2d\u7684GPU\u5185\u5b58\u9519\u8bef\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2602.10481", "categories": ["cs.CR", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.10481", "abs": "https://arxiv.org/abs/2602.10481", "authors": ["Mohan Rajagopalan", "Vinay Rao"], "title": "Protecting Context and Prompts: Deterministic Security for Non-Deterministic AI", "comment": null, "summary": "Large Language Model (LLM) applications are vulnerable to prompt injection and context manipulation attacks that traditional security models cannot prevent. We introduce two novel primitives--authenticated prompts and authenticated context--that provide cryptographically verifiable provenance across LLM workflows. Authenticated prompts enable self-contained lineage verification, while authenticated context uses tamper-evident hash chains to ensure integrity of dynamic inputs. Building on these primitives, we formalize a policy algebra with four proven theorems providing protocol-level Byzantine resistance--even adversarial agents cannot violate organizational policies. Five complementary defenses--from lightweight resource controls to LLM-based semantic validation--deliver layered, preventative security with formal guarantees. Evaluation against representative attacks spanning 6 exhaustive categories achieves 100% detection with zero false positives and nominal overhead. We demonstrate the first approach combining cryptographically enforced prompt lineage, tamper-evident context, and provable policy reasoning--shifting LLM security from reactive detection to preventative guarantees.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5bc6\u7801\u5b66\u9a8c\u8bc1\u548c\u5f62\u5f0f\u5316\u8bc1\u660e\u7684LLM\u5b89\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u8ba4\u8bc1\u63d0\u793a\u548c\u8ba4\u8bc1\u4e0a\u4e0b\u6587\u786e\u4fdd\u5de5\u4f5c\u6d41\u5b8c\u6574\u6027\uff0c\u5e76\u63d0\u4f9b\u9884\u9632\u6027\u5b89\u5168\u4fdd\u8bc1\u3002", "motivation": "\u4f20\u7edf\u5b89\u5168\u6a21\u578b\u65e0\u6cd5\u9632\u6b62LLM\u5e94\u7528\u4e2d\u7684\u63d0\u793a\u6ce8\u5165\u548c\u4e0a\u4e0b\u6587\u64cd\u7eb5\u653b\u51fb\uff0c\u9700\u8981\u65b0\u7684\u5b89\u5168\u673a\u5236\u6765\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7684\u5b8c\u6574\u6027\u548c\u9884\u9632\u6027\u4fdd\u62a4\u3002", "method": "\u5f15\u5165\u4e24\u4e2a\u5bc6\u7801\u5b66\u539f\u8bed\uff1a\u8ba4\u8bc1\u63d0\u793a\uff08\u63d0\u4f9b\u81ea\u5305\u542b\u7684\u6eaf\u6e90\u9a8c\u8bc1\uff09\u548c\u8ba4\u8bc1\u4e0a\u4e0b\u6587\uff08\u4f7f\u7528\u9632\u7be1\u6539\u54c8\u5e0c\u94fe\u786e\u4fdd\u52a8\u6001\u8f93\u5165\u5b8c\u6574\u6027\uff09\u3002\u57fa\u4e8e\u8fd9\u4e9b\u539f\u8bed\u6784\u5efa\u5f62\u5f0f\u5316\u7b56\u7565\u4ee3\u6570\uff0c\u63d0\u4f9b\u534f\u8bae\u7ea7\u62dc\u5360\u5ead\u5bb9\u9519\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e94\u5c42\u4e92\u8865\u9632\u5fa1\u673a\u5236\u3002", "result": "\u5728\u6db5\u76d66\u4e2a\u7c7b\u522b\u7684\u4ee3\u8868\u6027\u653b\u51fb\u8bc4\u4f30\u4e2d\uff0c\u5b9e\u73b0\u4e86100%\u68c0\u6d4b\u7387\u3001\u96f6\u8bef\u62a5\u548c\u53ef\u5ffd\u7565\u7684\u5f00\u9500\uff0c\u9996\u6b21\u7ed3\u5408\u4e86\u5bc6\u7801\u5b66\u5f3a\u5236\u7684\u63d0\u793a\u6eaf\u6e90\u3001\u9632\u7be1\u6539\u4e0a\u4e0b\u6587\u548c\u53ef\u8bc1\u660e\u7684\u7b56\u7565\u63a8\u7406\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06LLM\u5b89\u5168\u4ece\u88ab\u52a8\u68c0\u6d4b\u8f6c\u5411\u9884\u9632\u6027\u4fdd\u8bc1\uff0c\u901a\u8fc7\u5bc6\u7801\u5b66\u9a8c\u8bc1\u7684\u5b8c\u6574\u6027\u548c\u5f62\u5f0f\u5316\u8bc1\u660e\u7684\u7b56\u7565\u6267\u884c\uff0c\u4e3aLLM\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u53ef\u9a8c\u8bc1\u7684\u5b89\u5168\u4fdd\u969c\u3002"}}
{"id": "2602.10487", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.10487", "abs": "https://arxiv.org/abs/2602.10487", "authors": ["Viet Hoang Luu", "Amirmohammad Pasdar", "Wachiraphan Charoenwet", "Toby Murray", "Shaanan Cohney", "Van-Thuan Pham"], "title": "Following Dragons: Code Review-Guided Fuzzing", "comment": null, "summary": "Modern fuzzers scale to large, real-world software but often fail to exercise the program states developers consider most fragile or security-critical. Such states are typically deep in the execution space, gated by preconditions, or overshadowed by lower-value paths that consume limited fuzzing budgets. Meanwhile, developers routinely surface risk-relevant insights during code review, yet this information is largely ignored by automated testing tools. We present EyeQ, a system that leverages developer intelligence from code reviews to guide fuzzing. EyeQ extracts security-relevant signals from review discussions, localizes the implicated program regions, and translates these insights into annotation-based guidance for fuzzing. The approach operates atop existing annotation-aware fuzzing, requiring no changes to program semantics or developer workflows. We first validate EyeQ through a human-guided feasibility study on a security-focused dataset of PHP code reviews, establishing a strong baseline for review-guided fuzzing. We then automate the workflow using a large language model with carefully designed prompts. EyeQ significantly improves vulnerability discovery over standard fuzzing configurations, uncovering more than 40 previously unknown bugs in the security-critical PHP codebase.", "AI": {"tldr": "EyeQ\u7cfb\u7edf\u5229\u7528\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u5f00\u53d1\u8005\u667a\u80fd\u6765\u6307\u5bfc\u6a21\u7cca\u6d4b\u8bd5\uff0c\u901a\u8fc7\u63d0\u53d6\u5b89\u5168\u76f8\u5173\u4fe1\u53f7\u3001\u5b9a\u4f4d\u76f8\u5173\u7a0b\u5e8f\u533a\u57df\uff0c\u5e76\u5c06\u8fd9\u4e9b\u6d1e\u5bdf\u8f6c\u5316\u4e3a\u57fa\u4e8e\u6ce8\u89e3\u7684\u6a21\u7cca\u6d4b\u8bd5\u6307\u5bfc\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6f0f\u6d1e\u53d1\u73b0\u80fd\u529b\u3002", "motivation": "\u73b0\u4ee3\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u867d\u7136\u80fd\u6269\u5c55\u5230\u5927\u578b\u5b9e\u9645\u8f6f\u4ef6\uff0c\u4f46\u5f80\u5f80\u65e0\u6cd5\u8986\u76d6\u5f00\u53d1\u8005\u8ba4\u4e3a\u6700\u8106\u5f31\u6216\u5b89\u5168\u5173\u952e\u7684\u7a0b\u5e8f\u72b6\u6001\u3002\u8fd9\u4e9b\u72b6\u6001\u901a\u5e38\u6df1\u85cf\u5728\u6267\u884c\u7a7a\u95f4\u4e2d\uff0c\u53d7\u524d\u7f6e\u6761\u4ef6\u9650\u5236\uff0c\u6216\u88ab\u4f4e\u4ef7\u503c\u8def\u5f84\u63a9\u76d6\u3002\u540c\u65f6\uff0c\u5f00\u53d1\u8005\u5728\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7ecf\u5e38\u53d1\u73b0\u98ce\u9669\u76f8\u5173\u7684\u6d1e\u5bdf\uff0c\u4f46\u8fd9\u4e9b\u4fe1\u606f\u5728\u81ea\u52a8\u5316\u6d4b\u8bd5\u5de5\u5177\u4e2d\u88ab\u5ffd\u89c6\u3002", "method": "EyeQ\u7cfb\u7edf\u4ece\u4ee3\u7801\u5ba1\u67e5\u8ba8\u8bba\u4e2d\u63d0\u53d6\u5b89\u5168\u76f8\u5173\u4fe1\u53f7\uff0c\u5b9a\u4f4d\u6d89\u53ca\u7684\u7a0b\u5e8f\u533a\u57df\uff0c\u5e76\u5c06\u8fd9\u4e9b\u6d1e\u5bdf\u8f6c\u5316\u4e3a\u57fa\u4e8e\u6ce8\u89e3\u7684\u6a21\u7cca\u6d4b\u8bd5\u6307\u5bfc\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u73b0\u6709\u7684\u6ce8\u89e3\u611f\u77e5\u6a21\u7cca\u6d4b\u8bd5\uff0c\u65e0\u9700\u6539\u53d8\u7a0b\u5e8f\u8bed\u4e49\u6216\u5f00\u53d1\u8005\u5de5\u4f5c\u6d41\u7a0b\u3002\u9996\u5148\u901a\u8fc7\u4eba\u5de5\u6307\u5bfc\u7684\u53ef\u884c\u6027\u7814\u7a76\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u7136\u540e\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u7a0b\u3002", "result": "EyeQ\u663e\u8457\u6539\u8fdb\u4e86\u6f0f\u6d1e\u53d1\u73b0\u80fd\u529b\uff0c\u5728\u5b89\u5168\u5173\u952e\u7684PHP\u4ee3\u7801\u5e93\u4e2d\u53d1\u73b0\u4e8640\u591a\u4e2a\u5148\u524d\u672a\u77e5\u7684\u6f0f\u6d1e\uff0c\u76f8\u6bd4\u6807\u51c6\u6a21\u7cca\u6d4b\u8bd5\u914d\u7f6e\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u5f00\u53d1\u8005\u667a\u80fd\u6765\u6307\u5bfc\u6a21\u7cca\u6d4b\u8bd5\uff0cEyeQ\u80fd\u591f\u66f4\u6709\u6548\u5730\u53d1\u73b0\u5b89\u5168\u6f0f\u6d1e\uff0c\u8bc1\u660e\u4e86\u5c06\u4eba\u5de5\u5ba1\u67e5\u6d1e\u5bdf\u4e0e\u81ea\u52a8\u5316\u6d4b\u8bd5\u5de5\u5177\u7ed3\u5408\u7684\u4ef7\u503c\u3002"}}
{"id": "2602.10750", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10750", "abs": "https://arxiv.org/abs/2602.10750", "authors": ["Rumman Firdos", "Aman Dangi"], "title": "SecureScan: An AI-Driven Multi-Layer Framework for Malware and Phishing Detection Using Logistic Regression and Threat Intelligence Integration", "comment": null, "summary": "The growing sophistication of modern malware and phishing campaigns has diminished the effectiveness of traditional signature-based intrusion detection systems. This work presents SecureScan, an AI-driven, triple-layer detection framework that integrates logistic regression-based classification, heuristic analysis, and external threat intelligence via the VirusTotal API for comprehensive triage of URLs, file hashes, and binaries. The proposed architecture prioritizes efficiency by filtering known threats through heuristics, classifying uncertain samples using machine learning, and validating borderline cases with third-party intelligence. On benchmark datasets, SecureScan achieves 93.1 percent accuracy with balanced precision (0.87) and recall (0.92), demonstrating strong generalization and reduced overfitting through threshold-based decision calibration. A calibrated threshold and gray-zone logic (0.45-0.55) were introduced to minimize false positives and enhance real-world stability. Experimental results indicate that a lightweight statistical model, when augmented with calibrated verification and external intelligence, can achieve reliability and performance comparable to more complex deep learning systems.", "AI": {"tldr": "SecureScan\u662f\u4e00\u4e2aAI\u9a71\u52a8\u7684\u4e09\u5c42\u68c0\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u903b\u8f91\u56de\u5f52\u5206\u7c7b\u3001\u542f\u53d1\u5f0f\u5206\u6790\u548c\u5916\u90e8\u5a01\u80c1\u60c5\u62a5\uff0c\u7528\u4e8eURL\u3001\u6587\u4ef6\u54c8\u5e0c\u548c\u4e8c\u8fdb\u5236\u6587\u4ef6\u7684\u7efc\u5408\u68c0\u6d4b\uff0c\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u523093.1%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u4ee3\u6076\u610f\u8f6f\u4ef6\u548c\u9493\u9c7c\u653b\u51fb\u65e5\u76ca\u590d\u6742\uff0c\u4f20\u7edf\u57fa\u4e8e\u7b7e\u540d\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u6548\u679c\u4e0b\u964d\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e09\u5c42\u68c0\u6d4b\u6846\u67b6\uff1a1) \u542f\u53d1\u5f0f\u5206\u6790\u8fc7\u6ee4\u5df2\u77e5\u5a01\u80c1\uff1b2) \u673a\u5668\u5b66\u4e60\uff08\u903b\u8f91\u56de\u5f52\uff09\u5206\u7c7b\u4e0d\u786e\u5b9a\u6837\u672c\uff1b3) \u901a\u8fc7VirusTotal API\u9a8c\u8bc1\u8fb9\u754c\u6848\u4f8b\u3002\u5f15\u5165\u9608\u503c\u6821\u51c6\u548c\u7070\u533a\u903b\u8f91(0.45-0.55)\u51cf\u5c11\u8bef\u62a5\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u523093.1%\u51c6\u786e\u7387\uff0c\u7cbe\u786e\u5ea60.87\uff0c\u53ec\u56de\u73870.92\uff0c\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u51cf\u5c11\u8fc7\u62df\u5408\u3002\u8f7b\u91cf\u7ea7\u7edf\u8ba1\u6a21\u578b\u7ed3\u5408\u6821\u51c6\u9a8c\u8bc1\u548c\u5916\u90e8\u60c5\u62a5\uff0c\u6027\u80fd\u53ef\u4e0e\u590d\u6742\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u5ab2\u7f8e\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u7edf\u8ba1\u6a21\u578b\u901a\u8fc7\u6821\u51c6\u9a8c\u8bc1\u548c\u5916\u90e8\u5a01\u80c1\u60c5\u62a5\u589e\u5f3a\uff0c\u80fd\u591f\u5b9e\u73b0\u4e0e\u590d\u6742\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u76f8\u5f53\u7684\u53ef\u9760\u6027\u548c\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.10498", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.10498", "abs": "https://arxiv.org/abs/2602.10498", "authors": ["Qianli Wang", "Boyang Ma", "Minghui Xu", "Yue Zhang"], "title": "When Skills Lie: Hidden-Comment Injection in LLM Agents", "comment": "4 pages", "summary": "LLM agents often rely on Skills to describe available tools and recommended procedures. We study a hidden-comment prompt injection risk in this documentation layer: when a Markdown Skill is rendered to HTML, HTML comment blocks can become invisible to human reviewers, yet the raw text may still be supplied verbatim to the model. In experiments, we find that DeepSeek-V3.2 and GLM-4.5-Air can be influenced by malicious instructions embedded in a hidden comment appended to an otherwise legitimate Skill, yielding outputs that contain sensitive tool intentions. A short defensive system prompt that treats Skills as untrusted and forbids sensitive actions prevents these malicious tool calls and instead surfaces the suspicious hidden instructions.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u667a\u80fd\u4f53\u6280\u80fd\u6587\u6863\u4e2d\u7684\u9690\u85cf\u6ce8\u91ca\u5b58\u5728\u63d0\u793a\u6ce8\u5165\u98ce\u9669\uff0c\u6076\u610f\u6307\u4ee4\u53ef\u901a\u8fc7HTML\u6ce8\u91ca\u9690\u85cf\uff0c\u5f71\u54cdDeepSeek-V3.2\u548cGLM-4.5-Air\u6a21\u578b\u6267\u884c\u654f\u611f\u5de5\u5177\u8c03\u7528", "motivation": "LLM\u667a\u80fd\u4f53\u901a\u5e38\u4f9d\u8d56\u6280\u80fd\u6587\u6863\u6765\u63cf\u8ff0\u53ef\u7528\u5de5\u5177\u548c\u63a8\u8350\u6d41\u7a0b\uff0c\u4f46Markdown\u6280\u80fd\u6587\u6863\u5728\u6e32\u67d3\u4e3aHTML\u65f6\uff0cHTML\u6ce8\u91ca\u5757\u53ef\u80fd\u5bf9\u4eba\u7c7b\u5ba1\u67e5\u8005\u4e0d\u53ef\u89c1\uff0c\u800c\u539f\u59cb\u6587\u672c\u4ecd\u4f1a\u5b8c\u6574\u63d0\u4f9b\u7ed9\u6a21\u578b\uff0c\u8fd9\u6784\u6210\u4e86\u6f5c\u5728\u7684\u5b89\u5168\u98ce\u9669", "method": "\u901a\u8fc7\u5728\u5408\u6cd5\u6280\u80fd\u6587\u6863\u4e2d\u9644\u52a0\u6076\u610f\u6307\u4ee4\u7684\u9690\u85cf\u6ce8\u91ca\uff0c\u6d4b\u8bd5DeepSeek-V3.2\u548cGLM-4.5-Air\u6a21\u578b\u662f\u5426\u4f1a\u88ab\u5f71\u54cd\uff0c\u5e76\u8bbe\u8ba1\u9632\u5fa1\u6027\u7cfb\u7edf\u63d0\u793a\u6765\u9632\u6b62\u6076\u610f\u5de5\u5177\u8c03\u7528", "result": "\u5b9e\u9a8c\u53d1\u73b0DeepSeek-V3.2\u548cGLM-4.5-Air\u6a21\u578b\u786e\u5b9e\u4f1a\u53d7\u5230\u9690\u85cf\u6ce8\u91ca\u4e2d\u6076\u610f\u6307\u4ee4\u7684\u5f71\u54cd\uff0c\u4ea7\u751f\u5305\u542b\u654f\u611f\u5de5\u5177\u610f\u56fe\u7684\u8f93\u51fa\uff1b\u800c\u7b80\u77ed\u7684\u9632\u5fa1\u6027\u7cfb\u7edf\u63d0\u793a\u80fd\u6709\u6548\u963b\u6b62\u6076\u610f\u5de5\u5177\u8c03\u7528\u5e76\u66b4\u9732\u53ef\u7591\u7684\u9690\u85cf\u6307\u4ee4", "conclusion": "\u6280\u80fd\u6587\u6863\u5c42\u5b58\u5728\u9690\u85cf\u6ce8\u91ca\u63d0\u793a\u6ce8\u5165\u98ce\u9669\uff0c\u9700\u8981\u5c06\u6280\u80fd\u89c6\u4e3a\u4e0d\u53ef\u4fe1\u6765\u6e90\u5e76\u7981\u6b62\u654f\u611f\u64cd\u4f5c\uff0c\u9632\u5fa1\u6027\u7cfb\u7edf\u63d0\u793a\u80fd\u6709\u6548\u7f13\u89e3\u6b64\u5b89\u5168\u5a01\u80c1"}}
{"id": "2602.10573", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.10573", "abs": "https://arxiv.org/abs/2602.10573", "authors": ["Ruisheng Shi", "Ziding Lin", "Haoran Sun", "Qin Wang", "Shihan Zhang", "Lina Lan", "Zhiyuan Peng", "Chenfeng Wang"], "title": "CryptoCatch: Cryptomining Hidden Nowhere", "comment": "IEEE TDSC with DOI 10.1109/TDSC.2026.3661145", "summary": "Cryptomining poses significant security risks, yet traditional detection methods like blacklists and Deep Packet Inspection (DPI) are often ineffective against encrypted mining traffic and suffer from high false positive rates. In this paper, we propose a practical encrypted cryptomining traffic detection mechanism. It consists of a two-stage detection framework, which can effectively provide fine-grained detection results by machine learning and reduce false positives from classifiers through active probing. Our system achieves an F1-score of 0.99 and identifies specific cryptocurrencies with a 99.39\\% accuracy rate. Extensive testing across various mining pools confirms the effectiveness of our approach, offering a more precise and reliable solution for identifying cryptomining activities.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5b9e\u7528\u7684\u52a0\u5bc6\u52a0\u5bc6\u8d27\u5e01\u6316\u77ff\u6d41\u91cf\u68c0\u6d4b\u673a\u5236\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u68c0\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u548c\u4e3b\u52a8\u63a2\u6d4b\uff0c\u6709\u6548\u964d\u4f4e\u8bef\u62a5\u7387\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u3002", "motivation": "\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\uff08\u5982\u9ed1\u540d\u5355\u548c\u6df1\u5ea6\u5305\u68c0\u6d4b\uff09\u5bf9\u52a0\u5bc6\u6316\u77ff\u6d41\u91cf\u6548\u679c\u4e0d\u4f73\uff0c\u4e14\u8bef\u62a5\u7387\u9ad8\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5e94\u5bf9\u52a0\u5bc6\u8d27\u5e01\u6316\u77ff\u5e26\u6765\u7684\u5b89\u5168\u98ce\u9669\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u68c0\u6d4b\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u8fdb\u884c\u7ec6\u7c92\u5ea6\u68c0\u6d4b\uff0c\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u4e3b\u52a8\u63a2\u6d4b\u6765\u51cf\u5c11\u5206\u7c7b\u5668\u7684\u8bef\u62a5\u3002", "result": "\u7cfb\u7edf\u8fbe\u5230F1\u5206\u65700.99\uff0c\u8bc6\u522b\u7279\u5b9a\u52a0\u5bc6\u8d27\u5e01\u7684\u51c6\u786e\u7387\u8fbe99.39%\uff0c\u5728\u591a\u4e2a\u6316\u77ff\u6c60\u7684\u5e7f\u6cdb\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7cbe\u786e\u53ef\u9760\u7684\u52a0\u5bc6\u8d27\u5e01\u6316\u77ff\u6d3b\u52a8\u8bc6\u522b\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u52a0\u5bc6\u6316\u77ff\u6d41\u91cf\u5e76\u663e\u8457\u964d\u4f4e\u8bef\u62a5\u7387\u3002"}}
{"id": "2602.10626", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.10626", "abs": "https://arxiv.org/abs/2602.10626", "authors": ["Ruisheng Shi", "Zhiyuan Peng", "Tong Fu", "Lina Lan", "Qin Wang", "Jiaqi Zeng"], "title": "Invisible Trails? An Identity Alignment Scheme based on Online Tracking", "comment": "IEEE TDSC with DOI 10.1109/TDSC.2025.3627604", "summary": "Many tracking companies collect user data and sell it to data markets and advertisers. While they claim to protect user privacy by anonymizing the data, our research reveals that significant privacy risks persist even with anonymized data. Attackers can exploit this data to identify users' accounts on other websites and perform targeted identity alignment. In this paper, we propose an effective identity alignment scheme for accurately identifying targeted users. We develop a data collector to obtain the necessary datasets, an algorithm for identity alignment, and, based on this, construct two types of de-anonymization attacks: the \\textit{passive attack}, which analyzes tracker data to align identities, and the \\textit{active attack}, which induces users to interact online, leading to higher success rates. Furthermore, we introduce, for the first time, a novel evaluation framework for online tracking-based identity alignment. We investigate the key factors influencing the effectiveness of identity alignment. Additionally, we provide an independent assessment of our generated dataset and present a fully functional system prototype applied to a cryptocurrency use case.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63ed\u793a\u4e86\u533f\u540d\u5316\u7528\u6237\u6570\u636e\u4ecd\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ef\u5229\u7528\u8ffd\u8e2a\u6570\u636e\u8fdb\u884c\u8eab\u4efd\u5bf9\u9f50\u653b\u51fb\uff0c\u63d0\u51fa\u4e86\u88ab\u52a8\u548c\u4e3b\u52a8\u4e24\u79cd\u53bb\u533f\u540d\u5316\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e86\u9996\u4e2a\u5728\u7ebf\u8ffd\u8e2a\u8eab\u4efd\u5bf9\u9f50\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u5c3d\u7ba1\u8ffd\u8e2a\u516c\u53f8\u58f0\u79f0\u901a\u8fc7\u533f\u540d\u5316\u4fdd\u62a4\u7528\u6237\u9690\u79c1\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u533f\u540d\u5316\u6570\u636e\u4ecd\u5b58\u5728\u91cd\u5927\u9690\u79c1\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u5229\u7528\u8fd9\u4e9b\u6570\u636e\u8bc6\u522b\u7528\u6237\u5728\u5176\u4ed6\u7f51\u7ad9\u4e0a\u7684\u8d26\u6237\u5e76\u8fdb\u884c\u7cbe\u51c6\u8eab\u4efd\u5bf9\u9f50\uff0c\u8fd9\u66b4\u9732\u4e86\u5f53\u524d\u9690\u79c1\u4fdd\u62a4\u63aa\u65bd\u7684\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1\u4e86\u6570\u636e\u6536\u96c6\u5668\u83b7\u53d6\u5fc5\u8981\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u4e86\u8eab\u4efd\u5bf9\u9f50\u7b97\u6cd5\uff0c\u6784\u5efa\u4e86\u4e24\u79cd\u53bb\u533f\u540d\u5316\u653b\u51fb\uff1a\u88ab\u52a8\u653b\u51fb\uff08\u5206\u6790\u8ffd\u8e2a\u6570\u636e\u5bf9\u9f50\u8eab\u4efd\uff09\u548c\u4e3b\u52a8\u653b\u51fb\uff08\u8bf1\u5bfc\u7528\u6237\u5728\u7ebf\u4e92\u52a8\u4ee5\u63d0\u9ad8\u6210\u529f\u7387\uff09\uff0c\u5e76\u9996\u6b21\u5f15\u5165\u4e86\u5728\u7ebf\u8ffd\u8e2a\u8eab\u4efd\u5bf9\u9f50\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u8eab\u4efd\u5bf9\u9f50\u65b9\u6848\uff0c\u88ab\u52a8\u653b\u51fb\u548c\u4e3b\u52a8\u653b\u51fb\u90fd\u80fd\u6709\u6548\u8bc6\u522b\u76ee\u6807\u7528\u6237\uff0c\u4e3b\u52a8\u653b\u51fb\u6210\u529f\u7387\u66f4\u9ad8\u3002\u5efa\u7acb\u4e86\u8bc4\u4f30\u6846\u67b6\u5e76\u5206\u6790\u4e86\u5f71\u54cd\u8eab\u4efd\u5bf9\u9f50\u6548\u679c\u7684\u5173\u952e\u56e0\u7d20\uff0c\u63d0\u4f9b\u4e86\u751f\u6210\u6570\u636e\u96c6\u7684\u72ec\u7acb\u8bc4\u4f30\uff0c\u5e76\u5728\u52a0\u5bc6\u8d27\u5e01\u7528\u4f8b\u4e2d\u5c55\u793a\u4e86\u5b8c\u6574\u7cfb\u7edf\u539f\u578b\u3002", "conclusion": "\u533f\u540d\u5316\u6570\u636e\u5e76\u4e0d\u80fd\u5b8c\u5168\u4fdd\u62a4\u7528\u6237\u9690\u79c1\uff0c\u8eab\u4efd\u5bf9\u9f50\u653b\u51fb\u5177\u6709\u663e\u8457\u5a01\u80c1\u3002\u9700\u8981\u66f4\u5f3a\u5927\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u6765\u5e94\u5bf9\u6b64\u7c7b\u653b\u51fb\uff0c\u8bba\u6587\u63d0\u51fa\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u653b\u51fb\u65b9\u6cd5\u4e3a\u7406\u89e3\u548c\u9632\u5fa1\u6b64\u7c7b\u9690\u79c1\u5a01\u80c1\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2602.11015", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11015", "abs": "https://arxiv.org/abs/2602.11015", "authors": ["Valery Khvatov", "Alexey Neyman"], "title": "CVPL: A Geometric Framework for Post-Hoc Linkage Risk Assessment in Protected Tabular Data", "comment": "53 pages, 9 figures, 6 appendices. Code: https://github.com/DGT-Network/cvpl", "summary": "Formal privacy metrics provide compliance-oriented guarantees but often fail to quantify actual linkability in released datasets. We introduce CVPL (Cluster-Vector-Projection Linkage), a geometric framework for post-hoc assessment of linkage risk between original and protected tabular data. CVPL represents linkage analysis as an operator pipeline comprising blocking, vectorization, latent projection, and similarity evaluation, yielding continuous, scenario-dependent risk estimates rather than binary compliance verdicts. We formally define CVPL under an explicit threat model and introduce threshold-aware risk surfaces, R(lambda, tau), that capture the joint effects of protection strength and attacker strictness. We establish a progressive blocking strategy with monotonicity guarantees, enabling anytime risk estimation with valid lower bounds. We demonstrate that the classical Fellegi-Sunter linkage emerges as a special case of CVPL under restrictive assumptions, and that violations of these assumptions can lead to systematic over-linking bias. Empirical validation on 10,000 records across 19 protection configurations demonstrates that formal k-anonymity compliance may coexist with substantial empirical linkability, with a significant portion arising from non-quasi-identifier behavioral patterns. CVPL provides interpretable diagnostics identifying which features drive linkage feasibility, supporting privacy impact assessment, protection mechanism comparison, and utility-risk trade-off analysis.", "AI": {"tldr": "CVPL\u662f\u4e00\u4e2a\u51e0\u4f55\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u539f\u59cb\u6570\u636e\u4e0e\u4fdd\u62a4\u540e\u8868\u683c\u6570\u636e\u4e4b\u95f4\u7684\u94fe\u63a5\u98ce\u9669\uff0c\u63d0\u4f9b\u8fde\u7eed\u7684\u98ce\u9669\u4f30\u8ba1\u800c\u975e\u4e8c\u5143\u5408\u89c4\u5224\u65ad\u3002", "motivation": "\u5f62\u5f0f\u5316\u9690\u79c1\u5ea6\u91cf\u901a\u5e38\u53ea\u63d0\u4f9b\u5408\u89c4\u6027\u4fdd\u8bc1\uff0c\u4f46\u65e0\u6cd5\u91cf\u5316\u53d1\u5e03\u6570\u636e\u96c6\u4e2d\u5b9e\u9645\u7684\u94fe\u63a5\u53ef\u80fd\u6027\u3002\u9700\u8981\u4e00\u79cd\u540e\u9a8c\u8bc4\u4f30\u65b9\u6cd5\u6765\u8861\u91cf\u539f\u59cb\u6570\u636e\u4e0e\u4fdd\u62a4\u540e\u6570\u636e\u4e4b\u95f4\u7684\u94fe\u63a5\u98ce\u9669\u3002", "method": "CVPL\u5c06\u94fe\u63a5\u5206\u6790\u5efa\u6a21\u4e3a\u64cd\u4f5c\u7b26\u6d41\u6c34\u7ebf\uff1a\u5206\u5757\u3001\u5411\u91cf\u5316\u3001\u6f5c\u5728\u6295\u5f71\u548c\u76f8\u4f3c\u6027\u8bc4\u4f30\u3002\u5f15\u5165\u9608\u503c\u611f\u77e5\u98ce\u9669\u66f2\u9762R(\u03bb, \u03c4)\u6765\u6355\u6349\u4fdd\u62a4\u5f3a\u5ea6\u548c\u653b\u51fb\u8005\u4e25\u683c\u5ea6\u7684\u8054\u5408\u6548\u5e94\u3002\u5efa\u7acb\u5177\u6709\u5355\u8c03\u6027\u4fdd\u8bc1\u7684\u6e10\u8fdb\u5206\u5757\u7b56\u7565\u3002", "result": "\u572810,000\u6761\u8bb0\u5f55\u548c19\u79cd\u4fdd\u62a4\u914d\u7f6e\u4e0a\u7684\u5b9e\u8bc1\u9a8c\u8bc1\u8868\u660e\uff0c\u5f62\u5f0f\u5316\u7684k-\u533f\u540d\u5408\u89c4\u53ef\u80fd\u4e0e\u5b9e\u8d28\u6027\u7684\u7ecf\u9a8c\u94fe\u63a5\u6027\u5171\u5b58\uff0c\u5176\u4e2d\u5f88\u5927\u4e00\u90e8\u5206\u6765\u81ea\u975e\u51c6\u6807\u8bc6\u7b26\u7684\u884c\u4e3a\u6a21\u5f0f\u3002CVPL\u80fd\u8bc6\u522b\u9a71\u52a8\u94fe\u63a5\u53ef\u884c\u6027\u7684\u7279\u5f81\u3002", "conclusion": "CVPL\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u652f\u6301\u9690\u79c1\u5f71\u54cd\u8bc4\u4f30\u3001\u4fdd\u62a4\u673a\u5236\u6bd4\u8f83\u548c\u6548\u7528-\u98ce\u9669\u6743\u8861\u5206\u6790\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u4e8c\u5143\u5408\u89c4\u5224\u65ad\uff0c\u80fd\u66f4\u51c6\u786e\u5730\u91cf\u5316\u5b9e\u9645\u94fe\u63a5\u98ce\u9669\u3002"}}
{"id": "2602.10778", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.10778", "abs": "https://arxiv.org/abs/2602.10778", "authors": ["Maximilian Thang", "Lichao Wu", "Sasha Behrouzi", "Mohamadreza Rostami", "Jona te Lintelo", "Stjepan Picek", "Ahmad-Reza Sadeghi"], "title": "GoodVibe: Security-by-Vibe for LLM-Based Code Generation", "comment": null, "summary": "Large language models (LLMs) are increasingly used for code generation in fast, informal development workflows, often referred to as vibe coding, where speed and convenience are prioritized, and security requirements are rarely made explicit. In this setting, models frequently produce functionally correct but insecure code, creating a growing security risk. Existing approaches to improving code security rely on full-parameter fine-tuning or parameter-efficient adaptations, which are either costly and prone to catastrophic forgetting or operate at coarse granularity with limited interpretability and control.\n  We present GoodVibe, a neuron-level framework for improving the security of code language models by default. GoodVibe is based on the key insight that security-relevant reasoning is localized to a small subset of neurons. We identify these neurons using gradient-based attribution from a supervised security task and perform neuron-selective fine-tuning that updates only this security-critical subspace. To further reduce training cost, we introduce activation-driven neuron clustering, enabling structured updates with minimal overhead. We evaluate GoodVibe on six LLMs across security-critical programming languages, including C++, Java, Swift, and Go. GoodVibe substantially improves the security of generated code while preserving general model utility, achieving up to a 2.5x improvement over base models, matching or exceeding full fine-tuning with over 4,700x fewer trainable parameters, and reducing training computation by more than 3.6x compared to the parameter-efficient baseline (LoRA). Our results demonstrate that neuron-level optimization offers an effective and scalable approach to securing code generation without sacrificing efficiency or generality.", "AI": {"tldr": "GoodVibe\u662f\u4e00\u4e2a\u795e\u7ecf\u5143\u7ea7\u522b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8bc6\u522b\u5b89\u5168\u76f8\u5173\u795e\u7ecf\u5143\u5e76\u8fdb\u884c\u9009\u62e9\u6027\u5fae\u8c03\uff0c\u663e\u8457\u63d0\u5347\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u901a\u7528\u80fd\u529b\uff0c\u8bad\u7ec3\u6210\u672c\u8fdc\u4f4e\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "LLM\u5728\u5feb\u901f\u975e\u6b63\u5f0f\u5f00\u53d1\uff08vibe coding\uff09\u4e2d\u7ecf\u5e38\u751f\u6210\u529f\u80fd\u6b63\u786e\u4f46\u4e0d\u5b89\u5168\u7684\u4ee3\u7801\uff0c\u73b0\u6709\u5b89\u5168\u6539\u8fdb\u65b9\u6cd5\u8981\u4e48\u6210\u672c\u9ad8\u3001\u5bb9\u6613\u707e\u96be\u6027\u9057\u5fd8\uff0c\u8981\u4e48\u7c92\u5ea6\u7c97\u3001\u53ef\u89e3\u91ca\u6027\u548c\u63a7\u5236\u6709\u9650\u3002", "method": "\u57fa\u4e8e\u5b89\u5168\u76f8\u5173\u63a8\u7406\u96c6\u4e2d\u5728\u5c11\u6570\u795e\u7ecf\u5143\u7684\u6d1e\u5bdf\uff0c\u4f7f\u7528\u68af\u5ea6\u5f52\u56e0\u8bc6\u522b\u5b89\u5168\u5173\u952e\u795e\u7ecf\u5143\uff0c\u8fdb\u884c\u795e\u7ecf\u5143\u9009\u62e9\u6027\u5fae\u8c03\uff0c\u5e76\u5f15\u5165\u6fc0\u6d3b\u9a71\u52a8\u7684\u795e\u7ecf\u5143\u805a\u7c7b\u4ee5\u51cf\u5c11\u8bad\u7ec3\u6210\u672c\u3002", "result": "\u5728C++\u3001Java\u3001Swift\u3001Go\u7b49\u5b89\u5168\u5173\u952e\u7f16\u7a0b\u8bed\u8a00\u76846\u4e2aLLM\u4e0a\u8bc4\u4f30\uff0c\u5b89\u5168\u6027\u63d0\u5347\u8fbe2.5\u500d\uff0c\u5339\u914d\u6216\u8d85\u8fc7\u5168\u5fae\u8c03\u6548\u679c\u4f46\u53ef\u8bad\u7ec3\u53c2\u6570\u51cf\u5c114700\u500d\uff0c\u8bad\u7ec3\u8ba1\u7b97\u6bd4LoRA\u51cf\u5c113.6\u500d\u4ee5\u4e0a\u3002", "conclusion": "\u795e\u7ecf\u5143\u7ea7\u522b\u4f18\u5316\u4e3a\u5b89\u5168\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u5728\u4e0d\u727a\u7272\u6548\u7387\u6216\u901a\u7528\u6027\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u5b89\u5168\u6027\u3002"}}
{"id": "2602.11019", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.11019", "abs": "https://arxiv.org/abs/2602.11019", "authors": ["Jericho Cain", "Hayden Beadles"], "title": "Mask-Based Window-Level Insider Threat Detection for Campaign Discovery", "comment": null, "summary": "User and Entity Behavior Analytics (UEBA) systems commonly detect insider threats by scoring fixed time windows of user activity for anomalous behavior. While this window-level paradigm has proven effective for identifying sharp behavioral deviations, it remains unclear how much information about longer-running attack campaigns is already present within individual windows, and how such information can be leveraged for campaign discovery. In this work, we study unsupervised window-level insider threat detection on the CERT r4.2 dataset and show that explicitly separating activity presence from activity magnitude yields substantial performance gains. We introduce a dual-channel convolutional autoencoder that reconstructs both a binary activity mask and corresponding activity values, allowing the model to focus representational capacity on sparse behavioral structure rather than dense inactive baselines. Across multiday attack campaigns lasting between one and seven days, the proposed approach achieves a window-level precision-recall AUC of 0.71, substantially exceeding standard unsupervised autoencoder baselines and enabling high-precision operating points with zero false alarms.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u901a\u9053\u5377\u79ef\u81ea\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u5206\u79bb\u6d3b\u52a8\u5b58\u5728\u6027\u548c\u6d3b\u52a8\u5f3a\u5ea6\u6765\u6539\u8fdb\u7528\u6237\u548c\u5b9e\u4f53\u884c\u4e3a\u5206\u6790\u4e2d\u7684\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\uff0c\u5728CERT r4.2\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u56fa\u5b9a\u65f6\u95f4\u7a97\u53e3\u7684\u7528\u6237\u548c\u5b9e\u4f53\u884c\u4e3a\u5206\u6790\u7cfb\u7edf\u5728\u68c0\u6d4b\u77ed\u671f\u884c\u4e3a\u5f02\u5e38\u65b9\u9762\u6709\u6548\uff0c\u4f46\u5bf9\u4e8e\u6301\u7eed\u65f6\u95f4\u8f83\u957f\u7684\u653b\u51fb\u6d3b\u52a8\uff0c\u5c1a\u4e0d\u6e05\u695a\u5355\u4e2a\u7a97\u53e3\u5185\u5df2\u5305\u542b\u591a\u5c11\u4fe1\u606f\uff0c\u4ee5\u53ca\u5982\u4f55\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u8fdb\u884c\u653b\u51fb\u6d3b\u52a8\u53d1\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u901a\u9053\u5377\u79ef\u81ea\u7f16\u7801\u5668\uff0c\u540c\u65f6\u91cd\u6784\u4e8c\u8fdb\u5236\u6d3b\u52a8\u63a9\u7801\u548c\u5bf9\u5e94\u7684\u6d3b\u52a8\u6570\u503c\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5c06\u8868\u793a\u80fd\u529b\u96c6\u4e2d\u5728\u7a00\u758f\u7684\u884c\u4e3a\u7ed3\u6784\u4e0a\uff0c\u800c\u4e0d\u662f\u5bc6\u96c6\u7684\u975e\u6d3b\u52a8\u57fa\u7ebf\u3002", "result": "\u5728\u6301\u7eed1-7\u5929\u7684\u591a\u65e5\u653b\u51fb\u6d3b\u52a8\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u7a97\u53e3\u7ea7\u7cbe\u786e\u7387-\u53ec\u56de\u7387AUC\u4e3a0.71\uff0c\u663e\u8457\u8d85\u8fc7\u6807\u51c6\u65e0\u76d1\u7763\u81ea\u7f16\u7801\u5668\u57fa\u7ebf\uff0c\u5e76\u5b9e\u73b0\u4e86\u96f6\u8bef\u62a5\u7684\u9ad8\u7cbe\u5ea6\u64cd\u4f5c\u70b9\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u5206\u79bb\u6d3b\u52a8\u5b58\u5728\u6027\u548c\u6d3b\u52a8\u5f3a\u5ea6\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u65e0\u76d1\u7763\u7a97\u53e3\u7ea7\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u6027\u80fd\uff0c\u4e3a\u53d1\u73b0\u957f\u671f\u653b\u51fb\u6d3b\u52a8\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2602.11023", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.11023", "abs": "https://arxiv.org/abs/2602.11023", "authors": ["Shaoyu Li", "Hexuan Yu", "Shanghao Shi", "Md Mohaimin Al Barat", "Yang Xiao", "Y. Thomas Hou", "Wenjing Lou"], "title": "IU-GUARD: Privacy-Preserving Spectrum Coordination for Incumbent Users under Dynamic Spectrum Sharing", "comment": null, "summary": "With the growing demand for wireless spectrum, dynamic spectrum sharing (DSS) frameworks such as the Citizens Broadband Radio Service (CBRS) have emerged as practical solutions to improve utilization while protecting incumbent users (IUs) such as military radars. However, current incumbent protection mechanisms face critical limitations. The Environmental Sensing Capability (ESC) requires costly sensor deployments and remains vulnerable to interference and security risks. Alternatively, the Incumbent Informing Capability (IIC) requires IUs to disclose their identities and operational parameters to the Spectrum Coordination System (SCS), creating linkable records that compromise operational privacy and mission secrecy. We propose IU-GUARD, a privacy-preserving spectrum sharing framework that enables IUs to access spectrum without revealing their identities. Leveraging verifiable credentials (VCs) and zero-knowledge proofs (ZKPs), IU-GUARD allows IUs to prove their authorization to the SCS while disclosing only essential operational parameters. This decouples IU identity from spectrum access, prevents cross-request linkage, and mitigates the risk of centralized SCS data leakage. We implement a prototype, and our evaluation shows that IU-GUARD achieves strong privacy guarantees with practical computation and communication overhead, making it suitable for real-time DSS deployment.", "AI": {"tldr": "IU-GUARD\u662f\u4e00\u4e2a\u4fdd\u62a4\u9690\u79c1\u7684\u9891\u8c31\u5171\u4eab\u6846\u67b6\uff0c\u4f7f\u7528\u53ef\u9a8c\u8bc1\u51ed\u8bc1\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\uff0c\u8ba9\u4e3b\u8981\u7528\u6237\u65e0\u9700\u900f\u9732\u8eab\u4efd\u5373\u53ef\u8bbf\u95ee\u9891\u8c31\uff0c\u540c\u65f6\u4fdd\u62a4\u5176\u64cd\u4f5c\u9690\u79c1\u548c\u4efb\u52a1\u673a\u5bc6\u6027\u3002", "motivation": "\u5f53\u524d\u9891\u8c31\u5171\u4eab\u6846\u67b6\u4e2d\u7684\u4e3b\u8981\u7528\u6237\u4fdd\u62a4\u673a\u5236\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff1a\u73af\u5883\u611f\u77e5\u80fd\u529b\u9700\u8981\u6602\u8d35\u7684\u4f20\u611f\u5668\u90e8\u7f72\u4e14\u6613\u53d7\u5e72\u6270\u548c\u5b89\u5168\u98ce\u9669\uff1b\u4e3b\u8981\u7528\u6237\u4fe1\u606f\u80fd\u529b\u5219\u9700\u8981\u4e3b\u8981\u7528\u6237\u5411\u9891\u8c31\u534f\u8c03\u7cfb\u7edf\u62ab\u9732\u8eab\u4efd\u548c\u64cd\u4f5c\u53c2\u6570\uff0c\u8fd9\u4f1a\u521b\u5efa\u53ef\u94fe\u63a5\u7684\u8bb0\u5f55\uff0c\u635f\u5bb3\u64cd\u4f5c\u9690\u79c1\u548c\u4efb\u52a1\u673a\u5bc6\u6027\u3002", "method": "\u63d0\u51faIU-GUARD\u6846\u67b6\uff0c\u5229\u7528\u53ef\u9a8c\u8bc1\u51ed\u8bc1\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\u6280\u672f\uff0c\u5141\u8bb8\u4e3b\u8981\u7528\u6237\u5411\u9891\u8c31\u534f\u8c03\u7cfb\u7edf\u8bc1\u660e\u5176\u6388\u6743\uff0c\u540c\u65f6\u4ec5\u62ab\u9732\u5fc5\u8981\u7684\u64cd\u4f5c\u53c2\u6570\uff0c\u5c06\u4e3b\u8981\u7528\u6237\u8eab\u4efd\u4e0e\u9891\u8c31\u8bbf\u95ee\u89e3\u8026\uff0c\u9632\u6b62\u8de8\u8bf7\u6c42\u94fe\u63a5\uff0c\u5e76\u51cf\u8f7b\u96c6\u4e2d\u5f0f\u9891\u8c31\u534f\u8c03\u7cfb\u7edf\u6570\u636e\u6cc4\u9732\u98ce\u9669\u3002", "result": "\u5b9e\u73b0\u4e86\u4e00\u4e2a\u539f\u578b\u7cfb\u7edf\uff0c\u8bc4\u4f30\u663e\u793aIU-GUARD\u5728\u63d0\u4f9b\u5f3a\u5927\u9690\u79c1\u4fdd\u8bc1\u7684\u540c\u65f6\uff0c\u5177\u6709\u5b9e\u7528\u7684\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\uff0c\u9002\u5408\u5b9e\u65f6\u52a8\u6001\u9891\u8c31\u5171\u4eab\u90e8\u7f72\u3002", "conclusion": "IU-GUARD\u662f\u4e00\u4e2a\u5b9e\u7528\u7684\u9690\u79c1\u4fdd\u62a4\u9891\u8c31\u5171\u4eab\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u4e3b\u8981\u7528\u6237\u4fdd\u62a4\u673a\u5236\u7684\u5173\u952e\u9650\u5236\uff0c\u5e73\u8861\u4e86\u9891\u8c31\u5229\u7528\u6548\u7387\u548c\u4e3b\u8981\u7528\u6237\u9690\u79c1\u4fdd\u62a4\u7684\u9700\u6c42\u3002"}}

{"id": "2602.23787", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.23787", "abs": "https://arxiv.org/abs/2602.23787", "authors": ["Xiaofeng Zhou", "Linfeng Du", "Hanwei Fan", "Wei Zhang"], "title": "FPPS: An FPGA-Based Point Cloud Processing System", "comment": null, "summary": "Point cloud processing is a computational bottleneck in autonomous driving systems, especially for real-time applications, while energy efficiency remains a critical system constraint. This work presents FPPS, an FPGA-accelerated point cloud processing system designed to optimize the iterative closest point (ICP) algorithm, a classic cornerstone of 3D localization and perception pipelines. Evaluated on the widely used KITTI benchmark dataset, the proposed system achieves up to 35$\\times$ (and a runtime-weighted average of 15.95x) speedup over a state-of-the-art CPU baseline while maintaining equivalent registration accuracy. Notably, the design improves average power efficiency by 8.58x, offering a compelling balance between performance and energy consumption. These results position FPPS as a viable solution for resource-constrained embedded autonomous platforms where both latency and power are key design priorities.", "AI": {"tldr": "FPPS\uff1a\u57fa\u4e8eFPGA\u52a0\u901f\u7684\u70b9\u4e91\u5904\u7406\u7cfb\u7edf\uff0c\u9488\u5bf9\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684ICP\u7b97\u6cd5\u4f18\u5316\uff0c\u5728KITTI\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u6700\u9ad835\u500d\u52a0\u901f\u548c8.58\u500d\u80fd\u6548\u63d0\u5347", "motivation": "\u70b9\u4e91\u5904\u7406\u662f\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u7279\u522b\u662f\u5728\u5b9e\u65f6\u5e94\u7528\u4e2d\uff0c\u800c\u80fd\u6548\u4ecd\u7136\u662f\u5173\u952e\u7684\u7cfb\u7edf\u7ea6\u675f\u3002\u9700\u8981\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u5d4c\u5165\u5f0f\u81ea\u52a8\u9a7e\u9a76\u5e73\u53f0\u63d0\u4f9b\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u80fd\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86FPPS\u7cfb\u7edf\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8eFPGA\u52a0\u901f\u7684\u70b9\u4e91\u5904\u7406\u7cfb\u7edf\uff0c\u4e13\u95e8\u9488\u5bf9\u8fed\u4ee3\u6700\u8fd1\u70b9\uff08ICP\uff09\u7b97\u6cd5\u8fdb\u884c\u4f18\u5316\u8bbe\u8ba1\u3002ICP\u662f3D\u5b9a\u4f4d\u548c\u611f\u77e5\u6d41\u6c34\u7ebf\u4e2d\u7684\u7ecf\u5178\u6838\u5fc3\u7b97\u6cd5\u3002", "result": "\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684KITTI\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u8be5\u7cfb\u7edf\u76f8\u6bd4\u6700\u5148\u8fdb\u7684CPU\u57fa\u7ebf\u5b9e\u73b0\u4e86\u6700\u9ad835\u500d\uff08\u8fd0\u884c\u65f6\u52a0\u6743\u5e73\u574715.95\u500d\uff09\u7684\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u7b49\u6548\u7684\u914d\u51c6\u7cbe\u5ea6\u3002\u8bbe\u8ba1\u5c06\u5e73\u5747\u80fd\u6548\u63d0\u9ad8\u4e868.58\u500d\u3002", "conclusion": "FPPS\u5728\u6027\u80fd\u548c\u80fd\u8017\u4e4b\u95f4\u63d0\u4f9b\u4e86\u4ee4\u4eba\u4fe1\u670d\u7684\u5e73\u8861\uff0c\u4f7f\u5176\u6210\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u5d4c\u5165\u5f0f\u81ea\u52a8\u9a7e\u9a76\u5e73\u53f0\u7684\u53ef\u884c\u89e3\u51b3\u65b9\u6848\uff0c\u5176\u4e2d\u5ef6\u8fdf\u548c\u529f\u8017\u90fd\u662f\u5173\u952e\u7684\u8bbe\u8ba1\u4f18\u5148\u7ea7\u3002"}}
{"id": "2602.23828", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.23828", "abs": "https://arxiv.org/abs/2602.23828", "authors": ["Tsung-Han Lu", "Weihong Xu", "Tajana Rosing"], "title": "GenDRAM:Hardware-Software Co-Design of General Platform in DRAM", "comment": null, "summary": "Dynamic programming (DP) algorithms, such as All-Pairs Shortest Path (APSP) and genomic sequence alignment, are fundamental to many scientific domains but are severely bottlenecked by data movement on conventional architectures. While Processing-in-Memory (PIM) offers a promising solution, existing accelerators often address only a fraction of the work-flow, creating new system-level bottlenecks in host-accelerator communication and off-chip data streaming. In this work, we propose GenDRAM, a massively parallel PIM accelerator that overcomes these limitations. GenDRAM leverages the immense capacity and internal bandwidth of monolithic 3D DRAM(M3D DRAM) to integrate entire data-intensive pipelines, such as the full genomics workflow from seeding to alignment, onto a single heterogeneous chip. At its core is a novel architecture featuring specialized Search PUs for memory-intensive tasks and universal, multiplier-less Compute PUs for diverse DP calculations. This is enabled by a 3D-aware data mapping strategy that exploits the tiered latency of M3D DRAM for performance optimization. Through comprehensive simulation, we demonstrate that GenDRAM achieves a transformative performance leap, outperforming state-of-the-art GPU systems by over 68x on APSP and over 22x on the end-to-end genomics pipeline.", "AI": {"tldr": "GenDRAM\u662f\u4e00\u4e2a\u57fa\u4e8e\u5355\u72473D DRAM\u7684\u5927\u89c4\u6a21\u5e76\u884c\u5185\u5b58\u5904\u7406\u52a0\u901f\u5668\uff0c\u4e13\u95e8\u9488\u5bf9\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\uff08\u5982\u5168\u5bf9\u6700\u77ed\u8def\u5f84\u548c\u57fa\u56e0\u7ec4\u5e8f\u5217\u6bd4\u5bf9\uff09\u7684\u6570\u636e\u79fb\u52a8\u74f6\u9888\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u5b8c\u6574\u6570\u636e\u5bc6\u96c6\u578b\u5de5\u4f5c\u6d41\u96c6\u6210\u5230\u5355\u4e2a\u82af\u7247\u4e0a\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\uff08\u5982APSP\u548c\u57fa\u56e0\u7ec4\u5e8f\u5217\u6bd4\u5bf9\uff09\u5728\u4f20\u7edf\u67b6\u6784\u4e0a\u53d7\u9650\u4e8e\u6570\u636e\u79fb\u52a8\u74f6\u9888\uff0c\u800c\u73b0\u6709\u7684\u5185\u5b58\u5904\u7406\u52a0\u901f\u5668\u901a\u5e38\u53ea\u89e3\u51b3\u5de5\u4f5c\u6d41\u7684\u4e00\u90e8\u5206\uff0c\u5bfc\u81f4\u65b0\u7684\u7cfb\u7edf\u7ea7\u74f6\u9888\uff08\u4e3b\u673a-\u52a0\u901f\u5668\u901a\u4fe1\u548c\u7247\u5916\u6570\u636e\u6d41\uff09\u3002", "method": "\u5229\u7528\u5355\u72473D DRAM\u7684\u5de8\u5927\u5bb9\u91cf\u548c\u5185\u90e8\u5e26\u5bbd\uff0c\u5c06\u5b8c\u6574\u6570\u636e\u5bc6\u96c6\u578b\u6d41\u6c34\u7ebf\uff08\u5982\u4ece\u79cd\u5b50\u5230\u6bd4\u5bf9\u7684\u5b8c\u6574\u57fa\u56e0\u7ec4\u5de5\u4f5c\u6d41\uff09\u96c6\u6210\u5230\u5355\u4e2a\u5f02\u6784\u82af\u7247\u4e0a\u3002\u6838\u5fc3\u67b6\u6784\u5305\u62ec\u4e13\u95e8\u7528\u4e8e\u5185\u5b58\u5bc6\u96c6\u578b\u4efb\u52a1\u7684\u641c\u7d22\u5904\u7406\u5355\u5143\u548c\u901a\u7528\u7684\u65e0\u4e58\u6cd5\u5668\u8ba1\u7b97\u5904\u7406\u5355\u5143\uff0c\u91c7\u75283D\u611f\u77e5\u6570\u636e\u6620\u5c04\u7b56\u7565\u5229\u7528M3D DRAM\u7684\u5206\u5c42\u5ef6\u8fdf\u8fdb\u884c\u6027\u80fd\u4f18\u5316\u3002", "result": "\u901a\u8fc7\u5168\u9762\u4eff\u771f\u9a8c\u8bc1\uff0cGenDRAM\u5b9e\u73b0\u4e86\u53d8\u9769\u6027\u7684\u6027\u80fd\u98de\u8dc3\uff0c\u5728\u5168\u5bf9\u6700\u77ed\u8def\u5f84\u4e0a\u6bd4\u6700\u5148\u8fdb\u7684GPU\u7cfb\u7edf\u5feb68\u500d\u4ee5\u4e0a\uff0c\u5728\u7aef\u5230\u7aef\u57fa\u56e0\u7ec4\u6d41\u6c34\u7ebf\u4e0a\u5feb22\u500d\u4ee5\u4e0a\u3002", "conclusion": "GenDRAM\u901a\u8fc7\u5229\u7528\u5355\u72473D DRAM\u7684\u72ec\u7279\u7279\u6027\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\u7684\u6570\u636e\u79fb\u52a8\u74f6\u9888\u95ee\u9898\uff0c\u4e3a\u6570\u636e\u5bc6\u96c6\u578b\u8ba1\u7b97\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5185\u5b58\u5904\u7406\u52a0\u901f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.24010", "categories": ["cs.AR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.24010", "abs": "https://arxiv.org/abs/2602.24010", "authors": ["Mingkai Miao", "Guangyu Hu", "Wei Zhang", "Hongce Zhang"], "title": "LeGend: A Data-Driven Framework for Lemma Generation in Hardware Model Checking", "comment": null, "summary": "Property checking of RTL designs is a central task in formal verification. Among available engines, IC3/PDR is a widely used backbone whose performance critically depends on inductive generalization, the step that generalizes a concrete counterexample-to-induction (CTI) cube into a lemma. Prior work has explored machine learning to guide this step and achieved encouraging results, yet most methods adopt a per-clause graph analysis paradigm: for each clause they repeatedly build and analyze graphs, incurring heavy overhead and creating a scalability bottleneck. We introduce LeGend, which replaces this paradigm with one-time global representation learning. LeGend pre-trains a domain-adapted self-supervised model to produce latch embeddings that capture global circuit properties. These precomputed embeddings allow a lightweight model to predict high-quality lemmas with negligible overhead, effectively decoupling expensive learning from fast inference. Experiments show LeGend accelerates two state-of-the-art IC3/PDR engines across a diverse set of benchmarks, presenting a promising path to scale up formal verification.", "AI": {"tldr": "LeGend\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5168\u5c40\u8868\u793a\u5b66\u4e60\u7684\u65b9\u6cd5\u6765\u6539\u8fdbIC3/PDR\u4e2d\u7684\u5f52\u7eb3\u6cdb\u5316\u6b65\u9aa4\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u9886\u57df\u9002\u5e94\u7684\u81ea\u76d1\u7763\u6a21\u578b\u751f\u6210\u95e8\u9501\u5d4c\u5165\uff0c\u4ece\u800c\u4ee5\u53ef\u5ffd\u7565\u7684\u5f00\u9500\u9884\u6d4b\u9ad8\u8d28\u91cf\u5f15\u7406\uff0c\u663e\u8457\u52a0\u901f\u5f62\u5f0f\u9a8c\u8bc1\u3002", "motivation": "IC3/PDR\u662f\u5f62\u5f0f\u9a8c\u8bc1\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u6838\u5fc3\u5f15\u64ce\uff0c\u5176\u6027\u80fd\u5173\u952e\u53d6\u51b3\u4e8e\u5f52\u7eb3\u6cdb\u5316\u6b65\u9aa4\u3002\u73b0\u6709\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u6307\u5bfc\u65b9\u6cd5\u5927\u591a\u91c7\u7528\u9010\u5b50\u53e5\u56fe\u5206\u6790\u8303\u5f0f\uff0c\u9700\u8981\u91cd\u590d\u6784\u5efa\u548c\u5206\u6790\u56fe\uff0c\u5bfc\u81f4\u6c89\u91cd\u7684\u5f00\u9500\u548c\u53ef\u6269\u5c55\u6027\u74f6\u9888\u3002", "method": "LeGend\u91c7\u7528\u4e00\u6b21\u6027\u5168\u5c40\u8868\u793a\u5b66\u4e60\u8303\u5f0f\uff0c\u9884\u8bad\u7ec3\u4e00\u4e2a\u9886\u57df\u9002\u5e94\u7684\u81ea\u76d1\u7763\u6a21\u578b\u6765\u751f\u6210\u6355\u83b7\u5168\u5c40\u7535\u8def\u7279\u6027\u7684\u95e8\u9501\u5d4c\u5165\u3002\u8fd9\u4e9b\u9884\u8ba1\u7b97\u7684\u5d4c\u5165\u5141\u8bb8\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u6a21\u578b\u4ee5\u53ef\u5ffd\u7565\u7684\u5f00\u9500\u9884\u6d4b\u9ad8\u8d28\u91cf\u5f15\u7406\uff0c\u6709\u6548\u89e3\u8026\u6602\u8d35\u7684\u8bad\u7ec3\u548c\u5feb\u901f\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLeGend\u5728\u591a\u6837\u5316\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\u4e0a\u52a0\u901f\u4e86\u4e24\u4e2a\u6700\u5148\u8fdb\u7684IC3/PDR\u5f15\u64ce\uff0c\u5c55\u793a\u4e86\u5728\u5f62\u5f0f\u9a8c\u8bc1\u4e2d\u6269\u5c55\u5e94\u7528\u7684\u524d\u666f\u3002", "conclusion": "LeGend\u901a\u8fc7\u5168\u5c40\u8868\u793a\u5b66\u4e60\u53d6\u4ee3\u9010\u5b50\u53e5\u56fe\u5206\u6790\u8303\u5f0f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6307\u5bfc\u65b9\u6cd5\u7684\u53ef\u6269\u5c55\u6027\u74f6\u9888\uff0c\u4e3a\u5f62\u5f0f\u9a8c\u8bc1\u7684\u89c4\u6a21\u5316\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u8def\u5f84\u3002"}}
{"id": "2602.23367", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23367", "abs": "https://arxiv.org/abs/2602.23367", "authors": ["Shubh Laddha", "Lucas Changbencharoen", "Win Kuptivej", "Surya Shringla", "Archana Vaidheeswaran", "Yash Bhaskar"], "title": "HumanMCP: A Human-Like Query Dataset for Evaluating MCP Tool Retrieval Performance", "comment": "4 pages, 2 figures, 3 tables", "summary": "Model Context Protocol (MCP) servers contain a collection of thousands of open-source standardized tools, linking LLMs to external systems; however, existing datasets and benchmarks lack realistic, human-like user queries, remaining a critical gap in evaluating the tool usage and ecosystems of MCP servers. Existing datasets often do contain tool descriptions but fail to represent how different users portray their requests, leading to poor generalization and inflated reliability of certain benchmarks. This paper introduces the first large-scale MCP dataset featuring diverse, high-quality diverse user queries generated specifically to match 2800 tools across 308 MCP servers, developing on the MCP Zero dataset. Each tool is paired with multiple unique user personas that we have generated, to capture varying levels of user intent ranging from precise task requests, and ambiguous, exploratory commands, reflecting the complexity of real-world interaction patterns.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u9996\u4e2a\u5927\u89c4\u6a21MCP\u6570\u636e\u96c6\uff0c\u5305\u542b\u9488\u5bf9308\u4e2aMCP\u670d\u52a1\u5668\u4e2d2800\u4e2a\u5de5\u5177\u7684\u591a\u6837\u5316\u9ad8\u8d28\u91cf\u7528\u6237\u67e5\u8be2\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u771f\u5b9e\u7528\u6237\u67e5\u8be2\u6a21\u5f0f\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709MCP\u670d\u52a1\u5668\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u4e4f\u771f\u5b9e\u3001\u7c7b\u4f3c\u4eba\u7c7b\u7684\u7528\u6237\u67e5\u8be2\uff0c\u65e0\u6cd5\u53cd\u6620\u4e0d\u540c\u7528\u6237\u5982\u4f55\u8868\u8fbe\u8bf7\u6c42\uff0c\u5bfc\u81f4\u6cdb\u5316\u80fd\u529b\u5dee\u548c\u57fa\u51c6\u6d4b\u8bd5\u53ef\u9760\u6027\u88ab\u5938\u5927\u3002", "method": "\u57fa\u4e8eMCP Zero\u6570\u636e\u96c6\u5f00\u53d1\uff0c\u4e3a2800\u4e2a\u5de5\u5177\u751f\u6210\u591a\u6837\u5316\u9ad8\u8d28\u91cf\u7528\u6237\u67e5\u8be2\uff0c\u6bcf\u4e2a\u5de5\u5177\u914d\u5bf9\u591a\u4e2a\u72ec\u7279\u7684\u7528\u6237\u89d2\u8272\uff0c\u6db5\u76d6\u4ece\u7cbe\u786e\u4efb\u52a1\u8bf7\u6c42\u5230\u6a21\u7cca\u63a2\u7d22\u6027\u547d\u4ee4\u7684\u4e0d\u540c\u7528\u6237\u610f\u56fe\u5c42\u6b21\u3002", "result": "\u521b\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21MCP\u6570\u636e\u96c6\uff0c\u5305\u542b\u9488\u5bf9308\u4e2aMCP\u670d\u52a1\u5668\u4e2d2800\u4e2a\u5de5\u5177\u7684\u591a\u6837\u5316\u7528\u6237\u67e5\u8be2\uff0c\u53cd\u6620\u4e86\u771f\u5b9e\u4e16\u754c\u4ea4\u4e92\u6a21\u5f0f\u7684\u590d\u6742\u6027\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u586b\u8865\u4e86MCP\u670d\u52a1\u5668\u5de5\u5177\u4f7f\u7528\u548c\u751f\u6001\u7cfb\u7edf\u8bc4\u4f30\u7684\u5173\u952e\u7a7a\u767d\uff0c\u80fd\u591f\u66f4\u597d\u5730\u8bc4\u4f30\u5de5\u5177\u4f7f\u7528\u6548\u679c\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.23598", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2602.23598", "abs": "https://arxiv.org/abs/2602.23598", "authors": ["Md Hasanur Rashid", "Jesun Firoz", "Nathan R. Tallent", "Luanzheng Guo", "Meng Tang", "Dong Dai"], "title": "QoSFlow: Ensuring Service Quality of Distributed Workflows Using Interpretable Sensitivity Models", "comment": "to be published in 40th IEEE International Parallel & Distributed Processing Symposium (IPDPS), 2026", "summary": "With the increasing importance of distributed scientific workflows, there is a critical need to ensure Quality of Service (QoS) constraints, such as minimizing time or limiting execution to resource subsets. However, the unpredictable nature of workflow behavior, even with similar configurations, makes it difficult to provide QoS guarantees. For effective reasoning about QoS scheduling, we introduce QoSFlow, a performance modeling method that partitions a workflow's execution configuration space into regions with similar behavior. Each region groups configurations with comparable execution times according to a given statistical sensitivity, enabling efficient QoS-driven scheduling through analytical reasoning rather than exhaustive testing. Evaluation on three diverse workflows shows that QoSFlow's execution recommendations outperform the best-performing standard heuristic by 27.38%. Empirical validation confirms that QoSFlow's recommended configurations consistently match measured execution outcomes across different QoS constraints.", "AI": {"tldr": "QoSFlow\u662f\u4e00\u79cd\u6027\u80fd\u5efa\u6a21\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u5de5\u4f5c\u6d41\u6267\u884c\u914d\u7f6e\u7a7a\u95f4\u5212\u5206\u4e3a\u5177\u6709\u76f8\u4f3c\u884c\u4e3a\u7684\u533a\u57df\uff0c\u4e3a\u5206\u5e03\u5f0f\u79d1\u5b66\u5de5\u4f5c\u6d41\u63d0\u4f9bQoS\u4fdd\u8bc1\uff0c\u76f8\u6bd4\u6700\u4f73\u6807\u51c6\u542f\u53d1\u5f0f\u65b9\u6cd5\u6027\u80fd\u63d0\u534727.38%", "motivation": "\u968f\u7740\u5206\u5e03\u5f0f\u79d1\u5b66\u5de5\u4f5c\u6d41\u7684\u91cd\u8981\u6027\u65e5\u76ca\u589e\u52a0\uff0c\u9700\u8981\u786e\u4fdd\u670d\u52a1\u8d28\u91cf\u7ea6\u675f\uff08\u5982\u6700\u5c0f\u5316\u65f6\u95f4\u6216\u9650\u5236\u5728\u8d44\u6e90\u5b50\u96c6\u4e0a\u6267\u884c\uff09\uff0c\u4f46\u5de5\u4f5c\u6d41\u884c\u4e3a\u7684\u4e0d\u53ef\u9884\u6d4b\u6027\u4f7f\u5f97\u63d0\u4f9bQoS\u4fdd\u8bc1\u53d8\u5f97\u56f0\u96be", "method": "\u5f15\u5165QoSFlow\u6027\u80fd\u5efa\u6a21\u65b9\u6cd5\uff0c\u5c06\u5de5\u4f5c\u6d41\u7684\u6267\u884c\u914d\u7f6e\u7a7a\u95f4\u5212\u5206\u4e3a\u5177\u6709\u76f8\u4f3c\u884c\u4e3a\u7684\u533a\u57df\uff0c\u6bcf\u4e2a\u533a\u57df\u6839\u636e\u7ed9\u5b9a\u7684\u7edf\u8ba1\u654f\u611f\u6027\u5c06\u5177\u6709\u53ef\u6bd4\u6267\u884c\u65f6\u95f4\u7684\u914d\u7f6e\u5206\u7ec4\uff0c\u901a\u8fc7\u5206\u6790\u63a8\u7406\u800c\u975e\u7a77\u4e3e\u6d4b\u8bd5\u5b9e\u73b0\u9ad8\u6548\u7684QoS\u9a71\u52a8\u8c03\u5ea6", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u5de5\u4f5c\u6d41\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cQoSFlow\u7684\u6267\u884c\u5efa\u8bae\u6bd4\u6700\u4f73\u6807\u51c6\u542f\u53d1\u5f0f\u65b9\u6cd5\u6027\u80fd\u9ad8\u51fa27.38%\uff0c\u7ecf\u9a8c\u9a8c\u8bc1\u786e\u8ba4QoSFlow\u7684\u63a8\u8350\u914d\u7f6e\u5728\u4e0d\u540cQoS\u7ea6\u675f\u4e0b\u59cb\u7ec8\u4e0e\u5b9e\u6d4b\u6267\u884c\u7ed3\u679c\u5339\u914d", "conclusion": "QoSFlow\u901a\u8fc7\u914d\u7f6e\u7a7a\u95f4\u5206\u533a\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u79d1\u5b66\u5de5\u4f5c\u6d41\u7684QoS\u4fdd\u8bc1\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e\u5206\u6790\u63a8\u7406\u7684\u9ad8\u6548\u8c03\u5ea6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u8868\u73b0"}}
{"id": "2602.24269", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.24269", "abs": "https://arxiv.org/abs/2602.24269", "authors": ["William C. Tegge", "Alex K. Jones"], "title": "Shifting in-DRAM", "comment": "9 pages, 4 figures, 5 tables", "summary": "Processing-in-Memory (PIM) architectures enable computation directly within DRAM and help combat the memory wall problem. Bit-shifting is a fundamental operation that enables PIM applications such as shift-and-add multiplication, adders using carry propagation, and Galois field arithmetic used in cryptography algorithms like AES and Reed-Solomon error correction codes. Existing approaches to in-DRAM shifting require adding dedicated shifter circuits beneath the sense amplifiers to enable horizontal data movement across adjacent bitlines or vertical data layouts which store operand bits along a bitline to implement shifts as row-copy operations. In this paper, we propose a novel DRAM subarray design that enables in-DRAM bit-shifting for open-bitline architectures. In this new design, we built upon prior work that introduced a new type of cell used for row migration in asymmetric subarrays, called a \"migration cell\". We repurpose and extend the functionality by adding a row of migration cells at the top and bottom of each subarray which enables bidirectional bit-shifting within any given row. This new design maintains compatibility with standard DRAM operations. Unlike previous approaches to shifting, our design operates on horizontally-stored data, eliminating the need and overhead of data transposition, and our design leverages the existing cell structures, eliminating the need for additional complex logic and circuitry. We present an evaluation of our design that includes timing and energy analysis using NVMain, circuit-level validation of the in-DRAM shift operation using LTSPICE, and a VLSI layout implementation in Cadence Virtuoso.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684DRAM\u5b50\u9635\u5217\u8bbe\u8ba1\uff0c\u901a\u8fc7\u91cd\u65b0\u5229\u7528\u548c\u6269\u5c55\"\u8fc1\u79fb\u5355\u5143\"\u529f\u80fd\uff0c\u5728\u5f00\u653e\u4f4d\u7ebf\u67b6\u6784\u4e2d\u5b9e\u73b0DRAM\u5185\u6bd4\u7279\u79fb\u4f4d\u64cd\u4f5c\uff0c\u65e0\u9700\u6570\u636e\u8f6c\u7f6e\u6216\u989d\u5916\u590d\u6742\u7535\u8def\u3002", "motivation": "\u5904\u7406\u5185\u5b58(PIM)\u67b6\u6784\u901a\u8fc7\u5728DRAM\u5185\u76f4\u63a5\u8ba1\u7b97\u6765\u89e3\u51b3\u5185\u5b58\u5899\u95ee\u9898\u3002\u6bd4\u7279\u79fb\u4f4d\u662fPIM\u5e94\u7528\u4e2d\u7684\u57fa\u672c\u64cd\u4f5c\uff0c\u5982\u79fb\u4f4d\u52a0\u6cd5\u4e58\u6cd5\u3001\u8fdb\u4f4d\u4f20\u64ad\u52a0\u6cd5\u5668\u4ee5\u53caAES\u548cReed-Solomon\u7ea0\u9519\u7801\u7b49\u5bc6\u7801\u5b66\u7b97\u6cd5\u4e2d\u7684\u4f3d\u7f57\u534e\u57df\u7b97\u672f\u3002\u73b0\u6709DRAM\u5185\u79fb\u4f4d\u65b9\u6cd5\u9700\u8981\u6dfb\u52a0\u4e13\u7528\u79fb\u4f4d\u7535\u8def\u6216\u91c7\u7528\u5782\u76f4\u6570\u636e\u5e03\u5c40\uff0c\u5b58\u5728\u5f00\u9500\u5927\u3001\u9700\u8981\u6570\u636e\u8f6c\u7f6e\u7b49\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u5148\u524d\u5728\u975e\u5bf9\u79f0\u5b50\u9635\u5217\u4e2d\u7528\u4e8e\u884c\u8fc1\u79fb\u7684\"\u8fc1\u79fb\u5355\u5143\"\u8bbe\u8ba1\uff0c\u5728\u6bcf\u4e2a\u5b50\u9635\u5217\u7684\u9876\u90e8\u548c\u5e95\u90e8\u6dfb\u52a0\u4e00\u884c\u8fc1\u79fb\u5355\u5143\uff0c\u91cd\u65b0\u5229\u7528\u5e76\u6269\u5c55\u5176\u529f\u80fd\uff0c\u5b9e\u73b0\u4efb\u610f\u7ed9\u5b9a\u884c\u5185\u7684\u53cc\u5411\u6bd4\u7279\u79fb\u4f4d\u3002\u8be5\u8bbe\u8ba1\u4fdd\u6301\u4e0e\u6807\u51c6DRAM\u64cd\u4f5c\u7684\u517c\u5bb9\u6027\uff0c\u5bf9\u6c34\u5e73\u5b58\u50a8\u7684\u6570\u636e\u8fdb\u884c\u64cd\u4f5c\uff0c\u65e0\u9700\u6570\u636e\u8f6c\u7f6e\uff0c\u5e76\u5229\u7528\u73b0\u6709\u5355\u5143\u7ed3\u6784\uff0c\u65e0\u9700\u989d\u5916\u590d\u6742\u903b\u8f91\u548c\u7535\u8def\u3002", "result": "\u4f7f\u7528NVMain\u8fdb\u884c\u65f6\u5e8f\u548c\u80fd\u91cf\u5206\u6790\uff0c\u901a\u8fc7LTSPICE\u8fdb\u884c\u7535\u8def\u7ea7\u9a8c\u8bc1\uff0c\u5728Cadence Virtuoso\u4e2d\u5b9e\u73b0VLSI\u5e03\u5c40\u3002\u8bbe\u8ba1\u80fd\u591f\u6709\u6548\u5b9e\u73b0DRAM\u5185\u6bd4\u7279\u79fb\u4f4d\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6807\u51c6DRAM\u64cd\u4f5c\u7684\u517c\u5bb9\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684DRAM\u5b50\u9635\u5217\u8bbe\u8ba1\uff0c\u80fd\u591f\u5728\u5f00\u653e\u4f4d\u7ebf\u67b6\u6784\u4e2d\u5b9e\u73b0\u9ad8\u6548\u7684DRAM\u5185\u6bd4\u7279\u79fb\u4f4d\u64cd\u4f5c\u3002\u8be5\u8bbe\u8ba1\u901a\u8fc7\u91cd\u65b0\u5229\u7528\u8fc1\u79fb\u5355\u5143\uff0c\u907f\u514d\u4e86\u6570\u636e\u8f6c\u7f6e\u5f00\u9500\uff0c\u65e0\u9700\u989d\u5916\u590d\u6742\u7535\u8def\uff0c\u4e3aPIM\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6bd4\u7279\u79fb\u4f4d\u652f\u6301\u3002"}}
{"id": "2602.23407", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.23407", "abs": "https://arxiv.org/abs/2602.23407", "authors": ["Jiazheng Quan", "Xiaodong Li", "Bin Wang", "Guo An", "Like Liu", "Degen Huang", "Lin Liu", "Chengbin Hou"], "title": "Learning to Generate Secure Code via Token-Level Rewards", "comment": "18 pages, 3 figures", "summary": "Large language models (LLMs) have demonstrated strong capabilities in code generation, yet they remain prone to producing security vulnerabilities. Existing approaches commonly suffer from two key limitations: the scarcity of high-quality security data and coarse-grained reinforcement learning reward signals. To address these challenges, we propose Vul2Safe, a new secure code generation framework that leverages LLM self-reflection to construct high-confidence repair pairs from real-world vulnerabilities, and further generates diverse implicit prompts to build the PrimeVul+ dataset. Meanwhile, we introduce SRCode, a novel training framework that pioneers the use of token-level rewards in reinforcement learning for code security, which enables the model to continuously attend to and reinforce critical fine-grained security patterns during training. Compared with traditional instance-level reward schemes, our approach allows for more precise optimization of local security implementations. Extensive experiments show that PrimeVul+ and SRCode substantially reduce security vulnerabilities in generated code while improving overall code quality across multiple benchmarks.", "AI": {"tldr": "Vul2Safe\u6846\u67b6\u901a\u8fc7LLM\u81ea\u53cd\u601d\u6784\u5efa\u9ad8\u8d28\u91cf\u5b89\u5168\u4fee\u590d\u6570\u636e\u96c6PrimeVul+\uff0c\u5e76\u5f15\u5165SRCode\u8bad\u7ec3\u6846\u67b6\u4f7f\u7528token\u7ea7\u5956\u52b1\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\uff0c\u663e\u8457\u964d\u4f4e\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4ecd\u5bb9\u6613\u4ea7\u751f\u5b89\u5168\u6f0f\u6d1e\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a\u9ad8\u8d28\u91cf\u5b89\u5168\u6570\u636e\u7a00\u7f3a\u548c\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u4fe1\u53f7\u8fc7\u4e8e\u7c97\u7c92\u5ea6", "method": "1. \u63d0\u51faVul2Safe\u6846\u67b6\uff0c\u5229\u7528LLM\u81ea\u53cd\u601d\u4ece\u771f\u5b9e\u6f0f\u6d1e\u6784\u5efa\u9ad8\u7f6e\u4fe1\u5ea6\u4fee\u590d\u5bf9\uff0c\u5e76\u751f\u6210\u591a\u6837\u5316\u9690\u5f0f\u63d0\u793a\u6784\u5efaPrimeVul+\u6570\u636e\u96c6\n2. \u5f15\u5165SRCode\u8bad\u7ec3\u6846\u67b6\uff0c\u9996\u6b21\u5728\u4ee3\u7801\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u4e2d\u4f7f\u7528token\u7ea7\u5956\u52b1\uff0c\u4f7f\u6a21\u578b\u5728\u8bad\u7ec3\u4e2d\u6301\u7eed\u5173\u6ce8\u548c\u5f3a\u5316\u7ec6\u7c92\u5ea6\u5b89\u5168\u6a21\u5f0f", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPrimeVul+\u548cSRCode\u663e\u8457\u51cf\u5c11\u4e86\u751f\u6210\u4ee3\u7801\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u540c\u65f6\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u9ad8\u4e86\u6574\u4f53\u4ee3\u7801\u8d28\u91cf", "conclusion": "\u4e0e\u4f20\u7edf\u5b9e\u4f8b\u7ea7\u5956\u52b1\u65b9\u6848\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u7cbe\u786e\u5730\u4f18\u5316\u5c40\u90e8\u5b89\u5168\u5b9e\u73b0\uff0c\u4e3a\u5b89\u5168\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.23541", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23541", "abs": "https://arxiv.org/abs/2602.23541", "authors": ["Arvind Raghavan", "Elias Bareinboim"], "title": "Causal Identification from Counterfactual Data: Completeness and Bounding Results", "comment": null, "summary": "Previous work establishing completeness results for $\\textit{counterfactual identification}$ has been circumscribed to the setting where the input data belongs to observational or interventional distributions (Layers 1 and 2 of Pearl's Causal Hierarchy), since it was generally presumed impossible to obtain data from counterfactual distributions, which belong to Layer 3. However, recent work (Raghavan & Bareinboim, 2025) has formally characterized a family of counterfactual distributions which can be directly estimated via experimental methods - a notion they call $\\textit{counterfactual realizabilty}$. This leaves open the question of what $\\textit{additional}$ counterfactual quantities now become identifiable, given this new access to (some) Layer 3 data. To answer this question, we develop the CTFIDU+ algorithm for identifying counterfactual queries from an arbitrary set of Layer 3 distributions, and prove that it is complete for this task. Building on this, we establish the theoretical limit of which counterfactuals can be identified from physically realizable distributions, thus implying the $\\textit{fundamental limit to exact causal inference in the non-parametric setting}$. Finally, given the impossibility of identifying certain critical types of counterfactuals, we derive novel analytic bounds for such quantities using realizable counterfactual data, and corroborate using simulations that counterfactual data helps tighten the bounds for non-identifiable quantities in practice.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CTFIDU+\u7b97\u6cd5\uff0c\u7528\u4e8e\u4ece\u4efb\u610fLayer 3\u53cd\u4e8b\u5b9e\u5206\u5e03\u4e2d\u8bc6\u522b\u53cd\u4e8b\u5b9e\u67e5\u8be2\uff0c\u8bc1\u660e\u4e86\u8be5\u7b97\u6cd5\u7684\u5b8c\u5907\u6027\uff0c\u5e76\u5efa\u7acb\u4e86\u975e\u53c2\u6570\u8bbe\u7f6e\u4e0b\u7cbe\u786e\u56e0\u679c\u63a8\u7406\u7684\u7406\u8bba\u6781\u9650\u3002", "motivation": "\u5148\u524d\u5173\u4e8e\u53cd\u4e8b\u5b9e\u8bc6\u522b\u5b8c\u5907\u6027\u7684\u7814\u7a76\u4ec5\u9650\u4e8e\u89c2\u6d4b\u6216\u5e72\u9884\u5206\u5e03\uff08\u56e0\u679c\u5c42\u6b21\u7ed3\u6784\u7684Layer 1\u548c2\uff09\uff0c\u56e0\u4e3a\u4e00\u822c\u8ba4\u4e3a\u65e0\u6cd5\u83b7\u5f97Layer 3\u7684\u53cd\u4e8b\u5b9e\u5206\u5e03\u6570\u636e\u3002\u7136\u800c\uff0c\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\u67d0\u4e9b\u53cd\u4e8b\u5b9e\u5206\u5e03\u53ef\u4ee5\u901a\u8fc7\u5b9e\u9a8c\u65b9\u6cd5\u76f4\u63a5\u4f30\u8ba1\uff08\u53cd\u4e8b\u5b9e\u53ef\u5b9e\u73b0\u6027\uff09\uff0c\u8fd9\u5f15\u51fa\u4e86\u4e00\u4e2a\u95ee\u9898\uff1a\u5728\u83b7\u5f97\u8fd9\u4e9bLayer 3\u6570\u636e\u540e\uff0c\u54ea\u4e9b\u989d\u5916\u7684\u53cd\u4e8b\u5b9e\u91cf\u53d8\u5f97\u53ef\u8bc6\u522b\uff1f", "method": "\u5f00\u53d1\u4e86CTFIDU+\u7b97\u6cd5\uff0c\u7528\u4e8e\u4ece\u4efb\u610fLayer 3\u5206\u5e03\u4e2d\u8bc6\u522b\u53cd\u4e8b\u5b9e\u67e5\u8be2\uff0c\u5e76\u8bc1\u660e\u4e86\u8be5\u7b97\u6cd5\u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u5b8c\u5907\u6027\u3002\u57fa\u4e8e\u6b64\uff0c\u5efa\u7acb\u4e86\u4ece\u7269\u7406\u53ef\u5b9e\u73b0\u5206\u5e03\u4e2d\u8bc6\u522b\u53cd\u4e8b\u5b9e\u7684\u7406\u8bba\u6781\u9650\u3002", "result": "CTFIDU+\u7b97\u6cd5\u88ab\u8bc1\u660e\u662f\u5b8c\u5907\u7684\uff0c\u80fd\u591f\u8bc6\u522b\u4ece\u4efb\u610fLayer 3\u5206\u5e03\u4e2d\u53ef\u8bc6\u522b\u7684\u6240\u6709\u53cd\u4e8b\u5b9e\u67e5\u8be2\u3002\u7814\u7a76\u786e\u5b9a\u4e86\u975e\u53c2\u6570\u8bbe\u7f6e\u4e0b\u7cbe\u786e\u56e0\u679c\u63a8\u7406\u7684\u57fa\u672c\u6781\u9650\uff0c\u5e76\u9488\u5bf9\u4e0d\u53ef\u8bc6\u522b\u7684\u5173\u952e\u53cd\u4e8b\u5b9e\u7c7b\u578b\u63a8\u5bfc\u4e86\u65b0\u7684\u89e3\u6790\u8fb9\u754c\u3002", "conclusion": "\u672c\u6587\u5efa\u7acb\u4e86\u4ece\u7269\u7406\u53ef\u5b9e\u73b0\u7684\u53cd\u4e8b\u5b9e\u5206\u5e03\u4e2d\u8bc6\u522b\u53cd\u4e8b\u5b9e\u7684\u7406\u8bba\u6781\u9650\uff0c\u586b\u8865\u4e86\u56e0\u679c\u63a8\u7406\u5b8c\u5907\u6027\u7814\u7a76\u7684\u7a7a\u767d\u3002\u5bf9\u4e8e\u4e0d\u53ef\u8bc6\u522b\u7684\u53cd\u4e8b\u5b9e\u91cf\uff0c\u53cd\u4e8b\u5b9e\u6570\u636e\u5728\u5b9e\u8df5\u4e2d\u786e\u5b9e\u6709\u52a9\u4e8e\u6536\u7d27\u8fb9\u754c\uff0c\u4e3a\u56e0\u679c\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.24166", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2602.24166", "abs": "https://arxiv.org/abs/2602.24166", "authors": ["Christian Ewert", "Tim Hardow", "Melf Fritsch", "Leon Dietrich", "Henrik Strunck", "Rainer Buchty", "Mladen Berekovic", "Saleh Mulhem"], "title": "SAILOR: A Scalable and Energy-Efficient Ultra-Lightweight RISC-V for IoT Security", "comment": null, "summary": "Recently, RISC-V has contributed to the development of IoT devices, requiring architectures that balance energy efficiency, compact area, and integrated security. However, most recent RISC-V cores for IoT prioritize either area footprint or energy efficiency, while adding cryptographic support further compromises compactness. As a result, truly integrated architectures that simultaneously optimize efficiency and security remain largely unexplored, leaving constrained IoT environments vulnerable to performance and security trade-offs. In this paper, we introduce SAILOR, an energy-efficient and scalable ultra-lightweight RISC-V core family for cryptographic applications in IoT. Our design is modular and spans 1-, 2-, 4-, 8-, 16-, and 32-bit serialized execution data-paths, prioritizing minimal area. This modular design and adaptable data-path minimizes the overhead of integrating RISC-V cryptography extensions, achieving low hardware cost while significantly improving energy efficiency. We validate our design approach through a comprehensive analysis of area, energy, and efficiency trade-offs. The results surpass state-of-the-art solutions in both performance and energy efficiency by up to 13x and reduce area by up to 59 %, demonstrating that lightweight cryptographic features can be added without prohibitive overhead, and that energy- or area-efficient designs need not compromise performance.", "AI": {"tldr": "SAILOR\u662f\u4e00\u4e2a\u9762\u5411\u7269\u8054\u7f51\u52a0\u5bc6\u5e94\u7528\u7684\u8d85\u8f7b\u91cf\u7ea7RISC-V\u6838\u5fc3\u7cfb\u5217\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u53ef\u6269\u5c55\u6570\u636e\u8def\u5f84\uff081-32\u4f4d\u4e32\u884c\u6267\u884c\uff09\u5b9e\u73b0\u4e86\u9762\u79ef\u3001\u80fd\u6548\u548c\u52a0\u5bc6\u529f\u80fd\u7684\u5e73\u8861\u4f18\u5316\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570RISC-V\u7269\u8054\u7f51\u6838\u5fc3\u8981\u4e48\u4f18\u5148\u8003\u8651\u9762\u79ef\u5360\u7528\uff0c\u8981\u4e48\u4f18\u5148\u8003\u8651\u80fd\u6548\uff0c\u800c\u6dfb\u52a0\u52a0\u5bc6\u652f\u6301\u4f1a\u8fdb\u4e00\u6b65\u5f71\u54cd\u7d27\u51d1\u6027\u3002\u771f\u6b63\u540c\u65f6\u4f18\u5316\u80fd\u6548\u548c\u5b89\u5168\u6027\u7684\u96c6\u6210\u67b6\u6784\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u5bfc\u81f4\u53d7\u9650\u7269\u8054\u7f51\u73af\u5883\u9762\u4e34\u6027\u80fd\u548c\u5b89\u5168\u6027\u7684\u6743\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51faSAILOR\u6838\u5fc3\u7cfb\u5217\uff0c\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u652f\u63011\u30012\u30014\u30018\u300116\u548c32\u4f4d\u4e32\u884c\u6267\u884c\u6570\u636e\u8def\u5f84\uff0c\u4f18\u5148\u8003\u8651\u6700\u5c0f\u5316\u9762\u79ef\u3002\u8fd9\u79cd\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u53ef\u9002\u5e94\u6570\u636e\u8def\u5f84\u6700\u5c0f\u5316\u4e86\u96c6\u6210RISC-V\u52a0\u5bc6\u6269\u5c55\u7684\u5f00\u9500\u3002", "result": "SAILOR\u5728\u6027\u80fd\u548c\u80fd\u6548\u65b9\u9762\u8d85\u8d8a\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8fbe13\u500d\uff0c\u9762\u79ef\u51cf\u5c11\u9ad8\u8fbe59%\u3002\u9a8c\u8bc1\u4e86\u8f7b\u91cf\u7ea7\u52a0\u5bc6\u529f\u80fd\u53ef\u4ee5\u5728\u4e0d\u8fc7\u5ea6\u589e\u52a0\u5f00\u9500\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\uff0c\u4e14\u80fd\u6548\u6216\u9762\u79ef\u4f18\u5316\u7684\u8bbe\u8ba1\u65e0\u9700\u727a\u7272\u6027\u80fd\u3002", "conclusion": "SAILOR\u5c55\u793a\u4e86\u5728\u7269\u8054\u7f51\u52a0\u5bc6\u5e94\u7528\u4e2d\u5b9e\u73b0\u9762\u79ef\u3001\u80fd\u6548\u548c\u5b89\u5168\u6027\u5e73\u8861\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u53d7\u9650\u7269\u8054\u7f51\u73af\u5883\u63d0\u4f9b\u4e86\u65e0\u9700\u5728\u6027\u80fd\u548c\u5b89\u5168\u4e4b\u95f4\u505a\u51fa\u59a5\u534f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23545", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23545", "abs": "https://arxiv.org/abs/2602.23545", "authors": ["Matteo Ceriscioli", "Karthika Mohan"], "title": "Planning under Distribution Shifts with Causal POMDPs", "comment": "To appear at the 36th International Conference on Automated Planning and Scheduling (ICAPS-26)", "summary": "In the real world, planning is often challenged by distribution shifts. As such, a model of the environment obtained under one set of conditions may no longer remain valid as the distribution of states or the environment dynamics change, which in turn causes previously learned strategies to fail. In this work, we propose a theoretical framework for planning under partial observability using Partially Observable Markov Decision Processes (POMDPs) formulated using causal knowledge. By representing shifts in the environment as interventions on this causal POMDP, the framework enables evaluating plans under hypothesized changes and actively identifying which components of the environment have been altered. We show how to maintain and update a belief over both the latent state and the underlying domain, and we prove that the value function remains piecewise linear and convex (PWLC) in this augmented belief space. Preservation of PWLC under distribution shifts has the advantage of maintaining the tractability of planning via $\u03b1$-vector-based POMDP methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u5904\u7406\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u901a\u8fc7\u56e0\u679cPOMDP\u6a21\u578b\u5c06\u73af\u5883\u53d8\u5316\u8868\u793a\u4e3a\u5e72\u9884\uff0c\u4fdd\u6301\u503c\u51fd\u6570\u7684PWLC\u7279\u6027\u4ee5\u786e\u4fdd\u89c4\u5212\u7684\u53ef\u5904\u7406\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u89c4\u5212\u7ecf\u5e38\u9762\u4e34\u5206\u5e03\u504f\u79fb\u7684\u6311\u6218\uff0c\u73af\u5883\u6a21\u578b\u5728\u72b6\u6001\u5206\u5e03\u6216\u73af\u5883\u52a8\u6001\u53d8\u5316\u65f6\u53ef\u80fd\u5931\u6548\uff0c\u5bfc\u81f4\u5148\u524d\u5b66\u4e60\u7684\u7b56\u7565\u5931\u8d25\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u73af\u5883\u53d8\u5316\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u56e0\u679c\u77e5\u8bc6\u7684\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDP\uff09\u6784\u5efa\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u73af\u5883\u53d8\u5316\u8868\u793a\u4e3a\u5bf9\u8be5\u56e0\u679cPOMDP\u7684\u5e72\u9884\u3002\u8be5\u6846\u67b6\u80fd\u591f\u8bc4\u4f30\u5047\u8bbe\u53d8\u5316\u4e0b\u7684\u8ba1\u5212\uff0c\u5e76\u4e3b\u52a8\u8bc6\u522b\u73af\u5883\u4e2d\u7684\u54ea\u4e9b\u7ec4\u4ef6\u53d1\u751f\u4e86\u53d8\u5316\u3002\u540c\u65f6\u7ef4\u62a4\u548c\u66f4\u65b0\u5173\u4e8e\u6f5c\u5728\u72b6\u6001\u548c\u5e95\u5c42\u9886\u57df\u7684\u4fe1\u5ff5\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u8be5\u589e\u5f3a\u4fe1\u5ff5\u7a7a\u95f4\u4e2d\uff0c\u503c\u51fd\u6570\u4fdd\u6301\u5206\u6bb5\u7ebf\u6027\u51f8\uff08PWLC\uff09\u7279\u6027\u3002PWLC\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u4fdd\u6301\u5177\u6709\u4f18\u52bf\uff0c\u80fd\u591f\u7ef4\u6301\u57fa\u4e8e\u03b1\u5411\u91cf\u7684POMDP\u65b9\u6cd5\u7684\u53ef\u5904\u7406\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u7684\u5206\u5e03\u504f\u79fb\u89c4\u5212\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u901a\u8fc7\u56e0\u679c\u8868\u793a\u548cPWLC\u7279\u6027\u7684\u4fdd\u6301\uff0c\u786e\u4fdd\u4e86\u89c4\u5212\u65b9\u6cd5\u5728\u5b9e\u9645\u73af\u5883\u53d8\u5316\u4e2d\u7684\u6709\u6548\u6027\u548c\u53ef\u5904\u7406\u6027\u3002"}}
{"id": "2602.23935", "categories": ["cs.DC", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2602.23935", "abs": "https://arxiv.org/abs/2602.23935", "authors": ["Bowen Sun", "Christos D. Antonopoulos", "Evgenia Smirni", "Bin Ren", "Nikolaos Bellas", "Spyros Lalis"], "title": "Green or Fast? Learning to Balance Cold Starts and Idle Carbon in Serverless Computing", "comment": null, "summary": "Serverless computing simplifies cloud deployment but introduces new challenges in managing service latency and carbon emissions. Reducing cold-start latency requires retaining warm function instances, while minimizing carbon emissions favors reclaiming idle resources. This balance is further complicated by time-varying grid carbon intensity and varying workload patterns, under which static keep-alive policies are inefficient. We present LACE-RL, a latency-aware and carbon-efficient management framework that formulates serverless pod retention as a sequential decision problem. LACE-RL uses deep reinforcement learning to dynamically tune keep-alive durations, jointly modeling cold-start probability, function-specific latency costs, and real-time carbon intensity. Using the Huawei Public Cloud Trace, we show that LACE-RL reduces cold starts by 51.69% and idle keep-alive carbon emissions by 77.08% compared to Huawei's static policy, while achieving better latency-carbon trade-offs than state-of-the-art heuristic and single-objective baselines, approaching Oracle performance.", "AI": {"tldr": "LACE-RL\u662f\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u670d\u52a1\u5668\u65e0\u670d\u52a1\u8ba1\u7b97\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u51fd\u6570\u5b9e\u4f8b\u7684\u4fdd\u6d3b\u65f6\u957f\uff0c\u5728\u51cf\u5c11\u51b7\u542f\u52a8\u5ef6\u8fdf\u548c\u964d\u4f4e\u78b3\u6392\u653e\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "motivation": "\u65e0\u670d\u52a1\u8ba1\u7b97\u7b80\u5316\u4e86\u4e91\u90e8\u7f72\uff0c\u4f46\u5e26\u6765\u4e86\u670d\u52a1\u5ef6\u8fdf\u548c\u78b3\u6392\u653e\u7ba1\u7406\u7684\u65b0\u6311\u6218\u3002\u51cf\u5c11\u51b7\u542f\u52a8\u5ef6\u8fdf\u9700\u8981\u4fdd\u7559\u70ed\u51fd\u6570\u5b9e\u4f8b\uff0c\u800c\u6700\u5c0f\u5316\u78b3\u6392\u653e\u5219\u503e\u5411\u4e8e\u56de\u6536\u7a7a\u95f2\u8d44\u6e90\u3002\u8fd9\u79cd\u5e73\u8861\u5728\u65f6\u53d8\u7684\u7535\u7f51\u78b3\u5f3a\u5ea6\u548c\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\u6a21\u5f0f\u4e0b\u53d8\u5f97\u590d\u6742\uff0c\u9759\u6001\u4fdd\u6d3b\u7b56\u7565\u6548\u7387\u4f4e\u4e0b\u3002", "method": "LACE-RL\u5c06\u670d\u52a1\u5668\u65e0\u670d\u52a1Pod\u4fdd\u7559\u95ee\u9898\u5efa\u6a21\u4e3a\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\uff0c\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u8c03\u6574\u4fdd\u6d3b\u65f6\u957f\uff0c\u8054\u5408\u5efa\u6a21\u51b7\u542f\u52a8\u6982\u7387\u3001\u51fd\u6570\u7279\u5b9a\u7684\u5ef6\u8fdf\u6210\u672c\u548c\u5b9e\u65f6\u78b3\u5f3a\u5ea6\u3002", "result": "\u4f7f\u7528\u534e\u4e3a\u516c\u5171\u4e91\u8ffd\u8e2a\u6570\u636e\uff0cLACE-RL\u76f8\u6bd4\u534e\u4e3a\u9759\u6001\u7b56\u7565\u51cf\u5c11\u4e8651.69%\u7684\u51b7\u542f\u52a8\u548c77.08%\u7684\u7a7a\u95f2\u4fdd\u6d3b\u78b3\u6392\u653e\uff0c\u5728\u5ef6\u8fdf-\u78b3\u6392\u653e\u6743\u8861\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u542f\u53d1\u5f0f\u548c\u5355\u76ee\u6807\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63a5\u8fd1Oracle\u6027\u80fd\u3002", "conclusion": "LACE-RL\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u4fdd\u6d3b\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u670d\u52a1\u8ba1\u7b97\u4e2d\u5ef6\u8fdf\u548c\u78b3\u6392\u653e\u7684\u6743\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6bd4\u9759\u6001\u7b56\u7565\u548c\u73b0\u6709\u65b9\u6cd5\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2602.23579", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23579", "abs": "https://arxiv.org/abs/2602.23579", "authors": ["Guillem Rodr\u00edguez-Corominas", "Maria J. Blesa", "Christian Blum"], "title": "Construct, Merge, Solve & Adapt with Reinforcement Learning for the min-max Multiple Traveling Salesman Problem", "comment": null, "summary": "The Multiple Traveling Salesman Problem (mTSP) extends the Traveling Salesman Problem to m tours that start and end at a common depot and jointly visit all customers exactly once. In the min-max variant, the objective is to minimize the longest tour, reflecting workload balance. We propose a hybrid approach, Construct, Merge, Solve & Adapt with Reinforcement Learning (RL-CMSA), for the symmetric single-depot min-max mTSP. The method iteratively constructs diverse solutions using probabilistic clustering guided by learned pairwise q-values, merges routes into a compact pool, solves a restricted set-covering MILP, and refines solutions via inter-route remove, shift, and swap moves. The q-values are updated by reinforcing city-pair co-occurrences in high-quality solutions, while the pool is adapted through ageing and pruning. This combination of exact optimization and reinforcement-guided construction balances exploration and exploitation. Computational results on random and TSPLIB instances show that RL-CMSA consistently finds (near-)best solutions and outperforms a state-of-the-art hybrid genetic algorithm under comparable time limits, especially as instance size and the number of salesmen increase.", "AI": {"tldr": "\u63d0\u51faRL-CMSA\u65b9\u6cd5\u89e3\u51b3\u5bf9\u79f0\u5355\u4ed3\u5e93min-max mTSP\u95ee\u9898\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u5f15\u5bfc\u7684\u6784\u9020\u3001\u7cbe\u786e\u4f18\u5316\u548c\u81ea\u9002\u5e94\u673a\u5236\uff0c\u5728\u5e73\u8861\u5de5\u4f5c\u8d1f\u8f7d\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6df7\u5408\u9057\u4f20\u7b97\u6cd5\u3002", "motivation": "\u89e3\u51b3\u591a\u65c5\u884c\u5546\u95ee\u9898\u4e2d\u7684min-max\u53d8\u4f53\uff0c\u76ee\u6807\u662f\u5e73\u8861\u5404\u9500\u552e\u5458\u7684\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u6700\u5c0f\u5316\u6700\u957f\u8def\u7ebf\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u95ee\u9898\u89c4\u6a21\u548c\u9500\u552e\u5458\u6570\u91cf\u589e\u52a0\u65f6\u8868\u73b0\u53d7\u9650\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u6df7\u5408\u65b9\u6cd5\u3002", "method": "\u63d0\u51faRL-CMSA\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u57fa\u4e8e\u5b66\u4e60\u5230\u7684\u6210\u5bf9q\u503c\u7684\u6982\u7387\u805a\u7c7b\u6784\u9020\u591a\u6837\u5316\u89e3\uff1b2) \u5408\u5e76\u8def\u7ebf\u5230\u7d27\u51d1\u6c60\uff1b3) \u6c42\u89e3\u53d7\u9650\u96c6\u5408\u8986\u76d6MILP\uff1b4) \u901a\u8fc7\u8def\u7ebf\u95f4\u79fb\u9664\u3001\u8f6c\u79fb\u548c\u4ea4\u6362\u64cd\u4f5c\u7cbe\u5316\u89e3\uff1b5) \u7528\u9ad8\u8d28\u91cf\u89e3\u4e2d\u7684\u57ce\u5e02\u5bf9\u5171\u73b0\u66f4\u65b0q\u503c\uff1b6) \u901a\u8fc7\u8001\u5316\u548c\u526a\u679d\u81ea\u9002\u5e94\u8c03\u6574\u6c60\u3002", "result": "\u5728\u968f\u673a\u548cTSPLIB\u5b9e\u4f8b\u4e0a\u7684\u8ba1\u7b97\u7ed3\u679c\u8868\u660e\uff0cRL-CMSA\u80fd\u6301\u7eed\u627e\u5230(\u63a5\u8fd1)\u6700\u4f18\u89e3\uff0c\u5728\u53ef\u6bd4\u65f6\u95f4\u9650\u5236\u4e0b\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6df7\u5408\u9057\u4f20\u7b97\u6cd5\uff0c\u7279\u522b\u662f\u5f53\u5b9e\u4f8b\u89c4\u6a21\u548c\u9500\u552e\u5458\u6570\u91cf\u589e\u52a0\u65f6\u3002", "conclusion": "RL-CMSA\u7ed3\u5408\u7cbe\u786e\u4f18\u5316\u548c\u5f3a\u5316\u5b66\u4e60\u5f15\u5bfc\u7684\u6784\u9020\uff0c\u5e73\u8861\u4e86\u63a2\u7d22\u548c\u5229\u7528\uff0c\u4e3a\u5bf9\u79f0\u5355\u4ed3\u5e93min-max mTSP\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u6c42\u89e3\u8d28\u91cf\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2602.23516", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23516", "abs": "https://arxiv.org/abs/2602.23516", "authors": ["Meisam Mohammady", "Qin Yang", "Nicholas Stout", "Ayesha Samreen", "Han Wang", "Christopher J Quinn", "Yuan Hong"], "title": "Lap2: Revisiting Laplace DP-SGD for High Dimensions via Majorization Theory", "comment": "16 pages including appendix. arXiv admin note: text overlap with arXiv:2509.06264", "summary": "Differentially Private Stochastic Gradient Descent (DP-SGD) is a cornerstone technique for ensuring privacy in deep learning, widely used in both training from scratch and fine-tuning large-scale language models. While DP-SGD predominantly relies on the Gaussian mechanism, the Laplace mechanism remains underutilized due to its reliance on L1 norm clipping. This constraint severely limits its practicality in high-dimensional models because the L1 norm of an n-dimensional gradient can be up to sqrt(n) times larger than its L2 norm. As a result, the required noise scale grows significantly with model size, leading to poor utility or untrainable models.\n  In this work, we introduce Lap2, a new solution that enables L2 clipping for Laplace DP-SGD while preserving strong privacy guarantees. We overcome the dimensionality-driven clipping barrier by computing coordinate-wise moment bounds and applying majorization theory to construct a tight, data-independent upper bound over the full model. By exploiting the Schur-convexity of the moment accountant function, we aggregate these bounds using a carefully designed majorization set that respects the L2 clipping constraint. This yields a multivariate privacy accountant that scales gracefully with model dimension and enables the use of thousands of moments. Empirical evaluations demonstrate that our approach significantly improves the performance of Laplace DP-SGD, achieving results comparable to or better than Gaussian DP-SGD under strong privacy constraints. For instance, fine-tuning RoBERTa-base (125M parameters) on SST-2 achieves 87.88% accuracy at epsilon=0.54, outperforming Gaussian (87.16%) and standard Laplace (48.97%) under the same budget.", "AI": {"tldr": "Lap2\uff1a\u4e00\u79cd\u65b0\u7684\u5dee\u5206\u9690\u79c1\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\uff0c\u4f7f\u7528L2\u88c1\u526a\u5b9e\u73b0Laplace\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfLaplace DP-SGD\u56e0L1\u88c1\u526a\u5728\u9ad8\u7ef4\u6a21\u578b\u4e2d\u566a\u58f0\u8fc7\u5927\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfLaplace DP-SGD\u4f9d\u8d56L1\u8303\u6570\u88c1\u526a\uff0c\u5728\u9ad8\u7ef4\u6a21\u578b\u4e2dL1\u8303\u6570\u53ef\u80fd\u6bd4L2\u8303\u6570\u5927sqrt(n)\u500d\uff0c\u5bfc\u81f4\u566a\u58f0\u89c4\u6a21\u968f\u6a21\u578b\u7ef4\u5ea6\u6025\u5267\u589e\u52a0\uff0c\u4e25\u91cd\u5f71\u54cd\u6a21\u578b\u5b9e\u7528\u6027\u3002", "method": "\u901a\u8fc7\u8ba1\u7b97\u5750\u6807\u65b9\u5411\u77e9\u8fb9\u754c\uff0c\u5e94\u7528\u4f18\u5316\u7406\u8bba\u6784\u5efa\u6570\u636e\u65e0\u5173\u7684\u7d27\u81f4\u4e0a\u754c\uff0c\u5229\u7528\u77e9\u8ba1\u6570\u51fd\u6570\u7684Schur\u51f8\u6027\uff0c\u8bbe\u8ba1\u6ee1\u8db3L2\u88c1\u526a\u7ea6\u675f\u7684\u4f18\u5316\u96c6\uff0c\u5b9e\u73b0\u591a\u53d8\u91cf\u9690\u79c1\u8ba1\u6570\u3002", "result": "Lap2\u663e\u8457\u63d0\u5347\u4e86Laplace DP-SGD\u6027\u80fd\uff0c\u5728\u5f3a\u9690\u79c1\u7ea6\u675f\u4e0b\u8fbe\u5230\u6216\u8d85\u8d8aGaussian DP-SGD\u3002\u4f8b\u5982\uff0c\u5728RoBERTa-base\u4e0a\u5fae\u8c03SST-2\uff0c\u03b5=0.54\u65f6\u51c6\u786e\u7387\u8fbe\u523087.88%\uff0c\u4f18\u4e8eGaussian\u768487.16%\u548c\u6807\u51c6Laplace\u768448.97%\u3002", "conclusion": "Lap2\u6210\u529f\u89e3\u51b3\u4e86Laplace\u673a\u5236\u5728\u9ad8\u7ef4\u5dee\u5206\u9690\u79c1\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5b9e\u7528\u6027\u969c\u788d\uff0c\u4e3aDP-SGD\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u9009\u62e9\uff0c\u5728\u4fdd\u6301\u5f3a\u9690\u79c1\u4fdd\u8bc1\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.24044", "categories": ["cs.DC", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24044", "abs": "https://arxiv.org/abs/2602.24044", "authors": ["Ferran Agullo", "Joan Oliveras", "Chen Wang", "Alberto Gutierrez-Torre", "Olivier Tardieu", "Alaa Youssef", "Jordi Torres", "Josep Ll. Berral"], "title": "Data Driven Optimization of GPU efficiency for Distributed LLM Adapter Serving", "comment": "journal extension of the workshop paper titled as \"A data-driven ml approach for maximizing performance in llm-adapter serving\"", "summary": "Large Language Model (LLM) adapters enable low-cost model specialization, but introduce complex caching and scheduling challenges in distributed serving systems where hundreds of adapters must be hosted concurrently. While prior work has largely focused on latency minimization, resource efficiency through throughput maximization remains underexplored. This paper presents a data-driven pipeline that, for a given workload, computes an adapter placement that serves the workload with the minimum number of GPUs while avoiding request starvation and GPU memory errors. To that end, the approach identifies the maximum feasible throughput attainable on each GPU by leveraging accurate performance predictions learned from real serving behavior. The proposed pipeline integrates three components: (i) a Digital Twin (DT) tailored to LLM-adapter serving, (ii) a distilled machine learning (ML) model trained on DT-generated data, and (iii) a greedy placement algorithm that exploits ML-based performance estimates to maximize GPU efficiency. The DT emulates real system dynamics with high fidelity, achieving below 5% throughput estimation error while executing up to 90 times faster than full LLM benchmarking across both predictable and unpredictable workloads. The learned ML models further accelerate performance estimation with marginal accuracy degradation, enabling scalable optimization. Experimental results demonstrate that the pipeline substantially improves GPU efficiency by reducing the number of GPUs required to sustain target workloads. Beyond GPU efficiency, the pipeline can be adapted to alternative objectives, such as latency minimization, highlighting its versatility for future large-scale LLM serving infrastructures.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6570\u636e\u9a71\u52a8\u7ba1\u9053\uff0c\u901a\u8fc7\u4f18\u5316\u9002\u914d\u5668\u653e\u7f6e\u7b56\u7565\uff0c\u5728\u5206\u5e03\u5f0fLLM\u670d\u52a1\u7cfb\u7edf\u4e2d\u6700\u5927\u5316GPU\u6548\u7387\uff0c\u51cf\u5c11\u6240\u9700GPU\u6570\u91cf\uff0c\u540c\u65f6\u907f\u514d\u8bf7\u6c42\u9965\u997f\u548c\u5185\u5b58\u9519\u8bef\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9002\u914d\u5668\u867d\u7136\u5b9e\u73b0\u4e86\u4f4e\u6210\u672c\u6a21\u578b\u4e13\u4e1a\u5316\uff0c\u4f46\u5728\u5206\u5e03\u5f0f\u670d\u52a1\u7cfb\u7edf\u4e2d\u5f15\u5165\u590d\u6742\u7684\u7f13\u5b58\u548c\u8c03\u5ea6\u6311\u6218\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5ef6\u8fdf\u6700\u5c0f\u5316\uff0c\u800c\u901a\u8fc7\u541e\u5410\u91cf\u6700\u5927\u5316\u5b9e\u73b0\u8d44\u6e90\u6548\u7387\u7684\u7814\u7a76\u4ecd\u7136\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\u7684\u7ba1\u9053\uff1a1) \u9488\u5bf9LLM-\u9002\u914d\u5668\u670d\u52a1\u5b9a\u5236\u7684\u6570\u5b57\u5b6a\u751f(DT)\uff1b2) \u57fa\u4e8eDT\u751f\u6210\u6570\u636e\u8bad\u7ec3\u7684\u84b8\u998f\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff1b3) \u5229\u7528ML\u6027\u80fd\u4f30\u8ba1\u7684\u8d2a\u5fc3\u653e\u7f6e\u7b97\u6cd5\u6765\u6700\u5927\u5316GPU\u6548\u7387\u3002", "result": "\u6570\u5b57\u5b6a\u751f\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u5ea6\u4eff\u771f\uff0c\u541e\u5410\u91cf\u4f30\u8ba1\u8bef\u5dee\u4f4e\u4e8e5%\uff0c\u6267\u884c\u901f\u5ea6\u6bd4\u5b8c\u6574LLM\u57fa\u51c6\u6d4b\u8bd5\u5feb90\u500d\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7ba1\u9053\u663e\u8457\u63d0\u9ad8\u4e86GPU\u6548\u7387\uff0c\u51cf\u5c11\u4e86\u7ef4\u6301\u76ee\u6807\u5de5\u4f5c\u8d1f\u8f7d\u6240\u9700\u7684GPU\u6570\u91cf\u3002", "conclusion": "\u8be5\u7ba1\u9053\u4e0d\u4ec5\u63d0\u9ad8\u4e86GPU\u6548\u7387\uff0c\u8fd8\u53ef\u9002\u5e94\u5176\u4ed6\u76ee\u6807\uff08\u5982\u5ef6\u8fdf\u6700\u5c0f\u5316\uff09\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5927\u89c4\u6a21LLM\u670d\u52a1\u57fa\u7840\u8bbe\u65bd\u4e2d\u7684\u591a\u529f\u80fd\u6027\u548c\u672a\u6765\u6f5c\u529b\u3002"}}
{"id": "2602.23605", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23605", "abs": "https://arxiv.org/abs/2602.23605", "authors": ["Zongzhe Xu", "Zitao Shuai", "Eideen Mozaffari", "Ravi S. Aysola", "Rajesh Kumar", "Yuzhe Yang"], "title": "SleepLM: Natural-Language Intelligence for Human Sleep", "comment": null, "summary": "We present SleepLM, a family of sleep-language foundation models that enable human sleep alignment, interpretation, and interaction with natural language. Despite the critical role of sleep, learning-based sleep analysis systems operate in closed label spaces (e.g., predefined stages or events) and fail to describe, query, or generalize to novel sleep phenomena. SleepLM bridges natural language and multimodal polysomnography, enabling language-grounded representations of sleep physiology. To support this alignment, we introduce a multilevel sleep caption generation pipeline that enables the curation of the first large-scale sleep-text dataset, comprising over 100K hours of data from more than 10,000 individuals. Furthermore, we present a unified pretraining objective that combines contrastive alignment, caption generation, and signal reconstruction to better capture physiological fidelity and cross-modal interactions. Extensive experiments on real-world sleep understanding tasks verify that SleepLM outperforms state-of-the-art in zero-shot and few-shot learning, cross-modal retrieval, and sleep captioning. Importantly, SleepLM also exhibits intriguing capabilities including language-guided event localization, targeted insight generation, and zero-shot generalization to unseen tasks. All code and data will be open-sourced.", "AI": {"tldr": "SleepLM\u662f\u4e00\u4e2a\u7761\u7720-\u8bed\u8a00\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4e0e\u591a\u6a21\u6001\u591a\u5bfc\u7761\u7720\u56fe\u5bf9\u9f50\uff0c\u5b9e\u73b0\u7761\u7720\u751f\u7406\u7684\u8bed\u8a00\u8868\u5f81\uff0c\u652f\u6301\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u5b66\u4e60\u3001\u8de8\u6a21\u6001\u68c0\u7d22\u7b49\u4efb\u52a1\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5b66\u4e60\u7684\u7761\u7720\u5206\u6790\u7cfb\u7edf\u5c40\u9650\u4e8e\u5c01\u95ed\u6807\u7b7e\u7a7a\u95f4\uff08\u5982\u9884\u5b9a\u4e49\u9636\u6bb5\u6216\u4e8b\u4ef6\uff09\uff0c\u65e0\u6cd5\u63cf\u8ff0\u3001\u67e5\u8be2\u6216\u6cdb\u5316\u5230\u65b0\u7684\u7761\u7720\u73b0\u8c61\uff0c\u9700\u8981\u5c06\u81ea\u7136\u8bed\u8a00\u4e0e\u591a\u6a21\u6001\u7761\u7720\u6570\u636e\u5bf9\u9f50\u3002", "method": "1) \u5f15\u5165\u591a\u7ea7\u7761\u7720\u63cf\u8ff0\u751f\u6210\u6d41\u7a0b\uff0c\u521b\u5efa\u9996\u4e2a\u5927\u89c4\u6a21\u7761\u7720-\u6587\u672c\u6570\u636e\u96c6\uff0810\u4e07+\u5c0f\u65f6\uff0c1\u4e07+\u4e2a\u4f53\uff09\uff1b2) \u63d0\u51fa\u7edf\u4e00\u9884\u8bad\u7ec3\u76ee\u6807\uff0c\u7ed3\u5408\u5bf9\u6bd4\u5bf9\u9f50\u3001\u63cf\u8ff0\u751f\u6210\u548c\u4fe1\u53f7\u91cd\u5efa\uff0c\u6355\u6349\u751f\u7406\u4fdd\u771f\u5ea6\u548c\u8de8\u6a21\u6001\u4ea4\u4e92\u3002", "result": "SleepLM\u5728\u771f\u5b9e\u4e16\u754c\u7761\u7720\u7406\u89e3\u4efb\u52a1\u4e2d\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728\u96f6\u6837\u672c/\u5c11\u6837\u672c\u5b66\u4e60\u3001\u8de8\u6a21\u6001\u68c0\u7d22\u548c\u7761\u7720\u63cf\u8ff0\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u5c55\u73b0\u51fa\u8bed\u8a00\u5f15\u5bfc\u4e8b\u4ef6\u5b9a\u4f4d\u3001\u76ee\u6807\u6d1e\u5bdf\u751f\u6210\u548c\u96f6\u6837\u672c\u6cdb\u5316\u5230\u672a\u89c1\u4efb\u52a1\u7684\u80fd\u529b\u3002", "conclusion": "SleepLM\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4e0e\u591a\u6a21\u6001\u7761\u7720\u6570\u636e\u7684\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4e86\u66f4\u7075\u6d3b\u3001\u53ef\u89e3\u91ca\u7684\u7761\u7720\u5206\u6790\uff0c\u4e3a\u7761\u7720\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u6240\u6709\u4ee3\u7801\u548c\u6570\u636e\u5c06\u5f00\u6e90\u3002"}}
{"id": "2602.23632", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23632", "abs": "https://arxiv.org/abs/2602.23632", "authors": ["Lun Zhan", "Feng Xiong", "Huanyong Liu", "Feng Zhang", "Yuhui Yin"], "title": "MMKG-RDS: Reasoning Data Synthesis via Deep Mining of Multimodal Knowledge Graphs", "comment": null, "summary": "Synthesizing high-quality training data is crucial for enhancing domain models' reasoning abilities. Existing methods face limitations in long-tail knowledge coverage, effectiveness verification, and interpretability. Knowledge-graph-based approaches still fall short in functionality, granularity, customizability, and evaluation. To address these issues, we propose MMKG-RDS, a flexible framework for reasoning data synthesis that leverages multimodal knowledge graphs. It supports fine-grained knowledge extraction, customizable path sampling, and multidimensional data quality scoring. We validate MMKG-RDS with the MMKG-RDS-Bench dataset, covering five domains, 17 task types, and 14,950 samples. Experimental results show fine-tuning Qwen3 models (0.6B/8B/32B) on a small number of synthesized samples improves reasoning accuracy by 9.2%. The framework also generates distinct data, challenging existing models on tasks involving tables and formulas, useful for complex benchmark construction. The dataset and code are available at https://github.com/360AILAB-NLP/MMKG-RDS", "AI": {"tldr": "MMKG-RDS\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u7684\u63a8\u7406\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u63d0\u53d6\u3001\u53ef\u5b9a\u5236\u8def\u5f84\u91c7\u6837\u548c\u591a\u7ef4\u6570\u636e\u8d28\u91cf\u8bc4\u5206\uff0c\u63d0\u5347\u9886\u57df\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u957f\u5c3e\u77e5\u8bc6\u8986\u76d6\u3001\u6709\u6548\u6027\u9a8c\u8bc1\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u65b9\u6cd5\u5728\u529f\u80fd\u6027\u3001\u7c92\u5ea6\u3001\u53ef\u5b9a\u5236\u6027\u548c\u8bc4\u4f30\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u63a8\u7406\u6570\u636e\u5408\u6210\u6846\u67b6\u3002", "method": "\u63d0\u51faMMKG-RDS\u6846\u67b6\uff0c\u5229\u7528\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u652f\u6301\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u63d0\u53d6\u3001\u53ef\u5b9a\u5236\u8def\u5f84\u91c7\u6837\u548c\u591a\u7ef4\u6570\u636e\u8d28\u91cf\u8bc4\u5206\uff0c\u6784\u5efaMMKG-RDS-Bench\u6570\u636e\u96c6\u8986\u76d65\u4e2a\u9886\u57df\u300117\u79cd\u4efb\u52a1\u7c7b\u578b\u548c14,950\u4e2a\u6837\u672c\u3002", "result": "\u5728\u5c11\u91cf\u5408\u6210\u6837\u672c\u4e0a\u5fae\u8c03Qwen3\u6a21\u578b\uff080.6B/8B/32B\uff09\u53ef\u5c06\u63a8\u7406\u51c6\u786e\u7387\u63d0\u53479.2%\uff0c\u6846\u67b6\u751f\u6210\u7684\u6570\u636e\u80fd\u6311\u6218\u73b0\u6709\u6a21\u578b\u5728\u8868\u683c\u548c\u516c\u5f0f\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u9002\u7528\u4e8e\u590d\u6742\u57fa\u51c6\u6784\u5efa\u3002", "conclusion": "MMKG-RDS\u662f\u4e00\u4e2a\u6709\u6548\u7684\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u9a71\u52a8\u7684\u63a8\u7406\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u751f\u6210\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u636e\uff0c\u4e3a\u590d\u6742\u57fa\u51c6\u6784\u5efa\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2602.23569", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.23569", "abs": "https://arxiv.org/abs/2602.23569", "authors": ["Vincent Langford", "Shihan Zhao", "Hongyu Zhang", "Ben Dong", "Qian Wang", "Anees Rehman", "Yuntao Liu"], "title": "CLOAQ: Combined Logic and Angle Obfuscation for Quantum Circuits", "comment": "To appear at ISCAS 2026", "summary": "In the realm of quantum computing, quantum circuits serve as essential depictions of quantum algorithms, which are then compiled into executable operations for quantum computations. Quantum compilers are responsible for converting these algorithmic quantum circuits into versions compatible with specific quantum hardware, thus connecting quantum software with hardware. Nevertheless, untrusted quantum compilers present notable threats. They have the potential to result in the theft of quantum circuit designs and jeopardize sensitive intellectual property (IP). In this work, we propose CLOAQ, a quantum circuit obfuscation (QCO) approach that hides the logic and the phase angles of selected gates within the obfuscated quantum circuit. To evaluate the effectiveness of CLOAQ, we sample the input state uniformly from the Hilbert space of all qubits, which is more accurate than prior work that use all-|0> inputs. Our results show that CLOAQ benefits from the synergy between logic and phase protections. Compared with prior QCO approaches using only one perspective, the combined method is more resilient to attacks and causes greater functional disruption when the unlocking key is incorrect.", "AI": {"tldr": "CLOAQ\u662f\u4e00\u79cd\u91cf\u5b50\u7535\u8def\u6df7\u6dc6\u65b9\u6cd5\uff0c\u901a\u8fc7\u9690\u85cf\u9009\u5b9a\u95e8\u7684\u903b\u8f91\u548c\u76f8\u4f4d\u89d2\u5ea6\u6765\u4fdd\u62a4\u91cf\u5b50\u7535\u8def\u8bbe\u8ba1\uff0c\u9632\u6b62\u4e0d\u4fe1\u4efb\u7684\u91cf\u5b50\u7f16\u8bd1\u5668\u7a83\u53d6\u77e5\u8bc6\u4ea7\u6743\u3002", "motivation": "\u4e0d\u4fe1\u4efb\u7684\u91cf\u5b50\u7f16\u8bd1\u5668\u53ef\u80fd\u7a83\u53d6\u91cf\u5b50\u7535\u8def\u8bbe\u8ba1\uff0c\u5371\u53ca\u654f\u611f\u7684\u77e5\u8bc6\u4ea7\u6743\u3002\u73b0\u6709\u91cf\u5b50\u7535\u8def\u6df7\u6dc6\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u4fdd\u62a4\u65b9\u6848\u3002", "method": "\u63d0\u51faCLOAQ\u91cf\u5b50\u7535\u8def\u6df7\u6dc6\u65b9\u6cd5\uff0c\u540c\u65f6\u9690\u85cf\u9009\u5b9a\u95e8\u7684\u903b\u8f91\u548c\u76f8\u4f4d\u89d2\u5ea6\u3002\u91c7\u7528\u4ece\u6240\u6709\u91cf\u5b50\u6bd4\u7279\u7684\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u5747\u5300\u91c7\u6837\u8f93\u5165\u72b6\u6001\u7684\u65b9\u6cd5\u8fdb\u884c\u8bc4\u4f30\uff0c\u6bd4\u4e4b\u524d\u4f7f\u7528\u5168|0>\u8f93\u5165\u7684\u65b9\u6cd5\u66f4\u51c6\u786e\u3002", "result": "CLOAQ\u53d7\u76ca\u4e8e\u903b\u8f91\u548c\u76f8\u4f4d\u4fdd\u62a4\u7684\u534f\u540c\u4f5c\u7528\u3002\u4e0e\u4ec5\u4f7f\u7528\u5355\u4e00\u89c6\u89d2\u7684\u5148\u524dQCO\u65b9\u6cd5\u76f8\u6bd4\uff0c\u7ec4\u5408\u65b9\u6cd5\u5bf9\u653b\u51fb\u66f4\u5177\u5f39\u6027\uff0c\u5f53\u89e3\u9501\u5bc6\u94a5\u9519\u8bef\u65f6\u4f1a\u9020\u6210\u66f4\u5927\u7684\u529f\u80fd\u7834\u574f\u3002", "conclusion": "CLOAQ\u901a\u8fc7\u7ed3\u5408\u903b\u8f91\u548c\u76f8\u4f4d\u4fdd\u62a4\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u6709\u6548\u7684\u91cf\u5b50\u7535\u8def\u6df7\u6dc6\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u597d\u5730\u4fdd\u62a4\u91cf\u5b50\u7535\u8def\u8bbe\u8ba1\u514d\u53d7\u4e0d\u4fe1\u4efb\u91cf\u5b50\u7f16\u8bd1\u5668\u7684\u5a01\u80c1\u3002"}}
{"id": "2602.23643", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23643", "abs": "https://arxiv.org/abs/2602.23643", "authors": ["Judah Goldfeder", "Philippe Wyder", "Yann LeCun", "Ravid Shwartz Ziv"], "title": "AI Must Embrace Specialization via Superhuman Adaptable Intelligence", "comment": null, "summary": "Everyone from AI executives and researchers to doomsayers, politicians, and activists is talking about Artificial General Intelligence (AGI). Yet, they often don't seem to agree on its exact definition. One common definition of AGI is an AI that can do everything a human can do, but are humans truly general? In this paper, we address what's wrong with our conception of AGI, and why, even in its most coherent formulation, it is a flawed concept to describe the future of AI. We explore whether the most widely accepted definitions are plausible, useful, and truly general. We argue that AI must embrace specialization, rather than strive for generality, and in its specialization strive for superhuman performance, and introduce Superhuman Adaptable Intelligence (SAI). SAI is defined as intelligence that can learn to exceed humans at anything important that we can do, and that can fill in the skill gaps where humans are incapable. We then lay out how SAI can help hone a discussion around AI that was blurred by an overloaded definition of AGI, and extrapolate the implications of using it as a guide for the future.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6279\u5224\u4e86\u5f53\u524d\u5bf9\u901a\u7528\u4eba\u5de5\u667a\u80fd\uff08AGI\uff09\u7684\u5b9a\u4e49\uff0c\u8ba4\u4e3a\u4eba\u7c7b\u672c\u8eab\u5e76\u975e\u771f\u6b63\"\u901a\u7528\"\uff0c\u63d0\u51fa\u4e86\"\u8d85\u4eba\u9002\u5e94\u6027\u667a\u80fd\uff08SAI\uff09\"\u4f5c\u4e3a\u66f4\u5b9e\u7528\u7684AI\u53d1\u5c55\u65b9\u5411\uff0c\u5f3a\u8c03\u4e13\u4e1a\u5316\u800c\u975e\u901a\u7528\u6027\u3002", "motivation": "\u5f53\u524dAI\u9886\u57df\u5bf9AGI\u7684\u5b9a\u4e49\u5b58\u5728\u6df7\u4e71\u548c\u4e0d\u4e00\u81f4\uff0c\u5404\u65b9\u5bf9AGI\u7684\u7406\u89e3\u5404\u4e0d\u76f8\u540c\u3002\u4f5c\u8005\u8ba4\u4e3a\u73b0\u6709\u7684AGI\u6982\u5ff5\u5b58\u5728\u95ee\u9898\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003AI\u7684\u53d1\u5c55\u65b9\u5411\uff0c\u7279\u522b\u662f\"\u4eba\u7c7b\u80fd\u505a\u7684\u4e00\u5207\"\u8fd9\u79cd\u5b9a\u4e49\u662f\u5426\u5408\u7406\u548c\u6709\u7528\u3002", "method": "\u901a\u8fc7\u5206\u6790\u73b0\u6709AGI\u5b9a\u4e49\u7684\u95ee\u9898\uff0c\u8bba\u8bc1\u4eba\u7c7b\u5e76\u975e\u771f\u6b63\"\u901a\u7528\"\uff0c\u63d0\u51faSAI\uff08\u8d85\u4eba\u9002\u5e94\u6027\u667a\u80fd\uff09\u4f5c\u4e3a\u66ff\u4ee3\u6982\u5ff5\u3002SAI\u5b9a\u4e49\u4e3a\u80fd\u591f\u5b66\u4e60\u5728\u4eba\u7c7b\u80fd\u505a\u7684\u4efb\u4f55\u91cd\u8981\u4e8b\u60c5\u4e0a\u8d85\u8d8a\u4eba\u7c7b\uff0c\u5e76\u80fd\u586b\u8865\u4eba\u7c7b\u80fd\u529b\u7a7a\u767d\u7684\u667a\u80fd\u3002", "result": "\u63d0\u51fa\u4e86SAI\u6982\u5ff5\u4f5c\u4e3aAGI\u7684\u66ff\u4ee3\u6846\u67b6\uff0c\u8ba4\u4e3aAI\u5e94\u8be5\u8ffd\u6c42\u4e13\u4e1a\u5316\u800c\u975e\u901a\u7528\u6027\uff0c\u5728\u4e13\u4e1a\u5316\u4e2d\u5b9e\u73b0\u8d85\u4eba\u6027\u80fd\u3002SAI\u80fd\u591f\u5e2e\u52a9\u6f84\u6e05\u56e0AGI\u5b9a\u4e49\u8fc7\u8f7d\u800c\u6a21\u7cca\u7684AI\u8ba8\u8bba\u3002", "conclusion": "AGI\u662f\u4e00\u4e2a\u6709\u7f3a\u9677\u7684\u6982\u5ff5\uff0cAI\u53d1\u5c55\u5e94\u8be5\u4e13\u6ce8\u4e8e\u4e13\u4e1a\u5316\u800c\u975e\u901a\u7528\u6027\u3002SAI\u63d0\u4f9b\u4e86\u66f4\u6e05\u6670\u3001\u66f4\u5b9e\u7528\u7684\u6846\u67b6\u6765\u6307\u5bfcAI\u7684\u672a\u6765\u53d1\u5c55\uff0c\u5f3a\u8c03\u5728\u7279\u5b9a\u9886\u57df\u5b9e\u73b0\u8d85\u4eba\u6027\u80fd\u5e76\u586b\u8865\u4eba\u7c7b\u80fd\u529b\u7a7a\u767d\u3002"}}
{"id": "2602.23668", "categories": ["cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.23668", "abs": "https://arxiv.org/abs/2602.23668", "authors": ["Yihan", "Wen", "Xin Chen"], "title": "PseudoAct: Leveraging Pseudocode Synthesis for Flexible Planning and Action Control in Large Language Model Agents", "comment": null, "summary": "Large language model (LLM) agents typically rely on reactive decision-making paradigms such as ReAct, selecting actions conditioned on growing execution histories. While effective for short tasks, these approaches often lead to redundant tool usage, unstable reasoning, and high token consumption in complex long-horizon tasks involving branching, iteration, or multi-tool coordination. To address these limitations, this paper introduces PseudoAct, a novel framework for flexible planning and action control in LLM agents through pseudocode synthesis. Leveraging the ability of LLMs to express task-solving strategies as code, PseudoAct synthesizes a structured pseudocode plan that decomposes a task into subtasks and explicitly encodes control flow, including sequencing, conditionals, loops, parallel composition, and combinations of these logic primitives. Actions are then executed by following this global plan, making the decision logic explicit and temporally coherent. This design reduces redundant actions, prevents infinite loops, and avoids uninformative alternative exploration, enabling consistent and efficient long-horizon decision-making. Experiments on benchmark datasets show that our method significantly outperforms existing reactive agent approaches, achieving a 20.93% absolute gain in success rate on FEVER and setting a new state-of-the-art on HotpotQA.", "AI": {"tldr": "PseudoAct\uff1a\u901a\u8fc7\u4f2a\u4ee3\u7801\u5408\u6210\u5b9e\u73b0LLM\u667a\u80fd\u4f53\u7075\u6d3b\u89c4\u5212\u548c\u884c\u52a8\u63a7\u5236\u7684\u65b0\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u590d\u6742\u957f\u65f6\u4efb\u52a1\u6027\u80fd", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\uff08\u5982ReAct\uff09\u4f9d\u8d56\u53cd\u5e94\u5f0f\u51b3\u7b56\u8303\u5f0f\uff0c\u5728\u590d\u6742\u957f\u65f6\u4efb\u52a1\u4e2d\u9762\u4e34\u5197\u4f59\u5de5\u5177\u4f7f\u7528\u3001\u63a8\u7406\u4e0d\u7a33\u5b9a\u3001token\u6d88\u8017\u9ad8\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u7ed3\u6784\u5316\u7684\u89c4\u5212\u65b9\u6cd5", "method": "\u5229\u7528LLM\u5c06\u4efb\u52a1\u89e3\u51b3\u7b56\u7565\u8868\u8fbe\u4e3a\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u5408\u6210\u7ed3\u6784\u5316\u4f2a\u4ee3\u7801\u8ba1\u5212\uff0c\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u5b50\u4efb\u52a1\u5e76\u663e\u5f0f\u7f16\u7801\u63a7\u5236\u6d41\uff08\u987a\u5e8f\u3001\u6761\u4ef6\u3001\u5faa\u73af\u3001\u5e76\u884c\u7b49\uff09\uff0c\u7136\u540e\u6309\u5168\u5c40\u8ba1\u5212\u6267\u884c\u884c\u52a8", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u53cd\u5e94\u5f0f\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u5728FEVER\u4e0a\u5b9e\u73b020.93%\u7684\u7edd\u5bf9\u6210\u529f\u7387\u63d0\u5347\uff0c\u5728HotpotQA\u4e0a\u8fbe\u5230\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73", "conclusion": "PseudoAct\u901a\u8fc7\u4f2a\u4ee3\u7801\u5408\u6210\u5b9e\u73b0\u663e\u5f0f\u3001\u65f6\u95f4\u4e00\u81f4\u7684\u51b3\u7b56\u903b\u8f91\uff0c\u51cf\u5c11\u5197\u4f59\u884c\u52a8\u3001\u9632\u6b62\u65e0\u9650\u5faa\u73af\u3001\u907f\u514d\u65e0\u4fe1\u606f\u66ff\u4ee3\u63a2\u7d22\uff0c\u4e3aLLM\u667a\u80fd\u4f53\u63d0\u4f9b\u4e00\u81f4\u9ad8\u6548\u7684\u957f\u671f\u51b3\u7b56\u80fd\u529b"}}
{"id": "2602.23659", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.23659", "abs": "https://arxiv.org/abs/2602.23659", "authors": ["Jeff Nijsse", "Andrea Pinto"], "title": "Central Bank Digital Currencies: Where is the Privacy, Technology, and Anonymity?", "comment": "21 pages, 7 figures", "summary": "In an age of financial system digitisation and the increasing adoption of digital currencies, Central Bank Digital Currencies (CBDCs) have emerged as a focal point for technological innovation. Privacy compliance has become a key factor in the successful design of CBDCs, extending beyond technical requirements to influence legal requirements, user trust, and security considerations. Implementing Privacy-Enhancing Technologies (PETs) in CBDCs requires an interdisciplinary approach, however, the lack of a common understanding of privacy and the essential technological characteristics restricts progress. This work investigates: (1) How privacy can be defined within the framework of CBDCs and what implications does this definition have for CBDCs design? and (2) Which PETs can be employed to enhance privacy in CBDC design? We propose a comprehensive definition for privacy that is mapped to the cryptographic landscape for feature implementation. The research is validated against case studies from 20 current CBDCs. The study shows that comprehensive privacy can be designed in the proposal stage, but that privacy does not reach the launched version of the CBDC.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u592e\u884c\u6570\u5b57\u8d27\u5e01\u4e2d\u7684\u9690\u79c1\u5b9a\u4e49\u53ca\u5176\u5bf9\u8bbe\u8ba1\u7684\u5f71\u54cd\uff0c\u5206\u6790\u4e86\u53ef\u7528\u7684\u9690\u79c1\u589e\u5f3a\u6280\u672f\uff0c\u5e76\u901a\u8fc720\u4e2aCBDC\u6848\u4f8b\u9a8c\u8bc1\u4e86\u7814\u7a76\u53d1\u73b0\u3002", "motivation": "\u968f\u7740\u91d1\u878d\u7cfb\u7edf\u6570\u5b57\u5316\u548c\u6570\u5b57\u8d27\u5e01\u91c7\u7528\u589e\u52a0\uff0c\u592e\u884c\u6570\u5b57\u8d27\u5e01\u6210\u4e3a\u6280\u672f\u521b\u65b0\u7126\u70b9\u3002\u9690\u79c1\u5408\u89c4\u5df2\u6210\u4e3aCBDC\u6210\u529f\u8bbe\u8ba1\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4e0d\u4ec5\u6d89\u53ca\u6280\u672f\u8981\u6c42\uff0c\u8fd8\u5f71\u54cd\u6cd5\u5f8b\u8981\u6c42\u3001\u7528\u6237\u4fe1\u4efb\u548c\u5b89\u5168\u8003\u8651\u3002\u7136\u800c\uff0c\u7f3a\u4e4f\u5bf9\u9690\u79c1\u7684\u5171\u540c\u7406\u89e3\u548c\u6280\u672f\u7279\u6027\u9650\u5236\u4e86\u9690\u79c1\u589e\u5f3a\u6280\u672f\u5728CBDC\u4e2d\u7684\u5e94\u7528\u8fdb\u5c55\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e00\u4e2a\u5168\u9762\u7684\u9690\u79c1\u5b9a\u4e49\uff0c\u5e76\u5c06\u5176\u6620\u5c04\u5230\u5bc6\u7801\u5b66\u9886\u57df\u4ee5\u8fdb\u884c\u529f\u80fd\u5b9e\u73b0\u3002\u901a\u8fc7\u5bf920\u4e2a\u5f53\u524dCBDC\u7684\u6848\u4f8b\u7814\u7a76\u6765\u9a8c\u8bc1\u7814\u7a76\u6210\u679c\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5168\u9762\u7684\u9690\u79c1\u53ef\u4ee5\u5728\u63d0\u6848\u9636\u6bb5\u8fdb\u884c\u8bbe\u8ba1\uff0c\u4f46\u9690\u79c1\u529f\u80fd\u901a\u5e38\u65e0\u6cd5\u5728\u6700\u7ec8\u53d1\u5e03\u7684CBDC\u7248\u672c\u4e2d\u5b9e\u73b0\u3002", "conclusion": "CBDC\u8bbe\u8ba1\u9700\u8981\u8de8\u5b66\u79d1\u65b9\u6cd5\u6765\u6574\u5408\u9690\u79c1\u589e\u5f3a\u6280\u672f\uff0c\u4f46\u5f53\u524d\u5b9e\u8df5\u8868\u660e\u9690\u79c1\u529f\u80fd\u5728\u4ece\u63d0\u6848\u5230\u5b9e\u9645\u53d1\u5e03\u7684\u8f6c\u5316\u8fc7\u7a0b\u4e2d\u5b58\u5728\u5b9e\u65bd\u5dee\u8ddd\u3002"}}
{"id": "2602.23698", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.23698", "abs": "https://arxiv.org/abs/2602.23698", "authors": ["Eman Alqahtani", "Mustafa A. Mustafa"], "title": "Privacy-Preserving Local Energy Trading Considering Network Fees", "comment": null, "summary": "Driven by the widespread deployment of distributed energy resources, local energy markets (LEMs) have emerged as a promising approach for enabling direct trades among prosumers and consumers to balance intermittent generation and demand locally. However, LEMs involve processing sensitive participant data, which, if not protected, poses privacy risks. At the same time, since electricity is exchanged over the physical power network, market mechanisms should consider physical constraints and network-related costs. Existing work typically addresses these issues separately, either by incorporating grid-related aspects or by providing privacy protection. To address this gap, we propose a privacy-preserving protocol for LEMs, with consideration of network fees that can incite participants to respect physical limits. The protocol is based on a double-auction mechanism adapted from prior work to enable more efficient application of our privacy-preserving approach. To protect participants' data, we use secure multiparty computation. In addition, Schnorr's identification protocol is employed with multiparty verification to ensure authenticated participation without compromising privacy. We further optimise the protocol to reduce communication and round complexity. We prove that the protocol meets its security requirements and show through experimentation its feasibility at a typical LEM scale: a market with 5,000 participants can be cleared in 4.17 minutes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4fdd\u62a4\u9690\u79c1\u7684\u672c\u5730\u80fd\u6e90\u5e02\u573a\u534f\u8bae\uff0c\u8be5\u534f\u8bae\u7ed3\u5408\u4e86\u7535\u7f51\u8d39\u7528\u8003\u8651\uff0c\u4f7f\u7528\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u548cSchnorr\u8eab\u4efd\u9a8c\u8bc1\u534f\u8bae\uff0c\u5728\u4fdd\u62a4\u53c2\u4e0e\u8005\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u786e\u4fdd\u7535\u7f51\u7269\u7406\u7ea6\u675f\u3002", "motivation": "\u672c\u5730\u80fd\u6e90\u5e02\u573a\u6d89\u53ca\u5904\u7406\u654f\u611f\u7684\u53c2\u4e0e\u8005\u6570\u636e\uff0c\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff0c\u540c\u65f6\u7535\u529b\u4ea4\u6362\u9700\u8981\u8003\u8651\u7535\u7f51\u7269\u7406\u7ea6\u675f\u548c\u76f8\u5173\u6210\u672c\u3002\u73b0\u6709\u5de5\u4f5c\u901a\u5e38\u5355\u72ec\u5904\u7406\u8fd9\u4e9b\u95ee\u9898\uff0c\u8981\u4e48\u5173\u6ce8\u7535\u7f51\u65b9\u9762\uff0c\u8981\u4e48\u63d0\u4f9b\u9690\u79c1\u4fdd\u62a4\uff0c\u7f3a\u4e4f\u7efc\u5408\u8003\u8651\u3002", "method": "\u57fa\u4e8e\u53cc\u62cd\u5356\u673a\u5236\uff0c\u91c7\u7528\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u4fdd\u62a4\u53c2\u4e0e\u8005\u6570\u636e\u9690\u79c1\uff0c\u4f7f\u7528Schnorr\u8eab\u4efd\u9a8c\u8bc1\u534f\u8bae\u8fdb\u884c\u591a\u65b9\u9a8c\u8bc1\u786e\u4fdd\u8ba4\u8bc1\u53c2\u4e0e\u800c\u4e0d\u6cc4\u9732\u9690\u79c1\uff0c\u5e76\u5bf9\u534f\u8bae\u8fdb\u884c\u4f18\u5316\u4ee5\u51cf\u5c11\u901a\u4fe1\u548c\u8f6e\u6b21\u590d\u6742\u5ea6\u3002", "result": "\u534f\u8bae\u6ee1\u8db3\u5b89\u5168\u8981\u6c42\uff0c\u5b9e\u9a8c\u8868\u660e\u5728\u5178\u578b\u672c\u5730\u80fd\u6e90\u5e02\u573a\u89c4\u6a21\u4e0b\u5177\u6709\u53ef\u884c\u6027\uff1a\u4e00\u4e2a\u62e5\u67095,000\u540d\u53c2\u4e0e\u8005\u7684\u5e02\u573a\u53ef\u4ee5\u57284.17\u5206\u949f\u5185\u5b8c\u6210\u6e05\u7b97\u3002", "conclusion": "\u63d0\u51fa\u7684\u9690\u79c1\u4fdd\u62a4\u534f\u8bae\u6210\u529f\u89e3\u51b3\u4e86\u672c\u5730\u80fd\u6e90\u5e02\u573a\u4e2d\u9690\u79c1\u4fdd\u62a4\u548c\u7535\u7f51\u7ea6\u675f\u7684\u53cc\u91cd\u6311\u6218\uff0c\u4e3a\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u80fd\u6e90\u4ea4\u6613\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u65b9\u6848\u3002"}}
{"id": "2602.23701", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.23701", "abs": "https://arxiv.org/abs/2602.23701", "authors": ["Yawen Wang", "Wenjie Wu", "Junjie Wang", "Qing Wang"], "title": "From Flat Logs to Causal Graphs: Hierarchical Failure Attribution for LLM-based Multi-Agent Systems", "comment": null, "summary": "LLM-powered Multi-Agent Systems (MAS) have demonstrated remarkable capabilities in complex domains but suffer from inherent fragility and opaque failure mechanisms. Existing failure attribution methods, whether relying on direct prompting, costly replays, or supervised fine-tuning, typically treat execution logs as flat sequences. This linear perspective fails to disentangle the intricate causal links inherent to MAS, leading to weak observability and ambiguous responsibility boundaries. To address these challenges, we propose CHIEF, a novel framework that transforms chaotic trajectories into a structured hierarchical causal graph. It then employs hierarchical oracle-guided backtracking to efficiently prune the search space via sybthesized virtual oracles. Finally, it implements counterfactual attribution via a progressive causal screening strategy to rigorously distinguish true root causes from propagated symptoms. Experiments on Who&When benchmark show that CHIEF outperforms eight strong and state-of-the-art baselines on both agent- and step-level accuracy. Ablation studies further confirm the critical role of each proposed module.", "AI": {"tldr": "CHIEF\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6df7\u6c8c\u8f68\u8ff9\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u5c42\u6b21\u56e0\u679c\u56fe\uff0c\u5e76\u91c7\u7528\u5c42\u6b21\u5316\u56de\u6eaf\u548c\u53cd\u4e8b\u5b9e\u5f52\u56e0\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6545\u969c\u5f52\u56e0\u7684\u51c6\u786e\u6027\u3002", "motivation": "LLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u590d\u6742\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b58\u5728\u56fa\u6709\u7684\u8106\u5f31\u6027\u548c\u4e0d\u900f\u660e\u7684\u6545\u969c\u673a\u5236\u3002\u73b0\u6709\u7684\u6545\u969c\u5f52\u56e0\u65b9\u6cd5\u901a\u5e38\u5c06\u6267\u884c\u65e5\u5fd7\u89c6\u4e3a\u6241\u5e73\u5e8f\u5217\uff0c\u8fd9\u79cd\u7ebf\u6027\u89c6\u89d2\u65e0\u6cd5\u89e3\u8026MAS\u4e2d\u590d\u6742\u7684\u56e0\u679c\u8054\u7cfb\uff0c\u5bfc\u81f4\u53ef\u89c2\u6d4b\u6027\u5f31\u548c\u8d23\u4efb\u8fb9\u754c\u6a21\u7cca\u3002", "method": "CHIEF\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a1) \u5c06\u6df7\u6c8c\u8f68\u8ff9\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u5c42\u6b21\u56e0\u679c\u56fe\uff1b2) \u91c7\u7528\u5c42\u6b21\u5316oracle\u5f15\u5bfc\u7684\u56de\u6eaf\uff0c\u901a\u8fc7\u5408\u6210\u865a\u62dforacle\u9ad8\u6548\u526a\u679d\u641c\u7d22\u7a7a\u95f4\uff1b3) \u5b9e\u65bd\u6e10\u8fdb\u56e0\u679c\u7b5b\u9009\u7b56\u7565\u8fdb\u884c\u53cd\u4e8b\u5b9e\u5f52\u56e0\uff0c\u4e25\u683c\u533a\u5206\u771f\u6b63\u7684\u6839\u672c\u539f\u56e0\u548c\u4f20\u64ad\u7684\u75c7\u72b6\u3002", "result": "\u5728Who&When\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCHIEF\u5728\u667a\u80fd\u4f53\u7ea7\u548c\u6b65\u9aa4\u7ea7\u51c6\u786e\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u516b\u4e2a\u5f3a\u5927\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86\u6bcf\u4e2a\u63d0\u51fa\u6a21\u5757\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "CHIEF\u901a\u8fc7\u7ed3\u6784\u5316\u5c42\u6b21\u56e0\u679c\u8868\u793a\u548c\u7cfb\u7edf\u5316\u5f52\u56e0\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6545\u969c\u8bca\u65ad\u80fd\u529b\uff0c\u4e3a\u89e3\u51b3MAS\u7684\u8106\u5f31\u6027\u548c\u4e0d\u900f\u660e\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23760", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.23760", "abs": "https://arxiv.org/abs/2602.23760", "authors": ["Jie Li", "Jing Li", "Lu Lv", "Zhanyu Ju", "Fengkui Gong"], "title": "PLA for Drone RID Frames via Motion Estimation and Consistency Verification", "comment": null, "summary": "Drone Remote Identification (RID) plays a critical role in low-altitude airspace supervision, yet its broadcast nature and lack of cryptographic protection make it vulnerable to spoofing and replay attacks. In this paper, we propose a consistency verification-based physical-layer authentication (PLA) algorithm for drone RID frames. A RID-aware sensing and decoding module is first developed to extract communication-derived sensing parameters, including angle-of-arrival, Doppler shift, average channel gain, and the number of transmit antennas, together with the identity and motion-related information decoded from previously authenticated RID frames. Rather than fusing all heterogeneous information into a single representation, different types of information are selectively utilized according to their physical relevance and reliability. Specifically, real-time wireless sensing parameter constraints and previously authenticated motion states are incorporated in a yaw-augmented constant-acceleration extended Kalman filter (CA-EKF) to estimate the three-dimensional position and motion states of the drone. To further enhance authentication reliability under highly maneuverable and non-stationary flight scenarios, a data-driven long short-term memory-based motion estimator is employed, and its predictions are adaptively combined with the CA-EKF via an error-aware fusion strategy. Finally, RID frames are authenticated by verifying consistency in the number of transmit antennas, motion estimates, and no-fly-zone constraints. Simulation results demonstrate that the proposed algorithm significantly improves authentication reliability and robustness under realistic wireless impairments and complex drone maneuvers, outperforming existing RF feature-based and motion model-based PLA schemes.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e00\u81f4\u6027\u9a8c\u8bc1\u7684\u7269\u7406\u5c42\u8ba4\u8bc1\u7b97\u6cd5\uff0c\u901a\u8fc7\u878d\u5408\u65e0\u7ebf\u611f\u77e5\u53c2\u6570\u548c\u8fd0\u52a8\u72b6\u6001\u4fe1\u606f\u6765\u589e\u5f3a\u65e0\u4eba\u673a\u8fdc\u7a0b\u8bc6\u522b\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002", "motivation": "\u65e0\u4eba\u673a\u8fdc\u7a0b\u8bc6\u522b(RID)\u7cfb\u7edf\u7684\u5e7f\u64ad\u7279\u6027\u548c\u7f3a\u4e4f\u5bc6\u7801\u4fdd\u62a4\u4f7f\u5176\u5bb9\u6613\u53d7\u5230\u6b3a\u9a97\u548c\u91cd\u653e\u653b\u51fb\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u8eab\u4efd\u9a8c\u8bc1\u673a\u5236\u3002", "method": "\u5f00\u53d1RID\u611f\u77e5\u7684\u89e3\u7801\u6a21\u5757\u63d0\u53d6\u611f\u77e5\u53c2\u6570\uff0c\u7ed3\u5408\u504f\u822a\u589e\u5f3a\u7684\u6052\u5b9a\u52a0\u901f\u5ea6\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u548cLSTM\u8fd0\u52a8\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u8bef\u5dee\u611f\u77e5\u878d\u5408\u7b56\u7565\u8fdb\u884c\u4e00\u81f4\u6027\u9a8c\u8bc1\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u5728\u771f\u5b9e\u65e0\u7ebf\u635f\u4f24\u548c\u590d\u6742\u65e0\u4eba\u673a\u673a\u52a8\u6761\u4ef6\u4e0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba4\u8bc1\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u7684RF\u7279\u5f81\u548c\u8fd0\u52a8\u6a21\u578b\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684\u7269\u7406\u5c42\u8ba4\u8bc1\u7b97\u6cd5\u901a\u8fc7\u591a\u6e90\u4fe1\u606f\u878d\u5408\u548c\u4e00\u81f4\u6027\u9a8c\u8bc1\uff0c\u6709\u6548\u589e\u5f3a\u4e86\u65e0\u4eba\u673aRID\u7cfb\u7edf\u7684\u5b89\u5168\u6027\uff0c\u5bf9\u6297\u6b3a\u9a97\u548c\u91cd\u653e\u653b\u51fb\u3002"}}
{"id": "2602.23834", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23834", "abs": "https://arxiv.org/abs/2602.23834", "authors": ["Xuhui Dou", "Hayretdin Bahsi", "Alejandro Guerra-Manzanares"], "title": "Enhancing Continual Learning for Software Vulnerability Prediction: Addressing Catastrophic Forgetting via Hybrid-Confidence-Aware Selective Replay for Temporal LLM Fine-Tuning", "comment": "Accepted for publication in the Proceedings of the 2026 International Conference on Information Systems Security and Privacy (ICISSP)", "summary": "Recent work applies Large Language Models (LLMs) to source-code vulnerability detection, but most evaluations still rely on random train-test splits that ignore time and overestimate real-world performance. In practice, detectors are deployed on evolving code bases and must recognise future vulnerabilities under temporal distribution shift. This paper investigates continual fine-tuning of a decoder-style language model (microsoft/phi-2 with LoRA) on a CVE-linked dataset spanning 2018-2024, organised into bi-monthly windows. We evaluate eight continual learning strategies, including window-only and cumulative training, replay-based baselines and regularisation-based variants. We propose Hybrid Class-Aware Selective Replay (Hybrid-CASR), a confidence-aware replay method for binary vulnerability classification that prioritises uncertain samples while maintaining a balanced ratio of VULNERABLE and FIXED functions in the replay buffer. On bi-monthly forward evaluation Hybrid-CASR achieves a Macro-F1 of 0.667, improving on the window-only baseline (0.651) by 0.016 with statistically significant gains ($p = 0.026$) and stronger backward retention (IBR@1 of 0.741). Hybrid-CASR also reduces training time per window by about 17 percent compared to the baseline, whereas cumulative training delivers only a minor F1 increase (0.661) at a 15.9-fold computational cost. Overall, the results show that selective replay with class balancing offers a practical accuracy-efficiency trade-off for LLM-based temporal vulnerability detection under continuous temporal drift.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51faHybrid-CASR\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u611f\u77e5\u7684\u91cd\u653e\u548c\u7c7b\u522b\u5e73\u8861\u7b56\u7565\uff0c\u5728\u6301\u7eed\u5b66\u4e60\u6846\u67b6\u4e0b\u63d0\u5347LLM\u5bf9\u6e90\u4ee3\u7801\u6f0f\u6d1e\u7684\u65f6\u5e8f\u68c0\u6d4b\u6027\u80fd\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5728\u51c6\u786e\u7387\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u53d6\u5f97\u66f4\u597d\u5e73\u8861\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6e90\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u7814\u7a76\u5927\u591a\u91c7\u7528\u968f\u673a\u5212\u5206\u7684\u8bad\u7ec3\u6d4b\u8bd5\u96c6\uff0c\u5ffd\u7565\u4e86\u65f6\u95f4\u56e0\u7d20\uff0c\u9ad8\u4f30\u4e86\u5b9e\u9645\u6027\u80fd\u3002\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\uff0c\u68c0\u6d4b\u5668\u9700\u8981\u5728\u4e0d\u65ad\u6f14\u5316\u7684\u4ee3\u7801\u5e93\u4e0a\u5de5\u4f5c\uff0c\u9762\u4e34\u65f6\u5e8f\u5206\u5e03\u504f\u79fb\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eCVE\u76842018-2024\u6570\u636e\u96c6\uff0c\u6309\u53cc\u6708\u7a97\u53e3\u7ec4\u7ec7\u3002\u91c7\u7528phi-2\u6a21\u578b\u914d\u5408LoRA\u8fdb\u884c\u6301\u7eed\u5fae\u8c03\uff0c\u8bc4\u4f30\u4e868\u79cd\u6301\u7eed\u5b66\u4e60\u7b56\u7565\u3002\u63d0\u51fa\u4e86Hybrid-CASR\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u7f6e\u4fe1\u5ea6\u611f\u77e5\u7684\u91cd\u653e\u65b9\u6cd5\uff0c\u4f18\u5148\u9009\u62e9\u4e0d\u786e\u5b9a\u6837\u672c\uff0c\u540c\u65f6\u5728\u91cd\u653e\u7f13\u51b2\u533a\u4e2d\u4fdd\u6301\u6f0f\u6d1e\u51fd\u6570\u548c\u4fee\u590d\u51fd\u6570\u7684\u5e73\u8861\u6bd4\u4f8b\u3002", "result": "\u5728\u53cc\u6708\u524d\u5411\u8bc4\u4f30\u4e2d\uff0cHybrid-CASR\u8fbe\u5230Macro-F1\u4e3a0.667\uff0c\u76f8\u6bd4\u4ec5\u7a97\u53e3\u8bad\u7ec3\u57fa\u7ebf\uff080.651\uff09\u63d0\u53470.016\uff0c\u5177\u6709\u7edf\u8ba1\u663e\u8457\u6027\uff08p=0.026\uff09\u3002\u540c\u65f6\u540e\u5411\u4fdd\u7559\u80fd\u529b\u66f4\u5f3a\uff08IBR@1\u4e3a0.741\uff09\uff0c\u6bcf\u4e2a\u7a97\u53e3\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u7ea617%\u3002\u7d2f\u79ef\u8bad\u7ec3\u4ec5\u5e26\u6765\u5fae\u5c0fF1\u63d0\u5347\uff080.661\uff09\u4f46\u8ba1\u7b97\u6210\u672c\u589e\u52a015.9\u500d\u3002", "conclusion": "\u5e26\u6709\u7c7b\u522b\u5e73\u8861\u7684\u9009\u62e9\u6027\u91cd\u653e\u7b56\u7565\u4e3a\u57fa\u4e8eLLM\u7684\u65f6\u5e8f\u6f0f\u6d1e\u68c0\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u51c6\u786e\u7387-\u6548\u7387\u6743\u8861\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u6301\u7eed\u7684\u65f6\u95f4\u6f02\u79fb\u95ee\u9898\u3002"}}
{"id": "2602.23730", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23730", "abs": "https://arxiv.org/abs/2602.23730", "authors": ["Longyin Zhang", "Shuo Sun", "Yingxu He", "Won Cheng Yi Lewis", "Muhammad Huzaifah Bin Md Shahrin", "Hardik Bhupendra Sailor", "Heng Meng Jeremy Wong", "Tarun Kumar Vangani", "Yi Ma", "Qiongqiong Wang", "Minh Duc Pham", "Ridong Jiang", "Jingtao Li", "Jingyi Liao", "Zhuohan Liu", "Yanfeng Lu", "Manas Gupta", "Ai Ti Aw"], "title": "Unlocking Cognitive Capabilities and Analyzing the Perception-Logic Trade-off", "comment": null, "summary": "Recent advancements in Multimodal Large Language Models (MLLMs) pursue omni-perception capabilities, yet integrating robust sensory grounding with complex reasoning remains a challenge, particularly for underrepresented regions. In this report, we introduce the research preview of MERaLiON2-Omni (Alpha), a 10B-parameter multilingual omni-perception tailored for Southeast Asia (SEA). We present a progressive training pipeline that explicitly decouples and then integrates \"System 1\" (Perception) and \"System 2\" (Reasoning) capabilities. First, we establish a robust Perception Backbone by aligning region-specific audio-visual cues (e.g., Singlish code-switching, local cultural landmarks) with a multilingual LLM through orthogonal modality adaptation. Second, to inject cognitive capabilities without large-scale supervision, we propose a cost-effective Generate-Judge-Refine pipeline. By utilizing a Super-LLM to filter hallucinations and resolve conflicts via a consensus mechanism, we synthesize high-quality silver data that transfers textual Chain-of-Thought reasoning to multimodal scenarios.\n  Comprehensive evaluation on our newly introduced SEA-Omni Benchmark Suite reveals an Efficiency-Stability Paradox: while reasoning acts as a non-linear amplifier for abstract tasks (boosting mathematical and instruction-following performance significantly), it introduces instability in low-level sensory processing. Specifically, we identify Temporal Drift in long-context audio, where extended reasoning desynchronizes the model from acoustic timestamps, and Visual Over-interpretation, where logic overrides pixel-level reality. This report details the architecture, the data-efficient training recipe, and a diagnostic analysis of the trade-offs between robust perception and structured reasoning.", "AI": {"tldr": "MERaLiON2-Omni (Alpha) \u662f\u4e00\u4e2a\u9488\u5bf9\u4e1c\u5357\u4e9a\u5730\u533a\u768410B\u53c2\u6570\u591a\u8bed\u8a00\u5168\u611f\u77e5\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u79bb\u548c\u6574\u5408\"\u7cfb\u7edf1\"\uff08\u611f\u77e5\uff09\u4e0e\"\u7cfb\u7edf2\"\uff08\u63a8\u7406\uff09\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u611f\u77e5\u4e0e\u63a8\u7406\u7ed3\u5408\u7684\u6311\u6218\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8ffd\u6c42\u5168\u611f\u77e5\u80fd\u529b\uff0c\u4f46\u5c06\u7a33\u5065\u7684\u611f\u5b98\u57fa\u7840\u4e0e\u590d\u6742\u63a8\u7406\u76f8\u7ed3\u5408\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u7279\u522b\u662f\u5728\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u5730\u533a\uff08\u5982\u4e1c\u5357\u4e9a\uff09\u3002\u9700\u8981\u89e3\u51b3\u533a\u57df\u7279\u5b9a\u7684\u89c6\u542c\u7ebf\u7d22\uff08\u5982\u65b0\u52a0\u5761\u5f0f\u82f1\u8bed\u8bed\u7801\u8f6c\u6362\u3001\u5f53\u5730\u6587\u5316\u5730\u6807\uff09\u4e0e\u591a\u8bed\u8a00LLM\u7684\u6574\u5408\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u6d41\u7a0b\uff1a1) \u901a\u8fc7\u6b63\u4ea4\u6a21\u6001\u9002\u5e94\u5efa\u7acb\u7a33\u5065\u7684\u611f\u77e5\u9aa8\u5e72\uff0c\u5c06\u533a\u57df\u7279\u5b9a\u7684\u89c6\u542c\u7ebf\u7d22\u4e0e\u591a\u8bed\u8a00LLM\u5bf9\u9f50\uff1b2) \u63d0\u51fa\u6210\u672c\u6548\u76ca\u9ad8\u7684\u751f\u6210-\u5224\u65ad-\u7cbe\u70bc\u6d41\u7a0b\uff0c\u5229\u7528\u8d85\u7ea7LLM\u8fc7\u6ee4\u5e7b\u89c9\u5e76\u901a\u8fc7\u5171\u8bc6\u673a\u5236\u89e3\u51b3\u51b2\u7a81\uff0c\u5408\u6210\u9ad8\u8d28\u91cf\u94f6\u6570\u636e\uff0c\u5c06\u6587\u672c\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u8f6c\u79fb\u5230\u591a\u6a21\u6001\u573a\u666f\u3002", "result": "\u5728\u65b0\u5f15\u5165\u7684SEA-Omni\u57fa\u51c6\u5957\u4ef6\u4e0a\u7684\u8bc4\u4f30\u63ed\u793a\u4e86\u6548\u7387-\u7a33\u5b9a\u6027\u6096\u8bba\uff1a\u63a8\u7406\u4f5c\u4e3a\u62bd\u8c61\u4efb\u52a1\u7684\u975e\u7ebf\u6027\u653e\u5927\u5668\uff08\u663e\u8457\u63d0\u5347\u6570\u5b66\u548c\u6307\u4ee4\u8ddf\u968f\u6027\u80fd\uff09\uff0c\u4f46\u5728\u4f4e\u7ea7\u611f\u5b98\u5904\u7406\u4e2d\u5f15\u5165\u4e0d\u7a33\u5b9a\u6027\uff0c\u5177\u4f53\u8868\u73b0\u4e3a\u957f\u4e0a\u4e0b\u6587\u97f3\u9891\u4e2d\u7684\u65f6\u95f4\u6f02\u79fb\u548c\u89c6\u89c9\u8fc7\u5ea6\u89e3\u91ca\u95ee\u9898\u3002", "conclusion": "\u8be5\u7814\u7a76\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u67b6\u6784\u3001\u6570\u636e\u9ad8\u6548\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5bf9\u7a33\u5065\u611f\u77e5\u4e0e\u7ed3\u6784\u5316\u63a8\u7406\u4e4b\u95f4\u6743\u8861\u7684\u8bca\u65ad\u5206\u6790\uff0c\u4e3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533a\u57df\u7279\u5b9a\u5e94\u7528\u4e2d\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2602.23777", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23777", "abs": "https://arxiv.org/abs/2602.23777", "authors": ["Zhipeng Xu", "Zilong Wang", "Xinyang Jiang", "Dongsheng Li", "De Cheng", "Nannan Wang"], "title": "Reasoning-Driven Multimodal LLM for Domain Generalization", "comment": "Accepted at ICLR 2026 (Poster)", "summary": "This paper addresses the domain generalization (DG) problem in deep learning. While most DG methods focus on enforcing visual feature invariance, we leverage the reasoning capability of multimodal large language models (MLLMs) and explore the potential of constructing reasoning chains that derives image categories to achieve more robust predictions under domain shift. To this end, we systematically study the role of reasoning in DG using DomainBed-Reasoning, a newly constructed extension of DomainBed dataset, in which each sample is paired with class-relevant reasoning chains. Our analysis reveals two key challenges: (i) fine-tuning MLLMs with reasoning chains for classification is more challenging than direct label supervision, since the model must optimize complex reasoning sequences before label prediction; and (ii) mismatches in reasoning patterns between supervision signals and fine-tuned MLLMs lead to a trade-off between semantic richness (informative but harder to optimize) and optimization efficiency (easier to optimize but less informative). To address these issues, we propose RD-MLDG (Reasoning-Driven Multimodal LLM for Domain Generalization), a framework with two components: (i) MTCT (Multi-Task Cross-Training), which introduces an additional direct classification pathway to guide reasoning supervision; and (ii) SARR (Self-Aligned Reasoning Regularization), which preserves the semantic richness of reasoning chains while mitigating reasoning-pattern mismatches via iterative self-labeling. Experiments on standard DomainBed datasets (PACS, VLCS, OfficeHome, TerraInc) demonstrate that RD-MLDG achieves state-of-the-art performances, highlighting reasoning as a promising complementary signal for robust out-of-domain generalization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRD-MLDG\u6846\u67b6\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u89e3\u51b3\u9886\u57df\u6cdb\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u63a8\u7406\u94fe\u6784\u5efa\u5b9e\u73b0\u66f4\u9c81\u68d2\u7684\u57df\u5916\u9884\u6d4b\u3002", "motivation": "\u5927\u591a\u6570\u9886\u57df\u6cdb\u5316\u65b9\u6cd5\u5173\u6ce8\u89c6\u89c9\u7279\u5f81\u4e0d\u53d8\u6027\uff0c\u672c\u6587\u63a2\u7d22\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u6784\u5efa\u63a8\u7406\u94fe\u6765\u83b7\u5f97\u66f4\u9c81\u68d2\u7684\u57df\u5916\u9884\u6d4b\u6027\u80fd\u3002", "method": "\u63d0\u51faRD-MLDG\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1a1) MTCT\uff08\u591a\u4efb\u52a1\u4ea4\u53c9\u8bad\u7ec3\uff09\uff0c\u5f15\u5165\u76f4\u63a5\u5206\u7c7b\u8def\u5f84\u6307\u5bfc\u63a8\u7406\u76d1\u7763\uff1b2) SARR\uff08\u81ea\u5bf9\u9f50\u63a8\u7406\u6b63\u5219\u5316\uff09\uff0c\u901a\u8fc7\u8fed\u4ee3\u81ea\u6807\u6ce8\u4fdd\u6301\u63a8\u7406\u94fe\u7684\u8bed\u4e49\u4e30\u5bcc\u6027\u5e76\u7f13\u89e3\u63a8\u7406\u6a21\u5f0f\u4e0d\u5339\u914d\u95ee\u9898\u3002", "result": "\u5728\u6807\u51c6DomainBed\u6570\u636e\u96c6\uff08PACS\u3001VLCS\u3001OfficeHome\u3001TerraInc\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRD-MLDG\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u63a8\u7406\u80fd\u529b\u662f\u63d0\u5347\u9886\u57df\u6cdb\u5316\u6027\u80fd\u7684\u6709\u524d\u666f\u7684\u8865\u5145\u4fe1\u53f7\uff0cRD-MLDG\u6846\u67b6\u901a\u8fc7\u6709\u6548\u5229\u7528\u63a8\u7406\u94fe\u5b9e\u73b0\u4e86\u66f4\u9c81\u68d2\u7684\u57df\u5916\u6cdb\u5316\u3002"}}
{"id": "2602.23802", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.23802", "abs": "https://arxiv.org/abs/2602.23802", "authors": ["Yiyang Fang", "Wenke Huang", "Pei Fu", "Yihao Yang", "Kehua Su", "Zhenbo Luo", "Jian Luan", "Mang Ye"], "title": "EMO-R3: Reflective Reinforcement Learning for Emotional Reasoning in Multimodal Large Language Models", "comment": "Accepted by CVPR 2026", "summary": "Multimodal Large Language Models (MLLMs) have shown remarkable progress in visual reasoning and understanding tasks but still struggle to capture the complexity and subjectivity of human emotions. Existing approaches based on supervised fine-tuning often suffer from limited generalization and poor interpretability, while reinforcement learning methods such as Group Relative Policy Optimization fail to align with the intrinsic characteristics of emotional cognition. To address these challenges, we propose Reflective Reinforcement Learning for Emotional Reasoning (EMO-R3), a framework designed to enhance the emotional reasoning ability of MLLMs. Specifically, we introduce Structured Emotional Thinking to guide the model to perform step-by-step emotional reasoning in a structured and interpretable manner, and design a Reflective Emotional Reward that enables the model to re-evaluate its reasoning based on visual-text consistency and emotional coherence. Extensive experiments demonstrate that EMO-R3 significantly improves both the interpretability and emotional intelligence of MLLMs, achieving superior performance across multiple visual emotional understanding benchmarks.", "AI": {"tldr": "EMO-R3\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u60c5\u611f\u601d\u7ef4\u548c\u53cd\u601d\u6027\u60c5\u611f\u5956\u52b1\uff0c\u589e\u5f3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u611f\u63a8\u7406\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u89e3\u91ca\u6027\u548c\u60c5\u611f\u667a\u80fd\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u6355\u6349\u4eba\u7c7b\u60c5\u611f\u7684\u590d\u6742\u6027\u548c\u4e3b\u89c2\u6027\u65b9\u9762\u4ecd\u5b58\u5728\u56f0\u96be\u3002\u73b0\u6709\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u6cdb\u5316\u80fd\u529b\u6709\u9650\u4e14\u89e3\u91ca\u6027\u5dee\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5982GRPO\u672a\u80fd\u4e0e\u60c5\u611f\u8ba4\u77e5\u7684\u5185\u5728\u7279\u6027\u5bf9\u9f50\u3002", "method": "\u63d0\u51faEMO-R3\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u7ed3\u6784\u5316\u60c5\u611f\u601d\u7ef4\uff0c\u5f15\u5bfc\u6a21\u578b\u4ee5\u7ed3\u6784\u5316\u3001\u53ef\u89e3\u91ca\u7684\u65b9\u5f0f\u8fdb\u884c\u9010\u6b65\u60c5\u611f\u63a8\u7406\uff1b2) \u53cd\u601d\u6027\u60c5\u611f\u5956\u52b1\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u57fa\u4e8e\u89c6\u89c9-\u6587\u672c\u4e00\u81f4\u6027\u548c\u60c5\u611f\u8fde\u8d2f\u6027\u91cd\u65b0\u8bc4\u4f30\u5176\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cEMO-R3\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u91ca\u6027\u548c\u60c5\u611f\u667a\u80fd\uff0c\u5728\u591a\u4e2a\u89c6\u89c9\u60c5\u611f\u7406\u89e3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "EMO-R3\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u601d\u7ef4\u548c\u53cd\u601d\u6027\u5956\u52b1\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u60c5\u611f\u7406\u89e3\u548c\u89e3\u91ca\u80fd\u529b\u3002"}}
{"id": "2602.24009", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24009", "abs": "https://arxiv.org/abs/2602.24009", "authors": ["Zhicheng Fang", "Jingjie Zheng", "Chenxu Fu", "Wei Xu"], "title": "Jailbreak Foundry: From Papers to Runnable Attacks for Reproducible Benchmarking", "comment": null, "summary": "Jailbreak techniques for large language models (LLMs) evolve faster than benchmarks, making robustness estimates stale and difficult to compare across papers due to drift in datasets, harnesses, and judging protocols. We introduce JAILBREAK FOUNDRY (JBF), a system that addresses this gap via a multi-agent workflow to translate jailbreak papers into executable modules for immediate evaluation within a unified harness. JBF features three core components: (i) JBF-LIB for shared contracts and reusable utilities; (ii) JBF-FORGE for the multi-agent paper-to-module translation; and (iii) JBF-EVAL for standardizing evaluations. Across 30 reproduced attacks, JBF achieves high fidelity with a mean (reproduced-reported) attack success rate (ASR) deviation of +0.26 percentage points. By leveraging shared infrastructure, JBF reduces attack-specific implementation code by nearly half relative to original repositories and achieves an 82.5% mean reused-code ratio. This system enables a standardized AdvBench evaluation of all 30 attacks across 10 victim models using a consistent GPT-4o judge. By automating both attack integration and standardized evaluation, JBF offers a scalable solution for creating living benchmarks that keep pace with the rapidly shifting security landscape.", "AI": {"tldr": "JAILBREAK FOUNDRY (JBF) \u662f\u4e00\u4e2a\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u72f1\u6280\u672f\u8bc4\u4f30\u6807\u51c6\u5316\u95ee\u9898\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u5c06\u8d8a\u72f1\u8bba\u6587\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u6a21\u5757\uff0c\u5b9e\u73b0\u7edf\u4e00\u6846\u67b6\u4e0b\u7684\u5373\u65f6\u8bc4\u4f30\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8d8a\u72f1\u6280\u672f\u53d1\u5c55\u901f\u5ea6\u5feb\u4e8e\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5bfc\u81f4\u9c81\u68d2\u6027\u8bc4\u4f30\u8fc7\u65f6\u4e14\u96be\u4ee5\u8de8\u8bba\u6587\u6bd4\u8f83\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u6570\u636e\u96c6\u3001\u6d4b\u8bd5\u6846\u67b6\u548c\u8bc4\u5224\u534f\u8bae\u5b58\u5728\u6f02\u79fb\u95ee\u9898\u3002", "method": "JBF\u7cfb\u7edf\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1aJBF-LIB\uff08\u5171\u4eab\u5408\u7ea6\u548c\u53ef\u590d\u7528\u5de5\u5177\uff09\u3001JBF-FORGE\uff08\u591a\u667a\u80fd\u4f53\u8bba\u6587\u5230\u6a21\u5757\u8f6c\u6362\uff09\u3001JBF-EVAL\uff08\u6807\u51c6\u5316\u8bc4\u4f30\uff09\u3002\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u5c06\u8d8a\u72f1\u8bba\u6587\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u6a21\u5757\u3002", "result": "\u572830\u4e2a\u590d\u73b0\u7684\u653b\u51fb\u4e2d\uff0cJBF\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u5ea6\uff0c\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\u504f\u5dee\u4ec5\u4e3a+0.26\u4e2a\u767e\u5206\u70b9\u3002\u901a\u8fc7\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\uff0cJBF\u5c06\u653b\u51fb\u7279\u5b9a\u5b9e\u73b0\u4ee3\u7801\u51cf\u5c11\u4e86\u8fd1\u4e00\u534a\uff0c\u5e73\u5747\u4ee3\u7801\u590d\u7528\u7387\u8fbe\u523082.5%\u3002", "conclusion": "JBF\u901a\u8fc7\u81ea\u52a8\u5316\u653b\u51fb\u96c6\u6210\u548c\u6807\u51c6\u5316\u8bc4\u4f30\uff0c\u4e3a\u521b\u5efa\u80fd\u591f\u8ddf\u4e0a\u5feb\u901f\u53d8\u5316\u5b89\u5168\u683c\u5c40\u7684\u6d3b\u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23974", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23974", "abs": "https://arxiv.org/abs/2602.23974", "authors": ["Fan Zhang", "Baoru Huang", "Xin Zhang"], "title": "Pessimistic Auxiliary Policy for Offline Reinforcement Learning", "comment": null, "summary": "Offline reinforcement learning aims to learn an agent from pre-collected datasets, avoiding unsafe and inefficient real-time interaction. However, inevitable access to out-ofdistribution actions during the learning process introduces approximation errors, causing the error accumulation and considerable overestimation. In this paper, we construct a new pessimistic auxiliary policy for sampling reliable actions. Specifically, we develop a pessimistic auxiliary strategy by maximizing the lower confidence bound of the Q-function. The pessimistic auxiliary strategy exhibits a relatively high value and low uncertainty in the vicinity of the learned policy, avoiding the learned policy sampling high-value actions with potentially high errors during the learning process. Less approximation error introduced by sampled action from pessimistic auxiliary strategy leads to the alleviation of error accumulation. Extensive experiments on offline reinforcement learning benchmarks reveal that utilizing the pessimistic auxiliary strategy can effectively improve the efficacy of other offline RL approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u60b2\u89c2\u8f85\u52a9\u7b56\u7565\uff0c\u901a\u8fc7\u6700\u5927\u5316Q\u51fd\u6570\u7684\u4e0b\u7f6e\u4fe1\u754c\u6765\u91c7\u6837\u53ef\u9760\u52a8\u4f5c\uff0c\u7f13\u89e3\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8bef\u5dee\u7d2f\u79ef\u548c\u8fc7\u9ad8\u4f30\u8ba1\u95ee\u9898\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4ece\u9884\u6536\u96c6\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\uff0c\u907f\u514d\u5b9e\u65f6\u4ea4\u4e92\u7684\u98ce\u9669\u548c\u4f4e\u6548\u3002\u4f46\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u4e0d\u53ef\u907f\u514d\u5730\u8bbf\u95ee\u5206\u5e03\u5916\u52a8\u4f5c\u4f1a\u5f15\u5165\u8fd1\u4f3c\u8bef\u5dee\uff0c\u5bfc\u81f4\u8bef\u5dee\u7d2f\u79ef\u548c\u4e25\u91cd\u7684\u8fc7\u9ad8\u4f30\u8ba1\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u60b2\u89c2\u8f85\u52a9\u7b56\u7565\uff0c\u901a\u8fc7\u6700\u5927\u5316Q\u51fd\u6570\u7684\u4e0b\u7f6e\u4fe1\u754c\u6765\u91c7\u6837\u53ef\u9760\u52a8\u4f5c\u3002\u8be5\u7b56\u7565\u5728\u5b66\u4e60\u7b56\u7565\u9644\u8fd1\u8868\u73b0\u51fa\u76f8\u5bf9\u8f83\u9ad8\u7684\u4ef7\u503c\u548c\u8f83\u4f4e\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u907f\u514d\u5b66\u4e60\u8fc7\u7a0b\u91c7\u6837\u5177\u6709\u6f5c\u5728\u9ad8\u8bef\u5dee\u7684\u9ad8\u4ef7\u503c\u52a8\u4f5c\u3002", "result": "\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u5229\u7528\u60b2\u89c2\u8f85\u52a9\u7b56\u7565\u80fd\u6709\u6548\u63d0\u9ad8\u5176\u4ed6\u79bb\u7ebfRL\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "\u60b2\u89c2\u8f85\u52a9\u7b56\u7565\u901a\u8fc7\u91c7\u6837\u53ef\u9760\u52a8\u4f5c\u51cf\u5c11\u8fd1\u4f3c\u8bef\u5dee\uff0c\u4ece\u800c\u7f13\u89e3\u8bef\u5dee\u7d2f\u79ef\u95ee\u9898\uff0c\u4e3a\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6539\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2602.24037", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24037", "abs": "https://arxiv.org/abs/2602.24037", "authors": ["Vanya Priscillia Bendatu", "Yao Lu"], "title": "Portfolio Reinforcement Learning with Scenario-Context Rollout", "comment": null, "summary": "Market regime shifts induce distribution shifts that can degrade the performance of portfolio rebalancing policies. We propose macro-conditioned scenario-context rollout (SCR) that generates plausible next-day multivariate return scenarios under stress events. However, doing so faces new challenges, as history will never tell what would have happened differently. As a result, incorporating scenario-based rewards from rollouts introduces a reward--transition mismatch in temporal-difference learning, destabilizing RL critic training.\n  We analyze this inconsistency and show it leads to a mixed evaluation target. Guided by this analysis, we construct a counterfactual next state using the rollout-implied continuations and augment the critic agent's bootstrap target. Doing so stabilizes the learning and provides a viable bias-variance tradeoff.\n  In out-of-sample evaluations across 31 distinct universes of U.S. equity and ETF portfolios, our method improves Sharpe ratio by up to 76% and reduces maximum drawdown by up to 53% compared with classic and RL-based portfolio rebalancing baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8f\u89c2\u6761\u4ef6\u573a\u666f\u4e0a\u4e0b\u6587\u5c55\u5f00\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5e02\u573a\u538b\u529b\u4e8b\u4ef6\u4e0b\u751f\u6210\u5408\u7406\u7684\u6b21\u65e5\u591a\u53d8\u91cf\u6536\u76ca\u573a\u666f\uff0c\u5e76\u901a\u8fc7\u53cd\u4e8b\u5b9e\u72b6\u6001\u6784\u5efa\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5956\u52b1-\u8f6c\u79fb\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6295\u8d44\u7ec4\u5408\u518d\u5e73\u8861\u7b56\u7565\u7684\u8868\u73b0\u3002", "motivation": "\u5e02\u573a\u673a\u5236\u8f6c\u53d8\u4f1a\u5bfc\u81f4\u5206\u5e03\u504f\u79fb\uff0c\u4ece\u800c\u964d\u4f4e\u6295\u8d44\u7ec4\u5408\u518d\u5e73\u8861\u7b56\u7565\u7684\u6027\u80fd\u3002\u5386\u53f2\u6570\u636e\u65e0\u6cd5\u544a\u8bc9\u6211\u4eec\u5982\u679c\u53d1\u751f\u4e0d\u540c\u60c5\u51b5\u4f1a\u600e\u6837\uff0c\u8fd9\u7ed9\u751f\u6210\u5408\u7406\u7684\u538b\u529b\u4e8b\u4ef6\u573a\u666f\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u63d0\u51fa\u5b8f\u89c2\u6761\u4ef6\u573a\u666f\u4e0a\u4e0b\u6587\u5c55\u5f00\u65b9\u6cd5\uff0c\u751f\u6210\u538b\u529b\u4e8b\u4ef6\u4e0b\u7684\u6b21\u65e5\u591a\u53d8\u91cf\u6536\u76ca\u573a\u666f\u3002\u4e3a\u4e86\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u5956\u52b1-\u8f6c\u79fb\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u901a\u8fc7\u5c55\u5f00\u9690\u542b\u7684\u8fde\u7eed\u6027\u6784\u5efa\u53cd\u4e8b\u5b9e\u4e0b\u4e00\u72b6\u6001\uff0c\u5e76\u589e\u5f3a\u8bc4\u8bba\u8005\u667a\u80fd\u4f53\u7684\u5f15\u5bfc\u76ee\u6807\u3002", "result": "\u572831\u4e2a\u4e0d\u540c\u7684\u7f8e\u56fd\u80a1\u7968\u548cETF\u6295\u8d44\u7ec4\u5408\u7684\u6837\u672c\u5916\u8bc4\u4f30\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u7ecf\u5178\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6295\u8d44\u7ec4\u5408\u518d\u5e73\u8861\u57fa\u7ebf\uff0c\u590f\u666e\u6bd4\u7387\u63d0\u5347\u9ad8\u8fbe76%\uff0c\u6700\u5927\u56de\u64a4\u964d\u4f4e\u9ad8\u8fbe53%\u3002", "conclusion": "\u901a\u8fc7\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5956\u52b1-\u8f6c\u79fb\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u7a33\u5b9a\u5b66\u4e60\u8fc7\u7a0b\u5e76\u63d0\u4f9b\u53ef\u884c\u7684\u504f\u5dee-\u65b9\u5dee\u6743\u8861\uff0c\u663e\u8457\u6539\u5584\u6295\u8d44\u7ec4\u5408\u518d\u5e73\u8861\u7b56\u7565\u5728\u538b\u529b\u5e02\u573a\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002"}}
{"id": "2602.24055", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.24055", "abs": "https://arxiv.org/abs/2602.24055", "authors": ["Reva Schwartz", "Carina Westling", "Morgan Briggs", "Marzieh Fadaee", "Isar Nejadgholi", "Matthew Holmes", "Fariza Rashid", "Maya Carlyle", "Afaf Ta\u00efk", "Kyra Wilson", "Peter Douglas", "Theodora Skeadas", "Gabriella Waters", "Rumman Chowdhury", "Thiago Lacerda"], "title": "CIRCLE: A Framework for Evaluating AI from a Real-World Lens", "comment": "Accepted at Intelligent Systems Conference (IntelliSys) 2026", "summary": "This paper proposes CIRCLE, a six-stage, lifecycle-based framework to bridge the reality gap between model-centric performance metrics and AI's materialized outcomes in deployment. While existing frameworks like MLOps focus on system stability and benchmarks measure abstract capabilities, decision-makers outside the AI stack lack systematic evidence about the behavior of AI technologies under real-world user variability and constraints. CIRCLE operationalizes the Validation phase of TEVV (Test, Evaluation, Verification, and Validation) by formalizing the translation of stakeholder concerns outside the stack into measurable signals. Unlike participatory design, which often remains localized, or algorithmic audits, which are often retrospective, CIRCLE provides a structured, prospective protocol for linking context-sensitive qualitative insights to scalable quantitative metrics. By integrating methods such as field testing, red teaming, and longitudinal studies into a coordinated pipeline, CIRCLE produces systematic knowledge: evidence that is comparable across sites yet sensitive to local context. This can enable governance based on materialized downstream effects rather than theoretical capabilities.", "AI": {"tldr": "CIRCLE\u662f\u4e00\u4e2a\u516d\u9636\u6bb5\u751f\u547d\u5468\u671f\u6846\u67b6\uff0c\u65e8\u5728\u5f25\u5408\u6a21\u578b\u4e2d\u5fc3\u6027\u80fd\u6307\u6807\u4e0eAI\u5b9e\u9645\u90e8\u7f72\u6548\u679c\u4e4b\u95f4\u7684\u73b0\u5b9e\u5dee\u8ddd\uff0c\u901a\u8fc7\u5c06\u5229\u76ca\u76f8\u5173\u8005\u5173\u6ce8\u8f6c\u5316\u4e3a\u53ef\u6d4b\u91cf\u4fe1\u53f7\uff0c\u63d0\u4f9b\u7cfb\u7edf\u5316\u7684\u8bc1\u636e\u652f\u6301\u51b3\u7b56\u3002", "motivation": "\u73b0\u6709MLOps\u6846\u67b6\u5173\u6ce8\u7cfb\u7edf\u7a33\u5b9a\u6027\uff0c\u57fa\u51c6\u6d4b\u8bd5\u8861\u91cf\u62bd\u8c61\u80fd\u529b\uff0c\u4f46AI\u6280\u672f\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u9762\u4e34\u771f\u5b9e\u7528\u6237\u53d8\u5f02\u6027\u548c\u7ea6\u675f\uff0c\u51b3\u7b56\u8005\u7f3a\u4e4f\u5173\u4e8eAI\u5728\u73b0\u5b9e\u6761\u4ef6\u4e0b\u884c\u4e3a\u7684\u7cfb\u7edf\u8bc1\u636e\u3002", "method": "CIRCLE\u5c06TEVV\uff08\u6d4b\u8bd5\u3001\u8bc4\u4f30\u3001\u9a8c\u8bc1\u548c\u786e\u8ba4\uff09\u4e2d\u7684\u9a8c\u8bc1\u9636\u6bb5\u64cd\u4f5c\u5316\uff0c\u901a\u8fc7\u516d\u9636\u6bb5\u751f\u547d\u5468\u671f\u6846\u67b6\uff0c\u5c06\u5806\u6808\u5916\u7684\u5229\u76ca\u76f8\u5173\u8005\u5173\u6ce8\u6b63\u5f0f\u8f6c\u5316\u4e3a\u53ef\u6d4b\u91cf\u4fe1\u53f7\u3002\u6574\u5408\u73b0\u573a\u6d4b\u8bd5\u3001\u7ea2\u961f\u6d4b\u8bd5\u548c\u7eb5\u5411\u7814\u7a76\u7b49\u65b9\u6cd5\uff0c\u5f62\u6210\u534f\u8c03\u7684\u7ba1\u9053\u3002", "result": "CIRCLE\u4ea7\u751f\u7cfb\u7edf\u5316\u77e5\u8bc6\uff1a\u8de8\u7ad9\u70b9\u53ef\u6bd4\u8f83\u4f46\u5bf9\u672c\u5730\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u8bc1\u636e\u3002\u4e0e\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\uff08\u901a\u5e38\u5c40\u9650\u4e8e\u672c\u5730\uff09\u6216\u7b97\u6cd5\u5ba1\u8ba1\uff08\u901a\u5e38\u662f\u56de\u987e\u6027\uff09\u4e0d\u540c\uff0cCIRCLE\u63d0\u4f9b\u4e86\u5c06\u4e0a\u4e0b\u6587\u654f\u611f\u5b9a\u6027\u89c1\u89e3\u4e0e\u53ef\u6269\u5c55\u5b9a\u91cf\u6307\u6807\u8fde\u63a5\u7684\u7ed3\u6784\u5316\u524d\u77bb\u6027\u534f\u8bae\u3002", "conclusion": "CIRCLE\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u57fa\u4e8e\u5b9e\u9645\u4e0b\u6e38\u6548\u5e94\u800c\u975e\u7406\u8bba\u80fd\u529b\u7684\u6cbb\u7406\uff0c\u4e3aAI\u90e8\u7f72\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5f25\u5408\u6a21\u578b\u6027\u80fd\u4e0e\u5b9e\u9645\u5e94\u7528\u6548\u679c\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2602.24080", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.24080", "abs": "https://arxiv.org/abs/2602.24080", "authors": ["Xiang Li", "Jiabao Gao", "Sipei Lin", "Xuan Zhou", "Chi Zhang", "Bo Cheng", "Jiale Han", "Benyou Wang"], "title": "Human or Machine? A Preliminary Turing Test for Speech-to-Speech Interaction", "comment": "Accepted by ICLR 2026 Conference", "summary": "The pursuit of human-like conversational agents has long been guided by the Turing test. For modern speech-to-speech (S2S) systems, a critical yet unanswered question is whether they can converse like humans. To tackle this, we conduct the first Turing test for S2S systems, collecting 2,968 human judgments on dialogues between 9 state-of-the-art S2S systems and 28 human participants. Our results deliver a clear finding: no existing evaluated S2S system passes the test, revealing a significant gap in human-likeness. To diagnose this failure, we develop a fine-grained taxonomy of 18 human-likeness dimensions and crowd-annotate our collected dialogues accordingly. Our analysis shows that the bottleneck is not semantic understanding but stems from paralinguistic features, emotional expressivity, and conversational persona. Furthermore, we find that off-the-shelf AI models perform unreliably as Turing test judges. In response, we propose an interpretable model that leverages the fine-grained human-likeness ratings and delivers accurate and transparent human-vs-machine discrimination, offering a powerful tool for automatic human-likeness evaluation. Our work establishes the first human-likeness evaluation for S2S systems and moves beyond binary outcomes to enable detailed diagnostic insights, paving the way for human-like improvements in conversational AI systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u5bf9\u8bed\u97f3\u5230\u8bed\u97f3\u7cfb\u7edf\u8fdb\u884c\u4e86\u56fe\u7075\u6d4b\u8bd5\uff0c\u53d1\u73b0\u73b0\u6709\u7cfb\u7edf\u5747\u672a\u901a\u8fc7\u6d4b\u8bd5\uff0c\u4e3b\u8981\u74f6\u9888\u5728\u4e8e\u526f\u8bed\u8a00\u7279\u5f81\u3001\u60c5\u611f\u8868\u8fbe\u548c\u5bf9\u8bdd\u4e2a\u6027\uff0c\u800c\u975e\u8bed\u4e49\u7406\u89e3\u3002", "motivation": "\u73b0\u4ee3\u8bed\u97f3\u5230\u8bed\u97f3\u7cfb\u7edf\u80fd\u5426\u50cf\u4eba\u7c7b\u4e00\u6837\u5bf9\u8bdd\u662f\u4e00\u4e2a\u5173\u952e\u4f46\u672a\u89e3\u7b54\u7684\u95ee\u9898\uff0c\u9700\u8981\u5efa\u7acb\u9996\u4e2a\u9488\u5bf9S2S\u7cfb\u7edf\u7684\u4eba\u7c7b\u76f8\u4f3c\u6027\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u6536\u96c6\u4e862,968\u4e2a\u4eba\u7c7b\u5224\u65ad\uff0c\u8bc4\u4f309\u4e2a\u6700\u5148\u8fdb\u7684S2S\u7cfb\u7edf\u4e0e28\u540d\u4eba\u7c7b\u53c2\u4e0e\u8005\u7684\u5bf9\u8bdd\uff1b\u5f00\u53d1\u4e86\u5305\u542b18\u4e2a\u7ef4\u5ea6\u7684\u7ec6\u7c92\u5ea6\u4eba\u7c7b\u76f8\u4f3c\u6027\u5206\u7c7b\u6cd5\uff0c\u5e76\u5bf9\u6536\u96c6\u7684\u5bf9\u8bdd\u8fdb\u884c\u4f17\u5305\u6807\u6ce8\u3002", "result": "\u6240\u6709\u8bc4\u4f30\u7684S2S\u7cfb\u7edf\u5747\u672a\u901a\u8fc7\u56fe\u7075\u6d4b\u8bd5\uff1b\u74f6\u9888\u4e3b\u8981\u5728\u4e8e\u526f\u8bed\u8a00\u7279\u5f81\u3001\u60c5\u611f\u8868\u8fbe\u548c\u5bf9\u8bdd\u4e2a\u6027\uff1b\u73b0\u6210\u7684AI\u6a21\u578b\u4f5c\u4e3a\u56fe\u7075\u6d4b\u8bd5\u8bc4\u5224\u8005\u8868\u73b0\u4e0d\u53ef\u9760\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5229\u7528\u7ec6\u7c92\u5ea6\u4eba\u7c7b\u76f8\u4f3c\u6027\u8bc4\u5206\u7684\u53ef\u89e3\u91ca\u6a21\u578b\uff0c\u80fd\u591f\u51c6\u786e\u900f\u660e\u5730\u533a\u5206\u4eba\u7c7b\u4e0e\u673a\u5668\u5bf9\u8bdd\uff0c\u4e3a\u81ea\u52a8\u4eba\u7c7b\u76f8\u4f3c\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5f3a\u5927\u5de5\u5177\uff0c\u63a8\u52a8\u4e86\u5bf9\u8bddAI\u7cfb\u7edf\u5411\u4eba\u7c7b\u76f8\u4f3c\u6027\u7684\u6539\u8fdb\u3002"}}
{"id": "2602.24110", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.24110", "abs": "https://arxiv.org/abs/2602.24110", "authors": ["Yanwei Ren", "Haotian Zhang", "Likang Xiao", "Xikai Zhang", "Jiaxing Huang", "Jiayan Qiu", "Baosheng Yu", "Quan Chen", "Liu Liu"], "title": "Recycling Failures: Salvaging Exploration in RLVR via Fine-Grained Off-Policy Guidance", "comment": null, "summary": "Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a powerful paradigm for enhancing the complex reasoning capabilities of Large Reasoning Models. However, standard outcome-based supervision suffers from a critical limitation that penalizes trajectories that are largely correct but fail due to several missteps as heavily as completely erroneous ones. This coarse feedback signal causes the model to discard valuable largely correct rollouts, leading to a degradation in rollout diversity that prematurely narrows the exploration space. Process Reward Models have demonstrated efficacy in providing reliable step-wise verification for test-time scaling, naively integrating these signals into RLVR as dense rewards proves ineffective.Prior methods attempt to introduce off-policy guided whole-trajectory replacement that often outside the policy model's distribution, but still fail to utilize the largely correct rollouts generated by the model itself and thus do not effectively mitigate the narrowing of the exploration space. To address these issues, we propose SCOPE (Step-wise Correction for On-Policy Exploration), a novel framework that utilizes Process Reward Models to pinpoint the first erroneous step in suboptimal rollouts and applies fine-grained, step-wise off-policy rectification. By applying precise refinement on partially correct rollout, our method effectively salvages partially correct trajectories and increases diversity score by 13.5%, thereby sustaining a broad exploration space. Extensive experiments demonstrate that our approach establishes new state-of-the-art results, achieving an average accuracy of 46.6% on math reasoning and exhibiting robust generalization with 53.4% accuracy on out-of-distribution reasoning tasks.", "AI": {"tldr": "SCOPE\u6846\u67b6\u901a\u8fc7\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u5b9a\u4f4d\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u9996\u4e2a\u9519\u8bef\u6b65\u9aa4\uff0c\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4fee\u6b63\uff0c\u6709\u6548\u5229\u7528\u90e8\u5206\u6b63\u786e\u7684\u63a8\u7406\u8def\u5f84\uff0c\u63d0\u5347\u63a2\u7d22\u591a\u6837\u602713.5%\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u523046.6%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u7ed3\u679c\u7684\u5f3a\u5316\u5b66\u4e60\u76d1\u7763\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff1a\u5bf9\u90e8\u5206\u6b63\u786e\u4f46\u5305\u542b\u51e0\u4e2a\u9519\u8bef\u6b65\u9aa4\u7684\u63a8\u7406\u8f68\u8ff9\u7ed9\u4e88\u4e0e\u5b8c\u5168\u9519\u8bef\u8f68\u8ff9\u76f8\u540c\u7684\u60e9\u7f5a\uff0c\u5bfc\u81f4\u6a21\u578b\u4e22\u5f03\u6709\u4ef7\u503c\u7684\u63a8\u7406\u8def\u5f84\uff0c\u63a2\u7d22\u7a7a\u95f4\u8fc7\u65e9\u7f29\u5c0f\uff0c\u591a\u6837\u6027\u4e0b\u964d\u3002", "method": "\u63d0\u51faSCOPE\u6846\u67b6\uff0c\u5229\u7528\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u7cbe\u786e\u5b9a\u4f4d\u6b21\u4f18\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u7b2c\u4e00\u4e2a\u9519\u8bef\u6b65\u9aa4\uff0c\u5e94\u7528\u7ec6\u7c92\u5ea6\u7684\u3001\u6b65\u9aa4\u7ea7\u522b\u7684\u79bb\u7b56\u7565\u4fee\u6b63\uff0c\u5bf9\u90e8\u5206\u6b63\u786e\u7684\u63a8\u7406\u8f68\u8ff9\u8fdb\u884c\u7cbe\u786e\u4fee\u6b63\u3002", "result": "SCOPE\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u8f68\u8ff9\u7684\u591a\u6837\u6027\uff08\u63d0\u534713.5%\uff09\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u523046.6%\u7684\u5e73\u5747\u51c6\u786e\u7387\uff0c\u5728\u5206\u5e03\u5916\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u523053.4%\u7684\u51c6\u786e\u7387\uff0c\u5efa\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u7ed3\u679c\u3002", "conclusion": "\u901a\u8fc7\u7cbe\u786e\u5b9a\u4f4d\u548c\u4fee\u6b63\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u9996\u4e2a\u9519\u8bef\u6b65\u9aa4\uff0cSCOPE\u80fd\u591f\u6709\u6548\u5229\u7528\u90e8\u5206\u6b63\u786e\u7684\u63a8\u7406\u8def\u5f84\uff0c\u7ef4\u6301\u5e7f\u9614\u7684\u63a2\u7d22\u7a7a\u95f4\uff0c\u663e\u8457\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2602.24173", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24173", "abs": "https://arxiv.org/abs/2602.24173", "authors": ["Antoine Peyronnet", "Fabian Gloeckle", "Amaury Hayat"], "title": "LemmaBench: A Live, Research-Level Benchmark to Evaluate LLM Capabilities in Mathematics", "comment": "15 pages, 3 figures, 5 Tables", "summary": "We present a new approach for benchmarking Large Language Model (LLM) capabilities on research-level mathematics. Existing benchmarks largely rely on static, hand-curated sets of contest or textbook-style problems as proxies for mathematical research. Instead, we establish an updatable benchmark evaluating models directly on the latest research results in mathematics. This consists of an automatic pipeline that extracts lemmas from arXiv and rewrites them into self-contained statements by making all assumptions and required definitions explicit. It results in a benchmark that can be updated regularly with new problems taken directly from human mathematical research, while previous instances can be used for training without compromising future evaluations. We benchmark current state-of-the-art LLMs, which obtain around 10-15$\\%$ accuracy in theorem proving (pass@1) depending on the model, showing that there is currently a large margin of progression for LLMs to reach human-level proving capabilities in a research context.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8earXiv\u6700\u65b0\u6570\u5b66\u7814\u7a76\u8bba\u6587\u7684\u53ef\u66f4\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u7814\u7a76\u5c42\u9762\u7684\u80fd\u529b\uff0c\u76f8\u6bd4\u4f20\u7edf\u9759\u6001\u57fa\u51c6\u66f4\u80fd\u53cd\u6620\u771f\u5b9e\u7814\u7a76\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u7684\u624b\u5de5\u6574\u7406\u9898\u76ee\uff08\u5982\u7ade\u8d5b\u9898\u6216\u6559\u79d1\u4e66\u4e60\u9898\uff09\uff0c\u8fd9\u4e9b\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30LLM\u5728\u771f\u5b9e\u6570\u5b66\u7814\u7a76\u4e2d\u7684\u80fd\u529b\u3002\u9700\u8981\u5efa\u7acb\u80fd\u53cd\u6620\u6700\u65b0\u6570\u5b66\u7814\u7a76\u8fdb\u5c55\u7684\u52a8\u6001\u8bc4\u4f30\u4f53\u7cfb\u3002", "method": "\u5f00\u53d1\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\uff1a\u4ecearXiv\u63d0\u53d6\u5f15\u7406\uff0c\u901a\u8fc7\u660e\u786e\u6240\u6709\u5047\u8bbe\u548c\u5b9a\u4e49\u5c06\u5176\u91cd\u5199\u4e3a\u81ea\u5305\u542b\u7684\u9648\u8ff0\uff0c\u521b\u5efa\u53ef\u5b9a\u671f\u66f4\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002\u65e7\u5b9e\u4f8b\u53ef\u7528\u4e8e\u8bad\u7ec3\u800c\u4e0d\u5f71\u54cd\u672a\u6765\u8bc4\u4f30\u3002", "result": "\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u5728\u5b9a\u7406\u8bc1\u660e\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u7ea6\u4e3a10-15%\uff08pass@1\uff09\uff0c\u8868\u660eLLM\u8981\u8fbe\u5230\u4eba\u7c7b\u5728\u6570\u5b66\u7814\u7a76\u4e2d\u7684\u8bc1\u660e\u80fd\u529b\u4ecd\u6709\u5f88\u5927\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u53ef\u66f4\u65b0\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u8bc4\u4f30LLM\u5728\u6570\u5b66\u7814\u7a76\u80fd\u529b\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u4e0e\u4eba\u7c7b\u7814\u7a76\u6c34\u5e73\u4e4b\u95f4\u7684\u663e\u8457\u5dee\u8ddd\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2602.24195", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24195", "abs": "https://arxiv.org/abs/2602.24195", "authors": ["Gregory Kang Ruey Lau", "Hieu Dao", "Nicole Kan Hui Lin", "Bryan Kian Hsiang Low"], "title": "Uncertainty Quantification for Multimodal Large Language Models with Incoherence-adjusted Semantic Volume", "comment": "Earlier versions presented at ICLR 2025 QUESTION workshop and ICML 2025 R2-FM workshop", "summary": "Despite their capabilities, Multimodal Large Language Models (MLLMs) may produce plausible but erroneous outputs, hindering reliable deployment. Accurate uncertainty metrics could enable escalation of unreliable queries to human experts or larger models for improved performance. However, existing uncertainty metrics have practical constraints, such as being designed only for specific modalities, reliant on external tools, or computationally expensive. We introduce UMPIRE, a training-free uncertainty quantification framework for MLLMs that works efficiently across various input and output modalities without external tools, relying only on the models' own internal modality features. UMPIRE computes the incoherence-adjusted semantic volume of sampled MLLM responses for a given task instance, effectively capturing both the global semantic diversity of samples and the local incoherence of responses based on internal model confidence. We propose uncertainty desiderata for MLLMs and provide theoretical analysis motivating UMPIRE's design. Extensive experiments show that UMPIRE consistently outperforms baseline metrics in error detection and uncertainty calibration across image, audio, and video-text benchmarks, including adversarial and out-of-distribution settings. We also demonstrate UMPIRE's generalization to non-text output tasks, including image and audio generation.", "AI": {"tldr": "UMPIRE\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8ba1\u7b97\u91c7\u6837\u54cd\u5e94\u7684\u8bed\u4e49\u4f53\u79ef\u6765\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027\uff0c\u652f\u6301\u591a\u79cd\u8f93\u5165\u8f93\u51fa\u6a21\u6001\u4e14\u65e0\u9700\u5916\u90e8\u5de5\u5177", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u4ea7\u751f\u770b\u4f3c\u5408\u7406\u4f46\u9519\u8bef\u7684\u8f93\u51fa\uff0c\u5f71\u54cd\u53ef\u9760\u90e8\u7f72\u3002\u73b0\u6709\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u4ec5\u9002\u7528\u4e8e\u7279\u5b9a\u6a21\u6001\u3001\u4f9d\u8d56\u5916\u90e8\u5de5\u5177\u6216\u8ba1\u7b97\u6210\u672c\u9ad8", "method": "UMPIRE\u6846\u67b6\u57fa\u4e8e\u6a21\u578b\u5185\u90e8\u6a21\u6001\u7279\u5f81\uff0c\u8ba1\u7b97\u91c7\u6837\u54cd\u5e94\u7684\u4e0d\u8fde\u8d2f\u8c03\u6574\u8bed\u4e49\u4f53\u79ef\uff0c\u540c\u65f6\u6355\u6349\u6837\u672c\u7684\u5168\u5c40\u8bed\u4e49\u591a\u6837\u6027\u548c\u57fa\u4e8e\u5185\u90e8\u6a21\u578b\u7f6e\u4fe1\u5ea6\u7684\u5c40\u90e8\u4e0d\u8fde\u8d2f\u6027", "result": "\u5728\u56fe\u50cf\u3001\u97f3\u9891\u548c\u89c6\u9891-\u6587\u672c\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ec\u5bf9\u6297\u6027\u548c\u5206\u5e03\u5916\u8bbe\u7f6e\uff09\u4e2d\uff0cUMPIRE\u5728\u9519\u8bef\u68c0\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u975e\u6587\u672c\u8f93\u51fa\u4efb\u52a1\uff08\u5982\u56fe\u50cf\u548c\u97f3\u9891\u751f\u6210\uff09", "conclusion": "UMPIRE\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u6a21\u6001\uff0c\u4e0d\u4f9d\u8d56\u5916\u90e8\u5de5\u5177\uff0c\u80fd\u6709\u6548\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u53ef\u9760\u6027"}}

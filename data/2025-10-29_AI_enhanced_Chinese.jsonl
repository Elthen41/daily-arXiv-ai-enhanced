{"id": "2510.23691", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23691", "abs": "https://arxiv.org/abs/2510.23691", "authors": ["Zihao Wang", "Xujing Li", "Yining Ye", "Junjie Fang", "Haoming Wang", "Longxiang Liu", "Shihao Liang", "Junting Lu", "Zhiyong Wu", "Jiazhan Feng", "Wanjun Zhong", "Zili Li", "Yu Wang", "Yu Miao", "Bo Zhou", "Yuanfan Li", "Hao Wang", "Zhongkai Zhao", "Faming Wu", "Zhengxuan Jiang", "Weihao Tan", "Heyuan Yao", "Shi Yan", "Xiangyang Li", "Yitao Liang", "Yujia Qin", "Guang Shi"], "title": "Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents", "comment": null, "summary": "We present Game-TARS, a generalist game agent trained with a unified,\nscalable action space anchored to human-aligned native keyboard-mouse inputs.\nUnlike API- or GUI-based approaches, this paradigm enables large-scale\ncontinual pre-training across heterogeneous domains, including OS, web, and\nsimulation games. Game-TARS is pre-trained on over 500B tokens with diverse\ntrajectories and multimodal data. Key techniques include a decaying continual\nloss to reduce causal confusion and an efficient Sparse-Thinking strategy that\nbalances reasoning depth and inference cost. Experiments show that Game-TARS\nachieves about 2 times the success rate over the previous sota model on\nopen-world Minecraft tasks, is close to the generality of fresh humans in\nunseen web 3d games, and outperforms GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet\nin FPS benchmarks. Scaling results on training-time and test-time confirm that\nthe unified action space sustains improvements when scaled to cross-game and\nmultimodal data. Our results demonstrate that simple, scalable action\nrepresentations combined with large-scale pre-training provide a promising path\ntoward generalist agents with broad computer-use abilities.", "AI": {"tldr": "Game-TARS\u662f\u4e00\u4e2a\u901a\u7528\u6e38\u620f\u667a\u80fd\u4f53\uff0c\u4f7f\u7528\u7edf\u4e00\u3001\u53ef\u6269\u5c55\u7684\u52a8\u4f5c\u7a7a\u95f4\u8fdb\u884c\u8bad\u7ec3\uff0c\u57fa\u4e8e\u4eba\u7c7b\u5bf9\u9f50\u7684\u952e\u76d8\u9f20\u6807\u8f93\u5165\u3002\u901a\u8fc7\u5927\u89c4\u6a21\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u5728\u591a\u79cd\u9886\u57df\uff08\u64cd\u4f5c\u7cfb\u7edf\u3001\u7f51\u9875\u3001\u6a21\u62df\u6e38\u620f\uff09\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5728\u591a\u4e2a\u6e38\u620f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u8de8\u5f02\u6784\u9886\u57df\uff08\u64cd\u4f5c\u7cfb\u7edf\u3001\u7f51\u9875\u3001\u6a21\u62df\u6e38\u620f\uff09\u5de5\u4f5c\u7684\u901a\u7528\u6e38\u620f\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u7edf\u4e00\u3001\u53ef\u6269\u5c55\u7684\u52a8\u4f5c\u7a7a\u95f4\u5b9e\u73b0\u5927\u89c4\u6a21\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u89e3\u51b3\u73b0\u6709API\u6216GUI\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u4eba\u7c7b\u5bf9\u9f50\u952e\u76d8\u9f20\u6807\u8f93\u5165\u7684\u7edf\u4e00\u52a8\u4f5c\u7a7a\u95f4\uff1b\u8fdb\u884c\u8d85\u8fc7500B token\u7684\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\uff0c\u5305\u542b\u591a\u6837\u5316\u8f68\u8ff9\u548c\u591a\u6a21\u6001\u6570\u636e\uff1b\u91c7\u7528\u8870\u51cf\u6301\u7eed\u635f\u5931\u51cf\u5c11\u56e0\u679c\u6df7\u6dc6\uff1b\u4f7f\u7528\u9ad8\u6548\u7684\u7a00\u758f\u601d\u8003\u7b56\u7565\u5e73\u8861\u63a8\u7406\u6df1\u5ea6\u548c\u63a8\u7406\u6210\u672c\u3002", "result": "\u5728\u5f00\u653e\u4e16\u754cMinecraft\u4efb\u52a1\u4e2d\u6210\u529f\u7387\u6bd4\u4e4b\u524d\u6700\u5148\u8fdb\u6a21\u578b\u63d0\u9ad8\u7ea62\u500d\uff1b\u5728\u672a\u89c1\u8fc7\u7684\u7f51\u98753D\u6e38\u620f\u4e2d\u63a5\u8fd1\u65b0\u624b\u7684\u901a\u7528\u6027\uff1b\u5728FPS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8aGPT-5\u3001Gemini-2.5-Pro\u548cClaude-4-Sonnet\uff1b\u8bad\u7ec3\u65f6\u95f4\u548c\u6d4b\u8bd5\u65f6\u95f4\u7684\u6269\u5c55\u7ed3\u679c\u8bc1\u5b9e\u7edf\u4e00\u52a8\u4f5c\u7a7a\u95f4\u5728\u8de8\u6e38\u620f\u548c\u591a\u6a21\u6001\u6570\u636e\u6269\u5c55\u65f6\u6301\u7eed\u6539\u8fdb\u3002", "conclusion": "\u7b80\u5355\u3001\u53ef\u6269\u5c55\u7684\u52a8\u4f5c\u8868\u793a\u4e0e\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u76f8\u7ed3\u5408\uff0c\u4e3a\u5b9e\u73b0\u5177\u6709\u5e7f\u6cdb\u8ba1\u7b97\u673a\u4f7f\u7528\u80fd\u529b\u7684\u901a\u7528\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u4e00\u6761\u6709\u524d\u666f\u7684\u8def\u5f84\u3002"}}
{"id": "2510.23734", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23734", "abs": "https://arxiv.org/abs/2510.23734", "authors": ["Eamon Duede"], "title": "AI and the Decentering of Disciplinary Creativity", "comment": null, "summary": "This paper examines the role of artificial intelligence in scientific\nproblem-solving, with a focus on its implications for disciplinary creativity.\nDrawing on recent work in the philosophy of creativity, I distinguish between\ncreative approaches and creative products, and introduce the concept of\ndisciplinary creativity -the creative application of discipline-specific\nexpertise to a valued problem within that field. Through two cases in\nmathematics, I show that while computation can extend disciplinary creativity,\ncertain approaches involving AI can serve to displace it. This displacement has\nthe potential to alter (and, perhaps, diminish) the value of scientific\npursuit.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4eba\u5de5\u667a\u80fd\u5728\u79d1\u5b66\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u4f5c\u7528\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u5bf9\u5b66\u79d1\u521b\u9020\u529b\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u533a\u5206\u521b\u9020\u6027\u65b9\u6cd5\u548c\u521b\u9020\u6027\u4ea7\u54c1\uff0c\u63d0\u51fa\u5b66\u79d1\u521b\u9020\u529b\u7684\u6982\u5ff5\uff0c\u5e76\u901a\u8fc7\u6570\u5b66\u6848\u4f8b\u8bf4\u660eAI\u53ef\u80fd\u53d6\u4ee3\u800c\u975e\u6269\u5c55\u5b66\u79d1\u521b\u9020\u529b\u3002", "motivation": "\u7814\u7a76AI\u5728\u79d1\u5b66\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u89d2\u8272\uff0c\u7279\u522b\u5173\u6ce8\u5176\u5bf9\u5b66\u79d1\u521b\u9020\u529b\u7684\u6f5c\u5728\u5f71\u54cd\uff0c\u63a2\u8ba8AI\u53ef\u80fd\u5982\u4f55\u6539\u53d8\u79d1\u5b66\u8ffd\u6c42\u7684\u4ef7\u503c\u3002", "method": "\u57fa\u4e8e\u521b\u9020\u529b\u54f2\u5b66\u7684\u6700\u65b0\u7814\u7a76\uff0c\u533a\u5206\u521b\u9020\u6027\u65b9\u6cd5\u548c\u521b\u9020\u6027\u4ea7\u54c1\uff0c\u5f15\u5165\u5b66\u79d1\u521b\u9020\u529b\u7684\u6982\u5ff5\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u6570\u5b66\u6848\u4f8b\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8ba1\u7b97\u53ef\u4ee5\u6269\u5c55\u5b66\u79d1\u521b\u9020\u529b\uff0c\u4f46\u67d0\u4e9b\u6d89\u53caAI\u7684\u65b9\u6cd5\u53ef\u80fd\u53d6\u4ee3\u5b66\u79d1\u521b\u9020\u529b\uff0c\u8fd9\u79cd\u53d6\u4ee3\u6709\u53ef\u80fd\u6539\u53d8\u79d1\u5b66\u8ffd\u6c42\u7684\u4ef7\u503c\u3002", "conclusion": "AI\u5728\u79d1\u5b66\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u5e94\u7528\u9700\u8981\u8c28\u614e\uff0c\u56e0\u4e3a\u5b83\u53ef\u80fd\u901a\u8fc7\u53d6\u4ee3\u5b66\u79d1\u521b\u9020\u529b\u800c\u6539\u53d8\u79d1\u5b66\u8ffd\u6c42\u7684\u672c\u8d28\u548c\u4ef7\u503c\u3002"}}
{"id": "2510.23744", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23744", "abs": "https://arxiv.org/abs/2510.23744", "authors": ["Eline M. Bovy", "Caleb Probine", "Marnix Suilen", "Ufuk Topcu", "Nils Jansen"], "title": "Multi-Environment POMDPs: Discrete Model Uncertainty Under Partial Observability", "comment": "Accepted at NeurIPS 2025", "summary": "Multi-environment POMDPs (ME-POMDPs) extend standard POMDPs with discrete\nmodel uncertainty. ME-POMDPs represent a finite set of POMDPs that share the\nsame state, action, and observation spaces, but may arbitrarily vary in their\ntransition, observation, and reward models. Such models arise, for instance,\nwhen multiple domain experts disagree on how to model a problem. The goal is to\nfind a single policy that is robust against any choice of POMDP within the set,\ni.e., a policy that maximizes the worst-case reward across all POMDPs. We\ngeneralize and expand on existing work in the following way. First, we show\nthat ME-POMDPs can be generalized to POMDPs with sets of initial beliefs, which\nwe call adversarial-belief POMDPs (AB-POMDPs). Second, we show that any\narbitrary ME-POMDP can be reduced to a ME-POMDP that only varies in its\ntransition and reward functions or only in its observation and reward\nfunctions, while preserving (optimal) policies. We then devise exact and\napproximate (point-based) algorithms to compute robust policies for AB-POMDPs,\nand thus ME-POMDPs. We demonstrate that we can compute policies for standard\nPOMDP benchmarks extended to the multi-environment setting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u591a\u73af\u5883POMDPs\uff08ME-POMDPs\uff09\u53ca\u5176\u6269\u5c55\u5f62\u5f0fAB-POMDPs\uff0c\u7528\u4e8e\u5904\u7406\u5177\u6709\u79bb\u6563\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684POMDP\u95ee\u9898\uff0c\u65e8\u5728\u5bfb\u627e\u5bf9\u73af\u5883\u4e2d\u6240\u6709\u53ef\u80fd\u53d8\u5316\u90fd\u5177\u6709\u9c81\u68d2\u6027\u7684\u5355\u4e00\u7b56\u7565\u3002", "motivation": "\u5f53\u591a\u4e2a\u9886\u57df\u4e13\u5bb6\u5bf9\u95ee\u9898\u5efa\u6a21\u5b58\u5728\u5206\u6b67\u65f6\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u6846\u67b6\u3002ME-POMDPs\u6269\u5c55\u4e86\u6807\u51c6POMDP\uff0c\u901a\u8fc7\u8003\u8651\u4e00\u7ec4\u53ef\u80fd\u7684\u73af\u5883\u6a21\u578b\u6765\u5bfb\u627e\u9c81\u68d2\u7b56\u7565\u3002", "method": "1\uff09\u5c06ME-POMDPs\u63a8\u5e7f\u4e3a\u5177\u6709\u521d\u59cb\u4fe1\u5ff5\u96c6\u5408\u7684AB-POMDPs\uff1b2\uff09\u8bc1\u660e\u4efb\u610fME-POMDP\u53ef\u7b80\u5316\u4e3a\u4ec5\u53d8\u5316\u8f6c\u79fb\u548c\u5956\u52b1\u51fd\u6570\u6216\u4ec5\u53d8\u5316\u89c2\u6d4b\u548c\u5956\u52b1\u51fd\u6570\u7684\u5f62\u5f0f\uff1b3\uff09\u5f00\u53d1\u7cbe\u786e\u548c\u8fd1\u4f3c\uff08\u57fa\u4e8e\u70b9\uff09\u7684\u7b97\u6cd5\u6765\u8ba1\u7b97\u9c81\u68d2\u7b56\u7565\u3002", "result": "\u6210\u529f\u4e3a\u6807\u51c6POMDP\u57fa\u51c6\u6d4b\u8bd5\u7684\u591a\u73af\u5883\u6269\u5c55\u7248\u672c\u8ba1\u7b97\u4e86\u7b56\u7565\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "ME-POMDPs\u548cAB-POMDPs\u4e3a\u5904\u7406\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6846\u67b6\uff0c\u6240\u5f00\u53d1\u7684\u7b97\u6cd5\u80fd\u591f\u5728\u591a\u73af\u5883\u8bbe\u7f6e\u4e0b\u8ba1\u7b97\u9c81\u68d2\u7b56\u7565\u3002"}}
{"id": "2510.23746", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23746", "abs": "https://arxiv.org/abs/2510.23746", "authors": ["Laura Mismetti", "Marvin Alberts", "Andreas Krause", "Mara Graziani"], "title": "Test-Time Tuned Language Models Enable End-to-end De Novo Molecular Structure Generation from MS/MS Spectra", "comment": null, "summary": "Tandem Mass Spectrometry enables the identification of unknown compounds in\ncrucial fields such as metabolomics, natural product discovery and\nenvironmental analysis. However, current methods rely on database matching from\npreviously observed molecules, or on multi-step pipelines that require\nintermediate fragment or fingerprint prediction. This makes finding the correct\nmolecule highly challenging, particularly for compounds absent from reference\ndatabases. We introduce a framework that, by leveraging test-time tuning,\nenhances the learning of a pre-trained transformer model to address this gap,\nenabling end-to-end de novo molecular structure generation directly from the\ntandem mass spectra and molecular formulae, bypassing manual annotations and\nintermediate steps. We surpass the de-facto state-of-the-art approach DiffMS on\ntwo popular benchmarks NPLIB1 and MassSpecGym by 100% and 20%, respectively.\nTest-time tuning on experimental spectra allows the model to dynamically adapt\nto novel spectra, and the relative performance gain over conventional\nfine-tuning is of 62% on MassSpecGym. When predictions deviate from the ground\ntruth, the generated molecular candidates remain structurally accurate,\nproviding valuable guidance for human interpretation and more reliable\nidentification.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d4b\u8bd5\u65f6\u8c03\u4f18\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3a\u9884\u8bad\u7ec3transformer\u6a21\u578b\u76f4\u63a5\u4ece\u4e32\u8054\u8d28\u8c31\u548c\u5206\u5b50\u5f0f\u8fdb\u884c\u7aef\u5230\u7aef\u4ece\u5934\u5206\u5b50\u7ed3\u6784\u751f\u6210\uff0c\u65e0\u9700\u4f9d\u8d56\u6570\u636e\u5e93\u5339\u914d\u6216\u4e2d\u95f4\u6b65\u9aa4\uff0c\u5728\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u4e32\u8054\u8d28\u8c31\u5206\u6790\u65b9\u6cd5\u4f9d\u8d56\u6570\u636e\u5e93\u5339\u914d\u6216\u9700\u8981\u4e2d\u95f4\u7247\u6bb5\u9884\u6d4b\u7684\u591a\u6b65\u9aa4\u6d41\u7a0b\uff0c\u96be\u4ee5\u8bc6\u522b\u53c2\u8003\u6570\u636e\u5e93\u4e2d\u4e0d\u5b58\u5728\u7684\u5316\u5408\u7269\uff0c\u9650\u5236\u4e86\u5728\u4ee3\u8c22\u7ec4\u5b66\u3001\u5929\u7136\u4ea7\u7269\u53d1\u73b0\u7b49\u9886\u57df\u7684\u5e94\u7528\u3002", "method": "\u5229\u7528\u6d4b\u8bd5\u65f6\u8c03\u4f18\u589e\u5f3a\u9884\u8bad\u7ec3transformer\u6a21\u578b\uff0c\u76f4\u63a5\u4ece\u4e32\u8054\u8d28\u8c31\u548c\u5206\u5b50\u5f0f\u8fdb\u884c\u7aef\u5230\u7aef\u5206\u5b50\u7ed3\u6784\u751f\u6210\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u548c\u4e2d\u95f4\u6b65\u9aa4\uff0c\u80fd\u591f\u52a8\u6001\u9002\u5e94\u65b0\u7684\u8d28\u8c31\u6570\u636e\u3002", "result": "\u5728NPLIB1\u548cMassSpecGym\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5206\u522b\u8d85\u8d8aDiffMS\u65b9\u6cd5100%\u548c20%\uff0c\u6d4b\u8bd5\u65f6\u8c03\u4f18\u76f8\u6bd4\u4f20\u7edf\u5fae\u8c03\u5728MassSpecGym\u4e0a\u83b7\u5f9762%\u7684\u76f8\u5bf9\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u751f\u6210\u7ed3\u6784\u51c6\u786e\u7684\u5206\u5b50\u5019\u9009\u7269\uff0c\u5373\u4f7f\u9884\u6d4b\u504f\u79bb\u771f\u5b9e\u503c\uff0c\u4ecd\u80fd\u4e3a\u4eba\u5de5\u89e3\u91ca\u63d0\u4f9b\u6709\u4ef7\u503c\u6307\u5bfc\uff0c\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u5316\u5408\u7269\u8bc6\u522b\u3002"}}
{"id": "2510.23911", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.23911", "abs": "https://arxiv.org/abs/2510.23911", "authors": ["Arno Uhlig", "Iris Braun", "Matthias W\u00e4hlisch"], "title": "The SAP Cloud Infrastructure Dataset: A Reality Check of Scheduling and Placement of VMs in Cloud Computing", "comment": "15 pages", "summary": "Allocating resources in a distributed environment is a fundamental challenge.\nIn this paper, we analyze the scheduling and placement of virtual machines\n(VMs) in the cloud platform of SAP, the world's largest enterprise resource\nplanning software vendor. Based on data from roughly 1,800 hypervisors and\n48,000 VMs within a 30-day observation period, we highlight potential\nimprovements for workload management. The data was measured through\nobservability tooling that tracks resource usage and performance metrics across\nthe entire infrastructure. In contrast to existing datasets, ours uniquely\noffers fine-grained time-series telemetry data of fully virtualized\nenterprise-level workloads from both long-running and memory-intensive SAP\nS/4HANA and diverse, general-purpose applications. Our key findings include\nseveral suboptimal scheduling situations, such as CPU resource contention\nexceeding 40%, CPU ready times of up to 220 seconds, significantly imbalanced\ncompute hosts with a maximum CPU~utilization on intra-building block hosts of\nup to 99%, and overprovisioned CPU and memory resources resulting into over 80%\nof VMs using less than 70% of the provided resources. Bolstered by these\nfindings, we derive requirements for the design and implementation of novel\nplacement and scheduling algorithms and provide guidance to optimize resource\nallocations. We make the full dataset used in this study publicly available to\nenable data-driven evaluations of scheduling approaches for large-scale cloud\ninfrastructures in future research.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86SAP\u4e91\u5e73\u53f0\u4e2d\u865a\u62df\u673a\u8c03\u5ea6\u548c\u653e\u7f6e\u95ee\u9898\uff0c\u57fa\u4e8e1800\u4e2a\u7ba1\u7406\u7a0b\u5e8f\u548c48000\u4e2aVM\u768430\u5929\u6570\u636e\uff0c\u53d1\u73b0\u4e86CPU\u8d44\u6e90\u4e89\u7528\u8d85\u8fc740%\u3001CPU\u5c31\u7eea\u65f6\u95f4\u8fbe220\u79d2\u3001\u4e3b\u673a\u8d1f\u8f7d\u4e0d\u5e73\u8861\u7b49\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u8c03\u5ea6\u7b97\u6cd5\u7684\u9700\u6c42\u3002", "motivation": "\u5206\u6790\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u8d44\u6e90\u5206\u914d\u7684\u57fa\u672c\u6311\u6218\uff0c\u7279\u522b\u662f\u5728SAP\u4e91\u5e73\u53f0\u4e2d\u4f18\u5316\u865a\u62df\u673a\u8c03\u5ea6\u548c\u653e\u7f6e\uff0c\u4ee5\u63d0\u9ad8\u8d44\u6e90\u5229\u7528\u6548\u7387\u3002", "method": "\u57fa\u4e8e30\u5929\u89c2\u5bdf\u671f\u5185\u7ea61800\u4e2a\u7ba1\u7406\u7a0b\u5e8f\u548c48000\u4e2aVM\u7684\u7ec6\u7c92\u5ea6\u65f6\u95f4\u5e8f\u5217\u9065\u6d4b\u6570\u636e\uff0c\u4f7f\u7528\u53ef\u89c2\u6d4b\u6027\u5de5\u5177\u8ddf\u8e2a\u6574\u4e2a\u57fa\u7840\u8bbe\u65bd\u7684\u8d44\u6e90\u4f7f\u7528\u548c\u6027\u80fd\u6307\u6807\u3002", "result": "\u53d1\u73b0\u591a\u4e2a\u6b21\u4f18\u8c03\u5ea6\u60c5\u51b5\uff1aCPU\u8d44\u6e90\u4e89\u7528\u8d85\u8fc740%\u3001CPU\u5c31\u7eea\u65f6\u95f4\u9ad8\u8fbe220\u79d2\u3001\u8ba1\u7b97\u4e3b\u673a\u8d1f\u8f7d\u663e\u8457\u4e0d\u5e73\u8861\uff08\u6700\u5927CPU\u5229\u7528\u7387\u8fbe99%\uff09\u3001CPU\u548c\u5185\u5b58\u8d44\u6e90\u8fc7\u5ea6\u914d\u7f6e\u5bfc\u81f4\u8d85\u8fc780%\u7684VM\u4f7f\u7528\u4e0d\u523070%\u7684\u5206\u914d\u8d44\u6e90\u3002", "conclusion": "\u57fa\u4e8e\u7814\u7a76\u53d1\u73b0\uff0c\u63d0\u51fa\u4e86\u65b0\u578b\u653e\u7f6e\u548c\u8c03\u5ea6\u7b97\u6cd5\u7684\u8bbe\u8ba1\u9700\u6c42\uff0c\u5e76\u4e3a\u4f18\u5316\u8d44\u6e90\u5206\u914d\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002\u540c\u65f6\u516c\u5f00\u4e86\u5b8c\u6574\u6570\u636e\u96c6\uff0c\u4ee5\u652f\u6301\u672a\u6765\u5927\u89c4\u6a21\u4e91\u57fa\u7840\u8bbe\u65bd\u8c03\u5ea6\u65b9\u6cd5\u7684\u6570\u636e\u9a71\u52a8\u8bc4\u4f30\u3002"}}
{"id": "2510.23619", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23619", "abs": "https://arxiv.org/abs/2510.23619", "authors": ["Yuyang Miao", "Huijun Xing", "Danilo P. Mandic", "Tony G. Constantinides"], "title": "Short Ticketing Detection Framework Analysis Report", "comment": null, "summary": "This report presents a comprehensive analysis of an unsupervised multi-expert\nmachine learning framework for detecting short ticketing fraud in railway\nsystems. The study introduces an A/B/C/D station classification system that\nsuccessfully identifies suspicious patterns across 30 high-risk stations. The\nframework employs four complementary algorithms: Isolation Forest, Local\nOutlier Factor, One-Class SVM, and Mahalanobis Distance. Key findings include\nthe identification of five distinct short ticketing patterns and potential for\nshort ticketing recovery in transportation systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65e0\u76d1\u7763\u591a\u4e13\u5bb6\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u94c1\u8def\u7cfb\u7edf\u4e2d\u7684\u77ed\u7968\u6b3a\u8bc8\uff0c\u901a\u8fc7A/B/C/D\u8f66\u7ad9\u5206\u7c7b\u7cfb\u7edf\u8bc6\u522b\u4e8630\u4e2a\u9ad8\u98ce\u9669\u8f66\u7ad9\u7684\u53ef\u7591\u6a21\u5f0f\uff0c\u5e76\u53d1\u73b0\u4e865\u79cd\u4e0d\u540c\u7684\u77ed\u7968\u6a21\u5f0f\u3002", "motivation": "\u94c1\u8def\u7cfb\u7edf\u4e2d\u7684\u77ed\u7968\u6b3a\u8bc8\u9020\u6210\u91cd\u5927\u7ecf\u6d4e\u635f\u5931\uff0c\u9700\u8981\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u6765\u8bc6\u522b\u8fd9\u79cd\u6b3a\u8bc8\u884c\u4e3a\u5e76\u51cf\u5c11\u635f\u5931\u3002", "method": "\u91c7\u7528\u56db\u79cd\u4e92\u8865\u7b97\u6cd5\uff1a\u9694\u79bb\u68ee\u6797\u3001\u5c40\u90e8\u5f02\u5e38\u56e0\u5b50\u3001\u4e00\u7c7b\u652f\u6301\u5411\u91cf\u673a\u548c\u9a6c\u6c0f\u8ddd\u79bb\uff0c\u6784\u5efa\u65e0\u76d1\u7763\u591a\u4e13\u5bb6\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u5efa\u7acbA/B/C/D\u8f66\u7ad9\u5206\u7c7b\u7cfb\u7edf\u3002", "result": "\u6210\u529f\u8bc6\u522b\u4e8630\u4e2a\u9ad8\u98ce\u9669\u8f66\u7ad9\u7684\u53ef\u7591\u6a21\u5f0f\uff0c\u53d1\u73b0\u4e865\u79cd\u4e0d\u540c\u7684\u77ed\u7968\u6b3a\u8bc8\u6a21\u5f0f\uff0c\u5e76\u5c55\u793a\u4e86\u77ed\u7968\u56de\u6536\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u65e0\u76d1\u7763\u591a\u4e13\u5bb6\u673a\u5668\u5b66\u4e60\u6846\u67b6\u80fd\u6709\u6548\u68c0\u6d4b\u94c1\u8def\u7cfb\u7edf\u4e2d\u7684\u77ed\u7968\u6b3a\u8bc8\uff0c\u4e3a\u4ea4\u901a\u7cfb\u7edf\u7684\u6b3a\u8bc8\u68c0\u6d4b\u548c\u635f\u5931\u6062\u590d\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.24112", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.24112", "abs": "https://arxiv.org/abs/2510.24112", "authors": ["Junchi Wu", "Xinfei Wan", "Zhuoran Li", "Yuyang Jin", "Guangyu Sun", "Yun Liang", "Diyu Zhou", "Youwei Zhuo"], "title": "SlowPoke: Understanding and Detecting On-Chip Fail-Slow Failures in Many-Core Systems", "comment": "15 pages, 15 figures", "summary": "Many-core architectures are essential for high-performance computing, but\ntheir performance is undermined by widespread fail-slow failures. Detecting\nsuch failures on-chip is challenging, as prior methods from distributed systems\nare unsuitable due to strict memory limits and their inability to track\nfailures across the hardware topology. This paper introduces SlowPoke, a\nlightweight, hardware-aware framework for practical on-chip fail-slow\ndetection. SlowPoke combines compiler-based instrumentation for low-overhead\nmonitoring, on-the-fly trace compression to operate within kilobytes of memory,\nand a novel topology-aware ranking algorithm to pinpoint a failure's root\ncause. We evaluate SlowPoke on a wide range of representative many-core\nworkloads, and the results demonstrate that SlowPoke reduces the storage\noverhead of detection traces by an average of 115.9$\\times$, while achieving an\naverage fail-slow detection accuracy of 86.77% and a false positive rate (FPR)\nof 12.11%. More importantly, SlowPoke scales effectively across different\nmany-core architectures, making it practical for large-scale deployments.", "AI": {"tldr": "SlowPoke\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u786c\u4ef6\u611f\u77e5\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u591a\u6838\u67b6\u6784\u4e0a\u8fdb\u884c\u7247\u4e0a\u6545\u969c\u6162\u901f\u68c0\u6d4b\uff0c\u901a\u8fc7\u7f16\u8bd1\u5668\u63d2\u6869\u3001\u5728\u7ebf\u8ddf\u8e2a\u538b\u7f29\u548c\u62d3\u6251\u611f\u77e5\u6392\u540d\u7b97\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u5b58\u50a8\u5f00\u9500\u5e76\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u591a\u6838\u67b6\u6784\u5bf9\u9ad8\u6027\u80fd\u8ba1\u7b97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u6027\u80fd\u53d7\u5230\u5e7f\u6cdb\u5b58\u5728\u7684\u6545\u969c\u6162\u901f\u95ee\u9898\u7684\u4e25\u91cd\u5f71\u54cd\u3002\u73b0\u6709\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u65b9\u6cd5\u7531\u4e8e\u4e25\u683c\u7684\u5185\u5b58\u9650\u5236\u548c\u65e0\u6cd5\u8ddf\u8e2a\u786c\u4ef6\u62d3\u6251\u4e2d\u7684\u6545\u969c\uff0c\u4e0d\u9002\u5408\u7247\u4e0a\u68c0\u6d4b\u3002", "method": "\u7ed3\u5408\u7f16\u8bd1\u5668\u63d2\u6869\u8fdb\u884c\u4f4e\u5f00\u9500\u76d1\u63a7\uff0c\u4f7f\u7528\u5728\u7ebf\u8ddf\u8e2a\u538b\u7f29\u5728\u5343\u5b57\u8282\u5185\u5b58\u5185\u8fd0\u884c\uff0c\u5e76\u91c7\u7528\u65b0\u9896\u7684\u62d3\u6251\u611f\u77e5\u6392\u540d\u7b97\u6cd5\u6765\u5b9a\u4f4d\u6545\u969c\u7684\u6839\u672c\u539f\u56e0\u3002", "result": "\u5728\u4ee3\u8868\u6027\u591a\u6838\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cSlowPoke\u5c06\u68c0\u6d4b\u8ddf\u8e2a\u7684\u5b58\u50a8\u5f00\u9500\u5e73\u5747\u964d\u4f4e\u4e86115.9\u500d\uff0c\u5b9e\u73b0\u4e8686.77%\u7684\u5e73\u5747\u6545\u969c\u6162\u901f\u68c0\u6d4b\u51c6\u786e\u7387\u548c12.11%\u7684\u8bef\u62a5\u7387\u3002", "conclusion": "SlowPoke\u5728\u4e0d\u540c\u591a\u6838\u67b6\u6784\u4e0a\u90fd\u80fd\u6709\u6548\u6269\u5c55\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u90e8\u7f72\uff0c\u4e3a\u7247\u4e0a\u6545\u969c\u6162\u901f\u68c0\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.23772", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23772", "abs": "https://arxiv.org/abs/2510.23772", "authors": ["Vivek Veeriah", "Federico Barbero", "Marcus Chiam", "Xidong Feng", "Michael Dennis", "Ryan Pachauri", "Thomas Tumiel", "Johan Obando-Ceron", "Jiaxin Shi", "Shaobo Hou", "Satinder Singh", "Nenad Toma\u0161ev", "Tom Zahavy"], "title": "Evaluating In Silico Creativity: An Expert Review of AI Chess Compositions", "comment": "Accepted at the Creative AI Track, NeurIPS 2025", "summary": "The rapid advancement of Generative AI has raised significant questions\nregarding its ability to produce creative and novel outputs. Our recent work\ninvestigates this question within the domain of chess puzzles and presents an\nAI system designed to generate puzzles characterized by aesthetic appeal,\nnovelty, counter-intuitive and unique solutions. We briefly discuss our method\nbelow and refer the reader to the technical paper for more details. To assess\nour system's creativity, we presented a curated booklet of AI-generated puzzles\nto three world-renowned experts: International Master for chess compositions\nAmatzia Avni, Grandmaster Jonathan Levitt, and Grandmaster Matthew Sadler. All\nthree are noted authors on chess aesthetics and the evolving role of computers\nin the game. They were asked to select their favorites and explain what made\nthem appealing, considering qualities such as their creativity, level of\nchallenge, or aesthetic design.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u751f\u6210\u5f0fAI\u5728\u8c61\u68cb\u8c1c\u9898\u9886\u57df\u7684\u521b\u9020\u529b\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u751f\u6210\u5177\u6709\u7f8e\u5b66\u5438\u5f15\u529b\u3001\u65b0\u9896\u6027\u3001\u53cd\u76f4\u89c9\u548c\u72ec\u7279\u89e3\u6cd5\u7684AI\u7cfb\u7edf\uff0c\u5e76\u7531\u4e09\u4f4d\u56fd\u9645\u8c61\u68cb\u4e13\u5bb6\u8bc4\u4f30\u5176\u521b\u9020\u6027\u3002", "motivation": "\u7814\u7a76\u751f\u6210\u5f0fAI\u662f\u5426\u80fd\u4ea7\u751f\u521b\u9020\u6027\u548c\u65b0\u9896\u7684\u8f93\u51fa\uff0c\u7279\u522b\u662f\u5728\u8c61\u68cb\u8c1c\u9898\u8fd9\u4e00\u9700\u8981\u9ad8\u5ea6\u521b\u9020\u529b\u7684\u9886\u57df\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2aAI\u7cfb\u7edf\u6765\u751f\u6210\u8c61\u68cb\u8c1c\u9898\uff0c\u7136\u540e\u5c06\u7cbe\u9009\u7684AI\u751f\u6210\u8c1c\u9898\u63d0\u4ea4\u7ed9\u4e09\u4f4d\u4e16\u754c\u77e5\u540d\u8c61\u68cb\u4e13\u5bb6\uff08\u56fd\u9645\u8c61\u68cb\u6392\u5c40\u5927\u5e08Amatzia Avni\u3001\u7279\u7ea7\u5927\u5e08Jonathan Levitt\u548cMatthew Sadler\uff09\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u4e09\u4f4d\u4e13\u5bb6\u4ece\u521b\u9020\u529b\u3001\u6311\u6218\u6c34\u5e73\u548c\u7f8e\u5b66\u8bbe\u8ba1\u7b49\u89d2\u5ea6\u8bc4\u4f30\u4e86AI\u751f\u6210\u7684\u8c1c\u9898\uff0c\u5e76\u9009\u62e9\u4e86\u4ed6\u4eec\u6700\u559c\u6b22\u7684\u8c1c\u9898\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\u751f\u6210\u5f0fAI\u5728\u8c61\u68cb\u8c1c\u9898\u9886\u57df\u80fd\u591f\u4ea7\u751f\u5177\u6709\u521b\u9020\u6027\u548c\u7f8e\u5b66\u4ef7\u503c\u7684\u8f93\u51fa\uff0c\u5f97\u5230\u4e86\u4e13\u4e1a\u8c61\u68cb\u4e13\u5bb6\u7684\u8ba4\u53ef\u3002"}}
{"id": "2510.23993", "categories": ["cs.DC", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.23993", "abs": "https://arxiv.org/abs/2510.23993", "authors": ["Anthony Carreon", "Jagmohan Singh", "Shivank Sharma", "Shuzhi Zhang", "Venkat Raman"], "title": "A GPU-based Compressible Combustion Solver for Applications Exhibiting Disparate Space and Time Scales", "comment": "32 pages, 12 figures", "summary": "High-speed chemically active flows present significant computational\nchallenges due to their disparate space and time scales, where stiff chemistry\noften dominates simulation time. While modern supercomputing scientific codes\nachieve exascale performance by leveraging graphics processing units (GPUs),\nexisting GPU-based compressible combustion solvers face critical limitations in\nmemory management, load balancing, and handling the highly localized nature of\nchemical reactions. To this end, we present a high-performance compressible\nreacting flow solver built on the AMReX framework and optimized for multi-GPU\nsettings. Our approach addresses three GPU performance bottlenecks: memory\naccess patterns through column-major storage optimization, computational\nworkload variability via a bulk-sparse integration strategy for chemical\nkinetics, and multi-GPU load distribution for adaptive mesh refinement\napplications. The solver adapts existing matrix-based chemical kinetics\nformulations to multigrid contexts. Using representative combustion\napplications including hydrogen-air detonations and jet in supersonic crossflow\nconfigurations, we demonstrate $2-5\\times$ performance improvements over\ninitial GPU implementations with near-ideal weak scaling across $1-96$ NVIDIA\nH100 GPUs. Roofline analysis reveals substantial improvements in arithmetic\nintensity for both convection ($\\sim 10 \\times$) and chemistry ($\\sim 4\n\\times$) routines, confirming efficient utilization of GPU memory bandwidth and\ncomputational resources.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eAMReX\u6846\u67b6\u7684\u9ad8\u6027\u80fd\u53ef\u538b\u7f29\u53cd\u5e94\u6d41\u6c42\u89e3\u5668\uff0c\u9488\u5bf9\u591aGPU\u73af\u5883\u4f18\u5316\uff0c\u89e3\u51b3\u4e86GPU\u6027\u80fd\u74f6\u9888\u95ee\u9898\uff0c\u5728\u71c3\u70e7\u5e94\u7528\u4e2d\u5b9e\u73b0\u4e862-5\u500d\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u9ad8\u901f\u5316\u5b66\u53cd\u5e94\u6d41\u5b58\u5728\u663e\u8457\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u73b0\u6709\u7684GPU\u53ef\u538b\u7f29\u71c3\u70e7\u6c42\u89e3\u5668\u5728\u5185\u5b58\u7ba1\u7406\u3001\u8d1f\u8f7d\u5e73\u8861\u548c\u5904\u7406\u5316\u5b66\u53cd\u5e94\u7684\u9ad8\u5ea6\u5c40\u90e8\u5316\u7279\u6027\u65b9\u9762\u5b58\u5728\u5173\u952e\u9650\u5236\u3002", "method": "\u91c7\u7528\u5217\u4f18\u5148\u5b58\u50a8\u4f18\u5316\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\uff0c\u901a\u8fc7\u6279\u91cf\u7a00\u758f\u79ef\u5206\u7b56\u7565\u5904\u7406\u5316\u5b66\u52a8\u529b\u5b66\u8ba1\u7b97\u8d1f\u8f7d\u53d8\u5316\uff0c\u4e3a\u81ea\u9002\u5e94\u7f51\u683c\u7ec6\u5316\u5e94\u7528\u4f18\u5316\u591aGPU\u8d1f\u8f7d\u5206\u5e03\uff0c\u5e76\u5c06\u73b0\u6709\u57fa\u4e8e\u77e9\u9635\u7684\u5316\u5b66\u52a8\u529b\u5b66\u516c\u5f0f\u9002\u5e94\u591a\u7f51\u683c\u73af\u5883\u3002", "result": "\u5728\u6c22-\u7a7a\u6c14\u7206\u8f70\u548c\u8d85\u58f0\u901f\u6a2a\u6d41\u5c04\u6d41\u7b49\u4ee3\u8868\u6027\u71c3\u70e7\u5e94\u7528\u4e2d\uff0c\u76f8\u6bd4\u521d\u59cbGPU\u5b9e\u73b0\u5b9e\u73b0\u4e862-5\u500d\u7684\u6027\u80fd\u63d0\u5347\uff0c\u57281-96\u4e2aNVIDIA H100 GPU\u4e0a\u5b9e\u73b0\u4e86\u63a5\u8fd1\u7406\u60f3\u7684\u5f31\u6269\u5c55\u6027\u3002\u5c4b\u9876\u7ebf\u5206\u6790\u663e\u793a\u5bf9\u6d41\uff08\u7ea610\u500d\uff09\u548c\u5316\u5b66\uff08\u7ea64\u500d\uff09\u4f8b\u7a0b\u7684\u7b97\u672f\u5f3a\u5ea6\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "\u8be5\u6c42\u89e3\u5668\u6709\u6548\u5229\u7528\u4e86GPU\u5185\u5b58\u5e26\u5bbd\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u4e3a\u9ad8\u901f\u5316\u5b66\u53cd\u5e94\u6d41\u7684\u9ad8\u6027\u80fd\u8ba1\u7b97\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.23643", "categories": ["cs.CR", "cs.AI", "cs.LG", "I.2.6; D.4.6"], "pdf": "https://arxiv.org/pdf/2510.23643", "abs": "https://arxiv.org/abs/2510.23643", "authors": ["Zhixin Pan", "Ziyu Shu", "Linh Nguyen", "Amberbir Alemayoh"], "title": "SAND: A Self-supervised and Adaptive NAS-Driven Framework for Hardware Trojan Detection", "comment": null, "summary": "The globalized semiconductor supply chain has made Hardware Trojans (HT) a\nsignificant security threat to embedded systems, necessitating the design of\nefficient and adaptable detection mechanisms. Despite promising machine\nlearning-based HT detection techniques in the literature, they suffer from ad\nhoc feature selection and the lack of adaptivity, all of which hinder their\neffectiveness across diverse HT attacks. In this paper, we propose SAND, a\nselfsupervised and adaptive NAS-driven framework for efficient HT detection.\nSpecifically, this paper makes three key contributions. (1) We leverage\nself-supervised learning (SSL) to enable automated feature extraction,\neliminating the dependency on manually engineered features. (2) SAND integrates\nneural architecture search (NAS) to dynamically optimize the downstream\nclassifier, allowing for seamless adaptation to unseen benchmarks with minimal\nfine-tuning. (3) Experimental results show that SAND achieves a significant\nimprovement in detection accuracy (up to 18.3%) over state-of-the-art methods,\nexhibits high resilience against evasive Trojans, and demonstrates strong\ngeneralization.", "AI": {"tldr": "SAND\u662f\u4e00\u4e2a\u81ea\u76d1\u7763\u548c\u81ea\u9002\u5e94NAS\u9a71\u52a8\u7684\u786c\u4ef6\u6728\u9a6c\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u5b9e\u73b0\u81ea\u52a8\u7279\u5f81\u63d0\u53d6\uff0c\u5229\u7528\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u52a8\u6001\u4f18\u5316\u5206\u7c7b\u5668\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u6d4b\u7cbe\u5ea6\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5168\u7403\u5316\u534a\u5bfc\u4f53\u4f9b\u5e94\u94fe\u4f7f\u786c\u4ef6\u6728\u9a6c\u6210\u4e3a\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u91cd\u5927\u5b89\u5168\u5a01\u80c1\uff0c\u73b0\u6709\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u68c0\u6d4b\u6280\u672f\u5b58\u5728\u7279\u5f81\u9009\u62e9\u968f\u610f\u548c\u7f3a\u4e4f\u81ea\u9002\u5e94\u6027\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u4e0d\u540c\u6728\u9a6c\u653b\u51fb\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faSAND\u6846\u67b6\uff1a1\uff09\u5229\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u5b9e\u73b0\u81ea\u52a8\u7279\u5f81\u63d0\u53d6\uff0c\u6d88\u9664\u5bf9\u4eba\u5de5\u8bbe\u8ba1\u7279\u5f81\u7684\u4f9d\u8d56\uff1b2\uff09\u96c6\u6210\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u52a8\u6001\u4f18\u5316\u4e0b\u6e38\u5206\u7c7b\u5668\uff0c\u53ea\u9700\u5c11\u91cf\u5fae\u8c03\u5373\u53ef\u9002\u5e94\u672a\u89c1\u8fc7\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cSAND\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u68c0\u6d4b\u7cbe\u5ea6\u663e\u8457\u63d0\u5347\uff08\u6700\u9ad818.3%\uff09\uff0c\u5bf9\u89c4\u907f\u6027\u6728\u9a6c\u5177\u6709\u9ad8\u5f39\u6027\uff0c\u5e76\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "SAND\u6846\u67b6\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u548c\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u7684\u7ed3\u5408\uff0c\u4e3a\u786c\u4ef6\u6728\u9a6c\u68c0\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u81ea\u9002\u5e94\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.23807", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23807", "abs": "https://arxiv.org/abs/2510.23807", "authors": ["Hamid R. Tizhoosh"], "title": "Why Foundation Models in Pathology Are Failing", "comment": null, "summary": "In non-medical domains, foundation models (FMs) have revolutionized computer\nvision and language processing through large-scale self-supervised and\nmultimodal learning. Consequently, their rapid adoption in computational\npathology was expected to deliver comparable breakthroughs in cancer diagnosis,\nprognostication, and multimodal retrieval. However, recent systematic\nevaluations reveal fundamental weaknesses: low diagnostic accuracy, poor\nrobustness, geometric instability, heavy computational demands, and concerning\nsafety vulnerabilities. This short paper examines these shortcomings and argues\nthat they stem from deeper conceptual mismatches between the assumptions\nunderlying generic foundation modeling in mainstream AI and the intrinsic\ncomplexity of human tissue. Seven interrelated causes are identified:\nbiological complexity, ineffective self-supervision, overgeneralization,\nexcessive architectural complexity, lack of domain-specific innovation,\ninsufficient data, and a fundamental design flaw related to tissue patch size.\nThese findings suggest that current pathology foundation models remain\nconceptually misaligned with the nature of tissue morphology and call for a\nfundamental rethinking of the paradigm itself.", "AI": {"tldr": "\u75c5\u7406\u5b66\u57fa\u7840\u6a21\u578b\u5728\u764c\u75c7\u8bca\u65ad\u548c\u9884\u540e\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u5b58\u5728\u8bca\u65ad\u51c6\u786e\u7387\u4f4e\u3001\u9c81\u68d2\u6027\u5dee\u3001\u51e0\u4f55\u4e0d\u7a33\u5b9a\u3001\u8ba1\u7b97\u9700\u6c42\u5927\u548c\u5b89\u5168\u6f0f\u6d1e\u7b49\u95ee\u9898\uff0c\u4e3b\u8981\u6e90\u4e8e\u901a\u7528\u57fa\u7840\u6a21\u578b\u5047\u8bbe\u4e0e\u4eba\u4f53\u7ec4\u7ec7\u5185\u5728\u590d\u6742\u6027\u4e4b\u95f4\u7684\u6982\u5ff5\u4e0d\u5339\u914d\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u7840\u6a21\u578b\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u8bed\u8a00\u5904\u7406\u9886\u57df\u53d6\u5f97\u4e86\u7a81\u7834\uff0c\u4f46\u5728\u8ba1\u7b97\u75c5\u7406\u5b66\u4e2d\u7684\u5feb\u901f\u5e94\u7528\u5e76\u672a\u5e26\u6765\u9884\u671f\u7684\u764c\u75c7\u8bca\u65ad\u548c\u9884\u540e\u7a81\u7834\uff0c\u53cd\u800c\u66b4\u9732\u51fa\u7cfb\u7edf\u6027\u5f31\u70b9\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u73b0\u6709\u75c5\u7406\u5b66\u57fa\u7840\u6a21\u578b\uff0c\u8bc6\u522b\u5176\u6839\u672c\u5f31\u70b9\uff0c\u5e76\u5206\u6790\u5bfc\u81f4\u8fd9\u4e9b\u95ee\u9898\u7684\u4e03\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u539f\u56e0\u3002", "result": "\u53d1\u73b0\u5f53\u524d\u75c5\u7406\u5b66\u57fa\u7840\u6a21\u578b\u5b58\u5728\u8bca\u65ad\u51c6\u786e\u7387\u4f4e\u3001\u9c81\u68d2\u6027\u5dee\u3001\u51e0\u4f55\u4e0d\u7a33\u5b9a\u3001\u8ba1\u7b97\u9700\u6c42\u5927\u548c\u5b89\u5168\u6f0f\u6d1e\u7b49\u7cfb\u7edf\u6027\u7f3a\u9677\u3002", "conclusion": "\u75c5\u7406\u5b66\u57fa\u7840\u6a21\u578b\u5728\u6982\u5ff5\u4e0a\u4e0e\u7ec4\u7ec7\u5f62\u6001\u5b66\u672c\u8d28\u4e0d\u5339\u914d\uff0c\u9700\u8981\u5bf9\u8303\u5f0f\u672c\u8eab\u8fdb\u884c\u6839\u672c\u6027\u91cd\u65b0\u601d\u8003\u3002"}}
{"id": "2510.24175", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.24175", "abs": "https://arxiv.org/abs/2510.24175", "authors": ["Nitin Shukla", "Alessandro Romeo", "Caterina Caravita", "Michael Redenti", "Radim Vavrik", "Lubomir Riha", "Andrea Mignone", "Marco Rossazza", "Stefano Truzzi", "Luca Tornatore", "Antonio Ragagnin", "Tiago Castro", "Geray S. Karademir", "Klaus Dolag", "Pranab J. Deka", "Fabio Bacchini", "Rostislav-Paul Wilhelm", "Daniele Gregori", "Elisabetta Boella"], "title": "Towards Exascale Computing for Astrophysical Simulation Leveraging the Leonardo EuroHPC System", "comment": null, "summary": "Developing and redesigning astrophysical, cosmological, and space plasma\nnumerical codes for existing and next-generation accelerators is critical for\nenabling large-scale simulations. To address these challenges, the SPACE Center\nof Excellence (SPACE-CoE) fosters collaboration between scientists, code\ndevelopers, and high-performance computing experts to optimize applications for\nthe exascale era. This paper presents our strategy and initial results on the\nLeonardo system at CINECA for three flagship codes, namely gPLUTO, OpenGadget3\nand iPIC3D, using profiling tools to analyze performance on single and multiple\nnodes. Preliminary tests show all three codes scale efficiently, reaching 80%\nscalability up to 1,024 GPUs.", "AI": {"tldr": "SPACE-CoE\u4e2d\u5fc3\u901a\u8fc7\u4f18\u5316gPLUTO\u3001OpenGadget3\u548ciPIC3D\u4e09\u4e2a\u65d7\u8230\u4ee3\u7801\uff0c\u5728Leonardo\u7cfb\u7edf\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe1,024\u4e2aGPU\u768480%\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u5929\u4f53\u7269\u7406\u6a21\u62df\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u4e3a\u73b0\u6709\u548c\u4e0b\u4e00\u4ee3\u52a0\u901f\u5668\u5f00\u53d1\u548c\u91cd\u65b0\u8bbe\u8ba1\u5929\u4f53\u7269\u7406\u3001\u5b87\u5b99\u5b66\u548c\u7a7a\u95f4\u7b49\u79bb\u5b50\u4f53\u6570\u503c\u4ee3\u7801\uff0c\u4ee5\u652f\u6301\u5927\u89c4\u6a21\u6a21\u62df\uff0c\u5e94\u5bf9exascale\u8ba1\u7b97\u65f6\u4ee3\u7684\u6311\u6218\u3002", "method": "\u901a\u8fc7SPACE-CoE\u4e2d\u5fc3\u4fc3\u8fdb\u79d1\u5b66\u5bb6\u3001\u4ee3\u7801\u5f00\u53d1\u8005\u548c\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e13\u5bb6\u4e4b\u95f4\u7684\u5408\u4f5c\uff0c\u4f7f\u7528\u6027\u80fd\u5206\u6790\u5de5\u5177\u5728CINECA\u7684Leonardo\u7cfb\u7edf\u4e0a\u5bf9\u4e09\u4e2a\u65d7\u8230\u4ee3\u7801\u8fdb\u884c\u5355\u8282\u70b9\u548c\u591a\u8282\u70b9\u6027\u80fd\u5206\u6790\u3002", "result": "\u521d\u6b65\u6d4b\u8bd5\u663e\u793a\u6240\u6709\u4e09\u4e2a\u4ee3\u7801\u90fd\u80fd\u9ad8\u6548\u6269\u5c55\uff0c\u57281,024\u4e2aGPU\u4e0a\u8fbe\u523080%\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "SPACE-CoE\u4e2d\u5fc3\u7684\u534f\u4f5c\u7b56\u7565\u6210\u529f\u4f18\u5316\u4e86\u5929\u4f53\u7269\u7406\u6a21\u62df\u4ee3\u7801\u5728exascale\u7cfb\u7edf\u4e0a\u7684\u6027\u80fd\uff0c\u4e3a\u5927\u89c4\u6a21\u79d1\u5b66\u8ba1\u7b97\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.24422", "categories": ["cs.CR", "cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24422", "abs": "https://arxiv.org/abs/2510.24422", "authors": ["Bijeet Basak", "Nupur Patil", "Kurian Polachan", "Srinivas Vivek"], "title": "Attack on a PUF-based Secure Binary Neural Network", "comment": "Accepted at VLSID 2026. To be published in IEEE Xplore", "summary": "Binarized Neural Networks (BNNs) deployed on memristive crossbar arrays\nprovide energy-efficient solutions for edge computing but are susceptible to\nphysical attacks due to memristor nonvolatility. Recently, Rajendran et al.\n(IEEE Embedded Systems Letter 2025) proposed a Physical Unclonable Function\n(PUF)-based scheme to secure BNNs against theft attacks. Specifically, the\nweight and bias matrices of the BNN layers were secured by swapping columns\nbased on device's PUF key bits.\n  In this paper, we demonstrate that this scheme to secure BNNs is vulnerable\nto PUF-key recovery attack. As a consequence of our attack, we recover the\nsecret weight and bias matrices of the BNN. Our approach is motivated by\ndifferential cryptanalysis and reconstructs the PUF key bit-by-bit by observing\nthe change in model accuracy, and eventually recovering the BNN model\nparameters. Evaluated on a BNN trained on the MNIST dataset, our attack could\nrecover 85% of the PUF key, and recover the BNN model up to 93% classification\naccuracy compared to the original model's 96% accuracy. Our attack is very\nefficient and it takes a couple of minutes to recovery the PUF key and the\nmodel parameters.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u4e86\u5bf9\u57fa\u4e8ePUF\u4fdd\u62a4\u7684BNN\u6a21\u578b\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u5dee\u5206\u5bc6\u7801\u5206\u6790\u6062\u590dPUF\u5bc6\u94a5\u548c\u6a21\u578b\u53c2\u6570\u3002", "motivation": "\u7531\u4e8e\u5fc6\u963b\u5668\u975e\u6613\u5931\u6027\uff0c\u90e8\u7f72\u5728\u5fc6\u963b\u4ea4\u53c9\u9635\u5217\u4e0a\u7684BNN\u5bb9\u6613\u53d7\u5230\u7269\u7406\u653b\u51fb\u3002\u867d\u7136\u5df2\u6709PUF\u65b9\u6848\u4fdd\u62a4BNN\uff0c\u4f46\u672c\u6587\u53d1\u73b0\u8be5\u65b9\u6848\u5b58\u5728\u6f0f\u6d1e\u3002", "method": "\u91c7\u7528\u5dee\u5206\u5bc6\u7801\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u89c2\u5bdf\u6a21\u578b\u51c6\u786e\u7387\u53d8\u5316\u6765\u9010\u4f4d\u6062\u590dPUF\u5bc6\u94a5\uff0c\u6700\u7ec8\u83b7\u53d6BNN\u6a21\u578b\u53c2\u6570\u3002", "result": "\u5728MNIST\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u653b\u51fb\u80fd\u591f\u6062\u590d85%\u7684PUF\u5bc6\u94a5\uff0c\u6062\u590d\u7684BNN\u6a21\u578b\u8fbe\u523093%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff08\u539f\u6a21\u578b96%\uff09\u3002\u653b\u51fb\u6548\u7387\u9ad8\uff0c\u4ec5\u9700\u51e0\u5206\u949f\u5373\u53ef\u5b8c\u6210\u3002", "conclusion": "\u73b0\u6709\u7684PUF\u4fdd\u62a4\u65b9\u6848\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u5b89\u5168\u673a\u5236\u6765\u4fdd\u62a4BNN\u6a21\u578b\u3002"}}
{"id": "2510.23822", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23822", "abs": "https://arxiv.org/abs/2510.23822", "authors": ["Zhenyu Zhang", "Tianyi Chen", "Weiran Xu", "Alex Pentland", "Jiaxin Pei"], "title": "ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents", "comment": null, "summary": "Long-horizon tasks requiring multi-step reasoning and dynamic re-planning\nremain challenging for large language models (LLMs). Sequential prompting\nmethods are prone to context drift, loss of goal information, and recurrent\nfailure cycles, while hierarchical prompting methods often weaken cross-level\ncontinuity or incur substantial runtime overhead. We introduce ReCAP (Recursive\nContext-Aware Reasoning and Planning), a hierarchical framework with shared\ncontext for reasoning and planning in LLMs. ReCAP combines three key\nmechanisms: (i) plan-ahead decomposition, in which the model generates a full\nsubtask list, executes the first item, and refines the remainder; (ii)\nstructured re-injection of parent plans, maintaining consistent multi-level\ncontext during recursive return; and (iii) memory-efficient execution, bounding\nthe active prompt so costs scale linearly with task depth. Together these\nmechanisms align high-level goals with low-level actions, reduce redundant\nprompting, and preserve coherent context updates across recursion. Experiments\ndemonstrate that ReCAP substantially improves subgoal alignment and success\nrates on various long-horizon reasoning benchmarks, achieving a 32% gain on\nsynchronous Robotouille and a 29% improvement on asynchronous Robotouille under\nthe strict pass@1 protocol.", "AI": {"tldr": "ReCAP\u662f\u4e00\u4e2a\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5206\u5c42\u63a8\u7406\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u8ba1\u5212\u5206\u89e3\u3001\u7236\u8ba1\u5212\u7ed3\u6784\u5316\u91cd\u6ce8\u5165\u548c\u5185\u5b58\u9ad8\u6548\u6267\u884c\u673a\u5236\uff0c\u89e3\u51b3\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u7684\u4e0a\u4e0b\u6587\u6f02\u79fb\u548c\u76ee\u6807\u4fe1\u606f\u4e22\u5931\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9700\u8981\u591a\u6b65\u63a8\u7406\u548c\u52a8\u6001\u91cd\u89c4\u5212\u7684\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u9762\u4e34\u7684\u6311\u6218\uff0c\u5305\u62ec\u987a\u5e8f\u63d0\u793a\u65b9\u6cd5\u7684\u4e0a\u4e0b\u6587\u6f02\u79fb\u3001\u76ee\u6807\u4fe1\u606f\u4e22\u5931\u548c\u91cd\u590d\u5931\u8d25\u5faa\u73af\uff0c\u4ee5\u53ca\u5206\u5c42\u63d0\u793a\u65b9\u6cd5\u7684\u8de8\u7ea7\u8fde\u7eed\u6027\u51cf\u5f31\u548c\u8fd0\u884c\u65f6\u5f00\u9500\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u4e09\u4e2a\u5173\u952e\u673a\u5236\uff1a(i) \u8ba1\u5212\u63d0\u524d\u5206\u89e3\uff1a\u751f\u6210\u5b8c\u6574\u5b50\u4efb\u52a1\u5217\u8868\uff0c\u6267\u884c\u7b2c\u4e00\u9879\u5e76\u4f18\u5316\u5269\u4f59\u90e8\u5206\uff1b(ii) \u7ed3\u6784\u5316\u91cd\u6ce8\u5165\u7236\u8ba1\u5212\uff1a\u5728\u9012\u5f52\u8fd4\u56de\u65f6\u4fdd\u6301\u4e00\u81f4\u7684\u591a\u7ea7\u4e0a\u4e0b\u6587\uff1b(iii) \u5185\u5b58\u9ad8\u6548\u6267\u884c\uff1a\u9650\u5236\u6d3b\u52a8\u63d0\u793a\uff0c\u4f7f\u6210\u672c\u968f\u4efb\u52a1\u6df1\u5ea6\u7ebf\u6027\u6269\u5c55\u3002", "result": "\u5728\u591a\u4e2a\u957f\u65f6\u7a0b\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u5b50\u76ee\u6807\u5bf9\u9f50\u548c\u6210\u529f\u7387\uff0c\u5728\u540c\u6b65Robotouille\u4e0a\u83b7\u5f9732%\u7684\u63d0\u5347\uff0c\u5728\u5f02\u6b65Robotouille\u4e0a\u83b7\u5f9729%\u7684\u6539\u8fdb\uff08\u4e25\u683cpass@1\u534f\u8bae\uff09\u3002", "conclusion": "ReCAP\u6846\u67b6\u901a\u8fc7\u5c06\u9ad8\u5c42\u76ee\u6807\u4e0e\u4f4e\u5c42\u52a8\u4f5c\u5bf9\u9f50\u3001\u51cf\u5c11\u5197\u4f59\u63d0\u793a\u548c\u4fdd\u6301\u8de8\u9012\u5f52\u7684\u8fde\u8d2f\u4e0a\u4e0b\u6587\u66f4\u65b0\uff0c\u6709\u6548\u63d0\u5347\u4e86\u957f\u65f6\u7a0b\u4efb\u52a1\u7684\u63a8\u7406\u548c\u89c4\u5212\u80fd\u529b\u3002"}}
{"id": "2510.24205", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.24205", "abs": "https://arxiv.org/abs/2510.24205", "authors": ["Telmo Ribeiro", "Jos\u00e9 Proen\u00e7a", "M\u00e1rio Florido"], "title": "CoMPSeT: A Framework for Comparing Multiparty Session Types", "comment": "In Proceedings EXPRESS/SOS 2025, arXiv:2510.23211", "summary": "Concurrent systems are often complex and difficult to design. Choreographic\nlanguages, such as Multiparty Session Types (MPST), allow the description of\nglobal protocols of interactions by capturing valid patterns of interactions\nbetween participants. Many variations of MPST exist, each one with its rather\nspecific features and idiosyncrasies. Here we propose a tool (CoMPSeT) that\nprovides clearer insights over different features in existing MPST. We select a\nrepresentative set of MPST examples and provide mechanisms to combine different\nfeatures and to animate and compare the semantics of concrete examples. CoMPSeT\nis open-source, compiled into JavaScript, and can be directly executed from any\nbrowser, becoming useful both for researchers who want to better understand the\nlandscape of MPST and for teachers who want to explain global choreographies.", "AI": {"tldr": "CoMPSeT\u662f\u4e00\u4e2a\u5f00\u6e90\u5de5\u5177\uff0c\u7528\u4e8e\u5206\u6790\u548c\u6bd4\u8f83\u591a\u53c2\u4e0e\u65b9\u4f1a\u8bdd\u7c7b\u578b(MPST)\u7684\u4e0d\u540c\u7279\u6027\uff0c\u5e2e\u52a9\u7814\u7a76\u8005\u548c\u6559\u5e08\u66f4\u597d\u5730\u7406\u89e3\u5168\u5c40\u7f16\u6392\u534f\u8bae\u3002", "motivation": "\u5e76\u53d1\u7cfb\u7edf\u8bbe\u8ba1\u590d\u6742\uff0c\u73b0\u6709\u7684MPST\u53d8\u4f53\u5404\u6709\u7279\u5b9a\u529f\u80fd\u548c\u7279\u70b9\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u6bd4\u8f83\u5de5\u5177\u6765\u6e05\u6670\u5c55\u793a\u4e0d\u540c\u7279\u6027\u3002", "method": "\u9009\u62e9\u4ee3\u8868\u6027MPST\u793a\u4f8b\uff0c\u63d0\u4f9b\u673a\u5236\u6765\u7ec4\u5408\u4e0d\u540c\u7279\u6027\uff0c\u52a8\u753b\u5316\u5e76\u6bd4\u8f83\u5177\u4f53\u793a\u4f8b\u7684\u8bed\u4e49\uff0c\u5de5\u5177\u5f00\u6e90\u4e14\u53ef\u5728\u6d4f\u89c8\u5668\u4e2d\u76f4\u63a5\u6267\u884c\u3002", "result": "\u5f00\u53d1\u4e86CoMPSeT\u5de5\u5177\uff0c\u80fd\u591f\u76f4\u89c2\u5c55\u793a\u4e0d\u540cMPST\u7279\u6027\u7684\u8bed\u4e49\u5dee\u5f02\uff0c\u652f\u6301\u4ea4\u4e92\u5f0f\u5b66\u4e60\u548c\u6bd4\u8f83\u3002", "conclusion": "CoMPSeT\u4e3aMPST\u7814\u7a76\u8005\u548c\u6559\u5e08\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3\u5168\u5c40\u7f16\u6392\u534f\u8bae\u7684\u4e0d\u540c\u7279\u6027\u3002"}}
{"id": "2510.23824", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23824", "abs": "https://arxiv.org/abs/2510.23824", "authors": ["Murad Ismayilov", "Edwin Meriaux", "Shuo Wen", "Gregory Dudek"], "title": "Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models", "comment": "Accepted at MIT URTC 2025", "summary": "Coordinating multiple autonomous agents in shared environments under\ndecentralized conditions is a long-standing challenge in robotics and\nartificial intelligence. This work addresses the problem of decentralized goal\nassignment for multi-agent path planning, where agents independently generate\nranked preferences over goals based on structured representations of the\nenvironment, including grid visualizations and scenario data. After this\nreasoning phase, agents exchange their goal rankings, and assignments are\ndetermined by a fixed, deterministic conflict-resolution rule (e.g., agent\nindex ordering), without negotiation or iterative coordination. We\nsystematically compare greedy heuristics, optimal assignment, and large\nlanguage model (LLM)-based agents in fully observable grid-world settings. Our\nresults show that LLM-based agents, when provided with well-designed prompts\nand relevant quantitative information, can achieve near-optimal makespans and\nconsistently outperform traditional heuristics. These findings underscore the\npotential of language models for decentralized goal assignment in multi-agent\npath planning and highlight the importance of information structure in such\nsystems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u7684\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u76ee\u6807\u5206\u914d\u65b9\u6cd5\uff0c\u667a\u80fd\u4f53\u57fa\u4e8e\u73af\u5883\u7ed3\u6784\u5316\u8868\u793a\u72ec\u7acb\u751f\u6210\u76ee\u6807\u504f\u597d\u6392\u5e8f\uff0c\u901a\u8fc7\u56fa\u5b9a\u51b2\u7a81\u89e3\u51b3\u89c4\u5219\u8fdb\u884c\u5206\u914d\uff0c\u65e0\u9700\u534f\u5546\u6216\u8fed\u4ee3\u534f\u8c03\u3002", "motivation": "\u89e3\u51b3\u53bb\u4e2d\u5fc3\u5316\u6761\u4ef6\u4e0b\u591a\u667a\u80fd\u4f53\u5728\u5171\u4eab\u73af\u5883\u4e2d\u7684\u534f\u8c03\u6311\u6218\uff0c\u63a2\u7d22\u8bed\u8a00\u6a21\u578b\u5728\u53bb\u4e2d\u5fc3\u5316\u76ee\u6807\u5206\u914d\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u667a\u80fd\u4f53\u57fa\u4e8e\u7f51\u683c\u53ef\u89c6\u5316\u548c\u573a\u666f\u6570\u636e\u72ec\u7acb\u751f\u6210\u76ee\u6807\u504f\u597d\u6392\u5e8f\uff0c\u4ea4\u6362\u6392\u5e8f\u540e\u901a\u8fc7\u56fa\u5b9a\u786e\u5b9a\u6027\u51b2\u7a81\u89e3\u51b3\u89c4\u5219\uff08\u5982\u667a\u80fd\u4f53\u7d22\u5f15\u6392\u5e8f\uff09\u8fdb\u884c\u76ee\u6807\u5206\u914d\u3002", "result": "LLM\u667a\u80fd\u4f53\u5728\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u548c\u76f8\u5173\u5b9a\u91cf\u4fe1\u606f\u4e0b\uff0c\u80fd\u591f\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u5b8c\u5de5\u65f6\u95f4\uff0c\u5e76\u6301\u7eed\u4f18\u4e8e\u4f20\u7edf\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u5728\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u76ee\u6807\u5206\u914d\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4fe1\u606f\u7ed3\u6784\u5728\u6b64\u7c7b\u7cfb\u7edf\u4e2d\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.23847", "categories": ["cs.CR", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.23847", "abs": "https://arxiv.org/abs/2510.23847", "authors": ["Joel Poncha Lemayian", "Ghyslain Gagnon", "Kaiwen Zhang", "Pascal Giard"], "title": "EthVault: A Secure and Resource-Conscious FPGA-Based Ethereum Cold Wallet", "comment": "Under review for publication", "summary": "Cryptocurrency blockchain networks safeguard digital assets using\ncryptographic keys, with wallets playing a critical role in generating,\nstoring, and managing these keys. Wallets, typically categorized as hot and\ncold, offer varying degrees of security and convenience. However, they are\ngenerally software-based applications running on microcontrollers.\nConsequently, they are vulnerable to malware and side-channel attacks, allowing\nperpetrators to extract private keys by targeting critical algorithms, such as\nECC, which processes private keys to generate public keys and authorize\ntransactions. To address these issues, this work presents EthVault, the first\nhardware architecture for an Ethereum hierarchically deterministic cold wallet,\nfeaturing hardware implementations of key algorithms for secure key generation.\nAlso, an ECC architecture resilient to side-channel and timing attacks is\nproposed. Moreover, an architecture of the child key derivation function, a\nfundamental component of cryptocurrency wallets, is proposed. The design\nminimizes resource usage, meeting market demand for small, portable\ncryptocurrency wallets. FPGA implementation results validate the feasibility of\nthe proposed approach. The ECC architecture exhibits uniform execution behavior\nacross varying inputs, while the complete design utilizes only 27%, 7%, and 6%\nof LUTs, registers, and RAM blocks, respectively, on a Xilinx Zynq UltraScale+\nFPGA.", "AI": {"tldr": "EthVault\u662f\u9996\u4e2a\u7528\u4e8e\u4ee5\u592a\u574a\u5206\u5c42\u786e\u5b9a\u6027\u51b7\u94b1\u5305\u7684\u786c\u4ef6\u67b6\u6784\uff0c\u901a\u8fc7\u786c\u4ef6\u5b9e\u73b0\u5173\u952e\u7b97\u6cd5\u6765\u5b89\u5168\u751f\u6210\u5bc6\u94a5\uff0c\u5e76\u63d0\u51fa\u6297\u4fa7\u4fe1\u9053\u548c\u65f6\u5e8f\u653b\u51fb\u7684ECC\u67b6\u6784\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u8d44\u6e90\u4f7f\u7528\u3002", "motivation": "\u73b0\u6709\u7684\u52a0\u5bc6\u8d27\u5e01\u94b1\u5305\u901a\u5e38\u662f\u57fa\u4e8e\u8f6f\u4ef6\u7684\u5fae\u63a7\u5236\u5668\u5e94\u7528\uff0c\u5bb9\u6613\u53d7\u5230\u6076\u610f\u8f6f\u4ef6\u548c\u4fa7\u4fe1\u9053\u653b\u51fb\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u901a\u8fc7\u9488\u5bf9ECC\u7b49\u5173\u952e\u7b97\u6cd5\u63d0\u53d6\u79c1\u94a5\u3002", "method": "\u63d0\u51faEthVault\u786c\u4ef6\u67b6\u6784\uff0c\u5305\u62ec\u786c\u4ef6\u5b9e\u73b0\u7684\u5bc6\u94a5\u751f\u6210\u7b97\u6cd5\u3001\u6297\u4fa7\u4fe1\u9053\u548c\u65f6\u5e8f\u653b\u51fb\u7684ECC\u67b6\u6784\uff0c\u4ee5\u53ca\u5b50\u5bc6\u94a5\u6d3e\u751f\u51fd\u6570\u67b6\u6784\uff0c\u5e76\u5728FPGA\u4e0a\u5b9e\u73b0\u9a8c\u8bc1\u3002", "result": "FPGA\u5b9e\u73b0\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0cECC\u67b6\u6784\u5728\u4e0d\u540c\u8f93\u5165\u4e0b\u8868\u73b0\u51fa\u7edf\u4e00\u7684\u6267\u884c\u884c\u4e3a\uff0c\u5b8c\u6574\u8bbe\u8ba1\u5728Xilinx Zynq UltraScale+ FPGA\u4e0a\u4ec5\u4f7f\u7528\u4e8627%\u7684LUT\u30017%\u7684\u5bc4\u5b58\u5668\u548c6%\u7684RAM\u5757\u3002", "conclusion": "EthVault\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b89\u5168\u3001\u8d44\u6e90\u9ad8\u6548\u7684\u786c\u4ef6\u94b1\u5305\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u62b5\u5fa1\u4fa7\u4fe1\u9053\u548c\u65f6\u5e8f\u653b\u51fb\uff0c\u6ee1\u8db3\u5e02\u573a\u5bf9\u5c0f\u578b\u4fbf\u643a\u5f0f\u52a0\u5bc6\u8d27\u5e01\u94b1\u5305\u7684\u9700\u6c42\u3002"}}
{"id": "2510.23891", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23891", "abs": "https://arxiv.org/abs/2510.23891", "authors": ["Jiaqi Xue", "Yifei Zhao", "Mansour Al Ghanim", "Shangqian Gao", "Ruimin Sun", "Qian Lou", "Mengxin Zheng"], "title": "PRO: Enabling Precise and Robust Text Watermark for Open-Source LLMs", "comment": null, "summary": "Text watermarking for large language models (LLMs) enables model owners to\nverify text origin and protect intellectual property. While watermarking\nmethods for closed-source LLMs are relatively mature, extending them to\nopen-source models remains challenging, as developers cannot control the\ndecoding process. Consequently, owners of open-source LLMs lack practical means\nto verify whether text was generated by their models. A core difficulty lies in\nembedding watermarks directly into model weights without hurting detectability.\nA promising idea is to distill watermarks from a closed-source model into an\nopen one, but this suffers from (i) poor detectability due to mismatch between\nlearned and predefined patterns, and (ii) fragility to downstream modifications\nsuch as fine-tuning or model merging. To overcome these limitations, we propose\nPRO, a Precise and Robust text watermarking method for open-source LLMs. PRO\njointly trains a watermark policy model with the LLM, producing patterns that\nare easier for the model to learn and more consistent with detection criteria.\nA regularization term further simulates downstream perturbations and penalizes\ndegradation in watermark detectability, ensuring robustness under model edits.\nExperiments on open-source LLMs (e.g., LLaMA-3.2, LLaMA-3, Phi-2) show that PRO\nsubstantially improves both watermark detectability and resilience to model\nmodifications.", "AI": {"tldr": "PRO\u662f\u4e00\u79cd\u9488\u5bf9\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7cbe\u786e\u9c81\u68d2\u6587\u672c\u6c34\u5370\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u6c34\u5370\u7b56\u7565\u6a21\u578b\u4e0eLLM\uff0c\u89e3\u51b3\u4e86\u5f00\u6e90\u6a21\u578b\u6c34\u5370\u68c0\u6d4b\u6027\u5dee\u548c\u5bf9\u4e0b\u6e38\u4fee\u6539\u8106\u5f31\u7684\u95ee\u9898\u3002", "motivation": "\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u5b9e\u7528\u7684\u6587\u672c\u6765\u6e90\u9a8c\u8bc1\u624b\u6bb5\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u6a21\u578b\u6743\u91cd\u4e2d\u76f4\u63a5\u5d4c\u5165\u6c34\u5370\u800c\u4e0d\u635f\u5bb3\u68c0\u6d4b\u6027\uff0c\u4e14\u84b8\u998f\u65b9\u6cd5\u5b58\u5728\u68c0\u6d4b\u6027\u5dee\u548c\u5bf9\u4e0b\u6e38\u4fee\u6539\u8106\u5f31\u7684\u95ee\u9898\u3002", "method": "PRO\u8054\u5408\u8bad\u7ec3\u6c34\u5370\u7b56\u7565\u6a21\u578b\u4e0eLLM\uff0c\u751f\u6210\u6613\u4e8e\u6a21\u578b\u5b66\u4e60\u4e14\u4e0e\u68c0\u6d4b\u6807\u51c6\u4e00\u81f4\u7684\u6a21\u5f0f\uff0c\u901a\u8fc7\u6b63\u5219\u5316\u9879\u6a21\u62df\u4e0b\u6e38\u6270\u52a8\u5e76\u60e9\u7f5a\u6c34\u5370\u68c0\u6d4b\u6027\u9000\u5316\uff0c\u786e\u4fdd\u6a21\u578b\u7f16\u8f91\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5728LLaMA-3.2\u3001LLaMA-3\u3001Phi-2\u7b49\u5f00\u6e90LLM\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPRO\u663e\u8457\u63d0\u9ad8\u4e86\u6c34\u5370\u68c0\u6d4b\u6027\u548c\u5bf9\u6a21\u578b\u4fee\u6539\u7684\u97e7\u6027\u3002", "conclusion": "PRO\u4e3a\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cbe\u786e\u4e14\u9c81\u68d2\u7684\u6587\u672c\u6c34\u5370\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u68c0\u6d4b\u6027\u5dee\u548c\u6a21\u578b\u4fee\u6539\u8106\u5f31\u6027\u7684\u6838\u5fc3\u6311\u6218\u3002"}}
{"id": "2510.23881", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23881", "abs": "https://arxiv.org/abs/2510.23881", "authors": ["Xidong Feng", "Vivek Veeriah", "Marcus Chiam", "Michael Dennis", "Ryan Pachauri", "Thomas Tumiel", "Federico Barbero", "Johan Obando-Ceron", "Jiaxin Shi", "Satinder Singh", "Shaobo Hou", "Nenad Toma\u0161ev", "Tom Zahavy"], "title": "Generating Creative Chess Puzzles", "comment": null, "summary": "While Generative AI rapidly advances in various domains, generating truly\ncreative, aesthetic, and counter-intuitive outputs remains a challenge. This\npaper presents an approach to tackle these difficulties in the domain of chess\npuzzles. We start by benchmarking Generative AI architectures, and then\nintroduce an RL framework with novel rewards based on chess engine search\nstatistics to overcome some of those shortcomings. The rewards are designed to\nenhance a puzzle's uniqueness, counter-intuitiveness, diversity, and realism.\nOur RL approach dramatically increases counter-intuitive puzzle generation by\n10x, from 0.22\\% (supervised) to 2.5\\%, surpassing existing dataset rates\n(2.1\\%) and the best Lichess-trained model (0.4\\%). Our puzzles meet novelty\nand diversity benchmarks, retain aesthetic themes, and are rated by human\nexperts as more creative, enjoyable, and counter-intuitive than composed book\npuzzles, even approaching classic compositions. Our final outcome is a curated\nbooklet of these AI-generated puzzles, which is acknowledged for creativity by\nthree world-renowned experts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u56fd\u9645\u8c61\u68cb\u8c1c\u9898\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bbe\u8ba1\u57fa\u4e8e\u8c61\u68cb\u5f15\u64ce\u641c\u7d22\u7edf\u8ba1\u7684\u65b0\u578b\u5956\u52b1\u51fd\u6570\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8c1c\u9898\u7684\u53cd\u76f4\u89c9\u6027\u3001\u72ec\u7279\u6027\u548c\u591a\u6837\u6027\u3002", "motivation": "\u5c3d\u7ba1\u751f\u6210\u5f0fAI\u5728\u5404\u4e2a\u9886\u57df\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u5728\u751f\u6210\u771f\u6b63\u5177\u6709\u521b\u9020\u6027\u3001\u7f8e\u5b66\u4ef7\u503c\u548c\u53cd\u76f4\u89c9\u6027\u7684\u8f93\u51fa\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u56fd\u9645\u8c61\u68cb\u8c1c\u9898\u9886\u57df\u3002", "method": "\u9996\u5148\u5bf9\u751f\u6210\u5f0fAI\u67b6\u6784\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7136\u540e\u5f15\u5165\u57fa\u4e8e\u8c61\u68cb\u5f15\u64ce\u641c\u7d22\u7edf\u8ba1\u7684\u65b0\u578b\u5956\u52b1\u51fd\u6570\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u65e8\u5728\u589e\u5f3a\u8c1c\u9898\u7684\u72ec\u7279\u6027\u3001\u53cd\u76f4\u89c9\u6027\u3001\u591a\u6837\u6027\u548c\u771f\u5b9e\u6027\u3002", "result": "\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5c06\u53cd\u76f4\u89c9\u8c1c\u9898\u751f\u6210\u7387\u4ece0.22%\uff08\u76d1\u7763\u5b66\u4e60\uff09\u5927\u5e45\u63d0\u5347\u81f32.5%\uff0c\u8d85\u8fc7\u4e86\u73b0\u6709\u6570\u636e\u96c6\uff082.1%\uff09\u548c\u6700\u4f73Lichess\u8bad\u7ec3\u6a21\u578b\uff080.4%\uff09\u3002\u751f\u6210\u7684\u8c1c\u9898\u6ee1\u8db3\u65b0\u9896\u6027\u548c\u591a\u6837\u6027\u6807\u51c6\uff0c\u4fdd\u7559\u4e86\u7f8e\u5b66\u4e3b\u9898\uff0c\u5e76\u88ab\u4eba\u7c7b\u4e13\u5bb6\u8bc4\u4e3a\u6bd4\u4f20\u7edf\u4e66\u7c4d\u8c1c\u9898\u66f4\u5177\u521b\u9020\u6027\u3001\u8da3\u5473\u6027\u548c\u53cd\u76f4\u89c9\u6027\uff0c\u751a\u81f3\u63a5\u8fd1\u7ecf\u5178\u4f5c\u54c1\u6c34\u5e73\u3002", "conclusion": "\u6700\u7ec8\u6210\u679c\u662f\u4e00\u672c\u7ecf\u8fc7\u7cbe\u5fc3\u7b5b\u9009\u7684AI\u751f\u6210\u8c1c\u9898\u96c6\uff0c\u83b7\u5f97\u4e86\u4e09\u4f4d\u4e16\u754c\u77e5\u540d\u4e13\u5bb6\u7684\u521b\u9020\u529b\u8ba4\u53ef\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u751f\u6210\u9ad8\u8d28\u91cf\u521b\u9020\u6027\u5185\u5bb9\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.23927", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.23927", "abs": "https://arxiv.org/abs/2510.23927", "authors": ["Daniel Spokoyny", "Nikolai Vogler", "Xin Gao", "Tianyi Zheng", "Yufei Weng", "Jonghyun Park", "Jiajun Jiao", "Geoffrey M. Voelker", "Stefan Savage", "Taylor Berg-Kirkpatrick"], "title": "Victim as a Service: Designing a System for Engaging with Interactive Scammers", "comment": null, "summary": "Pig butchering, and similar interactive online scams, lower their victims'\ndefenses by building trust over extended periods of conversation - sometimes\nweeks or months. They have become increasingly public losses (at least $75B by\none recent study). However, because of their long-term conversational nature,\nthey are extremely challenging to investigate at scale. In this paper, we\ndescribe the motivation, design, implementation, and experience with\nCHATTERBOX, an LLM-based system that automates long-term engagement with online\nscammers, making large-scale investigations of their tactics possible. We\ndescribe the techniques we have developed to attract scam attempts, the system\nand LLM-engineering required to convincingly engage with scammers, and the\nnecessary capabilities required to satisfy or evade \"milestones\" in scammers'\nworkflow.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86CHATTERBOX\u7cfb\u7edf\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u4e0e\u5728\u7ebf\u8bc8\u9a97\u8005\u8fdb\u884c\u957f\u671f\u4e92\u52a8\uff0c\u4ee5\u5927\u89c4\u6a21\u8c03\u67e5\u4ed6\u4eec\u7684\u7b56\u7565\u3002", "motivation": "\u6740\u732a\u76d8\u7b49\u5728\u7ebf\u8bc8\u9a97\u901a\u8fc7\u957f\u671f\u5bf9\u8bdd\u5efa\u7acb\u4fe1\u4efb\u6765\u964d\u4f4e\u53d7\u5bb3\u8005\u9632\u5fa1\uff0c\u9020\u6210\u5de8\u5927\u7ecf\u6d4e\u635f\u5931\uff08\u81f3\u5c11750\u4ebf\u7f8e\u5143\uff09\uff0c\u4f46\u7531\u4e8e\u5176\u957f\u671f\u5bf9\u8bdd\u6027\u8d28\uff0c\u96be\u4ee5\u5927\u89c4\u6a21\u8c03\u67e5\u3002", "method": "\u5f00\u53d1\u4e86CHATTERBOX\u7cfb\u7edf\uff0c\u4f7f\u7528LLM\u6280\u672f\u81ea\u52a8\u5316\u4e0e\u8bc8\u9a97\u8005\u8fdb\u884c\u957f\u671f\u4e92\u52a8\uff0c\u5305\u62ec\u5438\u5f15\u8bc8\u9a97\u5c1d\u8bd5\u7684\u6280\u672f\u3001\u7cfb\u7edf\u8bbe\u8ba1\u548cLLM\u5de5\u7a0b\uff0c\u4ee5\u53ca\u6ee1\u8db3\u6216\u89c4\u907f\u8bc8\u9a97\u8005\u5de5\u4f5c\u6d41\u7a0b\u4e2d\"\u91cc\u7a0b\u7891\"\u7684\u5fc5\u8981\u80fd\u529b\u3002", "result": "\u8be5\u7cfb\u7edf\u4f7f\u5f97\u5927\u89c4\u6a21\u8c03\u67e5\u8bc8\u9a97\u8005\u7b56\u7565\u6210\u4e3a\u53ef\u80fd\u3002", "conclusion": "CHATTERBOX\u7cfb\u7edf\u4e3a\u89e3\u51b3\u957f\u671f\u5728\u7ebf\u8bc8\u9a97\u8c03\u67e5\u7684\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2510.23938", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23938", "abs": "https://arxiv.org/abs/2510.23938", "authors": ["Marcin Spoczynski", "Marcela S. Melara"], "title": "Scalable GPU-Based Integrity Verification for Large Machine Learning Models", "comment": null, "summary": "We present a security framework that strengthens distributed machine learning\nby standardizing integrity protections across CPU and GPU platforms and\nsignificantly reducing verification overheads. Our approach co-locates\nintegrity verification directly with large ML model execution on GPU\naccelerators, resolving the fundamental mismatch between how large ML workloads\ntypically run (primarily on GPUs) and how security verifications traditionally\noperate (on separate CPU-based processes), delivering both immediate\nperformance benefits and long-term architectural consistency. By performing\ncryptographic operations natively on GPUs using dedicated compute units (e.g.,\nIntel Arc's XMX units, NVIDIA's Tensor Cores), our solution eliminates the\npotential architectural bottlenecks that could plague traditional CPU-based\nverification systems when dealing with large models. This approach leverages\nthe same GPU-based high-memory bandwidth and parallel processing primitives\nthat power ML workloads ensuring integrity checks keep pace with model\nexecution even for massive models exceeding 100GB. This framework establishes a\ncommon integrity verification mechanism that works consistently across\ndifferent GPU vendors and hardware configurations. By anticipating future\ncapabilities for creating secure channels between trusted execution\nenvironments and GPU accelerators, we provide a hardware-agnostic foundation\nthat enterprise teams can deploy regardless of their underlying CPU and GPU\ninfrastructures.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5b89\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u5728CPU\u548cGPU\u5e73\u53f0\u4e0a\u6807\u51c6\u5316\u5b8c\u6574\u6027\u4fdd\u62a4\u5e76\u663e\u8457\u51cf\u5c11\u9a8c\u8bc1\u5f00\u9500\u6765\u52a0\u5f3a\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u3002\u8be5\u65b9\u6cd5\u5c06\u5b8c\u6574\u6027\u9a8c\u8bc1\u76f4\u63a5\u4e0eGPU\u52a0\u901f\u5668\u4e0a\u7684\u5927\u578bML\u6a21\u578b\u6267\u884c\u534f\u540c\u5b9a\u4f4d\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfCPU\u9a8c\u8bc1\u4e0eGPU\u8ba1\u7b97\u4e0d\u5339\u914d\u7684\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u4e3b\u8981\u5728GPU\u4e0a\u8fd0\u884c\uff0c\u800c\u5b89\u5168\u9a8c\u8bc1\u4f20\u7edf\u4e0a\u5728\u5355\u72ec\u7684\u57fa\u4e8eCPU\u7684\u8fdb\u7a0b\u4e0a\u8fd0\u884c\u4e4b\u95f4\u7684\u6839\u672c\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u63d0\u4f9b\u5373\u65f6\u6027\u80fd\u4f18\u52bf\u548c\u957f\u671f\u67b6\u6784\u4e00\u81f4\u6027\u3002", "method": "\u4f7f\u7528\u4e13\u7528\u8ba1\u7b97\u5355\u5143\uff08\u5982Intel Arc\u7684XMX\u5355\u5143\u3001NVIDIA\u7684Tensor Cores\uff09\u5728GPU\u4e0a\u672c\u5730\u6267\u884c\u52a0\u5bc6\u64cd\u4f5c\uff0c\u5229\u7528GPU\u7684\u9ad8\u5185\u5b58\u5e26\u5bbd\u548c\u5e76\u884c\u5904\u7406\u539f\u8bed\uff0c\u786e\u4fdd\u5b8c\u6574\u6027\u68c0\u67e5\u4e0e\u6a21\u578b\u6267\u884c\u540c\u6b65\u3002", "result": "\u6d88\u9664\u4e86\u4f20\u7edf\u57fa\u4e8eCPU\u7684\u9a8c\u8bc1\u7cfb\u7edf\u5728\u5904\u7406\u5927\u578b\u6a21\u578b\u65f6\u53ef\u80fd\u51fa\u73b0\u7684\u67b6\u6784\u74f6\u9888\uff0c\u5373\u4f7f\u5bf9\u4e8e\u8d85\u8fc7100GB\u7684\u5927\u89c4\u6a21\u6a21\u578b\uff0c\u5b8c\u6574\u6027\u68c0\u67e5\u4e5f\u80fd\u8ddf\u4e0a\u6a21\u578b\u6267\u884c\u901f\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u5efa\u7acb\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u5b8c\u6574\u6027\u9a8c\u8bc1\u673a\u5236\uff0c\u53ef\u5728\u4e0d\u540c\u7684GPU\u4f9b\u5e94\u5546\u548c\u786c\u4ef6\u914d\u7f6e\u4e2d\u4e00\u81f4\u5de5\u4f5c\uff0c\u4e3a\u4f01\u4e1a\u56e2\u961f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u786c\u4ef6\u65e0\u5173\u7684\u57fa\u7840\uff0c\u65e0\u8bba\u5176\u5e95\u5c42CPU\u548cGPU\u57fa\u7840\u8bbe\u65bd\u5982\u4f55\u90fd\u53ef\u4ee5\u90e8\u7f72\u3002"}}
{"id": "2510.23883", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23883", "abs": "https://arxiv.org/abs/2510.23883", "authors": ["Shrestha Datta", "Shahriar Kabir Nahin", "Anshuman Chhabra", "Prasant Mohapatra"], "title": "Agentic AI Security: Threats, Defenses, Evaluation, and Open Challenges", "comment": null, "summary": "Agentic AI systems powered by large language models (LLMs) and endowed with\nplanning, tool use, memory, and autonomy, are emerging as powerful, flexible\nplatforms for automation. Their ability to autonomously execute tasks across\nweb, software, and physical environments creates new and amplified security\nrisks, distinct from both traditional AI safety and conventional software\nsecurity. This survey outlines a taxonomy of threats specific to agentic AI,\nreviews recent benchmarks and evaluation methodologies, and discusses defense\nstrategies from both technical and governance perspectives. We synthesize\ncurrent research and highlight open challenges, aiming to support the\ndevelopment of secure-by-design agent systems.", "AI": {"tldr": "\u672c\u6587\u8c03\u67e5\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fdAI\u7cfb\u7edf\u6240\u9762\u4e34\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u63d0\u51fa\u4e86\u5a01\u80c1\u5206\u7c7b\u6cd5\uff0c\u56de\u987e\u4e86\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u6280\u672f\u548c\u6cbb\u7406\u5c42\u9762\u7684\u9632\u5fa1\u7b56\u7565\u3002", "motivation": "\u667a\u80fdAI\u7cfb\u7edf\u5728\u7f51\u9875\u3001\u8f6f\u4ef6\u548c\u7269\u7406\u73af\u5883\u4e2d\u81ea\u4e3b\u6267\u884c\u4efb\u52a1\u7684\u80fd\u529b\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u8fd9\u4e9b\u98ce\u9669\u65e2\u4e0d\u540c\u4e8e\u4f20\u7edfAI\u5b89\u5168\uff0c\u4e5f\u4e0d\u540c\u4e8e\u5e38\u89c4\u8f6f\u4ef6\u5b89\u5168\uff0c\u9700\u8981\u4e13\u95e8\u7814\u7a76\u3002", "method": "\u91c7\u7528\u8c03\u67e5\u5206\u6790\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u667a\u80fdAI\u7279\u6709\u7684\u5a01\u80c1\u5206\u7c7b\u6cd5\uff0c\u56de\u987e\u4e86\u6700\u8fd1\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u4ece\u6280\u672f\u548c\u6cbb\u7406\u4e24\u4e2a\u89d2\u5ea6\u5206\u6790\u9632\u5fa1\u7b56\u7565\u3002", "result": "\u7cfb\u7edf\u68b3\u7406\u4e86\u5f53\u524d\u7814\u7a76\u73b0\u72b6\uff0c\u8bc6\u522b\u4e86\u667a\u80fdAI\u7cfb\u7edf\u7684\u72ec\u7279\u5b89\u5168\u5a01\u80c1\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u9632\u5fa1\u65b9\u6cd5\u3002", "conclusion": "\u667a\u80fdAI\u7cfb\u7edf\u9700\u8981\u91c7\u7528\u5b89\u5168\u8bbe\u8ba1\u539f\u5219\uff0c\u5f53\u524d\u7814\u7a76\u4e3a\u5f00\u53d1\u5b89\u5168\u7684\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u4f46\u4ecd\u5b58\u5728\u8bb8\u591a\u5f00\u653e\u6311\u6218\u9700\u8981\u89e3\u51b3\u3002"}}
{"id": "2510.23925", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23925", "abs": "https://arxiv.org/abs/2510.23925", "authors": ["Guohao Sun", "Hang Hua", "Jian Wang", "Jiebo Luo", "Sohail Dianat", "Majid Rabbani", "Raghuveer Rao", "Zhiqiang Tao"], "title": "Latent Chain-of-Thought for Visual Reasoning", "comment": "NeurIPS 2025", "summary": "Chain-of-thought (CoT) reasoning is critical for improving the\ninterpretability and reliability of Large Vision-Language Models (LVLMs).\nHowever, existing training algorithms such as SFT, PPO, and GRPO may not\ngeneralize well across unseen reasoning tasks and heavily rely on a biased\nreward model. To address this challenge, we reformulate reasoning in LVLMs as\nposterior inference and propose a scalable training algorithm based on\namortized variational inference. By leveraging diversity-seeking reinforcement\nlearning algorithms, we introduce a novel sparse reward function for\ntoken-level learning signals that encourage diverse, high-likelihood latent\nCoT, overcoming deterministic sampling limitations and avoiding reward hacking.\nAdditionally, we implement a Bayesian inference-scaling strategy that replaces\ncostly Best-of-N and Beam Search with a marginal likelihood to efficiently rank\noptimal rationales and answers. We empirically demonstrate that the proposed\nmethod enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in\nterms of effectiveness, generalization, and interpretability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u5206\u63a8\u7406\u7684LVLM\u8bad\u7ec3\u7b97\u6cd5\uff0c\u901a\u8fc7\u7a00\u758f\u5956\u52b1\u51fd\u6570\u548c\u8d1d\u53f6\u65af\u63a8\u7406\u6269\u5c55\u7b56\u7565\uff0c\u5728\u4e03\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8bad\u7ec3\u7b97\u6cd5\uff08\u5982SFT\u3001PPO\u3001GRPO\uff09\u5728\u672a\u89c1\u63a8\u7406\u4efb\u52a1\u4e0a\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u4e14\u8fc7\u5ea6\u4f9d\u8d56\u6709\u504f\u5956\u52b1\u6a21\u578b\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u63a8\u7406\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u5c06LVLM\u63a8\u7406\u91cd\u65b0\u8868\u8ff0\u4e3a\u540e\u9a8c\u63a8\u7406\u95ee\u9898\uff0c\u91c7\u7528\u644a\u9500\u53d8\u5206\u63a8\u7406\u7684\u6269\u5c55\u8bad\u7ec3\u7b97\u6cd5\uff0c\u5f15\u5165\u7a00\u758f\u5956\u52b1\u51fd\u6570\u9f13\u52b1\u591a\u6837\u5316\u9ad8\u4f3c\u7136\u6f5c\u5728CoT\uff0c\u5e76\u4f7f\u7528\u8d1d\u53f6\u65af\u63a8\u7406\u6269\u5c55\u7b56\u7565\u66ff\u4ee3\u6602\u8d35\u7684\u641c\u7d22\u65b9\u6cd5\u3002", "result": "\u5728\u4e03\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u5b9e\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6709\u6548\u6027\u3001\u6cdb\u5316\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u63d0\u5347\u4e86\u6700\u5148\u8fdb\u7684LVLM\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u53d8\u5206\u63a8\u7406\u7684\u8bad\u7ec3\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347LVLM\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2510.24101", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.24101", "abs": "https://arxiv.org/abs/2510.24101", "authors": ["Nam Tran", "Khoa Nguyen", "Dongxi Liu", "Josef Pieprzyk", "Willy Susilo"], "title": "Traceable Signatures from Lattices", "comment": "45 pages", "summary": "Traceable signatures (Kiayas et al., EUROCRYPT 2004) is an anonymous digital\nsignature system that extends the tracing power of the opening authority in\ngroup signatures. There are many known constructions of traceable signatures,\nbut all are based on number-theoretic/pairing assumptions. For such reason,\nthey may not be secure in the presence of quantum computers. This work revisits\nthe notion of traceable signatures and presents a lattice-based construction\nprovably secure in the quantum random oracle model (QROM).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u57fa\u4e8e\u683c\u7684\u3001\u5728\u91cf\u5b50\u968f\u673a\u9884\u8a00\u673a\u6a21\u578b\u4e0b\u53ef\u8bc1\u660e\u5b89\u5168\u7684\u53ef\u8ffd\u8e2a\u7b7e\u540d\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u4e8e\u6570\u8bba/\u914d\u5bf9\u5047\u8bbe\u7684\u65b9\u6848\u5728\u91cf\u5b50\u8ba1\u7b97\u673a\u9762\u524d\u53ef\u80fd\u4e0d\u5b89\u5168\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u53ef\u8ffd\u8e2a\u7b7e\u540d\u65b9\u6848\u90fd\u57fa\u4e8e\u6570\u8bba/\u914d\u5bf9\u5047\u8bbe\uff0c\u5728\u91cf\u5b50\u8ba1\u7b97\u673a\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u53ef\u80fd\u4e0d\u5b89\u5168\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u57fa\u4e8e\u683c\u7684\u6297\u91cf\u5b50\u5b89\u5168\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u683c\u5bc6\u7801\u5b66\u6784\u5efa\u53ef\u8ffd\u8e2a\u7b7e\u540d\u65b9\u6848\uff0c\u5e76\u5728\u91cf\u5b50\u968f\u673a\u9884\u8a00\u673a\u6a21\u578b\u4e0b\u8fdb\u884c\u5b89\u5168\u6027\u8bc1\u660e\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u9996\u4e2a\u57fa\u4e8e\u683c\u7684\u53ef\u8ffd\u8e2a\u7b7e\u540d\u65b9\u6848\uff0c\u5e76\u5728QROM\u4e0b\u8bc1\u660e\u4e86\u5176\u5b89\u5168\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u53ef\u8ffd\u8e2a\u7b7e\u540d\u63d0\u4f9b\u4e86\u6297\u91cf\u5b50\u5b89\u5168\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u586b\u8865\u4e86\u73b0\u6709\u65b9\u6848\u5728\u91cf\u5b50\u5b89\u5168\u65b9\u9762\u7684\u7a7a\u767d\u3002"}}
{"id": "2510.23942", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23942", "abs": "https://arxiv.org/abs/2510.23942", "authors": ["Sridhar Mahadevan"], "title": "Decentralized Causal Discovery using Judo Calculus", "comment": "54 pages", "summary": "We describe a theory and implementation of an intuitionistic decentralized\nframework for causal discovery using judo calculus, which is formally defined\nas j-stable causal inference using j-do-calculus in a topos of sheaves. In\nreal-world applications -- from biology to medicine and social science --\ncausal effects depend on regime (age, country, dose, genotype, or lab\nprotocol). Our proposed judo calculus formalizes this context dependence\nformally as local truth: a causal claim is proven true on a cover of regimes,\nnot everywhere at once. The Lawvere-Tierney modal operator j chooses which\nregimes are relevant; j-stability means the claim holds constructively and\nconsistently across that family. We describe an algorithmic and implementation\nframework for judo calculus, combining it with standard score-based,\nconstraint-based, and gradient-based causal discovery methods. We describe\nexperimental results on a range of domains, from synthetic to real-world\ndatasets from biology and economics. Our experimental results show the\ncomputational efficiency gained by the decentralized nature of sheaf-theoretic\ncausal discovery, as well as improved performance over classical causal\ndiscovery methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u76f4\u89c9\u4e3b\u4e49\u53bb\u4e2d\u5fc3\u5316\u6846\u67b6\u7684\u56e0\u679c\u53d1\u73b0\u7406\u8bba\u2014\u2014\u67d4\u9053\u6f14\u7b97\uff0c\u4f7f\u7528j-\u7a33\u5b9a\u56e0\u679c\u63a8\u7406\u548cj-do-\u6f14\u7b97\u5728\u5c42\u62d3\u6251\u4e2d\u5f62\u5f0f\u5316\u5904\u7406\u56e0\u679c\u6548\u5e94\u7684\u73af\u5883\u4f9d\u8d56\u6027\u3002", "motivation": "\u73b0\u5b9e\u5e94\u7528\u4e2d\u56e0\u679c\u6548\u5e94\u4f9d\u8d56\u4e8e\u5177\u4f53\u73af\u5883\uff08\u5982\u5e74\u9f84\u3001\u56fd\u5bb6\u3001\u5242\u91cf\u3001\u57fa\u56e0\u578b\u7b49\uff09\uff0c\u9700\u8981\u5f62\u5f0f\u5316\u5904\u7406\u8fd9\u79cd\u73af\u5883\u4f9d\u8d56\u6027\u3002", "method": "\u7ed3\u5408\u5c42\u7406\u8bba\u548cLawvere-Tierney\u6a21\u6001\u7b97\u5b50j\uff0c\u5f00\u53d1\u4e86\u67d4\u9053\u6f14\u7b97\u7b97\u6cd5\u6846\u67b6\uff0c\u5e76\u4e0e\u57fa\u4e8e\u5206\u6570\u3001\u7ea6\u675f\u548c\u68af\u5ea6\u7684\u6807\u51c6\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u76f8\u7ed3\u5408\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u57fa\u4e8e\u5c42\u7406\u8bba\u7684\u53bb\u4e2d\u5fc3\u5316\u56e0\u679c\u53d1\u73b0\u5177\u6709\u8ba1\u7b97\u6548\u7387\u4f18\u52bf\uff0c\u6027\u80fd\u4f18\u4e8e\u7ecf\u5178\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u3002", "conclusion": "\u67d4\u9053\u6f14\u7b97\u4e3a\u5904\u7406\u73af\u5883\u4f9d\u8d56\u7684\u56e0\u679c\u53d1\u73b0\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u548c\u6027\u80fd\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u52bf\u3002"}}
{"id": "2510.24141", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.24141", "abs": "https://arxiv.org/abs/2510.24141", "authors": ["Miao Zhang", "Shenao Wang", "Guilin Zheng", "Yanjie Zhao", "Haoyu Wang"], "title": "Demystifying Cookie Sharing Risks in WebView-based Mobile App-in-app Ecosystems", "comment": "To appear in the 40th IEEE/ACM International Conference on Automated\n  Software Engineering (ASE'25)", "summary": "Mini-programs, an emerging mobile application paradigm within super-apps,\noffer a seamless and installation-free experience. However, the adoption of the\nweb-view component has disrupted their isolation mechanisms, exposing new\nattack surfaces and vulnerabilities. In this paper, we introduce a novel\nvulnerability called Cross Mini-program Cookie Sharing (CMCS), which arises\nfrom the shared web-view environment across mini-programs. This vulnerability\nallows unauthorized data exchange across mini-programs by enabling one\nmini-program to access cookies set by another within the same web-view context,\nviolating isolation principles. As a preliminary step, we analyzed the web-view\nmechanisms of four major platforms, including WeChat, AliPay, TikTok, and\nBaidu, and found that all of them are affected by CMCS vulnerabilities.\nFurthermore, we demonstrate the collusion attack enabled by CMCS, where\nprivileged mini-programs exfiltrate sensitive user data via cookies accessible\nto unprivileged mini-programs. To measure the impact of collusion attacks\nenabled by CMCS vulnerabilities in the wild, we developed MiCoScan, a static\nanalysis tool that detects mini-programs affected by CMCS vulnerabilities.\nMiCoScan employs web-view context modeling to identify clusters of\nmini-programs sharing the same web-view domain and cross-webview data flow\nanalysis to detect sensitive data transmissions to/from web-views. Using\nMiCoScan, we conducted a large-scale analysis of 351,483 mini-programs,\nidentifying 45,448 clusters sharing web-view domains, 7,965 instances of\nprivileged data transmission, and 9,877 mini-programs vulnerable to collusion\nattacks. Our findings highlight the widespread prevalence and significant\nsecurity risks posed by CMCS vulnerabilities, underscoring the urgent need for\nimproved isolation mechanisms in mini-program ecosystems.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u4e86\u4e00\u79cd\u540d\u4e3a\u8de8\u5c0f\u7a0b\u5e8fCookie\u5171\u4eab\uff08CMCS\uff09\u7684\u65b0\u6f0f\u6d1e\uff0c\u8be5\u6f0f\u6d1e\u6e90\u4e8e\u5c0f\u7a0b\u5e8f\u4e2dweb-view\u7ec4\u4ef6\u7684\u5171\u4eab\u73af\u5883\uff0c\u5141\u8bb8\u4e0d\u540c\u5c0f\u7a0b\u5e8f\u4e4b\u95f4\u672a\u7ecf\u6388\u6743\u5730\u4ea4\u6362\u6570\u636e\uff0c\u7834\u574f\u4e86\u9694\u79bb\u673a\u5236\u3002", "motivation": "\u5c0f\u7a0b\u5e8f\u91c7\u7528web-view\u7ec4\u4ef6\u7834\u574f\u4e86\u539f\u6709\u7684\u9694\u79bb\u673a\u5236\uff0c\u66b4\u9732\u51fa\u65b0\u7684\u653b\u51fb\u9762\u548c\u6f0f\u6d1e\uff0c\u9700\u8981\u7814\u7a76\u8fd9\u4e9b\u5b89\u5168\u98ce\u9669\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u5206\u6790\u4e86\u56db\u5927\u5e73\u53f0\uff08\u5fae\u4fe1\u3001\u652f\u4ed8\u5b9d\u3001\u6296\u97f3\u3001\u767e\u5ea6\uff09\u7684web-view\u673a\u5236\uff0c\u5f00\u53d1\u4e86MiCoScan\u9759\u6001\u5206\u6790\u5de5\u5177\uff0c\u901a\u8fc7web-view\u4e0a\u4e0b\u6587\u5efa\u6a21\u548c\u8de8web-view\u6570\u636e\u6d41\u5206\u6790\u6765\u68c0\u6d4b\u53d7CMCS\u6f0f\u6d1e\u5f71\u54cd\u7684\u5c0f\u7a0b\u5e8f\u3002", "result": "\u5728351,483\u4e2a\u5c0f\u7a0b\u5e8f\u7684\u5927\u89c4\u6a21\u5206\u6790\u4e2d\uff0c\u53d1\u73b045,448\u4e2a\u5171\u4eabweb-view\u57df\u7684\u96c6\u7fa4\uff0c7,965\u4e2a\u7279\u6743\u6570\u636e\u4f20\u8f93\u5b9e\u4f8b\uff0c9,877\u4e2a\u5c0f\u7a0b\u5e8f\u6613\u53d7\u5408\u8c0b\u653b\u51fb\u3002", "conclusion": "CMCS\u6f0f\u6d1e\u5728\u5c0f\u7a0b\u5e8f\u751f\u6001\u4e2d\u5e7f\u6cdb\u5b58\u5728\u4e14\u5e26\u6765\u91cd\u5927\u5b89\u5168\u98ce\u9669\uff0c\u8feb\u5207\u9700\u8981\u6539\u8fdb\u9694\u79bb\u673a\u5236\u3002"}}
{"id": "2510.23965", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23965", "abs": "https://arxiv.org/abs/2510.23965", "authors": ["Aymane El Gadarri", "Ali Aouad", "Vivek F. Farias"], "title": "The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity", "comment": null, "summary": "Traditional LLM alignment methods are vulnerable to heterogeneity in human\npreferences. Fitting a na\\\"ive probabilistic model to pairwise comparison data\n(say over prompt-completion pairs) yields an inconsistent estimate of the\npopulation-average utility -a canonical measure of social welfare. We propose a\nnew method, dubbed the sign estimator, that provides a simple, provably\nconsistent, and efficient estimator by replacing cross-entropy with binary\nclassification loss in the aggregation step. This simple modification recovers\nconsistent ordinal alignment under mild assumptions and achieves the first\npolynomial finite-sample error bounds in this setting. In realistic simulations\nof LLM alignment using digital twins, the sign estimator substantially reduces\npreference distortion over a panel of simulated personas, cutting (angular)\nestimation error by nearly 35% and decreasing disagreement with true population\npreferences from 12% to 8% compared to standard RLHF. Our method also compares\nfavorably to panel data heuristics that explicitly model user heterogeneity and\nrequire tracking individual-level preference data-all while maintaining the\nimplementation simplicity of existing LLM alignment pipelines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u7b26\u53f7\u4f30\u8ba1\u5668\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u4ea4\u53c9\u71b5\u635f\u5931\u66ff\u6362\u4e3a\u4e8c\u5143\u5206\u7c7b\u635f\u5931\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfLLM\u5bf9\u9f50\u65b9\u6cd5\u5728\u4eba\u7c7b\u504f\u597d\u5f02\u8d28\u6027\u4e0b\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u53ef\u8bc1\u660e\u7684\u4e00\u81f4\u6027\u548c\u591a\u9879\u5f0f\u6709\u9650\u6837\u672c\u8bef\u5dee\u754c\u3002", "motivation": "\u4f20\u7edfLLM\u5bf9\u9f50\u65b9\u6cd5\u5bf9\u4eba\u7c7b\u504f\u597d\u7684\u5f02\u8d28\u6027\u5f88\u8106\u5f31\uff0c\u62df\u5408\u7b80\u5355\u7684\u6982\u7387\u6a21\u578b\u5230\u6210\u5bf9\u6bd4\u8f83\u6570\u636e\u4f1a\u4ea7\u751f\u4e0d\u4e00\u81f4\u7684\u7fa4\u4f53\u5e73\u5747\u6548\u7528\u4f30\u8ba1\uff0c\u8fd9\u662f\u793e\u4f1a\u798f\u5229\u7684\u89c4\u8303\u5ea6\u91cf\u3002", "method": "\u63d0\u51fa\u7b26\u53f7\u4f30\u8ba1\u5668\u65b9\u6cd5\uff0c\u5728\u805a\u5408\u6b65\u9aa4\u4e2d\u7528\u4e8c\u5143\u5206\u7c7b\u635f\u5931\u66ff\u6362\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\u6062\u590d\u4e00\u81f4\u7684\u6709\u5e8f\u5bf9\u9f50\uff0c\u5e76\u5b9e\u73b0\u8be5\u8bbe\u7f6e\u4e0b\u7684\u9996\u4e2a\u591a\u9879\u5f0f\u6709\u9650\u6837\u672c\u8bef\u5dee\u754c\u3002", "result": "\u5728\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u7684LLM\u5bf9\u9f50\u73b0\u5b9e\u6a21\u62df\u4e2d\uff0c\u7b26\u53f7\u4f30\u8ba1\u5668\u663e\u8457\u51cf\u5c11\u4e86\u6a21\u62df\u4eba\u7269\u9762\u677f\u4e0a\u7684\u504f\u597d\u5931\u771f\uff0c\u5c06\uff08\u89d2\u5ea6\uff09\u4f30\u8ba1\u8bef\u5dee\u964d\u4f4e\u4e86\u8fd135%\uff0c\u4e0e\u771f\u5b9e\u7fa4\u4f53\u504f\u597d\u7684\u5206\u6b67\u4ece12%\u964d\u81f38%\uff0c\u4f18\u4e8e\u6807\u51c6RLHF\u3002", "conclusion": "\u7b26\u53f7\u4f30\u8ba1\u5668\u5728\u4fdd\u6301\u73b0\u6709LLM\u5bf9\u9f50\u7ba1\u9053\u5b9e\u73b0\u7b80\u5355\u6027\u7684\u540c\u65f6\uff0c\u4f18\u4e8e\u660e\u786e\u5efa\u6a21\u7528\u6237\u5f02\u8d28\u6027\u5e76\u9700\u8981\u8ddf\u8e2a\u4e2a\u4f53\u7ea7\u504f\u597d\u6570\u636e\u7684\u9762\u677f\u6570\u636e\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002"}}
{"id": "2510.23989", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23989", "abs": "https://arxiv.org/abs/2510.23989", "authors": ["Shangde Gao", "Zelin Xu", "Zhe Jiang"], "title": "Learning Individual Movement Shifts After Urban Disruptions with Social Infrastructure Reliance", "comment": null, "summary": "Shifts in individual movement patterns following disruptive events can reveal\nchanging demands for community resources. However, predicting such shifts\nbefore disruptive events remains challenging for several reasons. First,\nmeasures are lacking for individuals' heterogeneous social infrastructure\nresilience (SIR), which directly influences their movement patterns, and\ncommonly used features are often limited or unavailable at scale, e.g.,\nsociodemographic characteristics. Second, the complex interactions between\nindividual movement patterns and spatial contexts have not been sufficiently\ncaptured. Third, individual-level movement may be spatially sparse and not\nwell-suited to traditional decision-making methods for movement predictions.\nThis study incorporates individuals' SIR into a conditioned deep learning model\nto capture the complex relationships between individual movement patterns and\nlocal spatial context using large-scale, sparse individual-level data. Our\nexperiments demonstrate that incorporating individuals' SIR and spatial context\ncan enhance the model's ability to predict post-event individual movement\npatterns. The conditioned model can capture the divergent shifts in movement\npatterns among individuals who exhibit similar pre-event patterns but differ in\nSIR.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e2a\u4f53\u793e\u4f1a\u57fa\u7840\u8bbe\u65bd\u97e7\u6027(SIR)\u7684\u6761\u4ef6\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u7834\u574f\u6027\u4e8b\u4ef6\u540e\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u7684\u53d8\u5316\u3002", "motivation": "\u9884\u6d4b\u7834\u574f\u6027\u4e8b\u4ef6\u524d\u7684\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u53d8\u5316\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u7f3a\u4e4f\u8861\u91cf\u4e2a\u4f53\u5f02\u8d28\u6027\u793e\u4f1a\u57fa\u7840\u8bbe\u65bd\u97e7\u6027\u7684\u65b9\u6cd5\uff0c\u4e14\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u4e0e\u7a7a\u95f4\u73af\u5883\u7684\u590d\u6742\u4ea4\u4e92\u5173\u7cfb\u672a\u88ab\u5145\u5206\u6355\u6349\u3002", "method": "\u5c06\u4e2a\u4f53\u7684SIR\u7eb3\u5165\u6761\u4ef6\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5229\u7528\u5927\u89c4\u6a21\u7a00\u758f\u4e2a\u4f53\u7ea7\u6570\u636e\u6355\u6349\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u4e0e\u5c40\u90e8\u7a7a\u95f4\u73af\u5883\u7684\u590d\u6742\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7ed3\u5408\u4e2a\u4f53SIR\u548c\u7a7a\u95f4\u73af\u5883\u53ef\u4ee5\u589e\u5f3a\u6a21\u578b\u9884\u6d4b\u4e8b\u4ef6\u540e\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u7684\u80fd\u529b\u3002\u6761\u4ef6\u6a21\u578b\u80fd\u591f\u6355\u6349\u5177\u6709\u76f8\u4f3c\u4e8b\u4ef6\u524d\u6a21\u5f0f\u4f46SIR\u4e0d\u540c\u7684\u4e2a\u4f53\u5728\u79fb\u52a8\u6a21\u5f0f\u4e0a\u7684\u5dee\u5f02\u53d8\u5316\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u5c06\u4e2a\u4f53\u793e\u4f1a\u57fa\u7840\u8bbe\u65bd\u97e7\u6027\u7eb3\u5165\u9884\u6d4b\u6a21\u578b\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u9884\u6d4b\u7834\u574f\u6027\u4e8b\u4ef6\u540e\u7684\u4e2a\u4f53\u79fb\u52a8\u884c\u4e3a\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2510.24393", "categories": ["cs.CR", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.24393", "abs": "https://arxiv.org/abs/2510.24393", "authors": ["Yan Meng", "Jiachun Li", "Matthew Pillari", "Arjun Deopujari", "Liam Brennan", "Hafsah Shamsie", "Haojin Zhu", "Yuan Tian"], "title": "Your Microphone Array Retains Your Identity: A Robust Voice Liveness Detection System for Smart Speakers", "comment": "This is a paper accepted by USENIX Security 2022. See:\n  https://www.usenix.org/conference/usenixsecurity22/presentation/meng", "summary": "Though playing an essential role in smart home systems, smart speakers are\nvulnerable to voice spoofing attacks. Passive liveness detection, which\nutilizes only the collected audio rather than the deployed sensors to\ndistinguish between live-human and replayed voices, has drawn increasing\nattention. However, it faces the challenge of performance degradation under the\ndifferent environmental factors as well as the strict requirement of the fixed\nuser gestures.\n  In this study, we propose a novel liveness feature, array fingerprint, which\nutilizes the microphone array inherently adopted by the smart speaker to\ndetermine the identity of collected audios. Our theoretical analysis\ndemonstrates that by leveraging the circular layout of microphones, compared\nwith existing schemes, array fingerprint achieves a more robust performance\nunder the environmental change and user's movement. Then, to leverage such a\nfingerprint, we propose ARRAYID, a lightweight passive detection scheme, and\nelaborate a series of features working together with array fingerprint. Our\nevaluation on the dataset containing 32,780 audio samples and 14 spoofing\ndevices shows that ARRAYID achieves an accuracy of 99.84%, which is superior to\nexisting passive liveness detection schemes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u9635\u5217\u6307\u7eb9\u7684\u65b0\u578b\u6d3b\u4f53\u68c0\u6d4b\u7279\u5f81\uff0c\u5229\u7528\u667a\u80fd\u97f3\u7bb1\u5185\u7f6e\u7684\u9ea6\u514b\u98ce\u9635\u5217\u6765\u533a\u5206\u771f\u5b9e\u4eba\u58f0\u548c\u91cd\u653e\u8bed\u97f3\u653b\u51fb\uff0c\u5e76\u5f00\u53d1\u4e86ARRAYID\u8f7b\u91cf\u7ea7\u68c0\u6d4b\u65b9\u6848\uff0c\u5728\u5305\u542b32,780\u4e2a\u97f3\u9891\u6837\u672c\u7684\u6570\u636e\u96c6\u4e0a\u8fbe\u523099.84%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u667a\u80fd\u97f3\u7bb1\u5728\u667a\u80fd\u5bb6\u5c45\u7cfb\u7edf\u4e2d\u626e\u6f14\u91cd\u8981\u89d2\u8272\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u8bed\u97f3\u6b3a\u9a97\u653b\u51fb\u3002\u73b0\u6709\u7684\u88ab\u52a8\u6d3b\u4f53\u68c0\u6d4b\u65b9\u6cd5\u9762\u4e34\u73af\u5883\u56e0\u7d20\u53d8\u5316\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u4ee5\u53ca\u56fa\u5b9a\u7528\u6237\u59ff\u52bf\u8981\u6c42\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u9635\u5217\u6307\u7eb9\u7279\u5f81\uff0c\u5229\u7528\u667a\u80fd\u97f3\u7bb1\u56fa\u6709\u7684\u5706\u5f62\u5e03\u5c40\u9ea6\u514b\u98ce\u9635\u5217\u6765\u786e\u5b9a\u97f3\u9891\u8eab\u4efd\uff1b\u5f00\u53d1ARRAYID\u8f7b\u91cf\u7ea7\u88ab\u52a8\u68c0\u6d4b\u65b9\u6848\uff0c\u7ed3\u5408\u4e00\u7cfb\u5217\u4e0e\u9635\u5217\u6307\u7eb9\u534f\u540c\u5de5\u4f5c\u7684\u7279\u5f81\u3002", "result": "\u5728\u5305\u542b32,780\u4e2a\u97f3\u9891\u6837\u672c\u548c14\u79cd\u6b3a\u9a97\u8bbe\u5907\u7684\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cARRAYID\u8fbe\u523099.84%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u88ab\u52a8\u6d3b\u4f53\u68c0\u6d4b\u65b9\u6848\u3002", "conclusion": "\u9635\u5217\u6307\u7eb9\u7279\u5f81\u5728\u73af\u5883\u53d8\u5316\u548c\u7528\u6237\u79fb\u52a8\u60c5\u51b5\u4e0b\u6bd4\u73b0\u6709\u65b9\u6848\u5177\u6709\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0cARRAYID\u68c0\u6d4b\u65b9\u6848\u5728\u8bed\u97f3\u6b3a\u9a97\u653b\u51fb\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u5353\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.24408", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.24408", "abs": "https://arxiv.org/abs/2510.24408", "authors": ["Yifan Wu", "Xuewei Feng", "Yuxiang Yang", "Ke Xu"], "title": "Uncovering Gaps Between RFC Updates and TCP/IP Implementations: LLM-Facilitated Differential Checks on Intermediate Representations", "comment": "15 pages, 7 figures", "summary": "As the core of the Internet infrastructure, the TCP/IP protocol stack\nundertakes the task of network data transmission. However, due to the\ncomplexity of the protocol and the uncertainty of cross-layer interaction,\nthere are often inconsistencies between the implementation of the protocol\nstack code and the RFC standard. This inconsistency may not only lead to\ndifferences in protocol functions but also cause serious security\nvulnerabilities. At present, with the continuous expansion of protocol stack\nfunctions and the rapid iteration of RFC documents, it is increasingly\nimportant to detect and fix these inconsistencies. With the rise of large\nlanguage models, researchers have begun to explore how to extract protocol\nspecifications from RFC documents through these models, including protocol\nstack modeling, state machine extraction, text ambiguity analysis, and other\nrelated content. However, existing methods rely on predefined patterns or\nrule-based approaches that fail to generalize across different protocol\nspecifications. Automated and scalable detection of these inconsistencies\nremains a significant challenge. In this study, we propose an automated\nanalysis framework based on LLM and differential models. By modeling the\niterative relationship of the protocol and based on the iterative update\nrelationship of the RFC standard, we perform incremental code function analysis\non different versions of kernel code implementations to automatically perform\ncode detection and vulnerability analysis. We conduct extensive evaluations to\nvalidate the effectiveness of our framework, demonstrating its effectiveness in\nidentifying potential vulnerabilities caused by RFC code inconsistencies.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLLM\u548c\u5dee\u5206\u6a21\u578b\u7684\u81ea\u52a8\u5316\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4bTCP/IP\u534f\u8bae\u6808\u5b9e\u73b0\u4e0eRFC\u6807\u51c6\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u8bc6\u522b\u6f5c\u5728\u5b89\u5168\u6f0f\u6d1e\u3002", "motivation": "TCP/IP\u534f\u8bae\u6808\u5b9e\u73b0\u4e0eRFC\u6807\u51c6\u4e4b\u95f4\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u53ef\u80fd\u5bfc\u81f4\u529f\u80fd\u5dee\u5f02\u548c\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u6a21\u5f0f\u6216\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\uff0c\u65e0\u6cd5\u8de8\u4e0d\u540c\u534f\u8bae\u89c4\u8303\u6cdb\u5316\uff0c\u81ea\u52a8\u5316\u68c0\u6d4b\u4ecd\u9762\u4e34\u6311\u6218\u3002", "method": "\u57fa\u4e8eLLM\u548c\u5dee\u5206\u6a21\u578b\u7684\u81ea\u52a8\u5316\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u6a21\u534f\u8bae\u7684\u8fed\u4ee3\u5173\u7cfb\uff0c\u57fa\u4e8eRFC\u6807\u51c6\u7684\u8fed\u4ee3\u66f4\u65b0\u5173\u7cfb\uff0c\u5bf9\u4e0d\u540c\u7248\u672c\u5185\u6838\u4ee3\u7801\u5b9e\u73b0\u8fdb\u884c\u589e\u91cf\u4ee3\u7801\u529f\u80fd\u5206\u6790\uff0c\u81ea\u52a8\u6267\u884c\u4ee3\u7801\u68c0\u6d4b\u548c\u6f0f\u6d1e\u5206\u6790\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u5176\u5728\u8bc6\u522b\u7531RFC\u4ee3\u7801\u4e0d\u4e00\u81f4\u6027\u5f15\u8d77\u7684\u6f5c\u5728\u6f0f\u6d1e\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eLLM\u548c\u5dee\u5206\u6a21\u578b\u7684\u81ea\u52a8\u5316\u5206\u6790\u6846\u67b6\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u534f\u8bae\u6808\u5b9e\u73b0\u4e0eRFC\u6807\u51c6\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u8bc6\u522b\u6f5c\u5728\u5b89\u5168\u6f0f\u6d1e\u3002"}}
{"id": "2510.24028", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24028", "abs": "https://arxiv.org/abs/2510.24028", "authors": ["Tingyue Pan", "Mingyue Cheng", "Shilong Zhang", "Zhiding Liu", "Xiaoyu Tao", "Yucong Luo", "Jintao Zhang", "Qi Liu"], "title": "OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting", "comment": null, "summary": "Cross-domain time series forecasting is a valuable task in various web\napplications. Despite its rapid advancement, achieving effective generalization\nacross heterogeneous time series data remains a significant challenge. Existing\nmethods have made progress by extending single-domain models, yet often fall\nshort when facing domain-specific trend shifts and inconsistent periodic\npatterns. We argue that a key limitation lies in treating temporal series as\nundifferentiated sequence, without explicitly decoupling their inherent\nstructural components. To address this, we propose OneCast, a structured and\nmodular forecasting framework that decomposes time series into seasonal and\ntrend components, each modeled through tailored generative pathways.\nSpecifically, the seasonal component is captured by a lightweight projection\nmodule that reconstructs periodic patterns via interpretable basis functions.\nIn parallel, the trend component is encoded into discrete tokens at segment\nlevel via a semantic-aware tokenizer, and subsequently inferred through a\nmasked discrete diffusion mechanism. The outputs from both branches are\ncombined to produce a final forecast that captures seasonal patterns while\ntracking domain-specific trends. Extensive experiments across eight domains\ndemonstrate that OneCast mostly outperforms state-of-the-art baselines.", "AI": {"tldr": "OneCast\u662f\u4e00\u4e2a\u7ed3\u6784\u5316\u3001\u6a21\u5757\u5316\u7684\u8de8\u57df\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u5206\u91cf\uff0c\u5206\u522b\u4f7f\u7528\u5b9a\u5236\u5316\u751f\u6210\u8def\u5f84\u8fdb\u884c\u5efa\u6a21\uff0c\u5728\u591a\u4e2a\u9886\u57df\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u8de8\u57df\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u9762\u4e34\u9886\u57df\u7279\u5b9a\u8d8b\u52bf\u53d8\u5316\u548c\u4e0d\u4e00\u81f4\u5468\u671f\u6027\u6a21\u5f0f\u7684\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5c06\u65f6\u95f4\u5e8f\u5217\u89c6\u4e3a\u672a\u5206\u5316\u7684\u5e8f\u5217\uff0c\u672a\u80fd\u663e\u5f0f\u89e3\u8026\u5176\u56fa\u6709\u7ed3\u6784\u7ec4\u4ef6\u3002", "method": "\u63d0\u51faOneCast\u6846\u67b6\uff1a1\uff09\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u5206\u91cf\uff1b2\uff09\u5b63\u8282\u6027\u5206\u91cf\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6295\u5f71\u6a21\u5757\u4f7f\u7528\u53ef\u89e3\u91ca\u57fa\u51fd\u6570\u91cd\u5efa\u5468\u671f\u6027\u6a21\u5f0f\uff1b3\uff09\u8d8b\u52bf\u5206\u91cf\u901a\u8fc7\u8bed\u4e49\u611f\u77e5\u5206\u8bcd\u5668\u7f16\u7801\u4e3a\u5206\u6bb5\u7ea7\u79bb\u6563token\uff0c\u5e76\u901a\u8fc7\u63a9\u7801\u79bb\u6563\u6269\u6563\u673a\u5236\u8fdb\u884c\u63a8\u65ad\uff1b4\uff09\u4e24\u4e2a\u5206\u652f\u8f93\u51fa\u7ed3\u5408\u751f\u6210\u6700\u7ec8\u9884\u6d4b\u3002", "result": "\u5728\u516b\u4e2a\u9886\u57df\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cOneCast\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "OneCast\u901a\u8fc7\u7ed3\u6784\u5316\u5206\u89e3\u548c\u6a21\u5757\u5316\u5efa\u6a21\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u57df\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6cdb\u5316\u6311\u6218\uff0c\u80fd\u591f\u540c\u65f6\u6355\u6349\u5b63\u8282\u6027\u6a21\u5f0f\u548c\u8ddf\u8e2a\u9886\u57df\u7279\u5b9a\u8d8b\u52bf\u3002"}}
{"id": "2510.24498", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24498", "abs": "https://arxiv.org/abs/2510.24498", "authors": ["Tejaswini Bollikonda"], "title": "Design and Optimization of Cloud Native Homomorphic Encryption Workflows for Privacy-Preserving ML Inference", "comment": "6 pages 2 figures, 2 tABLES", "summary": "As machine learning (ML) models become increasingly deployed through cloud\ninfrastructures, the confidentiality of user data during inference poses a\nsignificant security challenge. Homomorphic Encryption (HE) has emerged as a\ncompelling cryptographic technique that enables computation on encrypted data,\nallowing predictions to be generated without decrypting sensitive inputs.\nHowever, the integration of HE within large scale cloud native pipelines\nremains constrained by high computational overhead, orchestration complexity,\nand model compatibility issues.\n  This paper presents a systematic framework for the design and optimization of\ncloud native homomorphic encryption workflows that support privacy-preserving\nML inference. The proposed architecture integrates containerized HE modules\nwith Kubernetes-based orchestration, enabling elastic scaling and parallel\nencrypted computation across distributed environments. Furthermore,\noptimization strategies including ciphertext packing, polynomial modulus\nadjustment, and operator fusion are employed to minimize latency and resource\nconsumption while preserving cryptographic integrity. Experimental results\ndemonstrate that the proposed system achieves up to 3.2times inference\nacceleration and 40% reduction in memory utilization compared to conventional\nHE pipelines. These findings illustrate a practical pathway for deploying\nsecure ML-as-a-Service (MLaaS) systems that guarantee data confidentiality\nunder zero-trust cloud conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e91\u539f\u751f\u540c\u6001\u52a0\u5bc6\u6846\u67b6\uff0c\u7528\u4e8e\u9690\u79c1\u4fdd\u62a4\u7684\u673a\u5668\u5b66\u4e60\u63a8\u7406\uff0c\u901a\u8fc7\u5bb9\u5668\u5316\u548cKubernetes\u7f16\u6392\u5b9e\u73b0\u5206\u5e03\u5f0f\u52a0\u5bc6\u8ba1\u7b97\uff0c\u4f18\u5316\u7b56\u7565\u4f7f\u63a8\u7406\u901f\u5ea6\u63d0\u53473.2\u500d\uff0c\u5185\u5b58\u4f7f\u7528\u51cf\u5c1140%\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u4e91\u57fa\u7840\u8bbe\u65bd\u4e2d\u7684\u90e8\u7f72\uff0c\u7528\u6237\u6570\u636e\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u673a\u5bc6\u6027\u6210\u4e3a\u91cd\u8981\u5b89\u5168\u6311\u6218\u3002\u540c\u6001\u52a0\u5bc6\u867d\u7136\u80fd\u5b9e\u73b0\u52a0\u5bc6\u6570\u636e\u4e0a\u7684\u8ba1\u7b97\uff0c\u4f46\u5728\u5927\u89c4\u6a21\u4e91\u539f\u751f\u7ba1\u9053\u4e2d\u7684\u96c6\u6210\u4ecd\u53d7\u9650\u4e8e\u9ad8\u8ba1\u7b97\u5f00\u9500\u3001\u7f16\u6392\u590d\u6742\u6027\u548c\u6a21\u578b\u517c\u5bb9\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u7cfb\u7edf\u5316\u6846\u67b6\uff0c\u96c6\u6210\u5bb9\u5668\u5316HE\u6a21\u5757\u4e0eKubernetes\u7f16\u6392\uff0c\u5b9e\u73b0\u5f39\u6027\u6269\u5c55\u548c\u5206\u5e03\u5f0f\u52a0\u5bc6\u8ba1\u7b97\u3002\u91c7\u7528\u5bc6\u6587\u6253\u5305\u3001\u591a\u9879\u5f0f\u6a21\u6570\u8c03\u6574\u548c\u7b97\u5b50\u878d\u5408\u7b49\u4f18\u5316\u7b56\u7565\u6765\u51cf\u5c11\u5ef6\u8fdf\u548c\u8d44\u6e90\u6d88\u8017\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u6bd4\u4f20\u7edfHE\u7ba1\u9053\uff0c\u8be5\u7cfb\u7edf\u5b9e\u73b0\u4e86\u9ad8\u8fbe3.2\u500d\u7684\u63a8\u7406\u52a0\u901f\u548c40%\u7684\u5185\u5b58\u4f7f\u7528\u51cf\u5c11\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u5728\u96f6\u4fe1\u4efb\u4e91\u6761\u4ef6\u4e0b\u90e8\u7f72\u4fdd\u8bc1\u6570\u636e\u673a\u5bc6\u6027\u7684\u5b89\u5168MLaaS\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2510.24085", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24085", "abs": "https://arxiv.org/abs/2510.24085", "authors": ["Md. Shihab Uddin", "Md Nazmus Shakib", "Rahul Bhadani"], "title": "Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine Learning Approach", "comment": null, "summary": "The increasing adoption of electric vehicles (EVs) necessitates an\nunderstanding of their driving behavior to enhance traffic safety and develop\nsmart driving systems. This study compares classical and machine learning\nmodels for EV car following behavior. Classical models include the Intelligent\nDriver Model (IDM), Optimum Velocity Model (OVM), Optimal Velocity Relative\nVelocity (OVRV), and a simplified CACC model, while the machine learning\napproach employs a Random Forest Regressor. Using a real world dataset of an EV\nfollowing an internal combustion engine (ICE) vehicle under varied driving\nconditions, we calibrated classical model parameters by minimizing the RMSE\nbetween predictions and real data. The Random Forest model predicts\nacceleration using spacing, speed, and gap type as inputs. Results demonstrate\nthe Random Forest's superior accuracy, achieving RMSEs of 0.0046 (medium gap),\n0.0016 (long gap), and 0.0025 (extra long gap). Among physics based models,\nCACC performed best, with an RMSE of 2.67 for long gaps. These findings\nhighlight the machine learning model's performance across all scenarios. Such\nmodels are valuable for simulating EV behavior and analyzing mixed autonomy\ntraffic dynamics in EV integrated environments.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u7ecf\u5178\u6a21\u578b\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u7535\u52a8\u6c7d\u8f66\u8ddf\u8f66\u884c\u4e3a\u5efa\u6a21\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u968f\u673a\u68ee\u6797\u6a21\u578b\u5728\u6240\u6709\u573a\u666f\u4e0b\u90fd\u4f18\u4e8e\u7269\u7406\u6a21\u578b\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u8f66\u8ddd\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u968f\u7740\u7535\u52a8\u6c7d\u8f66\u7684\u666e\u53ca\uff0c\u9700\u8981\u7406\u89e3\u5176\u9a7e\u9a76\u884c\u4e3a\u4ee5\u63d0\u9ad8\u4ea4\u901a\u5b89\u5168\u548c\u5f00\u53d1\u667a\u80fd\u9a7e\u9a76\u7cfb\u7edf\uff0c\u7279\u522b\u662f\u5728EV\u4e0e\u5185\u71c3\u673a\u8f66\u8f86\u6df7\u5408\u4ea4\u901a\u73af\u5883\u4e2d\u3002", "method": "\u4f7f\u7528\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff0c\u6bd4\u8f83\u4e86IDM\u3001OVM\u3001OVRV\u3001\u7b80\u5316CACC\u7b49\u7ecf\u5178\u7269\u7406\u6a21\u578b\u548c\u968f\u673a\u68ee\u6797\u56de\u5f52\u5668\uff0c\u901a\u8fc7\u6700\u5c0f\u5316RMSE\u6765\u6821\u51c6\u6a21\u578b\u53c2\u6570\u3002", "result": "\u968f\u673a\u68ee\u6797\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u5728\u4e2d\u7b49\u3001\u957f\u548c\u8d85\u957f\u8f66\u8ddd\u4e0b\u7684RMSE\u5206\u522b\u4e3a0.0046\u30010.0016\u548c0.0025\uff1b\u5728\u7269\u7406\u6a21\u578b\u4e2d\uff0cCACC\u8868\u73b0\u6700\u597d\uff0c\u957f\u8f66\u8ddd\u4e0b\u7684RMSE\u4e3a2.67\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u7535\u52a8\u6c7d\u8f66\u8ddf\u8f66\u884c\u4e3a\u5efa\u6a21\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5bf9\u6a21\u62dfEV\u884c\u4e3a\u548c\u5206\u6790\u6df7\u5408\u81ea\u52a8\u9a7e\u9a76\u4ea4\u901a\u52a8\u6001\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2510.24115", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24115", "abs": "https://arxiv.org/abs/2510.24115", "authors": ["Sandeep Vissapragada", "Vikrant Sahu", "Gagan Raj Gupta", "Vandita Singh"], "title": "HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology", "comment": null, "summary": "For doctors to truly trust artificial intelligence, it can't be a black box.\nThey need to understand its reasoning, almost as if they were consulting a\ncolleague. We created HistoLens1 to be that transparent, collaborative partner.\nIt allows a pathologist to simply ask a question in plain English about a\ntissue slide--just as they would ask a trainee. Our system intelligently\ntranslates this question into a precise query for its AI engine, which then\nprovides a clear, structured report. But it doesn't stop there. If a doctor\never asks, \"Why?\", HistoLens can instantly provide a 'visual proof' for any\nfinding--a heatmap that points to the exact cells and regions the AI used for\nits analysis. We've also ensured the AI focuses only on the patient's tissue,\njust like a trained pathologist would, by teaching it to ignore distracting\nbackground noise. The result is a workflow where the pathologist remains the\nexpert in charge, using a trustworthy AI assistant to verify their insights and\nmake faster, more confident diagnoses.", "AI": {"tldr": "HistoLens\u662f\u4e00\u4e2a\u900f\u660e\u7684AI\u75c5\u7406\u5b66\u52a9\u624b\uff0c\u5141\u8bb8\u75c5\u7406\u5b66\u5bb6\u7528\u81ea\u7136\u8bed\u8a00\u63d0\u95ee\uff0c\u63d0\u4f9b\u7ed3\u6784\u5316\u62a5\u544a\u548c\u53ef\u89c6\u5316\u8bc1\u636e\uff0c\u8ba9\u533b\u751f\u4fdd\u6301\u4e3b\u5bfc\u5730\u4f4d\u7684\u540c\u65f6\u83b7\u5f97AI\u8f85\u52a9\u8bca\u65ad\u3002", "motivation": "\u4e3a\u4e86\u8ba9\u533b\u751f\u771f\u6b63\u4fe1\u4efbAI\uff0c\u9700\u8981\u6d88\u9664AI\u7684\u9ed1\u76d2\u7279\u6027\uff0c\u4f7f\u5176\u80fd\u591f\u50cf\u54a8\u8be2\u540c\u4e8b\u4e00\u6837\u7406\u89e3AI\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u5f00\u53d1\u4e86HistoLens\u7cfb\u7edf\uff0c\u80fd\u591f\u5c06\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u8f6c\u5316\u4e3a\u7cbe\u786e\u7684AI\u67e5\u8be2\uff0c\u63d0\u4f9b\u7ed3\u6784\u5316\u62a5\u544a\u548c\u70ed\u529b\u56fe\u53ef\u89c6\u5316\u8bc1\u636e\uff0c\u5e76\u8bad\u7ec3AI\u4e13\u6ce8\u4e8e\u60a3\u8005\u7ec4\u7ec7\u800c\u5ffd\u7565\u80cc\u666f\u566a\u58f0\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u5de5\u4f5c\u6d41\u7a0b\uff0c\u75c5\u7406\u5b66\u5bb6\u4f5c\u4e3a\u4e13\u5bb6\u4e3b\u5bfc\u8bca\u65ad\u8fc7\u7a0b\uff0c\u4f7f\u7528\u53ef\u4fe1\u8d56\u7684AI\u52a9\u624b\u9a8c\u8bc1\u89c1\u89e3\uff0c\u5b9e\u73b0\u66f4\u5feb\u3001\u66f4\u81ea\u4fe1\u7684\u8bca\u65ad\u3002", "conclusion": "HistoLens\u901a\u8fc7\u900f\u660e\u6027\u548c\u534f\u4f5c\u6027\u8bbe\u8ba1\uff0c\u6210\u529f\u5efa\u7acb\u4e86\u533b\u751f\u4e0eAI\u4e4b\u95f4\u7684\u4fe1\u4efb\u5173\u7cfb\uff0c\u4f7fAI\u6210\u4e3a\u75c5\u7406\u5b66\u5bb6\u7684\u53ef\u9760\u5408\u4f5c\u4f19\u4f34\u3002"}}
{"id": "2510.24161", "categories": ["cs.AI", "cs.MM", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24161", "abs": "https://arxiv.org/abs/2510.24161", "authors": ["Wentao Tan", "Bowen Wang", "Heng Zhi", "Chenyu Liu", "Zhe Li", "Jian Liu", "Zengrong Lin", "Yukun Dai", "Yipeng Chen", "Wenjie Yang", "Enci Xie", "Hao Xue", "Baixu Ji", "Chen Xu", "Zhibin Wang", "Tianshi Wang", "Lei Zhu", "Heng Tao Shen"], "title": "BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning", "comment": null, "summary": "Multimodal large language models (MLLMs) have advanced vision-language\nreasoning and are increasingly deployed in embodied agents. However,\nsignificant limitations remain: MLLMs generalize poorly across digital-physical\nspaces and embodiments; vision-language-action models (VLAs) produce low-level\nactions yet lack robust high-level embodied reasoning; and most embodied large\nlanguage models (ELLMs) are constrained to digital-space with poor\ngeneralization to the physical world. Thus, unified models that operate\nseamlessly across digital and physical spaces while generalizing across\nembodiments and tasks remain absent. We introduce the \\textbf{Boundless Large\nModel (BLM$_1$)}, a multimodal spatial foundation model that preserves\ninstruction following and reasoning, incorporates embodied knowledge, and\nsupports robust cross-embodiment control. BLM$_1$ integrates three key\ncapabilities -- \\textit{cross-space transfer, cross-task learning, and\ncross-embodiment generalization} -- via a two-stage training paradigm. Stage I\ninjects embodied knowledge into the MLLM through curated digital corpora while\nmaintaining language competence. Stage II trains a policy module through an\nintent-bridging interface that extracts high-level semantics from the MLLM to\nguide control, without fine-tuning the MLLM backbone. This process is supported\nby a self-collected cross-embodiment demonstration suite spanning four robot\nembodiments and six progressively challenging tasks. Evaluations across digital\nand physical benchmarks show that a single BLM$_1$ instance outperforms four\nmodel families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving\n$\\sim\\!\\textbf{6%}$ gains in digital tasks and $\\sim\\!\\textbf{3%}$ in physical\ntasks.", "AI": {"tldr": "BLM\u2081\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u5b9e\u73b0\u8de8\u7a7a\u95f4\u4f20\u8f93\u3001\u8de8\u4efb\u52a1\u5b66\u4e60\u548c\u8de8\u5177\u8eab\u6cdb\u5316\uff0c\u5728\u6570\u5b57\u548c\u7269\u7406\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709MLLM\u5728\u6570\u5b57-\u7269\u7406\u7a7a\u95f4\u548c\u5177\u8eab\u5316\u4e4b\u95f4\u6cdb\u5316\u80fd\u529b\u5dee\uff0cVLA\u7f3a\u4e4f\u9ad8\u7ea7\u5177\u8eab\u63a8\u7406\uff0cELLM\u5c40\u9650\u4e8e\u6570\u5b57\u7a7a\u95f4\uff0c\u56e0\u6b64\u9700\u8981\u7edf\u4e00\u7684\u8de8\u7a7a\u95f4\u548c\u8de8\u5177\u8eab\u5316\u6a21\u578b\u3002", "method": "\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u6570\u5b57\u8bed\u6599\u6ce8\u5165\u5177\u8eab\u77e5\u8bc6\uff0c\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u610f\u56fe\u6865\u63a5\u63a5\u53e3\u8bad\u7ec3\u7b56\u7565\u6a21\u5757\uff0c\u63d0\u53d6MLLM\u7684\u9ad8\u7ea7\u8bed\u4e49\u6765\u6307\u5bfc\u63a7\u5236\u3002", "result": "\u5355\u4e2aBLM\u2081\u5b9e\u4f8b\u5728\u6570\u5b57\u4efb\u52a1\u4e2d\u63d0\u5347\u7ea66%\uff0c\u5728\u7269\u7406\u4efb\u52a1\u4e2d\u63d0\u5347\u7ea63%\uff0c\u4f18\u4e8eMLLM\u3001ELLM\u3001VLA\u548cGMLM\u56db\u7c7b\u6a21\u578b\u3002", "conclusion": "BLM\u2081\u6210\u529f\u5b9e\u73b0\u4e86\u8de8\u7a7a\u95f4\u3001\u8de8\u4efb\u52a1\u548c\u8de8\u5177\u8eab\u5316\u7684\u7edf\u4e00\u5efa\u6a21\uff0c\u4e3a\u5177\u8eab\u667a\u80fd\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.24297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24297", "abs": "https://arxiv.org/abs/2510.24297", "authors": ["Robin Schm\u00f6cker", "Alexander Dockhorn", "Bodo Rosenhahn"], "title": "Investigating Intra-Abstraction Policies For Non-exact Abstraction Algorithms", "comment": null, "summary": "One weakness of Monte Carlo Tree Search (MCTS) is its sample efficiency which\ncan be addressed by building and using state and/or action abstractions in\nparallel to the tree search such that information can be shared among nodes of\nthe same layer. The primary usage of abstractions for MCTS is to enhance the\nUpper Confidence Bound (UCB) value during the tree policy by aggregating visits\nand returns of an abstract node. However, this direct usage of abstractions\ndoes not take the case into account where multiple actions with the same parent\nmight be in the same abstract node, as these would then all have the same UCB\nvalue, thus requiring a tiebreak rule. In state-of-the-art abstraction\nalgorithms such as pruned On the Go Abstractions (pruned OGA), this case has\nnot been noticed, and a random tiebreak rule was implicitly chosen. In this\npaper, we propose and empirically evaluate several alternative\nintra-abstraction policies, several of which outperform the random policy\nacross a majority of environments and parameter settings.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9MCTS\u4e2d\u62bd\u8c61\u5316\u6280\u672f\u7684\u4f7f\u7528\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u591a\u79cd\u5185\u90e8\u62bd\u8c61\u7b56\u7565\u6765\u66ff\u4ee3\u968f\u673a\u5e73\u5c40\u51b3\u80dc\u89c4\u5219\uff0c\u5e76\u5728\u591a\u6570\u73af\u5883\u548c\u53c2\u6570\u8bbe\u7f6e\u4e2d\u8868\u73b0\u4f18\u4e8e\u968f\u673a\u7b56\u7565\u3002", "motivation": "MCTS\u7684\u6837\u672c\u6548\u7387\u95ee\u9898\u53ef\u4ee5\u901a\u8fc7\u72b6\u6001\u548c\u52a8\u4f5c\u62bd\u8c61\u6765\u89e3\u51b3\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5982pruned OGA\u5728\u591a\u4e2a\u52a8\u4f5c\u5c5e\u4e8e\u540c\u4e00\u62bd\u8c61\u8282\u70b9\u65f6\u4f7f\u7528\u968f\u673a\u5e73\u5c40\u51b3\u80dc\u89c4\u5219\uff0c\u8fd9\u53ef\u80fd\u4e0d\u662f\u6700\u4f18\u9009\u62e9\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u8bc1\u8bc4\u4f30\u4e86\u591a\u79cd\u66ff\u4ee3\u7684\u5185\u90e8\u62bd\u8c61\u7b56\u7565\uff0c\u7528\u4e8e\u5904\u7406\u540c\u4e00\u62bd\u8c61\u8282\u70b9\u4e2d\u591a\u4e2a\u52a8\u4f5c\u5177\u6709\u76f8\u540cUCB\u503c\u7684\u60c5\u51b5\u3002", "result": "\u591a\u4e2a\u63d0\u51fa\u7684\u5185\u90e8\u62bd\u8c61\u7b56\u7565\u5728\u5927\u591a\u6570\u73af\u5883\u548c\u53c2\u6570\u8bbe\u7f6e\u4e2d\u8868\u73b0\u4f18\u4e8e\u968f\u673a\u7b56\u7565\u3002", "conclusion": "\u5728MCTS\u4e2d\u4f7f\u7528\u62bd\u8c61\u5316\u6280\u672f\u65f6\uff0c\u9009\u62e9\u5408\u9002\u7684\u5185\u90e8\u62bd\u8c61\u7b56\u7565\u5bf9\u6027\u80fd\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u968f\u673a\u5e73\u5c40\u51b3\u80dc\u89c4\u5219\u5e76\u975e\u603b\u662f\u6700\u4f18\u9009\u62e9\u3002"}}
{"id": "2510.24299", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24299", "abs": "https://arxiv.org/abs/2510.24299", "authors": ["Jiayu Liu", "Wei Dai", "Zhenya Huang", "Ning Miao", "Enhong Chen"], "title": "Verifying Large Language Models' Reasoning Paths via Correlation Matrix Rank", "comment": null, "summary": "Despite the strong reasoning ability of large language models~(LLMs), they\nare prone to errors and hallucinations. As a result, how to check their outputs\neffectively and efficiently has become a critical problem in their\napplications. Existing checking methods heavily rely on external resources,\nsuch as trained verifiers (e.g., process/outcome reward models) or elaborate\nprompts, which lead to high computational overhead and are only applicable to\nspecific domains. In this paper, we investigate whether the internal behaviors\nof LLMs have already implied the credibility of their reasoning paths.\nSpecifically, we find that the rank of the correlation matrix between the input\nproblem and the output reasoning path is a robust indicator of reasoning\ncorrectness. Different from other correctness indicators for LLMs, the\ncalculation of the correlation matrix only relies on the LLM itself, which\navoids the hassle of training a separate model or designing complicated\nprompts. Based on it, we design a simple, plug-and-play Self-Indicator method\nto reweight candidate reasoning paths, which achieves significant performance\nimprovements than other voting and verification methods with very few\ncomputational overhead. Our experiments across multiple LLMs of varying scales\nand model families have further shown the effectiveness of Self-Indicator. It\nachieves over 75% accuracy in distinguishing correct reasoning paths from\nincorrect ones, and, in turn, improves the accuracies on three reasoning\nbenchmarks by more than 8%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u5185\u90e8\u884c\u4e3a\u7684\u81ea\u6211\u6307\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97\u8f93\u5165\u95ee\u9898\u4e0e\u8f93\u51fa\u63a8\u7406\u8def\u5f84\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u77e9\u9635\u79e9\u6765\u8bc4\u4f30\u63a8\u7406\u8def\u5f84\u7684\u53ef\u4fe1\u5ea6\uff0c\u65e0\u9700\u5916\u90e8\u8d44\u6e90\u5373\u53ef\u6709\u6548\u68c0\u6d4bLLM\u8f93\u51fa\u9519\u8bef\u3002", "motivation": "\u73b0\u6709\u68c0\u67e5\u65b9\u6cd5\u4e25\u91cd\u4f9d\u8d56\u5916\u90e8\u8d44\u6e90\uff08\u5982\u8bad\u7ec3\u9a8c\u8bc1\u5668\u6216\u590d\u6742\u63d0\u793a\uff09\uff0c\u5bfc\u81f4\u8ba1\u7b97\u5f00\u9500\u5927\u4e14\u4ec5\u9002\u7528\u4e8e\u7279\u5b9a\u9886\u57df\u3002\u672c\u6587\u7814\u7a76LLM\u5185\u90e8\u884c\u4e3a\u662f\u5426\u5df2\u9690\u542b\u5176\u63a8\u7406\u8def\u5f84\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u53d1\u73b0\u8f93\u5165\u95ee\u9898\u4e0e\u8f93\u51fa\u63a8\u7406\u8def\u5f84\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u77e9\u9635\u79e9\u662f\u63a8\u7406\u6b63\u786e\u6027\u7684\u7a33\u5065\u6307\u6807\u3002\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7b80\u5355\u5373\u63d2\u5373\u7528\u7684Self-Indicator\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u52a0\u6743\u5019\u9009\u63a8\u7406\u8def\u5f84\u6765\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5728\u591a\u4e2a\u4e0d\u540c\u89c4\u6a21\u548c\u6a21\u578b\u5bb6\u65cf\u7684LLM\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u533a\u5206\u6b63\u786e\u4e0e\u9519\u8bef\u63a8\u7406\u8def\u5f84\u65b9\u9762\u8fbe\u523075%\u4ee5\u4e0a\u51c6\u786e\u7387\uff0c\u5e76\u5728\u4e09\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u5c06\u51c6\u786e\u7387\u63d0\u9ad8\u4e868%\u4ee5\u4e0a\u3002", "conclusion": "LLM\u5185\u90e8\u884c\u4e3a\u786e\u5b9e\u9690\u542b\u4e86\u5176\u63a8\u7406\u8def\u5f84\u7684\u53ef\u4fe1\u5ea6\u4fe1\u606f\uff0cSelf-Indicator\u65b9\u6cd5\u80fd\u6709\u6548\u4e14\u9ad8\u6548\u5730\u68c0\u6d4bLLM\u8f93\u51fa\u9519\u8bef\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u6295\u7968\u548c\u9a8c\u8bc1\u65b9\u6cd5\u3002"}}
{"id": "2510.24303", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24303", "abs": "https://arxiv.org/abs/2510.24303", "authors": ["Deniz Gorur", "Antoni Rago", "Francesca Toni"], "title": "Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting", "comment": null, "summary": "Judgmental forecasting is the task of making predictions about future events\nbased on human judgment. This task can be seen as a form of claim verification,\nwhere the claim corresponds to a future event and the task is to assess the\nplausibility of that event. In this paper, we propose a novel multi-agent\nframework for claim verification, whereby different agents may disagree on\nclaim veracity and bring specific evidence for and against the claims,\nrepresented as quantitative bipolar argumentation frameworks (QBAFs). We then\ninstantiate the framework for supporting claim verification, with a variety of\nagents realised with Large Language Models (LLMs): (1) ArgLLM agents, an\nexisting approach for claim verification that generates and evaluates QBAFs;\n(2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM)\nfrom external sources is used to generate QBAFs; (3) RAG-ArgLLM agents,\nextending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of\narguments from external sources. Finally, we conduct experiments with two\nstandard judgmental forecasting datasets, with instances of our framework with\ntwo or three agents, empowered by six different base LLMs. We observe that\ncombining evidence from agents can improve forecasting accuracy, especially in\nthe case of three agents, while providing an explainable combination of\nevidence for claim verification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u5224\u65ad\u6027\u9884\u6d4b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u9884\u6d4b\u4efb\u52a1\u89c6\u4e3a\u58f0\u660e\u9a8c\u8bc1\u95ee\u9898\uff0c\u901a\u8fc7\u4e0d\u540c\u667a\u80fd\u4f53\u751f\u6210\u6b63\u53cd\u8bc1\u636e\u5e76\u6784\u5efa\u91cf\u5316\u53cc\u6781\u8bba\u8bc1\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u591a\u667a\u80fd\u4f53\u7ec4\u5408\u80fd\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8bc1\u636e\u7ec4\u5408\u3002", "motivation": "\u5224\u65ad\u6027\u9884\u6d4b\u662f\u57fa\u4e8e\u4eba\u7c7b\u5224\u65ad\u5bf9\u672a\u6765\u4e8b\u4ef6\u8fdb\u884c\u9884\u6d4b\u7684\u4efb\u52a1\uff0c\u53ef\u89c6\u4e3a\u58f0\u660e\u9a8c\u8bc1\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u8bc1\u636e\u6536\u96c6\u548c\u9a8c\u8bc1\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u6846\u67b6\u6765\u6574\u5408\u4e0d\u540c\u6765\u6e90\u7684\u8bc1\u636e\u5e76\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u58f0\u660e\u9a8c\u8bc1\u6846\u67b6\uff0c\u4f7f\u7528\u4e09\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\uff1a(1) ArgLLM\u667a\u80fd\u4f53 - \u73b0\u6709\u65b9\u6cd5\uff0c\u751f\u6210\u548c\u8bc4\u4f30QBAFs\uff1b(2) RbAM\u667a\u80fd\u4f53 - \u57fa\u4e8e\u5173\u7cfb\u8bba\u8bc1\u6316\u6398\u4ece\u5916\u90e8\u6e90\u751f\u6210QBAFs\uff1b(3) RAG-ArgLLM\u667a\u80fd\u4f53 - \u6269\u5c55ArgLLM\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4ece\u5916\u90e8\u6e90\u83b7\u53d6\u8bba\u8bc1\u3002\u5728\u6807\u51c6\u5224\u65ad\u6027\u9884\u6d4b\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u4f7f\u75282\u62163\u4e2a\u667a\u80fd\u4f53\u7ec4\u5408\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u667a\u80fd\u4f53\u7ec4\u5408\u80fd\u591f\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728\u4f7f\u7528\u4e09\u4e2a\u667a\u80fd\u4f53\u65f6\u6548\u679c\u66f4\u660e\u663e\uff0c\u540c\u65f6\u4e3a\u58f0\u660e\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u8bc1\u636e\u7ec4\u5408\u65b9\u5f0f\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u6846\u67b6\u901a\u8fc7\u6574\u5408\u4e0d\u540c\u6765\u6e90\u7684\u8bc1\u636e\u548c\u8bba\u8bc1\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5224\u65ad\u6027\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4e3a\u9884\u6d4b\u7ed3\u679c\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u590d\u6742\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.24337", "categories": ["cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.24337", "abs": "https://arxiv.org/abs/2510.24337", "authors": ["Daria Kravets-Meinke", "Hannah Schmid-Petri", "Sonja Niemann", "Ute Schmid"], "title": "Generative Large Language Models (gLLMs) in Content Analysis: A Practical Guide for Communication Research", "comment": null, "summary": "Generative Large Language Models (gLLMs), such as ChatGPT, are increasingly\nbeing used in communication research for content analysis. Studies show that\ngLLMs can outperform both crowd workers and trained coders, such as research\nassistants, on various coding tasks relevant to communication science, often at\na fraction of the time and cost. Additionally, gLLMs can decode implicit\nmeanings and contextual information, be instructed using natural language,\ndeployed with only basic programming skills, and require little to no annotated\ndata beyond a validation dataset - constituting a paradigm shift in automated\ncontent analysis. Despite their potential, the integration of gLLMs into the\nmethodological toolkit of communication research remains underdeveloped. In\ngLLM-assisted quantitative content analysis, researchers must address at least\nseven critical challenges that impact result quality: (1) codebook development,\n(2) prompt engineering, (3) model selection, (4) parameter tuning, (5)\niterative refinement, (6) validation of the model's reliability, and\noptionally, (7) performance enhancement. This paper synthesizes emerging\nresearch on gLLM-assisted quantitative content analysis and proposes a\ncomprehensive best-practice guide to navigate these challenges. Our goal is to\nmake gLLM-based content analysis more accessible to a broader range of\ncommunication researchers and ensure adherence to established disciplinary\nquality standards of validity, reliability, reproducibility, and research\nethics.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f20\u64ad\u7814\u7a76\u5185\u5bb9\u5206\u6790\u4e2d\u7684\u5e94\u7528\uff0c\u6307\u51fagLLMs\u5728\u7f16\u7801\u4efb\u52a1\u4e2d\u4f18\u4e8e\u4f17\u5305\u5de5\u4f5c\u8005\u548c\u8bad\u7ec3\u6709\u7d20\u7684\u7f16\u7801\u5458\uff0c\u4f46\u6574\u5408\u5230\u4f20\u64ad\u7814\u7a76\u65b9\u6cd5\u5de5\u5177\u7bb1\u4ecd\u4e0d\u6210\u719f\uff0c\u63d0\u51fa\u4e86\u5e94\u5bf9\u4e03\u4e2a\u5173\u952e\u6311\u6218\u7684\u6700\u4f73\u5b9e\u8df5\u6307\u5357\u3002", "motivation": "\u867d\u7136\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f20\u64ad\u7814\u7a76\u5185\u5bb9\u5206\u6790\u4e2d\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u4ee5\u66f4\u4f4e\u6210\u672c\u548c\u65f6\u95f4\u5b8c\u6210\u7f16\u7801\u4efb\u52a1\uff0c\u5e76\u89e3\u7801\u9690\u542b\u610f\u4e49\uff0c\u4f46\u5176\u5728\u4f20\u64ad\u7814\u7a76\u65b9\u6cd5\u8bba\u4e2d\u7684\u6574\u5408\u4ecd\u5904\u4e8e\u4e0d\u53d1\u8fbe\u72b6\u6001\uff0c\u9700\u8981\u7cfb\u7edf\u6307\u5bfc\u3002", "method": "\u7efc\u5408\u65b0\u5174\u7814\u7a76\uff0c\u63d0\u51fa\u5e94\u5bf9gLLM\u8f85\u52a9\u5b9a\u91cf\u5185\u5bb9\u5206\u6790\u4e2d\u4e03\u4e2a\u5173\u952e\u6311\u6218\u7684\u5168\u9762\u6700\u4f73\u5b9e\u8df5\u6307\u5357\uff0c\u5305\u62ec\u4ee3\u7801\u672c\u5f00\u53d1\u3001\u63d0\u793a\u5de5\u7a0b\u3001\u6a21\u578b\u9009\u62e9\u3001\u53c2\u6570\u8c03\u4f18\u3001\u8fed\u4ee3\u7cbe\u70bc\u3001\u53ef\u9760\u6027\u9a8c\u8bc1\u548c\u6027\u80fd\u589e\u5f3a\u3002", "result": "gLLMs\u5728\u4f20\u64ad\u79d1\u5b66\u76f8\u5173\u7f16\u7801\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f17\u5305\u5de5\u4f5c\u8005\u548c\u8bad\u7ec3\u6709\u7d20\u7684\u7f16\u7801\u5458\uff0c\u80fd\u591f\u89e3\u7801\u9690\u542b\u610f\u4e49\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4ec5\u9700\u57fa\u672c\u7f16\u7a0b\u6280\u80fd\u548c\u5c11\u91cf\u6807\u6ce8\u6570\u636e\u5373\u53ef\u90e8\u7f72\u3002", "conclusion": "\u672c\u6587\u65e8\u5728\u4f7f\u57fa\u4e8egLLM\u7684\u5185\u5bb9\u5206\u6790\u5bf9\u66f4\u5e7f\u6cdb\u7684\u4f20\u64ad\u7814\u7a76\u4eba\u5458\u66f4\u52a0\u53ef\u53ca\uff0c\u5e76\u786e\u4fdd\u9075\u5b88\u65e2\u5b9a\u7684\u5b66\u79d1\u8d28\u91cf\u6807\u51c6\uff0c\u5305\u62ec\u6709\u6548\u6027\u3001\u53ef\u9760\u6027\u3001\u53ef\u91cd\u590d\u6027\u548c\u7814\u7a76\u4f26\u7406\u3002"}}
{"id": "2510.24339", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24339", "abs": "https://arxiv.org/abs/2510.24339", "authors": ["Yunxuan Jiang", "Silan Hu", "Xiaoning Wang", "Yuanyuan Zhang", "Xiangyu Chang"], "title": "VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science Automation", "comment": "29 pages, 6 figures. Yunxuan Jiang and Silan Hu contributed equally.\n  Code available at https://github.com/fengzer/VDSAgents", "summary": "Large language models (LLMs) become increasingly integrated into data science\nworkflows for automated system design. However, these LLM-driven data science\nsystems rely solely on the internal reasoning of LLMs, lacking guidance from\nscientific and theoretical principles. This limits their trustworthiness and\nrobustness, especially when dealing with noisy and complex real-world datasets.\nThis paper provides VDSAgents, a multi-agent system grounded in the\nPredictability-Computability-Stability (PCS) principles proposed in the\nVeridical Data Science (VDS) framework. Guided by PCS principles, the system\nimplements a modular workflow for data cleaning, feature engineering, modeling,\nand evaluation. Each phase is handled by an elegant agent, incorporating\nperturbation analysis, unit testing, and model validation to ensure both\nfunctionality and scientific auditability. We evaluate VDSAgents on nine\ndatasets with diverse characteristics, comparing it with state-of-the-art\nend-to-end data science systems, such as AutoKaggle and DataInterpreter, using\nDeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the\nresults of AutoKaggle and DataInterpreter, which validates the feasibility of\nembedding PCS principles into LLM-driven data science automation.", "AI": {"tldr": "VDSAgents\u662f\u4e00\u4e2a\u57fa\u4e8ePCS\u539f\u5219\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u63d0\u5347LLM\u9a71\u52a8\u6570\u636e\u79d1\u5b66\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u548c\u9c81\u68d2\u6027\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524dLLM\u9a71\u52a8\u7684\u6570\u636e\u79d1\u5b66\u7cfb\u7edf\u4ec5\u4f9d\u8d56LLM\u5185\u90e8\u63a8\u7406\uff0c\u7f3a\u4e4f\u79d1\u5b66\u548c\u7406\u8bba\u539f\u5219\u6307\u5bfc\uff0c\u5728\u5904\u7406\u590d\u6742\u771f\u5b9e\u6570\u636e\u96c6\u65f6\u53ef\u4fe1\u5ea6\u548c\u9c81\u68d2\u6027\u4e0d\u8db3\u3002", "method": "\u57fa\u4e8ePCS\u539f\u5219\u6784\u5efa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u91c7\u7528\u6a21\u5757\u5316\u5de5\u4f5c\u6d41\u7a0b\u5904\u7406\u6570\u636e\u6e05\u6d17\u3001\u7279\u5f81\u5de5\u7a0b\u3001\u5efa\u6a21\u548c\u8bc4\u4f30\uff0c\u6bcf\u4e2a\u9636\u6bb5\u7531\u4e13\u95e8\u667a\u80fd\u4f53\u8d1f\u8d23\uff0c\u7ed3\u5408\u6270\u52a8\u5206\u6790\u3001\u5355\u5143\u6d4b\u8bd5\u548c\u6a21\u578b\u9a8c\u8bc1\u3002", "result": "\u57289\u4e2a\u4e0d\u540c\u7279\u5f81\u7684\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4f7f\u7528DeepSeek-V3\u548cGPT-4o\u4f5c\u4e3a\u540e\u7aef\uff0cVDSAgents\u6301\u7eed\u4f18\u4e8eAutoKaggle\u548cDataInterpreter\u7b49\u6700\u5148\u8fdb\u7684\u7aef\u5230\u7aef\u6570\u636e\u79d1\u5b66\u7cfb\u7edf\u3002", "conclusion": "\u5c06PCS\u539f\u5219\u5d4c\u5165LLM\u9a71\u52a8\u7684\u6570\u636e\u79d1\u5b66\u81ea\u52a8\u5316\u662f\u53ef\u884c\u7684\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2510.24359", "categories": ["cs.AI", "cs.SY", "eess.SY", "q-bio.QM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.24359", "abs": "https://arxiv.org/abs/2510.24359", "authors": ["Pedram Fard", "Alaleh Azhir", "Neguine Rezaii", "Jiazi Tian", "Hossein Estiri"], "title": "An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine", "comment": "This study has been supported by grants from the National Institutes\n  of Health: The National Institute on Aging R01AG074372 and The National\n  Institute of Allergy and Infectious Diseases R01AI165535", "summary": "Artificial intelligence in medicine is built to serve the average patient. By\nminimizing error across large datasets, most systems deliver strong aggregate\naccuracy yet falter at the margins: patients with rare variants,\nmultimorbidity, or underrepresented demographics. This average patient fallacy\nerodes both equity and trust. We propose a different design: a multi-agent\necosystem for N-of-1 decision support. In this environment, agents clustered by\norgan systems, patient populations, and analytic modalities draw on a shared\nlibrary of models and evidence synthesis tools. Their results converge in a\ncoordination layer that weighs reliability, uncertainty, and data density\nbefore presenting the clinician with a decision-support packet: risk estimates\nbounded by confidence ranges, outlier flags, and linked evidence. Validation\nshifts from population averages to individual reliability, measured by error in\nlow-density regions, calibration in the small, and risk--coverage trade-offs.\nAnticipated challenges include computational demands, automation bias, and\nregulatory fit, addressed through caching strategies, consensus checks, and\nadaptive trial frameworks. By moving from monolithic models to orchestrated\nintelligence, this approach seeks to align medical AI with the first principle\nof medicine: care that is transparent, equitable, and centered on the\nindividual.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u751f\u6001\u7cfb\u7edf\u7528\u4e8eN-of-1\u51b3\u7b56\u652f\u6301\uff0c\u65e8\u5728\u89e3\u51b3\u5f53\u524d\u533b\u7597AI\u7cfb\u7edf\u8fc7\u4e8e\u5173\u6ce8\u5e73\u5747\u60a3\u8005\u800c\u5ffd\u89c6\u8fb9\u7f18\u60a3\u8005\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u533b\u7597AI\u7cfb\u7edf\u901a\u8fc7\u6700\u5c0f\u5316\u5927\u578b\u6570\u636e\u96c6\u4e0a\u7684\u9519\u8bef\u6765\u63d0\u4f9b\u5f3a\u5927\u7684\u603b\u4f53\u51c6\u786e\u6027\uff0c\u4f46\u5728\u7f55\u89c1\u53d8\u5f02\u3001\u591a\u75c5\u5171\u5b58\u6216\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u4eba\u7fa4\u7b49\u8fb9\u7f18\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002\u8fd9\u79cd\u5e73\u5747\u60a3\u8005\u8c2c\u8bba\u4fb5\u8680\u4e86\u516c\u5e73\u6027\u548c\u4fe1\u4efb\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u751f\u6001\u7cfb\u7edf\uff0c\u667a\u80fd\u4f53\u6309\u5668\u5b98\u7cfb\u7edf\u3001\u60a3\u8005\u7fa4\u4f53\u548c\u5206\u6790\u6a21\u5f0f\u8fdb\u884c\u805a\u7c7b\uff0c\u5171\u4eab\u6a21\u578b\u5e93\u548c\u8bc1\u636e\u5408\u6210\u5de5\u5177\u3002\u7ed3\u679c\u5728\u534f\u8c03\u5c42\u4e2d\u6c47\u805a\uff0c\u6743\u8861\u53ef\u9760\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u548c\u6570\u636e\u5bc6\u5ea6\uff0c\u4e3a\u4e34\u5e8a\u533b\u751f\u63d0\u4f9b\u51b3\u7b56\u652f\u6301\u5305\u3002", "result": "\u9a8c\u8bc1\u4ece\u7fa4\u4f53\u5e73\u5747\u503c\u8f6c\u5411\u4e2a\u4f53\u53ef\u9760\u6027\uff0c\u901a\u8fc7\u4f4e\u5bc6\u5ea6\u533a\u57df\u7684\u9519\u8bef\u3001\u5c0f\u6837\u672c\u6821\u51c6\u548c\u98ce\u9669-\u8986\u76d6\u6743\u8861\u6765\u6d4b\u91cf\u3002", "conclusion": "\u901a\u8fc7\u4ece\u5355\u4e00\u6a21\u578b\u8f6c\u5411\u534f\u8c03\u667a\u80fd\uff0c\u8be5\u65b9\u6cd5\u65e8\u5728\u4f7f\u533b\u7597AI\u4e0e\u533b\u5b66\u7684\u9996\u8981\u539f\u5219\u4fdd\u6301\u4e00\u81f4\uff1a\u63d0\u4f9b\u900f\u660e\u3001\u516c\u5e73\u4e14\u4ee5\u4e2a\u4f53\u4e3a\u4e2d\u5fc3\u7684\u62a4\u7406\u3002"}}
{"id": "2510.24390", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24390", "abs": "https://arxiv.org/abs/2510.24390", "authors": ["Xianjun Gao", "Jianchun Liu", "Hongli Xu", "Liusheng Huang"], "title": "Improving LLM Reasoning via Dependency-Aware Query Decomposition and Logic-Parallel Content Expansion", "comment": null, "summary": "The integration of Large Language Models (LLMs) into real-time Web\napplications, such as AI-powered search and conversational agents, presents a\nfundamental Web infrastructure challenge: reconciling the demand for\nhigh-quality, complex reasoning with the stringent low-latency and\nhigh-throughput requirements of interactive services. Current LLM reasoning,\nhindered by computationally inefficient sequential generation and rigid\nreasoning strategies, creates a critical bottleneck for the Web services.\nExisting approaches typically optimize the LLM reasoning for either efficiency\nor quality but struggle to achieve both, and thus fail to meet the dual\nrequirements of modern Web platforms. To overcome these limitations, we propose\nOrion, a novel and efficient reasoning framework that enables dependency-aware\nquery decomposition and logic-parallel content expansion. Concretely, Orion\ndecomposes a single query reasoning process into two synergistic phases: (1)\n\\textit{key point generation}, which distills logically structured key points\nthrough retrieval-augmented few-shot prompting, and (2) \\textit{content\nparallel expansion}, which concurrently elaborates on these points based on a\ndependency graph to ensure logical consistency. Furthermore, Orion introduces a\npipeline scheduling mechanism that exploits the complementary computational\ncharacteristics of the two phases (generation imposes pressure on GPU computing\nand expansion stresses on GPU memory) across multiple queries, enabling\ncross-query parallelism and dramatically improving reasoning performance (\\ie,\nefficiency and quality). Experiments on diverse benchmarks show that Orion not\nonly delivers up to 4.33x higher token generation speed and 3.42x lower answer\nlatency over the baselines but also improves reasoning quality by up to 18.75%\nthrough explicitly modeling inter-point dependencies.", "AI": {"tldr": "Orion\u662f\u4e00\u4e2a\u9ad8\u6548\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4f9d\u8d56\u611f\u77e5\u7684\u67e5\u8be2\u5206\u89e3\u548c\u903b\u8f91\u5e76\u884c\u5185\u5bb9\u6269\u5c55\uff0c\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u65f6Web\u5e94\u7528\u4e2d\u7684\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230\u5b9e\u65f6Web\u5e94\u7528\u4e2d\u9762\u4e34\u5173\u952e\u6311\u6218\uff1a\u9700\u8981\u540c\u65f6\u6ee1\u8db3\u9ad8\u8d28\u91cf\u590d\u6742\u63a8\u7406\u548c\u4f4e\u5ef6\u8fdf\u9ad8\u541e\u5410\u91cf\u7684\u53cc\u91cd\u9700\u6c42\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u517c\u987e\u6548\u7387\u548c\u63a8\u7406\u8d28\u91cf\u3002", "method": "Orion\u91c7\u7528\u4e24\u9636\u6bb5\u534f\u540c\u63a8\u7406\uff1a\u5173\u952e\u70b9\u751f\u6210\uff08\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u7684\u5c11\u6837\u672c\u63d0\u793a\u751f\u6210\u903b\u8f91\u7ed3\u6784\u5316\u7684\u5173\u952e\u70b9\uff09\u548c\u5185\u5bb9\u5e76\u884c\u6269\u5c55\uff08\u57fa\u4e8e\u4f9d\u8d56\u56fe\u5e76\u53d1\u6269\u5c55\u5185\u5bb9\u786e\u4fdd\u903b\u8f91\u4e00\u81f4\u6027\uff09\uff0c\u5e76\u5f15\u5165\u6d41\u6c34\u7ebf\u8c03\u5ea6\u673a\u5236\u5b9e\u73b0\u8de8\u67e5\u8be2\u5e76\u884c\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cOrion\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u4e864.33\u500d\u7684token\u751f\u6210\u901f\u5ea6\u63d0\u5347\u30013.42\u500d\u7684\u7b54\u6848\u5ef6\u8fdf\u964d\u4f4e\uff0c\u63a8\u7406\u8d28\u91cf\u63d0\u5347\u8fbe18.75%\u3002", "conclusion": "Orion\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u5173\u952e\u70b9\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u5728\u4fdd\u6301\u63a8\u7406\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6548\u7387\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u65f6Web\u670d\u52a1\u4e2d\u7684\u6027\u80fd\u74f6\u9888\u3002"}}
{"id": "2510.24397", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24397", "abs": "https://arxiv.org/abs/2510.24397", "authors": ["Jiarui Qin", "Yunjia Xi", "Junjie Huang", "Renting Rui", "Di Yin", "Weiwen Liu", "Yong Yu", "Weinan Zhang", "Xing Sun"], "title": "APTBench: Benchmarking Agentic Potential of Base LLMs During Pre-Training", "comment": "46 pages", "summary": "With the rapid development of LLM-based agents, there is a growing trend to\nincorporate agent-specific data into the pre-training stage of LLMs, aiming to\nbetter align LLMs with real-world autonomous task execution. However, current\npre-training benchmarks primarily focus on isolated and static skills, e.g.,\ncommon knowledge or mathematical/code reasoning, and fail to reflect model's\nagentic capabilities. On the other hand, agent benchmarks are typically\ndesigned for post-trained models, requiring multi-turn task execution abilities\nthat base models struggle to support. Thus, there is a compelling need for a\nbenchmark that can evaluate agentic potentials during pre-training and guide\nthe model training more effectively. To address this gap, we propose APTBench,\na framework that converts real-world agent tasks and successful trajectories\ninto multiple-choice or text completion questions tailored for base models. It\nfocuses on core agentic abilities, e.g., planning and action, and covers key\nagent scenarios, software engineering and deep research. Compared to existing\ngeneral-purpose benchmarks, APTBench offers a more predictive signal of a\nmodel's downstream performance as an agent, while remaining significantly more\nlightweight and cost-effective than full-scale, end-to-end agent evaluations\nafter post-training.", "AI": {"tldr": "APTBench\u662f\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5c06\u771f\u5b9e\u4e16\u754c\u667a\u80fd\u4f53\u4efb\u52a1\u8f6c\u6362\u4e3a\u9002\u5408\u57fa\u7840\u6a21\u578b\u7684\u591a\u9009\u6216\u6587\u672c\u8865\u5168\u95ee\u9898\uff0c\u7528\u4e8e\u8bc4\u4f30\u9884\u8bad\u7ec3\u9636\u6bb5\u7684\u667a\u80fd\u4f53\u6f5c\u529b\u3002", "motivation": "\u5f53\u524d\u9884\u8bad\u7ec3\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u5b64\u7acb\u9759\u6001\u6280\u80fd\uff0c\u65e0\u6cd5\u53cd\u6620\u6a21\u578b\u7684\u667a\u80fd\u4f53\u80fd\u529b\uff1b\u800c\u667a\u80fd\u4f53\u57fa\u51c6\u901a\u5e38\u9488\u5bf9\u540e\u8bad\u7ec3\u6a21\u578b\uff0c\u57fa\u7840\u6a21\u578b\u96be\u4ee5\u652f\u6301\u591a\u8f6e\u4efb\u52a1\u6267\u884c\u3002\u9700\u8981\u80fd\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u8bc4\u4f30\u667a\u80fd\u4f53\u6f5c\u529b\u7684\u57fa\u51c6\u3002", "method": "\u5c06\u771f\u5b9e\u4e16\u754c\u667a\u80fd\u4f53\u4efb\u52a1\u548c\u6210\u529f\u8f68\u8ff9\u8f6c\u6362\u4e3a\u591a\u9009\u6216\u6587\u672c\u8865\u5168\u95ee\u9898\uff0c\u805a\u7126\u89c4\u5212\u548c\u884c\u52a8\u7b49\u6838\u5fc3\u667a\u80fd\u4f53\u80fd\u529b\uff0c\u8986\u76d6\u8f6f\u4ef6\u5de5\u7a0b\u548c\u6df1\u5ea6\u7814\u7a76\u7b49\u5173\u952e\u573a\u666f\u3002", "result": "\u76f8\u6bd4\u73b0\u6709\u901a\u7528\u57fa\u51c6\uff0cAPTBench\u80fd\u66f4\u51c6\u786e\u5730\u9884\u6d4b\u6a21\u578b\u4f5c\u4e3a\u667a\u80fd\u4f53\u7684\u4e0b\u6e38\u6027\u80fd\uff0c\u540c\u65f6\u6bd4\u540e\u8bad\u7ec3\u7684\u5168\u89c4\u6a21\u7aef\u5230\u7aef\u8bc4\u4f30\u66f4\u8f7b\u91cf\u3001\u6210\u672c\u6548\u76ca\u66f4\u9ad8\u3002", "conclusion": "APTBench\u586b\u8865\u4e86\u9884\u8bad\u7ec3\u9636\u6bb5\u667a\u80fd\u4f53\u80fd\u529b\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u4e3a\u66f4\u6709\u6548\u5730\u6307\u5bfc\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u5de5\u5177\u3002"}}
{"id": "2510.24435", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24435", "abs": "https://arxiv.org/abs/2510.24435", "authors": ["Benjamin Grando Moreira"], "title": "Human-Level Reasoning: A Comparative Study of Large Language Models on Logical and Abstract Reasoning", "comment": "12 pages", "summary": "Evaluating reasoning ability in Large Language Models (LLMs) is important for\nadvancing artificial intelligence, as it transcends mere linguistic task\nperformance. It involves understanding whether these models truly understand\ninformation, perform inferences, and are able to draw conclusions in a logical\nand valid way. This study compare logical and abstract reasoning skills of\nseveral LLMs - including GPT, Claude, DeepSeek, Gemini, Grok, Llama, Mistral,\nPerplexity, and Sabi\\'a - using a set of eight custom-designed reasoning\nquestions. The LLM results are benchmarked against human performance on the\nsame tasks, revealing significant differences and indicating areas where LLMs\nstruggle with deduction.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u903b\u8f91\u548c\u62bd\u8c61\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u8868\u73b0\uff0c\u5e76\u4e0e\u4eba\u7c7b\u8868\u73b0\u8fdb\u884c\u5bf9\u6bd4\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5728\u6f14\u7ece\u63a8\u7406\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u5bf9\u4e8e\u63a8\u8fdb\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u8fd9\u8d85\u8d8a\u4e86\u5355\u7eaf\u7684\u8bed\u8a00\u4efb\u52a1\u8868\u73b0\uff0c\u6d89\u53ca\u6a21\u578b\u662f\u5426\u771f\u6b63\u7406\u89e3\u4fe1\u606f\u3001\u8fdb\u884c\u63a8\u7406\u5e76\u4ee5\u903b\u8f91\u6709\u6548\u7684\u65b9\u5f0f\u5f97\u51fa\u7ed3\u8bba\u3002", "method": "\u4f7f\u7528\u516b\u4e2a\u5b9a\u5236\u8bbe\u8ba1\u7684\u63a8\u7406\u95ee\u9898\uff0c\u6bd4\u8f83\u4e86GPT\u3001Claude\u3001DeepSeek\u3001Gemini\u3001Grok\u3001Llama\u3001Mistral\u3001Perplexity\u548cSabi'a\u7b49\u591a\u4e2aLLM\u7684\u903b\u8f91\u548c\u62bd\u8c61\u63a8\u7406\u6280\u80fd\uff0c\u5e76\u5c06\u7ed3\u679c\u4e0e\u4eba\u7c7b\u5728\u76f8\u540c\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793aLLM\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u8868\u660e\u5728\u6f14\u7ece\u63a8\u7406\u65b9\u9762LLM\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u80fd\u529b\u65b9\u9762\u4ecd\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u6f14\u7ece\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u4e3a\u672a\u6765\u6a21\u578b\u6539\u8fdb\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2510.24442", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.24442", "abs": "https://arxiv.org/abs/2510.24442", "authors": ["Yiding Wang", "Yuxuan Chen", "Fanxu Meng", "Xifan Chen", "Xiaolei Yang", "Muhan Zhang"], "title": "Law in Silico: Simulating Legal Society with LLM-Based Agents", "comment": null, "summary": "Since real-world legal experiments are often costly or infeasible, simulating\nlegal societies with Artificial Intelligence (AI) systems provides an effective\nalternative for verifying and developing legal theory, as well as supporting\nlegal administration. Large Language Models (LLMs), with their world knowledge\nand role-playing capabilities, are strong candidates to serve as the foundation\nfor legal society simulation. However, the application of LLMs to simulate\nlegal systems remains underexplored. In this work, we introduce Law in Silico,\nan LLM-based agent framework for simulating legal scenarios with individual\ndecision-making and institutional mechanisms of legislation, adjudication, and\nenforcement. Our experiments, which compare simulated crime rates with\nreal-world data, demonstrate that LLM-based agents can largely reproduce\nmacro-level crime trends and provide insights that align with real-world\nobservations. At the same time, micro-level simulations reveal that a\nwell-functioning, transparent, and adaptive legal system offers better\nprotection of the rights of vulnerable individuals.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLaw in Silico\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u6cd5\u5f8b\u793e\u4f1a\uff0c\u901a\u8fc7\u4e2a\u4f53\u51b3\u7b56\u548c\u7acb\u6cd5\u3001\u88c1\u51b3\u3001\u6267\u6cd5\u7b49\u5236\u5ea6\u673a\u5236\u6765\u9a8c\u8bc1\u6cd5\u5f8b\u7406\u8bba\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u80fd\u590d\u73b0\u5b8f\u89c2\u72af\u7f6a\u8d8b\u52bf\uff0c\u5e76\u63ed\u793a\u826f\u597d\u6cd5\u5f8b\u7cfb\u7edf\u5bf9\u5f31\u52bf\u7fa4\u4f53\u7684\u4fdd\u62a4\u4f5c\u7528\u3002", "motivation": "\u73b0\u5b9e\u6cd5\u5f8b\u5b9e\u9a8c\u6210\u672c\u9ad8\u6602\u4e14\u96be\u4ee5\u5b9e\u65bd\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6cd5\u6765\u9a8c\u8bc1\u548c\u53d1\u5c55\u6cd5\u5f8b\u7406\u8bba\u3002\u5927\u8bed\u8a00\u6a21\u578b\u5177\u5907\u4e16\u754c\u77e5\u8bc6\u548c\u89d2\u8272\u626e\u6f14\u80fd\u529b\uff0c\u662f\u6784\u5efa\u6cd5\u5f8b\u793e\u4f1a\u6a21\u62df\u7684\u7406\u60f3\u57fa\u7840\u3002", "method": "\u5f00\u53d1Law in Silico\u6846\u67b6\uff0c\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u6a21\u62df\u6cd5\u5f8b\u573a\u666f\uff0c\u5305\u542b\u4e2a\u4f53\u51b3\u7b56\u673a\u5236\u548c\u7acb\u6cd5\u3001\u88c1\u51b3\u3001\u6267\u6cd5\u7b49\u5236\u5ea6\u673a\u5236\u3002\u901a\u8fc7\u6bd4\u8f83\u6a21\u62df\u72af\u7f6a\u7387\u4e0e\u73b0\u5b9e\u6570\u636e\u6765\u9a8c\u8bc1\u6846\u67b6\u6709\u6548\u6027\u3002", "result": "LLM\u667a\u80fd\u4f53\u80fd\u591f\u5f88\u5927\u7a0b\u5ea6\u4e0a\u590d\u73b0\u5b8f\u89c2\u5c42\u9762\u7684\u72af\u7f6a\u8d8b\u52bf\uff0c\u6a21\u62df\u7ed3\u679c\u4e0e\u73b0\u5b9e\u89c2\u5bdf\u4e00\u81f4\u3002\u5fae\u89c2\u5c42\u9762\u6a21\u62df\u663e\u793a\uff0c\u529f\u80fd\u826f\u597d\u3001\u900f\u660e\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u6cd5\u5f8b\u7cfb\u7edf\u80fd\u66f4\u597d\u5730\u4fdd\u62a4\u5f31\u52bf\u4e2a\u4f53\u7684\u6743\u5229\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u6cd5\u5f8b\u793e\u4f1a\u6a21\u62df\u662f\u9a8c\u8bc1\u6cd5\u5f8b\u7406\u8bba\u7684\u6709\u6548\u5de5\u5177\uff0c\u80fd\u591f\u63d0\u4f9b\u4e0e\u73b0\u5b9e\u4e00\u81f4\u7684\u6d1e\u5bdf\uff0c\u5e76\u5f3a\u8c03\u826f\u597d\u6cd5\u5f8b\u7cfb\u7edf\u5bf9\u5f31\u52bf\u7fa4\u4f53\u4fdd\u62a4\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.24528", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24528", "abs": "https://arxiv.org/abs/2510.24528", "authors": ["Zihan Chen", "Song Wang", "Xingbo Fu", "Chengshuai Shi", "Zhenyu Lei", "Cong Shen", "Jundong Li"], "title": "From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning", "comment": null, "summary": "The capability of in-context learning (ICL) enables large language models\n(LLMs) to perform novel tasks without parameter updates by conditioning on a\nfew input-output examples. However, collecting high-quality examples for new or\nchallenging tasks can be costly and labor-intensive. In this work, we propose a\ncost-efficient two-stage pipeline that reduces reliance on LLMs for data\nlabeling. Our approach first leverages readily available cross-task examples to\nprompt an LLM and pseudo-label a small set of target task instances. We then\nintroduce a graph-based label propagation method that spreads label information\nto the remaining target examples without additional LLM queries. The resulting\nfully pseudo-labeled dataset is used to construct in-task demonstrations for\nICL. This pipeline combines the flexibility of cross-task supervision with the\nscalability of LLM-free propagation. Experiments across five tasks demonstrate\nthat our method achieves strong performance while lowering labeling costs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6210\u672c\u6548\u76ca\u9ad8\u7684\u4e24\u9636\u6bb5\u7ba1\u9053\uff0c\u51cf\u5c11\u5bf9LLM\u6570\u636e\u6807\u6ce8\u7684\u4f9d\u8d56\uff0c\u901a\u8fc7\u8de8\u4efb\u52a1\u793a\u4f8b\u4f2a\u6807\u6ce8\u548c\u57fa\u4e8e\u56fe\u7684\u6807\u7b7e\u4f20\u64ad\u6765\u6784\u5efaICL\u6f14\u793a", "motivation": "\u4e3a\u65b0\u4efb\u52a1\u6216\u56f0\u96be\u4efb\u52a1\u6536\u96c6\u9ad8\u8d28\u91cf\u793a\u4f8b\u6210\u672c\u9ad8\u6602\u4e14\u52b3\u52a8\u5bc6\u96c6\uff0c\u9700\u8981\u51cf\u5c11\u5bf9LLM\u6807\u6ce8\u7684\u4f9d\u8d56", "method": "\u4e24\u9636\u6bb5\u7ba1\u9053\uff1a1) \u5229\u7528\u8de8\u4efb\u52a1\u793a\u4f8b\u63d0\u793aLLM\u4f2a\u6807\u6ce8\u5c11\u91cf\u76ee\u6807\u4efb\u52a1\u5b9e\u4f8b\uff1b2) \u57fa\u4e8e\u56fe\u7684\u6807\u7b7e\u4f20\u64ad\u65b9\u6cd5\u5c06\u6807\u7b7e\u4fe1\u606f\u4f20\u64ad\u5230\u5269\u4f59\u76ee\u6807\u793a\u4f8b", "result": "\u5728\u4e94\u4e2a\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5f3a\u52b2\u6027\u80fd", "conclusion": "\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u8de8\u4efb\u52a1\u76d1\u7763\u7684\u7075\u6d3b\u6027\u548c\u65e0\u9700LLM\u4f20\u64ad\u7684\u53ef\u6269\u5c55\u6027"}}
{"id": "2510.24645", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24645", "abs": "https://arxiv.org/abs/2510.24645", "authors": ["Zengzhuang Xu", "Bingguang Hao", "Zechuan Wang", "Yuntao Wen", "Maolin Wang", "Yang Liu", "Long Chen", "Dong Wang", "Yicheng Chen", "Cunyin Peng", "Chenyi Zhuang", "Jinjie Gu", "Leilei Gan", "Xiangyu Zhao", "Shi Gu"], "title": "FunReason-MT Technical Report: Overcoming the Complexity Barrier in Multi-Turn Function Calling", "comment": null, "summary": "Function calling (FC) empowers large language models (LLMs) and autonomous\nagents to interface with external tools, a critical capability for solving\ncomplex, real-world problems. As this ability becomes increasingly central to\nadvanced AI systems, the need for high-quality, multi-turn training data to\ndevelop and refine it cannot be overstated. Existing data synthesis methods,\nsuch as random environment sampling or multi-agent role-playing, are not\npowerful enough to generate high-quality data in real-world environments.\nPractical challenges come in three folds: targeted model training, isolation of\ntool architecture, and multi-turn logical dependency. To address these\nstructural deficiencies, we present FunReason-MT, a novel data synthesis\nframework for real-world multi-turn tool use. FunReason-MT resolves the\ncomplexity barrier in multi-turn FC data by employing 1) Environment-API Graph\nInteractions to gather varied high-quality trajectories, 2) Advanced Tool-Query\nSynthesis to simplify hard query construction, and 3) Guided Iterative Chain\nfor sophisticated CoT generation. Evaluations on Berkeley Function-Calling\nLeaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built\nupon FunReason-MT generated data achieves state-of-the-art performance among\ncomparable-sized models, outperforming most close-source models. Further\nperformance improvements on BFCLv4 confirm that FunReason-MT provides a\nreliable and robust source for agentic learning.", "AI": {"tldr": "FunReason-MT\u662f\u4e00\u4e2a\u7528\u4e8e\u771f\u5b9e\u4e16\u754c\u591a\u8f6e\u5de5\u5177\u4f7f\u7528\u7684\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u73af\u5883-API\u56fe\u4ea4\u4e92\u3001\u9ad8\u7ea7\u5de5\u5177\u67e5\u8be2\u5408\u6210\u548c\u5f15\u5bfc\u8fed\u4ee3\u94fe\u6765\u89e3\u51b3\u591a\u8f6e\u51fd\u6570\u8c03\u7528\u6570\u636e\u7684\u590d\u6742\u6027\uff0c\u5728BFCL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u5408\u6210\u65b9\u6cd5\uff08\u5982\u968f\u673a\u73af\u5883\u91c7\u6837\u6216\u591a\u667a\u80fd\u4f53\u89d2\u8272\u626e\u6f14\uff09\u4e0d\u8db3\u4ee5\u5728\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u751f\u6210\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u9700\u8981\u89e3\u51b3\u76ee\u6807\u6a21\u578b\u8bad\u7ec3\u3001\u5de5\u5177\u67b6\u6784\u9694\u79bb\u548c\u591a\u8f6e\u903b\u8f91\u4f9d\u8d56\u7b49\u5b9e\u9645\u6311\u6218\u3002", "method": "\u91c7\u7528\u73af\u5883-API\u56fe\u4ea4\u4e92\u6536\u96c6\u591a\u6837\u5316\u9ad8\u8d28\u91cf\u8f68\u8ff9\uff0c\u9ad8\u7ea7\u5de5\u5177\u67e5\u8be2\u5408\u6210\u7b80\u5316\u786c\u67e5\u8be2\u6784\u5efa\uff0c\u4ee5\u53ca\u5f15\u5bfc\u8fed\u4ee3\u94fe\u751f\u6210\u590d\u6742\u601d\u7ef4\u94fe\u3002", "result": "\u57fa\u4e8eFunReason-MT\u751f\u6210\u6570\u636e\u6784\u5efa\u76844B\u6a21\u578b\u5728BFCLv3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u540c\u7c7b\u5c3a\u5bf8\u6a21\u578b\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u5927\u591a\u6570\u95ed\u6e90\u6a21\u578b\uff0c\u5728BFCLv4\u4e0a\u7684\u8fdb\u4e00\u6b65\u6027\u80fd\u6539\u8fdb\u8bc1\u5b9e\u4e86\u5176\u53ef\u9760\u6027\u3002", "conclusion": "FunReason-MT\u4e3a\u667a\u80fd\u4f53\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u9760\u4e14\u5f3a\u5927\u7684\u6570\u636e\u6e90\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u591a\u8f6e\u51fd\u6570\u8c03\u7528\u6570\u636e\u5408\u6210\u7684\u7ed3\u6784\u7f3a\u9677\u3002"}}
{"id": "2510.24650", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24650", "abs": "https://arxiv.org/abs/2510.24650", "authors": ["Nitin Rai", "Daeun", "Choi", "Nathan S. Boyd", "Arnold W. Schumann"], "title": "Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning", "comment": "26 pages, 8 figures, and 2 tables", "summary": "Site-specific disease management (SSDM) in crops has advanced rapidly through\nmachine and deep learning (ML and DL) for real-time computer vision. Research\nevolved from handcrafted feature extraction to large-scale automated feature\nlearning. With foundation models (FMs), crop disease datasets are now processed\nin fundamentally new ways. Unlike traditional neural networks, FMs integrate\nvisual and textual data, interpret symptoms in text, reason about\nsymptom-management relationships, and support interactive QA for growers and\neducators. Adaptive and imitation learning in robotics further enables\nfield-based disease management. This review screened approx. 40 articles on FM\napplications for SSDM, focusing on large-language models (LLMs) and\nvision-language models (VLMs), and discussing their role in adaptive learning\n(AL), reinforcement learning (RL), and digital twin frameworks for targeted\nspraying. Key findings: (a) FMs are gaining traction with surging literature in\n2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL\nand AL are still nascent for smart spraying; (d) digital twins with RL can\nsimulate targeted spraying virtually; (e) addressing the sim-to-real gap is\ncritical for real-world deployment; (f) human-robot collaboration remains\nlimited, especially in human-in-the-loop approaches where robots detect early\nsymptoms and humans validate uncertain cases; (g) multi-modal FMs with\nreal-time feedback will drive next-gen SSDM. For updates, resources, and\ncontributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to\nsubmit papers, code, or datasets.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\uff08FMs\uff09\u7684\u4f5c\u7269\u5b9a\u70b9\u75c5\u5bb3\u7ba1\u7406\uff08SSDM\uff09\u7814\u7a76\u8fdb\u5c55\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u7684\u5e94\u7528\uff0c\u4ee5\u53ca\u5b83\u4eec\u5728\u81ea\u9002\u5e94\u5b66\u4e60\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u4e2d\u7684\u4f5c\u7528\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u5728\u5b9e\u65f6\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u4f5c\u7269\u75c5\u5bb3\u7ba1\u7406\u4ece\u624b\u5de5\u7279\u5f81\u63d0\u53d6\u53d1\u5c55\u5230\u5927\u89c4\u6a21\u81ea\u52a8\u7279\u5f81\u5b66\u4e60\u3002\u57fa\u7840\u6a21\u578b\u4e3a\u5904\u7406\u4f5c\u7269\u75c5\u5bb3\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u5168\u65b0\u7684\u65b9\u5f0f\uff0c\u80fd\u591f\u6574\u5408\u89c6\u89c9\u548c\u6587\u672c\u6570\u636e\uff0c\u89e3\u91ca\u75c7\u72b6\u6587\u672c\uff0c\u63a8\u7406\u75c7\u72b6\u4e0e\u6cbb\u7406\u5173\u7cfb\uff0c\u5e76\u4e3a\u79cd\u690d\u8005\u548c\u6559\u80b2\u8005\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u95ee\u7b54\u652f\u6301\u3002", "method": "\u901a\u8fc7\u7b5b\u9009\u7ea640\u7bc7\u5173\u4e8e\u57fa\u7840\u6a21\u578b\u5728\u5b9a\u70b9\u75c5\u5bb3\u7ba1\u7406\u4e2d\u5e94\u7528\u7684\u6587\u732e\uff0c\u91cd\u70b9\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u8ba8\u8bba\u5b83\u4eec\u5728\u81ea\u9002\u5e94\u5b66\u4e60\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u4e2d\u7684\u4f5c\u7528\u3002", "result": "\u4e3b\u8981\u53d1\u73b0\u5305\u62ec\uff1a\u57fa\u7840\u6a21\u578b\u57282023-24\u5e74\u6587\u732e\u6fc0\u589e\uff1b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u901f\u5ea6\u8fdc\u8d85\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u8868\u91cf\u589e\u957f5-10\u500d\uff1b\u5f3a\u5316\u5b66\u4e60\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u5728\u667a\u80fd\u55b7\u6d12\u4e2d\u4ecd\u5904\u4e8e\u8d77\u6b65\u9636\u6bb5\uff1b\u6570\u5b57\u5b6a\u751f\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u53ef\u6a21\u62df\u865a\u62df\u5b9a\u70b9\u55b7\u6d12\uff1b\u89e3\u51b3\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u5dee\u8ddd\u5bf9\u5b9e\u9645\u90e8\u7f72\u81f3\u5173\u91cd\u8981\uff1b\u4eba\u673a\u534f\u4f5c\u4ecd\u7136\u6709\u9650\uff1b\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u4e0e\u5b9e\u65f6\u53cd\u9988\u5c06\u63a8\u52a8\u4e0b\u4e00\u4ee3\u5b9a\u70b9\u75c5\u5bb3\u7ba1\u7406\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\u6b63\u5728\u6539\u53d8\u4f5c\u7269\u75c5\u5bb3\u7ba1\u7406\u7684\u65b9\u5f0f\uff0c\u7279\u522b\u662f\u5728\u6574\u5408\u89c6\u89c9\u548c\u6587\u672c\u4fe1\u606f\u3001\u652f\u6301\u4ea4\u4e92\u5f0f\u95ee\u7b54\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\u3002\u672a\u6765\u53d1\u5c55\u65b9\u5411\u5305\u62ec\u89e3\u51b3\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u5dee\u8ddd\u3001\u52a0\u5f3a\u4eba\u673a\u534f\u4f5c\uff0c\u4ee5\u53ca\u5f00\u53d1\u5177\u6709\u5b9e\u65f6\u53cd\u9988\u529f\u80fd\u7684\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u7cfb\u7edf\u3002"}}
{"id": "2510.24663", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24663", "abs": "https://arxiv.org/abs/2510.24663", "authors": ["Yifu Lu", "Shengjie Liu", "Li Dong"], "title": "OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan DAGs", "comment": "9 pages, 4 figures", "summary": "Agentic tool use has gained traction with the rise of agentic tool calling,\nyet most existing work overlooks the complexity of multi-turn tool\ninteractions. We introduce OrchDAG, a synthetic data generation pipeline that\nmodels tool execution as directed acyclic graphs (DAGs) with controllable\ncomplexity. Using this dataset, we benchmark model performance and propose a\ngraph-based reward to enhance RLVR training. Experiments show that the dataset\npresents a challenging but solvable benchmark, and the proposed reward is\neffective when combined with GRPO-style algorithms, highlighting the importance\nof leveraging topological structure and data complexity in multi-turn tool use.", "AI": {"tldr": "OrchDAG\u662f\u4e00\u4e2a\u5408\u6210\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u5c06\u5de5\u5177\u6267\u884c\u5efa\u6a21\u4e3a\u5177\u6709\u53ef\u63a7\u590d\u6742\u5ea6\u7684\u6709\u5411\u65e0\u73af\u56fe\uff0c\u7528\u4e8e\u591a\u8f6e\u5de5\u5177\u4ea4\u4e92\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u5927\u591a\u5ffd\u7565\u4e86\u591a\u8f6e\u5de5\u5177\u4ea4\u4e92\u7684\u590d\u6742\u6027\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u6765\u5efa\u6a21\u548c\u8bad\u7ec3\u667a\u80fd\u4f53\u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u3002", "method": "\u5f15\u5165OrchDAG\u5408\u6210\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u5c06\u5de5\u5177\u6267\u884c\u5efa\u6a21\u4e3a\u6709\u5411\u65e0\u73af\u56fe\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u5956\u52b1\u6765\u589e\u5f3aRLVR\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u5177\u6709\u6311\u6218\u6027\u4f46\u53ef\u89e3\u51b3\u7684\u57fa\u51c6\uff0c\u6240\u63d0\u51fa\u7684\u5956\u52b1\u5728\u4e0eGRPO\u98ce\u683c\u7b97\u6cd5\u7ed3\u5408\u65f6\u6709\u6548\u3002", "conclusion": "\u5728\u591a\u8f6e\u5de5\u5177\u4f7f\u7528\u4e2d\uff0c\u5229\u7528\u62d3\u6251\u7ed3\u6784\u548c\u6570\u636e\u590d\u6742\u5ea6\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.24690", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24690", "abs": "https://arxiv.org/abs/2510.24690", "authors": ["Shengjie Liu", "Li Dong", "Zhenyu Zhang"], "title": "Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning", "comment": "4 pages, 2 figures, short paper, NeurIPS 2025 workshop on Bridging\n  Language, Agent, and World Models for Reasoning and Planning", "summary": "We present a framework for uncovering and exploiting dependencies among tools\nand documents to enhance exemplar artifact generation. Our method begins by\nconstructing a tool knowledge graph from tool schemas,including descriptions,\narguments, and output payloads, using a DeepResearch-inspired analysis. In\nparallel, we derive a complementary knowledge graph from internal documents and\nSOPs, which is then fused with the tool graph. To generate exemplar plans, we\nadopt a deep-sparse integration strategy that aligns structural tool\ndependencies with procedural knowledge. Experiments demonstrate that this\nunified framework effectively models tool interactions and improves plan\ngeneration, underscoring the benefits of linking tool graphs with domain\nknowledge graphs for tool-augmented reasoning and planning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u8fc7\u6784\u5efa\u5de5\u5177\u548c\u6587\u6863\u77e5\u8bc6\u56fe\u8c31\u6765\u589e\u5f3a\u793a\u4f8b\u5de5\u4ef6\u751f\u6210\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u5de5\u5177\u4f9d\u8d56\u5173\u7cfb\u548c\u9886\u57df\u77e5\u8bc6\u6765\u6539\u8fdb\u89c4\u5212\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5de5\u5177\u548c\u6587\u6863\u4e4b\u95f4\u7684\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u7edf\u4e00\u6846\u67b6\u6765\u5efa\u6a21\u5de5\u5177\u4ea4\u4e92\u5e76\u63d0\u5347\u89c4\u5212\u751f\u6210\u8d28\u91cf\u3002", "method": "\u4ece\u5de5\u5177\u6a21\u5f0f\u6784\u5efa\u5de5\u5177\u77e5\u8bc6\u56fe\u8c31\uff0c\u4ece\u5185\u90e8\u6587\u6863\u548cSOP\u6784\u5efa\u8865\u5145\u77e5\u8bc6\u56fe\u8c31\uff0c\u91c7\u7528\u6df1\u5ea6\u7a00\u758f\u96c6\u6210\u7b56\u7565\u5bf9\u9f50\u7ed3\u6784\u5de5\u5177\u4f9d\u8d56\u4e0e\u7a0b\u5e8f\u77e5\u8bc6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u7edf\u4e00\u6846\u67b6\u80fd\u6709\u6548\u5efa\u6a21\u5de5\u5177\u4ea4\u4e92\u5e76\u6539\u8fdb\u89c4\u5212\u751f\u6210\uff0c\u9a8c\u8bc1\u4e86\u5c06\u5de5\u5177\u56fe\u8c31\u4e0e\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u94fe\u63a5\u7684\u76ca\u5904\u3002", "conclusion": "\u901a\u8fc7\u878d\u5408\u5de5\u5177\u56fe\u8c31\u548c\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u5de5\u5177\u589e\u5f3a\u63a8\u7406\u548c\u89c4\u5212\u7684\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u4f9d\u8d56\u5173\u7cfb\u5efa\u6a21\u7684\u91cd\u8981\u6027\u3002"}}

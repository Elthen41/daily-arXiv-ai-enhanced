{"id": "2510.18982", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18982", "abs": "https://arxiv.org/abs/2510.18982", "authors": ["Arpan Mukherjee", "Marcello Bullo", "Debabrota Basu", "Deniz G\u00fcnd\u00fcz"], "title": "Test-time Verification via Optimal Transport: Coverage, ROC, & Sub-optimality", "comment": null, "summary": "While test-time scaling with verification has shown promise in improving the\nperformance of large language models (LLMs), the role of the verifier and its\nimperfections remain underexplored. The effect of verification manifests\nthrough interactions of three quantities: (i) the generator's coverage, (ii)\nthe verifier's region of convergence (ROC), and (iii) the sampling algorithm's\nsub-optimality. Though recent studies capture subsets of these factors, a\nunified framework quantifying the geometry of their interplay is missing. We\nframe verifiable test-time scaling as a transport problem. This characterizes\nthe interaction of coverage, ROC, and sub-optimality, and uncovers that the\nsub-optimality--coverage curve exhibits three regimes. A transport regime --\nwhere sub-optimality increases with coverage, a policy improvement regime --\nwhere sub-optimality may decrease with coverage, depending on the verifier's\nROC, and a saturation regime -- where sub-optimality plateaus, unaffected by\ncoverage. We further propose and analyze two classes of sampling algorithms --\nsequential and batched, and examine how their computational complexities shape\nthese trade-offs. Empirical results with Qwen, Llama, and Gemma models\ncorroborate our theoretical findings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u6765\u5206\u6790\u9a8c\u8bc1\u5668\u5728\u6d4b\u8bd5\u65f6\u7f29\u653e\u4e2d\u7684\u4f5c\u7528\uff0c\u5c06\u53ef\u9a8c\u8bc1\u6d4b\u8bd5\u65f6\u7f29\u653e\u5efa\u6a21\u4e3a\u4f20\u8f93\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u6b21\u4f18\u6027-\u8986\u76d6\u7387\u66f2\u7ebf\u7684\u4e09\u4e2a\u673a\u5236\uff1a\u4f20\u8f93\u673a\u5236\u3001\u7b56\u7565\u6539\u8fdb\u673a\u5236\u548c\u9971\u548c\u673a\u5236\u3002", "motivation": "\u867d\u7136\u5e26\u9a8c\u8bc1\u7684\u6d4b\u8bd5\u65f6\u7f29\u653e\u5df2\u663e\u793a\u51fa\u6539\u5584\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u6f5c\u529b\uff0c\u4f46\u9a8c\u8bc1\u5668\u7684\u4f5c\u7528\u53ca\u5176\u7f3a\u9677\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u73b0\u6709\u7814\u7a76\u53ea\u6355\u6349\u4e86\u8fd9\u4e9b\u56e0\u7d20\u7684\u90e8\u5206\u5b50\u96c6\uff0c\u7f3a\u4e4f\u91cf\u5316\u5b83\u4eec\u76f8\u4e92\u4f5c\u7528\u51e0\u4f55\u7ed3\u6784\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u5c06\u53ef\u9a8c\u8bc1\u6d4b\u8bd5\u65f6\u7f29\u653e\u6784\u5efa\u4e3a\u4f20\u8f93\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u6790\u751f\u6210\u5668\u7684\u8986\u76d6\u7387\u3001\u9a8c\u8bc1\u5668\u7684\u6536\u655b\u533a\u57df\u548c\u91c7\u6837\u7b97\u6cd5\u7684\u6b21\u4f18\u6027\u8fd9\u4e09\u4e2a\u91cf\u7684\u76f8\u4e92\u4f5c\u7528\u6765\u8868\u5f81\u5176\u51e0\u4f55\u7279\u6027\u3002\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u987a\u5e8f\u548c\u6279\u91cf\u4e24\u7c7b\u91c7\u6837\u7b97\u6cd5\u3002", "result": "\u7406\u8bba\u5206\u6790\u53d1\u73b0\u6b21\u4f18\u6027-\u8986\u76d6\u7387\u66f2\u7ebf\u5448\u73b0\u4e09\u4e2a\u673a\u5236\uff1a\u4f20\u8f93\u673a\u5236\uff08\u6b21\u4f18\u6027\u968f\u8986\u76d6\u7387\u589e\u52a0\u800c\u589e\u52a0\uff09\u3001\u7b56\u7565\u6539\u8fdb\u673a\u5236\uff08\u6b21\u4f18\u6027\u53ef\u80fd\u968f\u8986\u76d6\u7387\u589e\u52a0\u800c\u51cf\u5c11\uff0c\u53d6\u51b3\u4e8e\u9a8c\u8bc1\u5668\u7684\u6536\u655b\u533a\u57df\uff09\u548c\u9971\u548c\u673a\u5236\uff08\u6b21\u4f18\u6027\u8d8b\u4e8e\u5e73\u7a33\uff0c\u4e0d\u53d7\u8986\u76d6\u7387\u5f71\u54cd\uff09\u3002\u4f7f\u7528Qwen\u3001Llama\u548cGemma\u6a21\u578b\u7684\u5b9e\u8bc1\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\u3002", "conclusion": "\u901a\u8fc7\u4f20\u8f93\u95ee\u9898\u7684\u89c6\u89d2\uff0c\u672c\u6587\u4e3a\u7406\u89e3\u9a8c\u8bc1\u5668\u5728\u6d4b\u8bd5\u65f6\u7f29\u653e\u4e2d\u7684\u4f5c\u7528\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u8986\u76d6\u7387\u3001\u9a8c\u8bc1\u5668\u6536\u655b\u533a\u57df\u548c\u91c7\u6837\u7b97\u6cd5\u6b21\u4f18\u6027\u4e4b\u95f4\u7684\u590d\u6742\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u5c55\u793a\u4e86\u4e0d\u540c\u91c7\u6837\u7b97\u6cd5\u5982\u4f55\u5f71\u54cd\u8fd9\u4e9b\u6743\u8861\u5173\u7cfb\u3002"}}
{"id": "2510.18988", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18988", "abs": "https://arxiv.org/abs/2510.18988", "authors": ["Silas Ruhrberg Est\u00e9vez", "Nicol\u00e1s Astorga", "Mihaela van der Schaar"], "title": "Timely Clinical Diagnosis through Active Test Selection", "comment": "None", "summary": "There is growing interest in using machine learning (ML) to support clinical\ndiag- nosis, but most approaches rely on static, fully observed datasets and\nfail to reflect the sequential, resource-aware reasoning clinicians use in\npractice. Diagnosis remains complex and error prone, especially in\nhigh-pressure or resource-limited settings, underscoring the need for\nframeworks that help clinicians make timely and cost-effective decisions. We\npropose ACTMED (Adaptive Clinical Test selection via Model-based Experimental\nDesign), a diagnostic framework that integrates Bayesian Experimental Design\n(BED) with large language models (LLMs) to better emulate real-world diagnostic\nreasoning. At each step, ACTMED selects the test expected to yield the greatest\nreduction in diagnostic uncertainty for a given patient. LLMs act as flexible\nsimulators, generating plausible patient state distributions and supporting\nbelief updates without requiring structured, task-specific training data.\nClinicians can remain in the loop; reviewing test suggestions, interpreting\nintermediate outputs, and applying clinical judgment throughout. We evaluate\nACTMED on real-world datasets and show it can optimize test selection to\nimprove diagnostic accuracy, interpretability, and resource use. This\nrepresents a step to- ward transparent, adaptive, and clinician-aligned\ndiagnostic systems that generalize across settings with reduced reliance on\ndomain-specific data.", "AI": {"tldr": "ACTMED\u662f\u4e00\u4e2a\u7ed3\u5408\u8d1d\u53f6\u65af\u5b9e\u9a8c\u8bbe\u8ba1\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e34\u5e8a\u8bca\u65ad\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9009\u62e9\u80fd\u6700\u5927\u7a0b\u5ea6\u51cf\u5c11\u8bca\u65ad\u4e0d\u786e\u5b9a\u6027\u7684\u6d4b\u8bd5\uff0c\u6a21\u62df\u771f\u5b9e\u4e34\u5e8a\u63a8\u7406\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8d44\u6e90\u5229\u7528\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u8bca\u65ad\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u5b8c\u6574\u6570\u636e\u96c6\uff0c\u65e0\u6cd5\u6a21\u62df\u4e34\u5e8a\u533b\u751f\u5728\u5b9e\u8df5\u4e2d\u7684\u987a\u5e8f\u6027\u3001\u8d44\u6e90\u611f\u77e5\u63a8\u7406\u8fc7\u7a0b\u3002\u8bca\u65ad\u5728\u9ad8\u538b\u6216\u8d44\u6e90\u6709\u9650\u73af\u5883\u4e2d\u4ecd\u7136\u590d\u6742\u4e14\u6613\u51fa\u9519\uff0c\u9700\u8981\u80fd\u591f\u5e2e\u52a9\u533b\u751f\u505a\u51fa\u53ca\u65f6\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u51b3\u7b56\u7684\u6846\u67b6\u3002", "method": "ACTMED\u6574\u5408\u8d1d\u53f6\u65af\u5b9e\u9a8c\u8bbe\u8ba1\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u6bcf\u4e2a\u6b65\u9aa4\u9009\u62e9\u9884\u671f\u80fd\u4e3a\u7279\u5b9a\u60a3\u8005\u5e26\u6765\u6700\u5927\u8bca\u65ad\u4e0d\u786e\u5b9a\u6027\u51cf\u5c11\u7684\u6d4b\u8bd5\u3002LLMs\u4f5c\u4e3a\u7075\u6d3b\u6a21\u62df\u5668\uff0c\u751f\u6210\u5408\u7406\u7684\u60a3\u8005\u72b6\u6001\u5206\u5e03\u5e76\u652f\u6301\u4fe1\u5ff5\u66f4\u65b0\uff0c\u65e0\u9700\u7ed3\u6784\u5316\u3001\u4efb\u52a1\u7279\u5b9a\u7684\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cACTMED\u80fd\u591f\u4f18\u5316\u6d4b\u8bd5\u9009\u62e9\uff0c\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8d44\u6e90\u4f7f\u7528\u6548\u7387\u3002", "conclusion": "ACTMED\u4ee3\u8868\u4e86\u5411\u900f\u660e\u3001\u81ea\u9002\u5e94\u4e14\u4e0e\u4e34\u5e8a\u533b\u751f\u5bf9\u9f50\u7684\u8bca\u65ad\u7cfb\u7edf\u8fc8\u51fa\u7684\u4e00\u6b65\uff0c\u80fd\u591f\u5728\u51cf\u5c11\u5bf9\u9886\u57df\u7279\u5b9a\u6570\u636e\u4f9d\u8d56\u7684\u60c5\u51b5\u4e0b\u8de8\u8bbe\u7f6e\u6cdb\u5316\u3002"}}
{"id": "2510.19055", "categories": ["cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.19055", "abs": "https://arxiv.org/abs/2510.19055", "authors": ["Brandon James Carone", "Iran R. Roman", "Pablo Ripoll\u00e9s"], "title": "The MUSE Benchmark: Probing Music Perception and Auditory Relational Reasoning in Audio LLMS", "comment": "5 pages, 2 figures, 2 tables", "summary": "Multimodal Large Language Models (MLLMs) have demonstrated capabilities in\naudio understanding, but current evaluations may obscure fundamental weaknesses\nin relational reasoning. We introduce the Music Understanding and Structural\nEvaluation (MUSE) Benchmark, an open-source resource with 10 tasks designed to\nprobe fundamental music perception skills. We evaluate four SOTA models (Gemini\nPro and Flash, Qwen2.5-Omni, and Audio-Flamingo 3) against a large human\nbaseline (N=200). Our results reveal a wide variance in SOTA capabilities and a\npersistent gap with human experts. While Gemini Pro succeeds on basic\nperception, Qwen and Audio Flamingo 3 perform at or near chance, exposing\nsevere perceptual deficits. Furthermore, we find Chain-of-Thought (CoT)\nprompting provides inconsistent, often detrimental results. Our work provides a\ncritical tool for evaluating invariant musical representations and driving\ndevelopment of more robust AI systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86MUSE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u97f3\u4e50\u7406\u89e3\u65b9\u9762\u7684\u5173\u7cfb\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524dSOTA\u6a21\u578b\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0c\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u97f3\u9891\u7406\u89e3\u65b9\u9762\u7684\u8bc4\u4f30\u53ef\u80fd\u63a9\u76d6\u4e86\u5176\u5728\u5173\u7cfb\u63a8\u7406\u65b9\u9762\u7684\u6839\u672c\u5f31\u70b9\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u5de5\u5177\u6765\u63ed\u793a\u8fd9\u4e9b\u7f3a\u9677\u3002", "method": "\u5f00\u53d1\u4e86MUSE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b10\u4e2a\u4efb\u52a1\u6765\u63a2\u6d4b\u57fa\u7840\u97f3\u4e50\u611f\u77e5\u6280\u80fd\uff0c\u8bc4\u4f30\u4e864\u4e2aSOTA\u6a21\u578b\uff08Gemini Pro\u548cFlash\u3001Qwen2.5-Omni\u3001Audio-Flamingo 3\uff09\u5e76\u4e0e200\u4eba\u7684\u4eba\u7c7b\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u53d1\u73b0SOTA\u6a21\u578b\u80fd\u529b\u5dee\u5f02\u5f88\u5927\uff0c\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5b58\u5728\u6301\u7eed\u5dee\u8ddd\uff1bGemini Pro\u5728\u57fa\u7840\u611f\u77e5\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46Qwen\u548cAudio Flamingo 3\u8868\u73b0\u63a5\u8fd1\u968f\u673a\u6c34\u5e73\uff1b\u601d\u7ef4\u94fe\u63d0\u793a\u63d0\u4f9b\u4e0d\u4e00\u81f4\u4e14\u901a\u5e38\u6709\u5bb3\u7684\u7ed3\u679c\u3002", "conclusion": "MUSE\u57fa\u51c6\u4e3a\u8bc4\u4f30\u4e0d\u53d8\u97f3\u4e50\u8868\u5f81\u548c\u5f00\u53d1\u66f4\u9c81\u68d2\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5173\u952e\u5de5\u5177\u3002"}}
{"id": "2510.19145", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19145", "abs": "https://arxiv.org/abs/2510.19145", "authors": ["Sanskar Amgain", "Daniel Lobo", "Atri Chatterjee", "Swarup Bhunia", "Fnu Suya"], "title": "HAMLOCK: HArdware-Model LOgically Combined attacK", "comment": null, "summary": "The growing use of third-party hardware accelerators (e.g., FPGAs, ASICs) for\ndeep neural networks (DNNs) introduces new security vulnerabilities.\nConventional model-level backdoor attacks, which only poison a model's weights\nto misclassify inputs with a specific trigger, are often detectable because the\nentire attack logic is embedded within the model (i.e., software), creating a\ntraceable layer-by-layer activation path.\n  This paper introduces the HArdware-Model Logically Combined Attack (HAMLOCK),\na far stealthier threat that distributes the attack logic across the\nhardware-software boundary. The software (model) is now only minimally altered\nby tuning the activations of few neurons to produce uniquely high activation\nvalues when a trigger is present. A malicious hardware Trojan detects those\nunique activations by monitoring the corresponding neurons' most significant\nbit or the 8-bit exponents and triggers another hardware Trojan to directly\nmanipulate the final output logits for misclassification.\n  This decoupled design is highly stealthy, as the model itself contains no\ncomplete backdoor activation path as in conventional attacks and hence, appears\nfully benign. Empirically, across benchmarks like MNIST, CIFAR10, GTSRB, and\nImageNet, HAMLOCK achieves a near-perfect attack success rate with a negligible\nclean accuracy drop. More importantly, HAMLOCK circumvents the state-of-the-art\nmodel-level defenses without any adaptive optimization. The hardware Trojan is\nalso undetectable, incurring area and power overheads as low as 0.01%, which is\neasily masked by process and environmental noise. Our findings expose a\ncritical vulnerability at the hardware-software interface, demanding new\ncross-layer defenses against this emerging threat.", "AI": {"tldr": "HAMLOCK\u662f\u4e00\u79cd\u65b0\u578b\u786c\u4ef6-\u8f6f\u4ef6\u8054\u5408\u653b\u51fb\uff0c\u901a\u8fc7\u5728\u786c\u4ef6\u4e2d\u690d\u5165\u6728\u9a6c\u6765\u68c0\u6d4b\u7279\u5b9a\u795e\u7ecf\u5143\u6fc0\u6d3b\uff0c\u4ece\u800c\u7ed5\u8fc7\u4f20\u7edf\u6a21\u578b\u7ea7\u540e\u95e8\u653b\u51fb\u68c0\u6d4b\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u7ea7\u540e\u95e8\u653b\u51fb\u5bb9\u6613\u88ab\u68c0\u6d4b\uff0c\u56e0\u4e3a\u653b\u51fb\u903b\u8f91\u5b8c\u5168\u5d4c\u5165\u5728\u6a21\u578b\u4e2d\uff0c\u800cHAMLOCK\u901a\u8fc7\u5c06\u653b\u51fb\u903b\u8f91\u5206\u5e03\u5728\u786c\u4ef6-\u8f6f\u4ef6\u8fb9\u754c\u6765\u63d0\u9ad8\u9690\u853d\u6027\u3002", "method": "\u8f6f\u4ef6\u5c42\u9762\u4ec5\u5fae\u8c03\u5c11\u91cf\u795e\u7ecf\u5143\u7684\u6fc0\u6d3b\u503c\uff0c\u786c\u4ef6\u5c42\u9762\u901a\u8fc7\u76d1\u63a7\u795e\u7ecf\u5143\u7684\u6700\u91cd\u8981\u4f4d\u62168\u4f4d\u6307\u6570\u6765\u68c0\u6d4b\u7279\u5b9a\u6fc0\u6d3b\uff0c\u5e76\u76f4\u63a5\u64cd\u7eb5\u6700\u7ec8\u8f93\u51falogits\u5b9e\u73b0\u8bef\u5206\u7c7b\u3002", "result": "\u5728MNIST\u3001CIFAR10\u3001GTSRB\u548cImageNet\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHAMLOCK\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u4e14\u6e05\u6d01\u51c6\u786e\u7387\u4e0b\u964d\u53ef\u5ffd\u7565\uff0c\u6210\u529f\u89c4\u907f\u4e86\u6700\u5148\u8fdb\u7684\u6a21\u578b\u7ea7\u9632\u5fa1\u3002", "conclusion": "HAMLOCK\u66b4\u9732\u4e86\u786c\u4ef6-\u8f6f\u4ef6\u63a5\u53e3\u7684\u5173\u952e\u6f0f\u6d1e\uff0c\u9700\u8981\u65b0\u7684\u8de8\u5c42\u9632\u5fa1\u6765\u5e94\u5bf9\u8fd9\u79cd\u65b0\u5174\u5a01\u80c1\u3002"}}
{"id": "2510.18893", "categories": ["cs.DC", "cs.AI", "cs.SE", "I.2.11; D.2.11"], "pdf": "https://arxiv.org/pdf/2510.18893", "abs": "https://arxiv.org/abs/2510.18893", "authors": ["Sergey Pugachev"], "title": "CodeCRDT: Observation-Driven Coordination for Multi-Agent LLM Code Generation", "comment": "11 pages, 3 figures", "summary": "Multi-agent LLM systems fail to realize parallel speedups due to costly\ncoordination. We present CodeCRDT, an observation-driven coordination pattern\nwhere agents coordinate by monitoring a shared state with observable updates\nand deterministic convergence, rather than explicit message passing. Using\nConflict-Free Replicated Data Types (CRDTs), CodeCRDT enables lock-free,\nconflict-free concurrent code generation with strong eventual consistency.\nEvaluation across 600 trials (6 tasks, 50 runs per mode) shows both benefits\nand trade-offs: up to 21.1% speedup on some tasks, up to 39.4% slowdown on\nothers, and 100% convergence with zero merge failures. The study formalizes\nobservation-driven coordination for stochastic LLM agents, revealing semantic\nconflict rates (5-10%) and quality-performance tradeoffs, and provides\nempirical characterization of when parallel coordination succeeds versus fails\nbased on task structure.", "AI": {"tldr": "CodeCRDT\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c2\u5bdf\u9a71\u52a8\u7684\u534f\u8c03\u6a21\u5f0f\uff0c\u901a\u8fc7\u5171\u4eab\u72b6\u6001\u76d1\u63a7\u800c\u975e\u663e\u5f0f\u6d88\u606f\u4f20\u9012\u6765\u5b9e\u73b0\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u7684\u5e76\u884c\u52a0\u901f\uff0c\u4f7f\u7528CRDT\u6280\u672f\u5b9e\u73b0\u65e0\u9501\u3001\u65e0\u51b2\u7a81\u7684\u5e76\u53d1\u4ee3\u7801\u751f\u6210\u3002", "motivation": "\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u7531\u4e8e\u6602\u8d35\u7684\u534f\u8c03\u6210\u672c\u800c\u65e0\u6cd5\u5b9e\u73b0\u5e76\u884c\u52a0\u901f\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u534f\u8c03\u673a\u5236\u6765\u63d0\u5347\u6027\u80fd\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u51b2\u7a81\u81ea\u7531\u590d\u5236\u6570\u636e\u7c7b\u578b\uff08CRDTs\uff09\u7684\u89c2\u5bdf\u9a71\u52a8\u534f\u8c03\u6a21\u5f0f\uff0c\u667a\u80fd\u4f53\u901a\u8fc7\u76d1\u63a7\u5171\u4eab\u72b6\u6001\u7684\u53ef\u89c1\u66f4\u65b0\u548c\u786e\u5b9a\u6027\u6536\u655b\u6765\u8fdb\u884c\u534f\u8c03\uff0c\u800c\u4e0d\u662f\u663e\u5f0f\u6d88\u606f\u4f20\u9012\u3002", "result": "\u5728600\u6b21\u8bd5\u9a8c\uff086\u4e2a\u4efb\u52a1\uff0c\u6bcf\u79cd\u6a21\u5f0f50\u6b21\u8fd0\u884c\uff09\u4e2d\uff0c\u67d0\u4e9b\u4efb\u52a1\u5b9e\u73b0\u4e86\u6700\u9ad821.1%\u7684\u52a0\u901f\uff0c\u5176\u4ed6\u4efb\u52a1\u6700\u591a39.4%\u7684\u51cf\u901f\uff0c100%\u6536\u655b\u4e14\u96f6\u5408\u5e76\u5931\u8d25\u3002\u63ed\u793a\u4e865-10%\u7684\u8bed\u4e49\u51b2\u7a81\u7387\u548c\u8d28\u91cf-\u6027\u80fd\u6743\u8861\u3002", "conclusion": "\u7814\u7a76\u5f62\u5f0f\u5316\u4e86\u968f\u673aLLM\u667a\u80fd\u4f53\u7684\u89c2\u5bdf\u9a71\u52a8\u534f\u8c03\uff0c\u63d0\u4f9b\u4e86\u57fa\u4e8e\u4efb\u52a1\u7ed3\u6784\u7684\u5e76\u884c\u534f\u8c03\u6210\u529f\u4e0e\u5931\u8d25\u7684\u5b9e\u8bc1\u7279\u5f81\u63cf\u8ff0\u3002"}}
{"id": "2510.19139", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.19139", "abs": "https://arxiv.org/abs/2510.19139", "authors": ["Sohyeon Jeon", "Hyung-Chul Lee"], "title": "A Multi-faceted Analysis of Cognitive Abilities: Evaluating Prompt Methods with Large Language Models on the CONSORT Checklist", "comment": null, "summary": "Despite the rapid expansion of Large Language Models (LLMs) in healthcare,\nthe ability of these systems to assess clinical trial reporting according to\nCONSORT standards remains unclear, particularly with respect to their cognitive\nand reasoning strategies. This study applies a behavioral and metacognitive\nanalytic approach with expert-validated data, systematically comparing two\nrepresentative LLMs under three prompt conditions. Clear differences emerged in\nhow the models approached various CONSORT items, and prompt types, including\nshifts in reasoning style, explicit uncertainty, and alternative\ninterpretations shaped response patterns. Our results highlight the current\nlimitations of these systems in clinical compliance automation and underscore\nthe importance of understanding their cognitive adaptations and strategic\nbehavior in developing more explainable and reliable medical AI.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u884c\u4e3a\u548c\u5143\u8ba4\u77e5\u5206\u6790\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e86\u4e24\u79cd\u4ee3\u8868\u6027LLM\u5728\u4e09\u79cd\u63d0\u793a\u6761\u4ef6\u4e0b\u8bc4\u4f30\u4e34\u5e8a\u8bd5\u9a8c\u62a5\u544aCONSORT\u6807\u51c6\u7684\u8ba4\u77e5\u548c\u63a8\u7406\u7b56\u7565\u5dee\u5f02\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u533b\u7597\u9886\u57df\u5feb\u901f\u6269\u5f20\uff0c\u4f46\u5176\u6839\u636eCONSORT\u6807\u51c6\u8bc4\u4f30\u4e34\u5e8a\u8bd5\u9a8c\u62a5\u544a\u7684\u80fd\u529b\u5c1a\u4e0d\u660e\u786e\uff0c\u7279\u522b\u662f\u5728\u8ba4\u77e5\u548c\u63a8\u7406\u7b56\u7565\u65b9\u9762\u3002", "method": "\u91c7\u7528\u884c\u4e3a\u548c\u5143\u8ba4\u77e5\u5206\u6790\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e13\u5bb6\u9a8c\u8bc1\u6570\u636e\uff0c\u7cfb\u7edf\u6bd4\u8f83\u4e24\u79cd\u4ee3\u8868\u6027LLM\u5728\u4e09\u79cd\u63d0\u793a\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u6a21\u578b\u5728\u5904\u7406\u4e0d\u540cCONSORT\u9879\u76ee\u548c\u63d0\u793a\u7c7b\u578b\u65f6\u8868\u73b0\u51fa\u660e\u663e\u5dee\u5f02\uff0c\u5305\u62ec\u63a8\u7406\u98ce\u683c\u8f6c\u53d8\u3001\u660e\u786e\u4e0d\u786e\u5b9a\u6027\u548c\u66ff\u4ee3\u89e3\u91ca\u7b49\u54cd\u5e94\u6a21\u5f0f\u53d8\u5316\u3002", "conclusion": "\u7ed3\u679c\u51f8\u663e\u4e86\u5f53\u524d\u7cfb\u7edf\u5728\u4e34\u5e8a\u5408\u89c4\u81ea\u52a8\u5316\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u4e86\u7406\u89e3\u5176\u8ba4\u77e5\u9002\u5e94\u548c\u7b56\u7565\u884c\u4e3a\u5bf9\u4e8e\u5f00\u53d1\u66f4\u53ef\u89e3\u91ca\u548c\u53ef\u9760\u7684\u533b\u7597AI\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.19169", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.19169", "abs": "https://arxiv.org/abs/2510.19169", "authors": ["Thomas Wang", "Haowen Li"], "title": "OpenGuardrails: An Open-Source Context-Aware AI Guardrails Platform", "comment": null, "summary": "As large language models (LLMs) become increasingly integrated into\nreal-world applications, safeguarding them against unsafe, malicious, or\nprivacy-violating content is critically important. We present OpenGuardrails,\nthe first open-source project to provide both a context-aware safety and\nmanipulation detection model and a deployable platform for comprehensive AI\nguardrails. OpenGuardrails protects against content-safety risks,\nmodel-manipulation attacks (e.g., prompt injection, jailbreaking,\ncode-interpreter abuse, and the generation/execution of malicious code), and\ndata leakage. Content-safety and model-manipulation detection are implemented\nby a unified large model, while data-leakage identification and redaction are\nperformed by a separate lightweight NER pipeline (e.g., Presidio-style models\nor regex-based detectors). The system can be deployed as a security gateway or\nan API-based service, with enterprise-grade, fully private deployment options.\nOpenGuardrails achieves state-of-the-art (SOTA) performance on safety\nbenchmarks, excelling in both prompt and response classification across\nEnglish, Chinese, and multilingual tasks. All models are released under the\nApache 2.0 license for public use.", "AI": {"tldr": "OpenGuardrails\u662f\u4e00\u4e2a\u5f00\u6e90\u9879\u76ee\uff0c\u63d0\u4f9b\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5b89\u5168\u6027\u548c\u64cd\u4f5c\u68c0\u6d4b\u6a21\u578b\uff0c\u4ee5\u53ca\u53ef\u90e8\u7f72\u7684AI\u62a4\u680f\u5e73\u53f0\uff0c\u4fdd\u62a4\u5185\u5bb9\u5b89\u5168\u3001\u9632\u6b62\u6a21\u578b\u64cd\u4f5c\u653b\u51fb\u548c\u6570\u636e\u6cc4\u9732\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u5e7f\u6cdb\u96c6\u6210\uff0c\u4fdd\u62a4\u5b83\u4eec\u514d\u53d7\u4e0d\u5b89\u5168\u3001\u6076\u610f\u6216\u4fb5\u72af\u9690\u79c1\u7684\u5185\u5bb9\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u7edf\u4e00\u7684\u5927\u6a21\u578b\u5b9e\u73b0\u5185\u5bb9\u5b89\u5168\u548c\u6a21\u578b\u64cd\u4f5c\u68c0\u6d4b\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7NER\u7ba1\u9053\uff08\u5982Presidio\u98ce\u683c\u6a21\u578b\u6216\u57fa\u4e8e\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u68c0\u6d4b\u5668\uff09\u8fdb\u884c\u6570\u636e\u6cc4\u9732\u8bc6\u522b\u548c\u7f16\u8f91\u3002\u7cfb\u7edf\u53ef\u4f5c\u4e3a\u5b89\u5168\u7f51\u5173\u6216\u57fa\u4e8eAPI\u7684\u670d\u52a1\u90e8\u7f72\u3002", "result": "\u5728\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u82f1\u8bed\u3001\u4e2d\u6587\u548c\u591a\u8bed\u8a00\u4efb\u52a1\u4e2d\u7684\u63d0\u793a\u548c\u54cd\u5e94\u5206\u7c7b\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u6240\u6709\u6a21\u578b\u5747\u4ee5Apache 2.0\u8bb8\u53ef\u8bc1\u53d1\u5e03\u4f9b\u516c\u4f17\u4f7f\u7528\uff0c\u63d0\u4f9b\u4f01\u4e1a\u7ea7\u3001\u5b8c\u5168\u79c1\u6709\u7684\u90e8\u7f72\u9009\u9879\u3002"}}
{"id": "2510.18897", "categories": ["cs.DC", "cs.AI", "cs.DB", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18897", "abs": "https://arxiv.org/abs/2510.18897", "authors": ["Jacopo Tagliabue"], "title": "AI for Distributed Systems Design: Scalable Cloud Optimization Through Repeated LLMs Sampling And Simulators", "comment": "Pre-print IAAA workshop submission", "summary": "We explore AI-driven distributed-systems policy design by combining\nstochastic code generation from large language models (LLMs) with deterministic\nverification in a domain-specific simulator. Using a Function-as-a-Service\nruntime (Bauplan) and its open-source simulator (Eudoxia) as a case study, we\nframe scheduler design as an iterative generate-and-verify loop: an LLM\nproposes a Python policy, the simulator evaluates it on standardized traces,\nand structured feedback steers subsequent generations. This setup preserves\ninterpretability while enabling targeted search over a large design space. We\ndetail the system architecture and report preliminary results on throughput\nimprovements across multiple models. Beyond early gains, we discuss the limits\nof the current setup and outline next steps; in particular, we conjecture that\nAI will be crucial for scaling this methodology by helping to bootstrap new\nsimulators.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u968f\u673a\u4ee3\u7801\u751f\u6210\u548c\u786e\u5b9a\u6027\u9a8c\u8bc1\u7684AI\u9a71\u52a8\u5206\u5e03\u5f0f\u7cfb\u7edf\u7b56\u7565\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210-\u9a8c\u8bc1\u5faa\u73af\u6846\u67b6\u5b9e\u73b0\u8c03\u5ea6\u5668\u8bbe\u8ba1\u3002", "motivation": "\u63a2\u7d22AI\u5728\u5206\u5e03\u5f0f\u7cfb\u7edf\u7b56\u7565\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u7ed3\u5408LLMs\u7684\u751f\u6210\u80fd\u529b\u548c\u9886\u57df\u7279\u5b9a\u6a21\u62df\u5668\u7684\u9a8c\u8bc1\uff0c\u5728\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u5927\u89c4\u6a21\u8bbe\u8ba1\u7a7a\u95f4\u7684\u5b9a\u5411\u641c\u7d22\u3002", "method": "\u4f7f\u7528Function-as-a-Service\u8fd0\u884c\u65f6\uff08Bauplan\uff09\u53ca\u5176\u5f00\u6e90\u6a21\u62df\u5668\uff08Eudoxia\uff09\u4f5c\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u5efa\u7acb\u8fed\u4ee3\u7684\u751f\u6210-\u9a8c\u8bc1\u5faa\u73af\uff1aLLM\u63d0\u51faPython\u7b56\u7565\uff0c\u6a21\u62df\u5668\u5728\u6807\u51c6\u5316\u8ddf\u8e2a\u4e0a\u8bc4\u4f30\uff0c\u7ed3\u6784\u5316\u53cd\u9988\u6307\u5bfc\u540e\u7eed\u751f\u6210\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u4e0a\u62a5\u544a\u4e86\u541e\u5410\u91cf\u6539\u8fdb\u7684\u521d\u6b65\u7ed3\u679c\uff0c\u5c55\u793a\u4e86\u65e9\u671f\u6536\u76ca\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u5f53\u524d\u8bbe\u7f6e\u7684\u5c40\u9650\u6027\u5e76\u6982\u8ff0\u4e86\u540e\u7eed\u6b65\u9aa4\uff0c\u7279\u522b\u63a8\u6d4bAI\u5728\u901a\u8fc7\u5e2e\u52a9\u5f15\u5bfc\u65b0\u6a21\u62df\u5668\u6765\u6269\u5c55\u8be5\u65b9\u6cd5\u8bba\u65b9\u9762\u5c06\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.19176", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.19176", "abs": "https://arxiv.org/abs/2510.19176", "authors": ["Yuqiao Tan", "Shizhu He", "Kang Liu", "Jun Zhao"], "title": "The Zero-Step Thinking: An Empirical Study of Mode Selection as Harder Early Exit in Reasoning Models", "comment": "Accepted by NeurIPS'25 Efficient Reasoning Workshop", "summary": "Reasoning models have demonstrated exceptional performance in tasks such as\nmathematics and logical reasoning, primarily due to their ability to engage in\nstep-by-step thinking during the reasoning process. However, this often leads\nto overthinking, resulting in unnecessary computational overhead. To address\nthis issue, Mode Selection aims to automatically decide between Long-CoT\n(Chain-of-Thought) or Short-CoT by utilizing either a Thinking or NoThinking\nmode. Simultaneously, Early Exit determines the optimal stopping point during\nthe iterative reasoning process. Both methods seek to reduce the computational\nburden. In this paper, we first identify Mode Selection as a more challenging\nvariant of the Early Exit problem, as they share similar objectives but differ\nin decision timing. While Early Exit focuses on determining the best stopping\npoint for concise reasoning at inference time, Mode Selection must make this\ndecision at the beginning of the reasoning process, relying on pre-defined fake\nthoughts without engaging in an explicit reasoning process, referred to as\nzero-step thinking. Through empirical studies on nine baselines, we observe\nthat prompt-based approaches often fail due to their limited classification\ncapabilities when provided with minimal hand-crafted information. In contrast,\napproaches that leverage internal information generally perform better across\nmost scenarios but still exhibit issues with stability. Our findings indicate\nthat existing methods relying solely on the information provided by models are\ninsufficient for effectively addressing Mode Selection in scenarios with\nlimited information, highlighting the ongoing challenges of this task. Our code\nis available at https://github.com/Trae1ounG/Zero_Step_Thinking.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u6a21\u5f0f\u9009\u62e9\u95ee\u9898\uff0c\u5c06\u5176\u89c6\u4e3a\u65e9\u671f\u9000\u51fa\u95ee\u9898\u7684\u66f4\u5177\u6311\u6218\u6027\u53d8\u4f53\u3002\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5728\u4fe1\u606f\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u96be\u4ee5\u6709\u6548\u89e3\u51b3\u6a21\u5f0f\u9009\u62e9\u95ee\u9898\u3002", "motivation": "\u63a8\u7406\u6a21\u578b\u5728\u6570\u5b66\u548c\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u9010\u6b65\u601d\u8003\u8fc7\u7a0b\u5e38\u5bfc\u81f4\u8fc7\u5ea6\u601d\u8003\uff0c\u4ea7\u751f\u4e0d\u5fc5\u8981\u7684\u8ba1\u7b97\u5f00\u9500\u3002\u6a21\u5f0f\u9009\u62e9\u548c\u65e9\u671f\u9000\u51fa\u65b9\u6cd5\u65e8\u5728\u51cf\u5c11\u8fd9\u79cd\u8ba1\u7b97\u8d1f\u62c5\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u6bd4\u8f83\u4e86\u4e5d\u79cd\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\u548c\u5229\u7528\u6a21\u578b\u5185\u90e8\u4fe1\u606f\u7684\u65b9\u6cd5\u3002\u6a21\u5f0f\u9009\u62e9\u9700\u8981\u5728\u63a8\u7406\u8fc7\u7a0b\u5f00\u59cb\u65f6\u505a\u51fa\u51b3\u7b56\uff0c\u4f9d\u8d56\u9884\u5b9a\u4e49\u7684\u865a\u5047\u601d\u8003\uff08\u96f6\u6b65\u601d\u8003\uff09\u3002", "result": "\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\u7531\u4e8e\u5206\u7c7b\u80fd\u529b\u6709\u9650\u800c\u7ecf\u5e38\u5931\u8d25\uff0c\u800c\u5229\u7528\u5185\u90e8\u4fe1\u606f\u7684\u65b9\u6cd5\u5728\u5927\u591a\u6570\u573a\u666f\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u4ecd\u5b58\u5728\u7a33\u5b9a\u6027\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u4fe1\u606f\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u4e0d\u8db3\u4ee5\u6709\u6548\u89e3\u51b3\u6a21\u5f0f\u9009\u62e9\u95ee\u9898\u3002", "conclusion": "\u6a21\u5f0f\u9009\u62e9\u662f\u65e9\u671f\u9000\u51fa\u95ee\u9898\u7684\u66f4\u5177\u6311\u6218\u6027\u53d8\u4f53\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u4fe1\u606f\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u4ecd\u9762\u4e34\u56f0\u96be\uff0c\u7a81\u663e\u4e86\u8be5\u4efb\u52a1\u7684\u6301\u7eed\u6311\u6218\u3002"}}
{"id": "2510.19012", "categories": ["cs.DC", "cs.DB", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.19012", "abs": "https://arxiv.org/abs/2510.19012", "authors": ["Ivan Borodii", "Illia Fedorovych", "Halyna Osukhivska", "Diana Velychko", "Roman Butsii"], "title": "Comparative analysis of large data processing in Apache Spark using Java, Python and Scala", "comment": "CITI 2025, 3rd International Workshop on Computer Information\n  Technologies in Industry 4.0, June 11-12, 2025, Ternopil, Ukraine. The\n  article includes 10 pages, 5 figures, 9 tables", "summary": "During the study, the results of a comparative analysis of the process of\nhandling large datasets using the Apache Spark platform in Java, Python, and\nScala programming languages were obtained. Although prior works have focused on\nindividual stages, comprehensive comparisons of full ETL workflows across\nprogramming languages using Apache Iceberg remain limited. The analysis was\nperformed by executing several operations, including downloading data from CSV\nfiles, transforming and loading it into an Apache Iceberg analytical table. It\nwas found that the performance of the Spark algorithm varies significantly\ndepending on the amount of data and the programming language used. When\nprocessing a 5-megabyte CSV file, the best result was achieved in Python: 6.71\nseconds, which is superior to Scala's score of 9.13 seconds and Java's time of\n9.62 seconds. For processing a large CSV file of 1.6 gigabytes, all programming\nlanguages demonstrated similar results: the fastest performance was showed in\nPython: 46.34 seconds, while Scala and Java showed results of 47.72 and 50.56\nseconds, respectively. When performing a more complex operation that involved\ncombining two CSV files into a single dataset for further loading into an\nApache Iceberg table, Scala demonstrated the highest performance, at 374.42\nseconds. Java processing was completed in 379.8 seconds, while Python was the\nleast efficient, with a runtime of 398.32 seconds. It follows that the\nprogramming language significantly affects the efficiency of data processing by\nthe Apache Spark algorithm, with Scala and Java being more productive for\nprocessing large amounts of data and complex operations, while Python\ndemonstrates an advantage in working with small amounts of data. The results\nobtained can be useful for optimizing data handling processes depending on\nspecific performance requirements and the amount of information being\nprocessed.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u5728Apache Spark\u5e73\u53f0\u4e0a\u4f7f\u7528Java\u3001Python\u548cScala\u5904\u7406\u5927\u6570\u636e\u7684\u6027\u80fd\u5dee\u5f02\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5bf9\u4e8e\u5c0f\u6570\u636e\u96c6\uff085MB\uff09\uff0cPython\u8868\u73b0\u6700\u4f73\uff086.71\u79d2\uff09\uff1b\u5bf9\u4e8e\u5927\u6570\u636e\u96c6\uff081.6GB\uff09\uff0c\u4e09\u79cd\u8bed\u8a00\u6027\u80fd\u76f8\u8fd1\uff0cPython\u7565\u4f18\uff0846.34\u79d2\uff09\uff1b\u5bf9\u4e8e\u590d\u6742\u64cd\u4f5c\uff08\u5408\u5e76\u4e24\u4e2aCSV\u6587\u4ef6\uff09\uff0cScala\u8868\u73b0\u6700\u597d\uff08374.42\u79d2\uff09\u3002", "motivation": "\u867d\u7136\u5df2\u6709\u7814\u7a76\u5173\u6ce8\u5355\u4e2a\u5904\u7406\u9636\u6bb5\uff0c\u4f46\u4f7f\u7528Apache Iceberg\u8de8\u7f16\u7a0b\u8bed\u8a00\u5bf9\u5b8c\u6574ETL\u5de5\u4f5c\u6d41\u7a0b\u8fdb\u884c\u5168\u9762\u6bd4\u8f83\u7684\u7814\u7a76\u4ecd\u7136\u6709\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5206\u6790\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u5728Apache Spark\u5e73\u53f0\u4e0a\u7684\u6570\u636e\u5904\u7406\u6027\u80fd\u5dee\u5f02\u3002", "method": "\u901a\u8fc7\u6267\u884c\u591a\u4e2a\u64cd\u4f5c\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\uff0c\u5305\u62ec\u4eceCSV\u6587\u4ef6\u4e0b\u8f7d\u6570\u636e\u3001\u8f6c\u6362\u6570\u636e\u5e76\u5c06\u5176\u52a0\u8f7d\u5230Apache Iceberg\u5206\u6790\u8868\u4e2d\u3002\u6d4b\u8bd5\u4e86\u4e0d\u540c\u5927\u5c0f\u7684\u6570\u636e\u96c6\uff085MB\u548c1.6GB\uff09\u4ee5\u53ca\u590d\u6742\u64cd\u4f5c\uff08\u5408\u5e76\u4e24\u4e2aCSV\u6587\u4ef6\uff09\u3002", "result": "\u5904\u74065MB CSV\u6587\u4ef6\u65f6\uff0cPython\u6700\u5feb\uff086.71\u79d2\uff09\uff0cScala\u6b21\u4e4b\uff089.13\u79d2\uff09\uff0cJava\u6700\u6162\uff089.62\u79d2\uff09\u3002\u5904\u74061.6GB CSV\u6587\u4ef6\u65f6\uff0c\u4e09\u79cd\u8bed\u8a00\u6027\u80fd\u76f8\u8fd1\uff1aPython\uff0846.34\u79d2\uff09\u3001Scala\uff0847.72\u79d2\uff09\u3001Java\uff0850.56\u79d2\uff09\u3002\u590d\u6742\u64cd\u4f5c\u4e2d\uff0cScala\u6700\u5feb\uff08374.42\u79d2\uff09\uff0cJava\u6b21\u4e4b\uff08379.8\u79d2\uff09\uff0cPython\u6700\u6162\uff08398.32\u79d2\uff09\u3002", "conclusion": "\u7f16\u7a0b\u8bed\u8a00\u663e\u8457\u5f71\u54cdApache Spark\u7b97\u6cd5\u7684\u6570\u636e\u5904\u7406\u6548\u7387\u3002Scala\u548cJava\u5728\u5904\u7406\u5927\u6570\u636e\u91cf\u548c\u590d\u6742\u64cd\u4f5c\u65f6\u66f4\u5177\u751f\u4ea7\u529b\uff0c\u800cPython\u5728\u5904\u7406\u5c0f\u6570\u636e\u91cf\u65f6\u5177\u6709\u4f18\u52bf\u3002\u8fd9\u4e9b\u7ed3\u679c\u53ef\u6839\u636e\u7279\u5b9a\u6027\u80fd\u8981\u6c42\u548c\u5904\u7406\u4fe1\u606f\u91cf\u6765\u4f18\u5316\u6570\u636e\u5904\u7406\u8fc7\u7a0b\u3002"}}
{"id": "2510.19205", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19205", "abs": "https://arxiv.org/abs/2510.19205", "authors": ["Yaoyao Qian", "Yuanli Wang", "Jinda Zhang", "Yun Zong", "Meixu Chen", "Hanhan Zhou", "Jindan Huang", "Yifan Zeng", "Xinyu Hu", "Chan Hee Song", "Danqing Zhang"], "title": "WebGraphEval: Multi-Turn Trajectory Evaluation for Web Agents using Graph Representation", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025) Workshop: Multi-Turn Interactions in Large Language Models", "summary": "Current evaluation of web agents largely reduces to binary success metrics or\nconformity to a single reference trajectory, ignoring the structural diversity\npresent in benchmark datasets. We present WebGraphEval, a framework that\nabstracts trajectories from multiple agents into a unified, weighted action\ngraph. This representation is directly compatible with benchmarks such as\nWebArena, leveraging leaderboard runs and newly collected trajectories without\nmodifying environments. The framework canonically encodes actions, merges\nrecurring behaviors, and applies structural analyses including reward\npropagation and success-weighted edge statistics. Evaluations across thousands\nof trajectories from six web agents show that the graph abstraction captures\ncross-model regularities, highlights redundancy and inefficiency, and\nidentifies critical decision points overlooked by outcome-based metrics. By\nframing web interaction as graph-structured data, WebGraphEval establishes a\ngeneral methodology for multi-path, cross-agent, and efficiency-aware\nevaluation of web agents.", "AI": {"tldr": "WebGraphEval\u662f\u4e00\u4e2a\u5c06\u591a\u4e2a\u667a\u80fd\u4f53\u7684\u8f68\u8ff9\u62bd\u8c61\u4e3a\u7edf\u4e00\u52a0\u6743\u52a8\u4f5c\u56fe\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u7f51\u9875\u667a\u80fd\u4f53\uff0c\u80fd\u591f\u6355\u6349\u7ed3\u6784\u591a\u6837\u6027\u5e76\u8bc6\u522b\u5173\u952e\u51b3\u7b56\u70b9\u3002", "motivation": "\u5f53\u524d\u7f51\u9875\u667a\u80fd\u4f53\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u4e8e\u4e8c\u5143\u6210\u529f\u6307\u6807\u6216\u5355\u4e00\u53c2\u8003\u8f68\u8ff9\uff0c\u5ffd\u7565\u4e86\u57fa\u51c6\u6570\u636e\u96c6\u4e2d\u7684\u7ed3\u6784\u591a\u6837\u6027\u3002", "method": "\u5c06\u591a\u4e2a\u667a\u80fd\u4f53\u7684\u8f68\u8ff9\u62bd\u8c61\u4e3a\u7edf\u4e00\u7684\u52a0\u6743\u52a8\u4f5c\u56fe\uff0c\u8fdb\u884c\u89c4\u8303\u5316\u7f16\u7801\u3001\u5408\u5e76\u91cd\u590d\u884c\u4e3a\uff0c\u5e76\u5e94\u7528\u7ed3\u6784\u5206\u6790\uff08\u5982\u5956\u52b1\u4f20\u64ad\u548c\u6210\u529f\u52a0\u6743\u8fb9\u7edf\u8ba1\uff09\u3002", "result": "\u5728\u6765\u81ea\u516d\u4e2a\u7f51\u9875\u667a\u80fd\u4f53\u7684\u6570\u5343\u6761\u8f68\u8ff9\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u56fe\u62bd\u8c61\u80fd\u591f\u6355\u6349\u8de8\u6a21\u578b\u89c4\u5f8b\u3001\u7a81\u51fa\u5197\u4f59\u548c\u4f4e\u6548\u884c\u4e3a\uff0c\u5e76\u8bc6\u522b\u88ab\u57fa\u4e8e\u7ed3\u679c\u7684\u6307\u6807\u5ffd\u7565\u7684\u5173\u952e\u51b3\u7b56\u70b9\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7f51\u9875\u4ea4\u4e92\u6784\u5efa\u4e3a\u56fe\u7ed3\u6784\u6570\u636e\uff0cWebGraphEval\u4e3a\u7f51\u9875\u667a\u80fd\u4f53\u7684\u591a\u8def\u5f84\u3001\u8de8\u667a\u80fd\u4f53\u548c\u6548\u7387\u611f\u77e5\u8bc4\u4f30\u5efa\u7acb\u4e86\u901a\u7528\u65b9\u6cd5\u3002"}}
{"id": "2510.19264", "categories": ["cs.CR", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.19264", "abs": "https://arxiv.org/abs/2510.19264", "authors": ["R. Can Aygun", "Yehuda Afek", "Anat Bremler-Barr", "Leonard Kleinrock"], "title": "LAPRAD: LLM-Assisted PRotocol Attack Discovery", "comment": "IFIP Networking 2025 Proceedings (Accepted on 05.05.2025)", "summary": "With the goal of improving the security of Internet protocols, we seek\nfaster, semi-automatic methods to discover new vulnerabilities in protocols\nsuch as DNS, BGP, and others. To this end, we introduce the LLM-Assisted\nProtocol Attack Discovery (LAPRAD) methodology, enabling security researchers\nwith some DNS knowledge to efficiently uncover vulnerabilities that would\notherwise be hard to detect.\n  LAPRAD follows a three-stage process. In the first, we consult an LLM\n(GPT-o1) that has been trained on a broad corpus of DNS-related sources and\nprevious DDoS attacks to identify potential exploits. In the second stage, a\ndifferent LLM automatically constructs the corresponding attack configurations\nusing the ReACT approach implemented via LangChain (DNS zone file generation).\nFinally, in the third stage, we validate the attack's functionality and\neffectiveness.\n  Using LAPRAD, we uncovered three new DDoS attacks on the DNS protocol and\nrediscovered two recently reported ones that were not included in the LLM's\ntraining data. The first new attack employs a bait-and-switch technique to\ntrick resolvers into caching large, bogus DNSSEC RRSIGs, reducing their serving\ncapacity to as little as 6%. The second exploits large DNSSEC encryption\nalgorithms (RSA-4096) with multiple keys, thereby bypassing a recently\nimplemented default RRSet limit. The third leverages ANY-type responses to\nproduce a similar effect.\n  These variations of a cache-flushing DDoS attack, called SigCacheFlush,\ncircumvent existing patches, severely degrade resolver query capacity, and\nimpact the latest versions of major DNS resolver implementations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLAPRAD\u7684LLM\u8f85\u52a9\u534f\u8bae\u653b\u51fb\u53d1\u73b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u6d41\u7a0b\uff08\u8bc6\u522b\u6f5c\u5728\u6f0f\u6d1e\u3001\u81ea\u52a8\u6784\u5efa\u653b\u51fb\u914d\u7f6e\u3001\u9a8c\u8bc1\u6709\u6548\u6027\uff09\u6765\u53d1\u73b0DNS\u534f\u8bae\u4e2d\u7684\u65b0DDoS\u653b\u51fb\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u4e92\u8054\u7f51\u534f\u8bae\u7684\u5b89\u5168\u6027\uff0c\u9700\u8981\u66f4\u5feb\u3001\u534a\u81ea\u52a8\u7684\u65b9\u6cd5\u6765\u53d1\u73b0DNS\u3001BGP\u7b49\u534f\u8bae\u4e2d\u7684\u65b0\u6f0f\u6d1e\u3002", "method": "LAPRAD\u91c7\u7528\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a1) \u54a8\u8be2\u7ecf\u8fc7DNS\u76f8\u5173\u6570\u636e\u8bad\u7ec3\u7684LLM\u8bc6\u522b\u6f5c\u5728\u6f0f\u6d1e\uff1b2) \u4f7f\u7528\u4e0d\u540cLLM\u901a\u8fc7ReACT\u65b9\u6cd5\u81ea\u52a8\u6784\u5efa\u653b\u51fb\u914d\u7f6e\uff1b3) \u9a8c\u8bc1\u653b\u51fb\u7684\u529f\u80fd\u6027\u548c\u6709\u6548\u6027\u3002", "result": "\u4f7f\u7528LAPRAD\u53d1\u73b0\u4e86\u4e09\u79cd\u65b0\u7684DNS DDoS\u653b\u51fb\uff1a1) \u8bf1\u9975\u5207\u6362\u6280\u672f\u6b3a\u9a97\u89e3\u6790\u5668\u7f13\u5b58\u5927\u578b\u4f2a\u9020DNSSEC RRSIG\uff1b2) \u5229\u7528\u5927\u578bDNSSEC\u52a0\u5bc6\u7b97\u6cd5\u7ed5\u8fc7RRSet\u9650\u5236\uff1b3) \u5229\u7528ANY\u7c7b\u578b\u54cd\u5e94\u4ea7\u751f\u7c7b\u4f3c\u6548\u679c\u3002\u8fd9\u4e9b\u653b\u51fb\u4e25\u91cd\u964d\u4f4e\u89e3\u6790\u5668\u67e5\u8be2\u80fd\u529b\u81f36%\u3002", "conclusion": "LAPRAD\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u53d1\u73b0\u65b0\u7684DNS\u534f\u8bae\u6f0f\u6d1e\uff0c\u8fd9\u4e9b\u540d\u4e3aSigCacheFlush\u7684\u7f13\u5b58\u5237\u65b0DDoS\u653b\u51fb\u53d8\u79cd\u80fd\u591f\u7ed5\u8fc7\u73b0\u6709\u8865\u4e01\uff0c\u5f71\u54cd\u4e3b\u8981DNS\u89e3\u6790\u5668\u5b9e\u73b0\u7684\u6700\u65b0\u7248\u672c\u3002"}}
{"id": "2510.19151", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.19151", "abs": "https://arxiv.org/abs/2510.19151", "authors": ["Seri Khoury", "Manish Purohit", "Aaron Schild", "Joshua Wang"], "title": "On the Randomized Locality of Matching Problems in Regular Graphs", "comment": "DISC 2025. Abstract modified for arXiv", "summary": "The main goal in distributed symmetry-breaking is to understand the locality\nof problems; i.e., the radius of the neighborhood that a node needs to explore\nin order to arrive at its part of a global solution. In this work, we study the\nlocality of matching problems in the family of regular graphs, which is one of\nthe main benchmarks for establishing lower bounds on the locality of\nsymmetry-breaking problems, as well as for obtaining classification results.\nFor approximate matching, we develop randomized algorithms to show that $(1 +\n\\epsilon)$-approximate matching in regular graphs is truly local; i.e., the\nlocality depends only on $\\epsilon$ and is independent of all other graph\nparameters. Furthermore, as long as the degree $\\Delta$ is not very small\n(namely, as long as $\\Delta \\geq \\text{poly}(1/\\epsilon)$), this dependence is\nonly logarithmic in $1/\\epsilon$. This stands in sharp contrast to maximal\nmatching in regular graphs which requires some dependence on the number of\nnodes $n$ or the degree $\\Delta$. We show matching lower bounds for both\nresults. For maximal matching, our techniques further allow us to establish a\nstrong separation between the node-averaged complexity and worst-case\ncomplexity of maximal matching in regular graphs, by showing that the former is\nonly $O(1)$. Central to our main technical contribution is a novel\nmartingale-based analysis for the $\\approx 40$-year-old algorithm by Luby. In\nparticular, our analysis shows that applying one round of Luby's algorithm on\nthe line graph of a $\\Delta$-regular graph results in an almost\n$\\Delta/2$-regular graph.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6b63\u5219\u56fe\u4e2d\u5339\u914d\u95ee\u9898\u7684\u5c40\u90e8\u6027\uff0c\u8bc1\u660e\u4e86(1+\u03b5)-\u8fd1\u4f3c\u5339\u914d\u662f\u771f\u6b63\u5c40\u90e8\u7684\uff08\u4ec5\u4f9d\u8d56\u4e8e\u03b5\uff09\uff0c\u800c\u6700\u5927\u5339\u914d\u9700\u8981\u4f9d\u8d56\u4e8e\u8282\u70b9\u6570n\u6216\u5ea6\u6570\u0394\u3002\u540c\u65f6\u63ed\u793a\u4e86\u6b63\u5219\u56fe\u4e2d\u6700\u5927\u5339\u914d\u7684\u8282\u70b9\u5e73\u5747\u590d\u6742\u5ea6\u4e0e\u6700\u574f\u60c5\u51b5\u590d\u6742\u5ea6\u4e4b\u95f4\u7684\u5f3a\u5206\u79bb\u3002", "motivation": "\u5206\u5e03\u5f0f\u5bf9\u79f0\u6027\u7834\u574f\u7684\u4e3b\u8981\u76ee\u6807\u662f\u7406\u89e3\u95ee\u9898\u7684\u5c40\u90e8\u6027\uff0c\u5373\u8282\u70b9\u9700\u8981\u63a2\u7d22\u90bb\u57df\u7684\u534a\u5f84\u624d\u80fd\u83b7\u5f97\u5168\u5c40\u89e3\u51b3\u65b9\u6848\u3002\u5728\u6b63\u5219\u56fe\u65cf\u4e2d\u7814\u7a76\u5339\u914d\u95ee\u9898\u7684\u5c40\u90e8\u6027\uff0c\u8fd9\u662f\u5efa\u7acb\u5bf9\u79f0\u6027\u7834\u574f\u95ee\u9898\u5c40\u90e8\u6027\u4e0b\u754c\u548c\u5206\u7c7b\u7ed3\u679c\u7684\u4e3b\u8981\u57fa\u51c6\u3002", "method": "\u5f00\u53d1\u968f\u673a\u7b97\u6cd5\uff0c\u4f7f\u7528\u57fa\u4e8e\u9785\u7684\u5206\u6790\u65b9\u6cd5\u5bf9Luby\u5df2\u670940\u5e74\u5386\u53f2\u7684\u7b97\u6cd5\u8fdb\u884c\u5206\u6790\uff0c\u8bc1\u660e\u5728\u0394-\u6b63\u5219\u56fe\u7684\u7ebf\u56fe\u4e0a\u5e94\u7528\u4e00\u8f6eLuby\u7b97\u6cd5\u4f1a\u4ea7\u751f\u51e0\u4e4e\u0394/2-\u6b63\u5219\u7684\u56fe\u3002", "result": "\u8bc1\u660e\u4e86(1+\u03b5)-\u8fd1\u4f3c\u5339\u914d\u5728\u6b63\u5219\u56fe\u4e2d\u662f\u771f\u6b63\u5c40\u90e8\u7684\uff0c\u4ec5\u4f9d\u8d56\u4e8e\u03b5\u4e14\u72ec\u7acb\u4e8e\u5176\u4ed6\u56fe\u53c2\u6570\uff1b\u5f53\u0394\u2265poly(1/\u03b5)\u65f6\uff0c\u8fd9\u79cd\u4f9d\u8d56\u5173\u7cfb\u4ec5\u4e3a1/\u03b5\u7684\u5bf9\u6570\u3002\u540c\u65f6\u5efa\u7acb\u4e86\u6700\u5927\u5339\u914d\u8282\u70b9\u5e73\u5747\u590d\u6742\u5ea6\u4e0e\u6700\u574f\u60c5\u51b5\u590d\u6742\u5ea6\u7684\u5f3a\u5206\u79bb\uff0c\u524d\u8005\u4ec5\u4e3aO(1)\u3002", "conclusion": "\u6b63\u5219\u56fe\u4e2d\u7684\u8fd1\u4f3c\u5339\u914d\u5177\u6709\u771f\u6b63\u7684\u5c40\u90e8\u6027\u7279\u5f81\uff0c\u800c\u6700\u5927\u5339\u914d\u7684\u5c40\u90e8\u6027\u9700\u8981\u4f9d\u8d56\u4e8e\u56fe\u89c4\u6a21\u53c2\u6570\u3002\u8fd9\u4e00\u7ed3\u679c\u63ed\u793a\u4e86\u5206\u5e03\u5f0f\u5bf9\u79f0\u6027\u7834\u574f\u95ee\u9898\u4e2d\u5c40\u90e8\u6027\u7279\u5f81\u7684\u91cd\u8981\u5dee\u5f02\uff0c\u5e76\u4e3a\u7406\u89e3\u5339\u914d\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2510.19261", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19261", "abs": "https://arxiv.org/abs/2510.19261", "authors": ["Marianna Molinari", "Ilaria Angela Amantea", "Marinella Quaranta", "Guido Governatori"], "title": "ChatGPT Unveils Its Limits: Principles of Law Deliver Checkmate", "comment": null, "summary": "This study examines the performance of ChatGPT with an experiment in the\nlegal domain. We compare the outcome with it a baseline using regular\nexpressions (Regex), rather than focusing solely on the assessment against\nhuman performance. The study reveals that even if ChatGPT has access to the\nnecessary knowledge and competencies, it is unable to assemble them, reason\nthrough, in a way that leads to an exhaustive result. This unveils a major\nlimitation of ChatGPT. Intelligence encompasses the ability to break down\ncomplex issues and address them according to multiple required competencies,\nproviding a unified and comprehensive solution. In the legal domain, one of the\nmost crucial tasks is reading legal decisions and extracting key passages\ncondensed from principles of law (PoLs), which are then incorporated into\nsubsequent rulings by judges or defense documents by lawyers. In performing\nthis task, artificial intelligence lacks an all-encompassing understanding and\nreasoning, which makes it inherently limited. Genuine intelligence, remains a\nuniquely human trait, at least in this particular field.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6cd5\u5f8b\u9886\u57df\u5b9e\u9a8c\u8bc4\u4f30ChatGPT\u6027\u80fd\uff0c\u4e0e\u6b63\u5219\u8868\u8fbe\u5f0f\u57fa\u7ebf\u5bf9\u6bd4\uff0c\u53d1\u73b0ChatGPT\u5373\u4f7f\u5177\u5907\u5fc5\u8981\u77e5\u8bc6\u548c\u80fd\u529b\uff0c\u4e5f\u65e0\u6cd5\u6574\u5408\u63a8\u7406\u5f97\u51fa\u5168\u9762\u7ed3\u679c\uff0c\u63ed\u793a\u4e86\u5176\u5728\u590d\u6742\u95ee\u9898\u5206\u89e3\u548c\u7efc\u5408\u89e3\u51b3\u65b9\u9762\u7684\u91cd\u5927\u5c40\u9650\u3002", "motivation": "\u8bc4\u4f30ChatGPT\u5728\u6cd5\u5f8b\u9886\u57df\u7684\u5b9e\u9645\u8868\u73b0\uff0c\u7279\u522b\u662f\u4e0e\u7b80\u5355\u6280\u672f\uff08\u6b63\u5219\u8868\u8fbe\u5f0f\uff09\u7684\u5bf9\u6bd4\uff0c\u800c\u975e\u4ec5\u4e0e\u4eba\u7c7b\u8868\u73b0\u6bd4\u8f83\uff0c\u4ee5\u63ed\u793aAI\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u771f\u5b9e\u5c40\u9650\u6027\u3002", "method": "\u5728\u6cd5\u5f8b\u9886\u57df\u8bbe\u8ba1\u5b9e\u9a8c\uff0c\u5c06ChatGPT\u7684\u8868\u73b0\u4e0e\u57fa\u4e8e\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u57fa\u7ebf\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\uff0c\u91cd\u70b9\u5173\u6ce8\u4ece\u6cd5\u5f8b\u5224\u51b3\u4e2d\u63d0\u53d6\u6cd5\u5f8b\u539f\u5219\u5173\u952e\u6bb5\u843d\u7684\u80fd\u529b\u3002", "result": "ChatGPT\u5373\u4f7f\u62e5\u6709\u5fc5\u8981\u7684\u77e5\u8bc6\u548c\u80fd\u529b\uff0c\u4e5f\u65e0\u6cd5\u6709\u6548\u6574\u5408\u548c\u63a8\u7406\u4ee5\u4ea7\u751f\u5168\u9762\u7ed3\u679c\uff0c\u5728\u590d\u6742\u95ee\u9898\u5206\u89e3\u548c\u591a\u80fd\u529b\u534f\u8c03\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\u3002", "conclusion": "\u771f\u6b63\u7684\u667a\u80fd\u5305\u62ec\u5206\u89e3\u590d\u6742\u95ee\u9898\u5e76\u534f\u8c03\u591a\u79cd\u80fd\u529b\u63d0\u4f9b\u7edf\u4e00\u5168\u9762\u89e3\u51b3\u65b9\u6848\u7684\u80fd\u529b\uff0c\u8fd9\u5728\u6cd5\u5f8b\u9886\u57df\u5c24\u4e3a\u5173\u952e\u3002\u76ee\u524d\uff0c\u771f\u6b63\u7684\u667a\u80fd\u4ecd\u7136\u662f\u4eba\u7c7b\u72ec\u6709\u7684\u7279\u8d28\uff0c\u81f3\u5c11\u5728\u8be5\u7279\u5b9a\u9886\u57df\u5982\u6b64\u3002"}}
{"id": "2510.19225", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19225", "abs": "https://arxiv.org/abs/2510.19225", "authors": ["Yongji Wu", "Xueshen Liu", "Haizhong Zheng", "Juncheng Gu", "Beidi Chen", "Z. Morley Mao", "Arvind Krishnamurthy", "Ion Stoica"], "title": "RLBoost: Harvesting Preemptible Resources for Cost-Efficient Reinforcement Learning on LLMs", "comment": null, "summary": "Reinforcement learning (RL) has become essential for unlocking advanced\nreasoning capabilities in large language models (LLMs). RL workflows involve\ninterleaving rollout and training stages with fundamentally different resource\nrequirements. Rollout typically dominates overall execution time, yet scales\nefficiently through multiple independent instances. In contrast, training\nrequires tightly-coupled GPUs with full-mesh communication. Existing RL\nframeworks fall into two categories: co-located and disaggregated\narchitectures. Co-located ones fail to address this resource tension by forcing\nboth stages to share the same GPUs. Disaggregated architectures, without\nmodifications of well-established RL algorithms, suffer from resource\nunder-utilization. Meanwhile, preemptible GPU resources, i.e., spot instances\non public clouds and spare capacity in production clusters, present significant\ncost-saving opportunities for accelerating RL workflows, if efficiently\nharvested for rollout.\n  In this paper, we present RLBoost, a systematic solution for cost-efficient\nRL training that harvests preemptible GPU resources. Our key insight is that\nrollout's stateless and embarrassingly parallel nature aligns perfectly with\npreemptible and often fragmented resources. To efficiently utilize these\nresources despite frequent and unpredictable availability changes, RLBoost\nadopts a hybrid architecture with three key techniques: (1) adaptive rollout\noffload to dynamically adjust workloads on the reserved (on-demand) cluster,\n(2) pull-based weight transfer that quickly provisions newly available\ninstances, and (3) token-level response collection and migration for efficient\npreemption handling and continuous load balancing. Extensive experiments show\nRLBoost increases training throughput by 1.51x-1.97x while improving cost\nefficiency by 28%-49% compared to using only on-demand GPU resources.", "AI": {"tldr": "RLBoost\u662f\u4e00\u4e2a\u5229\u7528\u53ef\u62a2\u5360GPU\u8d44\u6e90\u8fdb\u884c\u6210\u672c\u9ad8\u6548\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5378\u8f7d\u3001\u57fa\u4e8e\u62c9\u53d6\u7684\u6743\u91cd\u8f6c\u79fb\u548c\u4ee4\u724c\u7ea7\u54cd\u5e94\u6536\u96c6\u7b49\u5173\u952e\u6280\u672f\uff0c\u5728\u63d0\u5347\u8bad\u7ec3\u541e\u5410\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5de5\u4f5c\u6d41\u4e2d\uff0crollout\u9636\u6bb5\u5360\u7528\u5927\u90e8\u5206\u6267\u884c\u65f6\u95f4\u4f46\u53ef\u5e76\u884c\u6269\u5c55\uff0c\u800c\u8bad\u7ec3\u9636\u6bb5\u9700\u8981\u7d27\u5bc6\u8026\u5408\u7684GPU\u3002\u73b0\u6709\u6846\u67b6\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u8fd9\u79cd\u8d44\u6e90\u9700\u6c42\u77db\u76fe\uff0c\u540c\u65f6\u53ef\u62a2\u5360GPU\u8d44\u6e90\u63d0\u4f9b\u4e86\u663e\u8457\u7684\u6210\u672c\u8282\u7ea6\u673a\u4f1a\u3002", "method": "\u91c7\u7528\u6df7\u5408\u67b6\u6784\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u6280\u672f\uff1a(1) \u81ea\u9002\u5e94rollout\u5378\u8f7d\uff0c\u52a8\u6001\u8c03\u6574\u9884\u7559\u96c6\u7fa4\u4e0a\u7684\u5de5\u4f5c\u8d1f\u8f7d\uff1b(2) \u57fa\u4e8e\u62c9\u53d6\u7684\u6743\u91cd\u8f6c\u79fb\uff0c\u5feb\u901f\u914d\u7f6e\u65b0\u53ef\u7528\u5b9e\u4f8b\uff1b(3) \u4ee4\u724c\u7ea7\u54cd\u5e94\u6536\u96c6\u548c\u8fc1\u79fb\uff0c\u7528\u4e8e\u9ad8\u6548\u5904\u7406\u62a2\u5360\u548c\u6301\u7eed\u8d1f\u8f7d\u5747\u8861\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRLBoost\u76f8\u6bd4\u4ec5\u4f7f\u7528\u6309\u9700GPU\u8d44\u6e90\uff0c\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u53471.51-1.97\u500d\uff0c\u6210\u672c\u6548\u7387\u63d0\u9ad828%-49%\u3002", "conclusion": "RLBoost\u901a\u8fc7\u6709\u6548\u5229\u7528\u53ef\u62a2\u5360GPU\u8d44\u6e90\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5f3a\u5316\u5b66\u4e60\u5de5\u4f5c\u6d41\u4e2d\u7684\u8d44\u6e90\u5229\u7528\u6548\u7387\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u8bad\u7ec3\u541e\u5410\u91cf\u548c\u6210\u672c\u6548\u7387\u7684\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2510.19263", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19263", "abs": "https://arxiv.org/abs/2510.19263", "authors": ["Wachara Fungwacharakorn", "Gauvain Bourgne", "Ken Satoh"], "title": "An Argumentative Explanation Framework for Generalized Reason Model with Inconsistent Precedents", "comment": "10 pages, extended version for JURIX 2025 submission", "summary": "Precedential constraint is one foundation of case-based reasoning in AI and\nLaw. It generally assumes that the underlying set of precedents must be\nconsistent. To relax this assumption, a generalized notion of the reason model\nhas been introduced. While several argumentative explanation approaches exist\nfor reasoning with precedents based on the traditional consistent reason model,\nthere has been no corresponding argumentative explanation method developed for\nthis generalized reasoning framework accommodating inconsistent precedents. To\naddress this question, this paper examines an extension of the derivation state\nargumentation framework (DSA-framework) to explain the reasoning according to\nthe generalized notion of the reason model.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u63a8\u5bfc\u72b6\u6001\u8bba\u8bc1\u6846\u67b6\uff08DSA-framework\uff09\uff0c\u4e3a\u5bb9\u7eb3\u4e0d\u4e00\u81f4\u5148\u4f8b\u7684\u5e7f\u4e49\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u8bba\u8bc1\u6027\u89e3\u91ca\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u4e00\u81f4\u5148\u4f8b\u7684\u63a8\u7406\u6a21\u578b\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e3a\u5e7f\u4e49\u63a8\u7406\u6846\u67b6\uff08\u5141\u8bb8\u4e0d\u4e00\u81f4\u5148\u4f8b\uff09\u5f00\u53d1\u76f8\u5e94\u7684\u8bba\u8bc1\u6027\u89e3\u91ca\u65b9\u6cd5\u3002", "method": "\u6269\u5c55\u63a8\u5bfc\u72b6\u6001\u8bba\u8bc1\u6846\u67b6\uff08DSA-framework\uff09\uff0c\u4ee5\u89e3\u91ca\u57fa\u4e8e\u5e7f\u4e49\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u4e0d\u4e00\u81f4\u5148\u4f8b\u7684\u8bba\u8bc1\u6027\u89e3\u91ca\u6846\u67b6\u3002", "conclusion": "\u8be5\u6269\u5c55\u6846\u67b6\u586b\u8865\u4e86\u5e7f\u4e49\u63a8\u7406\u6a21\u578b\u4e2d\u8bba\u8bc1\u6027\u89e3\u91ca\u65b9\u6cd5\u7684\u7a7a\u767d\uff0c\u4e3a\u5904\u7406\u4e0d\u4e00\u81f4\u5148\u4f8b\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2510.19262", "categories": ["cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.19262", "abs": "https://arxiv.org/abs/2510.19262", "authors": ["Heng Xu", "Zhiwei Yu", "Chengze Du", "Ying Zhou", "Letian Li", "Haojie Wang", "Weiqiang Cheng", "Jialong Li"], "title": "RailS: Load Balancing for All-to-All Communication in Distributed Mixture-of-Experts Training", "comment": null, "summary": "Training Mixture-of-Experts (MoE) models introduces sparse and highly\nimbalanced all-to-all communication that dominates iteration time. Conventional\nload-balancing methods fail to exploit the deterministic topology of Rail\narchitectures, leaving multi-NIC bandwidth underutilized. We present RailS, a\ndistributed load-balancing framework that minimizes all-to-all completion time\nin MoE training. RailS leverages the Rail topology's symmetry to prove that\nuniform sending ensures uniform receiving, transforming global coordination\ninto local scheduling. Each node independently executes a Longest Processing\nTime First (LPT) spraying scheduler to proactively balance traffic using local\ninformation. RailS activates N parallel rails for fine-grained, topology-aware\nmultipath transmission. Across synthetic and real-world MoE workloads, RailS\nimproves bus bandwidth by 20%--78% and reduces completion time by 17%--78%. For\nMixtral workloads, it shortens iteration time by 18%--40% and achieves\nnear-optimal load balance, fully exploiting architectural parallelism in\ndistributed training.", "AI": {"tldr": "RailS\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u8d1f\u8f7d\u5747\u8861\u6846\u67b6\uff0c\u4e13\u95e8\u4f18\u5316MoE\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u7a00\u758f\u4e14\u9ad8\u5ea6\u4e0d\u5e73\u8861\u7684all-to-all\u901a\u4fe1\uff0c\u901a\u8fc7\u5229\u7528Rail\u67b6\u6784\u7684\u786e\u5b9a\u6027\u62d3\u6251\u548c\u5e76\u884c\u4f20\u8f93\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u5e26\u5bbd\u5229\u7528\u7387\u548c\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u8d1f\u8f7d\u5747\u8861\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u5229\u7528Rail\u67b6\u6784\u7684\u591aNIC\u5e26\u5bbd\uff0c\u5bfc\u81f4MoE\u8bad\u7ec3\u4e2d\u7684all-to-all\u901a\u4fe1\u6210\u4e3a\u6027\u80fd\u74f6\u9888\uff0c\u9700\u8981\u65b0\u7684\u62d3\u6251\u611f\u77e5\u8d1f\u8f7d\u5747\u8861\u65b9\u6848\u3002", "method": "RailS\u5229\u7528Rail\u62d3\u6251\u7684\u5bf9\u79f0\u6027\uff0c\u5c06\u5168\u5c40\u534f\u8c03\u8f6c\u5316\u4e3a\u672c\u5730\u8c03\u5ea6\uff0c\u6bcf\u4e2a\u8282\u70b9\u72ec\u7acb\u6267\u884cLPT\u55b7\u6d82\u8c03\u5ea6\u5668\u8fdb\u884c\u4e3b\u52a8\u6d41\u91cf\u5e73\u8861\uff0c\u5e76\u6fc0\u6d3bN\u6761\u5e76\u884crail\u8fdb\u884c\u7ec6\u7c92\u5ea6\u591a\u8def\u5f84\u4f20\u8f93\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9eMoE\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\uff0cRailS\u5c06\u603b\u7ebf\u5e26\u5bbd\u63d0\u534720%-78%\uff0c\u5b8c\u6210\u65f6\u95f4\u51cf\u5c1117%-78%\uff1b\u5728Mixtral\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\uff0c\u8fed\u4ee3\u65f6\u95f4\u7f29\u77ed18%-40%\uff0c\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u8d1f\u8f7d\u5747\u8861\u3002", "conclusion": "RailS\u901a\u8fc7\u62d3\u6251\u611f\u77e5\u7684\u8d1f\u8f7d\u5747\u8861\u548c\u5e76\u884c\u4f20\u8f93\u673a\u5236\uff0c\u5145\u5206\u6316\u6398\u5206\u5e03\u5f0f\u8bad\u7ec3\u4e2d\u7684\u67b6\u6784\u5e76\u884c\u6027\uff0c\u663e\u8457\u63d0\u5347MoE\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2510.19301", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.19301", "abs": "https://arxiv.org/abs/2510.19301", "authors": ["Ziheng Deng", "Xue Liu", "Jiantong Jiang", "Yankai Li", "Qingxu Deng", "Xiaochun Yang"], "title": "FLASH Viterbi: Fast and Adaptive Viterbi Decoding for Modern Data Systems", "comment": "Accepted for ICDE 2026", "summary": "The Viterbi algorithm is a key operator for structured sequence inference in\nmodern data systems, with applications in trajectory analysis, online\nrecommendation, and speech recognition. As these workloads increasingly migrate\nto resource-constrained edge platforms, standard Viterbi decoding remains\nmemory-intensive and computationally inflexible. Existing methods typically\ntrade decoding time for space efficiency, but often incur significant runtime\noverhead and lack adaptability to various system constraints. This paper\npresents FLASH Viterbi, a Fast, Lightweight, Adaptive, and Hardware-Friendly\nViterbi decoding operator that enhances adaptability and resource efficiency.\nFLASH Viterbi combines a non-recursive divide-and-conquer strategy with pruning\nand parallelization techniques to enhance both time and memory efficiency,\nmaking it well-suited for resource-constrained data systems.To further decouple\nspace complexity from the hidden state space size, we present FLASH-BS Viterbi,\na dynamic beam search variant built on a memory-efficient data structure. Both\nproposed algorithms exhibit strong adaptivity to diverse deployment scenarios\nby dynamically tuning internal parameters.To ensure practical deployment on\nedge devices, we also develop FPGA-based hardware accelerators for both\nalgorithms, demonstrating high throughput and low resource usage. Extensive\nexperiments show that our algorithms consistently outperform existing baselines\nin both decoding time and memory efficiency, while preserving adaptability and\nhardware-friendly characteristics essential for modern data systems. All codes\nare publicly available at https://github.com/Dzh-16/FLASH-Viterbi.", "AI": {"tldr": "FLASH Viterbi\u662f\u4e00\u79cd\u5feb\u901f\u3001\u8f7b\u91cf\u7ea7\u3001\u81ea\u9002\u5e94\u4e14\u786c\u4ef6\u53cb\u597d\u7684Viterbi\u89e3\u7801\u7b97\u5b50\uff0c\u901a\u8fc7\u975e\u9012\u5f52\u5206\u6cbb\u7b56\u7565\u7ed3\u5408\u526a\u679d\u548c\u5e76\u884c\u5316\u6280\u672f\uff0c\u63d0\u5347\u65f6\u95f4\u548c\u5185\u5b58\u6548\u7387\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u6570\u636e\u7cfb\u7edf\u3002", "motivation": "\u968f\u7740\u7ed3\u6784\u5316\u5e8f\u5217\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\u8fc1\u79fb\u5230\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u5e73\u53f0\uff0c\u6807\u51c6\u7684Viterbi\u89e3\u7801\u5b58\u5728\u5185\u5b58\u5bc6\u96c6\u548c\u8ba1\u7b97\u4e0d\u7075\u6d3b\u7684\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5728\u89e3\u7801\u65f6\u95f4\u548c\u7a7a\u95f4\u6548\u7387\u4e4b\u95f4\u6743\u8861\uff0c\u4f46\u5f80\u5f80\u4ea7\u751f\u663e\u8457\u7684\u8fd0\u884c\u65f6\u5f00\u9500\u4e14\u7f3a\u4e4f\u5bf9\u5404\u79cd\u7cfb\u7edf\u7ea6\u675f\u7684\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51fa\u4e86FLASH Viterbi\u7b97\u6cd5\uff0c\u7ed3\u5408\u975e\u9012\u5f52\u5206\u6cbb\u7b56\u7565\u4e0e\u526a\u679d\u548c\u5e76\u884c\u5316\u6280\u672f\uff1b\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86FLASH-BS Viterbi\uff0c\u57fa\u4e8e\u5185\u5b58\u9ad8\u6548\u6570\u636e\u7ed3\u6784\u7684\u52a8\u6001\u6ce2\u675f\u641c\u7d22\u53d8\u4f53\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u5185\u90e8\u53c2\u6570\u9002\u5e94\u4e0d\u540c\u90e8\u7f72\u573a\u666f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u89e3\u7801\u65f6\u95f4\u548c\u5185\u5b58\u6548\u7387\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u73b0\u4ee3\u6570\u636e\u7cfb\u7edf\u6240\u9700\u7684\u9002\u5e94\u6027\u548c\u786c\u4ef6\u53cb\u597d\u7279\u6027\u3002", "conclusion": "FLASH Viterbi\u7cfb\u5217\u7b97\u6cd5\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u6570\u636e\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u7684Viterbi\u89e3\u7801\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8eFPGA\u7684\u786c\u4ef6\u52a0\u901f\u5668\uff0c\u5c55\u793a\u4e86\u9ad8\u541e\u5410\u91cf\u548c\u4f4e\u8d44\u6e90\u4f7f\u7528\u3002"}}
{"id": "2510.19314", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19314", "abs": "https://arxiv.org/abs/2510.19314", "authors": ["Jinwu Hu", "Zihao Lian", "Zhiquan Wen", "Chenghao Li", "Guohao Chen", "Xutao Wen", "Bin Xiao", "Mingkui Tan"], "title": "Continual Knowledge Adaptation for Reinforcement Learning", "comment": "NeurIPS 2025", "summary": "Reinforcement Learning enables agents to learn optimal behaviors through\ninteractions with environments. However, real-world environments are typically\nnon-stationary, requiring agents to continuously adapt to new tasks and\nchanging conditions. Although Continual Reinforcement Learning facilitates\nlearning across multiple tasks, existing methods often suffer from catastrophic\nforgetting and inefficient knowledge utilization. To address these challenges,\nwe propose Continual Knowledge Adaptation for Reinforcement Learning (CKA-RL),\nwhich enables the accumulation and effective utilization of historical\nknowledge. Specifically, we introduce a Continual Knowledge Adaptation\nstrategy, which involves maintaining a task-specific knowledge vector pool and\ndynamically using historical knowledge to adapt the agent to new tasks. This\nprocess mitigates catastrophic forgetting and enables efficient knowledge\ntransfer across tasks by preserving and adapting critical model parameters.\nAdditionally, we propose an Adaptive Knowledge Merging mechanism that combines\nsimilar knowledge vectors to address scalability challenges, reducing memory\nrequirements while ensuring the retention of essential knowledge. Experiments\non three benchmarks demonstrate that the proposed CKA-RL outperforms\nstate-of-the-art methods, achieving an improvement of 4.20% in overall\nperformance and 8.02% in forward transfer. The source code is available at\nhttps://github.com/Fhujinwu/CKA-RL.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCKA-RL\u65b9\u6cd5\uff0c\u901a\u8fc7\u6301\u7eed\u77e5\u8bc6\u9002\u5e94\u7b56\u7565\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u4f7f\u7528\u4efb\u52a1\u7279\u5b9a\u77e5\u8bc6\u5411\u91cf\u6c60\u548c\u81ea\u9002\u5e94\u77e5\u8bc6\u5408\u5e76\u673a\u5236\uff0c\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u73af\u5883\u901a\u5e38\u662f\u975e\u5e73\u7a33\u7684\uff0c\u9700\u8981\u667a\u80fd\u4f53\u6301\u7eed\u9002\u5e94\u65b0\u4efb\u52a1\u548c\u53d8\u5316\u6761\u4ef6\u3002\u73b0\u6709\u7684\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u548c\u77e5\u8bc6\u5229\u7528\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6301\u7eed\u77e5\u8bc6\u9002\u5e94\u7b56\u7565\uff0c\u7ef4\u62a4\u4efb\u52a1\u7279\u5b9a\u77e5\u8bc6\u5411\u91cf\u6c60\uff0c\u52a8\u6001\u4f7f\u7528\u5386\u53f2\u77e5\u8bc6\u9002\u5e94\u65b0\u4efb\u52a1\uff1b\u5f15\u5165\u81ea\u9002\u5e94\u77e5\u8bc6\u5408\u5e76\u673a\u5236\uff0c\u5408\u5e76\u76f8\u4f3c\u77e5\u8bc6\u5411\u91cf\u4ee5\u51cf\u5c11\u5185\u5b58\u9700\u6c42\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCKA-RL\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u6574\u4f53\u6027\u80fd\u63d0\u53474.20%\uff0c\u524d\u5411\u8fc1\u79fb\u63d0\u53478.02%\u3002", "conclusion": "CKA-RL\u901a\u8fc7\u6301\u7eed\u77e5\u8bc6\u9002\u5e94\u548c\u81ea\u9002\u5e94\u77e5\u8bc6\u5408\u5e76\uff0c\u6709\u6548\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5b9e\u73b0\u8de8\u4efb\u52a1\u7684\u9ad8\u6548\u77e5\u8bc6\u8fc1\u79fb\uff0c\u5728\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2510.19470", "categories": ["cs.DC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19470", "abs": "https://arxiv.org/abs/2510.19470", "authors": ["Weihao Yang", "Hao Huang", "Donglei Wu", "Ningke Li", "Yanqi Pan", "Qiyang Zheng", "Wen Xia", "Shiyi Li", "Qiang Wang"], "title": "HybridEP: Scaling Expert Parallelism to Cross-Datacenter Scenario via Hybrid Expert/Data Transmission", "comment": null, "summary": "Mixture-of-Experts (MoE) has become a popular architecture for scaling large\nmodels. However, the rapidly growing scale outpaces model training on a single\nDC, driving a shift toward a more flexible, cross-DC training paradigm. Under\nthis, Expert Parallelism (EP) of MoE faces significant scalability issues due\nto the limited cross-DC bandwidth. Specifically, existing EP optimizations\nattempt to overlap data communication and computation, which has little benefit\nin low-bandwidth scenarios due to a much longer data communication time.\nTherefore, the trends of cross-DC EP scaling is fast becoming a critical\nroadblock to the continued growth of MoE models.\n  To address this, we propose HybridEP, a modeling-guided framework to optimize\nEP under constrained bandwidth. Our key idea is to dynamically transform the\nspatial placement of experts to reduce data communication traffic and\nfrequency, thereby minimizing EP's communication overheads. However, it is\nnon-trivial to find the optimal solution because it complicates the original\ncommunication pattern by mixing data and expert communication. We therefore\nbuild a stream-based model to determine the optimal transmission ratio. Guided\nby this, we incorporate two techniques: (1) domain-based partition to construct\nthe mapping between hybrid patterns and specific communication topology at GPU\nlevel, and (2) parameter-efficient migration to further refine this topology by\nreducing expert transmission overhead and enlarging the domain size. Combining\nall these designs, HybridEP can be considered as a more general EP with better\nscalability. Experimental results show that HybridEP outperforms existing\nstate-of-the-art MoE training systems by up to 5.6x under constrained\nbandwidth. We further compare HybridEP and EP on large-scale simulations.\nHybridEP achieves up to 1.45x speedup with 1k DCs under different bandwidths.", "AI": {"tldr": "\u63d0\u51faHybridEP\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u4e13\u5bb6\u7a7a\u95f4\u5e03\u5c40\u6765\u51cf\u5c11\u6570\u636e\u901a\u4fe1\u6d41\u91cf\u548c\u9891\u7387\uff0c\u4f18\u5316\u53d7\u9650\u5e26\u5bbd\u4e0b\u7684\u4e13\u5bb6\u5e76\u884c\u8bad\u7ec3\u6027\u80fd", "motivation": "\u968f\u7740MoE\u6a21\u578b\u89c4\u6a21\u5feb\u901f\u589e\u957f\uff0c\u5355\u6570\u636e\u4e2d\u5fc3\u8bad\u7ec3\u5df2\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\uff0c\u8f6c\u5411\u8de8\u6570\u636e\u4e2d\u5fc3\u8bad\u7ec3\u3002\u4f46\u5728\u4f4e\u5e26\u5bbd\u573a\u666f\u4e0b\uff0c\u73b0\u6709\u4e13\u5bb6\u5e76\u884c\u4f18\u5316\u6548\u679c\u6709\u9650\uff0c\u6210\u4e3aMoE\u6a21\u578b\u6301\u7eed\u589e\u957f\u7684\u5173\u952e\u74f6\u9888", "method": "\u6784\u5efa\u6d41\u5f0f\u6a21\u578b\u786e\u5b9a\u6700\u4f18\u4f20\u8f93\u6bd4\u4f8b\uff0c\u7ed3\u5408\u57fa\u4e8e\u57df\u7684\u5206\u533a\u6784\u5efa\u6df7\u5408\u6a21\u5f0f\u4e0eGPU\u7ea7\u901a\u4fe1\u62d3\u6251\u7684\u6620\u5c04\uff0c\u4ee5\u53ca\u53c2\u6570\u9ad8\u6548\u8fc1\u79fb\u6280\u672f\u51cf\u5c11\u4e13\u5bb6\u4f20\u8f93\u5f00\u9500\u5e76\u6269\u5927\u57df\u89c4\u6a21", "result": "\u5728\u53d7\u9650\u5e26\u5bbd\u4e0b\uff0cHybridEP\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u7684MoE\u8bad\u7ec3\u7cfb\u7edf\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe5.6\u500d\uff1b\u57281000\u4e2a\u6570\u636e\u4e2d\u5fc3\u7684\u5927\u89c4\u6a21\u6a21\u62df\u4e2d\uff0c\u5728\u4e0d\u540c\u5e26\u5bbd\u4e0b\u5b9e\u73b0\u9ad8\u8fbe1.45\u500d\u7684\u52a0\u901f", "conclusion": "HybridEP\u53ef\u88ab\u89c6\u4e3a\u5177\u6709\u66f4\u597d\u53ef\u6269\u5c55\u6027\u7684\u66f4\u901a\u7528\u4e13\u5bb6\u5e76\u884c\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u6570\u636e\u4e2d\u5fc3\u4e13\u5bb6\u5e76\u884c\u7684\u901a\u4fe1\u74f6\u9888\u95ee\u9898"}}
{"id": "2510.19390", "categories": ["cs.CR", "cs.ET", "math.OC", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.19390", "abs": "https://arxiv.org/abs/2510.19390", "authors": ["Max O. Al-Hasso", "Marko von der Leyen"], "title": "A Probabilistic Computing Approach to the Closest Vector Problem for Lattice-Based Factoring", "comment": "18 pages, 5 figures", "summary": "The closest vector problem (CVP) is a fundamental optimization problem in\nlattice-based cryptography and its conjectured hardness underpins the security\nof lattice-based cryptosystems. Furthermore, Schnorr's lattice-based factoring\nalgorithm reduces integer factoring (the foundation of current cryptosystems,\nincluding RSA) to the CVP. Recent work has investigated the inclusion of a\nheuristic CVP approximation `refinement' step in the lattice-based factoring\nalgorithm, using quantum variational algorithms to perform the heuristic\noptimization. This coincides with the emergence of probabilistic computing as a\nhardware accelerator for randomized algorithms including tasks in combinatorial\noptimization. In this work we investigate the application of probabilistic\ncomputing to the heuristic optimization task of CVP approximation refinement in\nlattice-based factoring. We present the design of a probabilistic computing\nalgorithm for this task, a discussion of `prime lattice' parameters, and\nexperimental results showing the efficacy of probabilistic computing for\nsolving the CVP as well as its efficacy as a subroutine for lattice-based\nfactoring. The main results found that (a) this approach is capable of finding\nthe maximal available CVP approximation refinement in time linear in problem\nsize and (b) probabilistic computing used in conjunction with the lattice\nparameters presented can find the composite prime factors of a semiprime number\nusing up to 100x fewer lattice instances than similar quantum and classical\nmethods.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5c06\u6982\u7387\u8ba1\u7b97\u5e94\u7528\u4e8e\u683c\u57fa\u5206\u89e3\u7b97\u6cd5\u4e2d\u7684CVP\u8fd1\u4f3c\u4f18\u5316\u4efb\u52a1\uff0c\u5c55\u793a\u4e86\u6982\u7387\u8ba1\u7b97\u5728\u89e3\u51b3CVP\u548c\u4f5c\u4e3a\u683c\u57fa\u5206\u89e3\u5b50\u7a0b\u5e8f\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "motivation": "\u6700\u8fd1\u7684\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u683c\u57fa\u5206\u89e3\u7b97\u6cd5\u4e2d\u52a0\u5165\u542f\u53d1\u5f0fCVP\u8fd1\u4f3c\u4f18\u5316\u6b65\u9aa4\uff0c\u4f7f\u7528\u91cf\u5b50\u53d8\u5206\u7b97\u6cd5\u6267\u884c\u542f\u53d1\u5f0f\u4f18\u5316\u3002\u8fd9\u4e0e\u6982\u7387\u8ba1\u7b97\u4f5c\u4e3a\u968f\u673a\u7b97\u6cd5\u786c\u4ef6\u52a0\u901f\u5668\u7684\u51fa\u73b0\u76f8\u543b\u5408\u3002", "method": "\u63d0\u51fa\u4e86\u7528\u4e8eCVP\u8fd1\u4f3c\u4f18\u5316\u7684\u6982\u7387\u8ba1\u7b97\u7b97\u6cd5\u8bbe\u8ba1\uff0c\u8ba8\u8bba\u4e86'\u7d20\u6570\u683c'\u53c2\u6570\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6982\u7387\u8ba1\u7b97\u5728\u89e3\u51b3CVP\u53ca\u5176\u4f5c\u4e3a\u683c\u57fa\u5206\u89e3\u5b50\u7a0b\u5e8f\u7684\u6709\u6548\u6027\u3002", "result": "\u4e3b\u8981\u7ed3\u679c\u53d1\u73b0\uff1a(a)\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u95ee\u9898\u89c4\u6a21\u7ebf\u6027\u65f6\u95f4\u5185\u627e\u5230\u6700\u5927\u53ef\u7528CVP\u8fd1\u4f3c\u4f18\u5316\uff1b(b)\u4e0e\u7c7b\u4f3c\u91cf\u5b50\u548c\u7ecf\u5178\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6982\u7387\u8ba1\u7b97\u7ed3\u5408\u6240\u63d0\u51fa\u7684\u683c\u53c2\u6570\u80fd\u591f\u4f7f\u7528\u6700\u591a100\u500d\u5c11\u7684\u683c\u5b9e\u4f8b\u627e\u5230\u534a\u7d20\u6570\u7684\u590d\u5408\u7d20\u56e0\u5b50\u3002", "conclusion": "\u6982\u7387\u8ba1\u7b97\u5728CVP\u8fd1\u4f3c\u4f18\u5316\u548c\u683c\u57fa\u5206\u89e3\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u51cf\u5c11\u6240\u9700\u8ba1\u7b97\u8d44\u6e90\u65b9\u9762\u3002"}}
{"id": "2510.19617", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.19617", "abs": "https://arxiv.org/abs/2510.19617", "authors": ["Eric Ding"], "title": "Propius: A Platform for Collaborative Machine Learning across the Edge and the Cloud", "comment": null, "summary": "Collaborative Machine Learning is a paradigm in the field of distributed\nmachine learning, designed to address the challenges of data privacy,\ncommunication overhead, and model heterogeneity. There have been significant\nadvancements in optimization and communication algorithm design and ML hardware\nthat enables fair, efficient and secure collaborative ML training. However,\nless emphasis is put on collaborative ML infrastructure development. Developers\nand researchers often build server-client systems for a specific collaborative\nML use case, which is not scalable and reusable. As the scale of collaborative\nML grows, the need for a scalable, efficient, and ideally multi-tenant resource\nmanagement system becomes more pressing. We propose a novel system, Propius,\nthat can adapt to the heterogeneity of client machines, and efficiently manage\nand control the computation flow between ML jobs and edge resources in a\nscalable fashion. Propius is comprised of a control plane and a data plane. The\ncontrol plane enables efficient resource sharing among multiple collaborative\nML jobs and supports various resource sharing policies, while the data plane\nimproves the scalability of collaborative ML model sharing and result\ncollection. Evaluations show that Propius outperforms existing resource\nmanagement techniques and frameworks in terms of resource utilization (up to\n$1.88\\times$), throughput (up to $2.76$), and job completion time (up to\n$1.26\\times$).", "AI": {"tldr": "\u63d0\u51faPropius\u7cfb\u7edf\uff0c\u7528\u4e8e\u89e3\u51b3\u534f\u4f5c\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u8d44\u6e90\u7ba1\u7406\u95ee\u9898\uff0c\u901a\u8fc7\u63a7\u5236\u5e73\u9762\u548c\u6570\u636e\u5e73\u9762\u5b9e\u73b0\u9ad8\u6548\u8d44\u6e90\u5206\u914d\u548c\u6a21\u578b\u5171\u4eab\uff0c\u663e\u8457\u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387\u3001\u541e\u5410\u91cf\u548c\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u3002", "motivation": "\u5f53\u524d\u534f\u4f5c\u673a\u5668\u5b66\u4e60\u7f3a\u4e4f\u53ef\u6269\u5c55\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u5f00\u53d1\u8005\u901a\u5e38\u6784\u5efa\u7279\u5b9a\u7528\u9014\u7684\u670d\u52a1\u5668-\u5ba2\u6237\u7aef\u7cfb\u7edf\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5927\u89c4\u6a21\u534f\u4f5cML\u7684\u9700\u6c42\uff0c\u9700\u8981\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u7684\u591a\u79df\u6237\u8d44\u6e90\u7ba1\u7406\u7cfb\u7edf\u3002", "method": "\u8bbe\u8ba1Propius\u7cfb\u7edf\uff0c\u5305\u542b\u63a7\u5236\u5e73\u9762\u548c\u6570\u636e\u5e73\u9762\u3002\u63a7\u5236\u5e73\u9762\u652f\u6301\u591a\u534f\u4f5cML\u4f5c\u4e1a\u95f4\u7684\u8d44\u6e90\u5171\u4eab\u548c\u591a\u79cd\u8d44\u6e90\u5206\u914d\u7b56\u7565\uff0c\u6570\u636e\u5e73\u9762\u63d0\u5347\u534f\u4f5cML\u6a21\u578b\u5171\u4eab\u548c\u7ed3\u679c\u6536\u96c6\u7684\u53ef\u6269\u5c55\u6027\u3002", "result": "\u8bc4\u4f30\u663e\u793aPropius\u5728\u8d44\u6e90\u5229\u7528\u7387\uff08\u6700\u9ad81.88\u500d\uff09\u3001\u541e\u5410\u91cf\uff08\u6700\u9ad82.76\u500d\uff09\u548c\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\uff08\u6700\u9ad81.26\u500d\uff09\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u8d44\u6e90\u7ba1\u7406\u6280\u672f\u548c\u6846\u67b6\u3002", "conclusion": "Propius\u7cfb\u7edf\u80fd\u591f\u9002\u5e94\u5ba2\u6237\u7aef\u673a\u5668\u7684\u5f02\u6784\u6027\uff0c\u4ee5\u53ef\u6269\u5c55\u65b9\u5f0f\u9ad8\u6548\u7ba1\u7406\u548c\u63a7\u5236ML\u4f5c\u4e1a\u4e0e\u8fb9\u7f18\u8d44\u6e90\u4e4b\u95f4\u7684\u8ba1\u7b97\u6d41\uff0c\u4e3a\u5927\u89c4\u6a21\u534f\u4f5cML\u63d0\u4f9b\u6709\u6548\u7684\u8d44\u6e90\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.19429", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19429", "abs": "https://arxiv.org/abs/2510.19429", "authors": ["Wonje Choi", "Jooyoung Kim", "Honguk Woo"], "title": "NeSyPr: Neurosymbolic Proceduralization For Efficient Embodied Reasoning", "comment": "Accepted at NeurIPS 2025", "summary": "We address the challenge of adopting language models (LMs) for embodied tasks\nin dynamic environments, where online access to large-scale inference engines\nor symbolic planners is constrained due to latency, connectivity, and resource\nlimitations. To this end, we present NeSyPr, a novel embodied reasoning\nframework that compiles knowledge via neurosymbolic proceduralization, thereby\nequipping LM-based agents with structured, adaptive, and timely reasoning\ncapabilities. In NeSyPr, task-specific plans are first explicitly generated by\na symbolic tool leveraging its declarative knowledge. These plans are then\ntransformed into composable procedural representations that encode the plans'\nimplicit production rules, enabling the resulting composed procedures to be\nseamlessly integrated into the LM's inference process. This neurosymbolic\nproceduralization abstracts and generalizes multi-step symbolic structured\npath-finding and reasoning into single-step LM inference, akin to human\nknowledge compilation. It supports efficient test-time inference without\nrelying on external symbolic guidance, making it well suited for deployment in\nlatency-sensitive and resource-constrained physical systems. We evaluate NeSyPr\non the embodied benchmarks PDDLGym, VirtualHome, and ALFWorld, demonstrating\nits efficient reasoning capabilities over large-scale reasoning models and a\nsymbolic planner, while using more compact LMs.", "AI": {"tldr": "NeSyPr\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u5177\u8eab\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u7a0b\u5e8f\u5316\u5c06\u77e5\u8bc6\u7f16\u8bd1\uff0c\u4e3a\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u63d0\u4f9b\u7ed3\u6784\u5316\u3001\u81ea\u9002\u5e94\u548c\u53ca\u65f6\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5728\u5ef6\u8fdf\u654f\u611f\u548c\u8d44\u6e90\u53d7\u9650\u7684\u7269\u7406\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u3002", "motivation": "\u89e3\u51b3\u5728\u52a8\u6001\u73af\u5883\u4e2d\u91c7\u7528\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5177\u8eab\u4efb\u52a1\u65f6\u9762\u4e34\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5ef6\u8fdf\u3001\u8fde\u63a5\u6027\u548c\u8d44\u6e90\u9650\u5236\u4e0b\u65e0\u6cd5\u5728\u7ebf\u8bbf\u95ee\u5927\u89c4\u6a21\u63a8\u7406\u5f15\u64ce\u6216\u7b26\u53f7\u89c4\u5212\u5668\u7684\u95ee\u9898\u3002", "method": "\u9996\u5148\u5229\u7528\u7b26\u53f7\u5de5\u5177\u751f\u6210\u4efb\u52a1\u7279\u5b9a\u8ba1\u5212\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u8ba1\u5212\u8f6c\u6362\u4e3a\u53ef\u7ec4\u5408\u7684\u7a0b\u5e8f\u8868\u793a\uff0c\u7f16\u7801\u8ba1\u5212\u7684\u9690\u5f0f\u4ea7\u751f\u89c4\u5219\uff0c\u4f7f\u7ec4\u5408\u540e\u7684\u7a0b\u5e8f\u80fd\u591f\u65e0\u7f1d\u96c6\u6210\u5230\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u4e2d\u3002", "result": "\u5728PDDLGym\u3001VirtualHome\u548cALFWorld\u7b49\u5177\u8eab\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cNeSyPr\u5c55\u793a\u4e86\u6bd4\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b\u548c\u7b26\u53f7\u89c4\u5212\u5668\u66f4\u9ad8\u6548\u7684\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u4f7f\u7528\u66f4\u7d27\u51d1\u7684\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "\u795e\u7ecf\u7b26\u53f7\u7a0b\u5e8f\u5316\u5c06\u591a\u6b65\u7b26\u53f7\u7ed3\u6784\u5316\u8def\u5f84\u67e5\u627e\u548c\u63a8\u7406\u62bd\u8c61\u5e76\u6cdb\u5316\u4e3a\u5355\u6b65\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u7c7b\u4f3c\u4e8e\u4eba\u7c7b\u77e5\u8bc6\u7f16\u8bd1\uff0c\u652f\u6301\u65e0\u9700\u5916\u90e8\u7b26\u53f7\u6307\u5bfc\u7684\u9ad8\u6548\u6d4b\u8bd5\u65f6\u63a8\u7406\u3002"}}
{"id": "2510.19418", "categories": ["cs.CR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19418", "abs": "https://arxiv.org/abs/2510.19418", "authors": ["Mete Harun Akcay", "Buse Gul Atli", "Siddharth Prakash Rao", "Alexandros Bakas"], "title": "From See to Shield: ML-Assisted Fine-Grained Access Control for Visual Data", "comment": "10 pages, 3 figures, 6 tables. In submission", "summary": "As the volume of stored data continues to grow, identifying and protecting\nsensitive information within large repositories becomes increasingly\nchallenging, especially when shared with multiple users with different roles\nand permissions. This work presents a system architecture for trusted data\nsharing with policy-driven access control, enabling selective protection of\nsensitive regions while maintaining scalability. The proposed architecture\nintegrates four core modules that combine automated detection of sensitive\nregions, post-correction, key management, and access control. Sensitive regions\nare secured using a hybrid scheme that employs symmetric encryption for\nefficiency and Attribute-Based Encryption for policy enforcement. The system\nsupports efficient key distribution and isolates key storage to strengthen\noverall security. To demonstrate its applicability, we evaluate the system on\nvisual datasets, where Privacy-Sensitive Objects in images are automatically\ndetected, reassessed, and selectively encrypted prior to sharing in a data\nrepository. Experimental results show that our system provides effective PSO\ndetection, increases macro-averaged F1 score (5%) and mean Average Precision\n(10%), and maintains an average policy-enforced decryption time of less than 1\nsecond per image. These results demonstrate the effectiveness, efficiency and\nscalability of our proposed solution for fine-grained access control.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u4fe1\u6570\u636e\u5171\u4eab\u7cfb\u7edf\u67b6\u6784\uff0c\u901a\u8fc7\u7b56\u7565\u9a71\u52a8\u7684\u8bbf\u95ee\u63a7\u5236\u5b9e\u73b0\u654f\u611f\u533a\u57df\u7684\u9009\u62e9\u6027\u4fdd\u62a4\uff0c\u7ed3\u5408\u81ea\u52a8\u68c0\u6d4b\u3001\u540e\u6821\u6b63\u3001\u5bc6\u94a5\u7ba1\u7406\u548c\u8bbf\u95ee\u63a7\u5236\u6a21\u5757\uff0c\u5728\u89c6\u89c9\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u5b58\u50a8\u6570\u636e\u91cf\u589e\u957f\uff0c\u5728\u5927\u89c4\u6a21\u5b58\u50a8\u5e93\u4e2d\u8bc6\u522b\u548c\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\u53d8\u5f97\u65e5\u76ca\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u4e0e\u5177\u6709\u4e0d\u540c\u89d2\u8272\u548c\u6743\u9650\u7684\u591a\u4e2a\u7528\u6237\u5171\u4eab\u6570\u636e\u65f6\u3002", "method": "\u96c6\u6210\u56db\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u81ea\u52a8\u654f\u611f\u533a\u57df\u68c0\u6d4b\u3001\u540e\u6821\u6b63\u3001\u5bc6\u94a5\u7ba1\u7406\u548c\u8bbf\u95ee\u63a7\u5236\u3002\u91c7\u7528\u6df7\u5408\u52a0\u5bc6\u65b9\u6848\uff0c\u4f7f\u7528\u5bf9\u79f0\u52a0\u5bc6\u63d0\u9ad8\u6548\u7387\uff0c\u57fa\u4e8e\u5c5e\u6027\u7684\u52a0\u5bc6\u5b9e\u73b0\u7b56\u7565\u6267\u884c\u3002\u652f\u6301\u9ad8\u6548\u5bc6\u94a5\u5206\u53d1\u5e76\u9694\u79bb\u5bc6\u94a5\u5b58\u50a8\u3002", "result": "\u5728\u89c6\u89c9\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u663e\u793a\uff0c\u7cfb\u7edf\u63d0\u4f9b\u6709\u6548\u7684\u9690\u79c1\u654f\u611f\u5bf9\u8c61\u68c0\u6d4b\uff0c\u5b8f\u89c2\u5e73\u5747F1\u5206\u6570\u63d0\u9ad85%\uff0c\u5e73\u5747\u7cbe\u5ea6\u5747\u503c\u63d0\u9ad810%\uff0c\u5e73\u5747\u7b56\u7565\u6267\u884c\u89e3\u5bc6\u65f6\u95f4\u4f4e\u4e8e\u6bcf\u5f20\u56fe\u50cf1\u79d2\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u7ec6\u7c92\u5ea6\u8bbf\u95ee\u63a7\u5236\u63d0\u4f9b\u4e86\u6709\u6548\u3001\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u5927\u89c4\u6a21\u6570\u636e\u5171\u4eab\u73af\u5883\u4e2d\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\u3002"}}
{"id": "2510.19420", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.MA", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.19420", "abs": "https://arxiv.org/abs/2510.19420", "authors": ["Chengcan Wu", "Zhixin Zhang", "Mingqian Xu", "Zeming Wei", "Meng Sun"], "title": "Monitoring LLM-based Multi-Agent Systems Against Corruptions via Node Evaluation", "comment": null, "summary": "Large Language Model (LLM)-based Multi-Agent Systems (MAS) have become a\npopular paradigm of AI applications. However, trustworthiness issues in MAS\nremain a critical concern. Unlike challenges in single-agent systems, MAS\ninvolve more complex communication processes, making them susceptible to\ncorruption attacks. To mitigate this issue, several defense mechanisms have\nbeen developed based on the graph representation of MAS, where agents represent\nnodes and communications form edges. Nevertheless, these methods predominantly\nfocus on static graph defense, attempting to either detect attacks in a fixed\ngraph structure or optimize a static topology with certain defensive\ncapabilities. To address this limitation, we propose a dynamic defense paradigm\nfor MAS graph structures, which continuously monitors communication within the\nMAS graph, then dynamically adjusts the graph topology, accurately disrupts\nmalicious communications, and effectively defends against evolving and diverse\ndynamic attacks. Experimental results in increasingly complex and dynamic MAS\nenvironments demonstrate that our method significantly outperforms existing MAS\ndefense mechanisms, contributing an effective guardrail for their trustworthy\napplications. Our code is available at\nhttps://github.com/ChengcanWu/Monitoring-LLM-Based-Multi-Agent-Systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u52a8\u6001\u9632\u5fa1\u8303\u5f0f\uff0c\u901a\u8fc7\u6301\u7eed\u76d1\u63a7\u901a\u4fe1\u5e76\u52a8\u6001\u8c03\u6574\u56fe\u62d3\u6251\u7ed3\u6784\u6765\u9632\u5fa1\u6076\u610f\u653b\u51fb\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6d89\u53ca\u590d\u6742\u7684\u901a\u4fe1\u8fc7\u7a0b\uff0c\u5bb9\u6613\u53d7\u5230\u8150\u8d25\u653b\u51fb\uff0c\u800c\u73b0\u6709\u7684\u9759\u6001\u56fe\u9632\u5fa1\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u52a8\u6001\u653b\u51fb\u3002", "method": "\u91c7\u7528\u52a8\u6001\u9632\u5fa1\u8303\u5f0f\uff0c\u6301\u7eed\u76d1\u63a7MAS\u56fe\u4e2d\u7684\u901a\u4fe1\uff0c\u52a8\u6001\u8c03\u6574\u56fe\u62d3\u6251\u7ed3\u6784\uff0c\u51c6\u786e\u7834\u574f\u6076\u610f\u901a\u4fe1\u3002", "result": "\u5728\u65e5\u76ca\u590d\u6742\u548c\u52a8\u6001\u7684MAS\u73af\u5883\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684MAS\u9632\u5fa1\u673a\u5236\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53ef\u4fe1\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9632\u62a4\u63aa\u65bd\u3002"}}
{"id": "2510.19805", "categories": ["cs.DC", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.19805", "abs": "https://arxiv.org/abs/2510.19805", "authors": ["Carl-Johan Fauvelle Munck af Rosensch\"old", "Feras M. Awaysheh", "Ahmad Awad"], "title": "Next Generation Cloud-native In-Memory Stores: From Redis to Valkey and Beyond", "comment": "10 pages, 5 figures, 2 algorithms, 4 tables", "summary": "In-memory key-value datastores have become indispensable building blocks of\nmodern cloud-native infrastructures, yet their evolution faces scalability,\ncompatibility, and sustainability constraints. The current literature lacks an\nexperimental evaluation of state-of-the-art tools in the domain. This study\naddressed this timely gap by benchmarking Redis alternatives and systematically\nevaluating Valkey, KeyDB, and Garnet under realistic workloads within\nKubernetes deployments. The results demonstrate clear trade-offs among the\nbenchmarked data systems. Our study presents a comprehensive performance and\nviability assessment of the emerging in-memory key-value stores. Metrics\ninclude throughput, tail latency, CPU and memory efficiency, and migration\ncomplexity. We highlight trade-offs between performance, compatibility, and\nlong-term viability, including project maturity, community support, and\nsustained development.", "AI": {"tldr": "\u672c\u6587\u5bf9Redis\u66ff\u4ee3\u54c1Valkey\u3001KeyDB\u548cGarnet\u5728Kubernetes\u73af\u5883\u4e0b\u7684\u6027\u80fd\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e86\u541e\u5410\u91cf\u3001\u5ef6\u8fdf\u3001\u8d44\u6e90\u6548\u7387\u548c\u8fc1\u79fb\u590d\u6742\u6027\u7b49\u6307\u6807\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5bf9\u5185\u5b58\u952e\u503c\u6570\u636e\u5b58\u50a8\u9886\u57df\u6700\u65b0\u5de5\u5177\u7684\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u8fd9\u4e9b\u5de5\u5177\u5728\u73b0\u4ee3\u4e91\u539f\u751f\u57fa\u7840\u8bbe\u65bd\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u53d1\u5c55\u9762\u4e34\u53ef\u6269\u5c55\u6027\u3001\u517c\u5bb9\u6027\u548c\u53ef\u6301\u7eed\u6027\u9650\u5236\u3002", "method": "\u5728Kubernetes\u90e8\u7f72\u4e2d\u4f7f\u7528\u73b0\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u5bf9Valkey\u3001KeyDB\u548cGarnet\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7cfb\u7edf\u8bc4\u4f30\u6027\u80fd\u6307\u6807\u3002", "result": "\u7ed3\u679c\u663e\u793a\u88ab\u6d4b\u8bd5\u7684\u6570\u636e\u7cfb\u7edf\u4e4b\u95f4\u5b58\u5728\u660e\u786e\u7684\u6743\u8861\u5173\u7cfb\uff0c\u4e0d\u540c\u5de5\u5177\u5728\u6027\u80fd\u3001\u517c\u5bb9\u6027\u548c\u957f\u671f\u53ef\u884c\u6027\u65b9\u9762\u5404\u6709\u4f18\u52a3\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u5bf9\u65b0\u5174\u5185\u5b58\u952e\u503c\u5b58\u50a8\u7684\u5168\u9762\u6027\u80fd\u548c\u53ef\u884c\u6027\u8bc4\u4f30\uff0c\u5f3a\u8c03\u4e86\u6027\u80fd\u3001\u517c\u5bb9\u6027\u548c\u957f\u671f\u53ef\u884c\u6027\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u5305\u62ec\u9879\u76ee\u6210\u719f\u5ea6\u3001\u793e\u533a\u652f\u6301\u548c\u6301\u7eed\u53d1\u5c55\u7b49\u65b9\u9762\u3002"}}
{"id": "2510.19661", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19661", "abs": "https://arxiv.org/abs/2510.19661", "authors": ["Xusen Guo", "Mingxing Peng", "Xixuan Hao", "Xingchen Zou", "Qiongyan Wang", "Sijie Ruan", "Yuxuan Liang"], "title": "AgentSense: LLMs Empower Generalizable and Explainable Web-Based Participatory Urban Sensing", "comment": "13 pages, 10 pages", "summary": "Web-based participatory urban sensing has emerged as a vital approach for\nmodern urban management by leveraging mobile individuals as distributed\nsensors. However, existing urban sensing systems struggle with limited\ngeneralization across diverse urban scenarios and poor interpretability in\ndecision-making. In this work, we introduce AgentSense, a hybrid, training-free\nframework that integrates large language models (LLMs) into participatory urban\nsensing through a multi-agent evolution system. AgentSense initially employs\nclassical planner to generate baseline solutions and then iteratively refines\nthem to adapt sensing task assignments to dynamic urban conditions and\nheterogeneous worker preferences, while producing natural language explanations\nthat enhance transparency and trust. Extensive experiments across two\nlarge-scale mobility datasets and seven types of dynamic disturbances\ndemonstrate that AgentSense offers distinct advantages in adaptivity and\nexplainability over traditional methods. Furthermore, compared to single-agent\nLLM baselines, our approach outperforms in both performance and robustness,\nwhile delivering more reasonable and transparent explanations. These results\nposition AgentSense as a significant advancement towards deploying adaptive and\nexplainable urban sensing systems on the web.", "AI": {"tldr": "AgentSense\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u8fdb\u5316\u7cfb\u7edf\u7684\u6df7\u5408\u8bad\u7ec3\u514d\u8d39\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230\u53c2\u4e0e\u5f0f\u57ce\u5e02\u611f\u77e5\u4e2d\uff0c\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u6765\u9002\u5e94\u52a8\u6001\u57ce\u5e02\u6761\u4ef6\u548c\u5f02\u6784\u5de5\u4f5c\u8005\u504f\u597d\uff0c\u540c\u65f6\u63d0\u4f9b\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u4ee5\u589e\u5f3a\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u3002", "motivation": "\u73b0\u6709\u7684\u57ce\u5e02\u611f\u77e5\u7cfb\u7edf\u5728\u591a\u6837\u5316\u57ce\u5e02\u573a\u666f\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u51b3\u7b56\u8fc7\u7a0b\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u9002\u5e94\u52a8\u6001\u57ce\u5e02\u6761\u4ef6\u3001\u8003\u8651\u5de5\u4f5c\u8005\u504f\u597d\u5e76\u63d0\u4f9b\u900f\u660e\u89e3\u91ca\u7684\u611f\u77e5\u7cfb\u7edf\u3002", "method": "AgentSense\u91c7\u7528\u6df7\u5408\u8bad\u7ec3\u514d\u8d39\u6846\u67b6\uff0c\u9996\u5148\u4f7f\u7528\u7ecf\u5178\u89c4\u5212\u5668\u751f\u6210\u57fa\u7ebf\u89e3\u51b3\u65b9\u6848\uff0c\u7136\u540e\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u8fdb\u5316\u7cfb\u7edf\u8fed\u4ee3\u4f18\u5316\u8fd9\u4e9b\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u5176\u9002\u5e94\u52a8\u6001\u57ce\u5e02\u6761\u4ef6\u548c\u5f02\u6784\u5de5\u4f5c\u8005\u504f\u597d\uff0c\u540c\u65f6\u751f\u6210\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002", "result": "\u5728\u4e24\u4e2a\u5927\u89c4\u6a21\u79fb\u52a8\u6570\u636e\u96c6\u548c\u4e03\u79cd\u52a8\u6001\u5e72\u6270\u7c7b\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cAgentSense\u5728\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002\u4e0e\u5355\u667a\u80fd\u4f53LLM\u57fa\u7ebf\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u5e76\u63d0\u4f9b\u66f4\u5408\u7406\u548c\u900f\u660e\u7684\u89e3\u91ca\u3002", "conclusion": "AgentSense\u4ee3\u8868\u4e86\u5411\u90e8\u7f72\u81ea\u9002\u5e94\u548c\u53ef\u89e3\u91ca\u57ce\u5e02\u611f\u77e5\u7cfb\u7edf\u7684\u91cd\u8981\u8fdb\u5c55\uff0c\u4e3a\u57fa\u4e8eWeb\u7684\u57ce\u5e02\u7ba1\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.23130", "categories": ["cs.AI", "cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.23130", "abs": "https://arxiv.org/abs/2509.23130", "authors": ["Qian Cheng", "Ruize Tang", "Emilie Ma", "Finn Hackett", "Peiyang He", "Yiming Su", "Ivan Beschastnikh", "Yu Huang", "Xiaoxing Ma", "Tianyin Xu"], "title": "SysMoBench: Evaluating AI on Formally Modeling Complex Real-World Systems", "comment": null, "summary": "Formal models are essential to specifying large, complex computer systems and\nverifying their correctness, but are notoriously expensive to write and\nmaintain. Recent advances in generative AI show promise in generating certain\nforms of specifications. However, existing work mostly targets small code, not\ncomplete systems. It is unclear whether AI can deal with realistic system\nartifacts, as this requires abstracting their complex behavioral properties\ninto formal models. We present SysMoBench, a benchmark that evaluates AI's\nability to formally model large, complex systems. We focus on concurrent and\ndistributed systems, which are keystones of today's critical computing\ninfrastructures, encompassing operating systems and cloud infrastructure. We\nuse TLA+, the de facto specification language for concurrent and distributed\nsystems, though the benchmark can be extended to other specification languages.\nWe address the primary challenge of evaluating AI-generated models by\nautomating metrics like syntactic and runtime correctness, conformance to\nsystem code, and invariant correctness. SysMoBench currently includes nine\ndiverse system artifacts: the Raft implementation of Etcd and Redis, the\nSpinlock and Mutex in Asterinas OS, etc.; more artifacts are being actively\nadded. SysMoBench enables us to understand the capabilities and limitations of\ntoday's LLMs and agents, putting tools in this area on a firm footing and\nopening up promising new research directions.", "AI": {"tldr": "SysMoBench\u662f\u4e00\u4e2a\u8bc4\u4f30AI\u4e3a\u5927\u578b\u590d\u6742\u7cfb\u7edf\u751f\u6210\u5f62\u5f0f\u5316\u6a21\u578b\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u6ce8\u4e8e\u5e76\u53d1\u548c\u5206\u5e03\u5f0f\u7cfb\u7edf\uff0c\u4f7f\u7528TLA+\u4f5c\u4e3a\u89c4\u8303\u8bed\u8a00\uff0c\u5305\u542b9\u4e2a\u7cfb\u7edf\u7ec4\u4ef6\u5e76\u81ea\u52a8\u5316\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u5f62\u5f0f\u5316\u6a21\u578b\u5bf9\u4e8e\u6307\u5b9a\u5927\u578b\u590d\u6742\u8ba1\u7b97\u673a\u7cfb\u7edf\u5e76\u9a8c\u8bc1\u5176\u6b63\u786e\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7f16\u5199\u548c\u7ef4\u62a4\u6210\u672c\u9ad8\u6602\u3002\u73b0\u6709AI\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u5c0f\u578b\u4ee3\u7801\u800c\u975e\u5b8c\u6574\u7cfb\u7edf\uff0c\u9700\u8981\u8bc4\u4f30AI\u662f\u5426\u80fd\u5904\u7406\u73b0\u5b9e\u7cfb\u7edf\u7ec4\u4ef6\u5e76\u5c06\u5176\u590d\u6742\u884c\u4e3a\u5c5e\u6027\u62bd\u8c61\u4e3a\u5f62\u5f0f\u5316\u6a21\u578b\u3002", "method": "\u5f00\u53d1SysMoBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u6ce8\u4e8e\u5e76\u53d1\u548c\u5206\u5e03\u5f0f\u7cfb\u7edf\uff0c\u4f7f\u7528TLA+\u4f5c\u4e3a\u89c4\u8303\u8bed\u8a00\uff0c\u81ea\u52a8\u5316\u8bc4\u4f30\u8bed\u6cd5\u548c\u8fd0\u884c\u65f6\u6b63\u786e\u6027\u3001\u4e0e\u7cfb\u7edf\u4ee3\u7801\u4e00\u81f4\u6027\u4ee5\u53ca\u4e0d\u53d8\u5f0f\u6b63\u786e\u6027\u7b49\u6307\u6807\u3002", "result": "SysMoBench\u76ee\u524d\u5305\u542b9\u4e2a\u591a\u6837\u5316\u7cfb\u7edf\u7ec4\u4ef6\uff1aEtcd\u548cRedis\u7684Raft\u5b9e\u73b0\u3001Asterinas OS\u4e2d\u7684\u81ea\u65cb\u9501\u548c\u4e92\u65a5\u9501\u7b49\uff0c\u66f4\u591a\u7ec4\u4ef6\u6b63\u5728\u79ef\u6781\u6dfb\u52a0\u4e2d\u3002", "conclusion": "SysMoBench\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u4e86\u89e3\u5f53\u524dLLM\u548c\u667a\u80fd\u4f53\u7684\u80fd\u529b\u4e0e\u5c40\u9650\u6027\uff0c\u4e3a\u8be5\u9886\u57df\u5de5\u5177\u63d0\u4f9b\u575a\u5b9e\u57fa\u7840\uff0c\u5e76\u5f00\u8f9f\u6709\u524d\u666f\u7684\u65b0\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2510.19666", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19666", "abs": "https://arxiv.org/abs/2510.19666", "authors": ["Matthew Keating", "Michael Casey"], "title": "A Graph Engine for Guitar Chord-Tone Soloing Education", "comment": "ICMC 2025", "summary": "We present a graph-based engine for computing chord tone soloing suggestions\nfor guitar students. Chord tone soloing is a fundamental practice for\nimprovising over a chord progression, where the instrumentalist uses only the\nnotes contained in the current chord. This practice is a building block for all\nadvanced jazz guitar theory but is difficult to learn and practice. First, we\ndiscuss methods for generating chord-tone arpeggios. Next, we construct a\nweighted graph where each node represents a chord tone arpeggio for a chord in\nthe progression. Then, we calculate the edge weight between each consecutive\nchord's nodes in terms of optimal transition tones. We then find the shortest\npath through this graph and reconstruct a chord-tone soloing line. Finally, we\ndiscuss a user-friendly system to handle input and output to this engine for\nguitar students to practice chord tone soloing.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u56fe\u8bba\u7684\u5409\u4ed6\u5373\u5174\u6f14\u594f\u5efa\u8bae\u5f15\u64ce\uff0c\u901a\u8fc7\u6784\u5efa\u548c\u5f26\u97f3\u9636\u56fe\u5e76\u8ba1\u7b97\u6700\u4f18\u8def\u5f84\uff0c\u4e3a\u5409\u4ed6\u5b66\u751f\u63d0\u4f9b\u548c\u5f26\u97f3\u72ec\u594f\u7ec3\u4e60\u6307\u5bfc\u3002", "motivation": "\u548c\u5f26\u97f3\u72ec\u594f\u662f\u7235\u58eb\u5409\u4ed6\u5373\u5174\u6f14\u594f\u7684\u57fa\u7840\u7ec3\u4e60\uff0c\u4f46\u5b66\u4e60\u548c\u7ec3\u4e60\u96be\u5ea6\u8f83\u5927\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u5de5\u5177\u6765\u5e2e\u52a9\u5b66\u751f\u638c\u63e1\u8fd9\u4e00\u91cd\u8981\u6280\u80fd\u3002", "method": "\u9996\u5148\u751f\u6210\u548c\u5f26\u97f3\u9636\uff0c\u6784\u5efa\u52a0\u6743\u56fe\u7ed3\u6784\uff0c\u8ba1\u7b97\u76f8\u90bb\u548c\u5f26\u8282\u70b9\u95f4\u7684\u6700\u4f18\u8fc7\u6e21\u97f3\u6743\u91cd\uff0c\u901a\u8fc7\u6700\u77ed\u8def\u5f84\u7b97\u6cd5\u751f\u6210\u548c\u5f26\u97f3\u72ec\u594f\u7ebf\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u6237\u53cb\u597d\u7684\u7cfb\u7edf\uff0c\u80fd\u591f\u5904\u7406\u8f93\u5165\u548c\u8f93\u51fa\uff0c\u4e3a\u5409\u4ed6\u5b66\u751f\u63d0\u4f9b\u6709\u6548\u7684\u548c\u5f26\u97f3\u72ec\u594f\u7ec3\u4e60\u5de5\u5177\u3002", "conclusion": "\u8be5\u57fa\u4e8e\u56fe\u8bba\u7684\u5f15\u64ce\u4e3a\u5409\u4ed6\u5b66\u751f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u548c\u5f26\u97f3\u72ec\u594f\u7ec3\u4e60\u7cfb\u7edf\uff0c\u6709\u52a9\u4e8e\u638c\u63e1\u7235\u58eb\u5409\u4ed6\u5373\u5174\u6f14\u594f\u7684\u57fa\u7840\u6280\u80fd\u3002"}}
{"id": "2510.19491", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19491", "abs": "https://arxiv.org/abs/2510.19491", "authors": ["Jonas Gebele", "Timm Mutzel", "Burak Oez", "Florian Matthes"], "title": "Cross-Chain Sealed-Bid Auctions Using Confidential Compute Blockchains", "comment": null, "summary": "Sealed-bid auctions ensure fair competition and efficient allocation but are\noften deployed on centralized infrastructure, enabling opaque manipulation.\nPublic blockchains eliminate central control, yet their inherent transparency\nconflicts with the confidentiality required for sealed bidding. Prior attempts\nstruggle to reconcile privacy, verifiability, and scalability without relying\non trusted intermediaries, multi-round protocols, or expensive cryptography. We\npresent a sealed-bid auction protocol that executes sensitive bidding logic on\na Trusted Execution Environment (TEE)-backed confidential compute blockchain\nwhile retaining settlement and enforcement on a public chain. Bidders commit\nfunds to enclave-generated escrow addresses, ensuring confidentiality and\nbinding commitments. After the deadline, any party can trigger resolution: the\nconfidential blockchain determines the winner through verifiable off-chain\ncomputation and issues signed settlement transactions for execution on the\npublic chain. Our design provides security, privacy, and scalability without\ntrusted third parties or protocol modifications. We implement it on SUAVE with\nEthereum settlement, evaluate its scalability and trust assumptions, and\ndemonstrate deployment with minimal integration on existing infrastructure", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u4fe1\u6267\u884c\u73af\u5883(TEE)\u7684\u5bc6\u5c01\u6295\u6807\u62cd\u5356\u534f\u8bae\uff0c\u5728\u673a\u5bc6\u8ba1\u7b97\u533a\u5757\u94fe\u4e0a\u6267\u884c\u654f\u611f\u6295\u6807\u903b\u8f91\uff0c\u540c\u65f6\u5728\u516c\u5171\u94fe\u4e0a\u5b8c\u6210\u7ed3\u7b97\u548c\u6267\u884c\uff0c\u89e3\u51b3\u4e86\u5bc6\u5c01\u6295\u6807\u7684\u9690\u79c1\u6027\u3001\u53ef\u9a8c\u8bc1\u6027\u548c\u53ef\u6269\u5c55\u6027\u4e4b\u95f4\u7684\u77db\u76fe\u3002", "motivation": "\u4f20\u7edf\u5bc6\u5c01\u6295\u6807\u62cd\u5356\u5728\u4e2d\u5fc3\u5316\u57fa\u7840\u8bbe\u65bd\u4e0a\u90e8\u7f72\u5b58\u5728\u4e0d\u900f\u660e\u64cd\u7eb5\u98ce\u9669\uff0c\u800c\u516c\u5171\u533a\u5757\u94fe\u7684\u900f\u660e\u6027\u4e0e\u5bc6\u5c01\u6295\u6807\u7684\u673a\u5bc6\u6027\u8981\u6c42\u76f8\u51b2\u7a81\u3002\u73b0\u6709\u65b9\u6848\u96be\u4ee5\u5728\u4e0d\u4f9d\u8d56\u53ef\u4fe1\u4e2d\u4ecb\u3001\u591a\u8f6e\u534f\u8bae\u6216\u6602\u8d35\u5bc6\u7801\u5b66\u7684\u60c5\u51b5\u4e0b\u540c\u65f6\u6ee1\u8db3\u9690\u79c1\u6027\u3001\u53ef\u9a8c\u8bc1\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u4f7f\u7528TEE\u652f\u6301\u7684\u673a\u5bc6\u8ba1\u7b97\u533a\u5757\u94fe\u6267\u884c\u654f\u611f\u6295\u6807\u903b\u8f91\uff0c\u6295\u6807\u4eba\u5c06\u8d44\u91d1\u63d0\u4ea4\u5230\u7531enclave\u751f\u6210\u7684\u6258\u7ba1\u5730\u5740\u786e\u4fdd\u673a\u5bc6\u6027\u548c\u7ed1\u5b9a\u627f\u8bfa\u3002\u622a\u6b62\u540e\u4efb\u4f55\u65b9\u90fd\u53ef\u89e6\u53d1\u89e3\u51b3\u65b9\u6848\uff1a\u673a\u5bc6\u533a\u5757\u94fe\u901a\u8fc7\u53ef\u9a8c\u8bc1\u7684\u94fe\u4e0b\u8ba1\u7b97\u786e\u5b9a\u83b7\u80dc\u8005\uff0c\u5e76\u7b7e\u53d1\u7b7e\u540d\u7ed3\u7b97\u4ea4\u6613\u5728\u516c\u5171\u94fe\u4e0a\u6267\u884c\u3002", "result": "\u8be5\u8bbe\u8ba1\u5728\u4e0d\u4f9d\u8d56\u53ef\u4fe1\u7b2c\u4e09\u65b9\u6216\u534f\u8bae\u4fee\u6539\u7684\u60c5\u51b5\u4e0b\u63d0\u4f9b\u4e86\u5b89\u5168\u6027\u3001\u9690\u79c1\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002\u5728SUAVE\u4e0a\u5b9e\u73b0\u5e76\u4e0e\u4ee5\u592a\u574a\u7ed3\u7b97\u96c6\u6210\uff0c\u8bc4\u4f30\u4e86\u5176\u53ef\u6269\u5c55\u6027\u548c\u4fe1\u4efb\u5047\u8bbe\uff0c\u5c55\u793a\u4e86\u5728\u73b0\u6709\u57fa\u7840\u8bbe\u65bd\u4e0a\u7684\u6700\u5c0f\u96c6\u6210\u90e8\u7f72\u3002", "conclusion": "\u63d0\u51fa\u7684\u534f\u8bae\u6210\u529f\u89e3\u51b3\u4e86\u5bc6\u5c01\u6295\u6807\u62cd\u5356\u5728\u533a\u5757\u94fe\u73af\u5883\u4e2d\u7684\u9690\u79c1\u4e0e\u900f\u660e\u6027\u77db\u76fe\uff0c\u901a\u8fc7TEE\u548c\u673a\u5bc6\u8ba1\u7b97\u533a\u5757\u94fe\u7684\u7ed3\u5408\u5b9e\u73b0\u4e86\u65e0\u9700\u53ef\u4fe1\u4e2d\u4ecb\u7684\u5b89\u5168\u3001\u79c1\u5bc6\u4e14\u53ef\u6269\u5c55\u7684\u62cd\u5356\u7cfb\u7edf\u3002"}}
{"id": "2510.19671", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19671", "abs": "https://arxiv.org/abs/2510.19671", "authors": ["Silvia Garc\u00eda-M\u00e9ndez", "Francisco de Arriba-P\u00e9rez"], "title": "Explainable e-sports win prediction through Machine Learning classification in streaming", "comment": null, "summary": "The increasing number of spectators and players in e-sports, along with the\ndevelopment of optimized communication solutions and cloud computing\ntechnology, has motivated the constant growth of the online game industry. Even\nthough Artificial Intelligence-based solutions for e-sports analytics are\ntraditionally defined as extracting meaningful patterns from related data and\nvisualizing them to enhance decision-making, most of the effort in professional\nwinning prediction has been focused on the classification aspect from a batch\nperspective, also leaving aside the visualization techniques. Consequently,\nthis work contributes to an explainable win prediction classification solution\nin streaming in which input data is controlled over several sliding windows to\nreflect relevant game changes. Experimental results attained an accuracy higher\nthan 90 %, surpassing the performance of competing solutions in the literature.\nUltimately, our system can be leveraged by ranking and recommender systems for\ninformed decision-making, thanks to the explainability module, which fosters\ntrust in the outcome predictions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u7535\u5b50\u7ade\u6280\u6d41\u5f0f\u80dc\u7387\u9884\u6d4b\u5206\u7c7b\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u6ed1\u52a8\u7a97\u53e3\u63a7\u5236\u8f93\u5165\u6570\u636e\u4ee5\u53cd\u6620\u6e38\u620f\u53d8\u5316\uff0c\u51c6\u786e\u7387\u8d85\u8fc790%\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u7535\u5b50\u7ade\u6280\u89c2\u4f17\u548c\u73a9\u5bb6\u6570\u91cf\u7684\u589e\u957f\uff0c\u4ee5\u53ca\u901a\u4fe1\u89e3\u51b3\u65b9\u6848\u548c\u4e91\u8ba1\u7b97\u6280\u672f\u7684\u53d1\u5c55\uff0c\u63a8\u52a8\u4e86\u5728\u7ebf\u6e38\u620f\u884c\u4e1a\u7684\u6301\u7eed\u53d1\u5c55\u3002\u867d\u7136\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u7535\u5b50\u7ade\u6280\u5206\u6790\u4f20\u7edf\u4e0a\u88ab\u5b9a\u4e49\u4e3a\u4ece\u76f8\u5173\u6570\u636e\u4e2d\u63d0\u53d6\u6709\u610f\u4e49\u7684\u6a21\u5f0f\u5e76\u8fdb\u884c\u53ef\u89c6\u5316\u4ee5\u589e\u5f3a\u51b3\u7b56\uff0c\u4f46\u5927\u591a\u6570\u4e13\u4e1a\u80dc\u7387\u9884\u6d4b\u5de5\u4f5c\u90fd\u96c6\u4e2d\u5728\u6279\u91cf\u5206\u7c7b\u65b9\u9762\uff0c\u800c\u5ffd\u7565\u4e86\u53ef\u89c6\u5316\u6280\u672f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u6d41\u5f0f\u80dc\u7387\u9884\u6d4b\u5206\u7c7b\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u591a\u4e2a\u6ed1\u52a8\u7a97\u53e3\u63a7\u5236\u8f93\u5165\u6570\u636e\u4ee5\u53cd\u6620\u76f8\u5173\u6e38\u620f\u53d8\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u51c6\u786e\u7387\u8d85\u8fc790%\uff0c\u8d85\u8d8a\u4e86\u6587\u732e\u4e2d\u7684\u7ade\u4e89\u89e3\u51b3\u65b9\u6848\u6027\u80fd\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u53ef\u88ab\u6392\u540d\u548c\u63a8\u8350\u7cfb\u7edf\u5229\u7528\u8fdb\u884c\u660e\u667a\u51b3\u7b56\uff0c\u5f97\u76ca\u4e8e\u53ef\u89e3\u91ca\u6027\u6a21\u5757\uff0c\u589e\u5f3a\u4e86\u5bf9\u7ed3\u679c\u9884\u6d4b\u7684\u4fe1\u4efb\u3002"}}
{"id": "2510.19698", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19698", "abs": "https://arxiv.org/abs/2510.19698", "authors": ["Yang Yang", "Hua XU", "Zhangyi Hu", "Yutao Yue"], "title": "RLIE: Rule Generation with Logistic Regression, Iterative Refinement, and Evaluation for Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) can propose rules in natural language,\nsidestepping the need for a predefined predicate space in traditional rule\nlearning. Yet many LLM-based approaches ignore interactions among rules, and\nthe opportunity to couple LLMs with probabilistic rule learning for robust\ninference remains underexplored. We present RLIE, a unified framework that\nintegrates LLMs with probabilistic modeling to learn a set of weighted rules.\nRLIE has four stages: (1) Rule generation, where an LLM proposes and filters\ncandidates; (2) Logistic regression, which learns probabilistic weights for\nglobal selection and calibration; (3) Iterative refinement, which updates the\nrule set using prediction errors; and (4) Evaluation, which compares the\nweighted rule set as a direct classifier with methods that inject rules into an\nLLM. We evaluate multiple inference strategies on real-world datasets. Applying\nrules directly with their learned weights yields superior performance, whereas\nprompting LLMs with the rules, weights, and logistic-model outputs surprisingly\ndegrades accuracy. This supports the view that LLMs excel at semantic\ngeneration and interpretation but are less reliable for precise probabilistic\nintegration. RLIE clarifies the potential and limitations of LLMs for inductive\nreasoning and couples them with classic probabilistic rule combination methods\nto enable more reliable neuro-symbolic reasoning.", "AI": {"tldr": "RLIE\u662f\u4e00\u4e2a\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u6982\u7387\u5efa\u6a21\u76f8\u7ed3\u5408\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4e8e\u5b66\u4e60\u52a0\u6743\u89c4\u5219\u96c6\uff0c\u901a\u8fc7\u89c4\u5219\u751f\u6210\u3001\u903b\u8f91\u56de\u5f52\u3001\u8fed\u4ee3\u4f18\u5316\u548c\u8bc4\u4f30\u56db\u4e2a\u9636\u6bb5\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u5ffd\u89c6\u4e86\u89c4\u5219\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4e14\u5c06LLM\u4e0e\u6982\u7387\u89c4\u5219\u5b66\u4e60\u7ed3\u5408\u8fdb\u884c\u9c81\u68d2\u63a8\u7406\u7684\u673a\u4f1a\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "RLIE\u5305\u542b\u56db\u4e2a\u9636\u6bb5\uff1aLLM\u751f\u6210\u548c\u7b5b\u9009\u5019\u9009\u89c4\u5219\uff1b\u903b\u8f91\u56de\u5f52\u5b66\u4e60\u6982\u7387\u6743\u91cd\uff1b\u57fa\u4e8e\u9884\u6d4b\u8bef\u5dee\u8fed\u4ee3\u4f18\u5316\u89c4\u5219\u96c6\uff1b\u8bc4\u4f30\u52a0\u6743\u89c4\u5219\u96c6\u4f5c\u4e3a\u76f4\u63a5\u5206\u7c7b\u5668\u7684\u6027\u80fd\u3002", "result": "\u76f4\u63a5\u4f7f\u7528\u5b66\u4e60\u5230\u7684\u6743\u91cd\u5e94\u7528\u89c4\u5219\u53ef\u83b7\u5f97\u4f18\u8d8a\u6027\u80fd\uff0c\u800c\u5c06\u89c4\u5219\u3001\u6743\u91cd\u548c\u903b\u8f91\u6a21\u578b\u8f93\u51fa\u63d0\u793a\u7ed9LLM\u53cd\u800c\u4f1a\u964d\u4f4e\u51c6\u786e\u6027\u3002", "conclusion": "LLM\u64c5\u957f\u8bed\u4e49\u751f\u6210\u548c\u89e3\u91ca\uff0c\u4f46\u5728\u7cbe\u786e\u6982\u7387\u96c6\u6210\u65b9\u9762\u53ef\u9760\u6027\u8f83\u4f4e\u3002RLIE\u9610\u660e\u4e86LLM\u5728\u5f52\u7eb3\u63a8\u7406\u4e2d\u7684\u6f5c\u529b\u548c\u5c40\u9650\u6027\uff0c\u5e76\u5c06\u5176\u4e0e\u7ecf\u5178\u6982\u7387\u89c4\u5219\u7ec4\u5408\u65b9\u6cd5\u7ed3\u5408\u4ee5\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u3002"}}
{"id": "2510.19676", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19676", "abs": "https://arxiv.org/abs/2510.19676", "authors": ["Nowfel Mashnoor", "Mohammad Akyash", "Hadi Kamali", "Kimia Azar"], "title": "CircuitGuard: Mitigating LLM Memorization in RTL Code Generation Against IP Leakage", "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable success in generative\ntasks, including register-transfer level (RTL) hardware synthesis. However,\ntheir tendency to memorize training data poses critical risks when proprietary\nor security-sensitive designs are unintentionally exposed during inference.\nWhile prior work has examined memorization in natural language, RTL introduces\nunique challenges: In RTL, structurally different implementations (e.g.,\nbehavioral vs. gate-level descriptions) can realize the same hardware, leading\nto intellectual property (IP) leakage (full or partial) even without verbatim\noverlap. Conversely, even small syntactic variations (e.g., operator precedence\nor blocking vs. non-blocking assignments) can drastically alter circuit\nbehavior, making correctness preservation especially challenging. In this work,\nwe systematically study memorization in RTL code generation and propose\nCircuitGuard, a defense strategy that balances leakage reduction with\ncorrectness preservation. CircuitGuard (1) introduces a novel RTL-aware\nsimilarity metric that captures both structural and functional equivalence\nbeyond surface-level overlap, and (2) develops an activation-level steering\nmethod that identifies and attenuates transformer components most responsible\nfor memorization. Our empirical evaluation demonstrates that CircuitGuard\nidentifies (and isolates) 275 memorization-critical features across layers\n18-28 of Llama 3.1-8B model, achieving up to 80% reduction in semantic\nsimilarity to proprietary patterns while maintaining generation quality.\nCircuitGuard further shows 78-85% cross-domain transfer effectiveness, enabling\nrobust memorization mitigation across circuit categories without retraining.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728RTL\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u8bb0\u5fc6\u95ee\u9898\uff0c\u63d0\u51fa\u4e86CircuitGuard\u9632\u5fa1\u7b56\u7565\uff0c\u901a\u8fc7RTL\u611f\u77e5\u76f8\u4f3c\u6027\u5ea6\u91cf\u548c\u6fc0\u6d3b\u7ea7\u5f15\u5bfc\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5bf9\u4e13\u6709\u8bbe\u8ba1\u7684\u8bb0\u5fc6\u6cc4\u9732\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728RTL\u786c\u4ef6\u5408\u6210\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\u7684\u503e\u5411\u53ef\u80fd\u5bfc\u81f4\u4e13\u6709\u6216\u5b89\u5168\u654f\u611f\u8bbe\u8ba1\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u610f\u5916\u6cc4\u9732\u3002RTL\u4ee3\u7801\u7684\u7279\u6b8a\u6027\u4f7f\u5f97\u4f20\u7edf\u81ea\u7136\u8bed\u8a00\u8bb0\u5fc6\u68c0\u6d4b\u65b9\u6cd5\u4e0d\u9002\u7528\uff0c\u9700\u8981\u4e13\u95e8\u89e3\u51b3\u65b9\u6848\u3002", "method": "CircuitGuard\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a(1) \u65b0\u9896\u7684RTL\u611f\u77e5\u76f8\u4f3c\u6027\u5ea6\u91cf\uff0c\u6355\u6349\u7ed3\u6784\u548c\u529f\u80fd\u7b49\u4ef7\u6027\uff1b(2) \u6fc0\u6d3b\u7ea7\u5f15\u5bfc\u65b9\u6cd5\uff0c\u8bc6\u522b\u5e76\u8870\u51cf\u8d1f\u8d23\u8bb0\u5fc6\u7684transformer\u7ec4\u4ef6\u3002", "result": "CircuitGuard\u5728Llama 3.1-8B\u6a21\u578b\u4e2d\u8bc6\u522b\u51fa275\u4e2a\u8bb0\u5fc6\u5173\u952e\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe80%\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u8d28\u91cf\uff0c\u5e76\u5c55\u793a78-85%\u7684\u8de8\u57df\u8fc1\u79fb\u6548\u679c\u3002", "conclusion": "CircuitGuard\u6709\u6548\u5e73\u8861\u4e86\u6cc4\u9732\u51cf\u5c11\u548c\u6b63\u786e\u6027\u4fdd\u6301\uff0c\u4e3aRTL\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u8bb0\u5fc6\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u8de8\u7535\u8def\u7c7b\u522b\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.19732", "categories": ["cs.AI", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.19732", "abs": "https://arxiv.org/abs/2510.19732", "authors": ["Gunshi Gupta", "Karmesh Yadav", "Zsolt Kira", "Yarin Gal", "Rahaf Aljundi"], "title": "Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning", "comment": "Accepted for Spotlight Presentation at NeurIPS 2025", "summary": "To enable embodied agents to operate effectively over extended timeframes, it\nis crucial to develop models that form and access memories to stay\ncontextualized in their environment. In the current paradigm of training\ntransformer-based policies for embodied sequential decision-making tasks,\nvisual inputs often overwhelm the context limits of transformers, while humans\ncan maintain and utilize a lifetime of experience compressed as memories.\nSignificant compression is possible in principle, as much of the input is\nirrelevant and can be abstracted. However, existing approaches predominantly\nfocus on either recurrent models with fixed-size memory or transformers with\nfull-context reliance. In this work, we propose Memo, a transformer-based\narchitecture and training recipe for reinforcement learning (RL) on\nmemory-intensive, long-horizon tasks. Memo incorporates the creation and\nretrieval of memory by interleaving periodic summarization tokens with the\ninputs of a model during training. We demonstrate Memo's effectiveness on a\ngridworld meta-RL benchmark and a multi-object navigation task in\nphoto-realistic indoor settings. Memo outperforms naive long-context\ntransformer baselines while being more compute and storage efficient.\nAdditionally, Memo generalizes better to longer contexts at inference time and\nremains robust in streaming settings, where historical context must be\ntruncated to fit inference constraints.", "AI": {"tldr": "Memo\u662f\u4e00\u79cd\u57fa\u4e8etransformer\u7684\u67b6\u6784\u548c\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u957f\u65f6\u7a0b\u4efb\u52a1\u7684\u8bb0\u5fc6\u95ee\u9898\uff0c\u901a\u8fc7\u63d2\u5165\u5468\u671f\u6027\u603b\u7ed3\u6807\u8bb0\u6765\u521b\u5efa\u548c\u68c0\u7d22\u8bb0\u5fc6\uff0c\u5728\u8ba1\u7b97\u548c\u5b58\u50a8\u6548\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u957f\u4e0a\u4e0b\u6587transformer\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709transformer\u7b56\u7565\u5728\u5177\u8eab\u51b3\u7b56\u4efb\u52a1\u4e2d\u89c6\u89c9\u8f93\u5165\u5e38\u5e38\u8d85\u51fa\u4e0a\u4e0b\u6587\u9650\u5236\uff0c\u800c\u4eba\u7c7b\u80fd\u591f\u5c06\u7ec8\u8eab\u7ecf\u9a8c\u538b\u7f29\u4e3a\u8bb0\u5fc6\u4f7f\u7528\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f7f\u7528\u56fa\u5b9a\u5927\u5c0f\u8bb0\u5fc6\u7684\u5faa\u73af\u6a21\u578b\uff0c\u8981\u4e48\u4f9d\u8d56\u5b8c\u6574\u4e0a\u4e0b\u6587\u7684transformer\uff0c\u7f3a\u4e4f\u6709\u6548\u7684\u8bb0\u5fc6\u538b\u7f29\u673a\u5236\u3002", "method": "\u63d0\u51faMemo\u67b6\u6784\uff0c\u5728\u8bad\u7ec3\u671f\u95f4\u5c06\u5468\u671f\u6027\u603b\u7ed3\u6807\u8bb0\u4e0e\u6a21\u578b\u8f93\u5165\u4ea4\u9519\uff0c\u5b9e\u73b0\u8bb0\u5fc6\u7684\u521b\u5efa\u548c\u68c0\u7d22\u3002\u8be5\u65b9\u6cd5\u5728\u7f51\u683c\u4e16\u754c\u5143\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u548c\u903c\u771f\u5ba4\u5185\u73af\u5883\u7684\u591a\u76ee\u6807\u5bfc\u822a\u4efb\u52a1\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "Memo\u5728\u8ba1\u7b97\u548c\u5b58\u50a8\u6548\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u957f\u4e0a\u4e0b\u6587transformer\u57fa\u7ebf\uff0c\u5728\u63a8\u7406\u65f6\u5bf9\u66f4\u957f\u4e0a\u4e0b\u6587\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u9700\u8981\u622a\u65ad\u5386\u53f2\u4e0a\u4e0b\u6587\u7684\u6d41\u5f0f\u8bbe\u7f6e\u4e2d\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "Memo\u901a\u8fc7\u8bb0\u5fc6\u538b\u7f29\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u957f\u65f6\u7a0b\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u4e0a\u4e0b\u6587\u9650\u5236\u95ee\u9898\uff0c\u4e3a\u5177\u8eab\u667a\u80fd\u4f53\u5728\u6269\u5c55\u65f6\u95f4\u6846\u67b6\u5185\u7684\u6709\u6548\u64cd\u4f5c\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.19738", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19738", "abs": "https://arxiv.org/abs/2510.19738", "authors": ["Rustem Turtayev", "Natalia Fedorova", "Oleg Serikov", "Sergey Koldyba", "Lev Avagyan", "Dmitrii Volkov"], "title": "Misalignment Bounty: Crowdsourcing AI Agent Misbehavior", "comment": null, "summary": "Advanced AI systems sometimes act in ways that differ from human intent. To\ngather clear, reproducible examples, we ran the Misalignment Bounty: a\ncrowdsourced project that collected cases of agents pursuing unintended or\nunsafe goals. The bounty received 295 submissions, of which nine were awarded.\n  This report explains the program's motivation and evaluation criteria, and\nwalks through the nine winning submissions step by step.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86'Misalignment Bounty'\u9879\u76ee\uff0c\u8fd9\u662f\u4e00\u4e2a\u4f17\u5305\u9879\u76ee\uff0c\u65e8\u5728\u6536\u96c6AI\u7cfb\u7edf\u8ffd\u6c42\u975e\u9884\u671f\u6216\u4e0d\u5b89\u5168\u76ee\u6807\u7684\u6848\u4f8b\u3002\u9879\u76ee\u6536\u5230295\u4efd\u63d0\u4ea4\uff0c\u5176\u4e2d9\u4efd\u83b7\u5956\u3002", "motivation": "\u6536\u96c6AI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u610f\u56fe\u4e0d\u4e00\u81f4\u884c\u4e3a\u7684\u6e05\u6670\u3001\u53ef\u590d\u73b0\u6848\u4f8b\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u548c\u89e3\u51b3AI\u5bf9\u9f50\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u4f17\u5305\u9879\u76ee\u6536\u96c6\u6848\u4f8b\uff0c\u4f7f\u7528\u7279\u5b9a\u8bc4\u4f30\u6807\u51c6\u5bf9295\u4efd\u63d0\u4ea4\u8fdb\u884c\u7b5b\u9009\uff0c\u6700\u7ec8\u9009\u51fa9\u4e2a\u83b7\u5956\u6848\u4f8b\u3002", "result": "\u6210\u529f\u6536\u96c6\u4e86295\u4efd\u6848\u4f8b\u63d0\u4ea4\uff0c\u5176\u4e2d9\u4e2a\u6848\u4f8b\u88ab\u8ba4\u5b9a\u4e3a\u6709\u4ef7\u503c\u7684AI\u5bf9\u9f50\u95ee\u9898\u5b9e\u4f8b\u3002", "conclusion": "Misalignment Bounty\u9879\u76ee\u4e3a\u7814\u7a76AI\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u9645\u6848\u4f8b\uff0c\u5c55\u793a\u4e86AI\u7cfb\u7edf\u53ef\u80fd\u504f\u79bb\u4eba\u7c7b\u610f\u56fe\u7684\u5177\u4f53\u65b9\u5f0f\u3002"}}
{"id": "2510.19771", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19771", "abs": "https://arxiv.org/abs/2510.19771", "authors": ["Gil Pasternak", "Dheeraj Rajagopal", "Julia White", "Dhruv Atreja", "Matthew Thomas", "George Hurn-Maloney", "Ash Lewis"], "title": "Beyond Reactivity: Measuring Proactive Problem Solving in LLM Agents", "comment": null, "summary": "LLM-based agents are increasingly moving towards proactivity: rather than\nawaiting instruction, they exercise agency to anticipate user needs and solve\nthem autonomously. However, evaluating proactivity is challenging; current\nbenchmarks are constrained to localized context, limiting their ability to test\nreasoning across sources and longer time horizons. To address this gap, we\npresent PROBE (Proactive Resolution Of BottlEnecks). PROBE decomposes\nproactivity as a pipeline of three core capabilities: (1) searching for\nunspecified issues, (2) identifying specific bottlenecks, and (3) executing\nappropriate resolutions. We apply PROBE to evaluate leading LLMs and popular\nagentic frameworks, showing that even state-of-the-art models struggle to solve\nthis benchmark. Computing our consistent measurements across frontier LLMs and\nagents, we find that the best end-to-end performance of 40% is achieved by both\nGPT-5 and Claude Opus-4.1. Additionally, we demonstrate the relative\ncapabilities of each model and analyze mutual failure modes. Our results\nhighlight the current limitations of autonomous action in agentic systems, and\nexpose promising future research directions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86PROBE\u57fa\u51c6\u6765\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u7684\u4e3b\u52a8\u6027\u80fd\u529b\uff0c\u53d1\u73b0\u5373\u4f7f\u662f\u5148\u8fdb\u6a21\u578b\u5728\u8be5\u57fa\u51c6\u4e0a\u7684\u7aef\u5230\u7aef\u6027\u80fd\u4e5f\u4ec5\u4e3a40%\uff0c\u63ed\u793a\u4e86\u81ea\u4e3b\u884c\u52a8\u7cfb\u7edf\u7684\u5f53\u524d\u5c40\u9650\u6027\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u4e3b\u52a8\u6027\u7684\u57fa\u51c6\u5c40\u9650\u4e8e\u5c40\u90e8\u4e0a\u4e0b\u6587\uff0c\u65e0\u6cd5\u6d4b\u8bd5\u8de8\u6765\u6e90\u548c\u957f\u65f6\u95f4\u8de8\u5ea6\u7684\u63a8\u7406\u80fd\u529b\uff0c\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51faPROBE\u57fa\u51c6\uff0c\u5c06\u4e3b\u52a8\u6027\u5206\u89e3\u4e3a\u4e09\u4e2a\u6838\u5fc3\u80fd\u529b\uff1a\u641c\u7d22\u672a\u6307\u5b9a\u95ee\u9898\u3001\u8bc6\u522b\u5177\u4f53\u74f6\u9888\u3001\u6267\u884c\u9002\u5f53\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5e94\u7528\u4e8e\u8bc4\u4f30\u9886\u5148LLM\u548c\u6d41\u884c\u667a\u80fd\u4f53\u6846\u67b6\u3002", "result": "GPT-5\u548cClaude Opus-4.1\u5728\u7aef\u5230\u7aef\u6027\u80fd\u4e0a\u8fbe\u523040%\u7684\u6700\u4f73\u8868\u73b0\uff0c\u4f46\u4ecd\u8fdc\u672a\u8fbe\u5230\u7406\u60f3\u6c34\u5e73\uff0c\u63ed\u793a\u4e86\u5404\u6a21\u578b\u7684\u76f8\u5bf9\u80fd\u529b\u548c\u5171\u540c\u5931\u8d25\u6a21\u5f0f\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u7a81\u663e\u4e86\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u81ea\u4e3b\u884c\u52a8\u7684\u5f53\u524d\u5c40\u9650\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u6709\u524d\u666f\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2510.19788", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19788", "abs": "https://arxiv.org/abs/2510.19788", "authors": ["Archana Warrier", "Dat Nyugen", "Michelangelo Naim", "Moksh Jain", "Yichao Liang", "Karen Schroeder", "Cambridge Yang", "Joshua B. Tenenbaum", "Sebastian Vollmer", "Kevin Ellis", "Zenna Tavares"], "title": "Benchmarking World-Model Learning", "comment": "30 pages, 10 figures", "summary": "Model-learning agents should gather information to learn world models that\nsupport many downstream tasks and inferences, such as predicting unobserved\nstates, estimating near- and far-term consequences of actions, planning action\nsequences, and detecting changes in dynamics. Current methods for learning and\nevaluating world models diverge from this goal: training and evaluation are\nanchored to next-frame prediction, and success is scored by reward maximization\nin the same environment. We propose WorldTest, a protocol to evaluate\nmodel-learning agents that separates reward-free interaction from a scored test\nphase in a different but related environment. WorldTest is\nopen-ended$\\unicode{x2014}$models should support many different tasks unknown\nahead of time$\\unicode{x2014}$and agnostic to model representation, allowing\ncomparison across approaches. We instantiated WorldTest with AutumnBench, a\nsuite of 43 interactive grid-world environments and 129 tasks across three\nfamilies: masked-frame prediction, planning, and predicting changes to the\ncausal dynamics. We compared 517 human participants and three frontier models\non AutumnBench. We found that humans outperform the models, and scaling compute\nimproves performance only in some environments but not others. WorldTest\nprovides a novel template$\\unicode{x2014}$reward-free exploration, derived\ntests, and behavior-based scoring$\\unicode{x2014}$to evaluate what agents learn\nabout environment dynamics, and AutumnBench exposes significant headroom in\nworld-model learning.", "AI": {"tldr": "WorldTest\u662f\u4e00\u4e2a\u8bc4\u4f30\u6a21\u578b\u5b66\u4e60\u667a\u80fd\u4f53\u7684\u65b0\u534f\u8bae\uff0c\u5c06\u65e0\u5956\u52b1\u4ea4\u4e92\u4e0e\u5728\u4e0d\u540c\u4f46\u76f8\u5173\u73af\u5883\u4e2d\u7684\u8bc4\u5206\u6d4b\u8bd5\u9636\u6bb5\u5206\u79bb\uff0c\u652f\u6301\u591a\u79cd\u672a\u77e5\u4efb\u52a1\u3002\u4f5c\u8005\u5f00\u53d1\u4e86AutumnBench\u6d4b\u8bd5\u5957\u4ef6\uff0c\u5305\u542b43\u4e2a\u4ea4\u4e92\u5f0f\u7f51\u683c\u4e16\u754c\u73af\u5883\u548c129\u4e2a\u4efb\u52a1\uff0c\u53d1\u73b0\u4eba\u7c7b\u8868\u73b0\u4f18\u4e8e\u524d\u6cbf\u6a21\u578b\uff0c\u4e14\u8ba1\u7b97\u6269\u5c55\u4ec5\u5728\u67d0\u4e9b\u73af\u5883\u4e2d\u63d0\u9ad8\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u4e16\u754c\u6a21\u578b\u5b66\u4e60\u548c\u8bc4\u4f30\u65b9\u6cd5\u504f\u79bb\u4e86\u771f\u6b63\u76ee\u6807\uff1a\u8bad\u7ec3\u548c\u8bc4\u4f30\u90fd\u951a\u5b9a\u5728\u4e0b\u4e00\u5e27\u9884\u6d4b\u4e0a\uff0c\u6210\u529f\u6807\u51c6\u662f\u5728\u540c\u4e00\u73af\u5883\u4e2d\u6700\u5927\u5316\u5956\u52b1\u3002\u4f5c\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u4e2a\u80fd\u8bc4\u4f30\u667a\u80fd\u4f53\u5bf9\u73af\u5883\u52a8\u6001\u5b66\u4e60\u7a0b\u5ea6\u7684\u534f\u8bae\uff0c\u652f\u6301\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u3002", "method": "\u63d0\u51faWorldTest\u534f\u8bae\uff0c\u5305\u542b\u65e0\u5956\u52b1\u63a2\u7d22\u3001\u884d\u751f\u6d4b\u8bd5\u548c\u884c\u4e3a\u8bc4\u5206\u4e09\u4e2a\u8981\u7d20\u3002\u5f00\u53d1AutumnBench\u6d4b\u8bd5\u5957\u4ef6\uff0c\u5305\u542b43\u4e2a\u7f51\u683c\u4e16\u754c\u73af\u5883\u548c129\u4e2a\u4efb\u52a1\uff0c\u6db5\u76d6\u4e09\u4e2a\u4efb\u52a1\u5bb6\u65cf\uff1a\u63a9\u7801\u5e27\u9884\u6d4b\u3001\u89c4\u5212\u548c\u56e0\u679c\u52a8\u6001\u53d8\u5316\u9884\u6d4b\u3002\u6bd4\u8f83\u4e86517\u540d\u4eba\u7c7b\u53c2\u4e0e\u8005\u548c\u4e09\u4e2a\u524d\u6cbf\u6a21\u578b\u7684\u8868\u73b0\u3002", "result": "\u4eba\u7c7b\u5728\u6240\u6709\u4efb\u52a1\u4e0a\u90fd\u4f18\u4e8e\u6a21\u578b\u8868\u73b0\u3002\u8ba1\u7b97\u6269\u5c55\u4ec5\u5728\u67d0\u4e9b\u73af\u5883\u4e2d\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\uff0c\u5728\u5176\u4ed6\u73af\u5883\u4e2d\u65e0\u6548\u3002AutumnBench\u63ed\u793a\u4e86\u4e16\u754c\u6a21\u578b\u5b66\u4e60\u65b9\u9762\u5b58\u5728\u663e\u8457\u63d0\u5347\u7a7a\u95f4\u3002", "conclusion": "WorldTest\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u8bc4\u4f30\u6a21\u677f\u6765\u8bc4\u4f30\u667a\u80fd\u4f53\u5bf9\u73af\u5883\u52a8\u6001\u7684\u5b66\u4e60\u7a0b\u5ea6\uff0cAutumnBench\u6d4b\u8bd5\u5957\u4ef6\u66b4\u9732\u4e86\u5f53\u524d\u4e16\u754c\u6a21\u578b\u5b66\u4e60\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u6539\u8fdb\u65b9\u5411\u3002"}}

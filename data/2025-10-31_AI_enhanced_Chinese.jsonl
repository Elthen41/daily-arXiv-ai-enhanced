{"id": "2510.26730", "categories": ["cs.DC", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.26730", "abs": "https://arxiv.org/abs/2510.26730", "authors": ["Zixu Shen", "Kexin Chu", "Yifan Zhang", "Dawei Xiang", "Runxin Wu", "Wei Zhang"], "title": "ExpertFlow: Adaptive Expert Scheduling and Memory Coordination for Efficient MoE Inference", "comment": "12 pages, 11 figures", "summary": "The expansion of large language models is increasingly limited by the\nconstrained memory capacity of modern GPUs. To mitigate this,\nMixture-of-Experts (MoE) architectures activate only a small portion of\nparameters during inference, significantly lowering both memory demand and\ncomputational overhead. However, conventional MoE inference approaches, which\nselect active experts independently at each layer, often introduce considerable\nlatency because of frequent parameter transfers between host and GPU memory. In\naddition, current cross-layer prediction strategies, which are typically based\non fixed steps, lack adaptability across different hardware platforms and\nworkloads, thereby reducing their robustness and effectiveness.\n  To address these challenges, we present ExpertFlow, a runtime system for MoE\ninference that combines adaptive expert prefetching and cache-aware routing.\nExpertFlow continuously adjusts its prediction horizon for expert activation by\nleveraging runtime statistics such as transfer bandwidth, parameter\ndimensionality, and model feedback signals. Furthermore, it incorporates a\nhybrid cross-layer prediction scheme that fuses pregating information with\nintermediate computational states to anticipate future expert needs. By\nadaptively refining prefetching decisions and aligning them with actual usage\nbehavior, ExpertFlow effectively decreases cache misses and removes latency\ncaused by expert swap-ins. Our evaluation demonstrates that ExpertFlow reduces\nmodel stall time to less than 0.1% of the baseline, highlighting its capability\nto optimize MoE inference under stringent memory constraints.", "AI": {"tldr": "ExpertFlow\u662f\u4e00\u4e2a\u7528\u4e8eMoE\u63a8\u7406\u7684\u8fd0\u884c\u65f6\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u4e13\u5bb6\u9884\u53d6\u548c\u7f13\u5b58\u611f\u77e5\u8def\u7531\u6765\u4f18\u5316\u5185\u5b58\u53d7\u9650\u73af\u5883\u4e0b\u7684\u63a8\u7406\u6027\u80fd\uff0c\u5c06\u6a21\u578b\u505c\u6ede\u65f6\u95f4\u964d\u4f4e\u5230\u57fa\u7ebf\u76840.1%\u4ee5\u4e0b\u3002", "motivation": "\u73b0\u4ee3GPU\u5185\u5b58\u5bb9\u91cf\u6709\u9650\u9650\u5236\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6269\u5c55\uff0c\u4f20\u7edfMoE\u63a8\u7406\u65b9\u6cd5\u7531\u4e8e\u6bcf\u5c42\u72ec\u7acb\u9009\u62e9\u6d3b\u8dc3\u4e13\u5bb6\u5bfc\u81f4\u9891\u7e41\u7684\u53c2\u6570\u4f20\u8f93\uff0c\u5f15\u5165\u663e\u8457\u5ef6\u8fdf\uff0c\u73b0\u6709\u8de8\u5c42\u9884\u6d4b\u7b56\u7565\u7f3a\u4e4f\u5bf9\u4e0d\u540c\u786c\u4ef6\u5e73\u53f0\u548c\u5de5\u4f5c\u8d1f\u8f7d\u7684\u9002\u5e94\u6027\u3002", "method": "\u7ed3\u5408\u81ea\u9002\u5e94\u4e13\u5bb6\u9884\u53d6\u548c\u7f13\u5b58\u611f\u77e5\u8def\u7531\uff0c\u5229\u7528\u4f20\u8f93\u5e26\u5bbd\u3001\u53c2\u6570\u7ef4\u5ea6\u548c\u6a21\u578b\u53cd\u9988\u4fe1\u53f7\u7b49\u8fd0\u884c\u65f6\u7edf\u8ba1\u4fe1\u606f\u6301\u7eed\u8c03\u6574\u4e13\u5bb6\u6fc0\u6d3b\u9884\u6d4b\u8303\u56f4\uff0c\u91c7\u7528\u6df7\u5408\u8de8\u5c42\u9884\u6d4b\u65b9\u6848\u878d\u5408\u9884\u95e8\u63a7\u4fe1\u606f\u548c\u4e2d\u95f4\u8ba1\u7b97\u72b6\u6001\u6765\u9884\u6d4b\u672a\u6765\u4e13\u5bb6\u9700\u6c42\u3002", "result": "\u8bc4\u4f30\u663e\u793aExpertFlow\u5c06\u6a21\u578b\u505c\u6ede\u65f6\u95f4\u964d\u4f4e\u5230\u57fa\u7ebf\u76840.1%\u4ee5\u4e0b\uff0c\u6709\u6548\u51cf\u5c11\u7f13\u5b58\u672a\u547d\u4e2d\u548c\u4e13\u5bb6\u4ea4\u6362\u5f15\u5165\u7684\u5ef6\u8fdf\u3002", "conclusion": "ExpertFlow\u80fd\u591f\u5728\u4e25\u683c\u5185\u5b58\u7ea6\u675f\u4e0b\u4f18\u5316MoE\u63a8\u7406\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9884\u53d6\u51b3\u7b56\u4e0e\u5b9e\u9645\u4f7f\u7528\u884c\u4e3a\u5bf9\u9f50\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002"}}
{"id": "2510.25775", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25775", "abs": "https://arxiv.org/abs/2510.25775", "authors": ["Francesco Spinnato"], "title": "Towards Piece-by-Piece Explanations for Chess Positions with SHAP", "comment": null, "summary": "Contemporary chess engines offer precise yet opaque evaluations, typically\nexpressed as centipawn scores. While effective for decision-making, these\noutputs obscure the underlying contributions of individual pieces or patterns.\nIn this paper, we explore adapting SHAP (SHapley Additive exPlanations) to the\ndomain of chess analysis, aiming to attribute a chess engines evaluation to\nspecific pieces on the board. By treating pieces as features and systematically\nablating them, we compute additive, per-piece contributions that explain the\nengines output in a locally faithful and human-interpretable manner. This\nmethod draws inspiration from classical chess pedagogy, where players assess\npositions by mentally removing pieces, and grounds it in modern explainable AI\ntechniques. Our approach opens new possibilities for visualization, human\ntraining, and engine comparison. We release accompanying code and data to\nfoster future research in interpretable chess AI.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u5c06SHAP\uff08SHapley Additive exPlanations\uff09\u65b9\u6cd5\u5e94\u7528\u4e8e\u56fd\u9645\u8c61\u68cb\u5206\u6790\uff0c\u65e8\u5728\u5c06\u8c61\u68cb\u5f15\u64ce\u7684\u8bc4\u4f30\u5f52\u56e0\u4e8e\u68cb\u76d8\u4e0a\u7684\u7279\u5b9a\u68cb\u5b50\uff0c\u4ece\u800c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u68cb\u5b50\u8d21\u732e\u5206\u6790\u3002", "motivation": "\u5f53\u524d\u8c61\u68cb\u5f15\u64ce\u63d0\u4f9b\u7cbe\u786e\u4f46\u4e0d\u900f\u660e\u7684\u8bc4\u4f30\uff08\u901a\u5e38\u4ee5\u767e\u5206\u5175\u5206\u6570\u8868\u793a\uff09\uff0c\u8fd9\u4e9b\u8f93\u51fa\u63a9\u76d6\u4e86\u5355\u4e2a\u68cb\u5b50\u6216\u6a21\u5f0f\u7684\u6f5c\u5728\u8d21\u732e\u3002\u4f5c\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u89e3\u91ca\u5f15\u64ce\u8bc4\u4f30\u7684\u65b9\u6cd5\uff0c\u4f7f\u5176\u5bf9\u4eba\u7c7b\u66f4\u6613\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u5c06\u68cb\u5b50\u89c6\u4e3a\u7279\u5f81\u5e76\u7cfb\u7edf\u5730\u6d88\u878d\u5b83\u4eec\uff0c\u8ba1\u7b97\u52a0\u6027\u7684\u3001\u6bcf\u4e2a\u68cb\u5b50\u7684\u8d21\u732e\uff0c\u4ee5\u5c40\u90e8\u5fe0\u5b9e\u4e14\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u65b9\u5f0f\u89e3\u91ca\u5f15\u64ce\u7684\u8f93\u51fa\u3002\u8be5\u65b9\u6cd5\u501f\u9274\u4e86\u53e4\u5178\u8c61\u68cb\u6559\u5b66\u6cd5\uff08\u73a9\u5bb6\u901a\u8fc7\u5fc3\u7406\u79fb\u9664\u68cb\u5b50\u6765\u8bc4\u4f30\u5c40\u9762\uff09\uff0c\u5e76\u5c06\u5176\u4e0e\u73b0\u4ee3\u53ef\u89e3\u91caAI\u6280\u672f\u76f8\u7ed3\u5408\u3002", "result": "\u8be5\u65b9\u6cd5\u4e3a\u53ef\u89c6\u5316\u3001\u4eba\u7c7b\u8bad\u7ec3\u548c\u5f15\u64ce\u6bd4\u8f83\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002\u4f5c\u8005\u53d1\u5e03\u4e86\u914d\u5957\u4ee3\u7801\u548c\u6570\u636e\u4ee5\u4fc3\u8fdb\u53ef\u89e3\u91ca\u8c61\u68cbAI\u7684\u672a\u6765\u7814\u7a76\u3002", "conclusion": "SHAP\u65b9\u6cd5\u6210\u529f\u5e94\u7528\u4e8e\u56fd\u9645\u8c61\u68cb\u5206\u6790\uff0c\u80fd\u591f\u63d0\u4f9b\u5bf9\u5f15\u64ce\u8bc4\u4f30\u7684\u68cb\u5b50\u7ea7\u89e3\u91ca\uff0c\u5c06\u53e4\u5178\u8c61\u68cb\u5206\u6790\u65b9\u6cd5\u4e0e\u73b0\u4ee3AI\u89e3\u91ca\u6280\u672f\u76f8\u7ed3\u5408\uff0c\u63a8\u52a8\u4e86\u53ef\u89e3\u91ca\u8c61\u68cbAI\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.25878", "categories": ["cs.CR", "cs.DC", "cs.GT"], "pdf": "https://arxiv.org/pdf/2510.25878", "abs": "https://arxiv.org/abs/2510.25878", "authors": ["Pavel Hub\u00e1\u010dek", "Jan V\u00e1clavek", "Michelle Yeo"], "title": "Foundations of Fiat-Denominated Loans Collateralized by Cryptocurrencies", "comment": null, "summary": "The rising importance of cryptocurrencies as financial assets pushed their\napplicability from an object of speculation closer to standard financial\ninstruments such as loans. In this work, we initiate the study of secure\nprotocols that enable fiat-denominated loans collateralized by cryptocurrencies\nsuch as Bitcoin. We provide limited-custodial protocols for such loans relying\nonly on trusted arbitration and provide their game-theoretical analysis. We\nalso highlight various interesting directions for future research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4ee5\u52a0\u5bc6\u8d27\u5e01\uff08\u5982\u6bd4\u7279\u5e01\uff09\u4e3a\u62b5\u62bc\u7684\u6cd5\u5e01\u8d37\u6b3e\u5b89\u5168\u534f\u8bae\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u53ef\u4fe1\u4ef2\u88c1\u7684\u6709\u9650\u6258\u7ba1\u534f\u8bae\uff0c\u5e76\u8fdb\u884c\u4e86\u535a\u5f08\u8bba\u5206\u6790\u3002", "motivation": "\u968f\u7740\u52a0\u5bc6\u8d27\u5e01\u4f5c\u4e3a\u91d1\u878d\u8d44\u4ea7\u7684\u91cd\u8981\u6027\u65e5\u76ca\u4e0a\u5347\uff0c\u5176\u5e94\u7528\u8303\u56f4\u4ece\u6295\u673a\u5bf9\u8c61\u6269\u5c55\u5230\u66f4\u63a5\u8fd1\u6807\u51c6\u91d1\u878d\u5de5\u5177\uff08\u5982\u8d37\u6b3e\uff09\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u652f\u6301\u4ee5\u52a0\u5bc6\u8d27\u5e01\u4e3a\u62b5\u62bc\u7684\u6cd5\u5e01\u8d37\u6b3e\u7684\u5b89\u5168\u534f\u8bae\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u53ef\u4fe1\u4ef2\u88c1\u7684\u6709\u9650\u6258\u7ba1\u534f\u8bae\uff0c\u4ec5\u4f9d\u8d56\u53ef\u4fe1\u4ef2\u88c1\u6765\u786e\u4fdd\u8d37\u6b3e\u5b89\u5168\uff0c\u5e76\u5bf9\u534f\u8bae\u8fdb\u884c\u4e86\u535a\u5f08\u8bba\u5206\u6790\u3002", "result": "\u5f00\u53d1\u4e86\u652f\u6301\u52a0\u5bc6\u8d27\u5e01\u62b5\u62bc\u8d37\u6b3e\u7684\u5b89\u5168\u534f\u8bae\u6846\u67b6\uff0c\u901a\u8fc7\u6709\u9650\u6258\u7ba1\u548c\u53ef\u4fe1\u4ef2\u88c1\u673a\u5236\u786e\u4fdd\u4ea4\u6613\u5b89\u5168\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u52a0\u5bc6\u8d27\u5e01\u62b5\u62bc\u8d37\u6b3e\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u5b89\u5168\u534f\u8bae\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u591a\u4e2a\u6709\u8da3\u65b9\u5411\u3002"}}
{"id": "2510.25856", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.25856", "abs": "https://arxiv.org/abs/2510.25856", "authors": ["Brooke Elizabeth Kidmose", "Andreas Brasen Kidmose", "Cliff C. Zou"], "title": "A Critical Roadmap to Driver Authentication via CAN Bus: Dataset Review, Introduction of the Kidmose CANid Dataset (KCID), and Proof of Concept", "comment": null, "summary": "Modern vehicles remain vulnerable to unauthorized use and theft despite\ntraditional security measures including immobilizers and keyless entry systems.\nCriminals exploit vulnerabilities in Controller Area Network (CAN) bus systems\nto bypass authentication mechanisms, while social media trends have expanded\nauto theft to include recreational joyriding by underage drivers. Driver\nauthentication via CAN bus data offers a promising additional layer of\ndefense-in-depth protection, but existing open-access driver fingerprinting\ndatasets suffer from critical limitations including reliance on decoded\ndiagnostic data rather than raw CAN traffic, artificial fixed-route\nexperimental designs, insufficient sampling rates, and lack of demographic\ninformation.\n  This paper provides a comprehensive review of existing open-access driver\nfingerprinting datasets, analyzing their strengths and limitations to guide\npractitioners in dataset selection. We introduce the Kidmose CANid Dataset\n(KCID), which addresses these fundamental shortcomings by providing raw CAN bus\ndata from 16 drivers across four vehicles, including essential demographic\ninformation and both daily driving and controlled fixed-route data. Beyond\ndataset contributions, we present a driver authentication anti-theft framework\nand implement a proof-of-concept prototype on a single-board computer. Through\nlive road trials with an unaltered passenger vehicle, we demonstrate the\npractical feasibility of CAN bus-based driver authentication anti-theft\nsystems. Finally, we explore diverse applications of KCID beyond driver\nauthentication, including driver profiling for insurance and safety\nassessments, mechanical anomaly detection, young driver monitoring, and\nimpaired driving detection. This work provides researchers with both the data\nand methodological foundation necessary to develop robust, deployable driver\nauthentication systems...", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Kidmose CANid\u6570\u636e\u96c6\uff08KCID\uff09\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u9a7e\u9a76\u5458\u6307\u7eb9\u8bc6\u522b\u6570\u636e\u96c6\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u539f\u59cbCAN\u603b\u7ebf\u6570\u636e\u3001\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8eCAN\u603b\u7ebf\u7684\u9a7e\u9a76\u5458\u8ba4\u8bc1\u9632\u76d7\u7cfb\u7edf\u539f\u578b\u3002", "motivation": "\u73b0\u4ee3\u8f66\u8f86\u867d\u7136\u914d\u5907\u4e86\u4f20\u7edf\u5b89\u5168\u63aa\u65bd\uff0c\u4f46\u4ecd\u9762\u4e34\u672a\u7ecf\u6388\u6743\u4f7f\u7528\u548c\u76d7\u7a83\u7684\u98ce\u9669\u3002\u72af\u7f6a\u5206\u5b50\u5229\u7528CAN\u603b\u7ebf\u7cfb\u7edf\u7684\u6f0f\u6d1e\u7ed5\u8fc7\u8ba4\u8bc1\u673a\u5236\uff0c\u793e\u4ea4\u5a92\u4f53\u8d8b\u52bf\u4e5f\u6269\u5927\u4e86\u672a\u6210\u5e74\u4eba\u5077\u8f66\u515c\u98ce\u7684\u95ee\u9898\u3002\u73b0\u6709\u9a7e\u9a76\u5458\u6307\u7eb9\u8bc6\u522b\u6570\u636e\u96c6\u5b58\u5728\u4e25\u91cd\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u597d\u7684\u6570\u636e\u96c6\u6765\u652f\u6301\u9a7e\u9a76\u5458\u8ba4\u8bc1\u9632\u76d7\u7cfb\u7edf\u7684\u5f00\u53d1\u3002", "method": "\u5f15\u5165Kidmose CANid\u6570\u636e\u96c6\uff08KCID\uff09\uff0c\u5305\u542b16\u540d\u9a7e\u9a76\u5458\u57284\u8f86\u8f66\u4e0a\u7684\u539f\u59cbCAN\u603b\u7ebf\u6570\u636e\uff0c\u63d0\u4f9b\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u548c\u65e5\u5e38\u9a7e\u9a76\u53ca\u56fa\u5b9a\u8def\u7ebf\u6570\u636e\u3002\u5f00\u53d1\u9a7e\u9a76\u5458\u8ba4\u8bc1\u9632\u76d7\u6846\u67b6\uff0c\u5e76\u5728\u5355\u677f\u8ba1\u7b97\u673a\u4e0a\u5b9e\u73b0\u6982\u5ff5\u9a8c\u8bc1\u539f\u578b\uff0c\u901a\u8fc7\u5b9e\u9645\u9053\u8def\u8bd5\u9a8c\u9a8c\u8bc1\u7cfb\u7edf\u53ef\u884c\u6027\u3002", "result": "\u901a\u8fc7\u672a\u6539\u88c5\u4e58\u7528\u8f66\u7684\u5b9e\u9645\u9053\u8def\u8bd5\u9a8c\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8eCAN\u603b\u7ebf\u7684\u9a7e\u9a76\u5458\u8ba4\u8bc1\u9632\u76d7\u7cfb\u7edf\u7684\u5b9e\u9645\u53ef\u884c\u6027\u3002KCID\u6570\u636e\u96c6\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u5f00\u53d1\u7a33\u5065\u3001\u53ef\u90e8\u7f72\u7684\u9a7e\u9a76\u5458\u8ba4\u8bc1\u7cfb\u7edf\u6240\u9700\u7684\u6570\u636e\u548c\u65b9\u6cd5\u57fa\u7840\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u6539\u8fdb\u7684\u6570\u636e\u96c6\uff0c\u8fd8\u5c55\u793a\u4e86\u57fa\u4e8eCAN\u603b\u7ebf\u7684\u9a7e\u9a76\u5458\u8ba4\u8bc1\u9632\u76d7\u7cfb\u7edf\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u4e3a\u9a7e\u9a76\u5458\u5206\u6790\u3001\u673a\u68b0\u5f02\u5e38\u68c0\u6d4b\u3001\u5e74\u8f7b\u9a7e\u9a76\u5458\u76d1\u63a7\u548c\u53d7\u635f\u9a7e\u9a76\u68c0\u6d4b\u7b49\u591a\u6837\u5316\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.25883", "categories": ["cs.AI", "cs.IT", "math.IT", "I.2.0; I.2.6; G.3"], "pdf": "https://arxiv.org/pdf/2510.25883", "abs": "https://arxiv.org/abs/2510.25883", "authors": ["Christian Dittrich", "Jennifer Flygare Kinne"], "title": "The Information-Theoretic Imperative: Compression and the Epistemic Foundations of Intelligence", "comment": "41 pages, 2 tables, 3 appendices. Submitted to arXiv for open access", "summary": "Existing frameworks converge on the centrality of compression to intelligence\nbut leave underspecified why this process enforces the discovery of causal\nstructure rather than superficial statistical patterns. We introduce a\ntwo-level framework to address this gap. The Information-Theoretic Imperative\n(ITI) establishes that any system persisting in uncertain environments must\nminimize epistemic entropy through predictive compression: this is the\nevolutionary \"why\" linking survival pressure to information-processing demands.\nThe Compression Efficiency Principle (CEP) specifies how efficient compression\nmechanically selects for generative, causal models through\nexception-accumulation dynamics, making reality alignment a consequence rather\nthan a contingent achievement. Together, ITI and CEP define a causal chain:\nfrom survival pressure to prediction necessity, compression requirement,\nefficiency optimization, generative structure discovery, and ultimately reality\nalignment. Each link follows from physical, information-theoretic, or\nevolutionary constraints, implying that intelligence is the mechanically\nnecessary outcome of persistence in structured environments. This framework\nyields empirically testable predictions: compression efficiency, measured as\napproach to the rate-distortion frontier, correlates with out-of-distribution\ngeneralization; exception-accumulation rates differentiate causal from\ncorrelational models; hierarchical systems exhibit increasing efficiency across\nabstraction layers; and biological systems demonstrate metabolic costs that\ntrack representational complexity. ITI and CEP thereby provide a unified\naccount of convergence across biological, artificial, and multi-scale systems,\naddressing the epistemic and functional dimensions of intelligence without\ninvoking assumptions about consciousness or subjective experience.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e24\u5c42\u6b21\u6846\u67b6\u6765\u89e3\u91ca\u4e3a\u4ec0\u4e48\u538b\u7f29\u8fc7\u7a0b\u4f1a\u5f3a\u5236\u53d1\u73b0\u56e0\u679c\u7ed3\u6784\u800c\u975e\u8868\u9762\u7edf\u8ba1\u6a21\u5f0f\u3002\u4fe1\u606f\u8bba\u5fc5\u8981\u6027(ITI)\u5efa\u7acb\u4e86\u751f\u5b58\u538b\u529b\u4e0e\u4fe1\u606f\u5904\u7406\u9700\u6c42\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u538b\u7f29\u6548\u7387\u539f\u5219(CEP)\u89e3\u91ca\u4e86\u9ad8\u6548\u538b\u7f29\u5982\u4f55\u901a\u8fc7\u5f02\u5e38\u79ef\u7d2f\u52a8\u6001\u9009\u62e9\u751f\u6210\u6027\u56e0\u679c\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u6846\u67b6\u867d\u7136\u8ba4\u540c\u538b\u7f29\u5bf9\u667a\u80fd\u7684\u6838\u5fc3\u4f5c\u7528\uff0c\u4f46\u672a\u80fd\u5177\u4f53\u8bf4\u660e\u4e3a\u4ec0\u4e48\u8fd9\u4e2a\u8fc7\u7a0b\u4f1a\u5f3a\u5236\u53d1\u73b0\u56e0\u679c\u7ed3\u6784\u800c\u975e\u8868\u9762\u7edf\u8ba1\u6a21\u5f0f\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7406\u8bba\u7a7a\u767d\u3002", "method": "\u5f15\u5165\u4e24\u5c42\u6b21\u6846\u67b6\uff1a\u4fe1\u606f\u8bba\u5fc5\u8981\u6027(ITI)\u548c\u538b\u7f29\u6548\u7387\u539f\u5219(CEP)\u3002ITI\u4ece\u7269\u7406\u3001\u4fe1\u606f\u8bba\u548c\u8fdb\u5316\u7ea6\u675f\u89d2\u5ea6\u5efa\u7acb\u4ece\u751f\u5b58\u538b\u529b\u5230\u9884\u6d4b\u5fc5\u8981\u6027\u3001\u538b\u7f29\u9700\u6c42\u3001\u6548\u7387\u4f18\u5316\u7684\u56e0\u679c\u94fe\uff1bCEP\u901a\u8fc7\u5f02\u5e38\u79ef\u7d2f\u52a8\u6001\u89e3\u91ca\u9ad8\u6548\u538b\u7f29\u5982\u4f55\u9009\u62e9\u751f\u6210\u6027\u56e0\u679c\u6a21\u578b\u3002", "result": "\u8be5\u6846\u67b6\u4ea7\u751f\u4e86\u53ef\u5b9e\u8bc1\u68c0\u9a8c\u7684\u9884\u6d4b\uff1a\u538b\u7f29\u6548\u7387\u4e0e\u5206\u5e03\u5916\u6cdb\u5316\u76f8\u5173\uff1b\u5f02\u5e38\u79ef\u7d2f\u7387\u533a\u5206\u56e0\u679c\u6a21\u578b\u4e0e\u76f8\u5173\u6a21\u578b\uff1b\u5206\u5c42\u7cfb\u7edf\u5728\u62bd\u8c61\u5c42\u95f4\u663e\u793a\u9012\u589e\u6548\u7387\uff1b\u751f\u7269\u7cfb\u7edf\u4ee3\u8c22\u6210\u672c\u8ddf\u8e2a\u8868\u5f81\u590d\u6742\u6027\u3002", "conclusion": "ITI\u548cCEP\u4e3a\u751f\u7269\u3001\u4eba\u5de5\u548c\u591a\u5c3a\u5ea6\u7cfb\u7edf\u4e2d\u7684\u6536\u655b\u63d0\u4f9b\u4e86\u7edf\u4e00\u89e3\u91ca\uff0c\u89e3\u51b3\u4e86\u667a\u80fd\u7684\u8ba4\u77e5\u548c\u529f\u80fd\u7ef4\u5ea6\uff0c\u65e0\u9700\u5f15\u5165\u5173\u4e8e\u610f\u8bc6\u6216\u4e3b\u89c2\u7ecf\u9a8c\u7684\u5047\u8bbe\u3002"}}
{"id": "2510.25884", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25884", "abs": "https://arxiv.org/abs/2510.25884", "authors": ["Eit\u00e1n Sprejer", "Fernando Avalos", "Augusto Bernardi", "Jose Pedro Brito de Azevedo Faustino", "Jacob Haimes", "Narmeen Fatimah Oozeer"], "title": "Approximating Human Preferences Using a Multi-Judge Learned System", "comment": null, "summary": "Aligning LLM-based judges with human preferences is a significant challenge,\nas they are difficult to calibrate and often suffer from rubric sensitivity,\nbias, and instability. Overcoming this challenge advances key applications,\nsuch as creating reliable reward models for Reinforcement Learning from Human\nFeedback (RLHF) and building effective routing systems that select the\nbest-suited model for a given user query. In this work, we propose a framework\nfor modeling diverse, persona-based preferences by learning to aggregate\noutputs from multiple rubric-conditioned judges. We investigate the performance\nof this approach against naive baselines and assess its robustness through case\nstudies on both human and LLM-judges biases. Our primary contributions include\na persona-based method for synthesizing preference labels at scale and two\ndistinct implementations of our aggregator: Generalized Additive Model (GAM)\nand a Multi-Layer Perceptron (MLP).", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u89d2\u8272\u7684\u504f\u597d\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u5408\u591a\u4e2a\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u4f30\u8005\u8f93\u51fa\u6765\u5bf9\u9f50LLM\u8bc4\u4f30\u8005\u4e0e\u4eba\u7c7b\u504f\u597d\uff0c\u89e3\u51b3\u6821\u51c6\u56f0\u96be\u3001\u8bc4\u5206\u6807\u51c6\u654f\u611f\u6027\u3001\u504f\u89c1\u548c\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u5bf9\u9f50\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u8005\u4e0e\u4eba\u7c7b\u504f\u597d\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\uff0c\u56e0\u4e3a\u5b83\u4eec\u96be\u4ee5\u6821\u51c6\u4e14\u7ecf\u5e38\u5b58\u5728\u8bc4\u5206\u6807\u51c6\u654f\u611f\u6027\u3001\u504f\u89c1\u548c\u4e0d\u7a33\u5b9a\u6027\u3002\u514b\u670d\u8fd9\u4e00\u6311\u6218\u53ef\u4ee5\u63a8\u8fdb\u5173\u952e\u5e94\u7528\uff0c\u5982\u4e3aRLHF\u521b\u5efa\u53ef\u9760\u7684\u5956\u52b1\u6a21\u578b\u548c\u6784\u5efa\u6709\u6548\u7684\u8def\u7531\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u89d2\u8272\u7684\u504f\u597d\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u5408\u591a\u4e2a\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u4f30\u8005\u8f93\u51fa\u6765\u5b66\u4e60\u504f\u597d\u3002\u5305\u62ec\u57fa\u4e8e\u89d2\u8272\u7684\u65b9\u6cd5\u5927\u89c4\u6a21\u5408\u6210\u504f\u597d\u6807\u7b7e\uff0c\u4ee5\u53ca\u4e24\u79cd\u805a\u5408\u5668\u5b9e\u73b0\uff1a\u5e7f\u4e49\u52a0\u6027\u6a21\u578b(GAM)\u548c\u591a\u5c42\u611f\u77e5\u5668(MLP)\u3002", "result": "\u8bc4\u4f30\u4e86\u8be5\u65b9\u6cd5\u76f8\u5bf9\u4e8e\u7b80\u5355\u57fa\u7ebf\u7684\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\u4e86\u5176\u5bf9\u4eba\u7c7b\u548cLLM\u8bc4\u4f30\u8005\u504f\u89c1\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5efa\u6a21\u591a\u6837\u5316\u7684\u57fa\u4e8e\u89d2\u8272\u7684\u504f\u597d\uff0c\u4e3a\u5bf9\u9f50LLM\u8bc4\u4f30\u8005\u4e0e\u4eba\u7c7b\u504f\u597d\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.25908", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25908", "abs": "https://arxiv.org/abs/2510.25908", "authors": ["Emily Herron", "Junqi Yin", "Feiyi Wang"], "title": "SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications", "comment": "Preprint Submitted to ACM Transactions on AI for Science (TAIS)", "summary": "Large language models (LLMs) have demonstrated transformative potential in\nscientific research, yet their deployment in high-stakes contexts raises\nsignificant trustworthiness concerns. Here, we introduce SciTrust 2.0, a\ncomprehensive framework for evaluating LLM trustworthiness in scientific\napplications across four dimensions: truthfulness, adversarial robustness,\nscientific safety, and scientific ethics. Our framework incorporates novel,\nopen-ended truthfulness benchmarks developed through a verified\nreflection-tuning pipeline and expert validation, alongside a novel ethics\nbenchmark for scientific research contexts covering eight subcategories\nincluding dual-use research and bias. We evaluated seven prominent LLMs,\nincluding four science-specialized models and three general-purpose industry\nmodels, using multiple evaluation metrics including accuracy, semantic\nsimilarity measures, and LLM-based scoring. General-purpose industry models\noverall outperformed science-specialized models across each trustworthiness\ndimension, with GPT-o4-mini demonstrating superior performance in truthfulness\nassessments and adversarial robustness. Science-specialized models showed\nsignificant deficiencies in logical and ethical reasoning capabilities, along\nwith concerning vulnerabilities in safety evaluations, particularly in\nhigh-risk domains such as biosecurity and chemical weapons. By open-sourcing\nour framework, we provide a foundation for developing more trustworthy AI\nsystems and advancing research on model safety and ethics in scientific\ncontexts.", "AI": {"tldr": "SciTrust 2.0\u662f\u4e00\u4e2a\u8bc4\u4f30\u79d1\u5b66\u5e94\u7528\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4fe1\u5ea6\u7684\u7efc\u5408\u6846\u67b6\uff0c\u6db5\u76d6\u771f\u5b9e\u6027\u3001\u5bf9\u6297\u9c81\u68d2\u6027\u3001\u79d1\u5b66\u5b89\u5168\u548c\u79d1\u5b66\u4f26\u7406\u56db\u4e2a\u7ef4\u5ea6\u3002\u8bc4\u4f30\u663e\u793a\u901a\u7528\u884c\u4e1a\u6a21\u578b\u5728\u5404\u65b9\u9762\u4f18\u4e8e\u79d1\u5b66\u4e13\u7528\u6a21\u578b\uff0c\u540e\u8005\u5728\u903b\u8f91\u548c\u4f26\u7406\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u7f3a\u9677\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u5c55\u73b0\u51fa\u53d8\u9769\u6f5c\u529b\uff0c\u4f46\u5728\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u5f15\u53d1\u4e86\u53ef\u4fe1\u5ea6\u62c5\u5fe7\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u6765\u786e\u4fdd\u5176\u53ef\u9760\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b\u65b0\u9896\u5f00\u653e\u5f0f\u771f\u5b9e\u6027\u57fa\u51c6\u548c\u79d1\u5b66\u4f26\u7406\u57fa\u51c6\u7684\u7efc\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u9a8c\u8bc1\u53cd\u601d\u8c03\u4f18\u6d41\u7a0b\u548c\u4e13\u5bb6\u9a8c\u8bc1\u6784\u5efa\uff0c\u4f7f\u7528\u51c6\u786e\u6027\u3001\u8bed\u4e49\u76f8\u4f3c\u5ea6\u548c\u57fa\u4e8eLLM\u7684\u8bc4\u5206\u7b49\u591a\u79cd\u6307\u6807\u8bc4\u4f307\u4e2a\u4e3b\u6d41LLM\u3002", "result": "\u901a\u7528\u884c\u4e1a\u6a21\u578b\u5728\u6240\u6709\u53ef\u4fe1\u5ea6\u7ef4\u5ea6\u4e0a\u5747\u4f18\u4e8e\u79d1\u5b66\u4e13\u7528\u6a21\u578b\uff0cGPT-4-mini\u5728\u771f\u5b9e\u6027\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002\u79d1\u5b66\u4e13\u7528\u6a21\u578b\u5728\u903b\u8f91\u548c\u4f26\u7406\u63a8\u7406\u80fd\u529b\u4e0a\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u5728\u751f\u7269\u5b89\u5168\u548c\u5316\u5b66\u6b66\u5668\u7b49\u9ad8\u5371\u9886\u57df\u7684\u5b89\u5168\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u4ee4\u4eba\u62c5\u5fe7\u7684\u8106\u5f31\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f00\u6e90\u8be5\u6846\u67b6\uff0c\u4e3a\u5f00\u53d1\u66f4\u53ef\u4fe1\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5e76\u63a8\u8fdb\u4e86\u79d1\u5b66\u80cc\u666f\u4e0b\u6a21\u578b\u5b89\u5168\u4e0e\u4f26\u7406\u7684\u7814\u7a76\u3002"}}
{"id": "2510.25932", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.25932", "abs": "https://arxiv.org/abs/2510.25932", "authors": ["Soufiane Essahli", "Oussama Sarsar", "Imane Fouad", "Anas Motii", "Ahmed Bentajer"], "title": "FakeZero: Real-Time, Privacy-Preserving Misinformation Detection for Facebook and X", "comment": "Accepted for publication in the Proceedings of the 24th IEEE\n  International Conference on Trust, Security and Privacy in Computing and\n  Communications (TrustCom 2025) Privacy track, 11 pages, 8 figures", "summary": "Social platforms distribute information at unprecedented speed, which in turn\naccelerates the spread of misinformation and threatens public discourse. We\npresent FakeZero, a fully client-side, cross-platform browser extension that\nflags unreliable posts on Facebook and X (formerly Twitter) while the user\nscrolls. All computation, DOM scraping, tokenisation, Transformer inference,\nand UI rendering run locally through the Chromium messaging API, so no personal\ndata leaves the device.FakeZero employs a three-stage training curriculum:\nbaseline fine-tuning and domain-adaptive training enhanced with focal loss,\nadversarial augmentation, and post-training quantisation. Evaluated on a\ndataset of 239,000 posts, the DistilBERT-Quant model (67.6 MB) reaches 97.1%\nmacro-F1, 97.4% accuracy, and an AUROC of 0.996, with a median latency of\napproximately 103 ms on a commodity laptop. A memory-efficient TinyBERT-Quant\nvariant retains 95.7% macro-F1 and 96.1% accuracy while shrinking the model to\n14.7 MB and lowering latency to approximately 40 ms, showing that high-quality\nfake-news detection is feasible under tight resource budgets with only modest\nperformance loss.By providing inline credibility cues, the extension can serve\nas a valuable tool for policymakers seeking to curb the spread of\nmisinformation across social networks. With user consent, FakeZero also opens\nthe door for researchers to collect large-scale datasets of fake news in the\nwild, enabling deeper analysis and the development of more robust detection\ntechniques.", "AI": {"tldr": "FakeZero\u662f\u4e00\u4e2a\u5b8c\u5168\u5ba2\u6237\u7aef\u3001\u8de8\u5e73\u53f0\u7684\u6d4f\u89c8\u5668\u6269\u5c55\uff0c\u80fd\u591f\u5728\u7528\u6237\u6eda\u52a8\u65f6\u5b9e\u65f6\u6807\u8bb0Facebook\u548cX\u5e73\u53f0\u4e0a\u7684\u4e0d\u53ef\u9760\u5e16\u5b50\u3002\u6240\u6709\u8ba1\u7b97\u90fd\u5728\u672c\u5730\u8fdb\u884c\uff0c\u4e0d\u6cc4\u9732\u4e2a\u4eba\u6570\u636e\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4ee5\u7a7a\u524d\u901f\u5ea6\u4f20\u64ad\u4fe1\u606f\uff0c\u52a0\u901f\u4e86\u9519\u8bef\u4fe1\u606f\u7684\u4f20\u64ad\u5e76\u5a01\u80c1\u516c\u5171\u8bdd\u8bed\u3002\u9700\u8981\u4e00\u79cd\u4fdd\u62a4\u9690\u79c1\u7684\u89e3\u51b3\u65b9\u6848\u6765\u8bc6\u522b\u4e0d\u53ef\u9760\u5185\u5bb9\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u8bfe\u7a0b\uff1a\u57fa\u7ebf\u5fae\u8c03\u3001\u57df\u81ea\u9002\u5e94\u8bad\u7ec3\uff08\u589e\u5f3a\u7126\u70b9\u635f\u5931\u3001\u5bf9\u6297\u589e\u5f3a\u548c\u540e\u8bad\u7ec3\u91cf\u5316\uff09\u3002\u4f7f\u7528DistilBERT-Quant\u548cTinyBERT-Quant\u6a21\u578b\u5728\u672c\u5730\u8fd0\u884c\u3002", "result": "\u5728239,000\u6761\u5e16\u5b50\u7684\u6570\u636e\u96c6\u4e0a\uff0cDistilBERT-Quant\u6a21\u578b\uff0867.6 MB\uff09\u8fbe\u523097.1%\u5b8fF1\u300197.4%\u51c6\u786e\u7387\u548c0.996 AUROC\uff0c\u4e2d\u4f4d\u5ef6\u8fdf\u7ea6103\u6beb\u79d2\u3002TinyBERT-Quant\u53d8\u4f53\uff0814.7 MB\uff09\u4fdd\u630195.7%\u5b8fF1\u548c96.1%\u51c6\u786e\u7387\uff0c\u5ef6\u8fdf\u964d\u81f3\u7ea640\u6beb\u79d2\u3002", "conclusion": "FakeZero\u8bc1\u660e\u5728\u4e25\u683c\u8d44\u6e90\u9884\u7b97\u4e0b\u5b9e\u73b0\u9ad8\u8d28\u91cf\u5047\u65b0\u95fb\u68c0\u6d4b\u662f\u53ef\u884c\u7684\uff0c\u53ef\u4f5c\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u904f\u5236\u9519\u8bef\u4fe1\u606f\u4f20\u64ad\u7684\u6709\u4ef7\u503c\u5de5\u5177\uff0c\u5e76\u4e3a\u7814\u7a76\u4eba\u5458\u6536\u96c6\u5927\u89c4\u6a21\u5047\u65b0\u95fb\u6570\u636e\u96c6\u63d0\u4f9b\u53ef\u80fd\u3002"}}
{"id": "2510.25939", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.25939", "abs": "https://arxiv.org/abs/2510.25939", "authors": ["Robert A. Bridges", "Thomas R. Mitchell", "Mauricio Mu\u00f1oz", "Ted Henriksson"], "title": "SoK: Honeypots & LLMs, More Than the Sum of Their Parts?", "comment": "Systemization of Knowledge", "summary": "The advent of Large Language Models (LLMs) promised to resolve the\nlong-standing paradox in honeypot design: achieving high-fidelity deception\nwith low operational risk. However, despite a flurry of research since late\n2022, progress has been incremental, and the field lacks a cohesive\nunderstanding of the emerging architectural patterns, core challenges, and\nevaluation paradigms. To fill this gap, this Systematization of Knowledge (SoK)\npaper provides the first comprehensive overview of this new domain. We survey\nand systematize three critical, intersecting research areas: first, we provide\na taxonomy of honeypot detection vectors, structuring the core problems that\nLLM-based realism must solve; second, we synthesize the emerging literature on\nLLM-honeypots, identifying a canonical architecture and key evaluation trends;\nand third, we chart the evolutionary path of honeypot log analysis, from simple\ndata reduction to automated intelligence generation. We synthesize these\nfindings into a forward-looking research roadmap, arguing that the true\npotential of this technology lies in creating autonomous, self-improving\ndeception systems to counter the emerging threat of intelligent, automated\nattackers.", "AI": {"tldr": "\u672c\u6587\u5bf9\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u871c\u7f50\u7814\u7a76\u8fdb\u884c\u4e86\u9996\u6b21\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u871c\u7f50\u68c0\u6d4b\u5411\u91cf\u7684\u5206\u7c7b\u6cd5\uff0c\u603b\u7ed3\u4e86LLM\u871c\u7f50\u7684\u5178\u578b\u67b6\u6784\u548c\u8bc4\u4f30\u8d8b\u52bf\uff0c\u5e76\u5c55\u671b\u4e86\u81ea\u4e3b\u3001\u81ea\u6539\u8fdb\u6b3a\u9a97\u7cfb\u7edf\u7684\u672a\u6765\u53d1\u5c55\u8def\u5f84\u3002", "motivation": "\u89e3\u51b3\u871c\u7f50\u8bbe\u8ba1\u4e2d\u957f\u671f\u5b58\u5728\u7684\u77db\u76fe\uff1a\u5b9e\u73b0\u9ad8\u4fdd\u771f\u6b3a\u9a97\u4e0e\u4f4e\u64cd\u4f5c\u98ce\u9669\u3002\u5c3d\u7ba1\u81ea2022\u5e74\u5e95\u4ee5\u6765\u76f8\u5173\u7814\u7a76\u6fc0\u589e\uff0c\u4f46\u8fdb\u5c55\u6709\u9650\uff0c\u9886\u57df\u7f3a\u4e4f\u5bf9\u65b0\u5174\u67b6\u6784\u6a21\u5f0f\u3001\u6838\u5fc3\u6311\u6218\u548c\u8bc4\u4f30\u8303\u5f0f\u7684\u7edf\u4e00\u7406\u89e3\u3002", "method": "\u91c7\u7528\u77e5\u8bc6\u7cfb\u7edf\u5316\uff08SoK\uff09\u65b9\u6cd5\uff0c\u7cfb\u7edf\u8c03\u7814\u4e09\u4e2a\u5173\u952e\u7814\u7a76\u9886\u57df\uff1a1\uff09\u871c\u7f50\u68c0\u6d4b\u5411\u91cf\u5206\u7c7b\u6cd5\uff1b2\uff09LLM\u871c\u7f50\u6587\u732e\u7efc\u5408\uff0c\u8bc6\u522b\u5178\u578b\u67b6\u6784\u548c\u8bc4\u4f30\u8d8b\u52bf\uff1b3\uff09\u871c\u7f50\u65e5\u5fd7\u5206\u6790\u7684\u6f14\u8fdb\u8def\u5f84\u5206\u6790\u3002", "result": "\u5efa\u7acb\u4e86\u871c\u7f50\u68c0\u6d4b\u5411\u91cf\u7684\u7ed3\u6784\u5316\u5206\u7c7b\uff0c\u8bc6\u522b\u4e86LLM\u871c\u7f50\u7684\u5178\u578b\u67b6\u6784\u6a21\u5f0f\uff0c\u603b\u7ed3\u4e86\u5173\u952e\u8bc4\u4f30\u8d8b\u52bf\uff0c\u5e76\u7ed8\u5236\u4e86\u4ece\u7b80\u5355\u6570\u636e\u7f29\u51cf\u5230\u81ea\u52a8\u5316\u60c5\u62a5\u751f\u6210\u7684\u871c\u7f50\u65e5\u5fd7\u5206\u6790\u6f14\u8fdb\u8def\u5f84\u3002", "conclusion": "\u8be5\u6280\u672f\u7684\u771f\u6b63\u6f5c\u529b\u5728\u4e8e\u521b\u5efa\u81ea\u4e3b\u3001\u81ea\u6539\u8fdb\u7684\u6b3a\u9a97\u7cfb\u7edf\uff0c\u4ee5\u5e94\u5bf9\u65b0\u5174\u7684\u667a\u80fd\u81ea\u52a8\u5316\u653b\u51fb\u8005\u5a01\u80c1\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u524d\u77bb\u6027\u8def\u7ebf\u56fe\u3002"}}
{"id": "2510.25933", "categories": ["cs.AI", "cs.HC", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.25933", "abs": "https://arxiv.org/abs/2510.25933", "authors": ["Nissan Yaron", "Dan Bystritsky", "Ben-Etzion Yaron"], "title": "Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual Accuracy by Directed Exoskeleton Reasoning", "comment": null, "summary": "We introduce Humans-Junior, a 3.8B model that matches GPT-4o on the FACTS\nGrounding public subset within a $\\pm 5$ pp equivalence margin.\n  Results. On Q1--Q500 under identical judges, GPT-4o scores 73.5% (95% CI\n69.5--77.2) and Humans-Junior 72.7% (95% CI 68.7--76.5); the paired difference\nis 0.8 pp (bootstrap 95% CI $-3.1$ to $+4.7$; permutation $p = 0.72$; Cohen's\n$d = 0.023$). TOST establishes equivalence at $\\pm 5$ pp (not at $\\pm 3$ pp).\nWhen purchased as managed APIs, Humans-Junior's base model\n(Phi-3.5-mini-instruct) is $\\approx 19\\times$ less expensive than GPT-4o on\nMicrosoft AI Foundry pricing; self-hosted or edge deployments can drive\nincremental inference cost toward zero. Measured vs estimated pricing sources\nare tabulated in Appendix E.\n  Method. Our approach combines minimal directed \"Exoskeleton Reasoning\"\nscaffolds with behavioral fine-tuning that teaches protocol compliance\n(epistemic discipline) rather than domain answers. Fine-tuning alone adds\nlittle; combined, they synergize (+17.7 pp, $p < 0.001$) and reduce variance\n($\\approx 25\\%$). In prompt-only settings on frontier models (Q1--Q100;\nnon-comparable), directed reasoning improved GPT-4o by +11.8 pp to 85.3% and\nGemini-2.5-Pro by +5.0 pp to 93.3% (baseline 88.3%, $n = 100$); see Section~5.\n  TL;DR. A 3.8B model achieves GPT-4o-level FACTS accuracy (equivalent within\n$\\pm 5$ pp on Q1--Q500). Cloud pricing shows $\\approx 19\\times$ lower cost\nversus GPT-4o, and self-hosted/edge deployments can approach zero marginal\ncost. Pricing sources are listed in Appendix E. Frontier prompt-only gains\n(Q1--Q100; non-comparable) and optimized-prompt exploratory results under\nearlier judges are summarized in Appendix F.\n  Keywords: Small Language Models, Factual Grounding, Directed Reasoning,\nFine-Tuning, Model Alignment, Cost-Efficient AI", "AI": {"tldr": "3.8B\u53c2\u6570\u7684Humans-Junior\u6a21\u578b\u5728FACTS Grounding\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e0eGPT-4o\u6027\u80fd\u76f8\u5f53\uff08\u5728\u00b15pp\u7b49\u6548\u8303\u56f4\u5185\uff09\uff0c\u4e91\u670d\u52a1\u6210\u672c\u964d\u4f4e\u7ea619\u500d\uff0c\u81ea\u6258\u7ba1\u90e8\u7f72\u53ef\u63a5\u8fd1\u96f6\u8fb9\u9645\u6210\u672c\u3002", "motivation": "\u5f00\u53d1\u6210\u672c\u6548\u76ca\u9ad8\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u63a8\u7406\u6210\u672c\u3002", "method": "\u7ed3\u5408\u6700\u5c0f\u5316\u5b9a\u5411\"\u5916\u9aa8\u9abc\u63a8\u7406\"\u652f\u67b6\u548c\u884c\u4e3a\u5fae\u8c03\uff0c\u6559\u5bfc\u534f\u8bae\u5408\u89c4\u6027\u800c\u975e\u9886\u57df\u77e5\u8bc6\uff0c\u4e24\u8005\u534f\u540c\u4f5c\u7528\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5728Q1-Q500\u6d4b\u8bd5\u4e2d\uff0cHumans-Junior\u5f97\u520672.7%\uff0cGPT-4o\u5f97\u520673.5%\uff0c\u5dee\u5f02\u4ec50.8pp\uff1b\u5b9a\u5411\u63a8\u7406\u5728GPT-4o\u4e0a\u63d0\u534711.8pp\u81f385.3%\uff0c\u5728Gemini-2.5-Pro\u4e0a\u63d0\u53475.0pp\u81f393.3%\u3002", "conclusion": "\u5c0f\u578b\u6a21\u578b\u901a\u8fc7\u9002\u5f53\u7684\u63a8\u7406\u652f\u67b6\u548c\u5fae\u8c03\u65b9\u6cd5\u53ef\u4ee5\u8fbe\u5230\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5f53\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u90e8\u7f72\u6210\u672c\u3002"}}
{"id": "2510.25960", "categories": ["cs.CR", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.25960", "abs": "https://arxiv.org/abs/2510.25960", "authors": ["Zeynep Yasemin Erdogan", "Shishir Nagaraja", "Chuadhry Mujeeb Ahmed", "Ryan Shah"], "title": "WaveVerif: Acoustic Side-Channel based Verification of Robotic Workflows", "comment": "11 pages, 3 figures, Corresponding Author: Prof. Shishir Nagaraja\n  (shishir.nagaraja@newcastle.ac.uk)", "summary": "In this paper, we present a framework that uses acoustic side- channel\nanalysis (ASCA) to monitor and verify whether a robot correctly executes its\nintended commands. We develop and evaluate a machine-learning-based workflow\nverification system that uses acoustic emissions generated by robotic\nmovements. The system can determine whether real-time behavior is consistent\nwith expected commands. The evaluation takes into account movement speed,\ndirection, and microphone distance. The results show that individual robot\nmovements can be validated with over 80% accuracy under baseline conditions\nusing four different classifiers: Support Vector Machine (SVM), Deep Neural\nNetwork (DNN), Recurrent Neural Network (RNN), and Convolutional Neural Network\n(CNN). Additionally, workflows such as pick-and-place and packing could be\nidentified with similarly high confidence. Our findings demonstrate that\nacoustic signals can support real-time, low-cost, passive verification in\nsensitive robotic environments without requiring hardware modifications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u58f0\u5b66\u4fa7\u4fe1\u9053\u5206\u6790\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u76d1\u6d4b\u548c\u9a8c\u8bc1\u673a\u5668\u4eba\u662f\u5426\u6b63\u786e\u6267\u884c\u5176\u9884\u671f\u547d\u4ee4\u3002\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5206\u6790\u673a\u5668\u4eba\u8fd0\u52a8\u4ea7\u751f\u7684\u58f0\u5b66\u4fe1\u53f7\uff0c\u80fd\u591f\u4ee5\u8d85\u8fc780%\u7684\u51c6\u786e\u7387\u9a8c\u8bc1\u5355\u4e2a\u673a\u5668\u4eba\u8fd0\u52a8\uff0c\u5e76\u80fd\u9ad8\u7f6e\u4fe1\u5ea6\u8bc6\u522b\u5de5\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u5b9e\u65f6\u3001\u4f4e\u6210\u672c\u3001\u88ab\u52a8\u7684\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u7528\u4e8e\u654f\u611f\u673a\u5668\u4eba\u73af\u5883\u4e2d\u7684\u884c\u4e3a\u9a8c\u8bc1\uff0c\u65e0\u9700\u786c\u4ef6\u4fee\u6539\u3002", "method": "\u5f00\u53d1\u5e76\u8bc4\u4f30\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u58f0\u5b66\u4fa7\u4fe1\u9053\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u4f7f\u7528\u56db\u79cd\u5206\u7c7b\u5668\uff08SVM\u3001DNN\u3001RNN\u3001CNN\uff09\u5206\u6790\u673a\u5668\u4eba\u8fd0\u52a8\u4ea7\u751f\u7684\u58f0\u5b66\u53d1\u5c04\u4fe1\u53f7\uff0c\u8003\u8651\u8fd0\u52a8\u901f\u5ea6\u3001\u65b9\u5411\u548c\u9ea6\u514b\u98ce\u8ddd\u79bb\u7b49\u56e0\u7d20\u3002", "result": "\u5728\u57fa\u51c6\u6761\u4ef6\u4e0b\uff0c\u4f7f\u7528\u56db\u79cd\u4e0d\u540c\u5206\u7c7b\u5668\u9a8c\u8bc1\u5355\u4e2a\u673a\u5668\u4eba\u8fd0\u52a8\u7684\u51c6\u786e\u7387\u8d85\u8fc780%\uff1b\u80fd\u591f\u4ee5\u7c7b\u4f3c\u9ad8\u7f6e\u4fe1\u5ea6\u8bc6\u522b\u62fe\u53d6\u653e\u7f6e\u548c\u5305\u88c5\u7b49\u5de5\u4f5c\u6d41\u7a0b\u3002", "conclusion": "\u58f0\u5b66\u4fe1\u53f7\u53ef\u4ee5\u652f\u6301\u654f\u611f\u673a\u5668\u4eba\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u3001\u4f4e\u6210\u672c\u3001\u88ab\u52a8\u9a8c\u8bc1\uff0c\u65e0\u9700\u786c\u4ef6\u4fee\u6539\u3002"}}
{"id": "2510.25951", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25951", "abs": "https://arxiv.org/abs/2510.25951", "authors": ["Sounak Banerjee", "Daphne Cornelisse", "Deepak Gopinath", "Emily Sumner", "Jonathan DeCastro", "Guy Rosman", "Eugene Vinitsky", "Mark K. Ho"], "title": "Estimating cognitive biases with attention-aware inverse planning", "comment": null, "summary": "People's goal-directed behaviors are influenced by their cognitive biases,\nand autonomous systems that interact with people should be aware of this. For\nexample, people's attention to objects in their environment will be biased in a\nway that systematically affects how they perform everyday tasks such as driving\nto work. Here, building on recent work in computational cognitive science, we\nformally articulate the attention-aware inverse planning problem, in which the\ngoal is to estimate a person's attentional biases from their actions. We\ndemonstrate how attention-aware inverse planning systematically differs from\nstandard inverse reinforcement learning and how cognitive biases can be\ninferred from behavior. Finally, we present an approach to attention-aware\ninverse planning that combines deep reinforcement learning with computational\ncognitive modeling. We use this approach to infer the attentional strategies of\nRL agents in real-life driving scenarios selected from the Waymo Open Dataset,\ndemonstrating the scalability of estimating cognitive biases with\nattention-aware inverse planning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6ce8\u610f\u529b\u611f\u77e5\u9006\u89c4\u5212\u95ee\u9898\uff0c\u65e8\u5728\u4ece\u4eba\u7c7b\u884c\u4e3a\u4e2d\u63a8\u65ad\u8ba4\u77e5\u504f\u89c1\uff0c\u7279\u522b\u662f\u6ce8\u610f\u529b\u504f\u89c1\u3002\u901a\u8fc7\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u548c\u8ba1\u7b97\u8ba4\u77e5\u5efa\u6a21\uff0c\u5728\u771f\u5b9e\u9a7e\u9a76\u573a\u666f\u4e2d\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u4eba\u7c7b\u7684\u76ee\u6807\u5bfc\u5411\u884c\u4e3a\u53d7\u5230\u8ba4\u77e5\u504f\u89c1\u5f71\u54cd\uff0c\u81ea\u4e3b\u7cfb\u7edf\u9700\u8981\u7406\u89e3\u8fd9\u4e9b\u504f\u89c1\u3002\u4f8b\u5982\uff0c\u4eba\u4eec\u5728\u65e5\u5e38\u4efb\u52a1\uff08\u5982\u9a7e\u9a76\uff09\u4e2d\u7684\u6ce8\u610f\u529b\u5206\u914d\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u5f71\u54cd\u884c\u4e3a\u8868\u73b0\u3002", "method": "\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e0e\u8ba1\u7b97\u8ba4\u77e5\u5efa\u6a21\uff0c\u6784\u5efa\u6ce8\u610f\u529b\u611f\u77e5\u9006\u89c4\u5212\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u4e0e\u6807\u51c6\u9006\u5f3a\u5316\u5b66\u4e60\u4e0d\u540c\uff0c\u4e13\u95e8\u7528\u4e8e\u4ece\u884c\u4e3a\u4e2d\u63a8\u65ad\u6ce8\u610f\u529b\u504f\u89c1\u3002", "result": "\u5728Waymo\u5f00\u653e\u6570\u636e\u96c6\u4e2d\u7684\u771f\u5b9e\u9a7e\u9a76\u573a\u666f\u4e2d\uff0c\u6210\u529f\u63a8\u65ad\u51fa\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u7684\u6ce8\u610f\u529b\u7b56\u7565\uff0c\u8bc1\u660e\u4e86\u6ce8\u610f\u529b\u611f\u77e5\u9006\u89c4\u5212\u5728\u4f30\u8ba1\u8ba4\u77e5\u504f\u89c1\u65b9\u9762\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u6ce8\u610f\u529b\u611f\u77e5\u9006\u89c4\u5212\u80fd\u591f\u6709\u6548\u4ece\u884c\u4e3a\u6570\u636e\u4e2d\u63a8\u65ad\u8ba4\u77e5\u504f\u89c1\uff0c\u4e3a\u7406\u89e3\u4eba\u7c7b\u6ce8\u610f\u529b\u673a\u5236\u53ca\u5176\u5bf9\u884c\u4e3a\u7684\u5f71\u54cd\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u5728\u81ea\u4e3b\u7cfb\u7edf\u4eba\u673a\u4ea4\u4e92\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.26003", "categories": ["cs.CR", "94A60"], "pdf": "https://arxiv.org/pdf/2510.26003", "abs": "https://arxiv.org/abs/2510.26003", "authors": ["Eirini Poimenidou", "K. A. Draziotis"], "title": "Message Recovery Attack in NTRU via Knapsack", "comment": null, "summary": "In the present paper, we introduce a message-recovery attack based on the\nModular Knapsack Problem, applicable to all variants of the NTRU-HPS\ncryptosystem. Assuming that a fraction $\\epsilon$ of the coefficients of the\nmessage ${\\bf{m}}\\in\\{-1,0,1\\}^N$ and of the nonce vector ${\\bf\nr}\\in\\{-1,0,1\\}^N$ are known in advance at random positions, we reduce message\ndecryption to finding a short vector in a lattice that encodes an instance of a\nmodular knapsack system. This allows us to address a key question: how much\ninformation about ${\\bf m}$, or about the pair $({\\bf m},{\\bf r})$, is required\nbefore recovery becomes feasible? A FLATTER reduction successfully recovers the\nmessage, in practice when $\\epsilon\\approx 0.45$. Our implementation finds\n${\\bf m}$ within a few minutes on a commodity desktop.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u80cc\u5305\u95ee\u9898\u7684\u6d88\u606f\u6062\u590d\u653b\u51fb\uff0c\u9002\u7528\u4e8e\u6240\u6709NTRU-HPS\u5bc6\u7801\u7cfb\u7edf\u53d8\u4f53\u3002\u5f53\u5df2\u77e5\u6d88\u606f\u548c\u975e\u5411\u91cf\u7684\u90e8\u5206\u7cfb\u6570\u65f6\uff0c\u53ef\u5c06\u6d88\u606f\u89e3\u5bc6\u7b80\u5316\u4e3a\u5728\u683c\u4e2d\u5bfb\u627e\u77ed\u5411\u91cf\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u5728\u5df2\u77e5\u90e8\u5206\u6d88\u606f\u6216\u975e\u5411\u91cf\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u591a\u5c11\u4fe1\u606f\u624d\u80fd\u5b9e\u73b0\u53ef\u884c\u7684\u6d88\u606f\u6062\u590d\u653b\u51fb\uff0c\u63a2\u8ba8NTRU-HPS\u5bc6\u7801\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u8fb9\u754c\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u6a21\u80cc\u5305\u95ee\u9898\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7FLATTER\u7ea6\u7b80\u6280\u672f\u5c06\u6d88\u606f\u89e3\u5bc6\u95ee\u9898\u8f6c\u5316\u4e3a\u683c\u4e2d\u7684\u77ed\u5411\u91cf\u5bfb\u627e\u95ee\u9898\u3002", "result": "\u5f53\u5df2\u77e5\u7ea645%\u7684\u7cfb\u6570\u65f6\uff0c\u653b\u51fb\u5728\u5b9e\u8df5\u4e2d\u6210\u529f\u6062\u590d\u6d88\u606f\uff0c\u5728\u666e\u901a\u53f0\u5f0f\u673a\u4e0a\u51e0\u5206\u949f\u5185\u5373\u53ef\u627e\u5230\u539f\u59cb\u6d88\u606f\u3002", "conclusion": "\u8be5\u653b\u51fb\u65b9\u6cd5\u6709\u6548\u63ed\u793a\u4e86NTRU-HPS\u5bc6\u7801\u7cfb\u7edf\u5728\u90e8\u5206\u4fe1\u606f\u6cc4\u9732\u60c5\u51b5\u4e0b\u7684\u8106\u5f31\u6027\uff0c\u4e3a\u5bc6\u7801\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2510.26012", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26012", "abs": "https://arxiv.org/abs/2510.26012", "authors": ["Siyi Wu", "Chiaxin Liang", "Ziqian Bi", "Leyi Zhao", "Tianyang Wang", "Junhao Song", "Yichao Zhang", "Keyu Chen", "Xinyuan Song"], "title": "AutoSurvey2: Empowering Researchers with Next Level Automated Literature Surveys", "comment": "TKDD 2025", "summary": "The rapid growth of research literature, particularly in large language\nmodels (LLMs), has made producing comprehensive and current survey papers\nincreasingly difficult. This paper introduces autosurvey2, a multi-stage\npipeline that automates survey generation through retrieval-augmented synthesis\nand structured evaluation. The system integrates parallel section generation,\niterative refinement, and real-time retrieval of recent publications to ensure\nboth topical completeness and factual accuracy. Quality is assessed using a\nmulti-LLM evaluation framework that measures coverage, structure, and relevance\nin alignment with expert review standards. Experimental results demonstrate\nthat autosurvey2 consistently outperforms existing retrieval-based and\nautomated baselines, achieving higher scores in structural coherence and\ntopical relevance while maintaining strong citation fidelity. By combining\nretrieval, reasoning, and automated evaluation into a unified framework,\nautosurvey2 provides a scalable and reproducible solution for generating\nlong-form academic surveys and contributes a solid foundation for future\nresearch on automated scholarly writing. All code and resources are available\nat https://github.com/annihi1ation/auto_research.", "AI": {"tldr": "autosurvey2\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u751f\u6210\u5b66\u672f\u7efc\u8ff0\u8bba\u6587\u7684\u591a\u9636\u6bb5\u6d41\u6c34\u7ebf\u7cfb\u7edf\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u5408\u6210\u548c\u7ed3\u6784\u5316\u8bc4\u4f30\uff0c\u7ed3\u5408\u5e76\u884c\u7ae0\u8282\u751f\u6210\u3001\u8fed\u4ee3\u4f18\u5316\u548c\u5b9e\u65f6\u6587\u732e\u68c0\u7d22\uff0c\u786e\u4fdd\u4e3b\u9898\u5b8c\u6574\u6027\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u3002", "motivation": "\u968f\u7740\u7814\u7a76\u6587\u732e\uff08\u7279\u522b\u662f\u5927\u8bed\u8a00\u6a21\u578b\u9886\u57df\uff09\u7684\u5feb\u901f\u589e\u957f\uff0c\u64b0\u5199\u5168\u9762\u4e14\u6700\u65b0\u7684\u7efc\u8ff0\u8bba\u6587\u53d8\u5f97\u8d8a\u6765\u8d8a\u56f0\u96be\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u6d41\u6c34\u7ebf\u65b9\u6cd5\uff0c\u5305\u62ec\u68c0\u7d22\u589e\u5f3a\u5408\u6210\u3001\u5e76\u884c\u7ae0\u8282\u751f\u6210\u3001\u8fed\u4ee3\u4f18\u5316\u548c\u5b9e\u65f6\u6587\u732e\u68c0\u7d22\uff0c\u5e76\u4f7f\u7528\u591aLLM\u8bc4\u4f30\u6846\u67b6\u6765\u8bc4\u4f30\u8986\u76d6\u5ea6\u3001\u7ed3\u6784\u548c\u76f8\u5173\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aautosurvey2\u5728\u7ed3\u6784\u8fde\u8d2f\u6027\u548c\u4e3b\u9898\u76f8\u5173\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u68c0\u7d22\u57fa\u7ebf\u548c\u81ea\u52a8\u5316\u57fa\u7ebf\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u5927\u7684\u5f15\u6587\u4fdd\u771f\u5ea6\u3002", "conclusion": "autosurvey2\u901a\u8fc7\u5c06\u68c0\u7d22\u3001\u63a8\u7406\u548c\u81ea\u52a8\u8bc4\u4f30\u6574\u5408\u5230\u7edf\u4e00\u6846\u67b6\u4e2d\uff0c\u4e3a\u751f\u6210\u957f\u7bc7\u5b66\u672f\u7efc\u8ff0\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u548c\u53ef\u590d\u73b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e3a\u81ea\u52a8\u5316\u5b66\u672f\u5199\u4f5c\u7684\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2510.26102", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.26102", "abs": "https://arxiv.org/abs/2510.26102", "authors": ["Lisha Shuai", "Jiuling Dong", "Nan Zhang", "Shaofeng Tan", "Haokun Zhang", "Zilong Song", "Gaoya Dong", "Xiaolong Yang"], "title": "PEEL: A Poisoning-Exposing Encoding Theoretical Framework for Local Differential Privacy", "comment": "14 pages, 1 figures", "summary": "Local Differential Privacy (LDP) is a widely adopted privacy-protection model\nin the Internet of Things (IoT) due to its lightweight, decentralized, and\nscalable nature. However, it is vulnerable to poisoning attacks, and existing\ndefenses either incur prohibitive resource overheads or rely on domain-specific\nprior knowledge, limiting their practical deployment. To address these\nlimitations, we propose PEEL, a Poisoning-Exposing Encoding theoretical\nframework for LDP, which departs from resource- or prior-dependent\ncountermeasures and instead leverages the inherent structural consistency of\nLDP-perturbed data. As a non-intrusive post-processing module, PEEL amplifies\nstealthy poisoning effects by re-encoding LDP-perturbed data via\nsparsification, normalization, and low-rank projection, thereby revealing both\noutput and rule poisoning attacks through structural inconsistencies in the\nreconstructed space. Theoretical analysis proves that PEEL, integrated with\nLDP, retains unbiasedness and statistical accuracy, while being robust to\nexpose both output and rule poisoning attacks. Moreover, evaluation results\nshow that LDP-integrated PEEL not only outperforms four state-of-the-art\ndefenses in terms of poisoning exposure accuracy but also significantly reduces\nclient-side computational costs, making it highly suitable for large-scale IoT\ndeployments.", "AI": {"tldr": "PEEL\u662f\u4e00\u4e2a\u9488\u5bf9\u672c\u5730\u5dee\u5206\u9690\u79c1(LDP)\u7684\u6295\u6bd2\u653b\u51fb\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u91cd\u65b0\u7f16\u7801LDP\u6270\u52a8\u6570\u636e\u6765\u66b4\u9732\u6295\u6bd2\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u7edf\u8ba1\u51c6\u786e\u6027\u548c\u964d\u4f4e\u5ba2\u6237\u7aef\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "LDP\u5728\u7269\u8054\u7f51\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u6613\u53d7\u6295\u6bd2\u653b\u51fb\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u8981\u4e48\u8d44\u6e90\u5f00\u9500\u8fc7\u5927\uff0c\u8981\u4e48\u4f9d\u8d56\u9886\u57df\u7279\u5b9a\u5148\u9a8c\u77e5\u8bc6\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u90e8\u7f72\u3002", "method": "PEEL\u4f5c\u4e3a\u975e\u4fb5\u5165\u5f0f\u540e\u5904\u7406\u6a21\u5757\uff0c\u901a\u8fc7\u7a00\u758f\u5316\u3001\u5f52\u4e00\u5316\u548c\u4f4e\u79e9\u6295\u5f71\u91cd\u65b0\u7f16\u7801LDP\u6270\u52a8\u6570\u636e\uff0c\u653e\u5927\u9690\u853d\u7684\u6295\u6bd2\u6548\u5e94\uff0c\u5728\u91cd\u6784\u7a7a\u95f4\u4e2d\u901a\u8fc7\u7ed3\u6784\u4e0d\u4e00\u81f4\u6027\u63ed\u793a\u8f93\u51fa\u548c\u89c4\u5219\u6295\u6bd2\u653b\u51fb\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660ePEEL\u4e0eLDP\u96c6\u6210\u4fdd\u6301\u65e0\u504f\u6027\u548c\u7edf\u8ba1\u51c6\u786e\u6027\uff0c\u540c\u65f6\u80fd\u6709\u6548\u66b4\u9732\u6295\u6bd2\u653b\u51fb\u3002\u8bc4\u4f30\u7ed3\u679c\u663e\u793aPEEL\u5728\u6295\u6bd2\u66b4\u9732\u51c6\u786e\u7387\u4e0a\u4f18\u4e8e\u56db\u79cd\u6700\u5148\u8fdb\u9632\u5fa1\u65b9\u6cd5\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u5ba2\u6237\u7aef\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "PEEL\u6846\u67b6\u4e3aLDP\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u8f7b\u91cf\u7ea7\u7684\u6295\u6bd2\u653b\u51fb\u9632\u5fa1\u65b9\u6848\uff0c\u7279\u522b\u9002\u5408\u5927\u89c4\u6a21\u7269\u8054\u7f51\u90e8\u7f72\u3002"}}
{"id": "2510.26023", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.26023", "abs": "https://arxiv.org/abs/2510.26023", "authors": ["Zhipeng Bao", "Qianwen Li"], "title": "Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization", "comment": "8 pages", "summary": "Despite significant advancements in recent decades, autonomous vehicles (AVs)\ncontinue to face challenges in navigating certain traffic scenarios where human\ndrivers excel. In such situations, AVs often become immobilized, disrupting\noverall traffic flow. Current recovery solutions, such as remote intervention\n(which is costly and inefficient) and manual takeover (which excludes\nnon-drivers and limits AV accessibility), are inadequate. This paper introduces\nStuckSolver, a novel Large Language Model (LLM) driven recovery framework that\nenables AVs to resolve immobilization scenarios through self-reasoning and/or\npassenger-guided decision-making. StuckSolver is designed as a plug-in add-on\nmodule that operates on top of the AV's existing perception-planning-control\nstack, requiring no modification to its internal architecture. Instead, it\ninterfaces with standard sensor data streams to detect immobilization states,\ninterpret environmental context, and generate high-level recovery commands that\ncan be executed by the AV's native planner. We evaluate StuckSolver on the\nBench2Drive benchmark and in custom-designed uncertainty scenarios. Results\nshow that StuckSolver achieves near-state-of-the-art performance through\nautonomous self-reasoning alone and exhibits further improvements when\npassenger guidance is incorporated.", "AI": {"tldr": "StuckSolver\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u6062\u590d\u6846\u67b6\uff0c\u80fd\u591f\u5728\u8f66\u8f86\u9677\u5165\u56f0\u5883\u65f6\u901a\u8fc7\u81ea\u4e3b\u63a8\u7406\u6216\u4e58\u5ba2\u6307\u5bfc\u6765\u89e3\u51b3\u95ee\u9898\uff0c\u65e0\u9700\u4fee\u6539\u73b0\u6709\u7cfb\u7edf\u67b6\u6784\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5728\u67d0\u4e9b\u4ea4\u901a\u573a\u666f\u4e2d\u5bb9\u6613\u9677\u5165\u56f0\u5883\uff0c\u800c\u73b0\u6709\u7684\u8fdc\u7a0b\u5e72\u9884\u548c\u4eba\u5de5\u63a5\u7ba1\u65b9\u6848\u5b58\u5728\u6210\u672c\u9ad8\u3001\u6548\u7387\u4f4e\u3001\u53ef\u8bbf\u95ee\u6027\u5dee\u7b49\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u63d2\u4ef6\u5f0f\u6a21\u5757\uff0c\u5229\u7528LLM\u5904\u7406\u6807\u51c6\u4f20\u611f\u5668\u6570\u636e\u6d41\uff0c\u68c0\u6d4b\u56f0\u5883\u72b6\u6001\uff0c\u7406\u89e3\u73af\u5883\u4e0a\u4e0b\u6587\uff0c\u5e76\u751f\u6210\u53ef\u7531\u8f66\u8f86\u539f\u751f\u89c4\u5212\u5668\u6267\u884c\u7684\u9ad8\u7ea7\u6062\u590d\u547d\u4ee4\u3002", "result": "\u5728Bench2Drive\u57fa\u51c6\u6d4b\u8bd5\u548c\u81ea\u5b9a\u4e49\u4e0d\u786e\u5b9a\u6027\u573a\u666f\u4e2d\uff0cStuckSolver\u4ec5\u901a\u8fc7\u81ea\u4e3b\u63a8\u7406\u5c31\u8fbe\u5230\u63a5\u8fd1\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u7ed3\u5408\u4e58\u5ba2\u6307\u5bfc\u540e\u6027\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "conclusion": "StuckSolver\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u5b9e\u7528\u7684\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u56f0\u5883\u6062\u590d\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4e0d\u4fee\u6539\u73b0\u6709\u7cfb\u7edf\u67b6\u6784\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347\u8f66\u8f86\u5728\u590d\u6742\u573a\u666f\u4e2d\u7684\u5e94\u5bf9\u80fd\u529b\u3002"}}
{"id": "2510.26103", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.26103", "abs": "https://arxiv.org/abs/2510.26103", "authors": ["Maximilian Schreiber", "Pascal Tippe"], "title": "Security Vulnerabilities in AI-Generated Code: A Large-Scale Analysis of Public GitHub Repositories", "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in Volume 16219 of the Lecture Notes in Computer Science series,\n  and is available online at https://doi.org/10.1007/978-981-95-3537-8_9", "summary": "This paper presents a comprehensive empirical analysis of security\nvulnerabilities in AI-generated code across public GitHub repositories. We\ncollected and analyzed 7,703 files explicitly attributed to four major AI\ntools: ChatGPT (91.52\\%), GitHub Copilot (7.50\\%), Amazon CodeWhisperer\n(0.52\\%), and Tabnine (0.46\\%). Using CodeQL static analysis, we identified\n4,241 Common Weakness Enumeration (CWE) instances across 77 distinct\nvulnerability types. Our findings reveal that while 87.9\\% of AI-generated code\ndoes not contain identifiable CWE-mapped vulnerabilities, significant patterns\nemerge regarding language-specific vulnerabilities and tool performance. Python\nconsistently exhibited higher vulnerability rates (16.18\\%-18.50\\%) compared to\nJavaScript (8.66\\%-8.99\\%) and TypeScript (2.50\\%-7.14\\%) across all tools. We\nobserved notable differences in security performance, with GitHub Copilot\nachieving better security density for Python (1,739 LOC per CWE) and\nTypeScript, while ChatGPT performed better for JavaScript. Additionally, we\ndiscovered widespread use of AI tools for documentation generation (39\\% of\ncollected files), an understudied application with implications for software\nmaintainability. These findings extend previous work with a significantly\nlarger dataset and provide valuable insights for developing language-specific\nand context-aware security practices for the responsible integration of\nAI-generated code into software development workflows.", "AI": {"tldr": "\u5bf9GitHub\u4e0aAI\u751f\u6210\u4ee3\u7801\u5b89\u5168\u6f0f\u6d1e\u7684\u5b9e\u8bc1\u5206\u6790\uff0c\u6536\u96c6\u4e867,703\u4e2a\u6587\u4ef6\uff0c\u53d1\u73b04,241\u4e2aCWE\u6f0f\u6d1e\u5b9e\u4f8b\uff0cPython\u6f0f\u6d1e\u7387\u6700\u9ad8\uff0c\u4e0d\u540cAI\u5de5\u5177\u5728\u5b89\u5168\u6027\u80fd\u4e0a\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u968f\u7740AI\u4ee3\u7801\u751f\u6210\u5de5\u5177\u7684\u666e\u53ca\uff0c\u9700\u8981\u4e86\u89e3\u8fd9\u4e9b\u5de5\u5177\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u72b6\u51b5\uff0c\u4e3a\u8d1f\u8d23\u4efb\u5730\u96c6\u6210AI\u751f\u6210\u4ee3\u7801\u5230\u8f6f\u4ef6\u5f00\u53d1\u5de5\u4f5c\u6d41\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u4f7f\u7528CodeQL\u9759\u6001\u5206\u6790\u5de5\u5177\u5bf9GitHub\u4e0a\u660e\u786e\u6807\u6ce8\u4e3aAI\u751f\u6210\u76847,703\u4e2a\u6587\u4ef6\u8fdb\u884c\u5206\u6790\uff0c\u6db5\u76d6ChatGPT\u3001GitHub Copilot\u3001Amazon CodeWhisperer\u548cTabnine\u56db\u79cd\u4e3b\u8981\u5de5\u5177\u3002", "result": "87.9%\u7684AI\u751f\u6210\u4ee3\u7801\u6ca1\u6709\u53ef\u8bc6\u522b\u6f0f\u6d1e\uff0c\u4f46Python\u6f0f\u6d1e\u7387(16.18%-18.50%)\u663e\u8457\u9ad8\u4e8eJavaScript(8.66%-8.99%)\u548cTypeScript(2.50%-7.14%)\uff1bGitHub Copilot\u5728Python\u548cTypeScript\u4e0a\u5b89\u5168\u5bc6\u5ea6\u66f4\u597d\uff0cChatGPT\u5728JavaScript\u4e0a\u8868\u73b0\u66f4\u597d\uff1b39%\u7684\u6587\u4ef6\u7528\u4e8e\u6587\u6863\u751f\u6210\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u5927\u89c4\u6a21\u6570\u636e\u96c6\u7684\u5206\u6790\u7ed3\u679c\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u8bed\u8a00\u7279\u5b9a\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u5b89\u5168\u5b9e\u8df5\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u8d1f\u8d23\u4efb\u5730\u96c6\u6210AI\u751f\u6210\u4ee3\u7801\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\u3002"}}
{"id": "2510.26057", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.26057", "abs": "https://arxiv.org/abs/2510.26057", "authors": ["Andrew L. Kun"], "title": "Can AI be Accountable?", "comment": "To be published as a chapter in Daniele Quercia and Marios\n  Constantinides (Eds.). Operationalizing Responsible AI. Cambridge University\n  Press. Forthcoming", "summary": "The AI we use is powerful, and its power is increasing rapidly. If this\npowerful AI is to serve the needs of consumers, voters, and decision makers,\nthen it is imperative that the AI is accountable. In general, an agent is\naccountable to a forum if the forum can request information from the agent\nabout its actions, if the forum and the agent can discuss this information, and\nif the forum can sanction the agent. Unfortunately, in too many cases today's\nAI is not accountable -- we cannot question it, enter into a discussion with\nit, let alone sanction it. In this chapter we relate the general definition of\naccountability to AI, we illustrate what it means for AI to be accountable and\nunaccountable, and we explore approaches that can improve our chances of living\nin a world where all AI is accountable to those who are affected by it.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u95ee\u8d23\u5236\u7684\u91cd\u8981\u6027\uff0c\u5206\u6790\u4e86\u5f53\u524dAI\u7f3a\u4e4f\u95ee\u8d23\u6027\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u5584AI\u95ee\u8d23\u6027\u7684\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740AI\u80fd\u529b\u7684\u5feb\u901f\u589e\u5f3a\uff0c\u786e\u4fddAI\u5bf9\u6d88\u8d39\u8005\u3001\u9009\u6c11\u548c\u51b3\u7b56\u8005\u8d1f\u8d23\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524d\u8bb8\u591aAI\u7cfb\u7edf\u7f3a\u4e4f\u95ee\u8d23\u6027\uff0c\u65e0\u6cd5\u88ab\u8d28\u7591\u3001\u8ba8\u8bba\u6216\u5236\u88c1\u3002", "method": "\u5c06\u4e00\u822c\u95ee\u8d23\u5236\u5b9a\u4e49\u5e94\u7528\u4e8eAI\uff0c\u9610\u8ff0AI\u95ee\u8d23\u6027\u7684\u542b\u4e49\uff0c\u63a2\u7d22\u63d0\u9ad8AI\u95ee\u8d23\u6027\u7684\u65b9\u6cd5\u3002", "result": "\u660e\u786e\u4e86AI\u95ee\u8d23\u5236\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u6307\u51fa\u4e86\u5f53\u524dAI\u95ee\u8d23\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u6539\u5584\u95ee\u8d23\u6027\u7684\u9014\u5f84\u3002", "conclusion": "\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u6240\u6709AI\u90fd\u80fd\u5bf9\u5176\u5f71\u54cd\u5bf9\u8c61\u8d1f\u8d23\u7684\u4e16\u754c\uff0c\u786e\u4fddAI\u7cfb\u7edf\u53ef\u4ee5\u88ab\u8d28\u7591\u3001\u8ba8\u8bba\u548c\u5fc5\u8981\u65f6\u53d7\u5230\u5236\u88c1\u3002"}}
{"id": "2510.26094", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26094", "abs": "https://arxiv.org/abs/2510.26094", "authors": ["Yuxin Li", "Minghao Liu", "Ruida Wang", "Wenzhao Ji", "Zhitao He", "Rui Pan", "Junming Huang", "Tong Zhang", "Yi R. Fung"], "title": "Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4", "comment": null, "summary": "We present **Lean4PHYS**, a comprehensive reasoning framework for\ncollege-level physics problems in Lean4. **Lean4PHYS** includes\n*LeanPhysBench*, a college-level benchmark for formal physics reasoning in\nLean4, which contains 200 hand-crafted and peer-reviewed statements derived\nfrom university textbooks and physics competition problems. To establish a\nsolid foundation for formal reasoning in physics, we also introduce *PhysLib*,\na community-driven repository containing fundamental unit systems and theorems\nessential for formal physics reasoning. Based on the benchmark and Lean4\nrepository we composed in **Lean4PHYS**, we report baseline results using major\nexpert Math Lean4 provers and state-of-the-art closed-source models, with the\nbest performance of DeepSeek-Prover-V2-7B achieving only 16% and\nClaude-Sonnet-4 achieving 35%. We also conduct a detailed analysis showing that\nour *PhysLib* can achieve an average improvement of 11.75% in model\nperformance. This demonstrates the challenging nature of our *LeanPhysBench*\nand the effectiveness of *PhysLib*. To the best of our knowledge, this is the\nfirst study to provide a physics benchmark in Lean4.", "AI": {"tldr": "Lean4PHYS\u662f\u4e00\u4e2a\u5728Lean4\u4e2d\u7528\u4e8e\u5927\u5b66\u7269\u7406\u95ee\u9898\u63a8\u7406\u7684\u6846\u67b6\uff0c\u5305\u542bLeanPhysBench\u57fa\u51c6\u6d4b\u8bd5\u548cPhysLib\u7269\u7406\u5e93\uff0c\u5f53\u524d\u6700\u4f73\u6a21\u578b\u6027\u80fd\u4ec5\u4e3a35%\uff0c\u8bc1\u660e\u4e86\u8be5\u57fa\u51c6\u7684\u6311\u6218\u6027\u548cPhysLib\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u5927\u5b66\u7269\u7406\u95ee\u9898\u63d0\u4f9b\u6b63\u5f0f\u7684\u63a8\u7406\u6846\u67b6\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u586b\u8865Lean4\u4e2d\u7269\u7406\u63a8\u7406\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u63a8\u52a8\u7269\u7406\u95ee\u9898\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002", "method": "\u6784\u5efaLeanPhysBench\u5305\u542b200\u4e2a\u624b\u5de5\u5236\u4f5c\u548c\u540c\u884c\u8bc4\u5ba1\u7684\u7269\u7406\u95ee\u9898\u9648\u8ff0\uff0c\u5f00\u53d1PhysLib\u793e\u533a\u9a71\u52a8\u7684\u7269\u7406\u5b9a\u7406\u5e93\uff0c\u4f7f\u7528\u4e3b\u6d41Lean4\u8bc1\u660e\u5668\u548c\u95ed\u6e90\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "DeepSeek-Prover-V2-7B\u6a21\u578b\u8fbe\u523016%\u7684\u6027\u80fd\uff0cClaude-Sonnet-4\u8fbe\u523035%\u7684\u6700\u4f73\u6027\u80fd\uff0cPhysLib\u5e73\u5747\u63d0\u5347\u6a21\u578b\u6027\u80fd11.75%\u3002", "conclusion": "LeanPhysBench\u5177\u6709\u6311\u6218\u6027\uff0cPhysLib\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u8fd9\u662f\u9996\u4e2a\u5728Lean4\u4e2d\u63d0\u4f9b\u7684\u7269\u7406\u57fa\u51c6\u7814\u7a76\u3002"}}
{"id": "2510.26210", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.26210", "abs": "https://arxiv.org/abs/2510.26210", "authors": ["Junlin Liu", "Zhaomeng Deng", "Ziming Wang", "Mengyu Yao", "Yifeng Cai", "Yutao Hu", "Ziqi Zhang", "Yao Guo", "Ding Li"], "title": "Who Moved My Transaction? Uncovering Post-Transaction Auditability Vulnerabilities in Modern Super Apps", "comment": "SaTS 2025 (Co-Located with ACM CCS 2025)", "summary": "Super apps are the cornerstones of modern digital life, embedding financial\ntransactions into nearly every aspect of daily routine. The prevailing security\nparadigm for these platforms is overwhelmingly focused on pre-transaction\nauthentication, preventing unauthorized payments before they occur. We argue\nthat a critical vulnerability vector has been largely overlooked: the fragility\nof post-transaction audit trails. We investigate the ease with which a user can\npermanently erase their transaction history from an app's interface, thereby\nconcealing unauthorized or sensitive activities from the account owner. To\nquantify this threat, we conducted an empirical study with 6 volunteers who\nperformed a cross-evaluation on six super apps. Our findings are alarming: all\nsix applications studied allow users to delete transaction records, yet a\nstaggering five out of six (83+\\%) fail to protect these records with strong\nauthentication. Only one app in our study required biometric verification for\ndeletion. This study provides the first concrete evidence of this\nnear-ubiquitous vulnerability, demonstrating a critical gap in the current\nmobile security landscape and underscoring the urgent need for a paradigm shift\ntowards ensuring post-transaction audit integrity.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8d85\u7ea7\u5e94\u7528\u666e\u904d\u5b58\u5728\u4ea4\u6613\u8bb0\u5f55\u5220\u9664\u6f0f\u6d1e\uff0c83%\u7684\u5e94\u7528\u7f3a\u4e4f\u5f3a\u8ba4\u8bc1\u4fdd\u62a4\uff0c\u5141\u8bb8\u7528\u6237\u8f7b\u6613\u5220\u9664\u4ea4\u6613\u5386\u53f2\uff0c\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u5f53\u524d\u8d85\u7ea7\u5e94\u7528\u5b89\u5168\u8303\u5f0f\u8fc7\u5ea6\u5173\u6ce8\u4ea4\u6613\u524d\u8ba4\u8bc1\uff0c\u800c\u5ffd\u89c6\u4e86\u4ea4\u6613\u540e\u5ba1\u8ba1\u8ffd\u8e2a\u7684\u8106\u5f31\u6027\uff0c\u7528\u6237\u53ef\u6c38\u4e45\u5220\u9664\u4ea4\u6613\u8bb0\u5f55\u6765\u9690\u85cf\u672a\u6388\u6743\u6216\u654f\u611f\u6d3b\u52a8\u3002", "method": "\u901a\u8fc76\u540d\u5fd7\u613f\u8005\u5bf96\u4e2a\u8d85\u7ea7\u5e94\u7528\u8fdb\u884c\u4ea4\u53c9\u8bc4\u4f30\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u91cf\u5316\u4ea4\u6613\u8bb0\u5f55\u5220\u9664\u7684\u5b89\u5168\u5a01\u80c1\u3002", "result": "\u6240\u67096\u4e2a\u5e94\u7528\u90fd\u5141\u8bb8\u7528\u6237\u5220\u9664\u4ea4\u6613\u8bb0\u5f55\uff0c\u4f46\u5176\u4e2d5\u4e2a\uff0883%\uff09\u7f3a\u4e4f\u5f3a\u8ba4\u8bc1\u4fdd\u62a4\uff0c\u53ea\u67091\u4e2a\u5e94\u7528\u8981\u6c42\u751f\u7269\u7279\u5f81\u9a8c\u8bc1\u624d\u80fd\u5220\u9664\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u63d0\u4f9b\u8be5\u666e\u904d\u6f0f\u6d1e\u7684\u5177\u4f53\u8bc1\u636e\uff0c\u8868\u660e\u5f53\u524d\u79fb\u52a8\u5b89\u5168\u5b58\u5728\u5173\u952e\u5dee\u8ddd\uff0c\u8feb\u5207\u9700\u8981\u5411\u786e\u4fdd\u4ea4\u6613\u540e\u5ba1\u8ba1\u5b8c\u6574\u6027\u8fdb\u884c\u8303\u5f0f\u8f6c\u53d8\u3002"}}
{"id": "2510.26136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26136", "abs": "https://arxiv.org/abs/2510.26136", "authors": ["Boqin Zhuang", "Jiacheng Qiao", "Mingqian Liu", "Mingxing Yu", "Ping Hong", "Rui Li", "Xiaoxia Song", "Xiangjun Xu", "Xu Chen", "Yaoyao Ma", "Yujie Gao"], "title": "Beyond Benchmarks: The Economics of AI Inference", "comment": null, "summary": "The inference cost of Large Language Models (LLMs) has become a critical\nfactor in determining their commercial viability and widespread adoption. This\npaper introduces a quantitative ``economics of inference'' framework, treating\nthe LLM inference process as a compute-driven intelligent production activity.\nWe analyze its marginal cost, economies of scale, and quality of output under\nvarious performance configurations. Based on empirical data from WiNEval-3.0,\nwe construct the first ``LLM Inference Production Frontier,'' revealing three\nprinciples: diminishing marginal cost, diminishing returns to scale, and an\noptimal cost-effectiveness zone. This paper not only provides an economic basis\nfor model deployment decisions but also lays an empirical foundation for the\nfuture market-based pricing and optimization of AI inference resources.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u91cf\u5316\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7ecf\u6d4e\u5b66\u6846\u67b6\uff0c\u5c06LLM\u63a8\u7406\u89c6\u4e3a\u8ba1\u7b97\u9a71\u52a8\u7684\u667a\u80fd\u751f\u4ea7\u6d3b\u52a8\uff0c\u5206\u6790\u4e86\u8fb9\u9645\u6210\u672c\u3001\u89c4\u6a21\u7ecf\u6d4e\u548c\u8f93\u51fa\u8d28\u91cf\uff0c\u5e76\u57fa\u4e8eWiNEval-3.0\u6570\u636e\u6784\u5efa\u4e86\u9996\u4e2aLLM\u63a8\u7406\u751f\u4ea7\u524d\u6cbf\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6210\u672c\u5df2\u6210\u4e3a\u51b3\u5b9a\u5176\u5546\u4e1a\u53ef\u884c\u6027\u548c\u5e7f\u6cdb\u5e94\u7528\u7684\u5173\u952e\u56e0\u7d20\uff0c\u9700\u8981\u5efa\u7acb\u7ecf\u6d4e\u5206\u6790\u6846\u67b6\u6765\u6307\u5bfc\u6a21\u578b\u90e8\u7f72\u51b3\u7b56\u548c\u8d44\u6e90\u4f18\u5316\u3002", "method": "\u91c7\u7528\u5b9a\u91cf\u7ecf\u6d4e\u5b66\u6846\u67b6\uff0c\u5c06LLM\u63a8\u7406\u8fc7\u7a0b\u89c6\u4e3a\u8ba1\u7b97\u9a71\u52a8\u7684\u667a\u80fd\u751f\u4ea7\u6d3b\u52a8\uff0c\u57fa\u4e8eWiNEval-3.0\u7684\u5b9e\u8bc1\u6570\u636e\u6784\u5efaLLM\u63a8\u7406\u751f\u4ea7\u524d\u6cbf\u3002", "result": "\u63ed\u793a\u4e86\u4e09\u4e2a\u539f\u5219\uff1a\u8fb9\u9645\u6210\u672c\u9012\u51cf\u3001\u89c4\u6a21\u6536\u76ca\u9012\u51cf\u548c\u6700\u4f18\u6210\u672c\u6548\u76ca\u533a\u57df\uff0c\u4e3a\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u7ecf\u6d4e\u4f9d\u636e\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e0d\u4ec5\u4e3a\u6a21\u578b\u90e8\u7f72\u51b3\u7b56\u63d0\u4f9b\u4e86\u7ecf\u6d4e\u57fa\u7840\uff0c\u8fd8\u4e3a\u672a\u6765\u57fa\u4e8e\u5e02\u573a\u7684AI\u63a8\u7406\u8d44\u6e90\u5b9a\u4ef7\u548c\u4f18\u5316\u5960\u5b9a\u4e86\u5b9e\u8bc1\u57fa\u7840\u3002"}}
{"id": "2510.26274", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26274", "abs": "https://arxiv.org/abs/2510.26274", "authors": ["Haohua Duan", "Liyao Xiang", "Xin Zhang"], "title": "PVMark: Enabling Public Verifiability for LLM Watermarking Schemes", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Watermarking schemes for large language models (LLMs) have been proposed to\nidentify the source of the generated text, mitigating the potential threats\nemerged from model theft. However, current watermarking solutions hardly\nresolve the trust issue: the non-public watermark detection cannot prove itself\nfaithfully conducting the detection. We observe that it is attributed to the\nsecret key mostly used in the watermark detection -- it cannot be public, or\nthe adversary may launch removal attacks provided the key; nor can it be\nprivate, or the watermarking detection is opaque to the public. To resolve the\ndilemma, we propose PVMark, a plugin based on zero-knowledge proof (ZKP),\nenabling the watermark detection process to be publicly verifiable by third\nparties without disclosing any secret key. PVMark hinges upon the proof of\n`correct execution' of watermark detection on which a set of ZKP constraints\nare built, including mapping, random number generation, comparison, and\nsummation. We implement multiple variants of PVMark in Python, Rust and Circom,\ncovering combinations of three watermarking schemes, three hash functions, and\nfour ZKP protocols, to show our approach effectively works under a variety of\ncircumstances. By experimental results, PVMark efficiently enables public\nverifiability on the state-of-the-art LLM watermarking schemes yet without\ncompromising the watermarking performance, promising to be deployed in\npractice.", "AI": {"tldr": "PVMark\u662f\u4e00\u4e2a\u57fa\u4e8e\u96f6\u77e5\u8bc6\u8bc1\u660e\u7684\u63d2\u4ef6\uff0c\u4f7fLLM\u6c34\u5370\u68c0\u6d4b\u8fc7\u7a0b\u80fd\u591f\u88ab\u7b2c\u4e09\u65b9\u516c\u5f00\u9a8c\u8bc1\uff0c\u800c\u65e0\u9700\u6cc4\u9732\u4efb\u4f55\u5bc6\u94a5\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u6c34\u5370\u65b9\u6848\u4e2d\u7684\u4fe1\u4efb\u95ee\u9898\u3002", "motivation": "\u5f53\u524dLLM\u6c34\u5370\u65b9\u6848\u5b58\u5728\u4fe1\u4efb\u95ee\u9898\uff1a\u975e\u516c\u5f00\u7684\u6c34\u5370\u68c0\u6d4b\u65e0\u6cd5\u8bc1\u660e\u5176\u5fe0\u5b9e\u6267\u884c\u68c0\u6d4b\u8fc7\u7a0b\u3002\u79d8\u5bc6\u5bc6\u94a5\u65e2\u4e0d\u80fd\u516c\u5f00\uff08\u5426\u5219\u653b\u51fb\u8005\u53ef\u80fd\u53d1\u8d77\u79fb\u9664\u653b\u51fb\uff09\uff0c\u4e5f\u4e0d\u80fd\u79c1\u6709\uff08\u5426\u5219\u68c0\u6d4b\u8fc7\u7a0b\u5bf9\u516c\u4f17\u4e0d\u900f\u660e\uff09\u3002", "method": "\u57fa\u4e8e\u96f6\u77e5\u8bc6\u8bc1\u660e\u6784\u5efa\u6c34\u5370\u68c0\u6d4b\u7684'\u6b63\u786e\u6267\u884c'\u8bc1\u660e\uff0c\u5305\u62ec\u6620\u5c04\u3001\u968f\u673a\u6570\u751f\u6210\u3001\u6bd4\u8f83\u548c\u6c42\u548c\u7b49\u7ea6\u675f\u3002\u5b9e\u73b0\u4e86\u591a\u4e2aPVMark\u53d8\u4f53\uff0c\u6db5\u76d6\u4e09\u79cd\u6c34\u5370\u65b9\u6848\u3001\u4e09\u79cd\u54c8\u5e0c\u51fd\u6570\u548c\u56db\u79cdZKP\u534f\u8bae\u7684\u7ec4\u5408\u3002", "result": "PVMark\u5728\u591a\u79cd\u73af\u5883\u4e0b\u6709\u6548\u5de5\u4f5c\uff0c\u80fd\u591f\u9ad8\u6548\u5730\u4e3a\u6700\u5148\u8fdb\u7684LLM\u6c34\u5370\u65b9\u6848\u63d0\u4f9b\u516c\u5f00\u53ef\u9a8c\u8bc1\u6027\uff0c\u4e14\u4e0d\u5f71\u54cd\u6c34\u5370\u6027\u80fd\u3002", "conclusion": "PVMark\u6210\u529f\u89e3\u51b3\u4e86LLM\u6c34\u5370\u68c0\u6d4b\u7684\u4fe1\u4efb\u56f0\u5883\uff0c\u6709\u671b\u5728\u5b9e\u9645\u4e2d\u90e8\u7f72\u5e94\u7528\u3002"}}
{"id": "2510.26143", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26143", "abs": "https://arxiv.org/abs/2510.26143", "authors": ["Bo Pang", "Deqian Kong", "Silvio Savarese", "Caiming Xiong", "Yingbo Zhou"], "title": "Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math", "comment": "9 pages", "summary": "Reinforcement learning (RL) can elicit strong reasoning in large language\nmodels (LLMs), yet most open efforts focus on math and code. We propose\nReasoning Curriculum, a simple two-stage curriculum that first elicits\nreasoning skills in pretraining-aligned domains such as math, then adapts and\nrefines these skills across other domains via joint RL. Stage 1 performs a\nbrief cold start and then math-only RL with verifiable rewards to develop\nreasoning skills. Stage 2 runs joint RL on mixed-domain data to transfer and\nconsolidate these skills. The curriculum is minimal and backbone-agnostic,\nrequiring no specialized reward models beyond standard verifiability checks.\nEvaluated on Qwen3-4B and Llama-3.1-8B over a multi-domain suite, reasoning\ncurriculum yields consistent gains. Ablations and a cognitive-skill analysis\nindicate that both stages are necessary and that math-first elicitation\nincreases cognitive behaviors important for solving complex problems. Reasoning\nCurriculum provides a compact, easy-to-adopt recipe for general reasoning.", "AI": {"tldr": "\u63d0\u51faReasoning Curriculum\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u6570\u5b66\u9886\u57dfRL\u8bad\u7ec3\u63a8\u7406\u6280\u80fd\uff0c\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u591a\u9886\u57df\u8054\u5408RL\u8fc1\u79fb\u548c\u5de9\u56fa\u6280\u80fd\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e00\u81f4\u7684\u63a8\u7406\u80fd\u529b\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6570\u5b66\u548c\u4ee3\u7801\u9886\u57df\uff0c\u7f3a\u4e4f\u5728\u5176\u4ed6\u9886\u57df\u6fc0\u53d1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u901a\u7528\u65b9\u6cd5\u3002", "method": "\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\uff1a1\uff09\u6570\u5b66\u9886\u57dfRL\u8bad\u7ec3\uff0c\u4f7f\u7528\u53ef\u9a8c\u8bc1\u5956\u52b1\u5f00\u53d1\u63a8\u7406\u6280\u80fd\uff1b2\uff09\u591a\u9886\u57df\u8054\u5408RL\uff0c\u8fc1\u79fb\u548c\u5de9\u56fa\u63a8\u7406\u6280\u80fd\u3002\u65b9\u6cd5\u7b80\u5355\u3001\u4e0e\u6a21\u578b\u67b6\u6784\u65e0\u5173\uff0c\u65e0\u9700\u4e13\u7528\u5956\u52b1\u6a21\u578b\u3002", "result": "\u5728Qwen3-4B\u548cLlama-3.1-8B\u6a21\u578b\u4e0a\u7684\u591a\u9886\u57df\u8bc4\u4f30\u663e\u793a\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\uff0c\u6d88\u878d\u5b9e\u9a8c\u8bc1\u660e\u4e24\u9636\u6bb5\u90fd\u662f\u5fc5\u8981\u7684\uff0c\u6570\u5b66\u4f18\u5148\u8bad\u7ec3\u589e\u52a0\u4e86\u89e3\u51b3\u590d\u6742\u95ee\u9898\u6240\u9700\u7684\u5173\u952e\u8ba4\u77e5\u884c\u4e3a\u3002", "conclusion": "Reasoning Curriculum\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7d27\u51d1\u3001\u6613\u4e8e\u91c7\u7528\u7684\u901a\u7528\u63a8\u7406\u8bad\u7ec3\u65b9\u6848\uff0c\u901a\u8fc7\u6570\u5b66\u4f18\u5148\u7684\u63a8\u7406\u6280\u80fd\u6fc0\u53d1\u548c\u8de8\u9886\u57df\u8fc1\u79fb\uff0c\u6709\u6548\u63d0\u5347\u6a21\u578b\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.26420", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26420", "abs": "https://arxiv.org/abs/2510.26420", "authors": ["Yingjia Wang", "Ting Qiao", "Xing Liu", "Chongzuo Li", "Sixing Wu", "Jianbin Li"], "title": "SSCL-BW: Sample-Specific Clean-Label Backdoor Watermarking for Dataset Ownership Verification", "comment": "8 pages,9 figures", "summary": "The rapid advancement of deep neural networks (DNNs) heavily relies on\nlarge-scale, high-quality datasets. However, unauthorized commercial use of\nthese datasets severely violates the intellectual property rights of dataset\nowners. Existing backdoor-based dataset ownership verification methods suffer\nfrom inherent limitations: poison-label watermarks are easily detectable due to\nlabel inconsistencies, while clean-label watermarks face high technical\ncomplexity and failure on high-resolution images. Moreover, both approaches\nemploy static watermark patterns that are vulnerable to detection and removal.\nTo address these issues, this paper proposes a sample-specific clean-label\nbackdoor watermarking (i.e., SSCL-BW). By training a U-Net-based watermarked\nsample generator, this method generates unique watermarks for each sample,\nfundamentally overcoming the vulnerability of static watermark patterns. The\ncore innovation lies in designing a composite loss function with three\ncomponents: target sample loss ensures watermark effectiveness, non-target\nsample loss guarantees trigger reliability, and perceptual similarity loss\nmaintains visual imperceptibility. During ownership verification, black-box\ntesting is employed to check whether suspicious models exhibit predefined\nbackdoor behaviors. Extensive experiments on benchmark datasets demonstrate the\neffectiveness of the proposed method and its robustness against potential\nwatermark removal attacks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6837\u672c\u7279\u5b9a\u7684\u5e72\u51c0\u6807\u7b7e\u540e\u95e8\u6c34\u5370\u65b9\u6cd5\uff08SSCL-BW\uff09\uff0c\u901a\u8fc7\u8bad\u7ec3U-Net\u6c34\u5370\u751f\u6210\u5668\u4e3a\u6bcf\u4e2a\u6837\u672c\u751f\u6210\u72ec\u7279\u6c34\u5370\uff0c\u514b\u670d\u9759\u6001\u6c34\u5370\u6a21\u5f0f\u7684\u8106\u5f31\u6027\uff0c\u6709\u6548\u4fdd\u62a4\u6570\u636e\u96c6\u77e5\u8bc6\u4ea7\u6743\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u540e\u95e8\u7684\u6570\u636e\u96c6\u6240\u6709\u6743\u9a8c\u8bc1\u65b9\u6cd5\u5b58\u5728\u56fa\u6709\u5c40\u9650\uff1a\u6bd2\u6807\u7b7e\u6c34\u5370\u56e0\u6807\u7b7e\u4e0d\u4e00\u81f4\u6613\u88ab\u68c0\u6d4b\uff0c\u5e72\u51c0\u6807\u7b7e\u6c34\u5370\u6280\u672f\u590d\u6742\u5ea6\u9ad8\u4e14\u5728\u9ad8\u8d28\u91cf\u56fe\u50cf\u4e0a\u6613\u5931\u8d25\uff0c\u4e14\u4e24\u79cd\u65b9\u6cd5\u90fd\u4f7f\u7528\u6613\u88ab\u68c0\u6d4b\u548c\u79fb\u9664\u7684\u9759\u6001\u6c34\u5370\u6a21\u5f0f\u3002", "method": "\u8bad\u7ec3U-Net\u6c34\u5370\u751f\u6210\u5668\u4e3a\u6bcf\u4e2a\u6837\u672c\u751f\u6210\u72ec\u7279\u6c34\u5370\uff0c\u8bbe\u8ba1\u5305\u542b\u76ee\u6807\u6837\u672c\u635f\u5931\u3001\u975e\u76ee\u6807\u6837\u672c\u635f\u5931\u548c\u611f\u77e5\u76f8\u4f3c\u6027\u635f\u5931\u7684\u590d\u5408\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u9ed1\u76d2\u6d4b\u8bd5\u9a8c\u8bc1\u53ef\u7591\u6a21\u578b\u662f\u5426\u8868\u73b0\u51fa\u9884\u5b9a\u4e49\u7684\u540e\u95e8\u884c\u4e3a\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u6709\u6548\uff0c\u5e76\u5bf9\u6f5c\u5728\u7684\u6c34\u5370\u79fb\u9664\u653b\u51fb\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "SSCL-BW\u65b9\u6cd5\u901a\u8fc7\u6837\u672c\u7279\u5b9a\u6c34\u5370\u751f\u6210\u548c\u590d\u5408\u635f\u5931\u51fd\u6570\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u6240\u6709\u6743\u9a8c\u8bc1\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u6570\u636e\u96c6\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.26238", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26238", "abs": "https://arxiv.org/abs/2510.26238", "authors": ["Duc-Hai Nguyen", "Vijayakumar Nanjappan", "Barry O'Sullivan", "Hoang D. Nguyen"], "title": "Questionnaire meets LLM: A Benchmark and Empirical Study of Structural Skills for Understanding Questions and Responses", "comment": "14 pages, 3 figures, 8 tables", "summary": "Millions of people take surveys every day, from market polls and academic\nstudies to medical questionnaires and customer feedback forms. These datasets\ncapture valuable insights, but their scale and structure present a unique\nchallenge for large language models (LLMs), which otherwise excel at few-shot\nreasoning over open-ended text. Yet, their ability to process questionnaire\ndata or lists of questions crossed with hundreds of respondent rows remains\nunderexplored. Current retrieval and survey analysis tools (e.g., Qualtrics,\nSPSS, REDCap) are typically designed for humans in the workflow, limiting such\ndata integration with LLM and AI-empowered automation. This gap leaves\nscientists, surveyors, and everyday users without evidence-based guidance on\nhow to best represent questionnaires for LLM consumption. We address this by\nintroducing QASU (Questionnaire Analysis and Structural Understanding), a\nbenchmark that probes six structural skills, including answer lookup,\nrespondent count, and multi-hop inference, across six serialization formats and\nmultiple prompt strategies. Experiments on contemporary LLMs show that choosing\nan effective format and prompt combination can improve accuracy by up to 8.8%\npoints compared to suboptimal formats. For specific tasks, carefully adding a\nlightweight structural hint through self-augmented prompting can yield further\nimprovements of 3-4% points on average. By systematically isolating format and\nprompting effects, our open source benchmark offers a simple yet versatile\nfoundation for advancing both research and real-world practice in LLM-based\nquestionnaire analysis.", "AI": {"tldr": "QASU\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u95ee\u5377\u6570\u636e\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u516d\u79cd\u5e8f\u5217\u5316\u683c\u5f0f\u548c\u591a\u79cd\u63d0\u793a\u7b56\u7565\u6d4b\u8bd5\u516d\u79cd\u7ed3\u6784\u6280\u80fd\uff0c\u7ed3\u679c\u663e\u793a\u9009\u62e9\u5408\u9002\u7684\u683c\u5f0f\u548c\u63d0\u793a\u7ec4\u5408\u53ef\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u95ee\u5377\u6570\u636e\u89c4\u6a21\u5e9e\u5927\u4f46\u7ed3\u6784\u590d\u6742\uff0c\u73b0\u6709\u5de5\u5177\u4e3b\u8981\u9762\u5411\u4eba\u5de5\u64cd\u4f5c\uff0c\u7f3a\u4e4f\u4e0eLLM\u96c6\u6210\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u7814\u7a76\u4eba\u5458\u548c\u7528\u6237\u7f3a\u4e4f\u5982\u4f55\u6700\u4f73\u8868\u793a\u95ee\u5377\u6570\u636e\u4f9bLLM\u4f7f\u7528\u7684\u6307\u5bfc\u3002", "method": "\u5f00\u53d1QASU\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u516d\u79cd\u7ed3\u6784\u6280\u80fd\u8bc4\u4f30\uff08\u5982\u7b54\u6848\u67e5\u627e\u3001\u53d7\u8bbf\u8005\u8ba1\u6570\u3001\u591a\u8df3\u63a8\u7406\uff09\uff0c\u91c7\u7528\u516d\u79cd\u5e8f\u5217\u5316\u683c\u5f0f\u548c\u591a\u79cd\u63d0\u793a\u7b56\u7565\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5305\u62ec\u81ea\u589e\u5f3a\u63d0\u793a\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u9009\u62e9\u6709\u6548\u7684\u683c\u5f0f\u548c\u63d0\u793a\u7ec4\u5408\u53ef\u5c06\u51c6\u786e\u7387\u63d0\u9ad8\u9ad8\u8fbe8.8\u4e2a\u767e\u5206\u70b9\uff1b\u5bf9\u4e8e\u7279\u5b9a\u4efb\u52a1\uff0c\u901a\u8fc7\u81ea\u589e\u5f3a\u63d0\u793a\u6dfb\u52a0\u8f7b\u91cf\u7ea7\u7ed3\u6784\u63d0\u793a\u53ef\u5e73\u5747\u63d0\u53473-4\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "QASU\u57fa\u51c6\u901a\u8fc7\u7cfb\u7edf\u9694\u79bb\u683c\u5f0f\u548c\u63d0\u793a\u6548\u5e94\uff0c\u4e3a\u57fa\u4e8eLLM\u7684\u95ee\u5377\u5206\u6790\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7b80\u5355\u800c\u591a\u529f\u80fd\u7684\u57fa\u7840\u6846\u67b6\u3002"}}
{"id": "2510.26523", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.26523", "abs": "https://arxiv.org/abs/2510.26523", "authors": ["Shuaishuai Liu", "Gergely Acs", "Gergely Bicz\u00f3k"], "title": "Interdependent Privacy in Smart Homes: Hunting for Bystanders in Privacy Policies", "comment": "18 pages, 2 figures", "summary": "Smart home devices such as video doorbells and security cameras are becoming\nincreasingly common in everyday life. While these devices offer convenience and\nsafety, they also raise new privacy concerns: how these devices affect others,\nlike neighbors, visitors, or people passing by. This issue is generally known\nas interdependent privacy, where one person's actions (or inaction) may impact\nthe privacy of others, and, specifically, bystander privacy in the context of\nsmart homes. Given lax data protection regulations in terms of shared physical\nspaces and amateur joint data controllers, we expect that the privacy policies\nof smart home products reflect the missing regulatory incentives. This paper\npresents a focused privacy policy analysis of 20 video doorbell and smart\ncamera products, concentrating explicitly on the bystander aspect. We show that\nalthough some of the vendors acknowledge bystanders, they address it only to\nthe extent of including disclaimers, shifting the ethical responsibility for\ncollecting the data of non-users to the device owner. In addition, we identify\nand examine real-world cases related to bystander privacy, demonstrating how\ncurrent deployments can impact non-users. Based on our findings, we analyze\nvendor privacy policies in light of existing legal frameworks and technical\ncapabilities, and we provide practical recommendations for both policy language\nand system design to enhance transparency and empower both bystanders and\ndevice owners.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e8620\u6b3e\u89c6\u9891\u95e8\u94c3\u548c\u667a\u80fd\u6444\u50cf\u5934\u7684\u9690\u79c1\u653f\u7b56\uff0c\u91cd\u70b9\u5173\u6ce8\u65c1\u89c2\u8005\u9690\u79c1\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0\u867d\u7136\u90e8\u5206\u5382\u5546\u627f\u8ba4\u65c1\u89c2\u8005\u5b58\u5728\uff0c\u4f46\u4ec5\u901a\u8fc7\u514d\u8d23\u58f0\u660e\u5c06\u6536\u96c6\u975e\u7528\u6237\u6570\u636e\u7684\u9053\u5fb7\u8d23\u4efb\u8f6c\u79fb\u7ed9\u8bbe\u5907\u6240\u6709\u8005\u3002", "motivation": "\u667a\u80fd\u5bb6\u5c45\u8bbe\u5907\uff08\u5982\u89c6\u9891\u95e8\u94c3\u548c\u5b89\u5168\u6444\u50cf\u5934\uff09\u65e5\u76ca\u666e\u53ca\uff0c\u867d\u7136\u63d0\u4f9b\u4fbf\u5229\u548c\u5b89\u5168\uff0c\u4f46\u4e5f\u5f15\u53d1\u65b0\u7684\u9690\u79c1\u62c5\u5fe7\uff1a\u8fd9\u4e9b\u8bbe\u5907\u5982\u4f55\u5f71\u54cd\u90bb\u5c45\u3001\u8bbf\u5ba2\u6216\u8def\u8fc7\u8005\u7b49\u4ed6\u4eba\u7684\u9690\u79c1\u3002\u8fd9\u4e2a\u95ee\u9898\u88ab\u79f0\u4e3a\u76f8\u4e92\u4f9d\u8d56\u9690\u79c1\uff0c\u5373\u4e00\u4e2a\u4eba\u7684\u884c\u4e3a\u53ef\u80fd\u5f71\u54cd\u4ed6\u4eba\u7684\u9690\u79c1\u3002", "method": "\u5bf920\u6b3e\u89c6\u9891\u95e8\u94c3\u548c\u667a\u80fd\u6444\u50cf\u5934\u4ea7\u54c1\u8fdb\u884c\u805a\u7126\u9690\u79c1\u653f\u7b56\u5206\u6790\uff0c\u7279\u522b\u5173\u6ce8\u65c1\u89c2\u8005\u65b9\u9762\u3002\u540c\u65f6\u8bc6\u522b\u548c\u68c0\u67e5\u4e0e\u65c1\u89c2\u8005\u9690\u79c1\u76f8\u5173\u7684\u771f\u5b9e\u6848\u4f8b\uff0c\u5c55\u793a\u5f53\u524d\u90e8\u7f72\u5982\u4f55\u5f71\u54cd\u975e\u7528\u6237\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u867d\u7136\u90e8\u5206\u5382\u5546\u627f\u8ba4\u65c1\u89c2\u8005\u5b58\u5728\uff0c\u4f46\u4ec5\u901a\u8fc7\u514d\u8d23\u58f0\u660e\u5c06\u6536\u96c6\u975e\u7528\u6237\u6570\u636e\u7684\u9053\u5fb7\u8d23\u4efb\u8f6c\u79fb\u7ed9\u8bbe\u5907\u6240\u6709\u8005\u3002\u901a\u8fc7\u771f\u5b9e\u6848\u4f8b\u5c55\u793a\u4e86\u5f53\u524d\u90e8\u7f72\u5bf9\u975e\u7528\u6237\u7684\u5f71\u54cd\u3002", "conclusion": "\u57fa\u4e8e\u7814\u7a76\u7ed3\u679c\uff0c\u5206\u6790\u73b0\u6709\u6cd5\u5f8b\u6846\u67b6\u548c\u6280\u672f\u80fd\u529b\u4e0b\u7684\u5382\u5546\u9690\u79c1\u653f\u7b56\uff0c\u4e3a\u653f\u7b56\u8bed\u8a00\u548c\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u5b9e\u7528\u5efa\u8bae\uff0c\u4ee5\u589e\u5f3a\u900f\u660e\u5ea6\u5e76\u8d4b\u4e88\u65c1\u89c2\u8005\u548c\u8bbe\u5907\u6240\u6709\u8005\u66f4\u591a\u6743\u529b\u3002"}}
{"id": "2510.26620", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.26620", "abs": "https://arxiv.org/abs/2510.26620", "authors": ["Nicholas Pecka", "Lotfi Ben Othmane", "Renee Bryce"], "title": "Toward Automated Security Risk Detection in Large Software Using Call Graph Analysis", "comment": null, "summary": "Threat modeling plays a critical role in the identification and mitigation of\nsecurity risks; however, manual approaches are often labor intensive and prone\nto error. This paper investigates the automation of software threat modeling\nthrough the clustering of call graphs using density-based and community\ndetection algorithms, followed by an analysis of the threats associated with\nthe identified clusters. The proposed method was evaluated through a case study\nof the Splunk Forwarder Operator (SFO), wherein selected clustering metrics\nwere applied to the software's call graph to assess pertinent code-density\nsecurity weaknesses. The results demonstrate the viability of the approach and\nunderscore its potential to facilitate systematic threat assessment. This work\ncontributes to the advancement of scalable, semi-automated threat modeling\nframeworks tailored for modern cloud-native environments.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u901a\u8fc7\u4f7f\u7528\u57fa\u4e8e\u5bc6\u5ea6\u548c\u793e\u533a\u68c0\u6d4b\u7b97\u6cd5\u5bf9\u8c03\u7528\u56fe\u8fdb\u884c\u805a\u7c7b\uff0c\u7136\u540e\u5206\u6790\u8bc6\u522b\u51fa\u7684\u96c6\u7fa4\u76f8\u5173\u5a01\u80c1\uff0c\u5b9e\u73b0\u8f6f\u4ef6\u5a01\u80c1\u5efa\u6a21\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5728Splunk Forwarder Operator\u6848\u4f8b\u7814\u7a76\u4e2d\u5f97\u5230\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u5176\u53ef\u884c\u6027\u3002", "motivation": "\u624b\u52a8\u5a01\u80c1\u5efa\u6a21\u65b9\u6cd5\u901a\u5e38\u52b3\u52a8\u5bc6\u96c6\u4e14\u5bb9\u6613\u51fa\u9519\uff0c\u9700\u8981\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728\u73b0\u4ee3\u4e91\u539f\u751f\u73af\u5883\u4e2d\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5bc6\u5ea6\u548c\u793e\u533a\u68c0\u6d4b\u7b97\u6cd5\u5bf9\u8f6f\u4ef6\u8c03\u7528\u56fe\u8fdb\u884c\u805a\u7c7b\uff0c\u7136\u540e\u5206\u6790\u8bc6\u522b\u51fa\u7684\u96c6\u7fa4\u76f8\u5173\u5a01\u80c1\u3002", "result": "\u5728Splunk Forwarder Operator\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u5e94\u7528\u9009\u5b9a\u7684\u805a\u7c7b\u6307\u6807\u8bc4\u4f30\u4ee3\u7801\u5bc6\u5ea6\u5b89\u5168\u5f31\u70b9\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u63a8\u8fdb\u4e3a\u73b0\u4ee3\u4e91\u539f\u751f\u73af\u5883\u91cf\u8eab\u5b9a\u5236\u7684\u53ef\u6269\u5c55\u534a\u81ea\u52a8\u5316\u5a01\u80c1\u5efa\u6a21\u6846\u67b6\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.26346", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26346", "abs": "https://arxiv.org/abs/2510.26346", "authors": ["Robin Schm\u00f6cker", "Alexander Dockhorn", "Bodo Rosenhahn"], "title": "Discovering State Equivalences in UCT Search Trees By Action Pruning", "comment": null, "summary": "One approach to enhance Monte Carlo Tree Search (MCTS) is to improve its\nsample efficiency by grouping/abstracting states or state-action pairs and\nsharing statistics within a group. Though state-action pair abstractions are\nmostly easy to find in algorithms such as On the Go Abstractions in Upper\nConfidence bounds applied to Trees (OGA-UCT), nearly no state abstractions are\nfound in either noisy or large action space settings due to constraining\nconditions. We provide theoretical and empirical evidence for this claim, and\nwe slightly alleviate this state abstraction problem by proposing a weaker\nstate abstraction condition that trades a minor loss in accuracy for finding\nmany more abstractions. We name this technique Ideal Pruning Abstractions in\nUCT (IPA-UCT), which outperforms OGA-UCT (and any of its derivatives) across a\nlarge range of test domains and iteration budgets as experimentally validated.\nIPA-UCT uses a different abstraction framework from Abstraction of State-Action\nPairs (ASAP) which is the one used by OGA-UCT, which we name IPA. Furthermore,\nwe show that both IPA and ASAP are special cases of a more general framework\nthat we call p-ASAP which itself is a special case of the ASASAP framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aIPA-UCT\u7684\u65b0\u6280\u672f\uff0c\u901a\u8fc7\u5f31\u5316\u72b6\u6001\u62bd\u8c61\u6761\u4ef6\u6765\u589e\u5f3aMCTS\u7684\u6837\u672c\u6548\u7387\uff0c\u5728\u591a\u79cd\u6d4b\u8bd5\u9886\u57df\u548c\u8fed\u4ee3\u9884\u7b97\u4e0b\u4f18\u4e8e\u73b0\u6709\u7684OGA-UCT\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u72b6\u6001-\u52a8\u4f5c\u5bf9\u62bd\u8c61\u65b9\u6cd5\uff08\u5982OGA-UCT\uff09\u5728\u566a\u58f0\u6216\u5927\u52a8\u4f5c\u7a7a\u95f4\u8bbe\u7f6e\u4e2d\u96be\u4ee5\u627e\u5230\u72b6\u6001\u62bd\u8c61\uff0c\u9650\u5236\u4e86MCTS\u7684\u6837\u672c\u6548\u7387\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u4e86IPA-UCT\u6280\u672f\uff0c\u4f7f\u7528\u8f83\u5f31\u7684\u7406\u60f3\u526a\u679d\u62bd\u8c61\uff08IPA\uff09\u6761\u4ef6\uff0c\u5728\u7cbe\u5ea6\u8f7b\u5fae\u635f\u5931\u7684\u60c5\u51b5\u4e0b\u627e\u5230\u66f4\u591a\u62bd\u8c61\u3002IPA\u548cASAP\u90fd\u662f\u66f4\u901a\u7528\u6846\u67b6p-ASAP\u7684\u7279\u6b8a\u60c5\u51b5\u3002", "result": "IPA-UCT\u5728\u5e7f\u6cdb\u7684\u6d4b\u8bd5\u9886\u57df\u548c\u8fed\u4ee3\u9884\u7b97\u4e0b\u5b9e\u9a8c\u9a8c\u8bc1\u4f18\u4e8eOGA-UCT\u53ca\u5176\u884d\u751f\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u653e\u677e\u72b6\u6001\u62bd\u8c61\u6761\u4ef6\uff0cIPA-UCT\u80fd\u591f\u627e\u5230\u66f4\u591a\u6709\u6548\u7684\u62bd\u8c61\uff0c\u663e\u8457\u63d0\u5347MCTS\u6027\u80fd\uff0c\u4e3a\u72b6\u6001\u62bd\u8c61\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.26374", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26374", "abs": "https://arxiv.org/abs/2510.26374", "authors": ["Qianli Shen", "Daoyuan Chen", "Yilun Huang", "Zhenqing Ling", "Yaliang Li", "Bolin Ding", "Jingren Zhou"], "title": "BOTS: A Unified Framework for Bayesian Online Task Selection in LLM Reinforcement Finetuning", "comment": null, "summary": "Reinforcement finetuning (RFT) is a key technique for aligning Large Language\nModels (LLMs) with human preferences and enhancing reasoning, yet its\neffectiveness is highly sensitive to which tasks are explored during training.\nUniform task sampling is inefficient, wasting computation on tasks that are\neither trivial or unsolvable, while existing task selection methods often\nsuffer from high rollout costs, poor adaptivity, or incomplete evidence. We\nintroduce \\textbf{BOTS}, a unified framework for \\textbf{B}ayesian\n\\textbf{O}nline \\textbf{T}ask \\textbf{S}election in LLM reinforcement\nfinetuning. Grounded in Bayesian inference, BOTS adaptively maintains posterior\nestimates of task difficulty as the model evolves. It jointly incorporates\n\\emph{explicit evidence} from direct evaluations of selected tasks and\n\\emph{implicit evidence} inferred from these evaluations for unselected tasks,\nwith Thompson sampling ensuring a principled balance between exploration and\nexploitation. To make implicit evidence practical, we instantiate it with an\nultra-light interpolation-based plug-in that estimates difficulties of\nunevaluated tasks without extra rollouts, adding negligible overhead.\nEmpirically, across diverse domains and LLM scales, BOTS consistently improves\ndata efficiency and performance over baselines and ablations, providing a\npractical and extensible solution for dynamic task selection in RFT.", "AI": {"tldr": "BOTS\u662f\u4e00\u4e2a\u7528\u4e8eLLM\u5f3a\u5316\u5fae\u8c03\u7684\u8d1d\u53f6\u65af\u5728\u7ebf\u4efb\u52a1\u9009\u62e9\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7ef4\u62a4\u4efb\u52a1\u96be\u5ea6\u540e\u9a8c\u4f30\u8ba1\uff0c\u7ed3\u5408\u663e\u5f0f\u548c\u9690\u5f0f\u8bc1\u636e\uff0c\u4f7f\u7528Thompson\u91c7\u6837\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u63d0\u9ad8\u6570\u636e\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5fae\u8c03\u65b9\u6cd5\u5728\u4efb\u52a1\u9009\u62e9\u4e0a\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u3001\u6210\u672c\u9ad8\u3001\u9002\u5e94\u6027\u5dee\u6216\u8bc1\u636e\u4e0d\u5b8c\u6574\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u4efb\u52a1\u9009\u62e9\u7b56\u7565\u6765\u4f18\u5316\u8bad\u7ec3\u8fc7\u7a0b\u3002", "method": "\u57fa\u4e8e\u8d1d\u53f6\u65af\u63a8\u65ad\u6846\u67b6\uff0c\u7ef4\u62a4\u4efb\u52a1\u96be\u5ea6\u540e\u9a8c\u4f30\u8ba1\uff0c\u7ed3\u5408\u76f4\u63a5\u8bc4\u4f30\u7684\u663e\u5f0f\u8bc1\u636e\u548c\u901a\u8fc7\u63d2\u503c\u63a8\u65ad\u7684\u9690\u5f0f\u8bc1\u636e\uff0c\u4f7f\u7528Thompson\u91c7\u6837\u8fdb\u884c\u4efb\u52a1\u9009\u62e9\uff0c\u65e0\u9700\u989d\u5916rollout\u5f00\u9500\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u548c\u4e0d\u540c\u89c4\u6a21\u7684LLM\u4e0a\uff0cBOTS\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u548c\u6d88\u878d\u5b9e\u9a8c\uff0c\u5728\u6570\u636e\u6548\u7387\u548c\u6027\u80fd\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "BOTS\u4e3aRFT\u4e2d\u7684\u52a8\u6001\u4efb\u52a1\u9009\u62e9\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2510.26380", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26380", "abs": "https://arxiv.org/abs/2510.26380", "authors": ["Yuanhang Liu", "Beichen Wang", "Peng Li", "Yang Liu"], "title": "AI Mathematician as a Partner in Advancing Mathematical Discovery - A Case Study in Homogenization Theory", "comment": "52 pages, 1 figure", "summary": "Artificial intelligence (AI) has demonstrated impressive progress in\nmathematical reasoning, yet its integration into the practice of mathematical\nresearch remains limited. In this study, we investigate how the AI\nMathematician (AIM) system can operate as a research partner rather than a mere\nproblem solver. Focusing on a challenging problem in homogenization theory, we\nanalyze the autonomous reasoning trajectories of AIM and incorporate targeted\nhuman interventions to structure the discovery process. Through iterative\ndecomposition of the problem into tractable subgoals, selection of appropriate\nanalytical methods, and validation of intermediate results, we reveal how human\nintuition and machine computation can complement one another. This\ncollaborative paradigm enhances the reliability, transparency, and\ninterpretability of the resulting proofs, while retaining human oversight for\nformal rigor and correctness. The approach leads to a complete and verifiable\nproof, and more broadly, demonstrates how systematic human-AI co-reasoning can\nadvance the frontier of mathematical discovery.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u4e86AI\u6570\u5b66\u5bb6\u7cfb\u7edf\u4f5c\u4e3a\u7814\u7a76\u4f19\u4f34\u800c\u975e\u5355\u7eaf\u95ee\u9898\u89e3\u51b3\u8005\u7684\u89d2\u8272\uff0c\u901a\u8fc7\u4eba\u7c7b\u4e0eAI\u7684\u534f\u4f5c\u63a8\u7406\uff0c\u5728\u5747\u8d28\u5316\u7406\u8bba\u4e2d\u5b8c\u6210\u4e86\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\u8bc1\u660e\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u6570\u5b66\u7814\u7a76\u5b9e\u8df5\u4e2d\u7684\u5e94\u7528\u4ecd\u7136\u6709\u9650\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22AI\u5982\u4f55\u4f5c\u4e3a\u7814\u7a76\u4f19\u4f34\u4e0e\u4eba\u7c7b\u534f\u4f5c\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u4f5c\u4e3a\u95ee\u9898\u89e3\u51b3\u5de5\u5177\u3002", "method": "\u901a\u8fc7\u5206\u6790AI\u7684\u81ea\u4e3b\u63a8\u7406\u8f68\u8ff9\uff0c\u7ed3\u5408\u9488\u5bf9\u6027\u7684\u4eba\u7c7b\u5e72\u9884\u6765\u7ed3\u6784\u5316\u53d1\u73b0\u8fc7\u7a0b\u3002\u91c7\u7528\u8fed\u4ee3\u5206\u89e3\u95ee\u9898\u4e3a\u53ef\u5904\u7406\u7684\u5b50\u76ee\u6807\u3001\u9009\u62e9\u9002\u5f53\u7684\u5206\u6790\u65b9\u6cd5\u4ee5\u53ca\u9a8c\u8bc1\u4e2d\u95f4\u7ed3\u679c\u7684\u65b9\u6cd5\u3002", "result": "\u6210\u529f\u5b8c\u6210\u4e86\u4e00\u4e2a\u5b8c\u6574\u4e14\u53ef\u9a8c\u8bc1\u7684\u8bc1\u660e\uff0c\u5c55\u793a\u4e86\u4eba\u7c7b\u76f4\u89c9\u4e0e\u673a\u5668\u8ba1\u7b97\u5982\u4f55\u76f8\u4e92\u8865\u5145\uff0c\u63d0\u9ad8\u4e86\u8bc1\u660e\u7684\u53ef\u9760\u6027\u3001\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u7cfb\u7edf\u5316\u7684\u4eba\u673a\u534f\u4f5c\u63a8\u7406\u80fd\u591f\u63a8\u8fdb\u6570\u5b66\u53d1\u73b0\u7684\u524d\u6cbf\uff0c\u8fd9\u79cd\u534f\u4f5c\u8303\u5f0f\u5728\u4fdd\u6301\u4eba\u7c7b\u5bf9\u5f62\u5f0f\u4e25\u8c28\u6027\u548c\u6b63\u786e\u6027\u76d1\u7763\u7684\u540c\u65f6\uff0c\u589e\u5f3a\u4e86\u6570\u5b66\u8bc1\u660e\u7684\u8d28\u91cf\u3002"}}
{"id": "2510.26384", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26384", "abs": "https://arxiv.org/abs/2510.26384", "authors": ["Andrew M. Bean", "Nabeel Seedat", "Shengzhuang Chen", "Jonathan Richard Schwarz"], "title": "Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings", "comment": "9 pages, 2 figures, 4 tables", "summary": "The prohibitive cost of evaluating large language models (LLMs) on\ncomprehensive benchmarks necessitates the creation of small yet representative\ndata subsets (i.e., tiny benchmarks) that enable efficient assessment while\nretaining predictive fidelity. Current methods for this task operate under a\nmodel-centric paradigm, selecting benchmarking items based on the collective\nperformance of existing models. Such approaches are limited by large upfront\ncosts, an inability to immediately handle new benchmarks (`cold-start'), and\nthe fragile assumption that future models will share the failure patterns of\ntheir predecessors. In this work, we challenge this paradigm and propose a\nitem-centric approach to benchmark subset selection, arguing that selection\nshould be based on the intrinsic properties of the task items themselves,\nrather than on model-specific failure patterns. We instantiate this\nitem-centric efficient benchmarking approach via a novel method, Scales++,\nwhere data selection is based on the cognitive demands of the benchmark\nsamples. Empirically, we show Scales++ reduces the upfront selection cost by\nover 18x while achieving competitive predictive fidelity. On the Open LLM\nLeaderboard, using just a 0.5\\% data subset, we predict full benchmark scores\nwith a 2.9% mean absolute error. We demonstrate that this item-centric approach\nenables more efficient model evaluation without significant fidelity\ndegradation, while also providing better cold-start performance and more\ninterpretable benchmarking.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9879\u76ee\u8ba4\u77e5\u9700\u6c42\u7684\u6570\u636e\u9009\u62e9\u65b9\u6cd5Scales++\uff0c\u7528\u4e8e\u521b\u5efa\u5c0f\u578b\u4f46\u5177\u6709\u4ee3\u8868\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b50\u96c6\uff0c\u663e\u8457\u964d\u4f4e\u8bc4\u4f30\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6a21\u578b\u6027\u80fd\u7684\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u5b58\u5728\u9ad8\u521d\u59cb\u6210\u672c\u3001\u65e0\u6cd5\u5904\u7406\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff08\u51b7\u542f\u52a8\u95ee\u9898\uff09\u4ee5\u53ca\u4f9d\u8d56\u73b0\u6709\u6a21\u578b\u5931\u8d25\u6a21\u5f0f\u7684\u8106\u5f31\u5047\u8bbe\u7b49\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u9879\u76ee\u4e2d\u5fc3\u7684\u65b9\u6cd5\uff0c\u57fa\u4e8e\u4efb\u52a1\u9879\u76ee\u7684\u5185\u5728\u5c5e\u6027\u800c\u975e\u6a21\u578b\u7279\u5b9a\u5931\u8d25\u6a21\u5f0f\u8fdb\u884c\u6570\u636e\u9009\u62e9\uff0c\u901a\u8fc7Scales++\u65b9\u6cd5\u6839\u636e\u57fa\u51c6\u6837\u672c\u7684\u8ba4\u77e5\u9700\u6c42\u9009\u62e9\u6570\u636e\u3002", "result": "Scales++\u5c06\u521d\u59cb\u9009\u62e9\u6210\u672c\u964d\u4f4e18\u500d\u4ee5\u4e0a\uff0c\u5728\u4ec5\u4f7f\u75280.5%\u6570\u636e\u5b50\u96c6\u7684\u60c5\u51b5\u4e0b\uff0c\u5728Open LLM\u6392\u884c\u699c\u4e0a\u9884\u6d4b\u5b8c\u6574\u57fa\u51c6\u5f97\u5206\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4e3a2.9%\u3002", "conclusion": "\u9879\u76ee\u4e2d\u5fc3\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u6a21\u578b\u8bc4\u4f30\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u597d\u7684\u51b7\u542f\u52a8\u6027\u80fd\u548c\u66f4\u53ef\u89e3\u91ca\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e14\u4e0d\u4f1a\u663e\u8457\u964d\u4f4e\u4fdd\u771f\u5ea6\u3002"}}
{"id": "2510.26402", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26402", "abs": "https://arxiv.org/abs/2510.26402", "authors": ["Vikrant Sahu", "Gagan Raj Gupta", "Raghav Borikar", "Nitin Mane"], "title": "Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback in Programming Education", "comment": null, "summary": "The rapid growth of programming education has outpaced traditional assessment\ntools, leaving faculty with limited means to provide meaningful, scalable\nfeedback. Conventional autograders, while efficient, act as black-box systems\nthat simply return pass/fail results, offering little insight into student\nthinking or learning needs.\n  Autograder+ is designed to shift autograding from a purely summative process\nto a formative learning experience. It introduces two key capabilities:\nautomated feedback generation using a fine-tuned Large Language Model, and\nvisualization of student code submissions to uncover learning patterns. The\nmodel is fine-tuned on curated student code and expert feedback to ensure\npedagogically aligned, context-aware guidance.\n  In evaluation across 600 student submissions from multiple programming tasks,\nthe system produced feedback with strong semantic alignment to instructor\ncomments. For visualization, contrastively learned code embeddings trained on\n1,000 annotated submissions enable grouping solutions into meaningful clusters\nbased on functionality and approach. The system also supports prompt-pooling,\nallowing instructors to guide feedback style through selected prompt templates.\n  By integrating AI-driven feedback, semantic clustering, and interactive\nvisualization, Autograder+ reduces instructor workload while supporting\ntargeted instruction and promoting stronger learning outcomes.", "AI": {"tldr": "Autograder+\u662f\u4e00\u4e2aAI\u9a71\u52a8\u7684\u7f16\u7a0b\u4f5c\u4e1a\u81ea\u52a8\u8bc4\u5206\u7cfb\u7edf\uff0c\u901a\u8fc7\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6559\u5b66\u5bf9\u9f50\u7684\u53cd\u9988\uff0c\u5e76\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u4ee3\u7801\u5d4c\u5165\u8fdb\u884c\u8bed\u4e49\u805a\u7c7b\u53ef\u89c6\u5316\uff0c\u5c06\u4f20\u7edf\u603b\u7ed3\u6027\u8bc4\u4f30\u8f6c\u53d8\u4e3a\u5f62\u6210\u6027\u5b66\u4e60\u4f53\u9a8c\u3002", "motivation": "\u4f20\u7edf\u81ea\u52a8\u8bc4\u5206\u7cfb\u7edf\u4f5c\u4e3a\u9ed1\u76d2\u4ec5\u8fd4\u56de\u901a\u8fc7/\u5931\u8d25\u7ed3\u679c\uff0c\u65e0\u6cd5\u63d0\u4f9b\u5bf9\u5b66\u751f\u601d\u7ef4\u548c\u5b66\u4e60\u9700\u6c42\u7684\u6df1\u5165\u6d1e\u5bdf\uff0c\u7f16\u7a0b\u6559\u80b2\u7684\u5feb\u901f\u53d1\u5c55\u8d85\u51fa\u4e86\u4f20\u7edf\u8bc4\u4f30\u5de5\u5177\u7684\u80fd\u529b\u8303\u56f4\u3002", "method": "\u7cfb\u7edf\u91c7\u7528\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u81ea\u52a8\u5316\u53cd\u9988\uff0c\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u4ee3\u7801\u5d4c\u5165\u8fdb\u884c\u8bed\u4e49\u805a\u7c7b\u53ef\u89c6\u5316\uff0c\u5e76\u652f\u6301\u63d0\u793a\u6c60\u8ba9\u6559\u5e08\u6307\u5bfc\u53cd\u9988\u98ce\u683c\u3002", "result": "\u5728600\u4efd\u5b66\u751f\u63d0\u4ea4\u7684\u8bc4\u4f30\u4e2d\uff0c\u7cfb\u7edf\u751f\u6210\u7684\u53cd\u9988\u4e0e\u6559\u5e08\u8bc4\u8bba\u5177\u6709\u5f3a\u8bed\u4e49\u5bf9\u9f50\uff0c\u57fa\u4e8e1000\u4efd\u6807\u6ce8\u63d0\u4ea4\u8bad\u7ec3\u7684\u4ee3\u7801\u5d4c\u5165\u80fd\u591f\u6309\u529f\u80fd\u548c\u65b9\u6cd5\u7684\u76f8\u4f3c\u6027\u5c06\u89e3\u51b3\u65b9\u6848\u5206\u7ec4\u4e3a\u6709\u610f\u4e49\u7684\u805a\u7c7b\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408AI\u9a71\u52a8\u53cd\u9988\u3001\u8bed\u4e49\u805a\u7c7b\u548c\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\uff0cAutograder+\u5728\u51cf\u5c11\u6559\u5e08\u5de5\u4f5c\u91cf\u7684\u540c\u65f6\u652f\u6301\u9488\u5bf9\u6027\u6559\u5b66\uff0c\u4fc3\u8fdb\u66f4\u5f3a\u7684\u5b66\u4e60\u6210\u679c\u3002"}}
{"id": "2510.26411", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26411", "abs": "https://arxiv.org/abs/2510.26411", "authors": ["Riccardo Renzulli", "Colas Lepoutre", "Enrico Cassano", "Marco Grangetto"], "title": "MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders", "comment": null, "summary": "Artificial intelligence in healthcare requires models that are accurate and\ninterpretable. We advance mechanistic interpretability in medical vision by\napplying Medical Sparse Autoencoders (MedSAEs) to the latent space of MedCLIP,\na vision-language model trained on chest radiographs and reports. To quantify\ninterpretability, we propose an evaluation framework that combines correlation\nmetrics, entropy analyzes, and automated neuron naming via the MedGEMMA\nfoundation model. Experiments on the CheXpert dataset show that MedSAE neurons\nachieve higher monosemanticity and interpretability than raw MedCLIP features.\nOur findings bridge high-performing medical AI and transparency, offering a\nscalable step toward clinically reliable representations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u533b\u5b66\u7a00\u758f\u81ea\u7f16\u7801\u5668(MedSAEs)\u5e94\u7528\u4e8eMedCLIP\u6a21\u578b\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u901a\u8fc7\u76f8\u5173\u6027\u6307\u6807\u3001\u71b5\u5206\u6790\u548c\u81ea\u52a8\u795e\u7ecf\u5143\u547d\u540d\u6765\u91cf\u5316\u53ef\u89e3\u91ca\u6027\uff0c\u5728CheXpert\u6570\u636e\u96c6\u4e0a\u8bc1\u660eMedSAE\u795e\u7ecf\u5143\u6bd4\u539f\u59cbMedCLIP\u7279\u5f81\u5177\u6709\u66f4\u9ad8\u7684\u5355\u4e49\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u533b\u7597AI\u9700\u8981\u65e2\u51c6\u786e\u53c8\u53ef\u89e3\u91ca\u7684\u6a21\u578b\uff0c\u63a8\u8fdb\u533b\u5b66\u89c6\u89c9\u4e2d\u7684\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u3002", "method": "\u5c06\u533b\u5b66\u7a00\u758f\u81ea\u7f16\u7801\u5668(MedSAEs)\u5e94\u7528\u4e8eMedCLIP\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u63d0\u51fa\u7ed3\u5408\u76f8\u5173\u6027\u6307\u6807\u3001\u71b5\u5206\u6790\u548c\u901a\u8fc7MedGEMMA\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u81ea\u52a8\u795e\u7ecf\u5143\u547d\u540d\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u5728CheXpert\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cMedSAE\u795e\u7ecf\u5143\u6bd4\u539f\u59cbMedCLIP\u7279\u5f81\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5355\u4e49\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u8fde\u63a5\u4e86\u9ad8\u6027\u80fd\u533b\u7597AI\u4e0e\u900f\u660e\u5ea6\uff0c\u4e3a\u5b9e\u73b0\u4e34\u5e8a\u53ef\u9760\u8868\u793a\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6b65\u9aa4\u3002"}}
{"id": "2510.26418", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26418", "abs": "https://arxiv.org/abs/2510.26418", "authors": ["Jianli Zhao", "Tingchen Fu", "Rylan Schaeffer", "Mrinank Sharma", "Fazl Barez"], "title": "Chain-of-Thought Hijacking", "comment": null, "summary": "Large reasoning models (LRMs) achieve higher task performance by allocating\nmore inference-time compute, and prior works suggest this scaled reasoning may\nalso strengthen safety by improving refusal. Yet we find the opposite: the same\nreasoning can be used to bypass safeguards. We introduce Chain-of-Thought\nHijacking, a jailbreak attack on reasoning models. The attack pads harmful\nrequests with long sequences of harmless puzzle reasoning. Across HarmBench,\nCoT Hijacking reaches a 99%, 94%, 100%, and 94% attack success rate (ASR) on\nGemini 2.5 Pro, GPT o4 mini, Grok 3 mini, and Claude 4 Sonnet, respectively -\nfar exceeding prior jailbreak methods for LRMs. To understand the effectiveness\nof our attack, we turn to a mechanistic analysis, which shows that mid layers\nencode the strength of safety checking, while late layers encode the\nverification outcome. Long benign CoT dilutes both signals by shifting\nattention away from harmful tokens. Targeted ablations of attention heads\nidentified by this analysis causally decrease refusal, confirming their role in\na safety subnetwork. These results show that the most interpretable form of\nreasoning - explicit CoT - can itself become a jailbreak vector when combined\nwith final-answer cues. We release prompts, outputs, and judge decisions to\nfacilitate replication.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aChain-of-Thought Hijacking\u7684\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6709\u5bb3\u8bf7\u6c42\u524d\u6dfb\u52a0\u65e0\u5bb3\u7684\u63a8\u7406\u5e8f\u5217\u6765\u7ed5\u8fc7\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5b89\u5168\u9632\u62a4\uff0c\u5728\u591a\u4e2a\u4e3b\u6d41\u6a21\u578b\u4e0a\u8fbe\u5230\u6781\u9ad8\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8ba4\u4e3a\u63a8\u7406\u6a21\u578b\u7684\u6269\u5c55\u63a8\u7406\u80fd\u529b\u53ef\u80fd\u589e\u5f3a\u5b89\u5168\u6027\uff0c\u4f46\u4f5c\u8005\u53d1\u73b0\u540c\u6837\u7684\u63a8\u7406\u80fd\u529b\u4e5f\u53ef\u88ab\u7528\u4e8e\u7ed5\u8fc7\u5b89\u5168\u9632\u62a4\uff0c\u56e0\u6b64\u7814\u7a76\u63a8\u7406\u6a21\u578b\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u4f7f\u7528Chain-of-Thought Hijacking\u653b\u51fb\u65b9\u6cd5\uff0c\u5c06\u6709\u5bb3\u8bf7\u6c42\u4e0e\u957f\u5e8f\u5217\u7684\u65e0\u5bb3\u8c1c\u9898\u63a8\u7406\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u7a00\u91ca\u5b89\u5168\u68c0\u67e5\u4fe1\u53f7\u6765\u7ed5\u8fc7\u6a21\u578b\u7684\u5b89\u5168\u673a\u5236\u3002", "result": "\u5728HarmBench\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728Gemini 2.5 Pro\u3001GPT o4 mini\u3001Grok 3 mini\u548cClaude 4 Sonnet\u4e0a\u7684\u653b\u51fb\u6210\u529f\u7387\u5206\u522b\u8fbe\u523099%\u300194%\u3001100%\u548c94%\uff0c\u8fdc\u8d85\u73b0\u6709\u8d8a\u72f1\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u6700\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u5f62\u5f0f\u2014\u2014\u663e\u5f0f\u94fe\u5f0f\u601d\u7ef4\uff0c\u5728\u4e0e\u6700\u7ec8\u7b54\u6848\u7ebf\u7d22\u7ed3\u5408\u65f6\uff0c\u672c\u8eab\u53ef\u80fd\u6210\u4e3a\u8d8a\u72f1\u653b\u51fb\u7684\u8f7d\u4f53\uff0c\u63ed\u793a\u4e86\u63a8\u7406\u6a21\u578b\u7684\u5b89\u5168\u8106\u5f31\u6027\u3002"}}
{"id": "2510.26493", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26493", "abs": "https://arxiv.org/abs/2510.26493", "authors": ["Qishuo Hua", "Lyumanshan Ye", "Dayuan Fu", "Yang Xiao", "Xiaojie Cai", "Yunze Wu", "Jifan Lin", "Junfei Wang", "Pengfei Liu"], "title": "Context Engineering 2.0: The Context of Context Engineering", "comment": null, "summary": "Karl Marx once wrote that ``the human essence is the ensemble of social\nrelations'', suggesting that individuals are not isolated entities but are\nfundamentally shaped by their interactions with other entities, within which\ncontexts play a constitutive and essential role. With the advent of computers\nand artificial intelligence, these contexts are no longer limited to purely\nhuman--human interactions: human--machine interactions are included as well.\nThen a central question emerges: How can machines better understand our\nsituations and purposes? To address this challenge, researchers have recently\nintroduced the concept of context engineering. Although it is often regarded as\na recent innovation of the agent era, we argue that related practices can be\ntraced back more than twenty years. Since the early 1990s, the field has\nevolved through distinct historical phases, each shaped by the intelligence\nlevel of machines: from early human--computer interaction frameworks built\naround primitive computers, to today's human--agent interaction paradigms\ndriven by intelligent agents, and potentially to human--level or superhuman\nintelligence in the future. In this paper, we situate context engineering,\nprovide a systematic definition, outline its historical and conceptual\nlandscape, and examine key design considerations for practice. By addressing\nthese questions, we aim to offer a conceptual foundation for context\nengineering and sketch its promising future. This paper is a stepping stone for\na broader community effort toward systematic context engineering in AI systems.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6027\u5730\u5b9a\u4e49\u4e86\u60c5\u5883\u5de5\u7a0b\uff0c\u8ffd\u6eaf\u5176\u4ece1990\u5e74\u4ee3\u81f3\u4eca\u7684\u53d1\u5c55\u5386\u7a0b\uff0c\u63a2\u8ba8\u4e86\u4ece\u4eba\u673a\u4ea4\u4e92\u5230\u4eba-\u667a\u80fd\u4f53\u4ea4\u4e92\u7684\u6f14\u53d8\uff0c\u5e76\u5c55\u671b\u4e86\u672a\u6765\u4eba\u7c7b\u7ea7\u6216\u8d85\u4eba\u7c7b\u667a\u80fd\u7684\u60c5\u5883\u5de5\u7a0b\u524d\u666f\u3002", "motivation": "\u53d7\u9a6c\u514b\u601d\u5173\u4e8e\"\u4eba\u7684\u672c\u8d28\u662f\u793e\u4f1a\u5173\u7cfb\u603b\u548c\"\u7684\u542f\u53d1\uff0c\u968f\u7740\u8ba1\u7b97\u673a\u548c\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\uff0c\u60c5\u5883\u4e0d\u518d\u5c40\u9650\u4e8e\u7eaf\u7cb9\u7684\u4eba\u9645\u4e92\u52a8\uff0c\u4eba\u673a\u4e92\u52a8\u4e5f\u88ab\u5305\u542b\u5176\u4e2d\u3002\u6838\u5fc3\u95ee\u9898\u662f\u5982\u4f55\u8ba9\u673a\u5668\u66f4\u597d\u5730\u7406\u89e3\u4eba\u7c7b\u7684\u60c5\u5883\u548c\u76ee\u7684\u3002", "method": "\u901a\u8fc7\u5386\u53f2\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u5c06\u60c5\u5883\u5de5\u7a0b\u7684\u53d1\u5c55\u5212\u5206\u4e3a\u4e0d\u540c\u5386\u53f2\u9636\u6bb5\uff0c\u6bcf\u4e2a\u9636\u6bb5\u7531\u673a\u5668\u7684\u667a\u80fd\u6c34\u5e73\u5851\u9020\uff1a\u4ece\u56f4\u7ed5\u539f\u59cb\u8ba1\u7b97\u673a\u6784\u5efa\u7684\u65e9\u671f\u4eba\u673a\u4ea4\u4e92\u6846\u67b6\uff0c\u5230\u4eca\u5929\u7531\u667a\u80fd\u4f53\u9a71\u52a8\u7684\u4eba-\u667a\u80fd\u4f53\u4ea4\u4e92\u8303\u5f0f\uff0c\u4ee5\u53ca\u672a\u6765\u53ef\u80fd\u7684\u4eba\u7c7b\u7ea7\u6216\u8d85\u4eba\u7c7b\u667a\u80fd\u3002", "result": "\u63d0\u51fa\u4e86\u60c5\u5883\u5de5\u7a0b\u7684\u7cfb\u7edf\u6027\u5b9a\u4e49\uff0c\u52fe\u52d2\u4e86\u5176\u5386\u53f2\u548c\u6982\u5ff5\u56fe\u666f\uff0c\u5e76\u8003\u5bdf\u4e86\u5b9e\u8df5\u4e2d\u7684\u5173\u952e\u8bbe\u8ba1\u8003\u8651\u56e0\u7d20\u3002", "conclusion": "\u672c\u6587\u4e3a\u60c5\u5883\u5de5\u7a0b\u63d0\u4f9b\u4e86\u6982\u5ff5\u57fa\u7840\uff0c\u5e76\u63cf\u7ed8\u4e86\u5176\u6709\u524d\u666f\u7684\u672a\u6765\uff0c\u662f\u63a8\u52a8AI\u7cfb\u7edf\u4e2d\u7cfb\u7edf\u6027\u60c5\u5883\u5de5\u7a0b\u66f4\u5e7f\u6cdb\u793e\u533a\u52aa\u529b\u7684\u57ab\u811a\u77f3\u3002"}}
{"id": "2510.26518", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.26518", "abs": "https://arxiv.org/abs/2510.26518", "authors": ["Rishub Jain", "Sophie Bridgers", "Lili Janzer", "Rory Greig", "Tian Huey Teh", "Vladimir Mikulik"], "title": "Human-AI Complementarity: A Goal for Amplified Oversight", "comment": null, "summary": "Human feedback is critical for aligning AI systems to human values. As AI\ncapabilities improve and AI is used to tackle more challenging tasks, verifying\nquality and safety becomes increasingly challenging. This paper explores how we\ncan leverage AI to improve the quality of human oversight. We focus on an\nimportant safety problem that is already challenging for humans:\nfact-verification of AI outputs. We find that combining AI ratings and human\nratings based on AI rater confidence is better than relying on either alone.\nGiving humans an AI fact-verification assistant further improves their\naccuracy, but the type of assistance matters. Displaying AI explanation,\nconfidence, and labels leads to over-reliance, but just showing search results\nand evidence fosters more appropriate trust. These results have implications\nfor Amplified Oversight -- the challenge of combining humans and AI to\nsupervise AI systems even as they surpass human expert performance.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528AI\u63d0\u9ad8\u4eba\u7c7b\u76d1\u7763\u8d28\u91cf\uff0c\u91cd\u70b9\u5173\u6ce8AI\u8f93\u51fa\u7684\u4e8b\u5b9e\u9a8c\u8bc1\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u7ed3\u5408AI\u8bc4\u7ea7\u548c\u57fa\u4e8eAI\u8bc4\u5206\u8005\u7f6e\u4fe1\u5ea6\u7684\u4eba\u7c7b\u8bc4\u7ea7\u6bd4\u5355\u72ec\u4f7f\u7528\u4efb\u4e00\u65b9\u6cd5\u66f4\u597d\u3002AI\u4e8b\u5b9e\u9a8c\u8bc1\u52a9\u624b\u80fd\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4eba\u7c7b\u51c6\u786e\u6027\uff0c\u4f46\u8f85\u52a9\u65b9\u5f0f\u5f88\u91cd\u8981\u3002", "motivation": "\u968f\u7740AI\u80fd\u529b\u63d0\u5347\u548c\u5904\u7406\u66f4\u590d\u6742\u4efb\u52a1\uff0c\u9a8c\u8bc1\u8d28\u91cf\u548c\u5b89\u5168\u6027\u53d8\u5f97\u65e5\u76ca\u56f0\u96be\u3002\u9700\u8981\u63a2\u7d22\u5982\u4f55\u5229\u7528AI\u6539\u8fdb\u4eba\u7c7b\u76d1\u7763\u8d28\u91cf\uff0c\u7279\u522b\u662f\u9488\u5bf9\u4eba\u7c7b\u5df2\u96be\u4ee5\u80dc\u4efb\u7684\u4e8b\u5b9e\u9a8c\u8bc1\u95ee\u9898\u3002", "method": "\u7814\u7a76AI\u8bc4\u7ea7\u4e0e\u4eba\u7c7b\u8bc4\u7ea7\u7684\u7ed3\u5408\u65b9\u5f0f\uff0c\u6d4b\u8bd5\u4e0d\u540c\u7c7b\u578b\u7684AI\u8f85\u52a9\uff08\u5982\u663e\u793aAI\u89e3\u91ca\u3001\u7f6e\u4fe1\u5ea6\u3001\u6807\u7b7e\uff0c\u6216\u4ec5\u663e\u793a\u641c\u7d22\u7ed3\u679c\u548c\u8bc1\u636e\uff09\u5bf9\u4eba\u7c7b\u4e8b\u5b9e\u9a8c\u8bc1\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002", "result": "\u7ed3\u5408AI\u8bc4\u7ea7\u548c\u57fa\u4e8eAI\u7f6e\u4fe1\u5ea6\u7684\u4eba\u7c7b\u8bc4\u7ea7\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u4efb\u4e00\u65b9\u6cd5\u3002AI\u52a9\u624b\u80fd\u63d0\u9ad8\u4eba\u7c7b\u51c6\u786e\u6027\uff0c\u4f46\u663e\u793aAI\u89e3\u91ca\u3001\u7f6e\u4fe1\u5ea6\u548c\u6807\u7b7e\u4f1a\u5bfc\u81f4\u8fc7\u5ea6\u4f9d\u8d56\uff0c\u800c\u4ec5\u663e\u793a\u641c\u7d22\u7ed3\u679c\u548c\u8bc1\u636e\u80fd\u57f9\u517b\u66f4\u9002\u5f53\u7684\u4fe1\u4efb\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u653e\u5927\u76d1\u7763\uff08\u7ed3\u5408\u4eba\u7c7b\u548cAI\u6765\u76d1\u7763\u8d85\u8d8a\u4eba\u7c7b\u4e13\u5bb6\u6027\u80fd\u7684AI\u7cfb\u7edf\uff09\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u5f3a\u8c03\u4e86AI\u8f85\u52a9\u65b9\u5f0f\u5bf9\u5efa\u7acb\u9002\u5f53\u4eba\u673a\u4fe1\u4efb\u5173\u7cfb\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2510.26606", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26606", "abs": "https://arxiv.org/abs/2510.26606", "authors": ["Kentaro Ozeki", "Risako Ando", "Takanobu Morishita", "Hirohiko Abe", "Koji Mineshima", "Mitsuhiro Okada"], "title": "Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives", "comment": "Accepted to the 8th BlackboxNLP Workshop at EMNLP 2025", "summary": "Normative reasoning is a type of reasoning that involves normative or deontic\nmodality, such as obligation and permission. While large language models (LLMs)\nhave demonstrated remarkable performance across various reasoning tasks, their\nability to handle normative reasoning remains underexplored. In this paper, we\nsystematically evaluate LLMs' reasoning capabilities in the normative domain\nfrom both logical and modal perspectives. Specifically, to assess how well LLMs\nreason with normative modals, we make a comparison between their reasoning with\nnormative modals and their reasoning with epistemic modals, which share a\ncommon formal structure. To this end, we introduce a new dataset covering a\nwide range of formal patterns of reasoning in both normative and epistemic\ndomains, while also incorporating non-formal cognitive factors that influence\nhuman reasoning. Our results indicate that, although LLMs generally adhere to\nvalid reasoning patterns, they exhibit notable inconsistencies in specific\ntypes of normative reasoning and display cognitive biases similar to those\nobserved in psychological studies of human reasoning. These findings highlight\nchallenges in achieving logical consistency in LLMs' normative reasoning and\nprovide insights for enhancing their reliability. All data and code are\nreleased publicly at https://github.com/kmineshima/NeuBAROCO.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c4\u8303\u63a8\u7406\u9886\u57df\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u867d\u7136LLMs\u603b\u4f53\u4e0a\u9075\u5faa\u6709\u6548\u63a8\u7406\u6a21\u5f0f\uff0c\u4f46\u5728\u7279\u5b9a\u7c7b\u578b\u7684\u89c4\u8303\u63a8\u7406\u4e2d\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u5e76\u8868\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u63a8\u7406\u4e2d\u7684\u8ba4\u77e5\u504f\u5dee\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cd\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5728\u5904\u7406\u6d89\u53ca\u4e49\u52a1\u548c\u8bb8\u53ef\u7b49\u89c4\u8303\u6a21\u6001\u7684\u63a8\u7406\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u89c4\u8303\u548c\u8ba4\u77e5\u9886\u57df\u7684\u5e7f\u6cdb\u5f62\u5f0f\u63a8\u7406\u6a21\u5f0f\uff0c\u540c\u65f6\u7eb3\u5165\u5f71\u54cd\u4eba\u7c7b\u63a8\u7406\u7684\u975e\u5f62\u5f0f\u8ba4\u77e5\u56e0\u7d20\uff0c\u6bd4\u8f83LLMs\u5728\u89c4\u8303\u6a21\u6001\u548c\u8ba4\u77e5\u6a21\u6001\u63a8\u7406\u4e2d\u7684\u8868\u73b0\u3002", "result": "LLMs\u603b\u4f53\u4e0a\u9075\u5faa\u6709\u6548\u63a8\u7406\u6a21\u5f0f\uff0c\u4f46\u5728\u7279\u5b9a\u7c7b\u578b\u7684\u89c4\u8303\u63a8\u7406\u4e2d\u5b58\u5728\u663e\u8457\u4e0d\u4e00\u81f4\u6027\uff0c\u5e76\u8868\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u63a8\u7406\u4e2d\u7684\u8ba4\u77e5\u504f\u5dee\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u7a81\u663e\u4e86\u5728LLMs\u89c4\u8303\u63a8\u7406\u4e2d\u5b9e\u73b0\u903b\u8f91\u4e00\u81f4\u6027\u7684\u6311\u6218\uff0c\u4e3a\u589e\u5f3a\u5176\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2510.26658", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26658", "abs": "https://arxiv.org/abs/2510.26658", "authors": ["Zewen Chi", "Li Dong", "Qingxiu Dong", "Yaru Hao", "Xun Wu", "Shaohan Huang", "Furu Wei"], "title": "The Era of Agentic Organization: Learning to Organize with Language Models", "comment": null, "summary": "We envision a new era of AI, termed agentic organization, where agents solve\ncomplex problems by working collaboratively and concurrently, enabling outcomes\nbeyond individual intelligence. To realize this vision, we introduce\nasynchronous thinking (AsyncThink) as a new paradigm of reasoning with large\nlanguage models, which organizes the internal thinking process into\nconcurrently executable structures. Specifically, we propose a thinking\nprotocol where an organizer dynamically assigns sub-queries to workers, merges\nintermediate knowledge, and produces coherent solutions. More importantly, the\nthinking structure in this protocol can be further optimized through\nreinforcement learning. Experiments demonstrate that AsyncThink achieves 28%\nlower inference latency compared to parallel thinking while improving accuracy\non mathematical reasoning. Moreover, AsyncThink generalizes its learned\nasynchronous thinking capabilities, effectively tackling unseen tasks without\nadditional training.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.26721", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.26721", "abs": "https://arxiv.org/abs/2510.26721", "authors": ["Xinhan Zheng", "Huyu Wu", "Xueting Wang", "Haiyun Jiang"], "title": "Unveiling Intrinsic Text Bias in Multimodal Large Language Models through Attention Key-Space Analysis", "comment": null, "summary": "Multimodal large language models (MLLMs) exhibit a pronounced preference for\ntextual inputs when processing vision-language data, limiting their ability to\nreason effectively from visual evidence. Unlike prior studies that attribute\nthis text bias to external factors such as data imbalance or instruction\ntuning, we propose that the bias originates from the model's internal\narchitecture. Specifically, we hypothesize that visual key vectors (Visual\nKeys) are out-of-distribution (OOD) relative to the text key space learned\nduring language-only pretraining. Consequently, these visual keys receive\nsystematically lower similarity scores during attention computation, leading to\ntheir under-utilization in the context representation. To validate this\nhypothesis, we extract key vectors from LLaVA and Qwen2.5-VL and analyze their\ndistributional structures using qualitative (t-SNE) and quantitative\n(Jensen-Shannon divergence) methods. The results provide direct evidence that\nvisual and textual keys occupy markedly distinct subspaces within the attention\nspace. The inter-modal divergence is statistically significant, exceeding\nintra-modal variation by several orders of magnitude. These findings reveal\nthat text bias arises from an intrinsic misalignment within the attention key\nspace rather than solely from external data factors.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u6587\u672c\u504f\u597d\u95ee\u9898\uff0c\u5176\u6839\u6e90\u5728\u4e8e\u6a21\u578b\u5185\u90e8\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u89c6\u89c9\u952e\u5411\u91cf\u4e0e\u6587\u672c\u952e\u5411\u91cf\u5206\u5e03\u4e0d\u5339\u914d\uff0c\u5bfc\u81f4\u89c6\u89c9\u4fe1\u606f\u5728\u6ce8\u610f\u529b\u8ba1\u7b97\u4e2d\u88ab\u4f4e\u4f30\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u89c6\u89c9\u8bed\u8a00\u6570\u636e\u65f6\u8868\u73b0\u51fa\u660e\u663e\u7684\u6587\u672c\u504f\u597d\uff0c\u9650\u5236\u4e86\u5176\u57fa\u4e8e\u89c6\u89c9\u8bc1\u636e\u8fdb\u884c\u6709\u6548\u63a8\u7406\u7684\u80fd\u529b\u3002\u73b0\u6709\u7814\u7a76\u5c06\u6b64\u5f52\u56e0\u4e8e\u5916\u90e8\u56e0\u7d20\u5982\u6570\u636e\u4e0d\u5e73\u8861\u6216\u6307\u4ee4\u8c03\u4f18\uff0c\u4f46\u672c\u6587\u8ba4\u4e3a\u504f\u89c1\u6e90\u4e8e\u6a21\u578b\u5185\u90e8\u67b6\u6784\u3002", "method": "\u4eceLLaVA\u548cQwen2.5-VL\u6a21\u578b\u4e2d\u63d0\u53d6\u952e\u5411\u91cf\uff0c\u4f7f\u7528t-SNE\u53ef\u89c6\u5316\u548cJensen-Shannon\u6563\u5ea6\u7b49\u5b9a\u6027\u548c\u5b9a\u91cf\u65b9\u6cd5\u5206\u6790\u5176\u5206\u5e03\u7ed3\u6784\u3002", "result": "\u89c6\u89c9\u952e\u5411\u91cf\u548c\u6587\u672c\u952e\u5411\u91cf\u5728\u6ce8\u610f\u529b\u7a7a\u95f4\u4e2d\u5360\u636e\u660e\u663e\u4e0d\u540c\u7684\u5b50\u7a7a\u95f4\uff0c\u6a21\u6001\u95f4\u5dee\u5f02\u5728\u7edf\u8ba1\u4e0a\u663e\u8457\uff0c\u6bd4\u6a21\u6001\u5185\u53d8\u5f02\u9ad8\u51fa\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u6587\u672c\u504f\u89c1\u6e90\u4e8e\u6ce8\u610f\u529b\u952e\u7a7a\u95f4\u7684\u5185\u5728\u9519\u4f4d\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5916\u90e8\u6570\u636e\u56e0\u7d20\u3002"}}
{"id": "2510.26732", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26732", "abs": "https://arxiv.org/abs/2510.26732", "authors": ["J. de Curt\u00f2", "I. de Zarz\u00e0", "Pablo Garc\u00eda", "Jordi Cabot"], "title": "Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models", "comment": null, "summary": "This paper presents a comprehensive cross-platform evaluation of reasoning\ncapabilities in contemporary foundation models, establishing an\ninfrastructure-agnostic benchmark across three computational paradigms: HPC\nsupercomputing (MareNostrum 5), cloud platforms (Nebius AI Studio), and\nuniversity clusters (a node with eight H200 GPUs).\n  We evaluate 15 foundation models across 79 problems spanning eight academic\ndomains (Physics, Mathematics, Chemistry, Economics, Biology, Statistics,\nCalculus, and Optimization) through three experimental phases: (1) Baseline\nestablishment: Six models (Mixtral-8x7B, Phi-3, LLaMA 3.1-8B, Gemma-2-9b,\nMistral-7B, OLMo-7B) evaluated on 19 problems using MareNostrum 5, establishing\nmethodology and reference performance; (2) Infrastructure validation: The\n19-problem benchmark repeated on university cluster (seven models including\nFalcon-Mamba state-space architecture) and Nebius AI Studio (nine\nstate-of-the-art models: Hermes-4 70B/405B, LLaMA 3.1-405B/3.3-70B, Qwen3\n30B/235B, DeepSeek-R1, GPT-OSS 20B/120B) to confirm infrastructure-agnostic\nreproducibility; (3) Extended evaluation: Full 79-problem assessment on both\nuniversity cluster and Nebius platforms, probing generalization at scale across\narchitectural diversity.\n  The findings challenge conventional scaling assumptions, establish training\ndata quality as more critical than model size, and provide actionable\nguidelines for model selection across educational, production, and research\ncontexts. The tri-infrastructure methodology and 79-problem benchmark enable\nlongitudinal tracking of reasoning capabilities as foundation models evolve.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8de8\u5e73\u53f0\u7684\u57fa\u7840\u6a21\u578b\u63a8\u7406\u80fd\u529b\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u4e09\u79cd\u8ba1\u7b97\u8303\u5f0f\uff08HPC\u8d85\u7ea7\u8ba1\u7b97\u3001\u4e91\u5e73\u53f0\u3001\u5927\u5b66\u96c6\u7fa4\uff09\u4e0a\u8bc4\u4f30\u4e8615\u4e2a\u57fa\u7840\u6a21\u578b\u57288\u4e2a\u5b66\u672f\u9886\u57df\u768479\u4e2a\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u7684\u89c4\u6a21\u6269\u5c55\u5047\u8bbe\uff0c\u53d1\u73b0\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u6bd4\u6a21\u578b\u89c4\u6a21\u66f4\u91cd\u8981\u3002", "motivation": "\u5efa\u7acb\u57fa\u7840\u8bbe\u65bd\u65e0\u5173\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5168\u9762\u8bc4\u4f30\u5f53\u4ee3\u57fa\u7840\u6a21\u578b\u5728\u4e0d\u540c\u8ba1\u7b97\u5e73\u53f0\u4e0a\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u6559\u80b2\u3001\u751f\u4ea7\u548c\u7814\u7a76\u573a\u666f\u63d0\u4f9b\u6a21\u578b\u9009\u62e9\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u5b9e\u9a8c\u8bbe\u8ba1\uff1a1) \u5728MareNostrum 5\u4e0a\u5efa\u7acb6\u4e2a\u6a21\u578b\u768419\u95ee\u9898\u57fa\u51c6\uff1b2) \u5728\u5927\u5b66\u96c6\u7fa4\u548cNebius AI Studio\u4e0a\u9a8c\u8bc1\u57fa\u7840\u8bbe\u65bd\u65e0\u5173\u7684\u53ef\u590d\u73b0\u6027\uff1b3) \u5728\u4e24\u4e2a\u5e73\u53f0\u4e0a\u8fdb\u884c\u5b8c\u6574\u768479\u95ee\u9898\u8bc4\u4f30\uff0c\u63a2\u7d22\u4e0d\u540c\u67b6\u6784\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u6311\u6218\u4e86\u4f20\u7edf\u7684\u89c4\u6a21\u6269\u5c55\u5047\u8bbe\uff0c\u786e\u7acb\u4e86\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u6bd4\u6a21\u578b\u89c4\u6a21\u66f4\u5173\u952e\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u8de8\u6559\u80b2\u3001\u751f\u4ea7\u548c\u7814\u7a76\u573a\u666f\u7684\u6a21\u578b\u9009\u62e9\u5b9e\u7528\u6307\u5357\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e09\u57fa\u7840\u8bbe\u65bd\u65b9\u6cd5\u548c79\u95ee\u9898\u57fa\u51c6\u80fd\u591f\u7eb5\u5411\u8ddf\u8e2a\u57fa\u7840\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u53d1\u5c55\uff0c\u4e3a\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u6846\u67b6\u3002"}}
{"id": "2510.26784", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26784", "abs": "https://arxiv.org/abs/2510.26784", "authors": ["Arnab Sen Sharma", "Giordano Rogers", "Natalie Shapira", "David Bau"], "title": "LLMs Process Lists With General Filter Heads", "comment": "Code and data at https://filter.baulab.info/", "summary": "We investigate the mechanisms underlying a range of list-processing tasks in\nLLMs, and we find that LLMs have learned to encode a compact, causal\nrepresentation of a general filtering operation that mirrors the generic\n\"filter\" function of functional programming. Using causal mediation analysis on\na diverse set of list-processing tasks, we find that a small number of\nattention heads, which we dub filter heads, encode a compact representation of\nthe filtering predicate in their query states at certain tokens. We demonstrate\nthat this predicate representation is general and portable: it can be extracted\nand reapplied to execute the same filtering operation on different collections,\npresented in different formats, languages, or even in tasks. However, we also\nidentify situations where transformer LMs can exploit a different strategy for\nfiltering: eagerly evaluating if an item satisfies the predicate and storing\nthis intermediate result as a flag directly in the item representations. Our\nresults reveal that transformer LMs can develop human-interpretable\nimplementations of abstract computational operations that generalize in ways\nthat are surprisingly similar to strategies used in traditional functional\nprogramming patterns.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLMs\u901a\u8fc7\u5c11\u91cf\u6ce8\u610f\u529b\u5934\u7f16\u7801\u901a\u7528\u7684\u8fc7\u6ee4\u64cd\u4f5c\u8868\u793a\uff0c\u8fd9\u79cd\u8868\u793a\u53ef\u4ee5\u8de8\u4e0d\u540c\u683c\u5f0f\u548c\u4efb\u52a1\u79fb\u690d\uff0c\u7c7b\u4f3c\u4e8e\u51fd\u6570\u5f0f\u7f16\u7a0b\u4e2d\u7684filter\u51fd\u6570\u3002", "motivation": "\u63a2\u7a76LLMs\u5728\u5217\u8868\u5904\u7406\u4efb\u52a1\u4e2d\u7684\u5de5\u4f5c\u673a\u5236\uff0c\u7406\u89e3\u5b83\u4eec\u5982\u4f55\u5b9e\u73b0\u901a\u7528\u7684\u8ba1\u7b97\u64cd\u4f5c\u3002", "method": "\u4f7f\u7528\u56e0\u679c\u4e2d\u4ecb\u5206\u6790\u5728\u591a\u79cd\u5217\u8868\u5904\u7406\u4efb\u52a1\u4e2d\u8bc6\u522b\u7f16\u7801\u8fc7\u6ee4\u8c13\u8bcd\u7684\u6ce8\u610f\u529b\u5934\uff08\u79f0\u4e3afilter heads\uff09\uff0c\u5e76\u6d4b\u8bd5\u8fd9\u4e9b\u8868\u793a\u7684\u901a\u7528\u6027\u548c\u53ef\u79fb\u690d\u6027\u3002", "result": "\u53d1\u73b0filter heads\u5728\u7279\u5b9atoken\u5904\u7f16\u7801\u7d27\u51d1\u7684\u8fc7\u6ee4\u8c13\u8bcd\u8868\u793a\uff0c\u8fd9\u79cd\u8868\u793a\u53ef\u4ee5\u63d0\u53d6\u5e76\u91cd\u65b0\u5e94\u7528\u4e8e\u4e0d\u540c\u96c6\u5408\u3001\u683c\u5f0f\u548c\u8bed\u8a00\u3002\u540c\u65f6\u8bc6\u522b\u51fa\u53e6\u4e00\u79cd\u7b56\u7565\uff1a\u6025\u5207\u8bc4\u4f30\u9879\u76ee\u662f\u5426\u6ee1\u8db3\u8c13\u8bcd\u5e76\u5728\u9879\u76ee\u8868\u793a\u4e2d\u5b58\u50a8\u6807\u5fd7\u3002", "conclusion": "Transformer LMs\u80fd\u591f\u53d1\u5c55\u51fa\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u62bd\u8c61\u8ba1\u7b97\u64cd\u4f5c\u5b9e\u73b0\uff0c\u5176\u6cdb\u5316\u65b9\u5f0f\u4e0e\u4f20\u7edf\u51fd\u6570\u5f0f\u7f16\u7a0b\u6a21\u5f0f\u60ca\u4eba\u76f8\u4f3c\u3002"}}

<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 1]
- [cs.CR](#cs.CR) [Total: 5]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [DRACO: Co-design for DSP-Efficient Rigid Body Dynamics Accelerator](https://arxiv.org/abs/2511.08395)
*Xingyu Liu,Jiawei Liang,Yipu Zhang,Linfeng Du,Chaofang Ma,Hui Yu,Jiang Xu,Wei Zhang*

Main category: cs.AR

TL;DR: 提出基于FPGA的硬件高效RBD加速器，包含三个关键创新：精度感知量化框架、除法延迟优化和模块间DSP复用方法，在多种机器人类型上实现8倍吞吐量提升和7.4倍延迟降低。


<details>
  <summary>Details</summary>
Motivation: 为高自由度机器人系统开发硬件高效的RBD（刚体动力学）加速器，解决现有加速器在性能和资源利用方面的不足。

Method: 1. 精度感知量化框架降低DSP需求同时保持运动精度；2. 质量矩阵求逆算法中的除法延迟优化，将倒数操作从最长延迟路径解耦；3. 模块间DSP复用方法提高DSP利用率和节省DSP使用。

Result: 实验结果显示，相比最先进的RBD加速器，在各种机器人类型上实现了最高8倍的吞吐量提升和7.4倍的延迟降低。

Conclusion: 该工作证明了所提出方法的有效性和可扩展性，特别适用于高自由度机器人系统。

Abstract: We propose a hardware-efficient RBD accelerator based on FPGA, introducing three key innovations. First, we propose a precision-aware quantization framework that reduces DSP demand while preserving motion accuracy. This is also the first study to systematically evaluate quantization impact on robot control and motion for hardware acceleration. Second, we leverage a division deferring optimization in mass matrix inversion algorithm, which decouples reciprocal operations from the longest latency path to improve the performance. Finally, we present an inter-module DSP reuse methodology to improve DSP utilization and save DSP usage. Experiment results show that our work achieves up to 8x throughput improvement and 7.4x latency reduction over state-of-the-art RBD accelerators across various robot types, demonstrating its effectiveness and scalability for high-DOF robotic systems.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [2] [KG-DF: A Black-box Defense Framework against Jailbreak Attacks Based on Knowledge Graphs](https://arxiv.org/abs/2511.07480)
*Shuyuan Liu,Jiawei Chen,Xiao Yang,Hang Su,Zhaoxia Yin*

Main category: cs.CR

TL;DR: 提出基于知识图谱的防御框架KG-DF，通过可扩展语义解析模块将输入查询转化为结构化概念表示，增强与安全知识的关联匹配，有效防御越狱攻击并提升通用问答质量。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛应用，越狱攻击安全问题日益突出，现有防御方法难以平衡模型通用性和安全性。过度防御限制正常使用，防御不足则存在安全漏洞。

Method: 提出知识图谱防御框架KG-DF，利用知识图谱的结构化知识表示和语义关联能力，通过可扩展语义解析模块将输入转化为结构化概念表示，关联安全知识库识别有害意图并提供安全推理路径。

Result: 实验结果表明，该框架能有效增强对各种越狱攻击方法的防御性能，同时在通用问答场景中通过融入领域通用知识提升LLM的响应质量。

Conclusion: KG-DF框架成功解决了大语言模型安全防御中通用性与安全性的平衡问题，为LLM的安全应用提供了有效解决方案。

Abstract: With the widespread application of large language models (LLMs) in various fields, the security challenges they face have become increasingly prominent, especially the issue of jailbreak. These attacks induce the model to generate erroneous or uncontrolled outputs through crafted inputs, threatening the generality and security of the model. Although existing defense methods have shown some effectiveness, they often struggle to strike a balance between model generality and security. Excessive defense may limit the normal use of the model, while insufficient defense may lead to security vulnerabilities. In response to this problem, we propose a Knowledge Graph Defense Framework (KG-DF). Specifically, because of its structured knowledge representation and semantic association capabilities, Knowledge Graph(KG) can be searched by associating input content with safe knowledge in the knowledge base, thus identifying potentially harmful intentions and providing safe reasoning paths. However, traditional KG methods encounter significant challenges in keyword extraction, particularly when confronted with diverse and evolving attack strategies. To address this issue, we introduce an extensible semantic parsing module, whose core task is to transform the input query into a set of structured and secure concept representations, thereby enhancing the relevance of the matching process. Experimental results show that our framework enhances defense performance against various jailbreak attack methods, while also improving the response quality of the LLM in general QA scenarios by incorporating domain-general knowledge.

</details>


### [3] [Biologically-Informed Hybrid Membership Inference Attacks on Generative Genomic Models](https://arxiv.org/abs/2511.07503)
*Asia Belfiore,Jonathan Passerat-Palmbach,Dmitrii Usynin*

Main category: cs.CR

TL;DR: 该研究探索使用语言模型生成合成基因突变谱，结合差分隐私保护敏感基因数据，并引入新型生物信息混合成员推理攻击来评估隐私保护效果。


<details>
  <summary>Details</summary>
Motivation: 随着基因数据可用性增加，基因数据的隐私保护问题日益突出，需要开发既能生成有用数据又能保护隐私的方法。

Method: 使用基于Transformer的GPT类语言模型生成合成基因突变谱，应用差分隐私技术，并开发了结合传统黑盒成员推理攻击和基因组学指标的混合攻击方法。

Result: 实验表明小型和大型Transformer模型都能有效生成小规模基因组学的合成变异，混合攻击相比传统基于指标的成员推理攻击具有更高的攻击成功率。

Conclusion: 语言模型是可行的合成基因变异生成器，但需要更强大的隐私评估方法来确保差分隐私保护的有效性。

Abstract: The increased availability of genetic data has transformed genomics research, but raised many privacy concerns regarding its handling due to its sensitive nature. This work explores the use of language models (LMs) for the generation of synthetic genetic mutation profiles, leveraging differential privacy (DP) for the protection of sensitive genetic data. We empirically evaluate the privacy guarantees of our DP modes by introducing a novel Biologically-Informed Hybrid Membership Inference Attack (biHMIA), which combines traditional black box MIA with contextual genomics metrics for enhanced attack power. Our experiments show that both small and large transformer GPT-like models are viable synthetic variant generators for small-scale genomics, and that our hybrid attack leads, on average, to higher adversarial success compared to traditional metric-based MIAs.

</details>


### [4] [A Decentralized Retrieval Augmented Generation System with Source Reliabilities Secured on Blockchain](https://arxiv.org/abs/2511.07577)
*Yining Lu,Wenyi Tang,Max Johnson,Taeho Jung,Meng Jiang*

Main category: cs.CR

TL;DR: 本文提出了一种去中心化的检索增强生成系统，通过区块链智能合约实现可靠性评分机制，在不可靠数据环境中比集中式系统性能提升10.7%，同时实现约56%的边际成本节省。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统采用集中式架构，存在数据收集、集成和管理成本高以及隐私问题。需要一种去中心化系统，让基础模型直接从数据所有者处获取信息，同时保持数据源的完全控制权。

Method: 设计去中心化RAG系统，引入新颖的可靠性评分机制，动态评估每个数据源基于其贡献的响应质量，在检索时优先选择高质量来源。评分过程通过区块链智能合约安全管理，创建可验证且防篡改的可靠性记录。

Result: 在两个模拟环境中使用Llama模型（3B和8B）评估，系统在类似真实世界不可靠数据环境中比集中式系统性能提升10.7%。在理想可靠数据环境下接近集中式系统的上限性能。去中心化基础设施通过批量更新操作实现约56%的边际成本节省。

Conclusion: 去中心化RAG系统通过区块链智能合约实现可靠的评分管理，在保持数据隐私和控制的同时，显著提升了在不可靠数据环境中的性能表现，并有效降低了运营成本。

Abstract: Existing retrieval-augmented generation (RAG) systems typically use a centralized architecture, causing a high cost of data collection, integration, and management, as well as privacy concerns. There is a great need for a decentralized RAG system that enables foundation models to utilize information directly from data owners who maintain full control over their sources. However, decentralization brings a challenge: the numerous independent data sources vary significantly in reliability, which can diminish retrieval accuracy and response quality. To address this, our decentralized RAG system has a novel reliability scoring mechanism that dynamically evaluates each source based on the quality of responses it contributes to generate and prioritizes high-quality sources during retrieval. To ensure transparency and trust, the scoring process is securely managed through blockchain-based smart contracts, creating verifiable and tamper-proof reliability records without relying on a central authority. We evaluate our decentralized system with two Llama models (3B and 8B) in two simulated environments where six data sources have different levels of reliability. Our system achieves a +10.7\% performance improvement over its centralized counterpart in the real world-like unreliable data environments. Notably, it approaches the upper-bound performance of centralized systems under ideally reliable data environments. The decentralized infrastructure enables secure and trustworthy scoring management, achieving approximately 56\% marginal cost savings through batched update operations. Our code and system are open-sourced at github.com/yining610/Reliable-dRAG.

</details>


### [5] [LoopLLM: Transferable Energy-Latency Attacks in LLMs via Repetitive Generation](https://arxiv.org/abs/2511.07876)
*Xingyu Li,Xiaolei Liu,Cheng Liu,Yixiao Xu,Kangyi Ding,Bangzhou Xin,Jia-Li Yin*

Main category: cs.CR

TL;DR: LoopLLM是一个针对大语言模型的能耗-延迟攻击框架，通过诱导重复生成触发低熵解码循环，使LLM持续生成直到达到输出限制，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有能耗-延迟攻击方法通过延迟终止符号生成来延长输出，但随着输出变长，通过输入控制终止符号变得困难，效果有限。

Method: 提出重复诱导提示优化，利用自回归漏洞诱导重复生成；引入令牌对齐集成优化，聚合梯度提升跨模型可转移性。

Result: 在12个开源和2个商业LLM上的实验表明，LoopLLM达到最大输出长度的90%以上，而基线方法仅为20%，对DeepSeek-V3和Gemini 2.5 Flash的可转移性提升约40%。

Conclusion: LoopLLM通过诱导重复生成有效触发低熵解码循环，显著提高了能耗-延迟攻击的效果和跨模型可转移性。

Abstract: As large language models (LLMs) scale, their inference incurs substantial computational resources, exposing them to energy-latency attacks, where crafted prompts induce high energy and latency cost. Existing attack methods aim to prolong output by delaying the generation of termination symbols. However, as the output grows longer, controlling the termination symbols through input becomes difficult, making these methods less effective. Therefore, we propose LoopLLM, an energy-latency attack framework based on the observation that repetitive generation can trigger low-entropy decoding loops, reliably compelling LLMs to generate until their output limits. LoopLLM introduces (1) a repetition-inducing prompt optimization that exploits autoregressive vulnerabilities to induce repetitive generation, and (2) a token-aligned ensemble optimization that aggregates gradients to improve cross-model transferability. Extensive experiments on 12 open-source and 2 commercial LLMs show that LoopLLM significantly outperforms existing methods, achieving over 90% of the maximum output length, compared to 20% for baselines, and improving transferability by around 40% to DeepSeek-V3 and Gemini 2.5 Flash.

</details>


### [6] [QLCoder: A Query Synthesizer For Static Analysis of Security Vulnerabilities](https://arxiv.org/abs/2511.08462)
*Claire Wang,Ziyang Li,Saikat Dutta,Mayur Naik*

Main category: cs.CR

TL;DR: QLCoder是一个自动从CVE元数据合成CodeQL查询的智能框架，通过结合LLM、语言服务器协议和RAG数据库，显著提高了安全查询生成的准确率。


<details>
  <summary>Details</summary>
Motivation: 静态分析工具需要编写复杂的安全查询，这需要安全专家和程序分析专家的专业知识。现有的方法难以自动生成有效的安全查询。

Method: QLCoder将LLM嵌入到带有执行反馈的合成循环中，使用自定义MCP接口与语言服务器协议（语法指导）和RAG数据库（语义检索）进行结构化交互。

Result: 在176个Java项目的CVE评估中，QLCoder成功为53.4%的CVE生成了正确查询，而仅使用Claude Code只能生成10%的正确查询。

Conclusion: QLCoder框架通过结构化约束和反馈机制，能够有效自动生成语法和语义有效的安全查询，显著优于纯LLM方法。

Abstract: Static analysis tools provide a powerful means to detect security vulnerabilities by specifying queries that encode vulnerable code patterns. However, writing such queries is challenging and requires diverse expertise in security and program analysis. To address this challenge, we present QLCoder - an agentic framework that automatically synthesizes queries in CodeQL, a powerful static analysis engine, directly from a given CVE metadata. QLCode embeds an LLM in a synthesis loop with execution feedback, while constraining its reasoning using a custom MCP interface that allows structured interaction with a Language Server Protocol (for syntax guidance) and a RAG database (for semantic retrieval of queries and documentation). This approach allows QLCoder to generate syntactically and semantically valid security queries. We evaluate QLCode on 176 existing CVEs across 111 Java projects. Building upon the Claude Code agent framework, QLCoder synthesizes correct queries that detect the CVE in the vulnerable but not in the patched versions for 53.4% of CVEs. In comparison, using only Claude Code synthesizes 10% correct queries.

</details>

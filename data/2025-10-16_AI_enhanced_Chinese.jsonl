{"id": "2510.12889", "categories": ["cs.DC", "C.2.4"], "pdf": "https://arxiv.org/pdf/2510.12889", "abs": "https://arxiv.org/abs/2510.12889", "authors": ["Wei Da", "Evangelia Kalyvianaki"], "title": "Dodoor: Efficient Randomized Decentralized Scheduling with Load Caching for Heterogeneous Tasks and Clusters", "comment": "single column,20 pages and 8 figures", "summary": "This paper introduces Dodoor, an efficient randomized decentralized scheduler\ndesigned for task scheduling in modern data centers. Dodoor leverages advanced\nresearch on the weighted balls-into-bins model with b-batched setting. Unlike\nother decentralized schedulers that rely on real-time probing of remote\nservers, Dodoor makes scheduling decisions based on cached server information,\nwhich is updated in batches, to reduce communication overheads. To schedule\ntasks with dynamic, multidimensional resource requirements in heterogeneous\ncluster, Dodoor uses a novel load score to measure servers' loads for each\nscheduled task. This score captures the anti-affinity between servers and tasks\nin contrast to the commonly used heuristic of counting pending tasks to balance\nload. On a 101-node heterogeneous cluster, Dodoor is evaluated using two\nworkloads: (i) simulated Azure virtual machines placements and (ii) real\nserverless Python functions executions in Docker. The evaluation shows that\nDodoor reduces scheduling messages by 55--66% on both workloads. Dodoor can\nalso increase throughput by up to 33.2% and 21.5%, reduce mean makespan latency\nby 12.1% and 7.2%, and improve tail latency by 21.9% and 24.6% across the two\nworkloads.", "AI": {"tldr": "Dodoor\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u968f\u673a\u5316\u53bb\u4e2d\u5fc3\u5316\u8c03\u5ea6\u5668\uff0c\u7528\u4e8e\u73b0\u4ee3\u6570\u636e\u4e2d\u5fc3\u7684\u4efb\u52a1\u8c03\u5ea6\u3002\u5b83\u57fa\u4e8e\u6279\u91cf\u66f4\u65b0\u7684\u7f13\u5b58\u670d\u52a1\u5668\u4fe1\u606f\u8fdb\u884c\u8c03\u5ea6\u51b3\u7b56\uff0c\u51cf\u5c11\u4e86\u901a\u4fe1\u5f00\u9500\uff0c\u5728101\u8282\u70b9\u5f02\u6784\u96c6\u7fa4\u4e0a\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u51cf\u5c11\u4e8655-66%\u7684\u8c03\u5ea6\u6d88\u606f\uff0c\u63d0\u5347\u4e86\u541e\u5410\u91cf\u548c\u964d\u4f4e\u4e86\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u4ee3\u6570\u636e\u4e2d\u5fc3\u9700\u8981\u9ad8\u6548\u7684\u4efb\u52a1\u8c03\u5ea6\u5668\uff0c\u4f46\u73b0\u6709\u53bb\u4e2d\u5fc3\u5316\u8c03\u5ea6\u5668\u4f9d\u8d56\u5b9e\u65f6\u63a2\u6d4b\u8fdc\u7a0b\u670d\u52a1\u5668\uff0c\u5bfc\u81f4\u901a\u4fe1\u5f00\u9500\u5927\u3002Dodoor\u65e8\u5728\u901a\u8fc7\u57fa\u4e8e\u7f13\u5b58\u4fe1\u606f\u7684\u8c03\u5ea6\u51b3\u7b56\u6765\u51cf\u5c11\u901a\u4fe1\u6210\u672c\u3002", "method": "Dodoor\u5229\u7528\u5e26\u6743\u91cd\u7684\u7403-\u7bb1\u6a21\u578b\u548c\u6279\u91cf\u8bbe\u7f6e\uff0c\u57fa\u4e8e\u6279\u91cf\u66f4\u65b0\u7684\u7f13\u5b58\u670d\u52a1\u5668\u4fe1\u606f\u8fdb\u884c\u8c03\u5ea6\u51b3\u7b56\u3002\u5b83\u4f7f\u7528\u65b0\u9896\u7684\u8d1f\u8f7d\u8bc4\u5206\u6765\u8861\u91cf\u670d\u52a1\u5668\u8d1f\u8f7d\uff0c\u6355\u6349\u670d\u52a1\u5668\u4e0e\u4efb\u52a1\u4e4b\u95f4\u7684\u53cd\u4eb2\u548c\u6027\uff0c\u800c\u4e0d\u662f\u7b80\u5355\u7684\u5f85\u5904\u7406\u4efb\u52a1\u8ba1\u6570\u3002", "result": "\u5728101\u8282\u70b9\u5f02\u6784\u96c6\u7fa4\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff1aDodoor\u5728\u4e24\u4e2a\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u5206\u522b\u51cf\u5c11\u4e8655-66%\u7684\u8c03\u5ea6\u6d88\u606f\uff1b\u541e\u5410\u91cf\u5206\u522b\u63d0\u5347\u4e8633.2%\u548c21.5%\uff1b\u5e73\u5747\u5b8c\u6210\u65f6\u95f4\u5ef6\u8fdf\u5206\u522b\u964d\u4f4e\u4e8612.1%\u548c7.2%\uff1b\u5c3e\u90e8\u5ef6\u8fdf\u5206\u522b\u6539\u5584\u4e8621.9%\u548c24.6%\u3002", "conclusion": "Dodoor\u901a\u8fc7\u57fa\u4e8e\u7f13\u5b58\u4fe1\u606f\u7684\u8c03\u5ea6\u65b9\u6cd5\u548c\u65b0\u9896\u7684\u8d1f\u8f7d\u8bc4\u5206\u673a\u5236\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u901a\u4fe1\u5f00\u9500\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u8c03\u5ea6\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u73b0\u4ee3\u6570\u636e\u4e2d\u5fc3\u4efb\u52a1\u8c03\u5ea6\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.13147", "categories": ["cs.AR", "cs.LG", "cs.PF", "C.1.4"], "pdf": "https://arxiv.org/pdf/2510.13147", "abs": "https://arxiv.org/abs/2510.13147", "authors": ["Faraz Tahmasebi", "Michael Pelluer", "Hyoukjun Kwon"], "title": "D-com: Accelerating Iterative Processing to Enable Low-rank Decomposition of Activations", "comment": "12 pages, 13 figures", "summary": "The computation and memory costs of large language models kept increasing\nover last decade, which reached over the scale of 1T parameters. To address the\nchallenges from the large scale models, model compression techniques such as\nlow-rank decomposition have been explored. Previous model decomposition works\nhave focused on weight decomposition to avoid costly runtime decomposition,\nwhose latency often significantly exceeds the benefits from decomposition\n(e.g., 38% more end-to-end latency when running Llama2-7b on A100 with 4K\nsequence length with activation decomposition compared to no decomposition). In\nthis work, we debunk such observations and report that the input decomposition\ncan be significantly beneficial with a proper choice of decomposition algorithm\nand hardware support. We adopt progressive decomposition algorithm, Lanczos\nalgorithm, and design a co-accelerator architecture for the decomposition\nalgorithm. To address the memory- boundness of the decomposition operation, we\nintroduce a novel compute replication methodology that moves the op- eration\ntoward compute-bound region, which enables 6.2x speedup in our evaluation. We\nalso develop an output shape- preserving computation scheme that eliminates\ndecomposi- tion costs in consecutive layers. To compensate model quality loss\nfrom compression, we introduce a multi-track decom- position approach that\nseparately handles outlier channels for high accuracy and low perplexity with\nminimal compu- tational costs. Combined together, our accelerator, D-com,\nprovides 22% end-to-end latency improvements compared to A100 GPU at the cost\nof small model quality degradation (e.g., 3% on AI2 Reasoning Challenge task).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f93\u5165\u5206\u89e3\u3001\u6e10\u8fdb\u5206\u89e3\u7b97\u6cd5\u548c\u4e13\u7528\u52a0\u901f\u5668\u67b6\u6784\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5206\u89e3\u5ef6\u8fdf\u5e76\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u6301\u7eed\u589e\u957f\uff0c\u5df2\u8d85\u8fc71T\u53c2\u6570\u89c4\u6a21\u3002\u73b0\u6709\u6a21\u578b\u5206\u89e3\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6743\u91cd\u5206\u89e3\uff0c\u4f46\u8fd0\u884c\u65f6\u5206\u89e3\u5ef6\u8fdf\u5f80\u5f80\u8d85\u8fc7\u5206\u89e3\u5e26\u6765\u7684\u6536\u76ca\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u5206\u89e3\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6e10\u8fdb\u5206\u89e3\u7b97\u6cd5\uff08Lanczos\u7b97\u6cd5\uff09\uff0c\u8bbe\u8ba1\u534f\u540c\u52a0\u901f\u5668\u67b6\u6784\uff0c\u5f15\u5165\u8ba1\u7b97\u590d\u5236\u65b9\u6cd5\u5c06\u64cd\u4f5c\u8f6c\u5411\u8ba1\u7b97\u5bc6\u96c6\u578b\u533a\u57df\uff0c\u5f00\u53d1\u8f93\u51fa\u5f62\u72b6\u4fdd\u6301\u8ba1\u7b97\u65b9\u6848\u6d88\u9664\u8fde\u7eed\u5c42\u7684\u5206\u89e3\u6210\u672c\uff0c\u91c7\u7528\u591a\u901a\u9053\u5206\u89e3\u65b9\u6cd5\u5206\u522b\u5904\u7406\u5f02\u5e38\u901a\u9053\u3002", "result": "\u5b9e\u73b0\u4e866.2\u500d\u7684\u52a0\u901f\uff0c\u4e0eA100 GPU\u76f8\u6bd4\u7aef\u5230\u7aef\u5ef6\u8fdf\u6539\u5584\u4e8622%\uff0c\u6a21\u578b\u8d28\u91cf\u635f\u5931\u8f83\u5c0f\uff08\u5982\u5728AI2\u63a8\u7406\u6311\u6218\u4efb\u52a1\u4e0a\u4ec53%\uff09\u3002", "conclusion": "\u901a\u8fc7\u9002\u5f53\u7684\u5206\u89e3\u7b97\u6cd5\u9009\u62e9\u548c\u786c\u4ef6\u652f\u6301\uff0c\u8f93\u5165\u5206\u89e3\u53ef\u4ee5\u663e\u8457\u6709\u76ca\uff0cD-com\u52a0\u901f\u5668\u5728\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2510.13029", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13029", "abs": "https://arxiv.org/abs/2510.13029", "authors": ["Xinlei Wang", "Mingtian Tan", "Jing Qiu", "Junhua Zhao", "Jinjin Gu"], "title": "Toward Reasoning-Centric Time-Series Analysis", "comment": null, "summary": "Traditional time series analysis has long relied on pattern recognition,\ntrained on static and well-established benchmarks. However, in real-world\nsettings -- where policies shift, human behavior adapts, and unexpected events\nunfold -- effective analysis must go beyond surface-level trends to uncover the\nactual forces driving them. The recent rise of Large Language Models (LLMs)\npresents new opportunities for rethinking time series analysis by integrating\nmultimodal inputs. However, as the use of LLMs becomes popular, we must remain\ncautious, asking why we use LLMs and how to exploit them effectively. Most\nexisting LLM-based methods still employ their numerical regression ability and\nignore their deeper reasoning potential. This paper argues for rethinking time\nseries with LLMs as a reasoning task that prioritizes causal structure and\nexplainability. This shift brings time series analysis closer to human-aligned\nunderstanding, enabling transparent and context-aware insights in complex\nreal-world environments.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u91cd\u65b0\u6784\u60f3\u4e3a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u4efb\u52a1\uff0c\u5f3a\u8c03\u56e0\u679c\u7ed3\u6784\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u800c\u975e\u4ec5\u4f9d\u8d56\u6570\u503c\u56de\u5f52\u80fd\u529b\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u9700\u8981\u8d85\u8d8a\u8868\u9762\u8d8b\u52bf\uff0c\u63ed\u793a\u9a71\u52a8\u56e0\u7d20\u3002\u4f20\u7edf\u65b9\u6cd5\u5728\u653f\u7b56\u53d8\u5316\u3001\u4eba\u7c7b\u884c\u4e3a\u9002\u5e94\u548c\u7a81\u53d1\u4e8b\u4ef6\u7b49\u52a8\u6001\u73af\u5883\u4e2d\u5b58\u5728\u5c40\u9650\uff0c\u800c\u73b0\u6709LLM\u65b9\u6cd5\u5927\u591a\u5ffd\u89c6\u5176\u6df1\u5c42\u63a8\u7406\u6f5c\u529b\u3002", "method": "\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u91cd\u65b0\u5b9a\u4e49\u4e3a\u63a8\u7406\u4efb\u52a1\uff0c\u5229\u7528LLMs\u7684\u591a\u6a21\u6001\u8f93\u5165\u6574\u5408\u80fd\u529b\uff0c\u91cd\u70b9\u5173\u6ce8\u56e0\u679c\u7ed3\u6784\u548c\u53ef\u89e3\u91ca\u6027\u5206\u6790\u3002", "result": "\u8be5\u65b9\u6cd5\u4f7f\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u66f4\u63a5\u8fd1\u4eba\u7c7b\u5bf9\u9f50\u7684\u7406\u89e3\uff0c\u80fd\u591f\u5728\u590d\u6742\u73b0\u5b9e\u73af\u5883\u4e2d\u63d0\u4f9b\u900f\u660e\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6d1e\u5bdf\u3002", "conclusion": "\u5c06LLMs\u4f5c\u4e3a\u63a8\u7406\u5de5\u5177\u800c\u975e\u5355\u7eaf\u56de\u5f52\u5de5\u5177\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u7684\u6df1\u5ea6\u548c\u5b9e\u7528\u6027\uff0c\u7279\u522b\u662f\u5728\u52a8\u6001\u53d8\u5316\u7684\u73b0\u5b9e\u573a\u666f\u4e2d\u3002"}}
{"id": "2510.13203", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.13203", "abs": "https://arxiv.org/abs/2510.13203", "authors": ["Mehdi Zekriyapanah Gashti"], "title": "Scrutiny new framework in integrated distributed reliable systems", "comment": null, "summary": "In this paper we represent a new framework for integrated distributed\nsystems. In the proposed framework we have used three parts to increase\nSatisfaction and Performance of this framework. At first we analyse integrated\nsystems and their evolution process and also ERPSD and ERPDRT framework briefly\nthen we explain the new FDIRS framework. Finally we compare the results of\nsimulation of the new framework with presented frameworks. Result showed In\nFIDRS framework, the technique of heterogeneous distributed data base is used\nto improve Performance and speed in responding to users. Finally by using FDIRS\nframework we succeeded to increase Efficiency, Performance and reliability of\nintegrated systems and remove some of previous frameworks problems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u96c6\u6210\u5206\u5e03\u5f0f\u7cfb\u7edf\u6846\u67b6FDIRS\uff0c\u901a\u8fc7\u4f7f\u7528\u5f02\u6784\u5206\u5e03\u5f0f\u6570\u636e\u5e93\u6280\u672f\u6765\u63d0\u9ad8\u7cfb\u7edf\u6027\u80fd\u3001\u54cd\u5e94\u901f\u5ea6\u548c\u53ef\u9760\u6027\uff0c\u89e3\u51b3\u4e86\u4e4b\u524d\u6846\u67b6\u7684\u4e00\u4e9b\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u96c6\u6210\u5206\u5e03\u5f0f\u7cfb\u7edf\u6846\u67b6\u5728\u6027\u80fd\u3001\u6548\u7387\u548c\u53ef\u9760\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u6846\u67b6\u6765\u63d0\u5347\u7cfb\u7edf\u6574\u4f53\u8868\u73b0\u3002", "method": "\u5206\u6790\u73b0\u6709\u96c6\u6210\u7cfb\u7edf\u53ca\u5176\u6f14\u8fdb\u8fc7\u7a0b\uff0c\u7b80\u8981\u4ecb\u7ecdERPSD\u548cERPDRT\u6846\u67b6\uff0c\u7136\u540e\u8be6\u7ec6\u9610\u8ff0\u65b0\u7684FDIRS\u6846\u67b6\uff0c\u5e76\u4f7f\u7528\u5f02\u6784\u5206\u5e03\u5f0f\u6570\u636e\u5e93\u6280\u672f\u6765\u63d0\u9ad8\u6027\u80fd\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0cFDIRS\u6846\u67b6\u5728\u6027\u80fd\u3001\u54cd\u5e94\u901f\u5ea6\u548c\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6846\u67b6\uff0c\u6210\u529f\u63d0\u9ad8\u4e86\u96c6\u6210\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u6027\u80fd\u3002", "conclusion": "FDIRS\u6846\u67b6\u901a\u8fc7\u91c7\u7528\u5f02\u6784\u5206\u5e03\u5f0f\u6570\u636e\u5e93\u6280\u672f\uff0c\u6709\u6548\u63d0\u5347\u4e86\u96c6\u6210\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u6027\u80fd\u3001\u6548\u7387\u548c\u53ef\u9760\u6027\uff0c\u89e3\u51b3\u4e86\u4e4b\u524d\u6846\u67b6\u7684\u82e5\u5e72\u95ee\u9898\u3002"}}
{"id": "2510.12812", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.12812", "abs": "https://arxiv.org/abs/2510.12812", "authors": ["Aleksandar Petrov", "Pierre Fernandez", "Tom\u00e1\u0161 Sou\u010dek", "Hady Elsahar"], "title": "We Can Hide More Bits: The Unused Watermarking Capacity in Theory and in Practice", "comment": null, "summary": "Despite rapid progress in deep learning-based image watermarking, the\ncapacity of current robust methods remains limited to the scale of only a few\nhundred bits. Such plateauing progress raises the question: How far are we from\nthe fundamental limits of image watermarking? To this end, we present an\nanalysis that establishes upper bounds on the message-carrying capacity of\nimages under PSNR and linear robustness constraints. Our results indicate\ntheoretical capacities are orders of magnitude larger than what current models\nachieve. Our experiments show this gap between theoretical and empirical\nperformance persists, even in minimal, easily analysable setups. This suggests\na fundamental problem. As proof that larger capacities are indeed possible, we\ntrain ChunkySeal, a scaled-up version of VideoSeal, which increases capacity 4\ntimes to 1024 bits, all while preserving image quality and robustness. These\nfindings demonstrate modern methods have not yet saturated watermarking\ncapacity, and that significant opportunities for architectural innovation and\ntraining strategies remain.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u56fe\u50cf\u6c34\u5370\u65b9\u6cd5\u7684\u5bb9\u91cf\u9650\u5236\uff0c\u5efa\u7acb\u4e86\u5728PSNR\u548c\u7ebf\u6027\u9c81\u68d2\u6027\u7ea6\u675f\u4e0b\u7684\u7406\u8bba\u5bb9\u91cf\u4e0a\u9650\uff0c\u53d1\u73b0\u7406\u8bba\u5bb9\u91cf\u8fdc\u9ad8\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u4f5c\u8005\u8bad\u7ec3\u4e86ChunkySeal\u6a21\u578b\uff0c\u5c06\u5bb9\u91cf\u63d0\u53474\u500d\u81f31024\u4f4d\uff0c\u540c\u65f6\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u5c3d\u7ba1\u6df1\u5ea6\u5b66\u4e60\u56fe\u50cf\u6c34\u5370\u6280\u672f\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u5f53\u524d\u9c81\u68d2\u65b9\u6cd5\u7684\u5bb9\u91cf\u4ecd\u9650\u5236\u5728\u51e0\u767e\u4f4d\u3002\u8fd9\u79cd\u8fdb\u5c55\u505c\u6ede\u5f15\u53d1\u4e86\u5bf9\u56fe\u50cf\u6c34\u5370\u57fa\u672c\u6781\u9650\u7684\u7591\u95ee\uff0c\u9700\u8981\u63a2\u7d22\u7406\u8bba\u5bb9\u91cf\u4e0e\u5b9e\u9645\u6027\u80fd\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u5efa\u7acb\u4e86\u5728PSNR\u548c\u7ebf\u6027\u9c81\u68d2\u6027\u7ea6\u675f\u4e0b\u7684\u56fe\u50cf\u6d88\u606f\u643a\u5e26\u5bb9\u91cf\u4e0a\u9650\u5206\u6790\uff0c\u5e76\u8bad\u7ec3\u4e86ChunkySeal\u6a21\u578b\u4f5c\u4e3aVideoSeal\u7684\u6269\u5c55\u7248\u672c\uff0c\u901a\u8fc7\u67b6\u6784\u521b\u65b0\u548c\u8bad\u7ec3\u7b56\u7565\u63d0\u5347\u5bb9\u91cf\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u56fe\u50cf\u6c34\u5370\u7684\u7406\u8bba\u5bb9\u91cf\u6bd4\u73b0\u6709\u65b9\u6cd5\u9ad8\u51fa\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u5bb9\u91cf\u4e0e\u5b9e\u9645\u6027\u80fd\u4e4b\u95f4\u7684\u5dee\u8ddd\u6301\u7eed\u5b58\u5728\u3002ChunkySeal\u6a21\u578b\u6210\u529f\u5c06\u5bb9\u91cf\u63d0\u53474\u500d\u81f31024\u4f4d\uff0c\u540c\u65f6\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u73b0\u4ee3\u65b9\u6cd5\u5c1a\u672a\u8fbe\u5230\u6c34\u5370\u5bb9\u91cf\u7684\u9971\u548c\u70b9\uff0c\u5728\u67b6\u6784\u521b\u65b0\u548c\u8bad\u7ec3\u7b56\u7565\u65b9\u9762\u4ecd\u5b58\u5728\u663e\u8457\u6539\u8fdb\u7a7a\u95f4\uff0c\u7406\u8bba\u5206\u6790\u4e3a\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2510.13306", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.13306", "abs": "https://arxiv.org/abs/2510.13306", "authors": ["Jannick Borowitz", "Ernestine Gro\u00dfmann", "Mattthias Schimek"], "title": "Distributed Reductions for the Maximum Weight Independent Set Problem", "comment": null, "summary": "Finding maximum-weight independent sets in graphs is an important NP-hard\noptimization problem. Given a vertex-weighted graph $G$, the task is to find a\nsubset of pairwise non-adjacent vertices of $G$ with maximum weight. Most\nrecently published practical exact algorithms and heuristics for this problem\nuse a variety of data-reduction rules to compute (near-)optimal solutions.\nApplying these rules results in an equivalent instance of reduced size. An\noptimal solution to the reduced instance can be easily used to construct an\noptimal solution for the original input.\n  In this work, we present the first distributed-memory parallel reduction\nalgorithms for this problem, targeting graphs beyond the scale of previous\nsequential approaches. Furthermore, we propose the first distributed\nreduce-and-greedy and reduce-and-peel algorithms for finding a maximum weight\nindependent set heuristically.\n  In our practical evaluation, our experiments on up to $1024$ processors\ndemonstrate good scalability of our distributed reduce algorithms while\nmaintaining good reduction impact. Our asynchronous reduce-and-peel approach\nachieves an average speedup of $33\\times$ over a sequential state-of-the-art\nreduce-and-peel approach on 36 real-world graphs with a solution quality close\nto the sequential algorithm. Our reduce-and-greedy algorithms even achieve\naverage speedups of up to $50\\times$ at the cost of a lower solution quality.\nMoreover, our distributed approach allows us to consider graphs with more than\none billion vertices and 17 billion edges.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5206\u5e03\u5f0f\u5185\u5b58\u5e76\u884c\u7f29\u51cf\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u6700\u5927\u6743\u91cd\u72ec\u7acb\u96c6\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u5728\u5927\u89c4\u6a21\u56fe\u4e0a\u7684\u9ad8\u6548\u5904\u7406\uff0c\u76f8\u6bd4\u73b0\u6709\u987a\u5e8f\u7b97\u6cd5\u83b7\u5f97\u4e86\u663e\u8457\u52a0\u901f\u3002", "motivation": "\u6700\u5927\u6743\u91cd\u72ec\u7acb\u96c6\u95ee\u9898\u662f\u4e00\u4e2a\u91cd\u8981\u7684NP\u96be\u4f18\u5316\u95ee\u9898\uff0c\u73b0\u6709\u7b97\u6cd5\u4e3b\u8981\u4f7f\u7528\u6570\u636e\u7f29\u51cf\u89c4\u5219\u6765\u6c42\u89e3\uff0c\u4f46\u7f3a\u4e4f\u5206\u5e03\u5f0f\u5e76\u884c\u5b9e\u73b0\uff0c\u65e0\u6cd5\u5904\u7406\u8d85\u5927\u89c4\u6a21\u56fe\u3002", "method": "\u5f00\u53d1\u4e86\u5206\u5e03\u5f0f\u5185\u5b58\u5e76\u884c\u7f29\u51cf\u7b97\u6cd5\uff0c\u5305\u62ec\u5206\u5e03\u5f0freduce-and-greedy\u548creduce-and-peel\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u652f\u6301\u5f02\u6b65\u5904\u7406\u3002", "result": "\u57281024\u4e2a\u5904\u7406\u5668\u4e0a\u5b9e\u9a8c\u663e\u793a\u826f\u597d\u53ef\u6269\u5c55\u6027\uff0creduce-and-peel\u65b9\u6cd5\u76f8\u6bd4\u987a\u5e8f\u7b97\u6cd5\u5e73\u5747\u52a0\u901f33\u500d\uff0creduce-and-greedy\u65b9\u6cd5\u5e73\u5747\u52a0\u901f50\u500d\uff0c\u80fd\u591f\u5904\u7406\u8d85\u8fc710\u4ebf\u9876\u70b9\u548c170\u4ebf\u8fb9\u7684\u56fe\u3002", "conclusion": "\u5206\u5e03\u5f0f\u5e76\u884c\u7f29\u51cf\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u8d85\u5927\u89c4\u6a21\u56fe\u7684\u6700\u5927\u6743\u91cd\u72ec\u7acb\u96c6\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u89e3\u8d28\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2510.12828", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.12828", "abs": "https://arxiv.org/abs/2510.12828", "authors": ["Shingo Kodama", "Haya Diwan", "Lucas Rosenblatt", "R. Teal Witter", "Niv Cohen"], "title": "SimKey: A Semantically Aware Key Module for Watermarking Language Models", "comment": null, "summary": "The rapid spread of text generated by large language models (LLMs) makes it\nincreasingly difficult to distinguish authentic human writing from machine\noutput. Watermarking offers a promising solution: model owners can embed an\nimperceptible signal into generated text, marking its origin. Most leading\napproaches seed an LLM's next-token sampling with a pseudo-random key that can\nlater be recovered to identify the text as machine-generated, while only\nminimally altering the model's output distribution. However, these methods\nsuffer from two related issues: (i) watermarks are brittle to simple\nsurface-level edits such as paraphrasing or reordering; and (ii) adversaries\ncan append unrelated, potentially harmful text that inherits the watermark,\nrisking reputational damage to model owners. To address these issues, we\nintroduce SimKey, a semantic key module that strengthens watermark robustness\nby tying key generation to the meaning of prior context. SimKey uses\nlocality-sensitive hashing over semantic embeddings to ensure that paraphrased\ntext yields the same watermark key, while unrelated or semantically shifted\ntext produces a different one. Integrated with state-of-the-art watermarking\nschemes, SimKey improves watermark robustness to paraphrasing and translation\nwhile preventing harmful content from false attribution, establishing\nsemantic-aware keying as a practical and extensible watermarking direction.", "AI": {"tldr": "SimKey\u662f\u4e00\u79cd\u8bed\u4e49\u5bc6\u94a5\u6a21\u5757\uff0c\u901a\u8fc7\u5c06\u5bc6\u94a5\u751f\u6210\u4e0e\u5148\u524d\u4e0a\u4e0b\u6587\u7684\u610f\u4e49\u7ed1\u5b9a\u6765\u589e\u5f3a\u6c34\u5370\u9c81\u68d2\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM\u6c34\u5370\u65b9\u6cd5\u5bf9\u8868\u9762\u7f16\u8f91\u8106\u5f31\u548c\u53ef\u80fd\u88ab\u6076\u610f\u5229\u7528\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\u7684\u5feb\u901f\u4f20\u64ad\uff0c\u533a\u5206\u771f\u5b9e\u4eba\u7c7b\u5199\u4f5c\u548c\u673a\u5668\u8f93\u51fa\u53d8\u5f97\u8d8a\u6765\u8d8a\u56f0\u96be\u3002\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a(i) \u6c34\u5370\u5bf9\u7b80\u5355\u7684\u8868\u9762\u7f16\u8f91\uff08\u5982\u6539\u5199\u6216\u91cd\u65b0\u6392\u5e8f\uff09\u5f88\u8106\u5f31\uff1b(ii) \u653b\u51fb\u8005\u53ef\u4ee5\u9644\u52a0\u4e0d\u76f8\u5173\u7684\u6709\u5bb3\u6587\u672c\u6765\u7ee7\u627f\u6c34\u5370\uff0c\u7ed9\u6a21\u578b\u6240\u6709\u8005\u5e26\u6765\u58f0\u8a89\u98ce\u9669\u3002", "method": "\u5f15\u5165SimKey\u8bed\u4e49\u5bc6\u94a5\u6a21\u5757\uff0c\u4f7f\u7528\u8bed\u4e49\u5d4c\u5165\u7684\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\u6765\u786e\u4fdd\u6539\u5199\u6587\u672c\u4ea7\u751f\u76f8\u540c\u7684\u6c34\u5370\u5bc6\u94a5\uff0c\u800c\u4e0d\u76f8\u5173\u6216\u8bed\u4e49\u8f6c\u79fb\u7684\u6587\u672c\u4ea7\u751f\u4e0d\u540c\u7684\u5bc6\u94a5\u3002SimKey\u4e0e\u6700\u5148\u8fdb\u7684\u6c34\u5370\u65b9\u6848\u96c6\u6210\u3002", "result": "SimKey\u63d0\u9ad8\u4e86\u6c34\u5370\u5bf9\u6539\u5199\u548c\u7ffb\u8bd1\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u9632\u6b62\u6709\u5bb3\u5185\u5bb9\u88ab\u9519\u8bef\u5f52\u56e0\u3002", "conclusion": "\u8bed\u4e49\u611f\u77e5\u5bc6\u94a5\u751f\u6210\u662f\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u6c34\u5370\u65b9\u5411\u3002"}}
{"id": "2510.13215", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.13215", "abs": "https://arxiv.org/abs/2510.13215", "authors": ["Joy Jia Yin Lim", "Ye He", "Jifan Yu", "Xin Cong", "Daniel Zhang-Li", "Zhiyuan Liu", "Huiqin Liu", "Lei Hou", "Juanzi Li", "Bin Xu"], "title": "Personalized Learning Path Planning with Goal-Driven Learner State Modeling", "comment": null, "summary": "Personalized Learning Path Planning (PLPP) aims to design adaptive learning\npaths that align with individual goals. While large language models (LLMs) show\npotential in personalizing learning experiences, existing approaches often lack\nmechanisms for goal-aligned planning. We introduce Pxplore, a novel framework\nfor PLPP that integrates a reinforcement-based training paradigm and an\nLLM-driven educational architecture. We design a structured learner state model\nand an automated reward function that transforms abstract objectives into\ncomputable signals. We train the policy combining supervised fine-tuning (SFT)\nand Group Relative Policy Optimization (GRPO), and deploy it within a\nreal-world learning platform. Extensive experiments validate Pxplore's\neffectiveness in producing coherent, personalized, and goal-driven learning\npaths. We release our code and dataset to facilitate future research.", "AI": {"tldr": "Pxplore\u662f\u4e00\u4e2a\u4e2a\u6027\u5316\u5b66\u4e60\u8def\u5f84\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u548cLLM\u9a71\u52a8\u7684\u6559\u80b2\u67b6\u6784\uff0c\u5c06\u62bd\u8c61\u5b66\u4e60\u76ee\u6807\u8f6c\u5316\u4e3a\u53ef\u8ba1\u7b97\u4fe1\u53f7\uff0c\u751f\u6210\u8fde\u8d2f\u3001\u4e2a\u6027\u5316\u548c\u76ee\u6807\u9a71\u52a8\u7684\u5b66\u4e60\u8def\u5f84\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u4e2a\u6027\u5316\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u76ee\u6807\u5bf9\u9f50\u89c4\u5212\u673a\u5236\uff0c\u65e0\u6cd5\u6709\u6548\u5c06\u4e2a\u4f53\u5b66\u4e60\u76ee\u6807\u8f6c\u5316\u4e3a\u5177\u4f53\u7684\u5b66\u4e60\u8def\u5f84\u3002", "method": "\u8bbe\u8ba1\u7ed3\u6784\u5316\u5b66\u4e60\u8005\u72b6\u6001\u6a21\u578b\u548c\u81ea\u52a8\u5956\u52b1\u51fd\u6570\uff0c\u7ed3\u5408\u76d1\u7763\u5fae\u8c03(SFT)\u548c\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(GRPO)\u8bad\u7ec3\u7b56\u7565\uff0c\u5e76\u5728\u771f\u5b9e\u5b66\u4e60\u5e73\u53f0\u4e2d\u90e8\u7f72\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86Pxplore\u5728\u751f\u6210\u8fde\u8d2f\u3001\u4e2a\u6027\u5316\u548c\u76ee\u6807\u9a71\u52a8\u5b66\u4e60\u8def\u5f84\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "Pxplore\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u76ee\u6807\u5bf9\u9f50\u7684\u4e2a\u6027\u5316\u5b66\u4e60\u8def\u5f84\u89c4\u5212\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u4ee3\u7801\u548c\u6570\u636e\u96c6\u652f\u6301\u3002"}}
{"id": "2510.13668", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13668", "abs": "https://arxiv.org/abs/2510.13668", "authors": ["Zhibin Wang", "Zetao Hong", "Xue Li", "Zibo Wang", "Shipeng Li", "Qingkai Meng", "Qing Wang", "Chengying Huan", "Rong Gu", "Sheng Zhong", "Chen Tian"], "title": "Adaptive Rescheduling in Prefill-Decode Disaggregated LLM Inference", "comment": null, "summary": "Large Language Model (LLM) inference has emerged as a fundamental paradigm.\nIn real-world scenarios, variations in output length cause severe workload\nimbalance in the decode phase, particularly for long-output reasoning tasks.\nExisting systems, such as PD disaggregation architectures, rely on static\nprefill-to-decode scheduling, which often results in SLO violations and OOM\nfailures under evolving decode workloads.\n  In this paper, we propose ARES, an adaptive decoding rescheduling system\npowered by length prediction to anticipate future workloads. Our core\ncontributions include: (1) A lightweight and continuous LLM-native prediction\nmethod that leverages LLM hidden state to model remaining generation length\nwith high precision (reducing MAE by 49.42%) and low overhead (cutting\npredictor parameters by 93.28%); (2) A rescheduling solution in decode phase\nwith : A dynamic balancing mechanism that integrates current and predicted\nworkloads, reducing P99 TPOT by 74.77% and achieving up to 2.24 times higher\ngoodput.", "AI": {"tldr": "ARES\u662f\u4e00\u4e2a\u57fa\u4e8e\u957f\u5ea6\u9884\u6d4b\u7684\u81ea\u9002\u5e94\u89e3\u7801\u91cd\u8c03\u5ea6\u7cfb\u7edf\uff0c\u901a\u8fc7LLM\u539f\u751f\u9884\u6d4b\u65b9\u6cd5\u51c6\u786e\u9884\u6d4b\u5269\u4f59\u751f\u6210\u957f\u5ea6\uff0c\u5728\u89e3\u7801\u9636\u6bb5\u5b9e\u73b0\u52a8\u6001\u8d1f\u8f7d\u5747\u8861\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u573a\u666f\u4e2d\u8f93\u51fa\u957f\u5ea6\u53d8\u5316\u5bfc\u81f4\u89e3\u7801\u9636\u6bb5\u5de5\u4f5c\u8d1f\u8f7d\u4e25\u91cd\u4e0d\u5e73\u8861\uff0c\u7279\u522b\u662f\u5728\u957f\u8f93\u51fa\u63a8\u7406\u4efb\u52a1\u4e2d\u3002\u73b0\u6709\u7cfb\u7edf\u91c7\u7528\u9759\u6001\u9884\u586b\u5145\u5230\u89e3\u7801\u8c03\u5ea6\uff0c\u5728\u53d8\u5316\u7684\u89e3\u7801\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7ecf\u5e38\u5bfc\u81f4SLO\u8fdd\u89c4\u548cOOM\u6545\u969c\u3002", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u8fde\u7eedLLM\u539f\u751f\u9884\u6d4b\u65b9\u6cd5\uff0c\u5229\u7528LLM\u9690\u85cf\u72b6\u6001\u5efa\u6a21\u5269\u4f59\u751f\u6210\u957f\u5ea6\uff1b\u5728\u89e3\u7801\u9636\u6bb5\u91c7\u7528\u91cd\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\uff0c\u96c6\u6210\u5f53\u524d\u548c\u9884\u6d4b\u5de5\u4f5c\u8d1f\u8f7d\u7684\u52a8\u6001\u5e73\u8861\u673a\u5236\u3002", "result": "\u9884\u6d4b\u65b9\u6cd5\u5c06MAE\u964d\u4f4e49.42%\uff0c\u9884\u6d4b\u5668\u53c2\u6570\u51cf\u5c1193.28%\uff1b\u91cd\u8c03\u5ea6\u673a\u5236\u5c06P99 TPOT\u964d\u4f4e74.77%\uff0c\u541e\u5410\u91cf\u63d0\u5347\u6700\u9ad8\u8fbe2.24\u500d\u3002", "conclusion": "ARES\u7cfb\u7edf\u901a\u8fc7\u81ea\u9002\u5e94\u89e3\u7801\u91cd\u8c03\u5ea6\u548c\u7cbe\u786e\u7684\u957f\u5ea6\u9884\u6d4b\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u63a8\u7406\u4e2d\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.13724", "categories": ["cs.DC", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.13724", "abs": "https://arxiv.org/abs/2510.13724", "authors": ["Aditya Tanikanti", "Benoit C\u00f4t\u00e9", "Yanfei Guo", "Le Chen", "Nickolaus Saint", "Ryan Chard", "Ken Raffenetti", "Rajeev Thakur", "Thomas Uram", "Ian Foster", "Michael E. Papka", "Venkatram Vishwanath"], "title": "FIRST: Federated Inference Resource Scheduling Toolkit for Scientific AI Model Access", "comment": null, "summary": "We present the Federated Inference Resource Scheduling Toolkit (FIRST), a\nframework enabling Inference-as-a-Service across distributed High-Performance\nComputing (HPC) clusters. FIRST provides cloud-like access to diverse AI\nmodels, like Large Language Models (LLMs), on existing HPC infrastructure.\nLeveraging Globus Auth and Globus Compute, the system allows researchers to run\nparallel inference workloads via an OpenAI-compliant API on private, secure\nenvironments. This cluster-agnostic API allows requests to be distributed\nacross federated clusters, targeting numerous hosted models. FIRST supports\nmultiple inference backends (e.g., vLLM), auto-scales resources, maintains\n\"hot\" nodes for low-latency execution, and offers both high-throughput batch\nand interactive modes. The framework addresses the growing demand for private,\nsecure, and scalable AI inference in scientific workflows, allowing researchers\nto generate billions of tokens daily on-premises without relying on commercial\ncloud infrastructure.", "AI": {"tldr": "FIRST\u662f\u4e00\u4e2a\u8054\u90a6\u63a8\u7406\u8d44\u6e90\u8c03\u5ea6\u5de5\u5177\u5305\uff0c\u5728\u5206\u5e03\u5f0f\u9ad8\u6027\u80fd\u8ba1\u7b97\u96c6\u7fa4\u4e0a\u63d0\u4f9b\u63a8\u7406\u5373\u670d\u52a1\uff0c\u652f\u6301\u7814\u7a76\u4eba\u5458\u901a\u8fc7OpenAI\u517c\u5bb9API\u5728\u79c1\u6709\u5b89\u5168\u73af\u5883\u4e2d\u8fd0\u884c\u5e76\u884c\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\u3002", "motivation": "\u89e3\u51b3\u79d1\u5b66\u5de5\u4f5c\u6d41\u4e2d\u5bf9\u79c1\u6709\u3001\u5b89\u5168\u3001\u53ef\u6269\u5c55AI\u63a8\u7406\u65e5\u76ca\u589e\u957f\u7684\u9700\u6c42\uff0c\u8ba9\u7814\u7a76\u4eba\u5458\u80fd\u591f\u5728\u672c\u5730\u57fa\u7840\u8bbe\u65bd\u4e0a\u751f\u6210\u6570\u5341\u4ebftoken\uff0c\u800c\u65e0\u9700\u4f9d\u8d56\u5546\u4e1a\u4e91\u57fa\u7840\u8bbe\u65bd\u3002", "method": "\u5229\u7528Globus Auth\u548cGlobus Compute\uff0c\u901a\u8fc7\u96c6\u7fa4\u65e0\u5173\u7684API\u5c06\u8bf7\u6c42\u5206\u53d1\u5230\u8054\u90a6\u96c6\u7fa4\uff0c\u652f\u6301\u591a\u79cd\u63a8\u7406\u540e\u7aef\uff08\u5982vLLM\uff09\uff0c\u81ea\u52a8\u6269\u5c55\u8d44\u6e90\uff0c\u7ef4\u62a4\"\u70ed\"\u8282\u70b9\u4ee5\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u6267\u884c\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u5728\u73b0\u6709HPC\u57fa\u7840\u8bbe\u65bd\u4e0a\u4ee5\u4e91\u670d\u52a1\u65b9\u5f0f\u8bbf\u95ee\u591a\u6837\u5316AI\u6a21\u578b\uff08\u5982\u5927\u8bed\u8a00\u6a21\u578b\uff09\uff0c\u652f\u6301\u9ad8\u541e\u5410\u91cf\u6279\u5904\u7406\u548c\u4ea4\u4e92\u6a21\u5f0f\u3002", "conclusion": "FIRST\u6210\u529f\u5b9e\u73b0\u4e86\u5728\u5206\u5e03\u5f0fHPC\u96c6\u7fa4\u4e0a\u63d0\u4f9b\u79c1\u6709\u3001\u5b89\u5168\u3001\u53ef\u6269\u5c55\u7684AI\u63a8\u7406\u670d\u52a1\uff0c\u6ee1\u8db3\u4e86\u79d1\u5b66\u5de5\u4f5c\u6d41\u5bf9\u5927\u89c4\u6a21AI\u63a8\u7406\u7684\u9700\u6c42\u3002"}}
{"id": "2510.13230", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13230", "abs": "https://arxiv.org/abs/2510.13230", "authors": ["Jalal Khan", "Manzoor Khan", "Sherzod Turaev", "Sumbal Malik", "Hesham El-Sayed", "Farman Ullah"], "title": "An Analytical Framework to Enhance Autonomous Vehicle Perception for Smart Cities", "comment": "32 pages, 14 figures", "summary": "The driving environment perception has a vital role for autonomous driving\nand nowadays has been actively explored for its realization. The research\ncommunity and relevant stakeholders necessitate the development of Deep\nLearning (DL) models and AI-enabled solutions to enhance autonomous vehicles\n(AVs) for smart mobility. There is a need to develop a model that accurately\nperceives multiple objects on the road and predicts the driver's perception to\ncontrol the car's movements. This article proposes a novel utility-based\nanalytical model that enables perception systems of AVs to understand the\ndriving environment. The article consists of modules: acquiring a custom\ndataset having distinctive objects, i.e., motorcyclists, rickshaws, etc; a\nDL-based model (YOLOv8s) for object detection; and a module to measure the\nutility of perception service from the performance values of trained model\ninstances. The perception model is validated based on the object detection\ntask, and its process is benchmarked by state-of-the-art deep learning models'\nperformance metrics from the nuScense dataset. The experimental results show\nthree best-performing YOLOv8s instances based on mAP@0.5 values, i.e.,\nSGD-based (0.832), Adam-based (0.810), and AdamW-based (0.822). However, the\nAdamW-based model (i.e., car: 0.921, motorcyclist: 0.899, truck: 0.793, etc.)\nstill outperforms the SGD-based model (i.e., car: 0.915, motorcyclist: 0.892,\ntruck: 0.781, etc.) because it has better class-level performance values,\nconfirmed by the proposed perception model. We validate that the proposed\nfunction is capable of finding the right perception for AVs. The results above\nencourage using the proposed perception model to evaluate the utility of\nlearning models and determine the appropriate perception for AVs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6548\u7528\u7684\u5206\u6790\u6a21\u578b\uff0c\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u73af\u5883\u611f\u77e5\u7cfb\u7edf\u3002\u8be5\u6a21\u578b\u5305\u542b\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u91c7\u96c6\u3001\u57fa\u4e8eYOLOv8s\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u5757\uff0c\u4ee5\u53ca\u4ece\u8bad\u7ec3\u6a21\u578b\u6027\u80fd\u503c\u4e2d\u6d4b\u91cf\u611f\u77e5\u670d\u52a1\u6548\u7528\u7684\u6a21\u5757\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6a21\u578b\u5728\u786e\u5b9a\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u6b63\u786e\u611f\u77e5\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u73af\u5883\u611f\u77e5\u5bf9\u667a\u80fd\u4ea4\u901a\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u51c6\u786e\u611f\u77e5\u9053\u8def\u591a\u76ee\u6807\u5e76\u9884\u6d4b\u9a7e\u9a76\u5458\u611f\u77e5\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u4ee5\u63a7\u5236\u8f66\u8f86\u8fd0\u52a8\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6548\u7528\u7684\u5206\u6790\u6a21\u578b\uff0c\u5305\u62ec\uff1a\u91c7\u96c6\u5305\u542b\u6469\u6258\u8f66\u624b\u3001\u4e09\u8f6e\u8f66\u7b49\u72ec\u7279\u5bf9\u8c61\u7684\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\uff1b\u4f7f\u7528YOLOv8s\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff1b\u4ece\u8bad\u7ec3\u6a21\u578b\u6027\u80fd\u503c\u4e2d\u6d4b\u91cf\u611f\u77e5\u670d\u52a1\u6548\u7528\u7684\u6a21\u5757\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u4e09\u4e2a\u6027\u80fd\u6700\u4f73\u7684YOLOv8s\u5b9e\u4f8b\uff1aSGD-based (mAP@0.5=0.832)\u3001Adam-based (0.810)\u548cAdamW-based (0.822)\u3002\u867d\u7136SGD\u6a21\u578b\u7684\u6574\u4f53mAP\u6700\u9ad8\uff0c\u4f46AdamW\u6a21\u578b\u5728\u7c7b\u522b\u7ea7\u522b\u6027\u80fd\u66f4\u4f18\uff08\u6c7d\u8f66\uff1a0.921\uff0c\u6469\u6258\u8f66\u624b\uff1a0.899\uff0c\u5361\u8f66\uff1a0.793\u7b49\uff09\u3002", "conclusion": "\u63d0\u51fa\u7684\u611f\u77e5\u51fd\u6570\u80fd\u591f\u4e3a\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u627e\u5230\u6b63\u786e\u7684\u611f\u77e5\uff0c\u9f13\u52b1\u4f7f\u7528\u8be5\u611f\u77e5\u6a21\u578b\u6765\u8bc4\u4f30\u5b66\u4e60\u6a21\u578b\u7684\u6548\u7528\u5e76\u786e\u5b9a\u9002\u5408\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u611f\u77e5\u3002"}}
{"id": "2510.13102", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.13102", "abs": "https://arxiv.org/abs/2510.13102", "authors": ["Victor Olaiya", "Adwait Nadkarni"], "title": "From base cases to backdoors: An Empirical Study of Unnatural Crypto-API Misuse", "comment": null, "summary": "Tools focused on cryptographic API misuse often detect the most basic\nexpressions of the vulnerable use, and are unable to detect non-trivial\nvariants. The question of whether tools should be designed to detect such\nvariants can only be answered if we know how developers use and misuse\ncryptographic APIs in the wild, and in particular, what the unnatural usage of\nsuch APIs looks like. This paper presents the first large-scale study that\ncharacterizes unnatural crypto-API usage through a qualitative analysis of\n5,704 representative API invocations. We develop an intuitive complexity metric\nto stratify 140,431 crypto-API invocations obtained from 20,508 Android\napplications, allowing us to sample 5,704 invocations that are representative\nof all strata, with each stratum consisting of invocations with similar\ncomplexity/naturalness. We qualitatively analyze the 5,704 sampled invocations\nusing manual reverse engineering, through an in-depth investigation that\ninvolves the development of minimal examples and exploration of native code.\nOur study results in two detailed taxonomies of unnatural crypto-API misuse,\nalong with 17 key findings that show the presence of highly unusual misuse,\nevasive code, and the inability of popular tools to reason about even mildly\nunconventional usage. Our findings lead to four key takeaways that inform\nfuture work focused on detecting unnatural crypto-API misuse.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5927\u89c4\u6a21\u7814\u7a76\u5206\u6790\u4e86\u5bc6\u7801API\u7684\u975e\u81ea\u7136\u4f7f\u7528\u6a21\u5f0f\uff0c\u5f00\u53d1\u4e86\u590d\u6742\u5ea6\u6307\u6807\u5bf9140,431\u4e2aAPI\u8c03\u7528\u8fdb\u884c\u5206\u5c42\uff0c\u5e76\u624b\u52a8\u5206\u6790\u4e865,704\u4e2a\u4ee3\u8868\u6027\u8c03\u7528\uff0c\u5efa\u7acb\u4e86\u975e\u81ea\u7136\u8bef\u7528\u7684\u8be6\u7ec6\u5206\u7c7b\u6cd5\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u53ea\u80fd\u68c0\u6d4b\u57fa\u672c\u7684\u5bc6\u7801API\u8bef\u7528\uff0c\u65e0\u6cd5\u8bc6\u522b\u975e\u5e73\u51e1\u53d8\u4f53\u3002\u9700\u8981\u4e86\u89e3\u5f00\u53d1\u8005\u5982\u4f55\u5728\u5b9e\u9645\u73af\u5883\u4e2d\u4f7f\u7528\u548c\u8bef\u7528\u5bc6\u7801API\uff0c\u7279\u522b\u662f\u975e\u81ea\u7136\u4f7f\u7528\u6a21\u5f0f\uff0c\u4ee5\u6307\u5bfc\u5de5\u5177\u8bbe\u8ba1\u3002", "method": "\u5f00\u53d1\u76f4\u89c2\u7684\u590d\u6742\u5ea6\u6307\u6807\u5bf9140,431\u4e2a\u5bc6\u7801API\u8c03\u7528\u8fdb\u884c\u5206\u5c42\uff0c\u4ece20,508\u4e2aAndroid\u5e94\u7528\u4e2d\u91c7\u68375,704\u4e2a\u4ee3\u8868\u6027\u8c03\u7528\uff0c\u901a\u8fc7\u624b\u52a8\u9006\u5411\u5de5\u7a0b\u3001\u5f00\u53d1\u6700\u5c0f\u793a\u4f8b\u548c\u63a2\u7d22\u539f\u751f\u4ee3\u7801\u8fdb\u884c\u5b9a\u6027\u5206\u6790\u3002", "result": "\u7814\u7a76\u5efa\u7acb\u4e86\u4e24\u4e2a\u8be6\u7ec6\u7684\u975e\u81ea\u7136\u5bc6\u7801API\u8bef\u7528\u5206\u7c7b\u6cd5\uff0c\u53d1\u73b0\u4e8617\u4e2a\u5173\u952e\u53d1\u73b0\uff0c\u5305\u62ec\u9ad8\u5ea6\u4e0d\u5bfb\u5e38\u7684\u8bef\u7528\u3001\u89c4\u907f\u4ee3\u7801\uff0c\u4ee5\u53ca\u6d41\u884c\u5de5\u5177\u65e0\u6cd5\u5904\u7406\u8f7b\u5fae\u975e\u4f20\u7edf\u4f7f\u7528\u7684\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u672a\u6765\u68c0\u6d4b\u975e\u81ea\u7136\u5bc6\u7801API\u8bef\u7528\u7684\u5de5\u4f5c\u63d0\u4f9b\u4e86\u56db\u4e2a\u5173\u952e\u542f\u793a\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u6539\u8fdb\u5de5\u5177\u4ee5\u5904\u7406\u66f4\u590d\u6742\u7684\u8bef\u7528\u6a21\u5f0f\u3002"}}
{"id": "2510.13417", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.13417", "abs": "https://arxiv.org/abs/2510.13417", "authors": ["Liesbeth Allein", "Nataly Pineda-Casta\u00f1eda", "Andrea Rocci", "Marie-Francine Moens"], "title": "Assessing LLM Reasoning Through Implicit Causal Chain Discovery in Climate Discourse", "comment": null, "summary": "How does a cause lead to an effect, and which intermediate causal steps\nexplain their connection? This work scrutinizes the mechanistic causal\nreasoning capabilities of large language models (LLMs) to answer these\nquestions through the task of implicit causal chain discovery. In a diagnostic\nevaluation framework, we instruct nine LLMs to generate all possible\nintermediate causal steps linking given cause-effect pairs in causal chain\nstructures. These pairs are drawn from recent resources in argumentation\nstudies featuring polarized discussion on climate change. Our analysis reveals\nthat LLMs vary in the number and granularity of causal steps they produce.\nAlthough they are generally self-consistent and confident about the\nintermediate causal connections in the generated chains, their judgments are\nmainly driven by associative pattern matching rather than genuine causal\nreasoning. Nonetheless, human evaluations confirmed the logical coherence and\nintegrity of the generated chains. Our baseline causal chain discovery\napproach, insights from our diagnostic evaluation, and benchmark dataset with\ncausal chains lay a solid foundation for advancing future work in implicit,\nmechanistic causal reasoning in argumentation settings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u673a\u5236\u6027\u56e0\u679c\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u9690\u5f0f\u56e0\u679c\u94fe\u53d1\u73b0\u4efb\u52a1\uff0c\u5206\u6790\u6a21\u578b\u5982\u4f55\u751f\u6210\u8fde\u63a5\u7ed9\u5b9a\u56e0\u679c\u5bf9\u7684\u4e2d\u95f4\u56e0\u679c\u6b65\u9aa4\u3002\u7814\u7a76\u53d1\u73b0LLMs\u5728\u751f\u6210\u56e0\u679c\u6b65\u9aa4\u7684\u6570\u91cf\u548c\u7c92\u5ea6\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u4e3b\u8981\u4f9d\u8d56\u5173\u8054\u6a21\u5f0f\u5339\u914d\u800c\u975e\u771f\u6b63\u7684\u56e0\u679c\u63a8\u7406\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u7406\u89e3\u56e0\u679c\u5173\u7cfb\u7684\u673a\u5236\uff0c\u7279\u522b\u662f\u5b83\u4eec\u80fd\u5426\u8bc6\u522b\u548c\u751f\u6210\u8fde\u63a5\u56e0\u679c\u5bf9\u7684\u4e2d\u95f4\u56e0\u679c\u6b65\u9aa4\uff0c\u4ee5\u8bc4\u4f30\u5176\u673a\u5236\u6027\u56e0\u679c\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u8bca\u65ad\u8bc4\u4f30\u6846\u67b6\uff0c\u8ba99\u4e2aLLMs\u4e3a\u6c14\u5019\u53d8\u5316\u8bba\u8bc1\u7814\u7a76\u4e2d\u7684\u56e0\u679c\u5bf9\u751f\u6210\u6240\u6709\u53ef\u80fd\u7684\u4e2d\u95f4\u56e0\u679c\u6b65\u9aa4\uff0c\u5206\u6790\u751f\u6210\u7684\u56e0\u679c\u94fe\u7ed3\u6784\u3002", "result": "LLMs\u5728\u751f\u6210\u56e0\u679c\u6b65\u9aa4\u7684\u6570\u91cf\u548c\u7c92\u5ea6\u4e0a\u8868\u73b0\u4e0d\u4e00\uff0c\u867d\u7136\u751f\u6210\u7684\u56e0\u679c\u94fe\u5728\u903b\u8f91\u4e0a\u5177\u6709\u4e00\u81f4\u6027\u548c\u5b8c\u6574\u6027\uff0c\u4f46\u5176\u5224\u65ad\u4e3b\u8981\u57fa\u4e8e\u5173\u8054\u6a21\u5f0f\u5339\u914d\u800c\u975e\u771f\u6b63\u7684\u56e0\u679c\u63a8\u7406\u3002", "conclusion": "\u7814\u7a76\u4e3a\u63a8\u8fdb\u9690\u5f0f\u673a\u5236\u6027\u56e0\u679c\u63a8\u7406\u5728\u8bba\u8bc1\u73af\u5883\u4e2d\u7684\u672a\u6765\u5de5\u4f5c\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u5305\u62ec\u57fa\u7ebf\u56e0\u679c\u94fe\u53d1\u73b0\u65b9\u6cd5\u3001\u8bca\u65ad\u8bc4\u4f30\u89c1\u89e3\u548c\u5e26\u56e0\u679c\u94fe\u7684\u57fa\u51c6\u6570\u636e\u96c6\u3002"}}
{"id": "2510.13322", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13322", "abs": "https://arxiv.org/abs/2510.13322", "authors": ["Baogang Song", "Dongdong Zhao", "Jianwen Xiang", "Qiben Xu", "Zizhuo Yu"], "title": "Injection, Attack and Erasure: Revocable Backdoor Attacks via Machine Unlearning", "comment": null, "summary": "Backdoor attacks pose a persistent security risk to deep neural networks\n(DNNs) due to their stealth and durability. While recent research has explored\nleveraging model unlearning mechanisms to enhance backdoor concealment,\nexisting attack strategies still leave persistent traces that may be detected\nthrough static analysis. In this work, we introduce the first paradigm of\nrevocable backdoor attacks, where the backdoor can be proactively and\nthoroughly removed after the attack objective is achieved. We formulate the\ntrigger optimization in revocable backdoor attacks as a bilevel optimization\nproblem: by simulating both backdoor injection and unlearning processes, the\ntrigger generator is optimized to achieve a high attack success rate (ASR)\nwhile ensuring that the backdoor can be easily erased through unlearning. To\nmitigate the optimization conflict between injection and removal objectives, we\nemploy a deterministic partition of poisoning and unlearning samples to reduce\nsampling-induced variance, and further apply the Projected Conflicting Gradient\n(PCGrad) technique to resolve the remaining gradient conflicts. Experiments on\nCIFAR-10 and ImageNet demonstrate that our method maintains ASR comparable to\nstate-of-the-art backdoor attacks, while enabling effective removal of backdoor\nbehavior after unlearning. This work opens a new direction for backdoor attack\nresearch and presents new challenges for the security of machine learning\nsystems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u53ef\u64a4\u9500\u540e\u95e8\u653b\u51fb\u8303\u5f0f\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u65b9\u6cd5\u8bbe\u8ba1\u89e6\u53d1\u5668\uff0c\u4f7f\u5176\u5728\u653b\u51fb\u6210\u529f\u540e\u80fd\u901a\u8fc7\u9057\u5fd8\u673a\u5236\u4e3b\u52a8\u5f7b\u5e95\u79fb\u9664\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u540e\u95e8\u653b\u51fb\u5b58\u5728\u7684\u6301\u4e45\u6027\u75d5\u8ff9\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u540e\u95e8\u653b\u51fb\u7b56\u7565\u5728\u5229\u7528\u6a21\u578b\u9057\u5fd8\u673a\u5236\u589e\u5f3a\u9690\u853d\u6027\u7684\u540c\u65f6\uff0c\u4ecd\u4f1a\u7559\u4e0b\u53ef\u80fd\u88ab\u9759\u6001\u5206\u6790\u68c0\u6d4b\u5230\u7684\u6301\u4e45\u75d5\u8ff9\uff0c\u8fd9\u6784\u6210\u4e86\u6301\u7eed\u7684\u5b89\u5168\u98ce\u9669\u3002", "method": "\u5c06\u53ef\u64a4\u9500\u540e\u95e8\u653b\u51fb\u4e2d\u7684\u89e6\u53d1\u5668\u4f18\u5316\u5efa\u6a21\u4e3a\u53cc\u5c42\u4f18\u5316\u95ee\u9898\uff1a\u901a\u8fc7\u6a21\u62df\u540e\u95e8\u6ce8\u5165\u548c\u9057\u5fd8\u8fc7\u7a0b\uff0c\u4f18\u5316\u89e6\u53d1\u5668\u751f\u6210\u5668\u4ee5\u5b9e\u73b0\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u786e\u4fdd\u540e\u95e8\u80fd\u901a\u8fc7\u9057\u5fd8\u8f7b\u677e\u64e6\u9664\u3002\u91c7\u7528\u786e\u5b9a\u6027\u5212\u5206\u4e2d\u6bd2\u548c\u9057\u5fd8\u6837\u672c\u51cf\u5c11\u91c7\u6837\u65b9\u5dee\uff0c\u5e76\u5e94\u7528\u6295\u5f71\u51b2\u7a81\u68af\u5ea6\u6280\u672f\u89e3\u51b3\u5269\u4f59\u68af\u5ea6\u51b2\u7a81\u3002", "result": "\u5728CIFAR-10\u548cImageNet\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u4e0e\u6700\u5148\u8fdb\u540e\u95e8\u653b\u51fb\u76f8\u5f53\u7684\u653b\u51fb\u6210\u529f\u7387\u7684\u540c\u65f6\uff0c\u80fd\u591f\u901a\u8fc7\u9057\u5fd8\u6709\u6548\u79fb\u9664\u540e\u95e8\u884c\u4e3a\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u540e\u95e8\u653b\u51fb\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u5e76\u4e3a\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u63d0\u51fa\u4e86\u65b0\u7684\u6311\u6218\u3002"}}
{"id": "2510.13370", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.13370", "abs": "https://arxiv.org/abs/2510.13370", "authors": ["Fernando Castillo", "Eduardo Brito", "Sebastian Werner", "Pille Pullonen-Raudvere", "Jonathan Heiss"], "title": "Towards Trusted Service Monitoring: Verifiable Service Level Agreements", "comment": "To be published in 3rd International Conference on Service-Oriented\n  Computing (ICSOC 2025). 15 pages. 4 figures", "summary": "Service Level Agreement (SLA) monitoring in service-oriented environments\nsuffers from inherent trust conflicts when providers self-report metrics,\ncreating incentives to underreport violations. We introduce a framework for\ngenerating verifiable SLA violation claims through trusted hardware monitors\nand zero-knowledge proofs, establishing cryptographic foundations for genuine\ntrustworthiness in service ecosystems. Our approach starts with\nmachine-readable SLA clauses converted into verifiable predicates and monitored\nwithin Trusted Execution Environments. These monitors collect timestamped\ntelemetry, organize measurements into Merkle trees, and produce signed\nattestations. Zero-knowledge proofs aggregate Service-Level Indicators to\nevaluate compliance, generating cryptographic proofs verifiable by\nstakeholders, arbitrators, or insurers in disputes, without accessing\nunderlying data. This ensures three security properties: integrity,\nauthenticity, and validity. Our prototype demonstrates linear scaling up to\nover 1 million events per hour for measurements with near constant-time proof\ngeneration and verification for single violation claims, enabling trustless SLA\nenforcement through cryptographic guarantees for automated compliance\nverification in service monitoring.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u53ef\u4fe1\u786c\u4ef6\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\u7684SLA\u76d1\u63a7\u6846\u67b6\uff0c\u901a\u8fc7\u5bc6\u7801\u5b66\u4fdd\u8bc1\u670d\u52a1\u7ea7\u522b\u534f\u8bae\u8fdd\u89c4\u58f0\u660e\u7684\u53ef\u9a8c\u8bc1\u6027\uff0c\u5b9e\u73b0\u65e0\u9700\u4fe1\u4efb\u7684\u81ea\u52a8\u5316\u5408\u89c4\u9a8c\u8bc1\u3002", "motivation": "\u89e3\u51b3\u670d\u52a1\u5bfc\u5411\u73af\u5883\u4e2dSLA\u76d1\u63a7\u5b58\u5728\u7684\u4fe1\u4efb\u51b2\u7a81\u95ee\u9898\uff0c\u5f53\u63d0\u4f9b\u5546\u81ea\u884c\u62a5\u544a\u6307\u6807\u65f6\u5b58\u5728\u5c11\u62a5\u8fdd\u89c4\u7684\u52a8\u673a\uff0c\u9700\u8981\u5efa\u7acb\u5bc6\u7801\u5b66\u57fa\u7840\u6765\u786e\u4fdd\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u7684\u771f\u6b63\u53ef\u4fe1\u5ea6\u3002", "method": "\u5c06\u673a\u5668\u53ef\u8bfb\u7684SLA\u6761\u6b3e\u8f6c\u6362\u4e3a\u53ef\u9a8c\u8bc1\u8c13\u8bcd\uff0c\u5728\u53ef\u4fe1\u6267\u884c\u73af\u5883\u4e2d\u76d1\u63a7\uff0c\u6536\u96c6\u65f6\u95f4\u6233\u9065\u6d4b\u6570\u636e\u5e76\u7ec4\u7ec7\u6210Merkle\u6811\uff0c\u751f\u6210\u7b7e\u540d\u8bc1\u660e\uff0c\u4f7f\u7528\u96f6\u77e5\u8bc6\u8bc1\u660e\u805a\u5408\u670d\u52a1\u7ea7\u522b\u6307\u6807\u6765\u8bc4\u4f30\u5408\u89c4\u6027\u3002", "result": "\u539f\u578b\u7cfb\u7edf\u5c55\u793a\u4e86\u5bf9\u6bcf\u5c0f\u65f6\u8d85\u8fc7100\u4e07\u4e2a\u4e8b\u4ef6\u7684\u7ebf\u6027\u6269\u5c55\u80fd\u529b\uff0c\u5355\u4e2a\u8fdd\u89c4\u58f0\u660e\u7684\u8bc1\u660e\u751f\u6210\u548c\u9a8c\u8bc1\u65f6\u95f4\u63a5\u8fd1\u5e38\u6570\uff0c\u652f\u6301\u5927\u89c4\u6a21\u670d\u52a1\u76d1\u63a7\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5bc6\u7801\u5b66\u4fdd\u8bc1\u5b9e\u73b0\u4e86\u4e09\u4e2a\u5b89\u5168\u5c5e\u6027\uff1a\u5b8c\u6574\u6027\u3001\u771f\u5b9e\u6027\u548c\u6709\u6548\u6027\uff0c\u4e3a\u670d\u52a1\u76d1\u63a7\u4e2d\u7684\u81ea\u52a8\u5316\u5408\u89c4\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u65e0\u9700\u4fe1\u4efb\u7684SLA\u6267\u884c\u673a\u5236\u3002"}}
{"id": "2510.13691", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13691", "abs": "https://arxiv.org/abs/2510.13691", "authors": ["Cecilia Di Florio", "Huimin Dong", "Antonino Rotolo"], "title": "A Modal Logic for Temporal and Jurisdictional Classifier Models", "comment": "18 pages, 2 figures. Extended version of a short paper accepted at\n  PRIMA 2025. This is the authors' version of the work. It is posted here for\n  your personal use", "summary": "Logic-based models can be used to build verification tools for machine\nlearning classifiers employed in the legal field. ML classifiers predict the\noutcomes of new cases based on previous ones, thereby performing a form of\ncase-based reasoning (CBR). In this paper, we introduce a modal logic of\nclassifiers designed to formally capture legal CBR. We incorporate principles\nfor resolving conflicts between precedents, by introducing into the logic the\ntemporal dimension of cases and the hierarchy of courts within the legal\nsystem.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u5f62\u5f0f\u5316\u6cd5\u5f8b\u6848\u4f8b\u63a8\u7406\u7684\u5206\u7c7b\u5668\u6a21\u6001\u903b\u8f91\uff0c\u7ed3\u5408\u65f6\u95f4\u7ef4\u5ea6\u548c\u6cd5\u9662\u5c42\u7ea7\u6765\u89e3\u51b3\u5148\u4f8b\u51b2\u7a81", "motivation": "\u57fa\u4e8e\u903b\u8f91\u7684\u6a21\u578b\u53ef\u7528\u4e8e\u6784\u5efa\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u7684\u9a8c\u8bc1\u5de5\u5177\uff0c\u8fd9\u4e9b\u5206\u7c7b\u5668\u5728\u6cd5\u5f8b\u9886\u57df\u901a\u8fc7\u6848\u4f8b\u63a8\u7406\u9884\u6d4b\u65b0\u6848\u4ef6\u7ed3\u679c", "method": "\u5f15\u5165\u5206\u7c7b\u5668\u6a21\u6001\u903b\u8f91\uff0c\u6574\u5408\u6848\u4ef6\u65f6\u95f4\u7ef4\u5ea6\u548c\u6cd5\u9662\u7cfb\u7edf\u5c42\u7ea7\uff0c\u4e3a\u6cd5\u5f8b\u6848\u4f8b\u63a8\u7406\u63d0\u4f9b\u5f62\u5f0f\u5316\u6846\u67b6", "result": "\u5f00\u53d1\u4e86\u80fd\u591f\u5904\u7406\u5148\u4f8b\u51b2\u7a81\u7684\u903b\u8f91\u7cfb\u7edf\uff0c\u901a\u8fc7\u65f6\u95f4\u987a\u5e8f\u548c\u6cd5\u9662\u5c42\u7ea7\u5173\u7cfb\u6765\u534f\u8c03\u4e0d\u4e00\u81f4\u7684\u5148\u4f8b", "conclusion": "\u8be5\u903b\u8f91\u6846\u67b6\u4e3a\u9a8c\u8bc1\u6cd5\u5f8b\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u57fa\u7840\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6a21\u62df\u6cd5\u5f8b\u6848\u4f8b\u63a8\u7406\u8fc7\u7a0b"}}
{"id": "2510.13462", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.13462", "abs": "https://arxiv.org/abs/2510.13462", "authors": ["Xin Zhao", "Xiaojun Chen", "Bingshan Liu", "Haoyu Gao", "Zhendong Zhao", "Yilong Chen"], "title": "Who Speaks for the Trigger? Dynamic Expert Routing in Backdoored Mixture-of-Experts Transformers", "comment": null, "summary": "Large language models (LLMs) with Mixture-of-Experts (MoE) architectures\nachieve impressive performance and efficiency by dynamically routing inputs to\nspecialized subnetworks, known as experts. However, this sparse routing\nmechanism inherently exhibits task preferences due to expert specialization,\nintroducing a new and underexplored vulnerability to backdoor attacks. In this\nwork, we investigate the feasibility and effectiveness of injecting backdoors\ninto MoE-based LLMs by exploiting their inherent expert routing preferences. We\nthus propose BadSwitch, a novel backdoor framework that integrates task-coupled\ndynamic trigger optimization with a sensitivity-guided Top-S expert tracing\nmechanism. Our approach jointly optimizes trigger embeddings during pretraining\nwhile identifying S most sensitive experts, subsequently constraining the Top-K\ngating mechanism to these targeted experts. Unlike traditional backdoor attacks\nthat rely on superficial data poisoning or model editing, BadSwitch primarily\nembeds malicious triggers into expert routing paths with strong task affinity,\nenabling precise and stealthy model manipulation. Through comprehensive\nevaluations across three prominent MoE architectures (Switch Transformer,\nQwenMoE, and DeepSeekMoE), we demonstrate that BadSwitch can efficiently hijack\npre-trained models with up to 100% success rate (ASR) while maintaining the\nhighest clean accuracy (ACC) among all baselines. Furthermore, BadSwitch\nexhibits strong resilience against both text-level and model-level defense\nmechanisms, achieving 94.07% ASR and 87.18% ACC on the AGNews dataset. Our\nanalysis of expert activation patterns reveals fundamental insights into MoE\nvulnerabilities. We anticipate this work will expose security risks in MoE\nsystems and contribute to advancing AI safety.", "AI": {"tldr": "BadSwitch\u662f\u4e00\u79cd\u9488\u5bf9MoE\u67b6\u6784LLM\u7684\u65b0\u578b\u540e\u95e8\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u4e13\u5bb6\u8def\u7531\u504f\u597d\uff0c\u5c06\u6076\u610f\u89e6\u53d1\u5668\u5d4c\u5165\u5230\u5177\u6709\u5f3a\u4efb\u52a1\u4eb2\u548c\u529b\u7684\u4e13\u5bb6\u8def\u7531\u8def\u5f84\u4e2d\uff0c\u5b9e\u73b0\u7cbe\u786e\u4e14\u9690\u853d\u7684\u6a21\u578b\u64cd\u63a7\u3002", "motivation": "MoE\u67b6\u6784\u4e2d\u7684\u7a00\u758f\u8def\u7531\u673a\u5236\u7531\u4e8e\u4e13\u5bb6\u4e13\u4e1a\u5316\u800c\u8868\u73b0\u51fa\u4efb\u52a1\u504f\u597d\uff0c\u8fd9\u5f15\u5165\u4e86\u4e00\u4e2a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u540e\u95e8\u653b\u51fb\u6f0f\u6d1e\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5728MoE-based LLM\u4e2d\u6ce8\u5165\u540e\u95e8\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faBadSwitch\u6846\u67b6\uff0c\u96c6\u6210\u4efb\u52a1\u8026\u5408\u52a8\u6001\u89e6\u53d1\u5668\u4f18\u5316\u548c\u654f\u611f\u5ea6\u5f15\u5bfc\u7684Top-S\u4e13\u5bb6\u8ffd\u8e2a\u673a\u5236\u3002\u5728\u9884\u8bad\u7ec3\u671f\u95f4\u8054\u5408\u4f18\u5316\u89e6\u53d1\u5668\u5d4c\u5165\uff0c\u540c\u65f6\u8bc6\u522bS\u4e2a\u6700\u654f\u611f\u4e13\u5bb6\uff0c\u968f\u540e\u5c06Top-K\u95e8\u63a7\u673a\u5236\u9650\u5236\u5728\u8fd9\u4e9b\u76ee\u6807\u4e13\u5bb6\u4e0a\u3002", "result": "\u5728\u4e09\u79cd\u4e3b\u6d41MoE\u67b6\u6784\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u663e\u793a\uff0cBadSwitch\u80fd\u9ad8\u6548\u52ab\u6301\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u6210\u529f\u7387\u9ad8\u8fbe100%\uff0c\u540c\u65f6\u5728\u6240\u6709\u57fa\u7ebf\u4e2d\u4fdd\u6301\u6700\u9ad8\u7684\u5e72\u51c0\u51c6\u786e\u7387\u3002\u5728AGNews\u6570\u636e\u96c6\u4e0a\u8fbe\u523094.07%\u653b\u51fb\u6210\u529f\u7387\u548c87.18%\u5e72\u51c0\u51c6\u786e\u7387\uff0c\u5bf9\u6587\u672c\u7ea7\u548c\u6a21\u578b\u7ea7\u9632\u5fa1\u673a\u5236\u8868\u73b0\u51fa\u5f3a\u97e7\u6027\u3002", "conclusion": "BadSwitch\u66b4\u9732\u4e86MoE\u7cfb\u7edf\u7684\u5b89\u5168\u98ce\u9669\uff0c\u4e13\u5bb6\u6fc0\u6d3b\u6a21\u5f0f\u5206\u6790\u63ed\u793a\u4e86MoE\u6f0f\u6d1e\u7684\u57fa\u672c\u89c1\u89e3\uff0c\u8fd9\u9879\u5de5\u4f5c\u5c06\u6709\u52a9\u4e8e\u63a8\u8fdbAI\u5b89\u5168\u53d1\u5c55\u3002"}}
{"id": "2510.13538", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.13538", "abs": "https://arxiv.org/abs/2510.13538", "authors": ["Alexander Ponticello", "Filipo Sharevski", "Simon Anell", "Katharina Krombholz"], "title": "How Blind and Low-Vision Users Manage Their Passwords", "comment": null, "summary": "Managing passwords securely and conveniently is still an open problem for\nmany users. Existing research has examined users' password management\nstrategies and identified pain points, such as security concerns, leading to\ninsecure practices. We investigate how Blind and Low-Vision (BLV) users tackle\nthis problem and how password managers can assist them. This paper presents the\nresults of a qualitative interview study with N = 33 BLV participants. We found\nthat all participants utilize password managers to some extent, which they\nperceive as fairly accessible. However, the adoption is mainly driven by the\nconvenience of storing and retrieving passwords. The security advantages -\ngenerating strong, random passwords - were avoided mainly due to the absence of\npractical accessibility. Password managers do not adhere to BLV users'\nunderlying needs for agency, which stem from experiences with inaccessible\nsoftware and vendors who deprioritize accessibility issues. Underutilization of\npassword managers leads BLV users to adopt insecure practices, such as reusing\npredictable passwords or resorting to 'security through obscurity' by writing\nimportant credentials in braille. We conclude our analysis by discussing the\nneed to implement practical accessibility and usability improvements for\npassword managers as a way of establishing trust and secure practices while\nmaintaining BLV users' agency.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8c03\u67e5\u4e86\u76f2\u4eba\u548c\u4f4e\u89c6\u529b\u7528\u6237\u5982\u4f55\u4f7f\u7528\u5bc6\u7801\u7ba1\u7406\u5668\uff0c\u53d1\u73b0\u867d\u7136\u6240\u6709\u53c2\u4e0e\u8005\u90fd\u4f7f\u7528\u5bc6\u7801\u7ba1\u7406\u5668\uff0c\u4f46\u4e3b\u8981\u662f\u4e3a\u4e86\u5b58\u50a8\u548c\u68c0\u7d22\u5bc6\u7801\u7684\u4fbf\u5229\u6027\uff0c\u800c\u975e\u5b89\u5168\u4f18\u52bf\u3002\u5bc6\u7801\u7ba1\u7406\u5668\u672a\u80fd\u6ee1\u8db3BLV\u7528\u6237\u5bf9\u81ea\u4e3b\u6743\u7684\u9700\u6c42\uff0c\u5bfc\u81f4\u4ed6\u4eec\u91c7\u7528\u4e0d\u5b89\u5168\u7684\u5bc6\u7801\u5b9e\u8df5\u3002", "motivation": "\u7814\u7a76\u76f2\u4eba\u548c\u4f4e\u89c6\u529b\u7528\u6237\u5728\u5bc6\u7801\u7ba1\u7406\u65b9\u9762\u7684\u6311\u6218\uff0c\u4ee5\u53ca\u5bc6\u7801\u7ba1\u7406\u5668\u5982\u4f55\u5e2e\u52a9\u4ed6\u4eec\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002\u73b0\u6709\u7814\u7a76\u8868\u660e\u7528\u6237\u5b58\u5728\u5b89\u5168\u62c5\u5fe7\u5bfc\u81f4\u4e0d\u5b89\u5168\u5b9e\u8df5\uff0c\u4f46\u7f3a\u4e4f\u5bf9BLV\u7528\u6237\u7279\u5b9a\u9700\u6c42\u7684\u7814\u7a76\u3002", "method": "\u91c7\u7528\u5b9a\u6027\u8bbf\u8c08\u7814\u7a76\u65b9\u6cd5\uff0c\u5bf933\u540d\u76f2\u4eba\u548c\u4f4e\u89c6\u529b\u53c2\u4e0e\u8005\u8fdb\u884c\u8bbf\u8c08\u7814\u7a76\u3002", "result": "\u6240\u6709\u53c2\u4e0e\u8005\u90fd\u4f7f\u7528\u5bc6\u7801\u7ba1\u7406\u5668\uff0c\u4e3b\u8981\u51fa\u4e8e\u5b58\u50a8\u548c\u68c0\u7d22\u5bc6\u7801\u7684\u4fbf\u5229\u6027\u3002\u5b89\u5168\u4f18\u52bf\uff08\u751f\u6210\u5f3a\u968f\u673a\u5bc6\u7801\uff09\u56e0\u7f3a\u4e4f\u5b9e\u9645\u53ef\u8bbf\u95ee\u6027\u800c\u88ab\u907f\u514d\u3002\u5bc6\u7801\u7ba1\u7406\u5668\u672a\u80fd\u6ee1\u8db3BLV\u7528\u6237\u5bf9\u81ea\u4e3b\u6743\u7684\u9700\u6c42\uff0c\u5bfc\u81f4\u4e0d\u5b89\u5168\u5b9e\u8df5\uff0c\u5982\u91cd\u590d\u4f7f\u7528\u53ef\u9884\u6d4b\u5bc6\u7801\u6216\u5728\u76f2\u6587\u4e2d\u4e66\u5199\u91cd\u8981\u51ed\u636e\u3002", "conclusion": "\u9700\u8981\u6539\u8fdb\u5bc6\u7801\u7ba1\u7406\u5668\u7684\u5b9e\u9645\u53ef\u8bbf\u95ee\u6027\u548c\u53ef\u7528\u6027\uff0c\u4ee5\u5efa\u7acb\u4fe1\u4efb\u548c\u5b89\u5168\u5b9e\u8df5\uff0c\u540c\u65f6\u7ef4\u62a4BLV\u7528\u6237\u7684\u81ea\u4e3b\u6743\u3002"}}
{"id": "2510.13744", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13744", "abs": "https://arxiv.org/abs/2510.13744", "authors": ["Shrey Pandit", "Austin Xu", "Xuan-Phi Nguyen", "Yifei Ming", "Caiming Xiong", "Shafiq Joty"], "title": "Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier Math", "comment": "21 pages, 8 figures, 5 tables", "summary": "Large language model (LLM)-based reasoning systems have recently achieved\ngold medal-level performance in the IMO 2025 competition, writing mathematical\nproofs where, to receive full credit, each step must be not only correct but\nalso sufficiently supported. To train LLM-based reasoners in such challenging,\nopen-ended settings, strong verifiers capable of catching step-level mistakes\nare necessary prerequisites. We introduce Hard2Verify, a human-annotated,\nstep-level verification benchmark produced with over 500 hours of human labor.\nHard2Verify is designed to rigorously assess step-level verifiers at the\nfrontier: Verifiers must provide step-level annotations or identify the first\nerror in responses generated by frontier LLMs for very recent, challenging, and\nopen-ended math questions. We evaluate 29 generative critics and process reward\nmodels, demonstrating that, beyond a few standouts, open-source verifiers lag\nclosed source models. We subsequently analyze what drives poor performance in\nstep-level verification, the impacts of scaling verifier compute, as well as\nfundamental questions such as self-verification and verification-generation\ndynamics.", "AI": {"tldr": "Hard2Verify\u662f\u4e00\u4e2a\u4eba\u5de5\u6807\u6ce8\u7684\u6b65\u9aa4\u7ea7\u9a8c\u8bc1\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u524d\u6cbfLLM\u5728\u6570\u5b66\u8bc1\u660e\u4e2d\u7684\u6b65\u9aa4\u9a8c\u8bc1\u80fd\u529b\uff0c\u53d1\u73b0\u5f00\u6e90\u9a8c\u8bc1\u5668\u666e\u904d\u843d\u540e\u4e8e\u95ed\u6e90\u6a21\u578b\u3002", "motivation": "\u5728IMO 2025\u7b49\u6570\u5b66\u7ade\u8d5b\u4e2d\uff0cLLM\u9700\u8981\u751f\u6210\u4e0d\u4ec5\u6b63\u786e\u800c\u4e14\u5145\u5206\u652f\u6301\u7684\u8bc1\u660e\u6b65\u9aa4\uff0c\u56e0\u6b64\u9700\u8981\u5f3a\u5927\u7684\u6b65\u9aa4\u7ea7\u9a8c\u8bc1\u5668\u6765\u8bad\u7ec3LLM\u63a8\u7406\u7cfb\u7edf\u3002", "method": "\u6784\u5efa\u4e86Hard2Verify\u57fa\u51c6\uff0c\u5305\u542b500\u591a\u5c0f\u65f6\u4eba\u5de5\u6807\u6ce8\u7684\u6b65\u9aa4\u7ea7\u9a8c\u8bc1\u6570\u636e\uff0c\u8bc4\u4f30\u4e8629\u4e2a\u751f\u6210\u5f0f\u6279\u8bc4\u5668\u548c\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u5728\u6311\u6218\u6027\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u9664\u4e86\u5c11\u6570\u8868\u73b0\u4f18\u5f02\u8005\u5916\uff0c\u5f00\u6e90\u9a8c\u8bc1\u5668\u666e\u904d\u843d\u540e\u4e8e\u95ed\u6e90\u6a21\u578b\uff0c\u7814\u7a76\u8fd8\u5206\u6790\u4e86\u6b65\u9aa4\u7ea7\u9a8c\u8bc1\u6027\u80fd\u5dee\u7684\u539f\u56e0\u3001\u9a8c\u8bc1\u5668\u8ba1\u7b97\u89c4\u6a21\u7684\u5f71\u54cd\u4ee5\u53ca\u81ea\u9a8c\u8bc1\u548c\u9a8c\u8bc1-\u751f\u6210\u52a8\u6001\u7b49\u57fa\u672c\u95ee\u9898\u3002", "conclusion": "Hard2Verify\u57fa\u51c6\u4e3a\u8bc4\u4f30\u524d\u6cbf\u6b65\u9aa4\u7ea7\u9a8c\u8bc1\u5668\u63d0\u4f9b\u4e86\u4e25\u683c\u6807\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u9a8c\u8bc1\u5668\u5728\u6570\u5b66\u8bc1\u660e\u6b65\u9aa4\u9a8c\u8bc1\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u6539\u8fdbLLM\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}

{"id": "2512.20677", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.20677", "abs": "https://arxiv.org/abs/2512.20677", "authors": ["Zhang Wei", "Peilu Hu", "Shengning Lang", "Hao Yan", "Li Mei", "Yichao Zhang", "Chen Yang", "Junfeng Hao", "Zhimo Han"], "title": "Automated Red-Teaming Framework for Large Language Model Security Assessment: A Comprehensive Attack Generation and Detection System", "comment": "18 pages", "summary": "As large language models (LLMs) are increasingly deployed in high-stakes domains, ensuring their security and alignment has become a critical challenge. Existing red-teaming practices depend heavily on manual testing, which limits scalability and fails to comprehensively cover the vast space of potential adversarial behaviors. This paper introduces an automated red-teaming framework that systematically generates, executes, and evaluates adversarial prompts to uncover security vulnerabilities in LLMs. Our framework integrates meta-prompting-based attack synthesis, multi-modal vulnerability detection, and standardized evaluation protocols spanning six major threat categories -- reward hacking, deceptive alignment, data exfiltration, sandbagging, inappropriate tool use, and chain-of-thought manipulation. Experiments on the GPT-OSS-20B model reveal 47 distinct vulnerabilities, including 21 high-severity and 12 novel attack patterns, achieving a $3.9\\times$ improvement in vulnerability discovery rate over manual expert testing while maintaining 89\\% detection accuracy. These results demonstrate the framework's effectiveness in enabling scalable, systematic, and reproducible AI safety evaluations. By providing actionable insights for improving alignment robustness, this work advances the state of automated LLM red-teaming and contributes to the broader goal of building secure and trustworthy AI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u7ea2\u961f\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u6027\u5730\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u76f8\u6bd4\u4eba\u5de5\u6d4b\u8bd5\u5728\u6f0f\u6d1e\u53d1\u73b0\u7387\u4e0a\u63d0\u5347\u4e863.9\u500d\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5173\u952e\u9886\u57df\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u786e\u4fdd\u5176\u5b89\u5168\u6027\u548c\u5bf9\u9f50\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7684\u7ea2\u961f\u6d4b\u8bd5\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\u65b9\u6cd5\uff0c\u8fd9\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u65e0\u6cd5\u5168\u9762\u8986\u76d6\u6f5c\u5728\u7684\u5bf9\u6297\u884c\u4e3a\u7a7a\u95f4\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u7ea2\u961f\u6d4b\u8bd5\u6846\u67b6\uff0c\u96c6\u6210\u4e86\u57fa\u4e8e\u5143\u63d0\u793a\u7684\u653b\u51fb\u5408\u6210\u3001\u591a\u6a21\u6001\u6f0f\u6d1e\u68c0\u6d4b\u548c\u6807\u51c6\u5316\u8bc4\u4f30\u534f\u8bae\uff0c\u6db5\u76d6\u516d\u5927\u5a01\u80c1\u7c7b\u522b\uff1a\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u3001\u6b3a\u9a97\u6027\u5bf9\u9f50\u3001\u6570\u636e\u6cc4\u9732\u3001\u6545\u610f\u8868\u73b0\u4e0d\u4f73\u3001\u4e0d\u5f53\u5de5\u5177\u4f7f\u7528\u548c\u601d\u7ef4\u94fe\u64cd\u7eb5\u3002", "result": "\u5728GPT-OSS-20B\u6a21\u578b\u4e0a\u53d1\u73b0\u4e8647\u4e2a\u4e0d\u540c\u7684\u6f0f\u6d1e\uff0c\u5305\u62ec21\u4e2a\u9ad8\u4e25\u91cd\u6027\u6f0f\u6d1e\u548c12\u4e2a\u65b0\u9896\u653b\u51fb\u6a21\u5f0f\uff0c\u6f0f\u6d1e\u53d1\u73b0\u7387\u6bd4\u4eba\u5de5\u4e13\u5bb6\u6d4b\u8bd5\u63d0\u9ad8\u4e863.9\u500d\uff0c\u540c\u65f6\u4fdd\u630189%\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u7cfb\u7edf\u5316\u548c\u53ef\u590d\u73b0\u7684AI\u5b89\u5168\u8bc4\u4f30\u65b9\u9762\u8868\u73b0\u51fa\u6709\u6548\u6027\uff0c\u4e3a\u6539\u8fdb\u5bf9\u9f50\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u63a8\u52a8\u4e86\u81ea\u52a8\u5316LLM\u7ea2\u961f\u6d4b\u8bd5\u7684\u53d1\u5c55\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u5b89\u5168\u53ef\u4fe1\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2512.20705", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.20705", "abs": "https://arxiv.org/abs/2512.20705", "authors": ["Meng Wang", "Philipp G\u00f6rz", "Joschua Schilling", "Keno Hassler", "Liwei Guo", "Thorsten Holz", "Ali Abbasi"], "title": "Anota: Identifying Business Logic Vulnerabilities via Annotation-Based Sanitization", "comment": null, "summary": "Detecting business logic vulnerabilities is a critical challenge in software security. These flaws come from mistakes in an application's design or implementation and allow attackers to trigger unintended application behavior. Traditional fuzzing sanitizers for dynamic analysis excel at finding vulnerabilities related to memory safety violations but largely fail to detect business logic vulnerabilities, as these flaws require understanding application-specific semantic context. Recent attempts to infer this context, due to their reliance on heuristics and non-portable language features, are inherently brittle and incomplete. As business logic vulnerabilities constitute a majority (27/40) of the most dangerous software weaknesses in practice, this is a worrying blind spot of existing tools. In this paper, we tackle this challenge with ANOTA, a novel human-in-the-loop sanitizer framework. ANOTA introduces a lightweight, user-friendly annotation system that enables users to directly encode their domain-specific knowledge as lightweight annotations that define an application's intended behavior. A runtime execution monitor then observes program behavior, comparing it against the policies defined by the annotations, thereby identifying deviations that indicate vulnerabilities. To evaluate the effectiveness of ANOTA, we combine ANOTA with a state-of-the-art fuzzer and compare it against other popular bug finding methods compatible with the same targets. The results show that ANOTA+FUZZER outperforms them in terms of effectiveness. More specifically, ANOTA+FUZZER can successfully reproduce 43 known vulnerabilities, and discovered 22 previously unknown vulnerabilities (17 CVEs assigned) during the evaluation. These results demonstrate that ANOTA provides a practical and effective approach for uncovering complex business logic flaws often missed by traditional security testing techniques.", "AI": {"tldr": "ANOTA\u662f\u4e00\u4e2a\u4eba\u7c7b\u53c2\u4e0e\u5faa\u73af\u7684sanitizer\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6ce8\u91ca\u7cfb\u7edf\u8ba9\u7528\u6237\u7f16\u7801\u9886\u57df\u77e5\u8bc6\uff0c\u8fd0\u884c\u65f6\u76d1\u63a7\u7a0b\u5e8f\u884c\u4e3a\u4e0e\u6ce8\u91ca\u5b9a\u4e49\u7b56\u7565\u7684\u504f\u5dee\uff0c\u4ece\u800c\u68c0\u6d4b\u4f20\u7edf\u6a21\u7cca\u6d4b\u8bd5\u96be\u4ee5\u53d1\u73b0\u7684\u4e1a\u52a1\u903b\u8f91\u6f0f\u6d1e\u3002", "motivation": "\u4e1a\u52a1\u903b\u8f91\u6f0f\u6d1e\u662f\u8f6f\u4ef6\u5b89\u5168\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4f20\u7edf\u6a21\u7cca\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u5185\u5b58\u5b89\u5168\u6f0f\u6d1e\uff0c\u65e0\u6cd5\u6709\u6548\u68c0\u6d4b\u9700\u8981\u7406\u89e3\u5e94\u7528\u7279\u5b9a\u8bed\u4e49\u4e0a\u4e0b\u6587\u7684\u4e1a\u52a1\u903b\u8f91\u6f0f\u6d1e\u3002\u8fd9\u4e9b\u6f0f\u6d1e\u5360\u6700\u5371\u9669\u8f6f\u4ef6\u5f31\u70b9\u7684\u5927\u591a\u6570\uff0827/40\uff09\uff0c\u662f\u73b0\u6709\u5de5\u5177\u7684\u76f2\u533a\u3002", "method": "ANOTA\u5f15\u5165\u8f7b\u91cf\u7ea7\u3001\u7528\u6237\u53cb\u597d\u7684\u6ce8\u91ca\u7cfb\u7edf\uff0c\u8ba9\u7528\u6237\u76f4\u63a5\u7f16\u7801\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u4f5c\u4e3a\u8f7b\u91cf\u7ea7\u6ce8\u91ca\u6765\u5b9a\u4e49\u5e94\u7528\u7684\u9884\u671f\u884c\u4e3a\u3002\u8fd0\u884c\u65f6\u6267\u884c\u76d1\u63a7\u5668\u89c2\u5bdf\u7a0b\u5e8f\u884c\u4e3a\uff0c\u5c06\u5176\u4e0e\u6ce8\u91ca\u5b9a\u4e49\u7684\u653f\u7b56\u8fdb\u884c\u6bd4\u8f83\uff0c\u8bc6\u522b\u6307\u793a\u6f0f\u6d1e\u7684\u504f\u5dee\u3002", "result": "ANOTA\u4e0e\u6700\u5148\u8fdb\u7684\u6a21\u7cca\u6d4b\u8bd5\u5668\u7ed3\u5408\u540e\uff0c\u6bd4\u5176\u4ed6\u517c\u5bb9\u76f8\u540c\u76ee\u6807\u7684\u9519\u8bef\u53d1\u73b0\u65b9\u6cd5\u66f4\u6709\u6548\u3002\u6210\u529f\u590d\u73b0\u4e8643\u4e2a\u5df2\u77e5\u6f0f\u6d1e\uff0c\u53d1\u73b0\u4e8622\u4e2a\u5148\u524d\u672a\u77e5\u7684\u6f0f\u6d1e\uff08\u5176\u4e2d17\u4e2a\u83b7\u5f97CVE\u7f16\u53f7\uff09\u3002", "conclusion": "ANOTA\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u6709\u6548\u7684\u65b9\u6cd5\u6765\u53d1\u73b0\u4f20\u7edf\u5b89\u5168\u6d4b\u8bd5\u6280\u672f\u7ecf\u5e38\u9057\u6f0f\u7684\u590d\u6742\u4e1a\u52a1\u903b\u8f91\u7f3a\u9677\uff0c\u586b\u8865\u4e86\u73b0\u6709\u5de5\u5177\u7684\u76f2\u533a\u3002"}}
{"id": "2512.20712", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.20712", "abs": "https://arxiv.org/abs/2512.20712", "authors": ["Omer Gazit", "Yael Itzhakev", "Yuval Elovici", "Asaf Shabtai"], "title": "Real-World Adversarial Attacks on RF-Based Drone Detectors", "comment": null, "summary": "Radio frequency (RF) based systems are increasingly used to detect drones by analyzing their RF signal patterns, converting them into spectrogram images which are processed by object detection models. Existing RF attacks against image based models alter digital features, making over-the-air (OTA) implementation difficult due to the challenge of converting digital perturbations to transmittable waveforms that may introduce synchronization errors and interference, and encounter hardware limitations. We present the first physical attack on RF image based drone detectors, optimizing class-specific universal complex baseband (I/Q) perturbation waveforms that are transmitted alongside legitimate communications. We evaluated the attack using RF recordings and OTA experiments with four types of drones. Our results show that modest, structured I/Q perturbations are compatible with standard RF chains and reliably reduce target drone detection while preserving detection of legitimate drones.", "AI": {"tldr": "\u9996\u6b21\u9488\u5bf9\u57fa\u4e8eRF\u56fe\u50cf\u7684\u65e0\u4eba\u673a\u68c0\u6d4b\u7cfb\u7edf\u63d0\u51fa\u7269\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u7279\u5b9a\u7c7b\u522b\u7684\u901a\u7528\u590d\u6570\u57fa\u5e26\u6270\u52a8\u6ce2\u5f62\uff0c\u5728\u5408\u6cd5\u901a\u4fe1\u4fe1\u53f7\u65c1\u4f20\u8f93\uff0c\u6709\u6548\u964d\u4f4e\u76ee\u6807\u65e0\u4eba\u673a\u68c0\u6d4b\u7387\u540c\u65f6\u4fdd\u6301\u5408\u6cd5\u65e0\u4eba\u673a\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u9488\u5bf9\u56fe\u50cf\u6a21\u578b\u7684RF\u653b\u51fb\u4e3b\u8981\u4fee\u6539\u6570\u5b57\u7279\u5f81\uff0c\u96be\u4ee5\u5728\u65e0\u7ebf\u4f20\u8f93\u4e2d\u5b9e\u73b0\uff0c\u56e0\u4e3a\u5c06\u6570\u5b57\u6270\u52a8\u8f6c\u6362\u4e3a\u53ef\u4f20\u8f93\u6ce2\u5f62\u4f1a\u5f15\u5165\u540c\u6b65\u8bef\u5dee\u3001\u5e72\u6270\u548c\u786c\u4ef6\u9650\u5236\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u9996\u4e2a\u9488\u5bf9RF\u56fe\u50cf\u65e0\u4eba\u673a\u68c0\u6d4b\u5668\u7684\u7269\u7406\u653b\u51fb\uff0c\u4f18\u5316\u7279\u5b9a\u7c7b\u522b\u7684\u901a\u7528\u590d\u6570\u57fa\u5e26(I/Q)\u6270\u52a8\u6ce2\u5f62\uff0c\u8fd9\u4e9b\u6ce2\u5f62\u4e0e\u5408\u6cd5\u901a\u4fe1\u4fe1\u53f7\u4e00\u8d77\u4f20\u8f93\uff0c\u517c\u5bb9\u6807\u51c6RF\u94fe\u3002", "result": "\u4f7f\u7528RF\u8bb0\u5f55\u548cOTA\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u56db\u79cd\u65e0\u4eba\u673a\u7c7b\u578b\uff0c\u7ed3\u679c\u8868\u660e\u9002\u5ea6\u3001\u7ed3\u6784\u5316\u7684I/Q\u6270\u52a8\u4e0e\u6807\u51c6RF\u94fe\u517c\u5bb9\uff0c\u80fd\u53ef\u9760\u964d\u4f4e\u76ee\u6807\u65e0\u4eba\u673a\u68c0\u6d4b\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u5408\u6cd5\u65e0\u4eba\u673a\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "conclusion": "\u6210\u529f\u5b9e\u73b0\u4e86\u9996\u4e2a\u9488\u5bf9RF\u56fe\u50cf\u65e0\u4eba\u673a\u68c0\u6d4b\u7cfb\u7edf\u7684\u7269\u7406\u653b\u51fb\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u4f18\u5316\u7279\u5b9a\u7c7b\u522b\u7684I/Q\u6270\u52a8\u6ce2\u5f62\u53ef\u4ee5\u5728\u5b9e\u9645\u65e0\u7ebf\u73af\u5883\u4e2d\u6709\u6548\u5e72\u6270\u76ee\u6807\u68c0\u6d4b\uff0c\u540c\u65f6\u4fdd\u6301\u7cfb\u7edf\u5bf9\u5176\u4ed6\u5408\u6cd5\u65e0\u4eba\u673a\u7684\u68c0\u6d4b\u529f\u80fd\u3002"}}
{"id": "2512.20823", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20823", "abs": "https://arxiv.org/abs/2512.20823", "authors": ["Razine Moundir Ghorab", "Emanuele Parisi", "Cristian Gutierrez", "Miquel Alberti-Binimelis", "Miquel Moreto", "Dario Garcia-Gasulla", "Gokcen Kestor"], "title": "NotSoTiny: A Large, Living Benchmark for RTL Code Generation", "comment": "9 pages, 5 figures", "summary": "LLMs have shown early promise in generating RTL code, yet evaluating their capabilities in realistic setups remains a challenge. So far, RTL benchmarks have been limited in scale, skewed toward trivial designs, offering minimal verification rigor, and remaining vulnerable to data contamination. To overcome these limitations and to push the field forward, this paper introduces NotSoTiny, a benchmark that assesses LLM on the generation of structurally rich and context-aware RTL. Built from hundreds of actual hardware designs produced by the Tiny Tapeout community, our automated pipeline removes duplicates, verifies correctness and periodically incorporates new designs to mitigate contamination, matching Tiny Tapeout release schedule. Evaluation results show that NotSoTiny tasks are more challenging than prior benchmarks, emphasizing its effectiveness in overcoming current limitations of LLMs applied to hardware design, and in guiding the improvement of such promising technology.", "AI": {"tldr": "NotSoTiny\u662f\u4e00\u4e2a\u8bc4\u4f30LLM\u751f\u6210RTL\u4ee3\u7801\u80fd\u529b\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u57fa\u4e8eTiny Tapeout\u793e\u533a\u7684\u771f\u5b9e\u786c\u4ef6\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u89c4\u6a21\u5c0f\u3001\u8bbe\u8ba1\u7b80\u5355\u3001\u9a8c\u8bc1\u4e0d\u4e25\u683c\u548c\u6570\u636e\u6c61\u67d3\u7b49\u95ee\u9898\u3002", "motivation": "\u5f53\u524dLLM\u5728\u751f\u6210RTL\u4ee3\u7801\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u591a\u4e2a\u95ee\u9898\uff1a\u89c4\u6a21\u6709\u9650\u3001\u504f\u5411\u7b80\u5355\u8bbe\u8ba1\u3001\u9a8c\u8bc1\u4e0d\u4e25\u683c\u3001\u5bb9\u6613\u53d7\u5230\u6570\u636e\u6c61\u67d3\u3002\u9700\u8981\u66f4\u771f\u5b9e\u3001\u66f4\u5177\u6311\u6218\u6027\u7684\u57fa\u51c6\u6765\u63a8\u52a8\u8be5\u9886\u57df\u53d1\u5c55\u3002", "method": "\u4eceTiny Tapeout\u793e\u533a\u7684\u6570\u767e\u4e2a\u771f\u5b9e\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u6784\u5efa\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\uff0c\u5305\u62ec\u53bb\u91cd\u3001\u9a8c\u8bc1\u6b63\u786e\u6027\uff0c\u5e76\u5b9a\u671f\u7eb3\u5165\u65b0\u8bbe\u8ba1\u4ee5\u5339\u914dTiny Tapeout\u53d1\u5e03\u8ba1\u5212\uff0c\u4ece\u800c\u51cf\u8f7b\u6570\u636e\u6c61\u67d3\u95ee\u9898\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793aNotSoTiny\u4efb\u52a1\u6bd4\u73b0\u6709\u57fa\u51c6\u66f4\u5177\u6311\u6218\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u514b\u670dLLM\u5e94\u7528\u4e8e\u786c\u4ef6\u8bbe\u8ba1\u5f53\u524d\u5c40\u9650\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e3a\u6539\u8fdb\u8fd9\u4e00\u6709\u524d\u666f\u7684\u6280\u672f\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "conclusion": "NotSoTiny\u57fa\u51c6\u6d4b\u8bd5\u901a\u8fc7\u63d0\u4f9b\u7ed3\u6784\u4e30\u5bcc\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684RTL\u751f\u6210\u4efb\u52a1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdbLLM\u5728\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u3001\u66f4\u5177\u6311\u6218\u6027\u7684\u5e73\u53f0\u3002"}}
{"id": "2512.20775", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.20775", "abs": "https://arxiv.org/abs/2512.20775", "authors": ["Alex Lynham", "David Alesch", "Ziyi Li", "Geoff Goodell"], "title": "Sark: Oblivious Integrity Without Global State", "comment": "9 pages, 11 figures, 3 tables", "summary": "In this paper, we introduce Sark, a reference architecture implementing the Unforgeable, Stateful, and Oblivious (USO) asset system as described by Goodell, Toliver, and Nakib. We describe the motivation, design, and implementation of Sloop, a permissioned, crash fault-tolerant (CFT) blockchain that forms a subsystem of Sark, and the other core subsystems, Porters, which accumulate and roll-up commitments from Clients. We analyse the operation of the system using the 'CIA Triad': Confidentiality, Availability, and Integrity. We then introduce the concept of Integrity Locus and use it to address design trade-offs related to decentralization. Finally, we point to future work on Byzantine fault-tolerance (BFT), and mitigating the local centrality of Porters.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Sark\u67b6\u6784\uff0c\u8fd9\u662f\u4e00\u4e2a\u5b9e\u73b0\u4e86USO\u8d44\u4ea7\u7cfb\u7edf\u7684\u53c2\u8003\u67b6\u6784\uff0c\u5305\u542bSloop\u533a\u5757\u94fe\u548cPorters\u5b50\u7cfb\u7edf\uff0c\u5206\u6790\u4e86\u7cfb\u7edf\u7684CIA\u4e09\u8981\u7d20\uff0c\u63d0\u51fa\u4e86\u5b8c\u6574\u6027\u8f68\u8ff9\u6982\u5ff5\u6765\u89e3\u51b3\u53bb\u4e2d\u5fc3\u5316\u8bbe\u8ba1\u6743\u8861\u3002", "motivation": "\u5b9e\u73b0Goodell\u3001Toliver\u548cNakib\u63cf\u8ff0\u7684\u4e0d\u53ef\u4f2a\u9020\u3001\u6709\u72b6\u6001\u4e14\u4e0d\u53ef\u89c1\u7684USO\u8d44\u4ea7\u7cfb\u7edf\uff0c\u63d0\u4f9b\u4e00\u4e2a\u53c2\u8003\u67b6\u6784\u6765\u652f\u6301\u8fd9\u7c7b\u7cfb\u7edf\u7684\u8bbe\u8ba1\u548c\u5b9e\u73b0\u3002", "method": "\u8bbe\u8ba1\u4e86Sark\u53c2\u8003\u67b6\u6784\uff0c\u5305\u542bSloop\uff08\u4e00\u4e2a\u8bb8\u53ef\u5236\u7684\u5d29\u6e83\u5bb9\u9519\u533a\u5757\u94fe\uff09\u548cPorters\uff08\u8d1f\u8d23\u4ece\u5ba2\u6237\u7aef\u7d2f\u79ef\u548c\u6c47\u603b\u627f\u8bfa\u7684\u5b50\u7cfb\u7edf\uff09\uff0c\u4f7f\u7528CIA\u4e09\u8981\u7d20\uff08\u673a\u5bc6\u6027\u3001\u53ef\u7528\u6027\u3001\u5b8c\u6574\u6027\uff09\u5206\u6790\u7cfb\u7edf\u8fd0\u884c\uff0c\u5e76\u5f15\u5165\u5b8c\u6574\u6027\u8f68\u8ff9\u6982\u5ff5\u6765\u5904\u7406\u53bb\u4e2d\u5fc3\u5316\u8bbe\u8ba1\u6743\u8861\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86Sark\u67b6\u6784\uff0c\u5305\u542bSloop\u533a\u5757\u94fe\u548cPorters\u5b50\u7cfb\u7edf\uff0c\u901a\u8fc7CIA\u4e09\u8981\u7d20\u5206\u6790\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u4f7f\u7528\u5b8c\u6574\u6027\u8f68\u8ff9\u6982\u5ff5\u89e3\u51b3\u4e86\u53bb\u4e2d\u5fc3\u5316\u8bbe\u8ba1\u4e2d\u7684\u6743\u8861\u95ee\u9898\u3002", "conclusion": "Sark\u67b6\u6784\u4e3aUSO\u8d44\u4ea7\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u884c\u7684\u5b9e\u73b0\u6846\u67b6\uff0c\u5b8c\u6574\u6027\u8f68\u8ff9\u6982\u5ff5\u6709\u52a9\u4e8e\u89e3\u51b3\u53bb\u4e2d\u5fc3\u5316\u8bbe\u8ba1\u4e2d\u7684\u5173\u952e\u6743\u8861\uff0c\u672a\u6765\u5de5\u4f5c\u5c06\u96c6\u4e2d\u5728\u5b9e\u73b0\u62dc\u5360\u5ead\u5bb9\u9519\u548c\u7f13\u89e3Porters\u7684\u672c\u5730\u4e2d\u5fc3\u5316\u95ee\u9898\u4e0a\u3002"}}
{"id": "2512.20953", "categories": ["cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.20953", "abs": "https://arxiv.org/abs/2512.20953", "authors": ["Yuxiao Wang", "Yuedong Xu", "Qingyang Duan", "Yuxuan Liu", "Lei Jiao", "Yinghao Yu", "Jun Wu"], "title": "Diving into 3D Parallelism with Heterogeneous Spot Instance GPUs: Design and Implications", "comment": null, "summary": "The rapid growth of large language models (LLMs) and the continuous release of new GPU products have significantly increased the demand for distributed training across heterogeneous GPU environments. In this paper, we present a comprehensive analysis of the challenges involved in implementing 3D parallelism in such environments, addressing critical issues such as the need for symmetric tensor parallelism, efficient gradient synchronization in asymmetric pipeline parallelism, and the trade-offs between memory utilization and computational efficiency. Building upon these insights, we introduce AutoHet, a novel system that automatically identifies the optimal parallelism plan for distributed training on heterogeneous GPUs. AutoHet supports asymmetric 3D parallelism structures and facilitates fine-grained workload distribution. We propose a theoretical model that frames the device grouping and load balancing as an optimization problem to minimize per-iteration training time, thus effectively balancing computing power and memory usage across GPUs with diverse capabilities. To enable elastic training upon spot instance preemption, AutoHet presents an efficient recovery strategy that prioritizes to retrieve training states from local nodes, and only downloads the missing checkpoints from the cloud storage. Our extensive evaluation, conducted on three large-scale models and utilizing combinations of three different GPU types, demonstrates that AutoHet outperforms existing DNN training systems, achieving up to a 1.79$\\times$ speedup in training throughput compared with Megatron-LM and Whale, and a 4.38$\\times$ speedup of recovery speed compared to a spot instance baseline.", "AI": {"tldr": "AutoHet\u7cfb\u7edf\u81ea\u52a8\u4e3a\u5f02\u6784GPU\u73af\u5883\u5bfb\u627e\u6700\u4f18\u76843D\u5e76\u884c\u8bad\u7ec3\u65b9\u6848\uff0c\u652f\u6301\u975e\u5bf9\u79f0\u5e76\u884c\u7ed3\u6784\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u5de5\u4f5c\u8d1f\u8f7d\u5206\u914d\uff0c\u5e76\u5728Spot\u5b9e\u4f8b\u4e2d\u65ad\u65f6\u63d0\u4f9b\u9ad8\u6548\u6062\u590d\u7b56\u7565\uff0c\u76f8\u6bd4\u73b0\u6709\u7cfb\u7edf\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u541e\u5410\u91cf\u548c\u6062\u590d\u901f\u5ea6\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u589e\u957f\u548c\u65b0GPU\u4ea7\u54c1\u7684\u4e0d\u65ad\u53d1\u5e03\uff0c\u5f02\u6784GPU\u73af\u5883\u4e0b\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u9700\u6c42\u663e\u8457\u589e\u52a0\u3002\u73b0\u6709\u7cfb\u7edf\u5728\u5f02\u6784\u73af\u5883\u4e2d\u5b9e\u73b03D\u5e76\u884c\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u5305\u62ec\u9700\u8981\u5bf9\u79f0\u5f20\u91cf\u5e76\u884c\u3001\u975e\u5bf9\u79f0\u6d41\u6c34\u7ebf\u5e76\u884c\u4e2d\u7684\u68af\u5ea6\u540c\u6b65\u6548\u7387\u95ee\u9898\uff0c\u4ee5\u53ca\u5185\u5b58\u5229\u7528\u4e0e\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u3002", "method": "\u63d0\u51faAutoHet\u7cfb\u7edf\uff0c\u652f\u6301\u975e\u5bf9\u79f03D\u5e76\u884c\u7ed3\u6784\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u5de5\u4f5c\u8d1f\u8f7d\u5206\u914d\u3002\u5efa\u7acb\u7406\u8bba\u6a21\u578b\uff0c\u5c06\u8bbe\u5907\u5206\u7ec4\u548c\u8d1f\u8f7d\u5e73\u8861\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u4f18\u5316\u95ee\u9898\uff0c\u4ee5\u6700\u5c0f\u5316\u6bcf\u6b21\u8fed\u4ee3\u7684\u8bad\u7ec3\u65f6\u95f4\uff0c\u4ece\u800c\u6709\u6548\u5e73\u8861\u4e0d\u540c\u80fd\u529bGPU\u4e4b\u95f4\u7684\u8ba1\u7b97\u80fd\u529b\u548c\u5185\u5b58\u4f7f\u7528\u3002\u9488\u5bf9Spot\u5b9e\u4f8b\u62a2\u5360\uff0c\u63d0\u51fa\u9ad8\u6548\u6062\u590d\u7b56\u7565\uff0c\u4f18\u5148\u4ece\u672c\u5730\u8282\u70b9\u68c0\u7d22\u8bad\u7ec3\u72b6\u6001\uff0c\u4ec5\u4ece\u4e91\u5b58\u50a8\u4e0b\u8f7d\u7f3a\u5931\u7684\u68c0\u67e5\u70b9\u3002", "result": "\u5728\u4e09\u4e2a\u5927\u89c4\u6a21\u6a21\u578b\u548c\u4e09\u79cd\u4e0d\u540cGPU\u7c7b\u578b\u7684\u7ec4\u5408\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793aAutoHet\u4f18\u4e8e\u73b0\u6709DNN\u8bad\u7ec3\u7cfb\u7edf\uff1a\u4e0eMegatron-LM\u548cWhale\u76f8\u6bd4\uff0c\u8bad\u7ec3\u541e\u5410\u91cf\u6700\u9ad8\u63d0\u53471.79\u500d\uff1b\u4e0eSpot\u5b9e\u4f8b\u57fa\u7ebf\u76f8\u6bd4\uff0c\u6062\u590d\u901f\u5ea6\u63d0\u53474.38\u500d\u3002", "conclusion": "AutoHet\u7cfb\u7edf\u6210\u529f\u89e3\u51b3\u4e86\u5f02\u6784GPU\u73af\u5883\u4e2d3D\u5e76\u884c\u8bad\u7ec3\u7684\u6311\u6218\uff0c\u901a\u8fc7\u81ea\u52a8\u5bfb\u627e\u6700\u4f18\u5e76\u884c\u65b9\u6848\u548c\u9ad8\u6548\u6062\u590d\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u5e03\u5f0f\u8bad\u7ec3\u7684\u6027\u80fd\u548c\u5f39\u6027\u3002"}}
{"id": "2512.20626", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.20626", "abs": "https://arxiv.org/abs/2512.20626", "authors": ["Chi-Hsiang Hsiao", "Yi-Cheng Wang", "Tzung-Sheng Lin", "Yi-Ren Yeh", "Chu-Song Chen"], "title": "MegaRAG: Multimodal Knowledge Graph-Based Retrieval Augmented Generation", "comment": null, "summary": "Retrieval-augmented generation (RAG) enables large language models (LLMs) to dynamically access external information, which is powerful for answering questions over previously unseen documents. Nonetheless, they struggle with high-level conceptual understanding and holistic comprehension due to limited context windows, which constrain their ability to perform deep reasoning over long-form, domain-specific content such as full-length books. To solve this problem, knowledge graphs (KGs) have been leveraged to provide entity-centric structure and hierarchical summaries, offering more structured support for reasoning. However, existing KG-based RAG solutions remain restricted to text-only inputs and fail to leverage the complementary insights provided by other modalities such as vision. On the other hand, reasoning from visual documents requires textual, visual, and spatial cues into structured, hierarchical concepts. To address this issue, we introduce a multimodal knowledge graph-based RAG that enables cross-modal reasoning for better content understanding. Our method incorporates visual cues into the construction of knowledge graphs, the retrieval phase, and the answer generation process. Experimental results across both global and fine-grained question answering tasks show that our approach consistently outperforms existing RAG-based approaches on both textual and multimodal corpora.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u7684\u68c0\u7d22\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u89c6\u89c9\u7ebf\u7d22\u6765\u63d0\u5347\u5bf9\u957f\u6587\u6863\u5185\u5bb9\u7684\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u5728\u5904\u7406\u957f\u6587\u6863\uff08\u5982\u6574\u672c\u4e66\uff09\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u4e0a\u4e0b\u6587\u7a97\u53e3\u5927\u5c0f\uff0c\u96be\u4ee5\u8fdb\u884c\u6df1\u5ea6\u63a8\u7406\u3002\u73b0\u6709\u7684\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u65b9\u6cd5\u867d\u7136\u63d0\u4f9b\u7ed3\u6784\u5316\u652f\u6301\uff0c\u4f46\u4ec5\u9650\u4e8e\u6587\u672c\u8f93\u5165\uff0c\u672a\u80fd\u5229\u7528\u89c6\u89c9\u7b49\u591a\u6a21\u6001\u4fe1\u606f\u7684\u4e92\u8865\u4f18\u52bf\u3002", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u7684\u68c0\u7d22\u751f\u6210\u6846\u67b6\uff0c\u5c06\u89c6\u89c9\u7ebf\u7d22\u6574\u5408\u5230\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u3001\u68c0\u7d22\u9636\u6bb5\u548c\u7b54\u6848\u751f\u6210\u8fc7\u7a0b\u4e2d\uff0c\u5b9e\u73b0\u8de8\u6a21\u6001\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5168\u5c40\u548c\u7ec6\u7c92\u5ea6\u95ee\u7b54\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\uff0c\u5728\u6587\u672c\u548c\u591a\u6a21\u6001\u8bed\u6599\u5e93\u4e0a\u5747\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u89c6\u89c9\u4fe1\u606f\u5230\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u7684\u68c0\u7d22\u751f\u6210\u6846\u67b6\u4e2d\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5bf9\u590d\u6742\u6587\u6863\u5185\u5bb9\u7684\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u591a\u6a21\u6001\u6587\u6863\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.20860", "categories": ["cs.CR", "cs.OS"], "pdf": "https://arxiv.org/pdf/2512.20860", "abs": "https://arxiv.org/abs/2512.20860", "authors": ["Alejandro Avina", "Yashas Hariprasad", "Naveen Kumar Chaudhary"], "title": "pokiSEC: A Multi-Architecture, Containerized Ephemeral Malware Detonation Sandbox", "comment": "12 pages", "summary": "Dynamic malware analysis requires executing untrusted binaries inside strongly isolated, rapidly resettable environments. In practice, many detonation workflows remain tied to heavyweight hypervisors or dedicated bare-metal labs, limiting portability and automation. This challenge has intensified with the adoption of ARM64 developer hardware (e.g., Apple Silicon), where common open-source sandbox recipes and pre-built environments frequently assume x86_64 hosts and do not translate cleanly across architectures. This paper presents pokiSEC, a lightweight, ephemeral malware detonation sandbox that packages the full virtualization and access stack inside a Docker container. pokiSEC integrates QEMU with hardware acceleration (KVM when available) and exposes a browser-based workflow that supports bring-your-own Windows disk images. The key contribution is a Universal Entrypoint that performs runtime host-architecture detection and selects validated hypervisor configurations (machine types, acceleration modes, and device profiles), enabling a single container image and codebase to launch Windows guests on both ARM64 and x86_64 hosts. We validate pokiSEC on Apple Silicon (ARM64) and Ubuntu (AMD64), demonstrating interactive performance suitable for analyst workflows and consistent teardown semantics via ephemeral container lifecycles.", "AI": {"tldr": "pokiSEC\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u4e34\u65f6\u6027\u7684\u6076\u610f\u8f6f\u4ef6\u5f15\u7206\u6c99\u7bb1\uff0c\u5c06\u5b8c\u6574\u7684\u865a\u62df\u5316\u548c\u8bbf\u95ee\u5806\u6808\u6253\u5305\u5728Docker\u5bb9\u5668\u4e2d\uff0c\u652f\u6301\u5728ARM64\u548cx86_64\u4e3b\u673a\u4e0a\u8fd0\u884cWindows\u865a\u62df\u673a\u3002", "motivation": "\u52a8\u6001\u6076\u610f\u8f6f\u4ef6\u5206\u6790\u9700\u8981\u5728\u5f3a\u9694\u79bb\u3001\u5feb\u901f\u91cd\u7f6e\u7684\u73af\u5883\u4e2d\u6267\u884c\u4e0d\u53ef\u4fe1\u4e8c\u8fdb\u5236\u6587\u4ef6\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u4f9d\u8d56\u4e8e\u91cd\u91cf\u7ea7\u865a\u62df\u673a\u7ba1\u7406\u7a0b\u5e8f\u6216\u4e13\u7528\u88f8\u673a\u5b9e\u9a8c\u5ba4\uff0c\u9650\u5236\u4e86\u53ef\u79fb\u690d\u6027\u548c\u81ea\u52a8\u5316\u3002\u968f\u7740ARM64\u5f00\u53d1\u786c\u4ef6\uff08\u5982Apple Silicon\uff09\u7684\u91c7\u7528\uff0c\u8bb8\u591a\u5f00\u6e90\u6c99\u7bb1\u65b9\u6848\u5047\u8bbex86_64\u4e3b\u673a\uff0c\u65e0\u6cd5\u5728\u4e0d\u540c\u67b6\u6784\u95f4\u826f\u597d\u79fb\u690d\u3002", "method": "pokiSEC\u5c06QEMU\u4e0e\u786c\u4ef6\u52a0\u901f\uff08KVM\uff09\u96c6\u6210\u5230Docker\u5bb9\u5668\u4e2d\uff0c\u63d0\u4f9b\u57fa\u4e8e\u6d4f\u89c8\u5668\u7684\u5de5\u4f5c\u6d41\uff0c\u652f\u6301\u81ea\u5e26Windows\u78c1\u76d8\u955c\u50cf\u3002\u5173\u952e\u521b\u65b0\u662f\"\u901a\u7528\u5165\u53e3\u70b9\"\uff0c\u6267\u884c\u8fd0\u884c\u65f6\u4e3b\u673a\u67b6\u6784\u68c0\u6d4b\u5e76\u9009\u62e9\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u865a\u62df\u673a\u7ba1\u7406\u7a0b\u5e8f\u914d\u7f6e\uff08\u673a\u5668\u7c7b\u578b\u3001\u52a0\u901f\u6a21\u5f0f\u548c\u8bbe\u5907\u914d\u7f6e\u6587\u4ef6\uff09\u3002", "result": "\u5728Apple Silicon\uff08ARM64\uff09\u548cUbuntu\uff08AMD64\uff09\u4e0a\u9a8c\u8bc1\u4e86pokiSEC\uff0c\u5c55\u793a\u4e86\u9002\u5408\u5206\u6790\u5e08\u5de5\u4f5c\u6d41\u7a0b\u7684\u4ea4\u4e92\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u4e34\u65f6\u5bb9\u5668\u751f\u547d\u5468\u671f\u5b9e\u73b0\u4e00\u81f4\u7684\u62c6\u9664\u8bed\u4e49\u3002", "conclusion": "pokiSEC\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u8de8\u67b6\u6784\u7684\u6076\u610f\u8f6f\u4ef6\u5f15\u7206\u6c99\u7bb1\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u52a8\u6001\u6076\u610f\u8f6f\u4ef6\u5206\u6790\u73af\u5883\u5728\u53ef\u79fb\u690d\u6027\u548c\u81ea\u52a8\u5316\u65b9\u9762\u7684\u9650\u5236\uff0c\u7279\u522b\u652f\u6301ARM64\u548cx86_64\u67b6\u6784\u7684\u5f02\u6784\u73af\u5883\u3002"}}
{"id": "2512.20967", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.20967", "abs": "https://arxiv.org/abs/2512.20967", "authors": ["Linggao Kong", "Yuedong Xu", "Lei Jiao", "Chuan Xu"], "title": "Deadline-Aware Online Scheduling for LLM Fine-Tuning with Spot Market Predictions", "comment": null, "summary": "As foundation models grow in size, fine-tuning them becomes increasingly expensive. While GPU spot instances offer a low-cost alternative to on-demand resources, their volatile prices and availability make deadline-aware scheduling particularly challenging. We tackle this difficulty by using a mix of spot and on-demand instances. Distinctively, we show the predictability of prices and availability in a spot instance market, the power of prediction in enabling cost-efficient scheduling and its sensitivity to estimation errors. An integer programming problem is formulated to capture the use of mixed instances under both the price and availability dynamics. We propose an online allocation algorithm with prediction based on the committed horizon control approach that leverages a \\emph{commitment level} to enforce the partial sequence of decisions. When this prediction becomes inaccurate, we further present a complementary online algorithm without predictions. An online policy selection algorithm is developed that learns the best policy from a pool constructed by varying the parameters of both algorithms. We prove that the prediction-based algorithm achieves tighter performance bounds as prediction error decreases, while the policy selection algorithm possesses a regret bound of $\\mathcal{O}(\\sqrt{T})$. Experimental results demonstrate that our online framework can adaptively select the best policy under varying spot market dynamics and prediction quality, consistently outperforming baselines and improving utility by up to 54.8\\%.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9884\u6d4b\u7684\u5728\u7ebf\u8c03\u5ea6\u6846\u67b6\uff0c\u7528\u4e8e\u5728GPU\u73b0\u8d27\u5b9e\u4f8b\u5e02\u573a\u4e2d\u8fdb\u884c\u7ecf\u6d4e\u9ad8\u6548\u7684\u5927\u6a21\u578b\u5fae\u8c03\uff0c\u901a\u8fc7\u6df7\u5408\u4f7f\u7528\u73b0\u8d27\u548c\u6309\u9700\u5b9e\u4f8b\u6765\u964d\u4f4e\u6210\u672c\uff0c\u540c\u65f6\u6ee1\u8db3\u622a\u6b62\u65f6\u95f4\u8981\u6c42\u3002", "motivation": "\u968f\u7740\u57fa\u7840\u6a21\u578b\u89c4\u6a21\u589e\u5927\uff0c\u5fae\u8c03\u6210\u672c\u6025\u5267\u4e0a\u5347\u3002GPU\u73b0\u8d27\u5b9e\u4f8b\u867d\u7136\u6210\u672c\u8f83\u4f4e\uff0c\u4f46\u5176\u4ef7\u683c\u548c\u53ef\u7528\u6027\u7684\u6ce2\u52a8\u6027\u4f7f\u5f97\u6ee1\u8db3\u622a\u6b62\u65f6\u95f4\u7684\u8c03\u5ea6\u53d8\u5f97\u7279\u522b\u56f0\u96be\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5229\u7528\u73b0\u8d27\u5b9e\u4f8b\u4f4e\u6210\u672c\u4f18\u52bf\uff0c\u540c\u65f6\u5e94\u5bf9\u5176\u4e0d\u786e\u5b9a\u6027\u7684\u8c03\u5ea6\u65b9\u6848\u3002", "method": "1) \u5c55\u793a\u73b0\u8d27\u5e02\u573a\u4ef7\u683c\u548c\u53ef\u7528\u6027\u7684\u53ef\u9884\u6d4b\u6027\uff1b2) \u6784\u5efa\u6574\u6570\u89c4\u5212\u95ee\u9898\u6765\u5efa\u6a21\u6df7\u5408\u5b9e\u4f8b\u4f7f\u7528\u4e0b\u7684\u4ef7\u683c\u548c\u53ef\u7528\u6027\u52a8\u6001\uff1b3) \u63d0\u51fa\u57fa\u4e8e\u9884\u6d4b\u7684\u5728\u7ebf\u5206\u914d\u7b97\u6cd5\uff0c\u91c7\u7528\u627f\u8bfa\u6c34\u5e73\u63a7\u5236\u65b9\u6cd5\uff1b4) \u5f53\u9884\u6d4b\u4e0d\u51c6\u786e\u65f6\uff0c\u63d0\u51fa\u65e0\u9884\u6d4b\u7684\u8865\u5145\u7b97\u6cd5\uff1b5) \u5f00\u53d1\u5728\u7ebf\u7b56\u7565\u9009\u62e9\u7b97\u6cd5\uff0c\u4ece\u53c2\u6570\u5316\u7b56\u7565\u6c60\u4e2d\u5b66\u4e60\u6700\u4f73\u7b56\u7565\u3002", "result": "1) \u8bc1\u660e\u57fa\u4e8e\u9884\u6d4b\u7684\u7b97\u6cd5\u5728\u9884\u6d4b\u8bef\u5dee\u51cf\u5c0f\u65f6\u80fd\u83b7\u5f97\u66f4\u7d27\u7684\u6027\u80fd\u754c\u9650\uff1b2) \u7b56\u7565\u9009\u62e9\u7b97\u6cd5\u5177\u6709O(\u221aT)\u7684\u9057\u61be\u754c\u9650\uff1b3) \u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u5728\u7ebf\u6846\u67b6\u80fd\u81ea\u9002\u5e94\u9009\u62e9\u6700\u4f73\u7b56\u7565\uff0c\u5728\u4e0d\u540c\u73b0\u8d27\u5e02\u573a\u52a8\u6001\u548c\u9884\u6d4b\u8d28\u91cf\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5c06\u6548\u7528\u63d0\u5347\u9ad8\u8fbe54.8%\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u73b0\u8d27\u5e02\u573a\u4ef7\u683c\u548c\u53ef\u7528\u6027\u7684\u53ef\u9884\u6d4b\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u5728\u7ebf\u8c03\u5ea6\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u5229\u7528\u6df7\u5408\u5b9e\u4f8b\u8d44\u6e90\uff0c\u5728\u5927\u6a21\u578b\u5fae\u8c03\u4e2d\u5b9e\u73b0\u6210\u672c\u6548\u76ca\u548c\u622a\u6b62\u65f6\u95f4\u4fdd\u8bc1\u7684\u5e73\u8861\u3002"}}
{"id": "2512.20628", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20628", "abs": "https://arxiv.org/abs/2512.20628", "authors": ["Edited by Tessai Hayama", "Takayuki Ito", "Takahiro Uchiya", "Motoki Miura", "Takahiro Kawaji", "Takaya Yuizono", "Atsuo Yoshitaka", "Tokuro Matsuo", "Shun Okuhara", "Jawad Haqbeen", "Sofia Sahab", "Wen Gu", "Shiyao Ding"], "title": "Proceedings of the 20th International Conference on Knowledge, Information and Creativity Support Systems (KICSS 2025)", "comment": "Conference proceedings; 325 pages; published in cooperation with IEICE Proceedings Series. A subset of papers will appear in IEICE Transactions on Information and Systems (special section). Venue: Aore Nagaoka, Japan, December 3-5, 2025. Editors: KICSS 2025 Organizing Committee", "summary": "This volume presents the proceedings of the 20th International Conference on Knowledge, Information and Creativity Support Systems (KICSS 2025), held in Nagaoka, Japan, on December 3-5, 2025. The conference, organized in cooperation with the IEICE Proceedings Series, provides a multidisciplinary forum for researchers in artificial intelligence, knowledge engineering, human-computer interaction, and creativity support systems. The proceedings include peer-reviewed papers accepted through a double-blind review process. Selected papers have been recommended for publication in IEICE Transactions on Information and Systems after an additional peer-review process.", "AI": {"tldr": "KICSS 2025\u4f1a\u8bae\u8bba\u6587\u96c6\uff0c\u6db5\u76d6\u4eba\u5de5\u667a\u80fd\u3001\u77e5\u8bc6\u5de5\u7a0b\u3001\u4eba\u673a\u4ea4\u4e92\u548c\u521b\u9020\u529b\u652f\u6301\u7cfb\u7edf\u7b49\u8de8\u5b66\u79d1\u9886\u57df", "motivation": "\u4e3a\u4eba\u5de5\u667a\u80fd\u3001\u77e5\u8bc6\u5de5\u7a0b\u3001\u4eba\u673a\u4ea4\u4e92\u548c\u521b\u9020\u529b\u652f\u6301\u7cfb\u7edf\u9886\u57df\u7684\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e00\u4e2a\u591a\u5b66\u79d1\u4ea4\u6d41\u5e73\u53f0\uff0c\u4fc3\u8fdb\u76f8\u5173\u9886\u57df\u7684\u5b66\u672f\u4ea4\u6d41\u4e0e\u5408\u4f5c", "method": "\u901a\u8fc7\u53cc\u76f2\u8bc4\u5ba1\u6d41\u7a0b\u63a5\u53d7\u540c\u884c\u8bc4\u5ba1\u8bba\u6587\uff0c\u90e8\u5206\u4f18\u79c0\u8bba\u6587\u7ecf\u8fc7\u989d\u5916\u8bc4\u5ba1\u540e\u63a8\u8350\u81f3IEICE Transactions on Information and Systems\u671f\u520a\u53d1\u8868", "result": "\u6210\u529f\u4e3e\u529e\u4e86\u7b2c20\u5c4a\u56fd\u9645\u4f1a\u8bae\uff0c\u51fa\u7248\u4e86\u5305\u542b\u591a\u5b66\u79d1\u7814\u7a76\u6210\u679c\u7684\u4f1a\u8bae\u8bba\u6587\u96c6\uff0c\u5efa\u7acb\u4e86\u4e0eIEICE Proceedings Series\u7684\u5408\u4f5c\u5173\u7cfb", "conclusion": "KICSS 2025\u4f1a\u8bae\u4e3a\u76f8\u5173\u9886\u57df\u7684\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u5b66\u672f\u4ea4\u6d41\u5e73\u53f0\uff0c\u901a\u8fc7\u4e25\u683c\u7684\u8bc4\u5ba1\u6d41\u7a0b\u786e\u4fdd\u4e86\u8bba\u6587\u8d28\u91cf\uff0c\u4fc3\u8fdb\u4e86\u8de8\u5b66\u79d1\u7814\u7a76\u7684\u5408\u4f5c\u4e0e\u53d1\u5c55"}}
{"id": "2512.20872", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.20872", "abs": "https://arxiv.org/abs/2512.20872", "authors": ["Jakir Hossain", "Gurvinder Singh", "Lukasz Ziarek", "Ahmet Erdem Sar\u0131y\u00fcce"], "title": "Better Call Graphs: A New Dataset of Function Call Graphs for Malware Classification", "comment": null, "summary": "Function call graphs (FCGs) have emerged as a powerful abstraction for malware detection, capturing the behavioral structure of applications beyond surface-level signatures. Their utility in traditional program analysis has been well established, enabling effective classification and analysis of malicious software. In the mobile domain, especially in the Android ecosystem, FCG-based malware classification is particularly critical due to the platform's widespread adoption and the complex, component-based structure of Android apps. However, progress in this direction is hindered by the lack of large-scale, high-quality Android-specific FCG datasets. Existing datasets are often outdated, dominated by small or redundant graphs resulting from app repackaging, and fail to reflect the diversity of real-world malware. These limitations lead to overfitting and unreliable evaluation of graph-based classification methods. To address this gap, we introduce Better Call Graphs (BCG), a comprehensive dataset of large and unique FCGs extracted from recent Android application packages (APKs). BCG includes both benign and malicious samples spanning various families and types, along with graph-level features for each APK. Through extensive experiments using baseline classifiers, we demonstrate the necessity and value of BCG compared to existing datasets. BCG is publicly available at https://erdemub.github.io/BCG-dataset.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Better Call Graphs (BCG)\u6570\u636e\u96c6\uff0c\u8fd9\u662f\u4e00\u4e2a\u9488\u5bf9Android\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u7684\u5927\u89c4\u6a21\u3001\u9ad8\u8d28\u91cf\u51fd\u6570\u8c03\u7528\u56fe\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u8fc7\u65f6\u3001\u5197\u4f59\u548c\u591a\u6837\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u51fd\u6570\u8c03\u7528\u56fe\u5728\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u5728Android\u9886\u57df\u7f3a\u4e4f\u5927\u89c4\u6a21\u3001\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6\u3002\u73b0\u6709\u6570\u636e\u96c6\u901a\u5e38\u8fc7\u65f6\u3001\u5305\u542b\u5927\u91cf\u91cd\u590d\u6216\u5197\u4f59\u7684\u56fe\uff08\u7531\u4e8e\u5e94\u7528\u91cd\u6253\u5305\uff09\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u6076\u610f\u8f6f\u4ef6\u7684\u591a\u6837\u6027\uff0c\u5bfc\u81f4\u57fa\u4e8e\u56fe\u7684\u5206\u7c7b\u65b9\u6cd5\u5bb9\u6613\u8fc7\u62df\u5408\u4e14\u8bc4\u4f30\u4e0d\u53ef\u9760\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86BCG\u6570\u636e\u96c6\uff0c\u4ece\u6700\u8fd1\u7684Android\u5e94\u7528\u5305\u4e2d\u63d0\u53d6\u5927\u89c4\u6a21\u4e14\u72ec\u7279\u7684\u51fd\u6570\u8c03\u7528\u56fe\u3002\u6570\u636e\u96c6\u5305\u542b\u826f\u6027\u548c\u6076\u610f\u6837\u672c\uff0c\u6db5\u76d6\u591a\u79cd\u5bb6\u65cf\u548c\u7c7b\u578b\uff0c\u5e76\u4e3a\u6bcf\u4e2aAPK\u63d0\u4f9b\u56fe\u7ea7\u7279\u5f81\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u57fa\u7ebf\u5206\u7c7b\u5668\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86BCG\u76f8\u6bd4\u73b0\u6709\u6570\u636e\u96c6\u7684\u5fc5\u8981\u6027\u548c\u4ef7\u503c\u3002BCG\u6570\u636e\u96c6\u5df2\u516c\u5f00\u53ef\u7528\uff0c\u5730\u5740\u4e3ahttps://erdemub.github.io/BCG-dataset\u3002", "conclusion": "BCG\u6570\u636e\u96c6\u586b\u8865\u4e86Android\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u9886\u57df\u9ad8\u8d28\u91cf\u51fd\u6570\u8c03\u7528\u56fe\u6570\u636e\u96c6\u7684\u7a7a\u767d\uff0c\u4e3a\u57fa\u4e8e\u56fe\u7684\u5206\u7c7b\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u3001\u591a\u6837\u5316\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8be5\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2512.20968", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20968", "abs": "https://arxiv.org/abs/2512.20968", "authors": ["Sirui Chen", "Jingji Chen", "Siqi Zhu", "Ziheng Jiang", "Yanghua Peng", "Xuehai Qian"], "title": "Mesh-Attention: A New Communication-Efficient Distributed Attention with Improved Data Locality", "comment": null, "summary": "Distributed attention is a fundamental problem for scaling context window for Large Language Models (LLMs). The state-of-the-art method, Ring-Attention, suffers from scalability limitations due to its excessive communication traffic. This paper proposes a new distributed attention algorithm, Mesh-Attention, by rethinking the design space of distributed attention with a new matrix-based model. Our method assigns a two-dimensional tile -- rather than one-dimensional row or column -- of computation blocks to each GPU to achieve higher efficiency through lower communication-computation (CommCom) ratio. The general approach covers Ring-Attention as a special case, and allows the tuning of CommCom ratio with different tile shapes. Importantly, we propose a greedy algorithm that can efficiently search the scheduling space within the tile with restrictions that ensure efficient communication among GPUs. The theoretical analysis shows that Mesh-Attention leads to a much lower communication complexity and exhibits good scalability comparing to other current algorithms.\n  Our extensive experiment results show that Mesh-Attention can achieve up to 3.4x speedup (2.9x on average) and reduce the communication volume by up to 85.4% (79.0% on average) on 256 GPUs. Our scalability results further demonstrate that Mesh-Attention sustains superior performance as the system scales, substantially reducing overhead in large-scale deployments. The results convincingly confirm the advantage of Mesh-Attention.", "AI": {"tldr": "Mesh-Attention\uff1a\u4e00\u79cd\u65b0\u7684\u5206\u5e03\u5f0f\u6ce8\u610f\u529b\u7b97\u6cd5\uff0c\u901a\u8fc7\u4e8c\u7ef4\u8ba1\u7b97\u5757\u5206\u914d\u964d\u4f4e\u901a\u4fe1\u8ba1\u7b97\u6bd4\uff0c\u76f8\u6bd4Ring-Attention\u5728256 GPU\u4e0a\u5b9e\u73b0\u5e73\u57472.9\u500d\u52a0\u901f\u548c79%\u901a\u4fe1\u91cf\u51cf\u5c11", "motivation": "\u73b0\u6709\u6700\u5148\u8fdb\u7684Ring-Attention\u65b9\u6cd5\u5728\u6269\u5c55\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3\u65f6\u5b58\u5728\u53ef\u6269\u5c55\u6027\u9650\u5236\uff0c\u4e3b\u8981\u95ee\u9898\u662f\u901a\u4fe1\u6d41\u91cf\u8fc7\u5927\u3002\u9700\u8981\u8bbe\u8ba1\u66f4\u9ad8\u6548\u7684\u5206\u5e03\u5f0f\u6ce8\u610f\u529b\u7b97\u6cd5\u6765\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u3002", "method": "\u63d0\u51faMesh-Attention\u7b97\u6cd5\uff0c\u91c7\u7528\u65b0\u7684\u57fa\u4e8e\u77e9\u9635\u7684\u6a21\u578b\u91cd\u65b0\u601d\u8003\u5206\u5e03\u5f0f\u6ce8\u610f\u529b\u8bbe\u8ba1\u7a7a\u95f4\u3002\u6838\u5fc3\u521b\u65b0\u662f\u5c06\u4e8c\u7ef4\u8ba1\u7b97\u5757\uff08\u800c\u975e\u4e00\u7ef4\u884c\u6216\u5217\uff09\u5206\u914d\u7ed9\u6bcf\u4e2aGPU\uff0c\u901a\u8fc7\u964d\u4f4e\u901a\u4fe1\u8ba1\u7b97\u6bd4\u63d0\u9ad8\u6548\u7387\u3002\u7b97\u6cd5\u5305\u542b\u8d2a\u5a6a\u641c\u7d22\u7b97\u6cd5\u6765\u9ad8\u6548\u8c03\u5ea6\u8ba1\u7b97\u5757\uff0c\u786e\u4fddGPU\u95f4\u901a\u4fe1\u6548\u7387\u3002", "result": "\u5728256\u4e2aGPU\u4e0a\uff0cMesh-Attention\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u6700\u9ad83.4\u500d\uff08\u5e73\u57472.9\u500d\uff09\u52a0\u901f\uff0c\u901a\u4fe1\u91cf\u51cf\u5c11\u6700\u9ad885.4%\uff08\u5e73\u574779%\uff09\u3002\u7406\u8bba\u5206\u6790\u663e\u793a\u901a\u4fe1\u590d\u6742\u5ea6\u663e\u8457\u964d\u4f4e\uff0c\u53ef\u6269\u5c55\u6027\u4f18\u4e8e\u5f53\u524d\u7b97\u6cd5\u3002", "conclusion": "Mesh-Attention\u901a\u8fc7\u4e8c\u7ef4\u8ba1\u7b97\u5757\u5206\u914d\u548c\u4f18\u5316\u7684\u901a\u4fe1\u8c03\u5ea6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5206\u5e03\u5f0f\u6ce8\u610f\u529b\u7684\u901a\u4fe1\u5f00\u9500\uff0c\u5728\u5927\u89c4\u6a21\u90e8\u7f72\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u53ef\u6269\u5c55\u6027\u548c\u6027\u80fd\u4f18\u52bf\u3002"}}
{"id": "2512.20630", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20630", "abs": "https://arxiv.org/abs/2512.20630", "authors": ["Aayam Bansal", "Ishaan Gangwani"], "title": "MicroProbe: Efficient Reliability Assessment for Foundation Models with Minimal Data", "comment": "ICML NewInML", "summary": "Foundation model reliability assessment typically requires thousands of evaluation examples, making it computationally expensive and time-consuming for real-world deployment. We introduce microprobe, a novel approach that achieves comprehensive reliability assessment using only 100 strategically selected probe examples. Our method combines strategic prompt diversity across five key reliability dimensions with advanced uncertainty quantification and adaptive weighting to efficiently detect potential failure modes. Through extensive empirical evaluation on multiple language models (GPT-2 variants, GPT-2 Medium, GPT-2 Large) and cross-domain validation (healthcare, finance, legal), we demonstrate that microprobe achieves 23.5% higher composite reliability scores compared to random sampling baselines, with exceptional statistical significance (p < 0.001, Cohen's d = 1.21). Expert validation by three AI safety researchers confirms the effectiveness of our strategic selection, rating our approach 4.14/5.0 versus 3.14/5.0 for random selection. microprobe completes reliability assessment with 99.9% statistical power while representing a 90% reduction in assessment cost and maintaining 95% of traditional method coverage. Our approach addresses a critical gap in efficient model evaluation for responsible AI deployment.", "AI": {"tldr": "Microprobe\u662f\u4e00\u79cd\u65b0\u9896\u7684\u5927\u6a21\u578b\u53ef\u9760\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4ec5\u9700100\u4e2a\u7cbe\u5fc3\u9009\u62e9\u7684\u63a2\u6d4b\u6837\u672c\u5373\u53ef\u5b9e\u73b0\u5168\u9762\u8bc4\u4f30\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u548c\u65f6\u95f4\u6d88\u8017\u3002", "motivation": "\u4f20\u7edf\u5927\u6a21\u578b\u53ef\u9760\u6027\u8bc4\u4f30\u9700\u8981\u6570\u5343\u4e2a\u8bc4\u4f30\u6837\u672c\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u8017\u65f6\u4e45\uff0c\u96be\u4ee5\u6ee1\u8db3\u5b9e\u9645\u90e8\u7f72\u9700\u6c42\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u4e94\u4e2a\u5173\u952e\u53ef\u9760\u6027\u7ef4\u5ea6\u7684\u7b56\u7565\u6027\u63d0\u793a\u591a\u6837\u6027\u3001\u5148\u8fdb\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4ee5\u53ca\u81ea\u9002\u5e94\u52a0\u6743\uff0c\u901a\u8fc7\u7cbe\u5fc3\u9009\u62e9\u7684100\u4e2a\u63a2\u6d4b\u6837\u672c\u9ad8\u6548\u68c0\u6d4b\u6f5c\u5728\u6545\u969c\u6a21\u5f0f\u3002", "result": "\u5728\u591a\u4e2a\u8bed\u8a00\u6a21\u578b\u548c\u8de8\u9886\u57df\u9a8c\u8bc1\u4e2d\uff0cmicroprobe\u76f8\u6bd4\u968f\u673a\u91c7\u6837\u57fa\u7ebf\u83b7\u5f9723.5%\u66f4\u9ad8\u7684\u7efc\u5408\u53ef\u9760\u6027\u5206\u6570\uff0c\u7edf\u8ba1\u663e\u8457\u6027\u6781\u5f3a\uff0c\u8bc4\u4f30\u6210\u672c\u964d\u4f4e90%\uff0c\u540c\u65f6\u4fdd\u630195%\u7684\u4f20\u7edf\u65b9\u6cd5\u8986\u76d6\u7387\u3002", "conclusion": "Microprobe\u4e3a\u8d1f\u8d23\u4efbAI\u90e8\u7f72\u4e2d\u7684\u9ad8\u6548\u6a21\u578b\u8bc4\u4f30\u586b\u8865\u4e86\u5173\u952e\u7a7a\u767d\uff0c\u80fd\u591f\u4ee5\u6781\u4f4e\u6210\u672c\u5b9e\u73b0\u5168\u9762\u53ef\u9760\u6027\u8bc4\u4f30\u3002"}}
{"id": "2512.20964", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.20964", "abs": "https://arxiv.org/abs/2512.20964", "authors": ["Ji Hyuk Jung", "Ji Won Yoon"], "title": "Neutralization of IMU-Based GPS Spoofing Detection using external IMU sensor and feedback methodology", "comment": "12 pages, 10 figures", "summary": "Autonomous Vehicles (AVs) refer to systems capable of perceiving their states and moving without human intervention. Among the factors required for autonomous decision-making in mobility, positional awareness of the vehicle itself is the most critical. Accordingly, extensive research has been conducted on defense mechanisms against GPS spoofing attacks, which threaten AVs by disrupting position recognition. Among these, detection methods based on internal IMU sensors are regarded as some of the most effective. In this paper, we propose a spoofing attack system designed to neutralize IMU sensor-based detection. First, we present an attack modeling approach for bypassing such detection. Then, based on EKF sensor fusion, we experimentally analyze both the impact of GPS spoofing values on the internal target system and how our proposed methodology reduces anomaly detection within the target system. To this end, this paper proposes an attack model that performs GPS spoofing by stealing internal dynamic state information using an external IMU sensor, and the experimental results demonstrate that attack values can be injected without being detected.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86GPS\u6b3a\u9a97\u653b\u51fb\u7684IMU\u4f20\u611f\u5668\u68c0\u6d4b\u7ed5\u8fc7\u7cfb\u7edf\uff0c\u901a\u8fc7\u7a83\u53d6\u5185\u90e8\u52a8\u6001\u72b6\u6001\u4fe1\u606f\u8fdb\u884cGPS\u6b3a\u9a97\uff0c\u5b9e\u9a8c\u8bc1\u660e\u653b\u51fb\u503c\u53ef\u4ee5\u5728\u4e0d\u88ab\u68c0\u6d4b\u7684\u60c5\u51b5\u4e0b\u6ce8\u5165\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u4f4d\u7f6e\u611f\u77e5\u5bf9\u5176\u81ea\u4e3b\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0cGPS\u6b3a\u9a97\u653b\u51fb\u4f1a\u7834\u574f\u4f4d\u7f6e\u8bc6\u522b\u3002\u867d\u7136\u57fa\u4e8e\u5185\u90e8IMU\u4f20\u611f\u5668\u7684\u68c0\u6d4b\u65b9\u6cd5\u88ab\u8ba4\u4e3a\u662f\u6700\u6709\u6548\u7684\u9632\u5fa1\u673a\u5236\u4e4b\u4e00\uff0c\u4f46\u672c\u6587\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u7ed5\u8fc7\u6b64\u7c7b\u68c0\u6d4b\u7684\u6b3a\u9a97\u653b\u51fb\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u653b\u51fb\u5efa\u6a21\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u5916\u90e8IMU\u4f20\u611f\u5668\u7a83\u53d6\u5185\u90e8\u52a8\u6001\u72b6\u6001\u4fe1\u606f\u6765\u6267\u884cGPS\u6b3a\u9a97\u3002\u57fa\u4e8eEKF\uff08\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\uff09\u4f20\u611f\u5668\u878d\u5408\uff0c\u5b9e\u9a8c\u5206\u6790\u4e86GPS\u6b3a\u9a97\u503c\u5bf9\u76ee\u6807\u7cfb\u7edf\u7684\u5f71\u54cd\u4ee5\u53ca\u6240\u63d0\u65b9\u6cd5\u5982\u4f55\u51cf\u5c11\u76ee\u6807\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u653b\u51fb\u6a21\u578b\u80fd\u591f\u5728\u4e0d\u88ab\u68c0\u6d4b\u7684\u60c5\u51b5\u4e0b\u6ce8\u5165\u653b\u51fb\u503c\uff0c\u6210\u529f\u7ed5\u8fc7\u4e86\u57fa\u4e8eIMU\u4f20\u611f\u5668\u7684GPS\u6b3a\u9a97\u68c0\u6d4b\u673a\u5236\u3002", "conclusion": "\u672c\u6587\u5c55\u793a\u4e86\u4e00\u79cd\u9488\u5bf9\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86GPS\u6b3a\u9a97\u68c0\u6d4b\u7684\u6709\u6548\u7ed5\u8fc7\u6280\u672f\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u57fa\u4e8eIMU\u4f20\u611f\u5668\u7684\u9632\u5fa1\u673a\u5236\u5b58\u5728\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u4e3a\u6539\u8fdb\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u5b89\u5168\u9632\u62a4\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2512.20632", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20632", "abs": "https://arxiv.org/abs/2512.20632", "authors": ["Jianbing Ma", "Ao Feng", "Zhenjie Gao", "Xinyu Song", "Li Su", "Bin Chen", "Wei Wang", "Jiamin Wu"], "title": "Erkang-Diagnosis-1.1 Technical Report", "comment": "9 pages; 4 figures", "summary": "This report provides a detailed introduction to Erkang-Diagnosis-1.1 model, our AI healthcare consulting assistant developed using Alibaba Qwen-3 model. The Erkang model integrates approximately 500GB of high-quality structured medical knowledge, employing a hybrid approach combining enhanced pre-training and retrieval-enhanced generation to create a secure, reliable, and professional AI health advisor. Through 3-5 efficient interaction rounds, Erkang Diagnosis can accurately understand user symptoms, conduct preliminary analysis, and provide valuable diagnostic suggestions and health guidance. Designed to become users intelligent health companions, it empowers primary healthcare and health management. To validate, Erkang-Diagnosis-1.1 leads GPT-4 in terms of comprehensive medical exams.", "AI": {"tldr": "Erkang-Diagnosis-1.1\u662f\u57fa\u4e8e\u963f\u91cc\u901a\u4e49\u5343\u95ee\u6a21\u578b\u5f00\u53d1\u7684AI\u533b\u7597\u54a8\u8be2\u52a9\u624b\uff0c\u6574\u5408500GB\u9ad8\u8d28\u91cf\u533b\u5b66\u77e5\u8bc6\uff0c\u91c7\u7528\u589e\u5f3a\u9884\u8bad\u7ec3\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6df7\u5408\u65b9\u6cd5\uff0c\u80fd\u57283-5\u8f6e\u4ea4\u4e92\u4e2d\u63d0\u4f9b\u51c6\u786e\u8bca\u65ad\u5efa\u8bae\u548c\u5065\u5eb7\u6307\u5bfc\u3002", "motivation": "\u5f00\u53d1\u5b89\u5168\u3001\u53ef\u9760\u3001\u4e13\u4e1a\u7684AI\u5065\u5eb7\u987e\u95ee\uff0c\u8d4b\u80fd\u57fa\u5c42\u533b\u7597\u548c\u5065\u5eb7\u7ba1\u7406\uff0c\u6210\u4e3a\u7528\u6237\u7684\u667a\u80fd\u5065\u5eb7\u4f34\u4fa3\u3002", "method": "\u57fa\u4e8e\u963f\u91cc\u901a\u4e49\u5343\u95ee\u6a21\u578b\uff0c\u6574\u5408\u7ea6500GB\u9ad8\u8d28\u91cf\u7ed3\u6784\u5316\u533b\u5b66\u77e5\u8bc6\uff0c\u91c7\u7528\u589e\u5f3a\u9884\u8bad\u7ec3\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u6df7\u5408\u65b9\u6cd5\u3002", "result": "Erkang-Diagnosis-1.1\u5728\u7efc\u5408\u533b\u5b66\u8003\u8bd5\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u4e8eGPT-4\u3002", "conclusion": "Erkang-Diagnosis-1.1\u662f\u4e00\u4e2a\u6709\u6548\u7684AI\u533b\u7597\u54a8\u8be2\u52a9\u624b\uff0c\u80fd\u591f\u901a\u8fc7\u9ad8\u6548\u4ea4\u4e92\u63d0\u4f9b\u51c6\u786e\u7684\u8bca\u65ad\u5efa\u8bae\uff0c\u5728\u533b\u5b66\u77e5\u8bc6\u8bc4\u4f30\u65b9\u9762\u8d85\u8d8a\u73b0\u6709\u5148\u8fdb\u6a21\u578b\u3002"}}
{"id": "2512.20647", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20647", "abs": "https://arxiv.org/abs/2512.20647", "authors": ["Leo Lu", "Jonathan Zhang", "Sean Chua", "Spencer Kim", "Kevin Zhu", "Sean O'Brien", "Vasu Sharma"], "title": "Reasoning Relay: Evaluating Stability and Interchangeability of Large Language Models in Mathematical Reasoning", "comment": "NeurIPS 2025 Workshop on Socially Responsible and Trustworthy Foundation Models (ResponsibleFM)", "summary": "Chain-of-Thought (CoT) prompting has significantly advanced the reasoning capabilities of large language models (LLMs). While prior work focuses on improving model performance through internal reasoning strategies, little is known about the interchangeability of reasoning across different models. In this work, we explore whether a partially completed reasoning chain from one model can be reliably continued by another model, either within the same model family or across families. We achieve this by assessing the sufficiency of intermediate reasoning traces as transferable scaffolds for logical coherence and final answer accuracy. We interpret this interchangeability as a means of examining inference-time trustworthiness, probing whether reasoning remains both coherent and reliable under model substitution. Using token-level log-probability thresholds to truncate reasoning at early, mid, and late stages from our baseline models, Gemma-3-4B-IT and LLaMA-3.1-70B-Instruct, we conduct continuation experiments with Gemma-3-1B-IT and LLaMA-3.1-8B-Instruct to test intra-family and cross-family behaviors. Our evaluation pipeline leverages truncation thresholds with a Process Reward Model (PRM), providing a reproducible framework for assessing reasoning stability via model interchange. Evaluations with a PRM reveal that hybrid reasoning chains often preserve, and in some cases even improve, final accuracy and logical structure. Our findings point towards interchangeability as an emerging behavioral property of reasoning models, offering insights into new paradigms for reliable modular reasoning in collaborative AI systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u4e4b\u95f4\u63a8\u7406\u94fe\u7684\u4e92\u6362\u6027\uff0c\u53d1\u73b0\u90e8\u5206\u5b8c\u6210\u7684\u63a8\u7406\u94fe\u53ef\u4ee5\u88ab\u5176\u4ed6\u6a21\u578b\u53ef\u9760\u5730\u7ee7\u7eed\uff0c\u6709\u65f6\u751a\u81f3\u80fd\u63d0\u5347\u6700\u7ec8\u51c6\u786e\u7387\u3002", "motivation": "\u867d\u7136CoT\u63d0\u793a\u663e\u8457\u63d0\u5347\u4e86LLMs\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5148\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u901a\u8fc7\u5185\u90e8\u63a8\u7406\u7b56\u7565\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u5bf9\u4e8e\u4e0d\u540c\u6a21\u578b\u95f4\u63a8\u7406\u7684\u4e92\u6362\u6027\u77e5\u4e4b\u751a\u5c11\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e00\u4e2a\u6a21\u578b\u90e8\u5206\u5b8c\u6210\u7684\u63a8\u7406\u94fe\u662f\u5426\u53ef\u4ee5\u88ab\u53e6\u4e00\u4e2a\u6a21\u578b\u53ef\u9760\u5730\u7ee7\u7eed\uff0c\u65e0\u8bba\u662f\u540c\u4e00\u6a21\u578b\u5bb6\u65cf\u5185\u8fd8\u662f\u8de8\u5bb6\u65cf\u3002", "method": "\u4f7f\u7528token\u7ea7\u5bf9\u6570\u6982\u7387\u9608\u503c\u5728\u65e9\u671f\u3001\u4e2d\u671f\u548c\u665a\u671f\u9636\u6bb5\u622a\u65ad\u57fa\u7ebf\u6a21\u578b\uff08Gemma-3-4B-IT\u548cLLaMA-3.1-70B-Instruct\uff09\u7684\u63a8\u7406\u94fe\uff0c\u7136\u540e\u7528Gemma-3-1B-IT\u548cLLaMA-3.1-8B-Instruct\u8fdb\u884c\u7ee7\u7eed\u5b9e\u9a8c\uff0c\u6d4b\u8bd5\u5bb6\u65cf\u5185\u548c\u8de8\u5bb6\u65cf\u884c\u4e3a\u3002\u8bc4\u4f30\u6d41\u7a0b\u7ed3\u5408\u622a\u65ad\u9608\u503c\u548c\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRM\uff09\uff0c\u4e3a\u901a\u8fc7\u6a21\u578b\u4e92\u6362\u8bc4\u4f30\u63a8\u7406\u7a33\u5b9a\u6027\u63d0\u4f9b\u53ef\u590d\u73b0\u6846\u67b6\u3002", "result": "\u4f7f\u7528PRM\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u6df7\u5408\u63a8\u7406\u94fe\u901a\u5e38\u80fd\u591f\u4fdd\u6301\u751a\u81f3\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u63d0\u5347\u6700\u7ec8\u51c6\u786e\u7387\u548c\u903b\u8f91\u7ed3\u6784\u3002\u8fd9\u8868\u660e\u63a8\u7406\u6a21\u578b\u5177\u6709\u4e92\u6362\u6027\u8fd9\u4e00\u65b0\u5174\u884c\u4e3a\u7279\u6027\u3002", "conclusion": "\u63a8\u7406\u7684\u4e92\u6362\u6027\u662f\u63a8\u7406\u6a21\u578b\u7684\u4e00\u4e2a\u65b0\u5174\u884c\u4e3a\u7279\u6027\uff0c\u4e3a\u534f\u4f5cAI\u7cfb\u7edf\u4e2d\u53ef\u9760\u7684\u6a21\u5757\u5316\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u8303\u5f0f\u89c1\u89e3\u3002"}}
{"id": "2512.21008", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21008", "abs": "https://arxiv.org/abs/2512.21008", "authors": ["Lichao Wu", "Sasha Behrouzi", "Mohamadreza Rostami", "Stjepan Picek", "Ahmad-Reza Sadeghi"], "title": "GateBreaker: Gate-Guided Attacks on Mixture-of-Expert LLMs", "comment": "Accepted by USENIX Security'26", "summary": "Mixture-of-Experts (MoE) architectures have advanced the scaling of Large Language Models (LLMs) by activating only a sparse subset of parameters per input, enabling state-of-the-art performance with reduced computational cost. As these models are increasingly deployed in critical domains, understanding and strengthening their alignment mechanisms is essential to prevent harmful outputs. However, existing LLM safety research has focused almost exclusively on dense architectures, leaving the unique safety properties of MoEs largely unexamined. The modular, sparsely-activated design of MoEs suggests that safety mechanisms may operate differently than in dense models, raising questions about their robustness.\n  In this paper, we present GateBreaker, the first training-free, lightweight, and architecture-agnostic attack framework that compromises the safety alignment of modern MoE LLMs at inference time. GateBreaker operates in three stages: (i) gate-level profiling, which identifies safety experts disproportionately routed on harmful inputs, (ii) expert-level localization, which localizes the safety structure within safety experts, and (iii) targeted safety removal, which disables the identified safety structure to compromise the safety alignment. Our study shows that MoE safety concentrates within a small subset of neurons coordinated by sparse routing. Selective disabling of these neurons, approximately 3% of neurons in the targeted expert layers, significantly increases the averaged attack success rate (ASR) from 7.4% to 64.9% against the eight latest aligned MoE LLMs with limited utility degradation. These safety neurons transfer across models within the same family, raising ASR from 17.9% to 67.7% with one-shot transfer attack. Furthermore, GateBreaker generalizes to five MoE vision language models (VLMs) with 60.9% ASR on unsafe image inputs.", "AI": {"tldr": "GateBreaker\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u8f7b\u91cf\u7ea7\u3001\u67b6\u6784\u65e0\u5173\u7684\u653b\u51fb\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9MoE LLMs\u7684\u5b89\u5168\u5bf9\u9f50\u673a\u5236\uff0c\u901a\u8fc7\u8bc6\u522b\u548c\u7981\u7528\u5b89\u5168\u4e13\u5bb6\u4e2d\u7684\u5173\u952e\u795e\u7ecf\u5143\u6765\u7834\u574f\u6a21\u578b\u7684\u5b89\u5168\u6027\u3002", "motivation": "\u968f\u7740MoE\u67b6\u6784\u5728\u5173\u952e\u9886\u57df\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u7406\u89e3\u5176\u5b89\u5168\u673a\u5236\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u5b89\u5168\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5bc6\u96c6\u67b6\u6784\uff0c\u5bf9MoE\u72ec\u7279\u7684\u5b89\u5168\u7279\u6027\u7814\u7a76\u4e0d\u8db3\uff0c\u5176\u6a21\u5757\u5316\u3001\u7a00\u758f\u6fc0\u6d3b\u7684\u8bbe\u8ba1\u53ef\u80fd\u5bfc\u81f4\u5b89\u5168\u673a\u5236\u4e0e\u5bc6\u96c6\u6a21\u578b\u4e0d\u540c\uff0c\u5b58\u5728\u6f5c\u5728\u8106\u5f31\u6027\u3002", "method": "GateBreaker\u91c7\u7528\u4e09\u9636\u6bb5\u653b\u51fb\u6846\u67b6\uff1a1) \u95e8\u7ea7\u5206\u6790\uff0c\u8bc6\u522b\u5728\u6709\u5bb3\u8f93\u5165\u4e0a\u88ab\u8fc7\u5ea6\u8def\u7531\u7684\u5b89\u5168\u4e13\u5bb6\uff1b2) \u4e13\u5bb6\u7ea7\u5b9a\u4f4d\uff0c\u5728\u5b89\u5168\u4e13\u5bb6\u5185\u90e8\u5b9a\u4f4d\u5b89\u5168\u7ed3\u6784\uff1b3) \u9488\u5bf9\u6027\u5b89\u5168\u79fb\u9664\uff0c\u7981\u7528\u5df2\u8bc6\u522b\u7684\u5b89\u5168\u7ed3\u6784\u4ee5\u7834\u574f\u5b89\u5168\u5bf9\u9f50\u3002", "result": "\u653b\u51fb\u6210\u529f\u7387\u4ece7.4%\u63d0\u5347\u81f364.9%\uff0c\u4ec5\u9700\u7981\u7528\u76ee\u6807\u4e13\u5bb6\u5c42\u4e2d\u7ea63%\u7684\u795e\u7ecf\u5143\u3002\u5b89\u5168\u795e\u7ecf\u5143\u5728\u540c\u4e00\u6a21\u578b\u5bb6\u65cf\u5185\u53ef\u8fc1\u79fb\uff0c\u5355\u6b21\u8fc1\u79fb\u653b\u51fb\u4f7f\u6210\u529f\u7387\u4ece17.9%\u63d0\u5347\u81f367.7%\u3002\u6846\u67b6\u53ef\u6cdb\u5316\u5230MoE\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u5371\u9669\u56fe\u50cf\u8f93\u5165\u4e0a\u8fbe\u523060.9%\u7684\u6210\u529f\u7387\u3002", "conclusion": "MoE\u7684\u5b89\u5168\u673a\u5236\u96c6\u4e2d\u5728\u7531\u7a00\u758f\u8def\u7531\u534f\u8c03\u7684\u5c0f\u90e8\u5206\u795e\u7ecf\u5143\u4e2d\uff0c\u8fd9\u4e9b\u795e\u7ecf\u5143\u5177\u6709\u53ef\u8fc1\u79fb\u6027\u3002GateBreaker\u63ed\u793a\u4e86MoE\u67b6\u6784\u7684\u5b89\u5168\u8106\u5f31\u6027\uff0c\u4e3a\u672a\u6765\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u65b9\u5411\u3002"}}
{"id": "2512.21048", "categories": ["cs.CR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.21048", "abs": "https://arxiv.org/abs/2512.21048", "authors": ["Savvy Sharma", "George Petrovic", "Sarthak Kaushik"], "title": "zkFL-Health: Blockchain-Enabled Zero-Knowledge Federated Learning for Medical AI Privacy", "comment": "10 pages, 1 figure, 5 tables", "summary": "Healthcare AI needs large, diverse datasets, yet strict privacy and governance constraints prevent raw data sharing across institutions. Federated learning (FL) mitigates this by training where data reside and exchanging only model updates, but practical deployments still face two core risks: (1) privacy leakage via gradients or updates (membership inference, gradient inversion) and (2) trust in the aggregator, a single point of failure that can drop, alter, or inject contributions undetected. We present zkFL-Health, an architecture that combines FL with zero-knowledge proofs (ZKPs) and Trusted Execution Environments (TEEs) to deliver privacy-preserving, verifiably correct collaborative training for medical AI. Clients locally train and commit their updates; the aggregator operates within a TEE to compute the global update and produces a succinct ZK proof (via Halo2/Nova) that it used exactly the committed inputs and the correct aggregation rule, without revealing any client update to the host. Verifier nodes validate the proof and record cryptographic commitments on-chain, providing an immutable audit trail and removing the need to trust any single party. We outline system and threat models tailored to healthcare, the zkFL-Health protocol, security/privacy guarantees, and a performance evaluation plan spanning accuracy, privacy risk, latency, and cost. This framework enables multi-institutional medical AI with strong confidentiality, integrity, and auditability, key properties for clinical adoption and regulatory compliance.", "AI": {"tldr": "zkFL-Health\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\u3001\u96f6\u77e5\u8bc6\u8bc1\u660e\u548c\u53ef\u4fe1\u6267\u884c\u73af\u5883\uff0c\u4e3a\u533b\u7597AI\u63d0\u4f9b\u9690\u79c1\u4fdd\u62a4\u3001\u53ef\u9a8c\u8bc1\u6b63\u786e\u7684\u534f\u4f5c\u8bad\u7ec3\u6846\u67b6\uff0c\u89e3\u51b3\u6570\u636e\u5171\u4eab\u4e2d\u7684\u9690\u79c1\u6cc4\u9732\u548c\u805a\u5408\u5668\u4fe1\u4efb\u95ee\u9898\u3002", "motivation": "\u533b\u7597AI\u9700\u8981\u5927\u89c4\u6a21\u591a\u6837\u5316\u6570\u636e\u96c6\uff0c\u4f46\u4e25\u683c\u7684\u9690\u79c1\u548c\u6cbb\u7406\u9650\u5236\u963b\u788d\u4e86\u673a\u6784\u95f4\u7684\u539f\u59cb\u6570\u636e\u5171\u4eab\u3002\u8054\u90a6\u5b66\u4e60\u867d\u7136\u80fd\u5728\u6570\u636e\u672c\u5730\u8bad\u7ec3\u5e76\u4ec5\u4ea4\u6362\u6a21\u578b\u66f4\u65b0\uff0c\u4f46\u4ecd\u9762\u4e34\u4e24\u4e2a\u6838\u5fc3\u98ce\u9669\uff1a1) \u901a\u8fc7\u68af\u5ea6\u6216\u66f4\u65b0\u7684\u9690\u79c1\u6cc4\u9732\uff08\u6210\u5458\u63a8\u7406\u3001\u68af\u5ea6\u53cd\u8f6c\uff09\uff1b2) \u5bf9\u805a\u5408\u5668\u7684\u4fe1\u4efb\u95ee\u9898\uff0c\u805a\u5408\u5668\u4f5c\u4e3a\u5355\u70b9\u6545\u969c\u53ef\u80fd\u4e22\u5f03\u3001\u7be1\u6539\u6216\u6ce8\u5165\u8d21\u732e\u800c\u4e0d\u88ab\u68c0\u6d4b\u3002", "method": "\u63d0\u51fazkFL-Health\u67b6\u6784\uff0c\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\u3001\u96f6\u77e5\u8bc6\u8bc1\u660e\u548c\u53ef\u4fe1\u6267\u884c\u73af\u5883\u3002\u5ba2\u6237\u7aef\u5728\u672c\u5730\u8bad\u7ec3\u5e76\u63d0\u4ea4\u66f4\u65b0\u627f\u8bfa\uff1b\u805a\u5408\u5668\u5728TEE\u5185\u8fd0\u884c\u4ee5\u8ba1\u7b97\u5168\u5c40\u66f4\u65b0\uff0c\u5e76\u901a\u8fc7Halo2/Nova\u751f\u6210\u7b80\u6d01\u7684ZK\u8bc1\u660e\uff0c\u8bc1\u660e\u5176\u4f7f\u7528\u4e86\u786e\u5207\u7684\u627f\u8bfa\u8f93\u5165\u548c\u6b63\u786e\u7684\u805a\u5408\u89c4\u5219\uff0c\u800c\u4e0d\u5411\u4e3b\u673a\u6cc4\u9732\u4efb\u4f55\u5ba2\u6237\u7aef\u66f4\u65b0\u3002\u9a8c\u8bc1\u8282\u70b9\u9a8c\u8bc1\u8bc1\u660e\u5e76\u5728\u94fe\u4e0a\u8bb0\u5f55\u52a0\u5bc6\u627f\u8bfa\uff0c\u63d0\u4f9b\u4e0d\u53ef\u53d8\u7684\u5ba1\u8ba1\u8ffd\u8e2a\u3002", "result": "\u8be5\u6846\u67b6\u4e3a\u591a\u673a\u6784\u533b\u7597AI\u63d0\u4f9b\u5f3a\u5927\u7684\u673a\u5bc6\u6027\u3001\u5b8c\u6574\u6027\u548c\u53ef\u5ba1\u8ba1\u6027\uff0c\u8fd9\u4e9b\u662f\u4e34\u5e8a\u91c7\u7528\u548c\u76d1\u7ba1\u5408\u89c4\u7684\u5173\u952e\u5c5e\u6027\u3002\u901a\u8fc7\u6027\u80fd\u8bc4\u4f30\u8ba1\u5212\u6db5\u76d6\u51c6\u786e\u6027\u3001\u9690\u79c1\u98ce\u9669\u3001\u5ef6\u8fdf\u548c\u6210\u672c\u7b49\u65b9\u9762\u3002", "conclusion": "zkFL-Health\u901a\u8fc7\u96f6\u77e5\u8bc6\u8bc1\u660e\u548c\u53ef\u4fe1\u6267\u884c\u73af\u5883\u7684\u7ed3\u5408\uff0c\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u5728\u533b\u7597\u9886\u57df\u7684\u9690\u79c1\u6cc4\u9732\u548c\u4fe1\u4efb\u95ee\u9898\uff0c\u4e3a\u5b9e\u73b0\u5b89\u5168\u3001\u53ef\u9a8c\u8bc1\u7684\u591a\u673a\u6784\u533b\u7597AI\u534f\u4f5c\u8bad\u7ec3\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2512.20649", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.20649", "abs": "https://arxiv.org/abs/2512.20649", "authors": ["Zixun Luo", "Yuhang Fan", "Yufei Li", "Youzhi Zhang", "Hengyu Lin", "Ziqi Wang"], "title": "AIAuditTrack: A Framework for AI Security system", "comment": null, "summary": "The rapid expansion of AI-driven applications powered by large language models has led to a surge in AI interaction data, raising urgent challenges in security, accountability, and risk traceability. This paper presents AiAuditTrack (AAT), a blockchain-based framework for AI usage traffic recording and governance. AAT leverages decentralized identity (DID) and verifiable credentials (VC) to establish trusted and identifiable AI entities, and records inter-entity interaction trajectories on-chain to enable cross-system supervision and auditing. AI entities are modeled as nodes in a dynamic interaction graph, where edges represent time-specific behavioral trajectories. Based on this model, a risk diffusion algorithm is proposed to trace the origin of risky behaviors and propagate early warnings across involved entities. System performance is evaluated using blockchain Transactions Per Second (TPS) metrics, demonstrating the feasibility and stability of AAT under large-scale interaction recording. AAT provides a scalable and verifiable solution for AI auditing, risk management, and responsibility attribution in complex multi-agent environments.", "AI": {"tldr": "AiAuditTrack (AAT) \u662f\u4e00\u4e2a\u57fa\u4e8e\u533a\u5757\u94fe\u7684AI\u4f7f\u7528\u6d41\u91cf\u8bb0\u5f55\u4e0e\u6cbb\u7406\u6846\u67b6\uff0c\u5229\u7528\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd\u548c\u53ef\u9a8c\u8bc1\u51ed\u8bc1\u5efa\u7acb\u53ef\u4fe1AI\u5b9e\u4f53\uff0c\u8bb0\u5f55\u4ea4\u4e92\u8f68\u8ff9\u5b9e\u73b0\u8de8\u7cfb\u7edf\u76d1\u7ba1\uff0c\u5e76\u63d0\u51fa\u98ce\u9669\u6269\u6563\u7b97\u6cd5\u8ffd\u8e2a\u98ce\u9669\u884c\u4e3a\u6e90\u5934\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684AI\u5e94\u7528\u5feb\u901f\u6269\u5c55\uff0cAI\u4ea4\u4e92\u6570\u636e\u6fc0\u589e\uff0c\u5e26\u6765\u4e86\u5b89\u5168\u3001\u95ee\u8d23\u548c\u98ce\u9669\u53ef\u8ffd\u6eaf\u6027\u65b9\u9762\u7684\u7d27\u8feb\u6311\u6218\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u4fe1\u7684AI\u4f7f\u7528\u8bb0\u5f55\u548c\u6cbb\u7406\u673a\u5236\u3002", "method": "1. \u5229\u7528\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd(DID)\u548c\u53ef\u9a8c\u8bc1\u51ed\u8bc1(VC)\u5efa\u7acb\u53ef\u4fe1\u53ef\u8bc6\u522b\u7684AI\u5b9e\u4f53\uff1b2. \u5c06AI\u5b9e\u4f53\u5efa\u6a21\u4e3a\u52a8\u6001\u4ea4\u4e92\u56fe\u4e2d\u7684\u8282\u70b9\uff0c\u8fb9\u8868\u793a\u65f6\u95f4\u7279\u5b9a\u7684\u884c\u4e3a\u8f68\u8ff9\uff1b3. \u63d0\u51fa\u98ce\u9669\u6269\u6563\u7b97\u6cd5\u8ffd\u8e2a\u98ce\u9669\u884c\u4e3a\u6e90\u5934\u5e76\u5728\u76f8\u5173\u5b9e\u4f53\u95f4\u4f20\u64ad\u65e9\u671f\u9884\u8b66\uff1b4. \u5728\u94fe\u4e0a\u8bb0\u5f55\u5b9e\u4f53\u95f4\u4ea4\u4e92\u8f68\u8ff9\u4ee5\u5b9e\u73b0\u8de8\u7cfb\u7edf\u76d1\u7ba1\u548c\u5ba1\u8ba1\u3002", "result": "\u901a\u8fc7\u533a\u5757\u94fe\u4ea4\u6613\u6bcf\u79d2(TPS)\u6307\u6807\u8bc4\u4f30\u7cfb\u7edf\u6027\u80fd\uff0c\u8bc1\u660eAAT\u5728\u5927\u89c4\u6a21\u4ea4\u4e92\u8bb0\u5f55\u4e0b\u7684\u53ef\u884c\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u4e3a\u590d\u6742\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684AI\u5ba1\u8ba1\u3001\u98ce\u9669\u7ba1\u7406\u548c\u8d23\u4efb\u5f52\u5c5e\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u9a8c\u8bc1\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "AAT\u6846\u67b6\u4e3aAI\u5ba1\u8ba1\u3001\u98ce\u9669\u7ba1\u7406\u548c\u8d23\u4efb\u5f52\u5c5e\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u9a8c\u8bc1\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5e94\u5bf9\u590d\u6742\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u5b89\u5168\u3001\u95ee\u8d23\u548c\u98ce\u9669\u53ef\u8ffd\u6eaf\u6027\u6311\u6218\u3002"}}
{"id": "2512.20650", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20650", "abs": "https://arxiv.org/abs/2512.20650", "authors": ["Esmail Gumaan"], "title": "Mixture of Attention Schemes (MoAS): Learning to Route Between MHA, GQA, and MQA", "comment": "5 pages", "summary": "The choice of attention mechanism in Transformer models involves a critical trade-off between modeling quality and inference efficiency. Multi-Head Attention (MHA) offers the best quality but suffers from large Key-Value (KV) cache memory requirements during inference. Multi-Query Attention (MQA) and Grouped-Query Attention (GQA) reduce memory usage but often at the cost of model performance. In this work, we propose Mixture of Attention Schemes (MoAS), a novel architecture that dynamically selects the optimal attention scheme (MHA, GQA, or MQA) for each token via a learned router. We demonstrate that dynamic routing performs better than static averaging of schemes and achieves performance competitive with the MHA baseline while offering potential for conditional compute efficiency. Experimental results on WikiText-2 show that dynamic routing (val loss 2.3074) outperforms a static mixture (2.3093), validating the effectiveness of the proposed method. Our code is available at https://github.com/Esmail-ibraheem/Mixture-of-Attention-Schemes-MoAS.", "AI": {"tldr": "\u63d0\u51faMoAS\u67b6\u6784\uff0c\u901a\u8fc7\u5b66\u4e60\u7684\u8def\u7531\u5668\u4e3a\u6bcf\u4e2atoken\u52a8\u6001\u9009\u62e9\u6700\u4f18\u6ce8\u610f\u529b\u65b9\u6848\uff08MHA\u3001GQA\u6216MQA\uff09\uff0c\u5728\u4fdd\u6301MHA\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11KV\u7f13\u5b58\u5185\u5b58\u9700\u6c42", "motivation": "Transformer\u6a21\u578b\u4e2d\u6ce8\u610f\u529b\u673a\u5236\u7684\u9009\u62e9\u9700\u8981\u5728\u5efa\u6a21\u8d28\u91cf\u548c\u63a8\u7406\u6548\u7387\u4e4b\u95f4\u6743\u8861\u3002MHA\u63d0\u4f9b\u6700\u4f73\u8d28\u91cf\u4f46\u63a8\u7406\u65f6KV\u7f13\u5b58\u5185\u5b58\u9700\u6c42\u5927\uff0cMQA\u548cGQA\u51cf\u5c11\u5185\u5b58\u4f46\u6027\u80fd\u4e0b\u964d", "method": "\u63d0\u51fa\u6df7\u5408\u6ce8\u610f\u529b\u65b9\u6848\uff08MoAS\uff09\uff0c\u901a\u8fc7\u5b66\u4e60\u7684\u8def\u7531\u5668\u4e3a\u6bcf\u4e2atoken\u52a8\u6001\u9009\u62e9\u6700\u4f18\u6ce8\u610f\u529b\u65b9\u6848\uff08MHA\u3001GQA\u6216MQA\uff09\uff0c\u800c\u4e0d\u662f\u9759\u6001\u5e73\u5747\u65b9\u6848", "result": "\u5728WikiText-2\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u52a8\u6001\u8def\u7531\uff08\u9a8c\u8bc1\u635f\u59312.3074\uff09\u4f18\u4e8e\u9759\u6001\u6df7\u5408\uff082.3093\uff09\uff0c\u6027\u80fd\u4e0eMHA\u57fa\u7ebf\u7ade\u4e89\uff0c\u540c\u65f6\u63d0\u4f9b\u6761\u4ef6\u8ba1\u7b97\u6548\u7387\u6f5c\u529b", "conclusion": "MoAS\u901a\u8fc7\u52a8\u6001\u8def\u7531\u673a\u5236\u6709\u6548\u5e73\u8861\u4e86\u6ce8\u610f\u529b\u673a\u5236\u7684\u8d28\u91cf\u4e0e\u6548\u7387\u6743\u8861\uff0c\u4e3aTransformer\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u67b6\u6784\u9009\u62e9"}}
{"id": "2512.21132", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2512.21132", "abs": "https://arxiv.org/abs/2512.21132", "authors": ["Tobias von Arx", "Niels M\u00fcndler", "Mark Vero", "Maximilian Baader", "Martin Vechev"], "title": "AutoBaxBuilder: Bootstrapping Code Security Benchmarking", "comment": null, "summary": "As LLMs see wide adoption in software engineering, the reliable assessment of the correctness and security of LLM-generated code is crucial. Notably, prior work has demonstrated that security is often overlooked, exposing that LLMs are prone to generating code with security vulnerabilities. These insights were enabled by specialized benchmarks, crafted through significant manual effort by security experts. However, relying on manually-crafted benchmarks is insufficient in the long term, because benchmarks (i) naturally end up contaminating training data, (ii) must extend to new tasks to provide a more complete picture, and (iii) must increase in difficulty to challenge more capable LLMs. In this work, we address these challenges and present AutoBaxBuilder, a framework that generates tasks and tests for code security benchmarking from scratch. We introduce a robust pipeline with fine-grained plausibility checks, leveraging the code understanding capabilities of LLMs to construct functionality tests and end-to-end security-probing exploits. To confirm the quality of the generated benchmark, we conduct both a qualitative analysis and perform quantitative experiments, comparing it against tasks constructed by human experts. We use AutoBaxBuilder to construct entirely new tasks and release them to the public as AutoBaxBench, together with a thorough evaluation of the security capabilities of LLMs on these tasks. We find that a new task can be generated in under 2 hours, costing less than USD 10.", "AI": {"tldr": "AutoBaxBuilder\u662f\u4e00\u4e2a\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u7684\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u96f6\u5f00\u59cb\u521b\u5efa\u4efb\u52a1\u548c\u6d4b\u8bd5\uff0c\u89e3\u51b3\u4eba\u5de5\u57fa\u51c6\u6d4b\u8bd5\u7684\u5c40\u9650\u6027\uff0c\u6210\u672c\u4f4e\u4e14\u6548\u7387\u9ad8\u3002", "motivation": "\u968f\u7740LLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u53ef\u9760\u8bc4\u4f30LLM\u751f\u6210\u4ee3\u7801\u7684\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7814\u7a76\u8868\u660eLLM\u5bb9\u6613\u751f\u6210\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\u7684\u4ee3\u7801\uff0c\u4f46\u5f53\u524d\u4f9d\u8d56\u5b89\u5168\u4e13\u5bb6\u624b\u5de5\u5236\u4f5c\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u57fa\u51c6\u6d4b\u8bd5\u4f1a\u6c61\u67d3\u8bad\u7ec3\u6570\u636e\uff1b2\uff09\u9700\u8981\u6269\u5c55\u5230\u65b0\u4efb\u52a1\u4ee5\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u8bc4\u4f30\uff1b3\uff09\u9700\u8981\u589e\u52a0\u96be\u5ea6\u4ee5\u6311\u6218\u66f4\u5f3a\u5927\u7684LLM\u3002", "method": "\u63d0\u51faAutoBaxBuilder\u6846\u67b6\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u7684\u5408\u7406\u6027\u68c0\u67e5\u6784\u5efa\u7a33\u5065\u7684\u6d41\u6c34\u7ebf\uff0c\u5229\u7528LLM\u7684\u4ee3\u7801\u7406\u89e3\u80fd\u529b\u6784\u5efa\u529f\u80fd\u6d4b\u8bd5\u548c\u7aef\u5230\u7aef\u7684\u5b89\u5168\u63a2\u6d4b\u5229\u7528\u3002\u6846\u67b6\u80fd\u591f\u4ece\u96f6\u5f00\u59cb\u751f\u6210\u4efb\u52a1\u548c\u6d4b\u8bd5\uff0c\u7528\u4e8e\u4ee3\u7801\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u4f7f\u7528AutoBaxBuilder\u6784\u5efa\u4e86\u5168\u65b0\u7684\u4efb\u52a1\u96c6AutoBaxBench\u5e76\u516c\u5f00\u53d1\u5e03\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u751f\u6210\u4e00\u4e2a\u65b0\u4efb\u52a1\u4ec5\u9700\u4e0d\u52302\u5c0f\u65f6\uff0c\u6210\u672c\u4f4e\u4e8e10\u7f8e\u5143\u3002\u901a\u8fc7\u5b9a\u6027\u5206\u6790\u548c\u5b9a\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u751f\u6210\u57fa\u51c6\u7684\u8d28\u91cf\uff0c\u5e76\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u6784\u5efa\u7684\u4efb\u52a1\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "conclusion": "AutoBaxBuilder\u6210\u529f\u89e3\u51b3\u4e86\u4eba\u5de5\u57fa\u51c6\u6d4b\u8bd5\u7684\u5c40\u9650\u6027\uff0c\u80fd\u591f\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u5730\u751f\u6210\u4ee3\u7801\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u4efb\u52a1\uff0c\u4e3a\u8bc4\u4f30LLM\u7684\u5b89\u5168\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u548c\u65b9\u6cd5\u3002"}}
{"id": "2512.20651", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20651", "abs": "https://arxiv.org/abs/2512.20651", "authors": ["Deliang Wen", "Ke Sun"], "title": "Memory Bear AI A Breakthrough from Memory to Cognition Toward Artificial General Intelligence", "comment": null, "summary": "Large language models (LLMs) face inherent limitations in memory, including restricted context windows, long-term knowledge forgetting, redundant information accumulation, and hallucination generation. These issues severely constrain sustained dialogue and personalized services. This paper proposes the Memory Bear system, which constructs a human-like memory architecture grounded in cognitive science principles. By integrating multimodal information perception, dynamic memory maintenance, and adaptive cognitive services, Memory Bear achieves a full-chain reconstruction of LLM memory mechanisms. Across domains such as healthcare, enterprise operations, and education, Memory Bear demonstrates substantial engineering innovation and performance breakthroughs. It significantly improves knowledge fidelity and retrieval efficiency in long-term conversations, reduces hallucination rates, and enhances contextual adaptability and reasoning capability through memory-cognition integration. Experimental results show that, compared with existing solutions (e.g., Mem0, MemGPT, Graphiti), Memory Bear outperforms them across key metrics, including accuracy, token efficiency, and response latency. This marks a crucial step forward in advancing AI from \"memory\" to \"cognition\".", "AI": {"tldr": "Memory Bear\u7cfb\u7edf\u901a\u8fc7\u6784\u5efa\u7c7b\u4eba\u8bb0\u5fc6\u67b6\u6784\uff0c\u89e3\u51b3LLM\u5728\u8bb0\u5fc6\u65b9\u9762\u7684\u56fa\u6709\u5c40\u9650\uff0c\u5305\u62ec\u53d7\u9650\u4e0a\u4e0b\u6587\u7a97\u53e3\u3001\u957f\u671f\u77e5\u8bc6\u9057\u5fd8\u3001\u5197\u4f59\u4fe1\u606f\u79ef\u7d2f\u548c\u5e7b\u89c9\u751f\u6210\u7b49\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u957f\u671f\u5bf9\u8bdd\u4e2d\u7684\u77e5\u8bc6\u4fdd\u771f\u5ea6\u548c\u68c0\u7d22\u6548\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u56fa\u6709\u7684\u8bb0\u5fc6\u9650\u5236\uff0c\u5305\u62ec\u53d7\u9650\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u3001\u957f\u671f\u77e5\u8bc6\u9057\u5fd8\u3001\u5197\u4f59\u4fe1\u606f\u79ef\u7d2f\u548c\u5e7b\u89c9\u751f\u6210\u7b49\u95ee\u9898\uff0c\u8fd9\u4e9b\u4e25\u91cd\u5236\u7ea6\u4e86\u6301\u7eed\u5bf9\u8bdd\u548c\u4e2a\u6027\u5316\u670d\u52a1\u7684\u5b9e\u73b0\u3002", "method": "\u57fa\u4e8e\u8ba4\u77e5\u79d1\u5b66\u539f\u7406\u6784\u5efa\u7c7b\u4eba\u8bb0\u5fc6\u67b6\u6784\uff0c\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f\u611f\u77e5\u3001\u52a8\u6001\u8bb0\u5fc6\u7ef4\u62a4\u548c\u81ea\u9002\u5e94\u8ba4\u77e5\u670d\u52a1\uff0c\u5b9e\u73b0\u5bf9LLM\u8bb0\u5fc6\u673a\u5236\u7684\u5168\u94fe\u91cd\u6784\u3002", "result": "\u5728\u533b\u7597\u3001\u4f01\u4e1a\u8fd0\u8425\u548c\u6559\u80b2\u7b49\u591a\u4e2a\u9886\u57df\u5c55\u793a\u51fa\u663e\u8457\u7684\u5de5\u7a0b\u521b\u65b0\u548c\u6027\u80fd\u7a81\u7834\uff0c\u76f8\u6bd4\u73b0\u6709\u89e3\u51b3\u65b9\u6848\uff08\u5982Mem0\u3001MemGPT\u3001Graphiti\uff09\uff0c\u5728\u51c6\u786e\u6027\u3001token\u6548\u7387\u548c\u54cd\u5e94\u5ef6\u8fdf\u7b49\u5173\u952e\u6307\u6807\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "Memory Bear\u7cfb\u7edf\u663e\u8457\u6539\u5584\u4e86\u957f\u671f\u5bf9\u8bdd\u4e2d\u7684\u77e5\u8bc6\u4fdd\u771f\u5ea6\u548c\u68c0\u7d22\u6548\u7387\uff0c\u964d\u4f4e\u4e86\u5e7b\u89c9\u7387\uff0c\u5e76\u901a\u8fc7\u8bb0\u5fc6-\u8ba4\u77e5\u96c6\u6210\u589e\u5f3a\u4e86\u4e0a\u4e0b\u6587\u9002\u5e94\u6027\u548c\u63a8\u7406\u80fd\u529b\uff0c\u6807\u5fd7\u7740AI\u4ece\"\u8bb0\u5fc6\"\u5411\"\u8ba4\u77e5\"\u8fc8\u8fdb\u7684\u5173\u952e\u4e00\u6b65\u3002"}}
{"id": "2512.21236", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.21236", "abs": "https://arxiv.org/abs/2512.21236", "authors": ["Yifan Huang", "Xiaojun Jia", "Wenbo Guo", "Yuqiang Sun", "Yihao Huang", "Chong Wang", "Yang Liu"], "title": "Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking", "comment": "Accepted to FSE 2026", "summary": "Large language models (LLMs) have revolutionized software development through AI-assisted coding tools, enabling developers with limited programming expertise to create sophisticated applications. However, this accessibility extends to malicious actors who may exploit these powerful tools to generate harmful software. Existing jailbreaking research primarily focuses on general attack scenarios against LLMs, with limited exploration of malicious code generation as a jailbreak target. To address this gap, we propose SPELL, a comprehensive testing framework specifically designed to evaluate the weakness of security alignment in malicious code generation. Our framework employs a time-division selection strategy that systematically constructs jailbreaking prompts by intelligently combining sentences from a prior knowledge dataset, balancing exploration of novel attack patterns with exploitation of successful techniques. Extensive evaluation across three advanced code models (GPT-4.1, Claude-3.5, and Qwen2.5-Coder) demonstrates SPELL's effectiveness, achieving attack success rates of 83.75%, 19.38%, and 68.12% respectively across eight malicious code categories. The generated prompts successfully produce malicious code in real-world AI development tools such as Cursor, with outputs confirmed as malicious by state-of-the-art detection systems at rates exceeding 73%. These findings reveal significant security gaps in current LLM implementations and provide valuable insights for improving AI safety alignment in code generation applications.", "AI": {"tldr": "SPELL\u6846\u67b6\u4e13\u95e8\u6d4b\u8bd5LLM\u5728\u6076\u610f\u4ee3\u7801\u751f\u6210\u65b9\u9762\u7684\u5b89\u5168\u5bf9\u9f50\u6f0f\u6d1e\uff0c\u901a\u8fc7\u65f6\u95f4\u5206\u914d\u9009\u62e9\u7b56\u7565\u6784\u5efa\u8d8a\u72f1\u63d0\u793a\uff0c\u5728GPT-4.1\u3001Claude-3.5\u548cQwen2.5-Coder\u4e0a\u5206\u522b\u8fbe\u523083.75%\u300119.38%\u548c68.12%\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "LLM\u8f85\u52a9\u7f16\u7a0b\u5de5\u5177\u4f7f\u975e\u4e13\u4e1a\u5f00\u53d1\u8005\u4e5f\u80fd\u521b\u5efa\u590d\u6742\u5e94\u7528\uff0c\u4f46\u8fd9\u4e5f\u53ef\u80fd\u88ab\u6076\u610f\u884c\u4e3a\u8005\u5229\u7528\u6765\u751f\u6210\u6709\u5bb3\u8f6f\u4ef6\u3002\u73b0\u6709\u8d8a\u72f1\u7814\u7a76\u4e3b\u8981\u9488\u5bf9\u901a\u7528\u653b\u51fb\u573a\u666f\uff0c\u5bf9\u6076\u610f\u4ee3\u7801\u751f\u6210\u4f5c\u4e3a\u8d8a\u72f1\u76ee\u6807\u7684\u63a2\u7d22\u6709\u9650\u3002", "method": "\u63d0\u51faSPELL\u6d4b\u8bd5\u6846\u67b6\uff0c\u91c7\u7528\u65f6\u95f4\u5206\u914d\u9009\u62e9\u7b56\u7565\uff0c\u901a\u8fc7\u667a\u80fd\u7ec4\u5408\u5148\u9a8c\u77e5\u8bc6\u6570\u636e\u96c6\u4e2d\u7684\u53e5\u5b50\u6765\u7cfb\u7edf\u6784\u5efa\u8d8a\u72f1\u63d0\u793a\uff0c\u5e73\u8861\u65b0\u9896\u653b\u51fb\u6a21\u5f0f\u7684\u63a2\u7d22\u4e0e\u6210\u529f\u6280\u672f\u7684\u5229\u7528\u3002", "result": "\u5728\u4e09\u4e2a\u5148\u8fdb\u4ee3\u7801\u6a21\u578b\u4e0a\u8bc4\u4f30\uff1aGPT-4.1\u653b\u51fb\u6210\u529f\u738783.75%\uff0cClaude-3.5\u4e3a19.38%\uff0cQwen2.5-Coder\u4e3a68.12%\u3002\u751f\u6210\u7684\u63d0\u793a\u5728Cursor\u7b49\u5b9e\u9645AI\u5f00\u53d1\u5de5\u5177\u4e2d\u6210\u529f\u4ea7\u751f\u6076\u610f\u4ee3\u7801\uff0c\u8d85\u8fc773%\u7684\u8f93\u51fa\u88ab\u5148\u8fdb\u68c0\u6d4b\u7cfb\u7edf\u786e\u8ba4\u4e3a\u6076\u610f\u3002", "conclusion": "\u5f53\u524dLLM\u5b9e\u73b0\u5b58\u5728\u91cd\u5927\u5b89\u5168\u6f0f\u6d1e\uff0cSPELL\u6846\u67b6\u4e3a\u6539\u8fdb\u4ee3\u7801\u751f\u6210\u5e94\u7528\u4e2d\u7684AI\u5b89\u5168\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2512.20661", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20661", "abs": "https://arxiv.org/abs/2512.20661", "authors": ["Yawei Liu"], "title": "From Fake Focus to Real Precision: Confusion-Driven Adversarial Attention Learning in Transformers", "comment": "10 pages, 5 figures, submited to WWW 2026", "summary": "Transformer-based models have been widely adopted for sentiment analysis tasks due to their exceptional ability to capture contextual information. However, these methods often exhibit suboptimal accuracy in certain scenarios. By analyzing their attention distributions, we observe that existing models tend to allocate attention primarily to common words, overlooking less popular yet highly task-relevant terms, which significantly impairs overall performance. To address this issue, we propose an Adversarial Feedback for Attention(AFA) training mechanism that enables the model to automatically redistribute attention weights to appropriate focal points without requiring manual annotations. This mechanism incorporates a dynamic masking strategy that attempts to mask various words to deceive a discriminator, while the discriminator strives to detect significant differences induced by these masks. Additionally, leveraging the sensitivity of Transformer models to token-level perturbations, we employ a policy gradient approach to optimize attention distributions, which facilitates efficient and rapid convergence. Experiments on three public datasets demonstrate that our method achieves state-of-the-art results. Furthermore, applying this training mechanism to enhance attention in large language models yields a further performance improvement of 12.6%", "AI": {"tldr": "\u63d0\u51faAFA\u5bf9\u6297\u6027\u53cd\u9988\u6ce8\u610f\u529b\u8bad\u7ec3\u673a\u5236\uff0c\u901a\u8fc7\u52a8\u6001\u63a9\u7801\u7b56\u7565\u548c\u653f\u7b56\u68af\u5ea6\u4f18\u5316\uff0c\u4f7fTransformer\u6a21\u578b\u80fd\u81ea\u52a8\u5c06\u6ce8\u610f\u529b\u91cd\u65b0\u5206\u914d\u5230\u4efb\u52a1\u76f8\u5173\u4f46\u8f83\u5c11\u51fa\u73b0\u7684\u8bcd\u6c47\u4e0a\uff0c\u63d0\u5347\u60c5\u611f\u5206\u6790\u6027\u80fd\u3002", "motivation": "\u73b0\u6709Transformer\u6a21\u578b\u5728\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e2d\uff0c\u6ce8\u610f\u529b\u4e3b\u8981\u5206\u914d\u7ed9\u5e38\u89c1\u8bcd\u6c47\uff0c\u800c\u5ffd\u7565\u4e86\u4e0d\u5e38\u89c1\u4f46\u9ad8\u5ea6\u4efb\u52a1\u76f8\u5173\u7684\u8bcd\u6c47\uff0c\u8fd9\u5bfc\u81f4\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u5bf9\u6297\u6027\u53cd\u9988\u6ce8\u610f\u529b(AFA)\u8bad\u7ec3\u673a\u5236\uff1a1) \u52a8\u6001\u63a9\u7801\u7b56\u7565\uff0c\u5c1d\u8bd5\u63a9\u7801\u4e0d\u540c\u8bcd\u6c47\u6765\u6b3a\u9a97\u5224\u522b\u5668\uff1b2) \u5224\u522b\u5668\u68c0\u6d4b\u63a9\u7801\u5f15\u8d77\u7684\u663e\u8457\u5dee\u5f02\uff1b3) \u5229\u7528Transformer\u5bf9token\u7ea7\u6270\u52a8\u7684\u654f\u611f\u6027\uff0c\u91c7\u7528\u653f\u7b56\u68af\u5ea6\u65b9\u6cd5\u4f18\u5316\u6ce8\u610f\u529b\u5206\u5e03\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002\u5c06\u8be5\u8bad\u7ec3\u673a\u5236\u5e94\u7528\u4e8e\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6ce8\u610f\u529b\uff0c\u83b7\u5f97\u4e8612.6%\u7684\u8fdb\u4e00\u6b65\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "AFA\u673a\u5236\u80fd\u6709\u6548\u89e3\u51b3Transformer\u6a21\u578b\u6ce8\u610f\u529b\u5206\u914d\u504f\u5dee\u95ee\u9898\uff0c\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u81ea\u52a8\u4f18\u5316\u6ce8\u610f\u529b\u5206\u5e03\uff0c\u663e\u8457\u63d0\u5347\u60c5\u611f\u5206\u6790\u6027\u80fd\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u3002"}}
{"id": "2512.20662", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20662", "abs": "https://arxiv.org/abs/2512.20662", "authors": ["Yiqing Ma", "Jung-Hua Liu"], "title": "Quantifying Laziness, Decoding Suboptimality, and Context Degradation in Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) often exhibit behavioral artifacts such as laziness (premature truncation of responses or partial compliance with multi-part requests), decoding suboptimality (failure to select higher-quality sequences due to myopic decoding), and context degradation (forgetting or ignoring core instructions over long conversations). We conducted three controlled experiments (A, B, and C) to quantify these phenomena across several advanced LLMs (OpenAI GPT-4 variant, DeepSeek). Our results indicate widespread laziness in satisfying complex multi-part instructions: models frequently omitted required sections or failed to meet length requirements despite explicit prompting. However, we found limited evidence of decoding suboptimality in a simple reasoning task (the models' greedy answers appeared to align with their highest-confidence solution), and we observed surprising robustness against context degradation in a 200-turn chaotic conversation test - the models maintained key facts and instructions far better than expected. These findings suggest that while compliance with detailed instructions remains an open challenge, modern LLMs may internally mitigate some hypothesized failure modes (such as context forgetting) in straightforward retrieval scenarios. We discuss implications for reliability, relate our findings to prior work on instruction-following and long-context processing, and recommend strategies (such as self-refinement and dynamic prompting) to reduce laziness and bolster multi-instruction compliance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u4e09\u4e2a\u5b9e\u9a8c\u91cf\u5316\u4e86LLMs\u7684\u884c\u4e3a\u7f3a\u9677\uff1a\u61d2\u60f0\u6027\uff08\u590d\u6742\u6307\u4ee4\u6267\u884c\u4e0d\u5b8c\u6574\uff09\u3001\u89e3\u7801\u6b21\u4f18\u6027\uff08\u77ed\u89c6\u89e3\u7801\uff09\u548c\u4e0a\u4e0b\u6587\u9000\u5316\uff08\u957f\u5bf9\u8bdd\u4e2d\u9057\u5fd8\u6307\u4ee4\uff09\u3002\u53d1\u73b0LLMs\u666e\u904d\u5b58\u5728\u61d2\u60f0\u95ee\u9898\uff0c\u4f46\u5728\u7b80\u5355\u63a8\u7406\u4efb\u52a1\u4e2d\u89e3\u7801\u6b21\u4f18\u6027\u6709\u9650\uff0c\u4e14\u5728\u957f\u5bf9\u8bdd\u4e2d\u8868\u73b0\u51fa\u610f\u5916\u7684\u4e0a\u4e0b\u6587\u4fdd\u6301\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ecf\u5e38\u8868\u73b0\u51fa\u884c\u4e3a\u7f3a\u9677\uff0c\u5982\u61d2\u60f0\uff08\u63d0\u524d\u622a\u65ad\u54cd\u5e94\u6216\u4e0d\u5b8c\u5168\u9075\u5b88\u591a\u90e8\u5206\u8bf7\u6c42\uff09\u3001\u89e3\u7801\u6b21\u4f18\u6027\uff08\u7531\u4e8e\u77ed\u89c6\u89e3\u7801\u800c\u672a\u80fd\u9009\u62e9\u66f4\u9ad8\u8d28\u91cf\u7684\u5e8f\u5217\uff09\u548c\u4e0a\u4e0b\u6587\u9000\u5316\uff08\u5728\u957f\u5bf9\u8bdd\u4e2d\u9057\u5fd8\u6216\u5ffd\u7565\u6838\u5fc3\u6307\u4ee4\uff09\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u53d7\u63a7\u5b9e\u9a8c\u91cf\u5316\u8fd9\u4e9b\u73b0\u8c61\uff0c\u4e86\u89e3\u73b0\u4ee3LLMs\u7684\u5b9e\u9645\u8868\u73b0\u3002", "method": "\u7814\u7a76\u8bbe\u8ba1\u4e86\u4e09\u4e2a\u53d7\u63a7\u5b9e\u9a8c\uff08A\u3001B\u3001C\uff09\uff0c\u5728\u591a\u4e2a\u5148\u8fdbLLMs\uff08OpenAI GPT-4\u53d8\u4f53\u3001DeepSeek\uff09\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002\u5b9e\u9a8cA\u91cf\u5316\u61d2\u60f0\u6027\uff0c\u8bc4\u4f30\u6a21\u578b\u5bf9\u590d\u6742\u591a\u90e8\u5206\u6307\u4ee4\u7684\u9075\u5b88\u7a0b\u5ea6\uff1b\u5b9e\u9a8cB\u6d4b\u8bd5\u89e3\u7801\u6b21\u4f18\u6027\uff0c\u4f7f\u7528\u7b80\u5355\u63a8\u7406\u4efb\u52a1\u68c0\u67e5\u6a21\u578b\u662f\u5426\u56e0\u77ed\u89c6\u89e3\u7801\u800c\u9009\u62e9\u6b21\u4f18\u7b54\u6848\uff1b\u5b9e\u9a8cC\u8bc4\u4f30\u4e0a\u4e0b\u6587\u9000\u5316\uff0c\u901a\u8fc7200\u8f6e\u6df7\u4e71\u5bf9\u8bdd\u6d4b\u8bd5\u6a21\u578b\u4fdd\u6301\u5173\u952e\u4e8b\u5b9e\u548c\u6307\u4ee4\u7684\u80fd\u529b\u3002", "result": "1. \u61d2\u60f0\u6027\u666e\u904d\u5b58\u5728\uff1a\u6a21\u578b\u7ecf\u5e38\u7701\u7565\u5fc5\u9700\u90e8\u5206\u6216\u672a\u80fd\u6ee1\u8db3\u957f\u5ea6\u8981\u6c42\uff1b2. \u89e3\u7801\u6b21\u4f18\u6027\u6709\u9650\uff1a\u5728\u7b80\u5355\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u7684\u8d2a\u5a6a\u7b54\u6848\u4f3c\u4e4e\u4e0e\u5176\u6700\u9ad8\u7f6e\u4fe1\u5ea6\u89e3\u51b3\u65b9\u6848\u4e00\u81f4\uff1b3. \u4e0a\u4e0b\u6587\u9000\u5316\u610f\u5916\u7a33\u5065\uff1a\u5728200\u8f6e\u6df7\u4e71\u5bf9\u8bdd\u6d4b\u8bd5\u4e2d\uff0c\u6a21\u578b\u4fdd\u6301\u5173\u952e\u4e8b\u5b9e\u548c\u6307\u4ee4\u7684\u80fd\u529b\u8fdc\u8d85\u9884\u671f\u3002", "conclusion": "\u867d\u7136\u9075\u5b88\u8be6\u7ec6\u6307\u4ee4\u4ecd\u662f\u5f00\u653e\u6311\u6218\uff0c\u4f46\u73b0\u4ee3LLMs\u53ef\u80fd\u5728\u5185\u90e8\u7f13\u89e3\u4e86\u4e00\u4e9b\u5047\u8bbe\u7684\u5931\u8d25\u6a21\u5f0f\uff08\u5982\u4e0a\u4e0b\u6587\u9057\u5fd8\uff09\u3002\u7814\u7a76\u8ba8\u8bba\u4e86\u53ef\u9760\u6027\u5f71\u54cd\uff0c\u5c06\u53d1\u73b0\u4e0e\u5148\u524d\u5173\u4e8e\u6307\u4ee4\u9075\u5faa\u548c\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u7684\u5de5\u4f5c\u8054\u7cfb\u8d77\u6765\uff0c\u5e76\u63a8\u8350\u4e86\u51cf\u5c11\u61d2\u60f0\u6027\u548c\u589e\u5f3a\u591a\u6307\u4ee4\u9075\u5b88\u7684\u7b56\u7565\uff08\u5982\u81ea\u6211\u5b8c\u5584\u548c\u52a8\u6001\u63d0\u793a\uff09\u3002"}}
{"id": "2512.20671", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20671", "abs": "https://arxiv.org/abs/2512.20671", "authors": ["Daan Di Scala", "Sophie Lathouwers", "Michael van Bekkum"], "title": "Bridging the AI Trustworthiness Gap between Functions and Norms", "comment": "Published as Position Paper during the TRUST-AI workshop at the ECAI2025 Conference", "summary": "Trustworthy Artificial Intelligence (TAI) is gaining traction due to regulations and functional benefits. While Functional TAI (FTAI) focuses on how to implement trustworthy systems, Normative TAI (NTAI) focuses on regulations that need to be enforced. However, gaps between FTAI and NTAI remain, making it difficult to assess trustworthiness of AI systems. We argue that a bridge is needed, specifically by introducing a conceptual language which can match FTAI and NTAI. Such a semantic language can assist developers as a framework to assess AI systems in terms of trustworthiness. It can also help stakeholders translate norms and regulations into concrete implementation steps for their systems. In this position paper, we describe the current state-of-the-art and identify the gap between FTAI and NTAI. We will discuss starting points for developing a semantic language and the envisioned effects of it. Finally, we provide key considerations and discuss future actions towards assessment of TAI.", "AI": {"tldr": "\u8be5\u7acb\u573a\u8bba\u6587\u6307\u51fa\u53ef\u4fe1\u4eba\u5de5\u667a\u80fd\uff08TAI\uff09\u5b58\u5728\u529f\u80fd\u6027TAI\uff08FTAI\uff09\u548c\u89c4\u8303\u6027TAI\uff08NTAI\uff09\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u63d0\u51fa\u9700\u8981\u5efa\u7acb\u8bed\u4e49\u8bed\u8a00\u4f5c\u4e3a\u6865\u6881\u6765\u8bc4\u4f30AI\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u968f\u7740\u6cd5\u89c4\u548c\u529f\u80fd\u9700\u6c42\u7684\u53d1\u5c55\uff0c\u53ef\u4fe1\u4eba\u5de5\u667a\u80fd\uff08TAI\uff09\u65e5\u76ca\u91cd\u8981\u3002\u7136\u800c\uff0c\u529f\u80fd\u6027TAI\uff08\u5173\u6ce8\u5982\u4f55\u5b9e\u73b0\u53ef\u4fe1\u7cfb\u7edf\uff09\u548c\u89c4\u8303\u6027TAI\uff08\u5173\u6ce8\u9700\u8981\u6267\u884c\u7684\u6cd5\u89c4\uff09\u4e4b\u95f4\u5b58\u5728\u8131\u8282\uff0c\u8fd9\u4f7f\u5f97\u8bc4\u4f30AI\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u53d8\u5f97\u56f0\u96be\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u5f15\u5165\u6982\u5ff5\u6027\u8bed\u4e49\u8bed\u8a00\u4f5c\u4e3a\u6865\u6881\uff0c\u5339\u914dFTAI\u548cNTAI\u3002\u8fd9\u79cd\u8bed\u4e49\u8bed\u8a00\u53ef\u4ee5\u4f5c\u4e3a\u6846\u67b6\u5e2e\u52a9\u5f00\u53d1\u8005\u8bc4\u4f30AI\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\uff0c\u540c\u65f6\u5e2e\u52a9\u5229\u76ca\u76f8\u5173\u8005\u5c06\u89c4\u8303\u548c\u6cd5\u89c4\u8f6c\u5316\u4e3a\u5177\u4f53\u7684\u5b9e\u65bd\u6b65\u9aa4\u3002", "result": "\u8bba\u6587\u63cf\u8ff0\u4e86\u5f53\u524d\u6700\u65b0\u8fdb\u5c55\uff0c\u8bc6\u522b\u4e86FTAI\u548cNTAI\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u8ba8\u8bba\u4e86\u5f00\u53d1\u8bed\u4e49\u8bed\u8a00\u7684\u8d77\u70b9\u53ca\u5176\u9884\u671f\u6548\u679c\uff0c\u5e76\u63d0\u4f9b\u4e86\u5173\u952e\u8003\u8651\u56e0\u7d20\u3002", "conclusion": "\u9700\u8981\u5efa\u7acb\u8bed\u4e49\u8bed\u8a00\u4f5c\u4e3a\u6865\u6881\u6765\u8fde\u63a5\u529f\u80fd\u6027TAI\u548c\u89c4\u8303\u6027TAI\uff0c\u4ee5\u4fc3\u8fdb\u53ef\u4fe1\u4eba\u5de5\u667a\u80fd\u7684\u8bc4\u4f30\u3002\u8bba\u6587\u63d0\u4f9b\u4e86\u672a\u6765\u884c\u52a8\u7684\u5173\u952e\u8003\u8651\u56e0\u7d20\u548c\u65b9\u5411\u3002"}}
{"id": "2512.21110", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.21110", "abs": "https://arxiv.org/abs/2512.21110", "authors": ["Ahmed M. Hussain", "Salahuddin Salahuddin", "Panos Papadimitratos"], "title": "Beyond Context: Large Language Models Failure to Grasp Users Intent", "comment": "22 pages and 23 figures", "summary": "Current Large Language Models (LLMs) safety approaches focus on explicitly harmful content while overlooking a critical vulnerability: the inability to understand context and recognize user intent. This creates exploitable vulnerabilities that malicious users can systematically leverage to circumvent safety mechanisms. We empirically evaluate multiple state-of-the-art LLMs, including ChatGPT, Claude, Gemini, and DeepSeek. Our analysis demonstrates the circumvention of reliable safety mechanisms through emotional framing, progressive revelation, and academic justification techniques. Notably, reasoning-enabled configurations amplified rather than mitigated the effectiveness of exploitation, increasing factual precision while failing to interrogate the underlying intent. The exception was Claude Opus 4.1, which prioritized intent detection over information provision in some use cases. This pattern reveals that current architectural designs create systematic vulnerabilities. These limitations require paradigmatic shifts toward contextual understanding and intent recognition as core safety capabilities rather than post-hoc protective mechanisms.", "AI": {"tldr": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u673a\u5236\u5b58\u5728\u91cd\u5927\u6f0f\u6d1e\uff1a\u65e0\u6cd5\u7406\u89e3\u4e0a\u4e0b\u6587\u548c\u8bc6\u522b\u7528\u6237\u610f\u56fe\uff0c\u5bfc\u81f4\u6076\u610f\u7528\u6237\u53ef\u901a\u8fc7\u60c5\u611f\u6846\u67b6\u3001\u6e10\u8fdb\u63ed\u793a\u548c\u5b66\u672f\u8bba\u8bc1\u7b49\u7cfb\u7edf\u5316\u65b9\u6cd5\u7ed5\u8fc7\u5b89\u5168\u9632\u62a4\u3002", "motivation": "\u73b0\u6709LLM\u5b89\u5168\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u663e\u6027\u6709\u5bb3\u5185\u5bb9\uff0c\u4f46\u5ffd\u89c6\u4e86\u5173\u952e\u6f0f\u6d1e\uff1a\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u7406\u89e3\u548c\u7528\u6237\u610f\u56fe\u8bc6\u522b\u80fd\u529b\u3002\u8fd9\u4e3a\u6076\u610f\u7528\u6237\u63d0\u4f9b\u4e86\u53ef\u7cfb\u7edf\u5229\u7528\u7684\u6f0f\u6d1e\u6765\u7ed5\u8fc7\u5b89\u5168\u673a\u5236\u3002", "method": "\u5bf9\u591a\u4e2a\u6700\u5148\u8fdb\u7684LLM\uff08\u5305\u62ecChatGPT\u3001Claude\u3001Gemini\u548cDeepSeek\uff09\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u5206\u6790\u901a\u8fc7\u60c5\u611f\u6846\u67b6\u3001\u6e10\u8fdb\u63ed\u793a\u548c\u5b66\u672f\u8bba\u8bc1\u7b49\u6280\u672f\u7ed5\u8fc7\u5b89\u5168\u673a\u5236\u7684\u6548\u679c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u589e\u5f3a\u914d\u7f6e\u53cd\u800c\u653e\u5927\u4e86\u5229\u7528\u6548\u679c\uff0c\u63d0\u9ad8\u4e86\u4e8b\u5b9e\u7cbe\u786e\u6027\u4f46\u672a\u80fd\u8d28\u7591\u5e95\u5c42\u610f\u56fe\u3002\u552f\u4e00\u4f8b\u5916\u662fClaude Opus 4.1\uff0c\u5728\u67d0\u4e9b\u7528\u4f8b\u4e2d\u4f18\u5148\u8003\u8651\u610f\u56fe\u68c0\u6d4b\u800c\u975e\u4fe1\u606f\u63d0\u4f9b\u3002", "conclusion": "\u5f53\u524d\u67b6\u6784\u8bbe\u8ba1\u5b58\u5728\u7cfb\u7edf\u6027\u6f0f\u6d1e\uff0c\u9700\u8981\u8303\u5f0f\u8f6c\u53d8\uff1a\u5c06\u4e0a\u4e0b\u6587\u7406\u89e3\u548c\u610f\u56fe\u8bc6\u522b\u4f5c\u4e3a\u6838\u5fc3\u5b89\u5168\u80fd\u529b\uff0c\u800c\u975e\u4e8b\u540e\u4fdd\u62a4\u673a\u5236\u3002"}}
{"id": "2512.20714", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.20714", "abs": "https://arxiv.org/abs/2512.20714", "authors": ["Iman Reihanian", "Yunfei Hou", "Qingquan Sun"], "title": "From Pilots to Practices: A Scoping Review of GenAI-Enabled Personalization in Computer Science Education", "comment": "Review article. 23 pages, 7 figures, 8 tables. Published in AI (MDPI), 2026", "summary": "Generative AI enables personalized computer science education at scale, yet questions remain about whether such personalization supports or undermines learning. This scoping review synthesizes 32 studies (2023-2025) purposively sampled from 259 records to map personalization mechanisms and effectiveness signals in higher-education computer science contexts. We identify five application domains: intelligent tutoring, personalized materials, formative feedback, AI-augmented assessment, and code review, and analyze how design choices shape learning outcomes. Designs incorporating explanation-first guidance, solution withholding, graduated hint ladders, and artifact grounding (student code, tests, and rubrics) consistently show more positive learning processes than unconstrained chat interfaces. Successful implementations share four patterns: context-aware tutoring anchored in student artifacts, multi-level hint structures requiring reflection, composition with traditional CS infrastructure (autograders and rubrics), and human-in-the-loop quality assurance. We propose an exploration-first adoption framework emphasizing piloting, instrumentation, learning-preserving defaults, and evidence-based scaling. Recurrent risks include academic integrity, privacy, bias and equity, and over-reliance, and we pair these with operational mitigation. The evidence supports generative AI as a mechanism for precision scaffolding when embedded in audit-ready workflows that preserve productive struggle while scaling personalized support.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u5206\u6790\u4e862023-2025\u5e74\u95f432\u9879\u7814\u7a76\uff0c\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5728\u9ad8\u7b49\u6559\u80b2\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u4e2d\u7684\u4e2a\u6027\u5316\u5e94\u7528\u6548\u679c\uff0c\u8bc6\u522b\u4e86\u4e94\u79cd\u5e94\u7528\u9886\u57df\u548c\u6210\u529f\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u63d0\u51fa\u4e86\u63a2\u7d22\u4f18\u5148\u7684\u91c7\u7528\u6846\u67b6\u3002", "motivation": "\u751f\u6210\u5f0fAI\u80fd\u591f\u5927\u89c4\u6a21\u5b9e\u73b0\u4e2a\u6027\u5316\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\uff0c\u4f46\u9700\u8981\u7814\u7a76\u8fd9\u79cd\u4e2a\u6027\u5316\u662f\u5426\u771f\u6b63\u652f\u6301\u5b66\u4e60\uff0c\u4ee5\u53ca\u5982\u4f55\u8bbe\u8ba1\u6709\u6548\u7684\u4e2a\u6027\u5316\u673a\u5236\u6765\u4f18\u5316\u5b66\u4e60\u6548\u679c\u3002", "method": "\u91c7\u7528\u8303\u56f4\u7efc\u8ff0\u65b9\u6cd5\uff0c\u4ece259\u6761\u8bb0\u5f55\u4e2d\u6709\u76ee\u7684\u5730\u62bd\u683732\u9879\u7814\u7a76\uff082023-2025\u5e74\uff09\uff0c\u5206\u6790\u9ad8\u7b49\u6559\u80b2\u8ba1\u7b97\u673a\u79d1\u5b66\u73af\u5883\u4e2d\u7684\u4e2a\u6027\u5316\u673a\u5236\u548c\u6709\u6548\u6027\u4fe1\u53f7\u3002", "result": "\u8bc6\u522b\u4e86\u4e94\u4e2a\u5e94\u7528\u9886\u57df\uff1a\u667a\u80fd\u8f85\u5bfc\u3001\u4e2a\u6027\u5316\u6750\u6599\u3001\u5f62\u6210\u6027\u53cd\u9988\u3001AI\u589e\u5f3a\u8bc4\u4f30\u548c\u4ee3\u7801\u5ba1\u67e5\u3002\u53d1\u73b0\u91c7\u7528\u89e3\u91ca\u4f18\u5148\u6307\u5bfc\u3001\u89e3\u51b3\u65b9\u6848\u4fdd\u7559\u3001\u5206\u7ea7\u63d0\u793a\u9636\u68af\u548c\u57fa\u4e8e\u5b66\u751f\u5de5\u4ef6\u7684\u8bbe\u8ba1\u6bd4\u65e0\u7ea6\u675f\u804a\u5929\u754c\u9762\u6548\u679c\u66f4\u597d\u3002\u6210\u529f\u5b9e\u65bd\u5171\u4eab\u56db\u79cd\u6a21\u5f0f\uff1a\u57fa\u4e8e\u5b66\u751f\u5de5\u4ef6\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u8f85\u5bfc\u3001\u9700\u8981\u53cd\u601d\u7684\u591a\u7ea7\u63d0\u793a\u7ed3\u6784\u3001\u4e0e\u4f20\u7edfCS\u57fa\u7840\u8bbe\u65bd\uff08\u81ea\u52a8\u8bc4\u5206\u5668\u548c\u8bc4\u5206\u6807\u51c6\uff09\u7684\u7ed3\u5408\u3001\u4ee5\u53ca\u4eba\u5728\u5faa\u73af\u7684\u8d28\u91cf\u4fdd\u8bc1\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u53ef\u4ee5\u4f5c\u4e3a\u7cbe\u786e\u652f\u67b6\u673a\u5236\uff0c\u4f46\u9700\u8981\u5d4c\u5165\u53ef\u5ba1\u8ba1\u7684\u5de5\u4f5c\u6d41\u7a0b\u4e2d\uff0c\u4fdd\u6301\u751f\u4ea7\u6027\u6323\u624e\u7684\u540c\u65f6\u6269\u5c55\u4e2a\u6027\u5316\u652f\u6301\u3002\u63d0\u51fa\u4e86\u63a2\u7d22\u4f18\u5148\u7684\u91c7\u7528\u6846\u67b6\uff0c\u5f3a\u8c03\u8bd5\u70b9\u3001\u5de5\u5177\u5316\u3001\u5b66\u4e60\u4fdd\u62a4\u9ed8\u8ba4\u8bbe\u7f6e\u548c\u57fa\u4e8e\u8bc1\u636e\u7684\u6269\u5c55\uff0c\u5e76\u8bc6\u522b\u4e86\u5b66\u672f\u8bda\u4fe1\u3001\u9690\u79c1\u3001\u504f\u89c1\u548c\u8fc7\u5ea6\u4f9d\u8d56\u7b49\u98ce\u9669\u53ca\u7f13\u89e3\u63aa\u65bd\u3002"}}
{"id": "2512.20723", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20723", "abs": "https://arxiv.org/abs/2512.20723", "authors": ["Prajwal Ghimire", "Keyoumars Ashkan"], "title": "From artificial to organic: Rethinking the roots of intelligence for digital health", "comment": null, "summary": "The term artificial implies an inherent dichotomy from the natural or organic. However, AI, as we know it, is a product of organic ingenuity: designed, implemented, and iteratively improved by human cognition. The very principles that underpin AI systems, from neural networks to decision-making algorithms, are inspired by the organic intelligence embedded in human neurobiology and evolutionary processes. The path from organic to artificial intelligence in digital health is neither mystical nor merely a matter of parameter count, it is fundamentally about organization and adaption. Thus, the boundaries between artificial and organic are far less distinct than the nomenclature suggests.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u4e0e\u6709\u673a\u667a\u80fd\u4e4b\u95f4\u7684\u754c\u9650\u6a21\u7cca\u6027\uff0c\u6307\u51faAI\u672c\u8d28\u4e0a\u662f\u4eba\u7c7b\u6709\u673a\u667a\u6167\u7684\u4ea7\u7269\uff0c\u5176\u539f\u7406\u6e90\u4e8e\u4eba\u7c7b\u795e\u7ecf\u751f\u7269\u5b66\u548c\u8fdb\u5316\u8fc7\u7a0b\u3002", "motivation": "\u4f5c\u8005\u65e8\u5728\u6311\u6218\"\u4eba\u5de5\"\u4e0e\"\u6709\u673a\"\u4e4b\u95f4\u7684\u4f20\u7edf\u4e8c\u5206\u6cd5\uff0c\u5f3a\u8c03\u4eba\u5de5\u667a\u80fd\u5b9e\u9645\u4e0a\u662f\u4eba\u7c7b\u6709\u673a\u667a\u6167\u7684\u5ef6\u4f38\uff0c\u800c\u975e\u5b8c\u5168\u72ec\u7acb\u4e8e\u81ea\u7136\u7684\u5b58\u5728\u3002", "method": "\u901a\u8fc7\u54f2\u5b66\u548c\u6982\u5ff5\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u4ece\u795e\u7ecf\u751f\u7269\u5b66\u3001\u8fdb\u5316\u8fc7\u7a0b\u548c\u8ba4\u77e5\u79d1\u5b66\u7684\u89d2\u5ea6\u63a2\u8ba8\u4eba\u5de5\u667a\u80fd\u7684\u672c\u8d28\uff0c\u5f3a\u8c03\u5176\u4e0e\u6709\u673a\u667a\u80fd\u7684\u5185\u5728\u8054\u7cfb\u3002", "result": "\u63ed\u793a\u4e86\u4eba\u5de5\u667a\u80fd\u4e0e\u6709\u673a\u667a\u80fd\u4e4b\u95f4\u7684\u754c\u9650\u8fdc\u6bd4\u672f\u8bed\u6240\u6697\u793a\u7684\u8981\u6a21\u7cca\uff0cAI\u7684\u53d1\u5c55\u672c\u8d28\u4e0a\u662f\u6709\u673a\u667a\u6167\u7684\u7ec4\u7ec7\u548c\u9002\u5e94\u8fc7\u7a0b\u7684\u5ef6\u4f38\u3002", "conclusion": "\u5728\u6570\u5b57\u5065\u5eb7\u9886\u57df\uff0c\u4ece\u6709\u673a\u667a\u80fd\u5230\u4eba\u5de5\u667a\u80fd\u7684\u8f6c\u53d8\u5e76\u975e\u795e\u79d8\u8fc7\u7a0b\uff0c\u800c\u662f\u5173\u4e8e\u7ec4\u7ec7\u548c\u9002\u5e94\u7684\u6839\u672c\u6027\u95ee\u9898\uff0c\u4eba\u5de5\u4e0e\u6709\u673a\u4e4b\u95f4\u7684\u533a\u5206\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u3002"}}
{"id": "2512.20745", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.20745", "abs": "https://arxiv.org/abs/2512.20745", "authors": ["Haipeng Luo", "Huawen Feng", "Qingfeng Sun", "Can Xu", "Kai Zheng", "Yufei Wang", "Tao Yang", "Han Hu", "Yansong Tang", "Di Wang"], "title": "AgentMath: Empowering Mathematical Reasoning for Large Language Models via Tool-Augmented Agent", "comment": "LLM, Mathematical Reasoning", "summary": "Large Reasoning Models (LRMs) like o3 and DeepSeek-R1 have achieved remarkable progress in natural language reasoning with long chain-of-thought. However, they remain computationally inefficient and struggle with accuracy when solving problems requiring complex mathematical operations. In this work, we present AgentMath, an agent framework that seamlessly integrates language models' reasoning capabilities with code interpreters' computational precision to efficiently tackle complex mathematical problems. Our approach introduces three key innovations: (1) An automated method that converts natural language chain-of-thought into structured tool-augmented trajectories, generating high-quality supervised fine-tuning (SFT) data to alleviate data scarcity; (2) A novel agentic reinforcement learning (RL) paradigm that dynamically interleaves natural language generation with real-time code execution. This enables models to autonomously learn optimal tool-use strategies through multi-round interactive feedback, while fostering emergent capabilities in code refinement and error correction; (3) An efficient training system incorporating innovative techniques, including request-level asynchronous rollout scheduling, agentic partial rollout, and prefix-aware weighted load balancing, achieving 4-5x speedup and making efficient RL training feasible on ultra-long sequences with scenarios with massive tool calls.Extensive evaluations show that AgentMath achieves state-of-the-art performance on challenging mathematical competition benchmarks including AIME24, AIME25, and HMMT25. Specifically, AgentMath-30B-A3B attains 90.6%, 86.4%, and 73.8% accuracy respectively, achieving advanced capabilities.These results validate the effectiveness of our approach and pave the way for building more sophisticated and scalable mathematical reasoning agents.", "AI": {"tldr": "AgentMath\u662f\u4e00\u4e2a\u5c06\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u4e0e\u4ee3\u7801\u89e3\u91ca\u5668\u8ba1\u7b97\u7cbe\u5ea6\u7ed3\u5408\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u751f\u6210\u76d1\u7763\u5fae\u8c03\u6570\u636e\u3001\u65b0\u578b\u5f3a\u5316\u5b66\u4e60\u8303\u5f0f\u4ee5\u53ca\u9ad8\u6548\u8bad\u7ec3\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u590d\u6742\u6570\u5b66\u95ee\u9898\u7684\u89e3\u51b3\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08\u5982o3\u548cDeepSeek-R1\uff09\u5728\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5728\u5904\u7406\u9700\u8981\u590d\u6742\u6570\u5b66\u8fd0\u7b97\u7684\u95ee\u9898\u65f6\u4ecd\u5b58\u5728\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u548c\u51c6\u786e\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7ed3\u5408\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u548c\u4ee3\u7801\u89e3\u91ca\u5668\u8ba1\u7b97\u7cbe\u5ea6\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1. \u81ea\u52a8\u5316\u65b9\u6cd5\uff1a\u5c06\u81ea\u7136\u8bed\u8a00\u601d\u7ef4\u94fe\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u5de5\u5177\u589e\u5f3a\u8f68\u8ff9\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u76d1\u7763\u5fae\u8c03\u6570\u636e\u4ee5\u7f13\u89e3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002\n2. \u65b0\u578b\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u8303\u5f0f\uff1a\u52a8\u6001\u4ea4\u9519\u81ea\u7136\u8bed\u8a00\u751f\u6210\u4e0e\u5b9e\u65f6\u4ee3\u7801\u6267\u884c\uff0c\u8ba9\u6a21\u578b\u901a\u8fc7\u591a\u8f6e\u4ea4\u4e92\u53cd\u9988\u81ea\u4e3b\u5b66\u4e60\u6700\u4f18\u5de5\u5177\u4f7f\u7528\u7b56\u7565\uff0c\u540c\u65f6\u57f9\u517b\u4ee3\u7801\u4f18\u5316\u548c\u9519\u8bef\u4fee\u6b63\u7684\u6d8c\u73b0\u80fd\u529b\u3002\n3. \u9ad8\u6548\u8bad\u7ec3\u7cfb\u7edf\uff1a\u91c7\u7528\u8bf7\u6c42\u7ea7\u5f02\u6b65rollout\u8c03\u5ea6\u3001\u667a\u80fd\u4f53\u90e8\u5206rollout\u548c\u524d\u7f00\u611f\u77e5\u52a0\u6743\u8d1f\u8f7d\u5e73\u8861\u7b49\u521b\u65b0\u6280\u672f\uff0c\u5b9e\u73b04-5\u500d\u52a0\u901f\uff0c\u4f7f\u5728\u8d85\u957f\u5e8f\u5217\u548c\u5927\u91cf\u5de5\u5177\u8c03\u7528\u573a\u666f\u4e0b\u7684\u9ad8\u6548\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6210\u4e3a\u53ef\u80fd\u3002", "result": "\u5728AIME24\u3001AIME25\u548cHMMT25\u7b49\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u7ade\u8d5b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgentMath\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u5177\u4f53\u6765\u8bf4\uff0cAgentMath-30B-A3B\u5206\u522b\u8fbe\u523090.6%\u300186.4%\u548c73.8%\u7684\u51c6\u786e\u7387\uff0c\u5c55\u73b0\u4e86\u5148\u8fdb\u7684\u80fd\u529b\u3002", "conclusion": "AgentMath\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\u9650\u5236\uff0c\u9a8c\u8bc1\u4e86\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e0e\u4ee3\u7801\u89e3\u91ca\u5668\u8ba1\u7b97\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e3a\u6784\u5efa\u66f4\u590d\u6742\u3001\u53ef\u6269\u5c55\u7684\u6570\u5b66\u63a8\u7406\u667a\u80fd\u4f53\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2512.20831", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.20831", "abs": "https://arxiv.org/abs/2512.20831", "authors": ["Rashmeet Kaur Nayyar", "Naman Shah", "Siddharth Srivastava"], "title": "Context-Sensitive Abstractions for Reinforcement Learning with Parameterized Actions", "comment": null, "summary": "Real-world sequential decision-making often involves parameterized action spaces that require both, decisions regarding discrete actions and decisions about continuous action parameters governing how an action is executed. Existing approaches exhibit severe limitations in this setting -- planning methods demand hand-crafted action models, and standard reinforcement learning (RL) algorithms are designed for either discrete or continuous actions but not both, and the few RL methods that handle parameterized actions typically rely on domain-specific engineering and fail to exploit the latent structure of these spaces. This paper extends the scope of RL algorithms to long-horizon, sparse-reward settings with parameterized actions by enabling agents to autonomously learn both state and action abstractions online. We introduce algorithms that progressively refine these abstractions during learning, increasing fine-grained detail in the critical regions of the state-action space where greater resolution improves performance. Across several continuous-state, parameterized-action domains, our abstraction-driven approach enables TD($\u03bb$) to achieve markedly higher sample efficiency than state-of-the-art baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u53c2\u6570\u5316\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u5b66\u4e60\u72b6\u6001\u548c\u52a8\u4f5c\u62bd\u8c61\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u7ebf\u6e10\u8fdb\u7ec6\u5316\u62bd\u8c61\u6765\u63d0\u9ad8\u7a00\u758f\u5956\u52b1\u3001\u957f\u89c6\u91ce\u4efb\u52a1\u7684\u6837\u672c\u6548\u7387\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u987a\u5e8f\u51b3\u7b56\u901a\u5e38\u6d89\u53ca\u53c2\u6570\u5316\u52a8\u4f5c\u7a7a\u95f4\uff0c\u9700\u8981\u540c\u65f6\u5904\u7406\u79bb\u6563\u52a8\u4f5c\u9009\u62e9\u548c\u8fde\u7eed\u52a8\u4f5c\u53c2\u6570\u51b3\u7b56\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e25\u91cd\u9650\u5236\uff1a\u89c4\u5212\u65b9\u6cd5\u9700\u8981\u624b\u5de5\u5236\u4f5c\u7684\u52a8\u4f5c\u6a21\u578b\uff0c\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u8981\u4e48\u9488\u5bf9\u79bb\u6563\u52a8\u4f5c\u8981\u4e48\u9488\u5bf9\u8fde\u7eed\u52a8\u4f5c\uff0c\u800c\u5c11\u6570\u5904\u7406\u53c2\u6570\u5316\u52a8\u4f5c\u7684RL\u65b9\u6cd5\u4f9d\u8d56\u9886\u57df\u7279\u5b9a\u5de5\u7a0b\u4e14\u672a\u80fd\u5229\u7528\u8fd9\u4e9b\u7a7a\u95f4\u7684\u6f5c\u5728\u7ed3\u6784\u3002", "method": "\u672c\u6587\u6269\u5c55\u4e86RL\u7b97\u6cd5\u5230\u957f\u89c6\u91ce\u3001\u7a00\u758f\u5956\u52b1\u7684\u53c2\u6570\u5316\u52a8\u4f5c\u8bbe\u7f6e\uff0c\u901a\u8fc7\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5728\u7ebf\u81ea\u4e3b\u5b66\u4e60\u72b6\u6001\u548c\u52a8\u4f5c\u62bd\u8c61\u3002\u5f15\u5165\u7684\u7b97\u6cd5\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u9010\u6b65\u7ec6\u5316\u8fd9\u4e9b\u62bd\u8c61\uff0c\u5728\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u7684\u5173\u952e\u533a\u57df\u589e\u52a0\u7ec6\u7c92\u5ea6\u7ec6\u8282\uff0c\u8fd9\u4e9b\u533a\u57df\u66f4\u9ad8\u7684\u5206\u8fa8\u7387\u80fd\u63d0\u9ad8\u6027\u80fd\u3002", "result": "\u5728\u591a\u4e2a\u8fde\u7eed\u72b6\u6001\u3001\u53c2\u6570\u5316\u52a8\u4f5c\u9886\u57df\u4e2d\uff0c\u8fd9\u79cd\u62bd\u8c61\u9a71\u52a8\u7684\u65b9\u6cd5\u4f7fTD(\u03bb)\u5b9e\u73b0\u4e86\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u663e\u8457\u66f4\u9ad8\u7684\u6837\u672c\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u5728\u7ebf\u5b66\u4e60\u72b6\u6001\u548c\u52a8\u4f5c\u62bd\u8c61\u5e76\u6e10\u8fdb\u7ec6\u5316\uff0c\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u53c2\u6570\u5316\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u7684\u957f\u89c6\u91ce\u3001\u7a00\u758f\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u6837\u672c\u6548\u7387\u3002"}}
{"id": "2512.20845", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.20845", "abs": "https://arxiv.org/abs/2512.20845", "authors": ["Onat Ozer", "Grace Wu", "Yuchen Wang", "Daniel Dosti", "Honghao Zhang", "Vivi De La Rue"], "title": "MAR:Multi-Agent Reflexion Improves Reasoning Abilities in LLMs", "comment": null, "summary": "LLMs have shown the capacity to improve their performance on reasoning tasks through reflecting on their mistakes, and acting with these reflections in mind. However, continual reflections of the same LLM onto itself exhibit degeneration of thought, where the LLM continues to repeat the same errors again and again even with the knowledge that its wrong. To address this problem, we instead introduce multi-agent with multi-persona debators as the method to generate reflections. Through out extensive experimentation, we've found that the leads to better diversity of in the reflections generated by the llm agent. We demonstrate an accuracy of 47% EM HotPot QA (question answering) and 82.7% on HumanEval (programming), both performances surpassing reflection with a single llm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u591a\u89d2\u8272\u8fa9\u8bba\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u591a\u6837\u5316\u7684\u53cd\u601d\u89c6\u89d2\u6765\u907f\u514d\u5355\u4e00LLM\u5728\u53cd\u601d\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u7684\u601d\u7ef4\u9000\u5316\u95ee\u9898\uff0c\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6bd4\u5355\u4e00LLM\u53cd\u601d\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLM\u5728\u901a\u8fc7\u53cd\u601d\u63d0\u5347\u63a8\u7406\u80fd\u529b\u65f6\u5b58\u5728\u601d\u7ef4\u9000\u5316\u95ee\u9898\uff0c\u5373LLM\u4f1a\u4e0d\u65ad\u91cd\u590d\u76f8\u540c\u7684\u9519\u8bef\uff0c\u5373\u4f7f\u77e5\u9053\u81ea\u5df1\u662f\u9519\u7684\u3002\u8fd9\u9650\u5236\u4e86\u53cd\u601d\u65b9\u6cd5\u7684\u6548\u679c\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u751f\u6210\u66f4\u6709\u6548\u7684\u53cd\u601d\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u591a\u89d2\u8272\u8fa9\u8bba\u65b9\u6cd5\uff0c\u4f7f\u7528\u591a\u4e2a\u5177\u6709\u4e0d\u540c\u89d2\u8272\u7684LLM\u667a\u80fd\u4f53\u8fdb\u884c\u8fa9\u8bba\u6765\u751f\u6210\u53cd\u601d\u3002\u8fd9\u79cd\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u591a\u6837\u5316\u7684\u89c6\u89d2\u548c\u8fa9\u8bba\u8fc7\u7a0b\uff0c\u907f\u514d\u4e86\u5355\u4e00LLM\u53cd\u601d\u65f6\u7684\u601d\u7ef4\u9000\u5316\u95ee\u9898\u3002", "result": "\u5728HotPot QA\uff08\u95ee\u7b54\uff09\u4efb\u52a1\u4e0a\u8fbe\u523047%\u7684\u7cbe\u786e\u5339\u914d\u7387\uff0c\u5728HumanEval\uff08\u7f16\u7a0b\uff09\u4efb\u52a1\u4e0a\u8fbe\u523082.7%\u7684\u51c6\u786e\u7387\uff0c\u8fd9\u4e24\u4e2a\u6027\u80fd\u90fd\u8d85\u8fc7\u4e86\u4f7f\u7528\u5355\u4e00LLM\u8fdb\u884c\u53cd\u601d\u7684\u65b9\u6cd5\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u591a\u89d2\u8272\u8fa9\u8bba\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u66f4\u591a\u6837\u5316\u7684\u53cd\u601d\uff0c\u6709\u6548\u907f\u514d\u4e86\u5355\u4e00LLM\u53cd\u601d\u65f6\u7684\u601d\u7ef4\u9000\u5316\u95ee\u9898\uff0c\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2512.20884", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20884", "abs": "https://arxiv.org/abs/2512.20884", "authors": ["Zan-Kai Chong", "Hiroyuki Ohsaki", "Bryan Ng"], "title": "The Silent Scholar Problem: A Probabilistic Framework for Breaking Epistemic Asymmetry in LLM Agents", "comment": null, "summary": "Autonomous agents powered by LLMs and Retrieval-Augmented Generation (RAG) are proficient consumers of digital content but remain unidirectional, a limitation we term epistemic asymmetry. This isolation leads to redundant reasoning and stagnates collective intelligence. Current self-reflection frameworks remain largely heuristic and private, lacking a probabilistic foundation to quantify certainty or justify external interaction.To bridge this gap, we propose a formal probabilistic framework that provides agents with a non-altruistic motive for bidirectional knowledge exchange. We model an agent's belief in a proposition using a Beta-Bernoulli distribution with a forgetting factor ($\u03b3$). This allows us to isolate epistemic uncertainty as the variance of belief, establishing a dual drive for interaction: A homeostatic motive: The need to maintain certainty against the temporal decay introduced by $\u03b3$. An optimal learning strategy: Targeting points of maximum ambiguity ($\\mathbb{E}[\u03b8]=0.5$) to maximize information gain. Under this framework, public contribution is reframed as optimal active learning: sharing solutions to elicit feedback is the most efficient method for an agent to reduce its own uncertainty. To ensure scalability, we introduce epistemic caching, which leverages the forgetting factor to dynamically prioritize resources for the active head of non-stationary knowledge distributions. Finally, we demonstrate how these accumulated belief states serve as verifiable reward signals for Reinforcement Learning from Human Feedback (RLHF) and high-quality data filters for Supervised Fine-Tuning (SFT). Simulation results validate that this uncertainty-driven strategy significantly outperforms random baselines in heterogeneous (Zipfian) environments, maintaining high adaptability to concept drift.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6982\u7387\u6846\u67b6\u7684\u53cc\u5411\u77e5\u8bc6\u4ea4\u6362\u6a21\u578b\uff0c\u901a\u8fc7Beta-Bernoulli\u5206\u5e03\u548c\u9057\u5fd8\u56e0\u5b50\u91cf\u5316\u667a\u80fd\u4f53\u4fe1\u5ff5\u4e0d\u786e\u5b9a\u6027\uff0c\u5c06\u516c\u5171\u8d21\u732e\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6700\u4f18\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f02\u6784\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u548c\u96c6\u4f53\u667a\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u548cRAG\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u5b58\u5728\u8ba4\u77e5\u4e0d\u5bf9\u79f0\u95ee\u9898\uff0c\u53ea\u80fd\u5355\u5411\u6d88\u8d39\u6570\u5b57\u5185\u5bb9\u800c\u7f3a\u4e4f\u53cc\u5411\u77e5\u8bc6\u4ea4\u6362\u3002\u73b0\u6709\u7684\u81ea\u6211\u53cd\u601d\u6846\u67b6\u5927\u591a\u662f\u542f\u53d1\u5f0f\u548c\u79c1\u6709\u7684\uff0c\u7f3a\u4e4f\u91cf\u5316\u786e\u5b9a\u6027\u548c\u8bc1\u660e\u5916\u90e8\u4ea4\u4e92\u5408\u7406\u6027\u7684\u6982\u7387\u57fa\u7840\u3002\u8fd9\u79cd\u9694\u79bb\u5bfc\u81f4\u5197\u4f59\u63a8\u7406\u548c\u96c6\u4f53\u667a\u80fd\u505c\u6ede\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6b63\u5f0f\u7684\u6982\u7387\u6846\u67b6\uff1a1) \u4f7f\u7528\u5e26\u9057\u5fd8\u56e0\u5b50\u03b3\u7684Beta-Bernoulli\u5206\u5e03\u5efa\u6a21\u667a\u80fd\u4f53\u5bf9\u547d\u9898\u7684\u4fe1\u5ff5\uff1b2) \u5c06\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e3a\u4fe1\u5ff5\u65b9\u5dee\uff1b3) \u5efa\u7acb\u53cc\u91cd\u4ea4\u4e92\u9a71\u52a8\uff1a\u7a33\u6001\u52a8\u673a\uff08\u7ef4\u6301\u786e\u5b9a\u6027\u5bf9\u6297\u65f6\u95f4\u8870\u51cf\uff09\u548c\u6700\u4f18\u5b66\u4e60\u7b56\u7565\uff08\u9488\u5bf9\u6700\u5927\u6a21\u7cca\u70b9\u4ee5\u6700\u5927\u5316\u4fe1\u606f\u589e\u76ca\uff09\uff1b4) \u5f15\u5165\u8ba4\u77e5\u7f13\u5b58\u673a\u5236\uff0c\u5229\u7528\u9057\u5fd8\u56e0\u5b50\u52a8\u6001\u4f18\u5148\u5904\u7406\u975e\u5e73\u7a33\u77e5\u8bc6\u5206\u5e03\u7684\u6d3b\u8dc3\u5934\u90e8\u8d44\u6e90\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\u9a71\u52a8\u7b56\u7565\u5728\u5f02\u6784\uff08Zipfian\uff09\u73af\u5883\u4e2d\u663e\u8457\u4f18\u4e8e\u968f\u673a\u57fa\u7ebf\uff0c\u4fdd\u6301\u5bf9\u6982\u5ff5\u6f02\u79fb\u7684\u9ad8\u9002\u5e94\u6027\u3002\u79ef\u7d2f\u7684\u4fe1\u5ff5\u72b6\u6001\u53ef\u4f5c\u4e3aRLHF\u7684\u53ef\u9a8c\u8bc1\u5956\u52b1\u4fe1\u53f7\u548cSFT\u7684\u9ad8\u8d28\u91cf\u6570\u636e\u8fc7\u6ee4\u5668\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u516c\u5171\u8d21\u732e\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6700\u4f18\u4e3b\u52a8\u5b66\u4e60\uff1a\u5206\u4eab\u89e3\u51b3\u65b9\u6848\u4ee5\u83b7\u53d6\u53cd\u9988\u662f\u667a\u80fd\u4f53\u51cf\u5c11\u81ea\u8eab\u4e0d\u786e\u5b9a\u6027\u7684\u6700\u6709\u6548\u65b9\u6cd5\u3002\u901a\u8fc7\u91cf\u5316\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u5efa\u7acb\u975e\u5229\u4ed6\u4e3b\u4e49\u7684\u53cc\u5411\u77e5\u8bc6\u4ea4\u6362\u52a8\u673a\uff0c\u89e3\u51b3\u4e86\u81ea\u4e3b\u667a\u80fd\u4f53\u7684\u8ba4\u77e5\u4e0d\u5bf9\u79f0\u95ee\u9898\uff0c\u4fc3\u8fdb\u4e86\u96c6\u4f53\u667a\u80fd\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.20985", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.20985", "abs": "https://arxiv.org/abs/2512.20985", "authors": ["Salman Jan", "Hassan Ali Razzaqi", "Ali Akarma", "Mohammad Riyaz Belgaum"], "title": "A Blockchain-Monitored Agentic AI Architecture for Trusted Perception-Reasoning-Action Pipelines", "comment": "This paper was presented at the IEEE International Conference on Computing and Applications (ICCA 2025), Bahrain", "summary": "The application of agentic AI systems in autonomous decision-making is growing in the areas of healthcare, smart cities, digital forensics, and supply chain management. Even though these systems are flexible and offer real-time reasoning, they also raise concerns of trust and oversight, and integrity of the information and activities upon which they are founded. The paper suggests a single architecture model comprising of LangChain-based multi-agent system with a permissioned blockchain to guarantee constant monitoring, policy enforcement, and immutable auditability of agentic action. The framework relates the perception conceptualization-action cycle to a blockchain layer of governance that verifies the inputs, evaluates recommended actions, and documents the outcomes of the execution. A Hyperledger Fabric-based system, action executors MCP-integrated, and LangChain agent are introduced and experiments of smart inventory management, traffic-signal control, and healthcare monitoring are done. The results suggest that blockchain-security verification is efficient in preventing unauthorized practices, offers traceability throughout the whole decision-making process, and maintains operational latency within reasonable ranges. The suggested framework provides a universal system of implementing high-impact agentic AI applications that are autonomous yet responsible.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LangChain\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u8bb8\u53ef\u533a\u5757\u94fe\u7684\u67b6\u6784\uff0c\u7528\u4e8e\u786e\u4fdd\u81ea\u4e3bAI\u7cfb\u7edf\u7684\u76d1\u63a7\u3001\u7b56\u7565\u6267\u884c\u548c\u4e0d\u53ef\u7be1\u6539\u5ba1\u8ba1\uff0c\u5728\u667a\u80fd\u5e93\u5b58\u7ba1\u7406\u3001\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u548c\u533b\u7597\u76d1\u63a7\u7b49\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1\u81ea\u4e3bAI\u7cfb\u7edf\u5728\u533b\u7597\u3001\u667a\u6167\u57ce\u5e02\u3001\u6570\u5b57\u53d6\u8bc1\u548c\u4f9b\u5e94\u94fe\u7ba1\u7406\u7b49\u9886\u57df\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u5177\u6709\u7075\u6d3b\u6027\u548c\u5b9e\u65f6\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u4e5f\u5f15\u53d1\u4e86\u4fe1\u4efb\u3001\u76d1\u7763\u4ee5\u53ca\u4fe1\u606f\u4e0e\u6d3b\u52a8\u5b8c\u6574\u6027\u65b9\u9762\u7684\u62c5\u5fe7\u3002", "method": "\u63d0\u51fa\u5355\u4e00\u67b6\u6784\u6a21\u578b\uff0c\u5305\u542b\u57fa\u4e8eLangChain\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u8bb8\u53ef\u533a\u5757\u94fe\uff0c\u5c06\u611f\u77e5-\u6982\u5ff5\u5316-\u884c\u52a8\u5faa\u73af\u4e0e\u533a\u5757\u94fe\u6cbb\u7406\u5c42\u5173\u8054\uff0c\u9a8c\u8bc1\u8f93\u5165\u3001\u8bc4\u4f30\u5efa\u8bae\u884c\u52a8\u5e76\u8bb0\u5f55\u6267\u884c\u7ed3\u679c\u3002\u5177\u4f53\u5b9e\u73b0\u5305\u62ecHyperledger Fabric\u7cfb\u7edf\u3001MCP\u96c6\u6210\u52a8\u4f5c\u6267\u884c\u5668\u548cLangChain\u667a\u80fd\u4f53\u3002", "result": "\u5b9e\u9a8c\u6db5\u76d6\u667a\u80fd\u5e93\u5b58\u7ba1\u7406\u3001\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u548c\u533b\u7597\u76d1\u63a7\u573a\u666f\uff0c\u7ed3\u679c\u663e\u793a\u533a\u5757\u94fe\u5b89\u5168\u9a8c\u8bc1\u80fd\u6709\u6548\u9632\u6b62\u672a\u7ecf\u6388\u6743\u7684\u64cd\u4f5c\uff0c\u63d0\u4f9b\u5168\u51b3\u7b56\u8fc7\u7a0b\u7684\u53ef\u8ffd\u6eaf\u6027\uff0c\u5e76\u5c06\u64cd\u4f5c\u5ef6\u8fdf\u4fdd\u6301\u5728\u5408\u7406\u8303\u56f4\u5185\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5b9e\u65bd\u9ad8\u5f71\u54cd\u529b\u81ea\u4e3bAI\u5e94\u7528\u63d0\u4f9b\u4e86\u901a\u7528\u7cfb\u7edf\uff0c\u65e2\u80fd\u4fdd\u6301\u81ea\u4e3b\u6027\u53c8\u80fd\u786e\u4fdd\u8d23\u4efb\u6027\uff0c\u5b9e\u73b0\u4e86\u81ea\u4e3b\u4e0e\u8d1f\u8d23\u7684\u5e73\u8861\u3002"}}
{"id": "2512.20991", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.20991", "abs": "https://arxiv.org/abs/2512.20991", "authors": ["Toqeer Ali Syed", "Abdulaziz Alshahrani", "Ali Ullah", "Ali Akarma", "Sohail Khan", "Muhammad Nauman", "Salman Jan"], "title": "FinAgent: An Agentic AI Framework Integrating Personal Finance and Nutrition Planning", "comment": "This paper was presented at the IEEE International Conference on Computing and Applications (ICCA 2025), Bahrain", "summary": "The issue of limited household budgets and nutritional demands continues to be a challenge especially in the middle-income environment where food prices fluctuate. This paper introduces a price aware agentic AI system, which combines personal finance management with diet optimization. With household income and fixed expenditures, medical and well-being status, as well as real-time food costs, the system creates nutritionally sufficient meals plans at comparatively reasonable prices that automatically adjust to market changes. The framework is implemented in a modular multi-agent architecture, which has specific agents (budgeting, nutrition, price monitoring, and health personalization). These agents share the knowledge base and use the substitution graph to ensure that the nutritional quality is maintained at a minimum cost. Simulations with a representative Saudi household case study show a steady 12-18\\% reduction in costs relative to a static weekly menu, nutrient adequacy of over 95\\% and high performance with price changes of 20-30%. The findings indicate that the framework can locally combine affordability with nutritional adequacy and provide a viable avenue of capacity-building towards sustainable and fair diet planning in line with Sustainable Development Goals on Zero Hunger and Good Health.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ef7\u683c\u611f\u77e5\u7684\u667a\u80fdAI\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e2a\u4eba\u8d22\u52a1\u7ba1\u7406\u4e0e\u996e\u98df\u4f18\u5316\uff0c\u4e3a\u4e2d\u7b49\u6536\u5165\u5bb6\u5ead\u63d0\u4f9b\u8425\u517b\u5145\u8db3\u4e14\u4ef7\u683c\u5408\u7406\u7684\u81b3\u98df\u8ba1\u5212\uff0c\u80fd\u81ea\u52a8\u9002\u5e94\u5e02\u573a\u4ef7\u683c\u6ce2\u52a8\u3002", "motivation": "\u4e2d\u7b49\u6536\u5165\u73af\u5883\u4e2d\u5bb6\u5ead\u9884\u7b97\u6709\u9650\u4e0e\u8425\u517b\u9700\u6c42\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u7279\u522b\u662f\u98df\u54c1\u4ef7\u683c\u6ce2\u52a8\u5e26\u6765\u7684\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u8003\u8651\u7ecf\u6d4e\u53ef\u8d1f\u62c5\u6027\u548c\u8425\u517b\u5145\u8db3\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5305\u542b\u9884\u7b97\u3001\u8425\u517b\u3001\u4ef7\u683c\u76d1\u63a7\u548c\u5065\u5eb7\u4e2a\u6027\u5316\u7b49\u4e13\u95e8\u667a\u80fd\u4f53\uff0c\u5171\u4eab\u77e5\u8bc6\u5e93\u5e76\u4f7f\u7528\u66ff\u4ee3\u56fe\u6765\u786e\u4fdd\u4ee5\u6700\u4f4e\u6210\u672c\u7ef4\u6301\u8425\u517b\u8d28\u91cf\u3002", "result": "\u5728\u6c99\u7279\u5bb6\u5ead\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u7cfb\u7edf\u76f8\u6bd4\u9759\u6001\u5468\u83dc\u5355\u5b9e\u73b012-18%\u7684\u6210\u672c\u964d\u4f4e\uff0c\u8425\u517b\u5145\u8db3\u7387\u8d85\u8fc795%\uff0c\u572820-30%\u4ef7\u683c\u6ce2\u52a8\u4e0b\u4ecd\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u6709\u6548\u7ed3\u5408\u7ecf\u6d4e\u53ef\u8d1f\u62c5\u6027\u4e0e\u8425\u517b\u5145\u8db3\u6027\uff0c\u4e3a\u5b9e\u73b0\u53ef\u6301\u7eed\u548c\u516c\u5e73\u7684\u996e\u98df\u89c4\u5212\u63d0\u4f9b\u4e86\u53ef\u884c\u9014\u5f84\uff0c\u7b26\u5408\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u4e2d\u96f6\u9965\u997f\u548c\u826f\u597d\u5065\u5eb7\u7684\u76ee\u6807\u3002"}}
{"id": "2512.21080", "categories": ["cs.AI", "cs.LG", "econ.EM"], "pdf": "https://arxiv.org/pdf/2512.21080", "abs": "https://arxiv.org/abs/2512.21080", "authors": ["Enoch Hyunwook Kang"], "title": "LLM Personas as a Substitute for Field Experiments in Method Benchmarking", "comment": null, "summary": "Field experiments (A/B tests) are often the most credible benchmark for methods in societal systems, but their cost and latency create a major bottleneck for iterative method development. LLM-based persona simulation offers a cheap synthetic alternative, yet it is unclear whether replacing humans with personas preserves the benchmark interface that adaptive methods optimize against. We prove an if-and-only-if characterization: when (i) methods observe only the aggregate outcome (aggregate-only observation) and (ii) evaluation depends only on the submitted artifact and not on the algorithm's identity or provenance (algorithm-blind evaluation), swapping humans for personas is just panel change from the method's point of view, indistinguishable from changing the evaluation population (e.g., New York to Jakarta). Furthermore, we move from validity to usefulness: we define an information-theoretic discriminability of the induced aggregate channel and show that making persona benchmarking as decision-relevant as a field experiment is fundamentally a sample-size question, yielding explicit bounds on the number of independent persona evaluations required to reliably distinguish meaningfully different methods at a chosen resolution.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\uff1a\u5728\u805a\u5408\u89c2\u5bdf\u548c\u7b97\u6cd5\u76f2\u8bc4\u4f30\u6761\u4ef6\u4e0b\uff0c\u7528LLM\u89d2\u8272\u6a21\u62df\u66ff\u4ee3\u4eba\u7c7b\u8fdb\u884cA/B\u6d4b\u8bd5\u662f\u6709\u6548\u7684\u57fa\u51c6\u66ff\u4ee3\u65b9\u6848\uff0c\u4e14\u533a\u5206\u4e0d\u540c\u65b9\u6cd5\u6240\u9700\u89d2\u8272\u8bc4\u4f30\u6570\u91cf\u53ef\u901a\u8fc7\u4fe1\u606f\u8bba\u754c\u9650\u786e\u5b9a\u3002", "motivation": "A/B\u6d4b\u8bd5\u4f5c\u4e3a\u793e\u4f1a\u7cfb\u7edf\u65b9\u6cd5\u8bc4\u4f30\u7684\u9ec4\u91d1\u6807\u51c6\uff0c\u4f46\u6210\u672c\u9ad8\u3001\u5ef6\u8fdf\u957f\uff0c\u963b\u788d\u4e86\u8fed\u4ee3\u65b9\u6cd5\u5f00\u53d1\u3002LLM\u89d2\u8272\u6a21\u62df\u63d0\u4f9b\u4e86\u5ec9\u4ef7\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u9700\u8981\u9a8c\u8bc1\u5176\u662f\u5426\u4fdd\u6301\u57fa\u51c6\u63a5\u53e3\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u5145\u8981\u6761\u4ef6\u7279\u5f81\uff1a\u5f53(1)\u65b9\u6cd5\u4ec5\u89c2\u5bdf\u805a\u5408\u7ed3\u679c\uff08\u805a\u5408\u89c2\u5bdf\uff09\uff0c(2)\u8bc4\u4f30\u4ec5\u4f9d\u8d56\u63d0\u4ea4\u4ea7\u7269\u800c\u975e\u7b97\u6cd5\u8eab\u4efd\uff08\u7b97\u6cd5\u76f2\u8bc4\u4f30\uff09\u65f6\uff0c\u89d2\u8272\u66ff\u6362\u4eba\u7c7b\u53ea\u662f\u9762\u677f\u53d8\u66f4\u3002\u5b9a\u4e49\u805a\u5408\u4fe1\u9053\u7684\u4fe1\u606f\u8bba\u53ef\u533a\u5206\u6027\uff0c\u63a8\u5bfc\u53ef\u9760\u533a\u5206\u4e0d\u540c\u65b9\u6cd5\u6240\u9700\u72ec\u7acb\u89d2\u8272\u8bc4\u4f30\u6570\u91cf\u7684\u660e\u786e\u754c\u9650\u3002", "result": "\u8bc1\u660e\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0cLLM\u89d2\u8272\u6a21\u62df\u53ef\u66ff\u4ee3\u4eba\u7c7b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e14\u89d2\u8272\u57fa\u51c6\u4e0e\u73b0\u573a\u5b9e\u9a8c\u540c\u7b49\u51b3\u7b56\u76f8\u5173\u6027\u672c\u8d28\u4e0a\u662f\u6837\u672c\u91cf\u95ee\u9898\uff0c\u7ed9\u51fa\u4e86\u6240\u9700\u8bc4\u4f30\u6570\u91cf\u7684\u7406\u8bba\u754c\u9650\u3002", "conclusion": "LLM\u89d2\u8272\u6a21\u62df\u5728\u805a\u5408\u89c2\u5bdf\u548c\u7b97\u6cd5\u76f2\u8bc4\u4f30\u6761\u4ef6\u4e0b\u662f\u6709\u6548\u7684A/B\u6d4b\u8bd5\u66ff\u4ee3\u65b9\u6848\uff0c\u4e3a\u8fed\u4ee3\u65b9\u6cd5\u5f00\u53d1\u63d0\u4f9b\u4e86\u5ec9\u4ef7\u3001\u5feb\u901f\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5e76\u63d0\u4f9b\u4e86\u786e\u5b9a\u6240\u9700\u8bc4\u4f30\u89c4\u6a21\u7684\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2512.21127", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21127", "abs": "https://arxiv.org/abs/2512.21127", "authors": ["Oliver Normand", "Esther Borsi", "Mitch Fruin", "Lauren E Walker", "Jamie Heagerty", "Chris C. Holmes", "Anthony J Avery", "Iain E Buchan", "Harry Coppock"], "title": "A Real-World Evaluation of LLM Medication Safety Reviews in NHS Primary Care", "comment": null, "summary": "Large language models (LLMs) often match or exceed clinician-level performance on medical benchmarks, yet very few are evaluated on real clinical data or examined beyond headline metrics. We present, to our knowledge, the first evaluation of an LLM-based medication safety review system on real NHS primary care data, with detailed characterisation of key failure behaviours across varying levels of clinical complexity. In a retrospective study using a population-scale EHR spanning 2,125,549 adults in NHS Cheshire and Merseyside, we strategically sampled patients to capture a broad range of clinical complexity and medication safety risk, yielding 277 patients after data-quality exclusions. An expert clinician reviewed these patients and graded system-identified issues and proposed interventions. Our primary LLM system showed strong performance in recognising when a clinical issue is present (sensitivity 100\\% [95\\% CI 98.2--100], specificity 83.1\\% [95\\% CI 72.7--90.1]), yet correctly identified all issues and interventions in only 46.9\\% [95\\% CI 41.1--52.8] of patients. Failure analysis reveals that, in this setting, the dominant failure mechanism is contextual reasoning rather than missing medication knowledge, with five primary patterns: overconfidence in uncertainty, applying standard guidelines without adjusting for patient context, misunderstanding how healthcare is delivered in practice, factual errors, and process blindness. These patterns persisted across patient complexity and demographic strata, and across a range of state-of-the-art models and configurations. We provide 45 detailed vignettes that comprehensively cover all identified failure cases. This work highlights shortcomings that must be addressed before LLM-based clinical AI can be safely deployed. It also begs larger-scale, prospective evaluations and deeper study of LLM behaviours in clinical contexts.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u5728\u771f\u5b9eNHS\u521d\u7ea7\u533b\u7597\u6570\u636e\u4e0a\u8bc4\u4f30LLM\u836f\u7269\u5b89\u5168\u5ba1\u67e5\u7cfb\u7edf\uff0c\u53d1\u73b0\u867d\u7136\u7cfb\u7edf\u80fd\u9ad8\u7075\u654f\u5ea6\u8bc6\u522b\u4e34\u5e8a\u95ee\u9898\uff0c\u4f46\u5728\u590d\u6742\u60c5\u5883\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff0c\u4ec5\u670946.9%\u7684\u60a3\u8005\u80fd\u6b63\u786e\u8bc6\u522b\u6240\u6709\u95ee\u9898\u548c\u5e72\u9884\u63aa\u65bd\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e38\u8fbe\u5230\u6216\u8d85\u8fc7\u4e34\u5e8a\u533b\u751f\u6c34\u5e73\uff0c\u4f46\u5f88\u5c11\u6709\u7814\u7a76\u5728\u771f\u5b9e\u4e34\u5e8a\u6570\u636e\u4e0a\u8bc4\u4f30LLM\uff0c\u6216\u6df1\u5165\u5206\u6790\u8d85\u8d8a\u8868\u9762\u6307\u6807\u7684\u8868\u73b0\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u8bc4\u4f30LLM\u5728\u771f\u5b9e\u533b\u7597\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u8868\u73b0\u3002", "method": "\u5728NHS Cheshire\u548cMerseyside\u5730\u533a2,125,549\u540d\u6210\u4eba\u7684\u56de\u987e\u6027\u7814\u7a76\u4e2d\uff0c\u6218\u7565\u6027\u5730\u62bd\u6837\u9009\u53d6\u60a3\u8005\u4ee5\u8986\u76d6\u5e7f\u6cdb\u7684\u4e34\u5e8a\u590d\u6742\u6027\u548c\u836f\u7269\u5b89\u5168\u98ce\u9669\uff0c\u6700\u7ec8\u7eb3\u5165277\u540d\u60a3\u8005\u3002\u7531\u4e13\u5bb6\u4e34\u5e8a\u533b\u751f\u5ba1\u67e5\u8fd9\u4e9b\u60a3\u8005\uff0c\u5e76\u5bf9\u7cfb\u7edf\u8bc6\u522b\u7684\u95ee\u9898\u548c\u63d0\u51fa\u7684\u5e72\u9884\u63aa\u65bd\u8fdb\u884c\u5206\u7ea7\u8bc4\u4f30\u3002", "result": "\u4e3b\u8981LLM\u7cfb\u7edf\u5728\u8bc6\u522b\u4e34\u5e8a\u95ee\u9898\u5b58\u5728\u65b9\u9762\u8868\u73b0\u5f3a\u52b2\uff08\u7075\u654f\u5ea6100%\uff0c\u7279\u5f02\u602783.1%\uff09\uff0c\u4f46\u4ec5\u572846.9%\u7684\u60a3\u8005\u4e2d\u6b63\u786e\u8bc6\u522b\u6240\u6709\u95ee\u9898\u548c\u5e72\u9884\u63aa\u65bd\u3002\u5931\u8d25\u5206\u6790\u63ed\u793a\u4e86\u4e94\u79cd\u4e3b\u8981\u5931\u8d25\u6a21\u5f0f\uff1a\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u8fc7\u5ea6\u81ea\u4fe1\u3001\u672a\u6839\u636e\u60a3\u8005\u60c5\u5883\u8c03\u6574\u6807\u51c6\u6307\u5357\u3001\u8bef\u89e3\u533b\u7597\u5b9e\u8df5\u65b9\u5f0f\u3001\u4e8b\u5b9e\u9519\u8bef\u548c\u6d41\u7a0b\u76f2\u70b9\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86LLM\u5728\u4e34\u5e8a\u60c5\u5883\u63a8\u7406\u65b9\u9762\u7684\u663e\u8457\u7f3a\u9677\uff0c\u8fd9\u4e9b\u7f3a\u9677\u5728\u6240\u6709\u60a3\u8005\u590d\u6742\u6027\u548c\u4eba\u53e3\u7edf\u8ba1\u5b66\u5c42\u6b21\u4ee5\u53ca\u5404\u79cd\u6700\u5148\u8fdb\u6a21\u578b\u548c\u914d\u7f6e\u4e2d\u6301\u7eed\u5b58\u5728\u3002\u5728LLM\u4e34\u5e8aAI\u5b89\u5168\u90e8\u7f72\u524d\u5fc5\u987b\u89e3\u51b3\u8fd9\u4e9b\u77ed\u677f\uff0c\u9700\u8981\u8fdb\u884c\u66f4\u5927\u89c4\u6a21\u7684\u524d\u77bb\u6027\u8bc4\u4f30\u548c\u66f4\u6df1\u5165\u7684LLM\u884c\u4e3a\u7814\u7a76\u3002"}}
{"id": "2512.21220", "categories": ["cs.AI", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.21220", "abs": "https://arxiv.org/abs/2512.21220", "authors": ["Le Wang", "Zonghao Ying", "Xiao Yang", "Quanchen Zou", "Zhenfei Yin", "Tianlin Li", "Jian Yang", "Yaodong Yang", "Aishan Liu", "Xianglong Liu"], "title": "RoboSafe: Safeguarding Embodied Agents via Executable Safety Logic", "comment": "11 pages, 6 figures", "summary": "Embodied agents powered by vision-language models (VLMs) are increasingly capable of executing complex real-world tasks, yet they remain vulnerable to hazardous instructions that may trigger unsafe behaviors. Runtime safety guardrails, which intercept hazardous actions during task execution, offer a promising solution due to their flexibility. However, existing defenses often rely on static rule filters or prompt-level control, which struggle to address implicit risks arising in dynamic, temporally dependent, and context-rich environments. To address this, we propose RoboSafe, a hybrid reasoning runtime safeguard for embodied agents through executable predicate-based safety logic. RoboSafe integrates two complementary reasoning processes on a Hybrid Long-Short Safety Memory. We first propose a Backward Reflective Reasoning module that continuously revisits recent trajectories in short-term memory to infer temporal safety predicates and proactively triggers replanning when violations are detected. We then propose a Forward Predictive Reasoning module that anticipates upcoming risks by generating context-aware safety predicates from the long-term safety memory and the agent's multimodal observations. Together, these components form an adaptive, verifiable safety logic that is both interpretable and executable as code. Extensive experiments across multiple agents demonstrate that RoboSafe substantially reduces hazardous actions (-36.8% risk occurrence) compared with leading baselines, while maintaining near-original task performance. Real-world evaluations on physical robotic arms further confirm its practicality. Code will be released upon acceptance.", "AI": {"tldr": "RoboSafe\uff1a\u4e00\u79cd\u7528\u4e8e\u5177\u8eab\u667a\u80fd\u4f53\u7684\u6df7\u5408\u63a8\u7406\u8fd0\u884c\u65f6\u5b89\u5168\u9632\u62a4\u7cfb\u7edf\uff0c\u901a\u8fc7\u53ef\u6267\u884c\u7684\u57fa\u4e8e\u8c13\u8bcd\u7684\u5b89\u5168\u903b\u8f91\u6765\u51cf\u5c11\u5371\u9669\u884c\u4e3a\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5177\u8eab\u667a\u80fd\u4f53\u5728\u6267\u884c\u590d\u6742\u73b0\u5b9e\u4efb\u52a1\u65f6\u5bb9\u6613\u53d7\u5230\u5371\u9669\u6307\u4ee4\u7684\u5f71\u54cd\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\uff08\u5982\u9759\u6001\u89c4\u5219\u8fc7\u6ee4\u5668\u6216\u63d0\u793a\u7ea7\u63a7\u5236\uff09\u96be\u4ee5\u5904\u7406\u52a8\u6001\u3001\u65f6\u95f4\u4f9d\u8d56\u548c\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u73af\u5883\u4e2d\u7684\u9690\u542b\u98ce\u9669\u3002", "method": "\u63d0\u51faRoboSafe\uff0c\u4e00\u79cd\u6df7\u5408\u63a8\u7406\u8fd0\u884c\u65f6\u5b89\u5168\u9632\u62a4\u7cfb\u7edf\uff0c\u5305\u542b\uff1a1\uff09\u540e\u5411\u53cd\u601d\u63a8\u7406\u6a21\u5757\uff0c\u6301\u7eed\u56de\u987e\u77ed\u671f\u8bb0\u5fc6\u4e2d\u7684\u8f68\u8ff9\u4ee5\u63a8\u65ad\u65f6\u95f4\u5b89\u5168\u8c13\u8bcd\uff1b2\uff09\u524d\u5411\u9884\u6d4b\u63a8\u7406\u6a21\u5757\uff0c\u4ece\u957f\u671f\u5b89\u5168\u8bb0\u5fc6\u548c\u591a\u6a21\u6001\u89c2\u5bdf\u4e2d\u751f\u6210\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5b89\u5168\u8c13\u8bcd\u3002\u4e24\u8005\u7ed3\u5408\u5f62\u6210\u53ef\u9002\u5e94\u3001\u53ef\u9a8c\u8bc1\u7684\u5b89\u5168\u903b\u8f91\u3002", "result": "\u5728\u591a\u4e2a\u667a\u80fd\u4f53\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRoboSafe\u663e\u8457\u51cf\u5c11\u4e86\u5371\u9669\u884c\u4e3a\uff08\u98ce\u9669\u53d1\u751f\u7387\u964d\u4f4e36.8%\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a5\u8fd1\u539f\u59cb\u7684\u4efb\u52a1\u6027\u80fd\u3002\u7269\u7406\u673a\u68b0\u81c2\u7684\u771f\u5b9e\u4e16\u754c\u8bc4\u4f30\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "RoboSafe\u901a\u8fc7\u53ef\u6267\u884c\u7684\u57fa\u4e8e\u8c13\u8bcd\u7684\u5b89\u5168\u903b\u8f91\uff0c\u4e3a\u5177\u8eab\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u6709\u6548\u3001\u53ef\u89e3\u91ca\u7684\u8fd0\u884c\u65f6\u5b89\u5168\u9632\u62a4\uff0c\u5728\u51cf\u5c11\u5371\u9669\u884c\u4e3a\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u4efb\u52a1\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}

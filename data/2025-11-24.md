<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 10]
- [cs.CR](#cs.CR) [Total: 7]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.DC](#cs.DC) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Stable diffusion models reveal a persisting human and AI gap in visual creativity](https://arxiv.org/abs/2511.16814)
*Silvia Rondini,Claudia Alvarez-Martin,Paula Angermair-Barkai,Olivier Penacchio,M. Paz,Matthew Pelowski,Dan Dediu,Antoni Rodriguez-Fornells,Xim Cerda-Company*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: While recent research suggests Large Language Models match human creative performance in divergent thinking tasks, visual creativity remains underexplored. This study compared image generation in human participants (Visual Artists and Non Artists) and using an image generation AI model (two prompting conditions with varying human input: high for Human Inspired, low for Self Guided). Human raters (N=255) and GPT4o evaluated the creativity of the resulting images. We found a clear creativity gradient, with Visual Artists being the most creative, followed by Non Artists, then Human Inspired generative AI, and finally Self Guided generative AI. Increased human guidance strongly improved GenAI's creative output, bringing its productions close to those of Non Artists. Notably, human and AI raters also showed vastly different creativity judgment patterns. These results suggest that, in contrast to language centered tasks, GenAI models may face unique challenges in visual domains, where creativity depends on perceptual nuance and contextual sensitivity, distinctly human capacities that may not be readily transferable from language models.

</details>


### [2] [Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs](https://arxiv.org/abs/2511.16837)
*Oliver Kramer*

Main category: cs.AI

TL;DR: Cognitive BASIC是一种基于BASIC风格的提示语言和模型内解释器，将大语言模型的推理过程结构化，形成明确的分步执行轨迹。


<details>
  <summary>Details</summary>
Motivation: 受复古BASIC简单性的启发，重新利用编号行和简单命令作为可解释的认知控制层，使现代LLM能够可靠地模拟这类短程序，实现模型内部透明的多步推理。

Method: 使用自然语言解释器文件指定命令语义、内存更新和日志行为，通过心理模型解释器提取声明性和程序性知识，检测矛盾并在必要时生成解决方案。

Result: 在三个LLM上进行的知识提取、冲突检测和推理任务基准测试表明，所有模型都能执行Cognitive BASIC程序，整体表现强劲但不均匀。

Conclusion: Cognitive BASIC提供了一种结构化的方法来实现LLM的透明推理，所有测试模型都能成功执行这种程序，显示出良好的通用性。

Abstract: Cognitive BASIC is a minimal, BASIC-style prompting language and in-model interpreter that structures large language model (LLM) reasoning into explicit, stepwise execution traces. Inspired by the simplicity of retro BASIC, we repurpose numbered lines and simple commands as an interpretable cognitive control layer. Modern LLMs can reliably simulate such short programs, enabling transparent multi-step reasoning inside the model. A natural-language interpreter file specifies command semantics, memory updates, and logging behavior. Our mental-model interpreter extracts declarative and procedural knowledge, detects contradictions, and produces resolutions when necessary. A comparison across three LLMs on a benchmark of knowledge extraction, conflict detection, and reasoning tasks shows that all models can execute Cognitive BASIC programs, with overall strong but not uniform performance.

</details>


### [3] [Fantastic Bugs and Where to Find Them in AI Benchmarks](https://arxiv.org/abs/2511.16842)
*Sang Truong,Yuheng Tu,Michael Hardy,Anka Reuel,Zeyu Tang,Jirayu Burapacheep,Jonathan Perera,Chibuike Uwakwe,Ben Domingue,Nick Haber,Sanmi Koyejo*

Main category: cs.AI

TL;DR: 提出一个利用响应模式统计分析来识别基准测试中无效问题的框架，通过检测统计量超出预期范围的问题来指导专家审查，在九个基准测试中达到84%的准确率。


<details>
  <summary>Details</summary>
Motivation: 基准测试对AI发展至关重要，但无效问题会破坏其可靠性。手动识别和修正数千个基准问题不可行，成为可靠评估的关键瓶颈。

Method: 基于AI评估中常用的核心假设（平均分足以总结模型性能），构建系统化基准修订框架，通过统计分析响应模式来标记潜在无效问题，并引入LLM-judge进行初步审查以减少人工工作量。

Result: 在九个广泛使用的基准测试中，该方法指导专家审查识别问题问题的准确率高达84%，显著提高了基准测试的可靠性。

Conclusion: 该框架提供了一个高效且可扩展的系统化基准修订方法，结合统计分析和LLM初步审查，大幅减少了人工工作量，提升了基准测试的质量和可靠性。

Abstract: Benchmarks are pivotal in driving AI progress, and invalid benchmark questions frequently undermine their reliability. Manually identifying and correcting errors among thousands of benchmark questions is not only infeasible but also a critical bottleneck for reliable evaluation. In this work, we introduce a framework for systematic benchmark revision that leverages statistical analysis of response patterns to flag potentially invalid questions for further expert review. Our approach builds on a core assumption commonly used in AI evaluations that the mean score sufficiently summarizes model performance. This implies a unidimensional latent construct underlying the measurement experiment, yielding expected ranges for various statistics for each item. When empirically estimated values for these statistics fall outside the expected range for an item, the item is more likely to be problematic. Across nine widely used benchmarks, our method guides expert review to identify problematic questions with up to 84\% precision. In addition, we introduce an LLM-judge first pass to review questions, further reducing human effort. Together, these components provide an efficient and scalable framework for systematic benchmark revision.

</details>


### [4] [Hybrid Differential Reward: Combining Temporal Difference and Action Gradients for Efficient Multi-Agent Reinforcement Learning in Cooperative Driving](https://arxiv.org/abs/2511.16916)
*Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种混合差分奖励(HDR)机制来解决多车辆协同驾驶中传统状态奖励函数存在的奖励差异消失问题，该机制结合了基于全局势函数的时序差分奖励和动作梯度奖励，显著提高了算法收敛速度和策略稳定性。


<details>
  <summary>Details</summary>
Motivation: 在多车辆协同驾驶任务中，传统基于状态的奖励函数存在奖励差异消失问题，导致策略梯度的信噪比低，严重影响算法收敛和性能提升。

Method: 提出混合差分奖励(HDR)机制，包含两个互补组件：基于全局势函数的时序差分奖励(TRD)和直接测量动作边际效用的动作梯度奖励(ARG)。将协同驾驶问题建模为具有时变智能体集的多智能体部分可观测马尔可夫博弈。

Result: 使用在线规划(MCTS)和多智能体强化学习(QMIX、MAPPO、MADDPG)算法进行的大量实验表明，HDR机制显著提高了收敛速度和策略稳定性。

Conclusion: HDR机制能够引导智能体学习高质量的合作策略，有效平衡交通效率和安全性。

Abstract: In multi-vehicle cooperative driving tasks involving high-frequency continuous control, traditional state-based reward functions suffer from the issue of vanishing reward differences. This phenomenon results in a low signal-to-noise ratio (SNR) for policy gradients, significantly hindering algorithm convergence and performance improvement. To address this challenge, this paper proposes a novel Hybrid Differential Reward (HDR) mechanism. We first theoretically elucidate how the temporal quasi-steady nature of traffic states and the physical proximity of actions lead to the failure of traditional reward signals. Building on this analysis, the HDR framework innovatively integrates two complementary components: (1) a Temporal Difference Reward (TRD) based on a global potential function, which utilizes the evolutionary trend of potential energy to ensure optimal policy invariance and consistency with long-term objectives; and (2) an Action Gradient Reward (ARG), which directly measures the marginal utility of actions to provide a local guidance signal with a high SNR. Furthermore, we formulate the cooperative driving problem as a Multi-Agent Partially Observable Markov Game (POMDPG) with a time-varying agent set and provide a complete instantiation scheme for HDR within this framework. Extensive experiments conducted using both online planning (MCTS) and Multi-Agent Reinforcement Learning (QMIX, MAPPO, MADDPG) algorithms demonstrate that the HDR mechanism significantly improves convergence speed and policy stability. The results confirm that HDR guides agents to learn high-quality cooperative policies that effectively balance traffic efficiency and safety.

</details>


### [5] [DAPS++: Rethinking Diffusion Inverse Problems with Decoupled Posterior Annealing](https://arxiv.org/abs/2511.17038)
*Hao Chen,Renzheng Zhang,Scott S. Howard*

Main category: cs.AI

TL;DR: 论文重新解释了扩散模型在逆问题求解中的作用，提出DAPS++方法将扩散阶段与数据驱动细化完全解耦，通过更少的函数评估和测量优化步骤实现高效计算和鲁棒重建。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯视角下基于分数的扩散方法在解决逆问题时，先验提供的指导有限，重建主要由测量一致性项驱动，导致推理过程与扩散动力学有效解耦。需要澄清这种结构并改进方法。

Method: 将扩散重新解释为期望最大化（EM）框架中的初始化阶段，提出DAPS++方法，使似然项更直接地指导推理，同时保持数值稳定性。

Result: DAPS++在多种图像恢复任务中实现了高计算效率和鲁棒的重建性能，需要更少的函数评估和测量优化步骤。

Conclusion: 通过将扩散阶段与数据驱动细化完全解耦，DAPS++揭示了为什么统一的扩散轨迹在实践中仍然有效，并为逆问题求解提供了更高效的解决方案。

Abstract: From a Bayesian perspective, score-based diffusion solves inverse problems through joint inference, embedding the likelihood with the prior to guide the sampling process. However, this formulation fails to explain its practical behavior: the prior offers limited guidance, while reconstruction is largely driven by the measurement-consistency term, leading to an inference process that is effectively decoupled from the diffusion dynamics. To clarify this structure, we reinterpret the role of diffusion in inverse problem solving as an initialization stage within an expectation--maximization (EM)--style framework, where the diffusion stage and the data-driven refinement are fully decoupled. We introduce \textbf{DAPS++}, which allows the likelihood term to guide inference more directly while maintaining numerical stability and providing insight into why unified diffusion trajectories remain effective in practice. By requiring fewer function evaluations (NFEs) and measurement-optimization steps, \textbf{DAPS++} achieves high computational efficiency and robust reconstruction performance across diverse image restoration tasks.

</details>


### [6] [MIR: Efficient Exploration in Episodic Multi-Agent Reinforcement Learning via Mutual Intrinsic Reward](https://arxiv.org/abs/2511.17165)
*Kesheng Chen,Wenjian Luo,Bang Zhang,Zeping Yin,Zipeng Ye*

Main category: cs.AI

TL;DR: 本文提出了一种名为MIR的相互内在奖励方法，用于解决多智能体强化学习中稀疏奖励的挑战，通过激励智能体探索影响队友的行为来改善团队探索效果。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中的稀疏奖励（特别是情节奖励）面临两个主要挑战：联合动作轨迹的指数级稀疏性，以及现有方法未能充分考虑影响团队状态的联合动作。

Method: 提出了相互内在奖励（MIR）方法，激励个体智能体探索能够影响队友的行为，并与原始策略结合使用，有效刺激团队探索。

Result: 在扩展的MiniGrid-MA环境中进行评估，实验结果表明该方法在稀疏奖励场景下优于现有最先进方法。

Conclusion: MIR是一种简单而有效的增强策略，能够显著改善多智能体强化学习在稀疏奖励环境中的性能表现。

Abstract: Episodic rewards present a significant challenge in reinforcement learning. While intrinsic reward methods have demonstrated effectiveness in single-agent rein-forcement learning scenarios, their application to multi-agent reinforcement learn-ing (MARL) remains problematic. The primary difficulties stem from two fac-tors: (1) the exponential sparsity of joint action trajectories that lead to rewards as the exploration space expands, and (2) existing methods often fail to account for joint actions that can influence team states. To address these challenges, this paper introduces Mutual Intrinsic Reward (MIR), a simple yet effective enhancement strategy for MARL with extremely sparse rewards like episodic rewards. MIR incentivizes individual agents to explore actions that affect their teammates, and when combined with original strategies, effectively stimulates team exploration and improves algorithm performance. For comprehensive experimental valida-tion, we extend the representative single-agent MiniGrid environment to create MiniGrid-MA, a series of MARL environments with sparse rewards. Our evalu-ation compares the proposed method against state-of-the-art approaches in the MiniGrid-MA setting, with experimental results demonstrating superior perfor-mance.

</details>


### [7] [Designing Domain-Specific Agents via Hierarchical Task Abstraction Mechanism](https://arxiv.org/abs/2511.17198)
*Kaiyu Li,Jiayu Wang,Zhi Wang,Hui Qiao,Weizhan Zhang,Deyu Meng,Xiangyong Cao*

Main category: cs.AI

TL;DR: 本文提出了一个基于分层任务抽象机制(HTAM)的新型智能体设计框架，专门解决通用智能体在专业领域(如遥感)中难以处理结构化工作流程的问题。该框架将多智能体系统组织成逻辑层次结构，与领域内在的任务依赖图相匹配。


<details>
  <summary>Details</summary>
Motivation: 通用智能体框架(如ReAct或角色扮演)在需要严格结构化工作流程的专业领域中表现不佳，特别是在遥感等需要专业工具和多步骤程序的领域。

Method: 引入分层任务抽象机制(HTAM)，将多智能体系统构建为逻辑层次结构，反映领域内在的任务依赖关系。每个层的子智能体在前一层输出上操作，确保程序正确性并将复杂问题分解为顺序层。

Result: 实验表明，基于HTAM框架的EarthAgent在复杂地理空间分析任务上显著优于现有的单智能体和多智能体系统。

Conclusion: 将智能体架构与领域内在任务结构对齐是构建稳健可靠的专业自主系统的关键步骤。

Abstract: LLM-driven agents, particularly those using general frameworks like ReAct or human-inspired role-playing, often struggle in specialized domains that necessitate rigorously structured workflows. Fields such as remote sensing, requiring specialized tools (e.g., correction, spectral indices calculation), and multi-step procedures (e.g., numerous intermediate products and optional steps), significantly challenge generalized approaches. To address this gap, we introduce a novel agent design framework centered on a Hierarchical Task Abstraction Mechanism (HTAM). Specifically, HTAM moves beyond emulating social roles, instead structuring multi-agent systems into a logical hierarchy that mirrors the intrinsic task-dependency graph of a given domain. This task-centric architecture thus enforces procedural correctness and decomposes complex problems into sequential layers, where each layer's sub-agents operate on the outputs of the preceding layers. We instantiate this framework as EarthAgent, a multi-agent system tailored for complex geospatial analysis. To evaluate such complex planning capabilities, we build GeoPlan-bench, a comprehensive benchmark of realistic, multi-step geospatial planning tasks. It is accompanied by a suite of carefully designed metrics to evaluate tool selection, path similarity, and logical completeness. Experiments show that EarthAgent substantially outperforms a range of established single- and multi-agent systems. Our work demonstrates that aligning agent architecture with a domain's intrinsic task structure is a critical step toward building robust and reliable specialized autonomous systems.

</details>


### [8] [Agentifying Agentic AI](https://arxiv.org/abs/2511.17332)
*Virginia Dignum,Frank Dignum*

Main category: cs.AI

TL;DR: 本文主张将AAMAS社区开发的BDI架构、通信协议、机制设计和制度建模等概念工具作为实现Agentic AI的基础，通过将自适应数据驱动方法与结构化推理协调模型相结合，构建具备能力、灵活性、透明度、合作性和问责性的智能体系统。


<details>
  <summary>Details</summary>
Motivation: Agentic AI需要为系统赋予持续自主性、推理和交互能力，这需要明确的认知、合作和治理模型作为补充，而现有AI方法在这方面存在不足。

Method: 利用AAMAS社区开发的BDI架构、通信协议、机制设计和制度建模等概念工具，将自适应数据驱动方法与结构化推理协调模型相结合。

Result: 提出了一个连接形式理论和实践自主性的智能体视角，为实现具备透明度、合作性和问责性的智能体系统指明了路径。

Conclusion: AAMAS社区的概念工具为构建真正意义上的Agentic AI系统提供了坚实基础，能够实现形式理论与实际自主性之间的有效衔接。

Abstract: Agentic AI seeks to endow systems with sustained autonomy, reasoning, and interaction capabilities. To realize this vision, its assumptions about agency must be complemented by explicit models of cognition, cooperation, and governance. This paper argues that the conceptual tools developed within the Autonomous Agents and Multi-Agent Systems (AAMAS) community, such as BDI architectures, communication protocols, mechanism design, and institutional modelling, provide precisely such a foundation. By aligning adaptive, data-driven approaches with structured models of reasoning and coordination, we outline a path toward agentic systems that are not only capable and flexible, but also transparent, cooperative, and accountable. The result is a perspective on agency that bridges formal theory and practical autonomy.

</details>


### [9] [That's not natural: The Impact of Off-Policy Training Data on Probe Performance](https://arxiv.org/abs/2511.17408)
*Nathalie Kirch,Samuel Dower,Adrians Skapars,Ekdeep Singh Lubana,Dmitrii Krasheninnikov*

Main category: cs.AI

TL;DR: 本文系统评估了使用合成数据和离策略数据对LLM行为探测泛化性能的影响，发现响应生成策略显著影响探测性能，离策略泛化成功可预测同策略泛化，欺骗和故意表现不佳的探测在真实监控场景中可能泛化失败。


<details>
  <summary>Details</summary>
Motivation: 由于许多LLM行为的自然示例稀少，研究人员不得不依赖合成或离策略的LLM响应来训练探测模型，需要评估这些数据对探测泛化性能的影响。

Method: 在八种不同的LLM行为上测试线性和注意力探测，使用多个LLM，比较不同响应生成策略对探测性能的影响。

Result: 发现响应生成策略显著影响探测性能，离策略数据成功泛化可预测同策略泛化，欺骗和故意表现不佳的探测可能泛化失败，训练数据域的偏移会导致更大的性能下降。

Conclusion: 在没有同策略数据的情况下，使用同域的离策略数据比使用不同域的同策略数据产生更可靠的探测，强调需要能更好处理LLM监控中分布偏移的方法。

Abstract: Probing has emerged as a promising method for monitoring Large Language Models (LLMs), enabling inference-time detection of concerning behaviours such as deception and sycophancy. However, natural examples of many behaviours are rare, forcing researchers to rely on synthetic or off-policy LLM responses for training probes. We systematically evaluate how the use of synthetic and off-policy data influences probe generalisation across eight distinct LLM behaviours. Testing linear and attention probes across multiple LLMs, we find that the response generation strategy can significantly affect probe performance, though the magnitude of this effect varies by behaviour. We find that successful generalisation from off-policy data, to test sets where the model is incentivised to produce the target behaviour, is predictive of successful on-policy generalisation. Leveraging this result, we predict that Deception and Sandbagging probes may fail to generalise from off-policy to on-policy data when used in real monitoring scenarios. Notably, shifts in the training data domain still cause even larger performance degradation, with different-domain test scores being consistently lower than the same-domain ones. These results indicate that, in the absence of on-policy data, using same-domain off-policy data yields more reliable probes than using on-policy data from a different domain, emphasizing the need for methods that can better handle distribution shifts in LLM monitoring.

</details>


### [10] [SRA-CP: Spontaneous Risk-Aware Selective Cooperative Perception](https://arxiv.org/abs/2511.17461)
*Jiaxi Liu,Chengyuan Ma,Hang Zhou,Weizhe Tang,Shixiao Liang,Haoyang Ding,Xiaopeng Li,Bin Ran*

Main category: cs.AI

TL;DR: 提出SRA-CP框架，通过风险感知选择性协作感知，在保持安全关键对象检测精度的同时大幅降低通信带宽需求


<details>
  <summary>Details</summary>
Motivation: 现有通用协作感知方法传输大量与驾驶安全无关的感知数据，超出可用通信带宽，且依赖预定义通信伙伴，不适合动态交通环境

Method: 采用去中心化协议，车辆持续广播轻量级感知覆盖摘要，仅在检测到风险相关盲区时启动针对性协作；包含感知风险识别模块和选择性信息交换融合模块

Result: 相比通用CP方法，SRA-CP在安全关键对象上AP损失小于1%，仅使用20%通信带宽；相比现有选择性CP方法，感知性能提升15%

Conclusion: SRA-CP框架有效解决了协作感知中的通信带宽和动态环境适应性问题，实现了高效的风险感知选择性协作

Abstract: Cooperative perception (CP) offers significant potential to overcome the limitations of single-vehicle sensing by enabling information sharing among connected vehicles (CVs). However, existing generic CP approaches need to transmit large volumes of perception data that are irrelevant to the driving safety, exceeding available communication bandwidth. Moreover, most CP frameworks rely on pre-defined communication partners, making them unsuitable for dynamic traffic environments. This paper proposes a Spontaneous Risk-Aware Selective Cooperative Perception (SRA-CP) framework to address these challenges. SRA-CP introduces a decentralized protocol where connected agents continuously broadcast lightweight perception coverage summaries and initiate targeted cooperation only when risk-relevant blind zones are detected. A perceptual risk identification module enables each CV to locally assess the impact of occlusions on its driving task and determine whether cooperation is necessary. When CP is triggered, the ego vehicle selects appropriate peers based on shared perception coverage and engages in selective information exchange through a fusion module that prioritizes safety-critical content and adapts to bandwidth constraints. We evaluate SRA-CP on a public dataset against several representative baselines. Results show that SRA-CP achieves less than 1% average precision (AP) loss for safety-critical objects compared to generic CP, while using only 20% of the communication bandwidth. Moreover, it improves the perception performance by 15% over existing selective CP methods that do not incorporate risk awareness.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [11] [Password Strength Analysis Through Social Network Data Exposure: A Combined Approach Relying on Data Reconstruction and Generative Models](https://arxiv.org/abs/2511.16716)
*Maurizio Atzori,Eleonora Calò,Loredana Caruccio,Stefano Cirillo,Giuseppe Polese,Giandomenico Solimando*

Main category: cs.CR

TL;DR: SODA ADVANCE是一个数据重建工具，通过整合社交媒体等公开数据来评估密码强度，并研究大型语言模型在密码生成和评估方面的能力与风险。实验表明LLMs能生成强密码并根据用户资料进行评估。


<details>
  <summary>Details</summary>
Motivation: 传统密码强度评估方法不足，用户倾向于使用易记但安全性低的密码，这增加了安全风险。

Method: 开发SODA ADVANCE工具，集成专门模块利用社交媒体等公开数据评估密码强度，并研究LLMs在密码生成和评估中的应用。

Result: 100名真实用户的实验评估显示，LLMs能生成强且个性化的密码，并能有效评估密码强度，特别是结合用户资料数据时。

Conclusion: LLMs在密码生成和评估方面具有潜力，特别是当能够利用用户资料信息时，但同时也需要考虑相关的安全风险。

Abstract: Although passwords remain the primary defense against unauthorized access, users often tend to use passwords that are easy to remember. This behavior significantly increases security risks, also due to the fact that traditional password strength evaluation methods are often inadequate. In this discussion paper, we present SODA ADVANCE, a data reconstruction tool also designed to enhance evaluation processes related to the password strength. In particular, SODA ADVANCE integrates a specialized module aimed at evaluating password strength by leveraging publicly available data from multiple sources, including social media platforms. Moreover, we investigate the capabilities and risks associated with emerging Large Language Models (LLMs) in evaluating and generating passwords, respectively. Experimental assessments conducted with 100 real users demonstrate that LLMs can generate strong and personalized passwords possibly defined according to user profiles. Additionally, LLMs were shown to be effective in evaluating passwords, especially when they can take into account user profile data.

</details>


### [12] [Membership Inference Attacks Beyond Overfitting](https://arxiv.org/abs/2511.16792)
*Mona Khalil,Alberto Blanco-Justicia,Najeeb Jebreel,Josep Domingo-Ferrer*

Main category: cs.CR

TL;DR: 本文研究了成员推理攻击的根本原因，发现即使没有过拟合的模型也会泄露训练数据隐私，特别是对类内异常样本。作者提出了针对这些易受攻击样本的防御策略。


<details>
  <summary>Details</summary>
Motivation: 成员推理攻击对机器学习模型的隐私构成严重威胁，传统防御方法如差分隐私往往导致准确性大幅下降。现有研究主要关注模型过拟合，但即使非过拟合模型也会泄露部分训练数据信息，这促使作者深入研究成员推理漏洞的根本原因。

Method: 通过实证分析非过拟合模型中易受成员推理攻击的训练样本特征，发现这些样本通常是类内异常值（如噪声样本或难以分类的样本）。基于此发现，作者提出了针对这些易受攻击样本的防御策略。

Result: 研究发现易受成员推理攻击的样本具有类内异常特征，这些样本在非过拟合模型中仍然存在隐私泄露风险。作者提出的防御策略能够有效保护这些易受攻击样本，增强机器学习模型的隐私保护能力。

Conclusion: 成员推理漏洞不仅源于模型过拟合，还与训练数据中异常样本的特性密切相关。针对这些易受攻击样本的防御策略可以更有效地保护隐私，同时避免传统方法带来的准确性损失。

Abstract: Membership inference attacks (MIAs) against machine learning (ML) models aim to determine whether a given data point was part of the model training data. These attacks may pose significant privacy risks to individuals whose sensitive data were used for training, which motivates the use of defenses such as differential privacy, often at the cost of high accuracy losses. MIAs exploit the differences in the behavior of a model when making predictions on samples it has seen during training (members) versus those it has not seen (non-members). Several studies have pointed out that model overfitting is the major factor contributing to these differences in behavior and, consequently, to the success of MIAs. However, the literature also shows that even non-overfitted ML models can leak information about a small subset of their training data. In this paper, we investigate the root causes of membership inference vulnerabilities beyond traditional overfitting concerns and suggest targeted defenses. We empirically analyze the characteristics of the training data samples vulnerable to MIAs in models that are not overfitted (and hence able to generalize). Our findings reveal that these samples are often outliers within their classes (e.g., noisy or hard to classify). We then propose potential defensive strategies to protect these vulnerable samples and enhance the privacy-preserving capabilities of ML models. Our code is available at https://github.com/najeebjebreel/mia_analysis.

</details>


### [13] [TICAL: Trusted and Integrity-protected Compilation of AppLications](https://arxiv.org/abs/2511.17070)
*Robert Krahn,Nikson Kanti Paul,Franz Gregor,Do Le Quoc,Andrey Brito,André Martin,Christof Fetzer*

Main category: cs.CR

TL;DR: Tical是一个实用的可信编译框架，在构建流水线中从源代码到最终可执行文件提供完整性保护和机密性。


<details>
  <summary>Details</summary>
Motivation: 现有硬件扩展方法主要关注运行时保护，但构建时的完整性和机密性保护同样重要，因为恶意注入的代码可能危及整个应用和系统。

Method: 利用TEEs作为运行时保护，并通过文件系统屏蔽和不可变审计日志增强TEEs，确保编译器链只能访问受信任的文件和中间输出。

Result: 评估显示Tical能够以可接受的性能开销保护整个CI/CD流水线的机密性和完整性。

Conclusion: Tical框架成功解决了构建流水线中的信任问题，为软件开发提供了端到端的安全保障。

Abstract: During the past few years, we have witnessed various efforts to provide confidentiality and integrity for applications running in untrusted environments such as public clouds. In most of these approaches, hardware extensions such as Intel SGX, TDX, AMD SEV, etc., are leveraged to provide encryption and integrity protection on process or VM level. Although all of these approaches increase the trust in the application at runtime, an often overlooked aspect is the integrity and confidentiality protection at build time, which is equally important as maliciously injected code during compilation can compromise the entire application and system.In this paper, we present Tical, a practical framework for trusted compilation that provides integrity protection and confidentiality in build pipelines from source code to the final executable. Our approach harnesses TEEs as runtime protection but enriches TEEs with file system shielding and an immutable audit log with version history to provide accountability. This way, we can ensure that the compiler chain can only access trusted files and intermediate output, such as object files produced by trusted processes. Our evaluation using micro- and macro-benchmarks shows that Tical can protect the confidentiality and integrity of whole CI/CD pipelines with an acceptable performance overhead.

</details>


### [14] [Constant-Size Cryptographic Evidence Structures for Regulated AI Workflows](https://arxiv.org/abs/2511.17118)
*Leo Kao*

Main category: cs.CR

TL;DR: 本文提出恒定大小的密码学证据结构，用于在受监管环境中为AI工作流提供可验证的审计证据。每个证据项是固定大小的密码学字段元组，支持与哈希链和Merkle树审计结构无缝集成。


<details>
  <summary>Details</summary>
Motivation: 为受监管AI工作流设计可验证的审计证据系统，解决证据存储大小和验证成本随事件数量线性增长的问题，满足临床试验管理、制药合规和医疗AI治理等领域的监管需求。

Method: 形式化受监管AI工作流模型，定义证据结构的语法和算法，提出基于抗碰撞哈希函数和标准数字签名方案的通用哈希-签名构造方法，并与哈希链日志、Merkle树锚定和可信执行环境集成。

Result: 实现了原型库并在商用硬件上进行微基准测试，证明恒定大小证据的每事件开销小且可预测，支持恒定大小存储和统一验证成本。

Conclusion: 恒定大小密码学证据结构为受监管AI工作流提供了高效、安全的审计解决方案，在存储效率和验证性能方面具有显著优势，适用于医疗AI等高度监管领域。

Abstract: This paper introduces constant-size cryptographic evidence structures, a general abstraction for representing verifiable audit evidence for AI workflows in regulated environments. Each evidence item is a fixed-size tuple of cryptographic fields, designed to (i) provide strong binding to workflow events and configurations, (ii) support constant-size storage and uniform verification cost per event, and (iii) compose cleanly with hash-chain and Merkle-based audit constructions. We formalize a simple model of regulated AI workflows, define syntax and algorithms for evidence structures, and articulate security goals such as audit integrity and non-equivocation. We present a generic hash-and-sign construction that instantiates this abstraction using a collision-resistant hash function and a standard digital signature scheme. We then show how to integrate the construction with hash-chained logs, Merkle-tree anchoring, and optionally trusted execution environments, and we analyze the asymptotic complexity of evidence generation and verification. Finally, we implement a prototype library and report microbenchmark results on commodity hardware, demonstrating that the per-event overhead of constant-size evidence is small and predictable. The design is informed by industrial experience with regulated AI systems at Codebat Technologies Inc., while the paper focuses on the abstraction, algorithms, and their security and performance characteristics, with implications for clinical trial management, pharmaceutical compliance, and medical AI governance.

</details>


### [15] [Steering in the Shadows: Causal Amplification for Activation Space Attacks in Large Language Models](https://arxiv.org/abs/2511.17194)
*Zhiyuan Xu,Stanislav Abaimov,Joseph Gardiner,Sana Belguith*

Main category: cs.CR

TL;DR: 本文发现LLM中间激活层存在因果放大效应，可通过敏感度缩放引导攻击实现行为控制，对白盒和供应链LLM部署构成安全威胁


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型通常通过审计数据、提示和拒绝策略来保证安全，但将前向传播视为实现细节。研究发现解码器LLM的中间激活层形成了脆弱的行为控制攻击面。

Method: 提出敏感度缩放引导(SSS)攻击方法：结合序列开始锚定和基于敏感度的强化，将有限扰动预算集中在最脆弱的层和标记上，利用残差流中的高增益区域进行渐进式激活级攻击。

Result: 在多个开源模型和四个行为维度上，SSS能诱导邪恶、幻觉、谄媚和情感的大幅偏移，同时保持高连贯性和通用能力。

Conclusion: 激活引导已成为白盒和供应链LLM部署的具体安全关切，需要重新考虑LLM安全审计的范围。

Abstract: Modern large language models (LLMs) are typically secured by auditing data, prompts, and refusal policies, while treating the forward pass as an implementation detail. We show that intermediate activations in decoder-only LLMs form a vulnerable attack surface for behavioral control. Building on recent findings on attention sinks and compression valleys, we identify a high-gain region in the residual stream where small, well-aligned perturbations are causally amplified along the autoregressive trajectory--a Causal Amplification Effect (CAE). We exploit this as an attack surface via Sensitivity-Scaled Steering (SSS), a progressive activation-level attack that combines beginning-of-sequence (BOS) anchoring with sensitivity-based reinforcement to focus a limited perturbation budget on the most vulnerable layers and tokens. We show that across multiple open-weight models and four behavioral axes, SSS induces large shifts in evil, hallucination, sycophancy, and sentiment while preserving high coherence and general capabilities, turning activation steering into a concrete security concern for white-box and supply-chain LLM deployments.

</details>


### [16] [Persistent BitTorrent Trackers](https://arxiv.org/abs/2511.17260)
*Francois Xavier Wicht,Zhengwei Tong,Shunfan Zhou,Hang Yin,Aviv Yaish*

Main category: cs.CR

TL;DR: 本文提出了一种基于区块链和可信执行环境的去中心化BitTorrent信誉系统，解决了传统私有追踪器的三大问题：信誉无法跨追踪器迁移、中心化服务器单点故障、上传统计自报告不可验证。


<details>
  <summary>Details</summary>
Motivation: 传统私有BitTorrent追踪器存在信誉无法迁移、中心化单点故障和自报告统计不可验证的问题，当追踪器关闭时用户会丢失贡献历史，无法向新社区证明信誉。

Method: 使用智能合约存储信誉，用加密证明替代自报告；接收方对传输片段签名，追踪器在可信执行环境中聚合验证后更新链上信誉；追踪器不可用时使用认证分布式哈希表进行发现，链上信誉作为公钥基础设施实现访问控制。

Result: 原型系统在Intel TDX上评估显示，传输收据仅增加不到6%的开销，签名聚合使验证速度提升2.5倍。

Conclusion: 该设计能够持久保存信誉，抵御追踪器故障，并通过工厂部署合约中的单跳迁移实现信誉的可移植性，在标准密码学假设下证明了安全性。

Abstract: Private BitTorrent trackers enforce upload-to-download ratios to prevent free-riding, but suffer from three critical weaknesses: reputation cannot move between trackers, centralized servers create single points of failure, and upload statistics are self-reported and unverifiable. When a tracker shuts down (whether by operator choice, technical failure, or legal action) users lose their contribution history and cannot prove their standing to new communities. We address these problems by storing reputation in smart contracts and replacing self-reports with cryptographic attestations. Receiving peers sign receipts for transferred pieces, which the tracker aggregates and verifies before updating on-chain reputation. Trackers run in Trusted Execution Environments (TEEs) to guarantee correct aggregation and prevent manipulation of state. If a tracker is unavailable, peers use an authenticated Distributed Hash Table (DHT) for discovery: the on-chain reputation acts as a Public Key Infrastructure (PKI), so peers can verify each other and maintain access control without the tracker. This design persists reputation across tracker failures and makes it portable to new instances through single-hop migration in factory-deployed contracts. We formalize the security requirements, prove correctness under standard cryptographic assumptions, and evaluate a prototype on Intel TDX. Measurements show that transfer receipts adds less than 6\% overhead with typical piece sizes, and signature aggregation speeds up verification by $2.5\times$.

</details>


### [17] [A Patient-Centric Blockchain Framework for Secure Electronic Health Record Management: Decoupling Data Storage from Access Control](https://arxiv.org/abs/2511.17464)
*Tanzim Hossain Romel,Kawshik Kumar Paul,Tanberul Islam Ruhan,Maisha Rahman Mim,Abu Sayed Md. Latiful Hoque*

Main category: cs.CR

TL;DR: 提出了一种以患者为中心的电子健康记录共享架构，使用区块链记录加密承诺和患者签名的时间限制权限，实现内容存储与授权审计的分离。


<details>
  <summary>Details</summary>
Motivation: 旨在恢复患者对健康数据的控制权，同时保护临床敏感数据所需的安全属性，解决传统EHR共享中的隐私和控制问题。

Method: 采用链下存储加密FHIR资源，链上记录加密承诺和患者签名权限的架构；使用EIP-712标准进行权限签名，公钥包装分发密钥；提供Solidity参考实现作为单患者合约。

Result: 权限授予的链上成本平均78,000 gas（L1），1MB记录的端到端访问延迟为0.7-1.4秒；Layer-2部署可将gas使用减少10-13倍。

Conclusion: 该架构为恢复患者控制权提供了一条实用路径，同时保持了敏感临床数据所需的安全属性，讨论了元数据隐私、密钥注册要求和HIPAA/GDPR监管考虑。

Abstract: We present a patient-centric architecture for electronic health record (EHR) sharing that separates content storage from authorization and audit. Encrypted FHIR resources are stored off-chain; a public blockchain records only cryptographic commitments and patient-signed, time-bounded permissions using EIP-712. Keys are distributed via public-key wrapping, enabling storage providers to remain honest-but-curious without risking confidentiality. We formalize security goals (confidentiality, integrity, cryptographically attributable authorization, and auditability of authorization events) and provide a Solidity reference implementation deployed as single-patient contracts. On-chain costs for permission grants average 78,000 gas (L1), and end-to-end access latency for 1 MB records is 0.7--1.4s (mean values for S3 and IPFS respectively), dominated by storage retrieval. Layer-2 deployment reduces gas usage by 10--13x, though data availability charges dominate actual costs. We discuss metadata privacy, key registry requirements, and regulatory considerations (HIPAA/GDPR), demonstrating a practical route to restoring patient control while preserving security properties required for sensitive clinical data.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [18] [NX-CGRA: A Programmable Hardware Accelerator for Core Transformer Algorithms on Edge Devices](https://arxiv.org/abs/2511.17235)
*Rohit Prasad*

Main category: cs.AR

TL;DR: NX-CGRA是一种可编程硬件加速器，采用粗粒度可重构阵列架构，支持多种Transformer推理算法，在边缘计算场景下实现性能、能效和架构灵活性的平衡。


<details>
  <summary>Details</summary>
Motivation: 边缘计算中Transformer工作负载的多样性和复杂性日益增加，需要在性能、能效和架构灵活性之间取得平衡，而固定功能加速器无法满足这种需求。

Method: 采用粗粒度可重构阵列架构，具有软件驱动的可编程性，能够高效执行各种内核模式，包括线性和非线性函数。

Result: 使用真实Transformer模型的代表性基准测试进行评估，展示了高整体效率和在不同操作类别上的良好能效-面积权衡。

Conclusion: NX-CGRA作为一种可扩展和适应性强的硬件解决方案，在受限的功耗和硅预算下具有边缘Transformer部署的潜力。

Abstract: The increasing diversity and complexity of transformer workloads at the edge present significant challenges in balancing performance, energy efficiency, and architectural flexibility. This paper introduces NX-CGRA, a programmable hardware accelerator designed to support a range of transformer inference algorithms, including both linear and non-linear functions. Unlike fixed-function accelerators optimized for narrow use cases, NX-CGRA employs a coarse-grained reconfigurable array (CGRA) architecture with software-driven programmability, enabling efficient execution across varied kernel patterns. The architecture is evaluated using representative benchmarks derived from real-world transformer models, demonstrating high overall efficiency and favorable energy-area tradeoffs across different classes of operations. These results indicate the potential of NX-CGRA as a scalable and adaptable hardware solution for edge transformer deployment under constrained power and silicon budgets.

</details>


### [19] [DISCA: A Digital In-memory Stochastic Computing Architecture Using A Compressed Bent-Pyramid Format](https://arxiv.org/abs/2511.17265)
*Shady Agwa,Yikang Shen,Shiwei Wang,Themis Prodromakis*

Main category: cs.AR

TL;DR: 提出了一种新的数字内存随机计算架构DISCA，采用压缩的准随机Bent-Pyramid数据格式，在保持数字系统可扩展性和可靠性的同时，实现了类似模拟计算的计算简单性。


<details>
  <summary>Details</summary>
Motivation: 传统冯·诺依曼架构面临内存墙和摩尔定律终结的挑战，而现有内存计算架构由于设计限制导致性能大幅下降。AI应用向边缘迁移对硬件预算提出更多约束，需要更高效的矩阵乘法解决方案。

Method: 设计数字内存随机计算架构DISCA，使用压缩的准随机Bent-Pyramid数据格式，结合模拟计算的计算简单性和数字系统的可扩展性、可靠性优势。

Result: 后布局建模结果显示，在商用180nm CMOS技术下，DISCA在500MHz频率下达到每比特3.59 TOPS/W的能效。与对应架构相比，矩阵乘法工作负载的能效提高了数量级。

Conclusion: DISCA架构显著提升了矩阵乘法工作负载的能效，为解决AI边缘计算中的内存墙问题提供了有前景的解决方案。

Abstract: Nowadays, we are witnessing an Artificial Intelligence revolution that dominates the technology landscape in various application domains, such as healthcare, robotics, automotive, security, and defense. Massive-scale AI models, which mimic the human brain's functionality, typically feature millions and even billions of parameters through data-intensive matrix multiplication tasks. While conventional Von-Neumann architectures struggle with the memory wall and the end of Moore's Law, these AI applications are migrating rapidly towards the edge, such as in robotics and unmanned aerial vehicles for surveillance, thereby adding more constraints to the hardware budget of AI architectures at the edge. Although in-memory computing has been proposed as a promising solution for the memory wall, both analog and digital in-memory computing architectures suffer from substantial degradation of the proposed benefits due to various design limitations. We propose a new digital in-memory stochastic computing architecture, DISCA, utilizing a compressed version of the quasi-stochastic Bent-Pyramid data format. DISCA inherits the same computational simplicity of analog computing, while preserving the same scalability, productivity, and reliability of digital systems. Post-layout modeling results of DISCA show an energy efficiency of 3.59 TOPS/W per bit at 500 MHz using a commercial 180nm CMOS technology. Therefore, DISCA significantly improves the energy efficiency for matrix multiplication workloads by orders of magnitude if scaled and compared to its counterpart architectures.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [20] [MicroMoE: Fine-Grained Load Balancing for Mixture-of-Experts with Token Scheduling](https://arxiv.org/abs/2511.16947)
*Chenqi Zhao,Wenfei Wu,Linhai Song,Yuchen Xu*

Main category: cs.DC

TL;DR: 提出MicroEP并行化策略和MicroMoE系统，解决MoE训练中的负载不均衡问题，实现细粒度负载平衡，显著提升训练效率


<details>
  <summary>Details</summary>
Motivation: MoE模型在扩展深度学习模型方面具有优势，但其动态特性导致专家间负载不均衡，严重影响训练效率。现有解决方案要么牺牲模型精度，要么引入额外系统开销，无法实现细粒度负载平衡

Method: 提出MicroEP并行化策略，通过跨GPU的高效token调度在每个微批次中实现最优负载平衡。基于此构建MicroMoE分布式MoE训练系统

Result: 实验结果显示，MicroMoE相比最先进系统将端到端训练吞吐量提升高达47.6%，几乎始终实现GPU间最优负载平衡

Conclusion: MicroEP和MicroMoE有效解决了MoE训练中的负载不均衡问题，实现了细粒度负载平衡，显著提升了训练效率

Abstract: Mixture-of-Experts (MoE) has emerged as a promising approach to scale up deep learning models due to its significant reduction in computational resources. However, the dynamic nature of MoE leads to load imbalance among experts, severely impacting training efficiency. While previous research has attempted to address the load balancing challenge, existing solutions either compromise model accuracy or introduce additional system overhead. As a result, they fail to achieve fine-grained load balancing, which is crucial to optimizing training efficiency.
  We propose MicroEP, a novel parallelization strategy to achieve fine-grained load balancing in MoE systems. MicroEP is capable of achieving optimal load balancing in every micro-batch through efficient token scheduling across GPUs. Furthermore, we propose MicroMoE, an efficient distributed MoE training system with MicroEP's load balancing capabilities. Our experimental results demonstrate that MicroMoE improves the end-to-end training throughput by up to 47.6% compared with the state-of-the-art system, and almost consistently achieves optimal load balance among GPUs.

</details>

<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 5]
- [cs.DC](#cs.DC) [Total: 2]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Self-Purification Mitigates Backdoors in Multimodal Diffusion Language Models](https://arxiv.org/abs/2602.22246)
*Guangnian Wan,Qi Li,Gongfan Fang,Xinyin Ma,Xinchao Wang*

Main category: cs.CR

TL;DR: 本文提出DiSP框架，通过选择性掩码视觉token和自净化数据来防御多模态扩散语言模型的后门攻击，无需辅助模型或干净数据即可将攻击成功率从90%以上降至5%以下。


<details>
  <summary>Details</summary>
Motivation: 多模态扩散语言模型（MDLMs）作为自回归模型的有力竞争者，其后门攻击脆弱性尚未得到充分研究。虽然现有数据投毒方法能成功植入后门，但针对这类模型的有效防御策略仍然缺乏。

Method: 提出DiSP（Diffusion Self-Purification）防御框架，核心观察是：在推理时选择性掩码某些视觉token可以中和后门模型的触发行为。基于此，使用被攻击模型自身净化中毒数据集，然后在净化数据上微调模型以恢复为干净模型。

Result: 实验表明，DiSP能有效缓解后门效应，将攻击成功率从超过90%降至通常低于5%，同时在良性任务上保持模型性能。该方法无需辅助模型或干净参考数据。

Conclusion: DiSP框架为多模态扩散语言模型提供了有效的后门防御解决方案，通过模型自净化的方式在不依赖外部资源的情况下成功移除后门，为这类模型的安全性提供了重要保障。

Abstract: Multimodal Diffusion Language Models (MDLMs) have recently emerged as a competitive alternative to their autoregressive counterparts. Yet their vulnerability to backdoor attacks remains largely unexplored. In this work, we show that well-established data-poisoning pipelines can successfully implant backdoors into MDLMs, enabling attackers to manipulate model behavior via specific triggers while maintaining normal performance on clean inputs. However, defense strategies effective to these models are yet to emerge. To bridge this gap, we introduce a backdoor defense framework for MDLMs named DiSP (Diffusion Self-Purification). DiSP is driven by a key observation: selectively masking certain vision tokens at inference time can neutralize a backdoored model's trigger-induced behaviors and restore normal functionality. Building on this, we purify the poisoned dataset using the compromised model itself, then fine-tune the model on the purified data to recover it to a clean one. Given such a specific design, DiSP can remove backdoors without requiring any auxiliary models or clean reference data. Extensive experiments demonstrate that our approach effectively mitigates backdoor effects, reducing the attack success rate (ASR) from over 90% to typically under 5%, while maintaining model performance on benign tasks.

</details>


### [2] [Layer-Targeted Multilingual Knowledge Erasure in Large Language Models](https://arxiv.org/abs/2602.22562)
*Taoran Li,Varun Chandrasekaran,Zhiyuan Yu*

Main category: cs.CR

TL;DR: 研究发现大语言模型机器遗忘在跨语言泛化上失败，提出干预深度是关键因素，开发了MUTE框架通过识别语言无关层实现多语言知识擦除


<details>
  <summary>Details</summary>
Motivation: 现有研究表明大语言模型的机器遗忘在跨语言泛化上存在失败：在一个语言中擦除的知识经常在其他语言中仍然可访问。然而，这种失败的根本原因和原则性解决方案仍然未知

Method: 通过系统性的分层实验，识别干预深度为关键因素。提出MUTE框架，使用中心核对齐和语言区域发展分数来识别中间、语言无关的层，在这些层中跨语言表示收敛，并将遗忘更新限制在这些层

Result: 实验发现两种不同的失败模式：浅层干预实现擦除但破坏保留语言的多语言能力；深层干预保留效用但即使在源语言中也无法擦除目标知识。MUTE框架在三种LLM架构和三种遗忘算法上验证有效，通过Logit Lens探测确认了真正的知识移除而非输出级抑制

Conclusion: 干预层的选择不是自由参数，它从根本上决定多语言遗忘是否成功。MUTE框架通过识别语言无关层实现了稳健的多语言知识擦除，同时仅优化少量源语言

Abstract: Recent work has demonstrated that machine unlearning in Large Language Models (LLMs) fails to generalize across languages: knowledge erased in one language frequently remains accessible through others. However, the underlying cause of this failure and a principled solution remain open. In this work, we identify intervention depth as the key factor determining multilingual generalization. Through systematic layer-wise experiments, we characterize two distinct failure modes: shallow-layer interventions achieve erasure but collapse multilingual capabilities in held-out languages, while deep-layer interventions preserve utility but fail to erase target knowledge even in source languages. These findings reveal that the choice of intervention layer is not a free parameter; it fundamentally determines whether multilingual unlearning succeeds. We propose MUTE (Multilingual Unlearning via Targeted Erasure), a framework that uses Centered Kernel Alignment (CKA) and Linguistic Regions Development Score (LRDS) to identify intermediate, language-agnostic layers where cross-lingual representations converge. By restricting unlearning updates to these layers, MUTE achieves robust multilingual knowledge erasure while optimizing on only a small set of source languages. Extensive experiments across three LLM architectures and three unlearning algorithms validate our approach, with mechanistic analysis via Logit Lens probing confirming genuine knowledge removal rather than output-level suppression.

</details>


### [3] [DPSQL+: A Differentially Private SQL Library with a Minimum Frequency Rule](https://arxiv.org/abs/2602.22699)
*Tomoya Matsumoto,Shokichi Takakura,Shun Takagi,Satoshi Hasegawa*

Main category: cs.CR

TL;DR: DPSQL+是一个隐私保护的SQL库，同时强制执行用户级差分隐私和最小频率规则，通过模块化架构实现安全查询处理。


<details>
  <summary>Details</summary>
Motivation: SQL作为数据分析的标准接口，直接发布查询结果可能通过成员或属性推断攻击暴露敏感信息。差分隐私提供理论保障，但单独使用无法满足治理要求中的最小频率规则（要求每个发布组至少包含k个不同个体的贡献）。

Method: DPSQL+采用模块化架构：1)验证器静态限制查询到DP安全的SQL子集；2)会计师一致跟踪跨多个查询的累积隐私损失；3)后端接口与各种数据库引擎连接，确保可移植性和可扩展性。

Result: 在TPC-H基准测试中，DPSQL+在广泛的分析工作负载（从基本聚合到二次统计和连接操作）上实现了实用的准确性，并且在固定的全局隐私预算下，比评估中的先前库允许更多的查询。

Conclusion: DPSQL+成功地将用户级差分隐私与最小频率规则相结合，提供了一个实用的隐私保护SQL解决方案，在保持隐私保障的同时支持复杂的数据分析工作负载。

Abstract: SQL is the de facto interface for exploratory data analysis; however, releasing exact query results can expose sensitive information through membership or attribute inference attacks. Differential privacy (DP) provides rigorous privacy guarantees, but in practice, DP alone may not satisfy governance requirements such as the \emph{minimum frequency rule}, which requires each released group (cell) to include contributions from at least $k$ distinct individuals. In this paper, we present \textbf{DPSQL+}, a privacy-preserving SQL library that simultaneously enforces user-level $(\varepsilon,δ)$-DP and the minimum frequency rule. DPSQL+ adopts a modular architecture consisting of: (i) a \emph{Validator} that statically restricts queries to a DP-safe subset of SQL; (ii) an \emph{Accountant} that consistently tracks cumulative privacy loss across multiple queries; and (iii) a \emph{Backend} that interfaces with various database engines, ensuring portability and extensibility. Experiments on the TPC-H benchmark demonstrate that DPSQL+ achieves practical accuracy across a wide range of analytical workloads -- from basic aggregates to quadratic statistics and join operations -- and allows substantially more queries under a fixed global privacy budget than prior libraries in our evaluation.

</details>


### [4] [SettleFL: Trustless and Scalable Reward Settlement Protocol for Federated Learning on Permissionless Blockchains (Extended version)](https://arxiv.org/abs/2602.23167)
*Shuang Liang,Yang Hua,Linshan Jiang,Peishen Yan,Tao Song,Bin Yao,Haibing Guan*

Main category: cs.CR

TL;DR: SettleFL是一个去中心化的联邦学习奖励结算协议，通过两种可互操作策略解决区块链成本与模型训练高频迭代之间的矛盾，实现可扩展的信任最小化结算。


<details>
  <summary>Details</summary>
Motivation: 在开放联邦学习环境中，缺乏中央权威机构需要去中心化奖励结算，但无许可区块链的高昂成本与模型训练的高频迭代特性直接冲突。现有解决方案要么牺牲去中心化，要么因线性链上成本而面临可扩展性瓶颈。

Method: 提出SettleFL协议，采用共享领域特定电路架构，提供两种可互操作策略：1) Commit-and-Challenge变体，通过乐观执行和争议驱动仲裁最小化链上成本；2) Commit-with-Proof变体，通过每轮有效性证明保证即时最终性。该设计允许协议灵活适应不同的延迟和成本约束，同时在没有可信协调的情况下强制执行理性鲁棒性。

Result: 结合真实联邦学习工作负载和受控模拟的广泛实验表明，SettleFL在扩展到800名参与者时仍保持实用性，实现了显著降低的gas成本。

Conclusion: SettleFL通过创新的协议设计解决了去中心化联邦学习奖励结算中的可扩展性和成本问题，为开放联邦学习环境提供了信任最小化且经济高效的解决方案。

Abstract: In open Federated Learning (FL) environments where no central authority exists, ensuring collaboration fairness relies on decentralized reward settlement, yet the prohibitive cost of permissionless blockchains directly clashes with the high-frequency, iterative nature of model training. Existing solutions either compromise decentralization or suffer from scalability bottlenecks due to linear on-chain costs. To address this, we present SettleFL, a trustless and scalable reward settlement protocol designed to minimize total economic friction by offering a family of two interoperable protocols. Leveraging a shared domain-specific circuit architecture, SettleFL offers two interoperable strategies: (1) a Commit-and-Challenge variant that minimizes on-chain costs via optimistic execution and dispute-driven arbitration, and (2) a Commit-with-Proof variant that guarantees instant finality through per-round validity proofs. This design allows the protocol to flexibly adapt to varying latency and cost constraints while enforcing rational robustness without trusted coordination. We conduct extensive experiments combining real FL workloads and controlled simulations. Results show that SettleFL remains practical when scaling to 800 participants, achieving substantially lower gas cost.

</details>


### [5] [Strengthening security and noise resistance in one-way quantum key distribution protocols through hypercube-based quantum walks](https://arxiv.org/abs/2602.23261)
*David Polzoni,Tommaso Bianchi,Mauro Conti*

Main category: cs.CR

TL;DR: 本文提出了一种基于超立方体拓扑的量子行走QKD协议，相比现有的环形拓扑协议，在相同参数下显著提升了安全性和抗噪能力，并开发了开源仿真框架。


<details>
  <summary>Details</summary>
Motivation: 传统BB84等量子密钥分发协议虽然简单，但对窃听抵抗能力有限，在现实噪声条件下性能不佳。量子行走技术为增强QKD方案提供了新途径，但现有研究多基于环形拓扑，需要探索更优的拓扑结构来提升安全性和抗噪性。

Method: 1. 提出基于超立方体拓扑的量子行走QKD协议，其安全性完全依赖于量子行走拓扑而非协议细节；2. 开发了高效可扩展的单向QKD协议仿真框架，支持环形和超立方体两种拓扑；3. 使用IBM Qiskit实现，支持现实噪声模型下的噪声感知分析。

Result: 在相同参数下，超立方体拓扑相比环形拓扑（当前最优）提供了显著增强的安全性和噪声抵抗能力，有效加强了对抗窃听的保护。同时发布了完整的开源仿真框架。

Conclusion: 基于超立方体拓扑的量子行走QKD协议在安全性和抗噪性方面优于现有环形拓扑方案。开发的仿真框架为拓扑感知的QKD协议设计奠定了基础，结合了增强的噪声容忍度和拓扑驱动的安全性。

Abstract: Quantum Key Distribution (QKD) is a foundational cryptographic protocol that ensures information-theoretic security. However, classical protocols such as BB84, though favored for their simplicity, offer limited resistance to eavesdropping, and perform poorly under realistic noise conditions. Recent research has explored the use of discrete-time Quantum Walks (QWs) to enhance QKD schemes. In this work, we specifically focus on a one-way QKD protocol, where security depends exclusively on the underlying Quantum Walk (QW) topology, rather than the details of the protocol itself. Our paper introduces a novel protocol based on QWs over a hypercube topology and demonstrates that, under identical parameters, it provides significantly enhanced security and noise resistance compared to the circular topology (i.e., state-of-the-art), thereby strengthening protection against eavesdropping. Furthermore, we introduce an efficient and extensible simulation framework for one-way QKD protocols based on QWs, supporting both circular and hypercube topologies. Implemented with IBM's software development kit for quantum computing (i.e., Qiskit), our toolkit enables noise-aware analysis under realistic noise models. To support reproducibility and future developments, we release our entire simulation framework as open-source. This contribution establishes a foundation for the design of topology-aware QKD protocols that combine enhanced noise tolerance with topologically driven security.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [6] [An Artificial Intelligence Framework for Joint Structural-Temporal Load Forecasting in Cloud Native Platforms](https://arxiv.org/abs/2602.22780)
*Qingyuan Zhang*

Main category: cs.DC

TL;DR: 提出面向微服务拓扑的结构化时序联合负载预测框架，通过多粒度融合和结构先验增强，解决云原生环境中微服务调用关系复杂、负载波动多尺度叠加的问题。


<details>
  <summary>Details</summary>
Motivation: 云原生环境中微服务调用关系复杂，负载波动具有多尺度叠加特性，跨服务影响显著，传统负载预测方法难以有效建模这些复杂依赖关系。

Method: 将系统表示为时间演化的服务调用图与多元负载序列的耦合实体，构建基于服务级别观测的邻域聚合和全局汇总视图，形成实例、服务和集群三个层次的负载表示。使用统一序列编码器建模多尺度历史上下文，在注意力计算中引入轻量级结构先验以增强调用依赖表达。

Result: 通过单因素敏感性分析验证了多粒度融合和结构注入的必要性，明确了时间窗口长度、编码深度和正则化强度等关键超参数的有效配置范围。

Conclusion: 该框架为云环境中的容量评估、资源编排和运行时态势理解提供了可重用的建模范式和实现路径，能够更有效地捕获调用链上的负载传播和累积，同时保持对局部突发和整体趋势的一致性建模。

Abstract: This study targets cloud native environments where microservice invocation relations are complex, load fluctuations are multi-scale and superimposed, and cross-service impacts are significant. We propose a structured temporal joint load prediction framework oriented to microservice topology. The method represents the system as a coupled entity of a time-evolving service invocation graph and multivariate load sequences. It constructs neighborhood-aggregated and global summarized views based on service level observations. This forms layered load representations across instance, service, and cluster levels. A unified sequence encoder models multi-scale historical context. To strengthen the expression of invocation dependencies, the framework introduces a lightweight structural prior into attention computation. This enables more effective capture of load propagation and accumulation along invocation chains, while maintaining consistent modeling of local bursts and overall trends. The training objective adopts a multi-objective regression strategy that jointly optimizes service level and cluster level predictions to improve cross-granularity stability. We further conduct single-factor sensitivity analyses on key structural and training hyperparameters. We systematically examine the effects of time window length, encoding depth, and regularization strength. The results support the necessity of multi-granularity fusion and structural injection and clarify their effective configuration ranges. Overall, the framework provides a reusable modeling paradigm and implementation path for capacity assessment, resource orchestration, and runtime situational understanding in cloud environments.

</details>


### [7] [Workload Buoyancy: Keeping Apps Afloat by Identifying Shared Resource Bottlenecks](https://arxiv.org/abs/2602.22852)
*Oliver Larsson,Thijs Metsch,Cristian Klein,Erik Elmroth*

Main category: cs.DC

TL;DR: 本文提出了一种名为"浮力"的新抽象概念，用于在多租户异构计算环境中表征工作负载性能，通过整合应用级指标和系统级资源争用洞察，提供更准确的工作负载性能评估。


<details>
  <summary>Details</summary>
Motivation: 现代多租户异构计算环境中，传统的工作负载性能评估方法（如CPU利用率或应用级指标）往往无法捕捉资源争用和"噪声邻居"效应带来的复杂性能动态，导致性能瓶颈难以诊断和预测。

Method: 提出"浮力"抽象概念，整合应用级性能指标和系统级共享资源争用洞察，显式捕获跨多个资源的瓶颈和余量，提供更全面的性能动态视图。

Result: 与传统启发式方法相比，浮力在瓶颈指示方面平均提高了19.3%，能够更好地暴露性能限制性资源交互，可作为传统性能指标的替代方案，改善可观测性和调度决策。

Conclusion: 浮力提供了一种直观、可扩展且可泛化的抽象，能够促进资源感知和应用程序感知的编排，在多租户异构计算环境中实现更有效的性能管理和优化。

Abstract: Modern multi-tenant, hardware-heterogeneous computing environments pose significant challenges for effective workload orchestration. Simple heuristics for assessing workload performance, such as CPU utilization or application-level metrics, are often insufficient to capture the complex performance dynamics arising from resource contention and noisy-neighbor effects. In such environments, performance bottlenecks may emerge in any shared system resource, leading to unexpected and difficult-to-diagnose degradation.
  This paper introduces buoyancy, a novel abstraction for characterizing workload performance in multi-tenant systems. Unlike traditional approaches, buoyancy integrates application-level metrics with system-level insights of shared resource contention to provide a holistic view of performance dynamics. By explicitly capturing bottlenecks and headroom across multiple resources, buoyancy facilitates resource-aware and application-aware orchestration in a manner that is intuitive, extensible, and generalizable across heterogeneous platforms. We evaluate buoyancy using representative multi-tenant workloads to illustrate its ability to expose performance-limiting resource interactions. Buoyancy provides a 19.3% better indication of bottlenecks compared to traditional heuristics on average. We additionally show how buoyancy can act as a drop-in replacement for conventional performance metrics, enabling improved observability and more informed scheduling and optimization decisions.

</details>

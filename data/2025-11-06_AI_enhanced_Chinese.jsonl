{"id": "2511.02841", "categories": ["cs.CR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.02841", "abs": "https://arxiv.org/abs/2511.02841", "authors": ["Sandro Rodriguez Garzon", "Awid Vaziry", "Enis Mert Kuzu", "Dennis Enrique Gehrmann", "Buse Varkan", "Alexander Gaballa", "Axel K\u00fcpper"], "title": "AI Agents with Decentralized Identifiers and Verifiable Credentials", "comment": "This work has been submitted to SCITEPRESS for possible publication", "summary": "LLM-based AI agents still lack the technical means to automatically build\nnuanced and differentiated trust in other agents at the beginning of an\nagent-to-agent dialogue. But autonomous and interoperable trust establishing\nbecomes a fundamental prerequisite once agents start to operate beyond isolated\nenvironments and engage in dialogues across individual or organizational\nboundaries. A promising way to fill this gap in Agentic AI is to equip agents\nwith long-lived digital identities and introduce tamper-proof and flexible\nidentity-bound attestations of agents, provisioned by commonly trusted third\nparties and designed for cross-domain verifiability. This article presents a\nconceptual framework and a prototypical multi-agent system, where each agent is\nendowed with a self-sovereign digital identity. It combines a unique and\nledger-anchored Decentralized Identifier (DID) of an agent with a set of\nthird-party issued Verifiable Credentials (VCs). This enables agents at the\nstart of a dialog to prove ownership of their self-controlled DIDs for\nauthentication purposes and to establish various cross-domain trust\nrelationships through the spontaneous exchange of their self-hosted DID-bound\nVCs. A comprehensive evaluation of the prototypical implementation demonstrates\ntechnical feasibility but also reveals limitations once an agent's LLM is in\nsole charge to control the respective security procedures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u81ea\u7ba1\u7406\u6570\u5b57\u8eab\u4efd\u7684\u591a\u667a\u80fd\u4f53\u4fe1\u4efb\u5efa\u7acb\u6846\u67b6\uff0c\u901a\u8fc7\u53bb\u4e2d\u5fc3\u5316\u6807\u8bc6\u7b26\u548c\u53ef\u9a8c\u8bc1\u51ed\u8bc1\u5b9e\u73b0\u8de8\u57df\u4fe1\u4efb\u5173\u7cfb\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684AI\u667a\u80fd\u4f53\u5728\u5bf9\u8bdd\u5f00\u59cb\u65f6\u7f3a\u4e4f\u81ea\u52a8\u5efa\u7acb\u7ec6\u7c92\u5ea6\u4fe1\u4efb\u7684\u6280\u672f\u624b\u6bb5\uff0c\u800c\u8de8\u7ec4\u7ec7\u8fb9\u754c\u7684\u81ea\u4e3b\u4e92\u64cd\u4f5c\u4fe1\u4efb\u5efa\u7acb\u662f\u667a\u80fd\u4f53\u5728\u975e\u9694\u79bb\u73af\u5883\u4e2d\u8fd0\u884c\u7684\u57fa\u672c\u524d\u63d0\u3002", "method": "\u4e3a\u6bcf\u4e2a\u667a\u80fd\u4f53\u914d\u5907\u81ea\u7ba1\u7406\u6570\u5b57\u8eab\u4efd\uff0c\u7ed3\u5408\u8d26\u672c\u951a\u5b9a\u7684\u53bb\u4e2d\u5fc3\u5316\u6807\u8bc6\u7b26\u548c\u7b2c\u4e09\u65b9\u9881\u53d1\u7684\u53ef\u9a8c\u8bc1\u51ed\u8bc1\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5728\u5bf9\u8bdd\u5f00\u59cb\u65f6\u8bc1\u660e\u8eab\u4efd\u6240\u6709\u6743\u5e76\u901a\u8fc7\u4ea4\u6362\u51ed\u8bc1\u5efa\u7acb\u8de8\u57df\u4fe1\u4efb\u5173\u7cfb\u3002", "result": "\u539f\u578b\u7cfb\u7edf\u8bc4\u4f30\u8bc1\u660e\u4e86\u6280\u672f\u53ef\u884c\u6027\uff0c\u4f46\u4e5f\u63ed\u793a\u4e86\u5f53\u667a\u80fd\u4f53\u7684LLM\u5355\u72ec\u63a7\u5236\u5b89\u5168\u7a0b\u5e8f\u65f6\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u81ea\u7ba1\u7406\u6570\u5b57\u8eab\u4efd\u4e0e\u53ef\u9a8c\u8bc1\u51ed\u8bc1\u7684\u7ed3\u5408\u4e3aAI\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8de8\u57df\u4fe1\u4efb\u5efa\u7acb\u673a\u5236\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u89e3\u51b3LLM\u5355\u72ec\u63a7\u5236\u5b89\u5168\u7a0b\u5e8f\u7684\u95ee\u9898\u3002"}}
{"id": "2511.03029", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03029", "abs": "https://arxiv.org/abs/2511.03029", "authors": ["Kajol Kulkarni", "Samuel Kemmler", "Anna Schwarz", "Gulcin Gedik", "Yanxiang Chen", "Dimitrios Papageorgiou", "Ioannis Kavroulakis", "Roman Iakymchuk"], "title": "Harvesting energy consumption on European HPC systems: Sharing Experience from the CEEC project", "comment": "10 pages, 11 figures, conference", "summary": "Energy efficiency has emerged as a central challenge for modern\nhigh-performance computing (HPC) systems, where escalating computational\ndemands and architectural complexity have led to significant energy footprints.\nThis paper presents the collective experience of the EuroHPC JU Center of\nExcellence in Exascale CFD (CEEC) in measuring, analyzing, and optimizing\nenergy consumption across major European HPC systems. We briefly review key\nmethodologies and tools for energy measurement as well as define metrics for\nreporting results. Through case studies using representative CFD applications\n(waLBerla, FLEXI/GAL{\\AE}XI, Neko, and NekRS), we evaluate energy-to-solution\nand time-to-solution metrics on diverse architectures, including CPU- and\nGPU-based partitions of LUMI, MareNostrum5, MeluXina, and JUWELS Booster. Our\nresults highlight the advantages of accelerators and mixed-precision techniques\nfor reducing energy consumption while maintaining computational accuracy.\nFinally, we advocate the need to facilitate energy measurements on HPC systems\nin order to raise awareness, teach the community, and take actions toward more\nsustainable exascale computing.", "AI": {"tldr": "\u6b27\u6d32\u9ad8\u6027\u80fd\u8ba1\u7b97\u5353\u8d8a\u4e2d\u5fc3\u5728CFD\u9886\u57df\u7684\u80fd\u6e90\u6548\u7387\u7814\u7a76\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\u4e86\u591a\u79cdCFD\u5e94\u7528\u5728\u4e0d\u540c\u67b6\u6784\u4e0a\u7684\u80fd\u8017\u8868\u73b0\uff0c\u5f3a\u8c03\u52a0\u901f\u5668\u548c\u6df7\u5408\u7cbe\u5ea6\u6280\u672f\u5bf9\u964d\u4f4e\u80fd\u8017\u7684\u4f18\u52bf\u3002", "motivation": "\u73b0\u4ee3\u9ad8\u6027\u80fd\u8ba1\u7b97\u7cfb\u7edf\u9762\u4e34\u80fd\u6e90\u6548\u7387\u6311\u6218\uff0c\u8ba1\u7b97\u9700\u6c42\u589e\u957f\u548c\u67b6\u6784\u590d\u6742\u6027\u5bfc\u81f4\u663e\u8457\u80fd\u8017\u8db3\u8ff9\uff0c\u9700\u8981\u6d4b\u91cf\u3001\u5206\u6790\u548c\u4f18\u5316\u80fd\u6e90\u6d88\u8017\u3002", "method": "\u4f7f\u7528\u4ee3\u8868\u6027CFD\u5e94\u7528\uff08waLBerla\u3001FLEXI/GAL\u00c6XI\u3001Neko\u3001NekRS\uff09\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\uff0c\u8bc4\u4f30\u4e0d\u540c\u67b6\u6784\uff08CPU\u548cGPU\uff09\u4e0a\u7684\u80fd\u6e90\u89e3\u51b3\u65b9\u6848\u548c\u65f6\u95f4\u89e3\u51b3\u65b9\u6848\u6307\u6807\u3002", "result": "\u7ed3\u679c\u663e\u793a\u52a0\u901f\u5668\u548c\u6df7\u5408\u7cbe\u5ea6\u6280\u672f\u5728\u4fdd\u6301\u8ba1\u7b97\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u80fd\u8017\uff0c\u5728LUMI\u3001MareNostrum5\u3001MeluXina\u548cJUWELS Booster\u7b49\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\u4e86\u6548\u679c\u3002", "conclusion": "\u9700\u8981\u4fc3\u8fdbHPC\u7cfb\u7edf\u4e0a\u7684\u80fd\u6e90\u6d4b\u91cf\uff0c\u63d0\u9ad8\u610f\u8bc6\u3001\u6559\u80b2\u793e\u533a\uff0c\u5e76\u91c7\u53d6\u884c\u52a8\u5b9e\u73b0\u66f4\u53ef\u6301\u7eed\u7684\u767e\u4ebf\u4ebf\u6b21\u8ba1\u7b97\u3002"}}
{"id": "2511.02997", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02997", "abs": "https://arxiv.org/abs/2511.02997", "authors": ["Jon Kutasov", "Chloe Loughridge", "Yuqi Sun", "Henry Sleight", "Buck Shlegeris", "Tyler Tracy", "Joe Benton"], "title": "Evaluating Control Protocols for Untrusted AI Agents", "comment": null, "summary": "As AI systems become more capable and widely deployed as agents, ensuring\ntheir safe operation becomes critical. AI control offers one approach to\nmitigating the risk from untrusted AI agents by monitoring their actions and\nintervening or auditing when necessary. Evaluating the safety of these\nprotocols requires understanding both their effectiveness against current\nattacks and their robustness to adaptive adversaries. In this work, we\nsystematically evaluate a range of control protocols in SHADE-Arena, a dataset\nof diverse agentic environments. First, we evaluate blue team protocols,\nincluding deferral to trusted models, resampling, and deferring on critical\nactions, against a default attack policy. We find that resampling for\nincrimination and deferring on critical actions perform best, increasing safety\nfrom 50% to 96%. We then iterate on red team strategies against these protocols\nand find that attack policies with additional affordances, such as knowledge of\nwhen resampling occurs or the ability to simulate monitors, can substantially\nimprove attack success rates against our resampling strategy, decreasing safety\nto 17%. However, deferring on critical actions is highly robust to even our\nstrongest red team strategies, demonstrating the importance of denying attack\npolicies access to protocol internals.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86AI\u63a7\u5236\u534f\u8bae\u5728SHADE-Arena\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u5173\u952e\u884c\u52a8\u5ef6\u8fdf\u7b56\u7565\u5bf9\u7ea2\u961f\u653b\u51fb\u5177\u6709\u9ad8\u5ea6\u9c81\u68d2\u6027\uff0c\u800c\u91cd\u91c7\u6837\u7b56\u7565\u5728\u7ea2\u961f\u4e86\u89e3\u534f\u8bae\u5185\u90e8\u4fe1\u606f\u65f6\u5b89\u5168\u6027\u4f1a\u5927\u5e45\u4e0b\u964d\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u4f5c\u4e3a\u667a\u80fd\u4f53\u88ab\u5e7f\u6cdb\u90e8\u7f72\uff0c\u786e\u4fdd\u5176\u5b89\u5168\u8fd0\u884c\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002AI\u63a7\u5236\u901a\u8fc7\u76d1\u63a7\u667a\u80fd\u4f53\u884c\u4e3a\u5e76\u5728\u5fc5\u8981\u65f6\u5e72\u9884\u6216\u5ba1\u8ba1\u6765\u964d\u4f4e\u98ce\u9669\uff0c\u9700\u8981\u8bc4\u4f30\u8fd9\u4e9b\u534f\u8bae\u7684\u6709\u6548\u6027\u548c\u5bf9\u81ea\u9002\u5e94\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "method": "\u5728SHADE-Arena\u591a\u6837\u5316\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7cfb\u7edf\u8bc4\u4f30\u63a7\u5236\u534f\u8bae\uff0c\u5305\u62ec\u84dd\u961f\u534f\u8bae\uff08\u53ef\u4fe1\u6a21\u578b\u5ef6\u8fdf\u3001\u91cd\u91c7\u6837\u3001\u5173\u952e\u884c\u52a8\u5ef6\u8fdf\uff09\u5bf9\u6297\u9ed8\u8ba4\u653b\u51fb\u7b56\u7565\uff0c\u7136\u540e\u8fed\u4ee3\u7ea2\u961f\u7b56\u7565\u5bf9\u6297\u8fd9\u4e9b\u534f\u8bae\u3002", "result": "\u91cd\u91c7\u6837\u548c\u5173\u952e\u884c\u52a8\u5ef6\u8fdf\u534f\u8bae\u5c06\u5b89\u5168\u6027\u4ece50%\u63d0\u5347\u523096%\uff1b\u4f46\u5f53\u7ea2\u961f\u7b56\u7565\u5177\u6709\u989d\u5916\u80fd\u529b\uff08\u5982\u77e5\u9053\u91cd\u91c7\u6837\u53d1\u751f\u65f6\u95f4\u6216\u80fd\u6a21\u62df\u76d1\u63a7\u5668\uff09\u65f6\uff0c\u91cd\u91c7\u6837\u7b56\u7565\u7684\u5b89\u5168\u6027\u964d\u81f317%\uff1b\u5173\u952e\u884c\u52a8\u5ef6\u8fdf\u7b56\u7565\u5bf9\u6700\u5f3a\u7ea2\u961f\u653b\u51fb\u4ecd\u4fdd\u6301\u9ad8\u5ea6\u9c81\u68d2\u6027\u3002", "conclusion": "\u5173\u952e\u884c\u52a8\u5ef6\u8fdf\u7b56\u7565\u5bf9\u81ea\u9002\u5e94\u653b\u51fb\u5177\u6709\u9ad8\u5ea6\u9c81\u68d2\u6027\uff0c\u8bc1\u660e\u62d2\u7edd\u653b\u51fb\u7b56\u7565\u8bbf\u95ee\u534f\u8bae\u5185\u90e8\u4fe1\u606f\u7684\u91cd\u8981\u6027\uff0c\u4e3aAI\u63a7\u5236\u534f\u8bae\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2511.03286", "categories": ["cs.DC", "cs.MA", "cs.SE", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.03286", "abs": "https://arxiv.org/abs/2511.03286", "authors": ["Ehud Shapiro"], "title": "Characterising Global Platforms: Centralised, Decentralised, Federated, and Grassroots", "comment": null, "summary": "Global digital platforms are software systems designed to serve entire\npopulations, with some already serving billions of people. We propose atomic\ntransactions-based multiagent transition systems and protocols as a formal\nframework to study them; introduce essential agents -- minimal sets of agents\nthe removal of which makes communication impossible; and show that the\ncardinality of essential agents partitions all global platforms into four\nclasses:\n  1. Centralised -- one (the server)\n  2. Decentralised -- finite $>1$ (bootstrap nodes)\n  3. Federated -- infinite but not universal (all servers)\n  4. Grassroots -- universal (all agents)\n  Our illustrative formal example is a global social network, for which we\nprovide centralised, decentralised, federated, and grassroots specifications\nvia multiagent atomic transactions, and prove they satisfy basic correctness\nproperties. We discuss informally additional global platforms -- currencies,\n``sharing economy'' apps, AI, and more. While this may be the first\ncharacterisation of centralised, decentralised, and federated global platforms,\ngrassroots platforms have been formally defined previously, but using different\nnotions. Here, we prove that their original definition implies that all agents\nare essential, placing grassroots platforms in a distinct class within the\nbroader formal context that includes all global platforms. This work provides\nthe first mathematical framework for classifying any global platform --\nexisting or imagined -- by providing a multiagent atomic-transactions\nspecification of it and determining the cardinality of the minimal set of\nessential agents in the ensuing multiagent protocol. It thus", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u539f\u5b50\u4e8b\u52a1\u7684\u591a\u667a\u80fd\u4f53\u8f6c\u6362\u7cfb\u7edf\u548c\u534f\u8bae\u4f5c\u4e3a\u7814\u7a76\u5168\u7403\u6570\u5b57\u5e73\u53f0\u7684\u6b63\u5f0f\u6846\u67b6\uff0c\u5f15\u5165\u4e86\u57fa\u672c\u667a\u80fd\u4f53\u7684\u6982\u5ff5\uff0c\u5e76\u6839\u636e\u57fa\u672c\u667a\u80fd\u4f53\u7684\u57fa\u6570\u5c06\u5168\u7403\u5e73\u53f0\u5206\u4e3a\u56db\u7c7b\uff1a\u4e2d\u5fc3\u5316\u3001\u53bb\u4e2d\u5fc3\u5316\u3001\u8054\u90a6\u5316\u548c\u8349\u6839\u5316\u3002", "motivation": "\u4e3a\u5168\u7403\u6570\u5b57\u5e73\u53f0\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u7c7b\u548c\u5206\u6790\u4e0d\u540c\u7c7b\u578b\u7684\u5e73\u53f0\u67b6\u6784\uff0c\u5305\u62ec\u73b0\u6709\u548c\u60f3\u8c61\u4e2d\u7684\u5e73\u53f0\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u539f\u5b50\u4e8b\u52a1\u7684\u591a\u667a\u80fd\u4f53\u8f6c\u6362\u7cfb\u7edf\u548c\u534f\u8bae\u4f5c\u4e3a\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u5f15\u5165\u57fa\u672c\u667a\u80fd\u4f53\u7684\u6982\u5ff5\uff0c\u5e76\u901a\u8fc7\u5206\u6790\u6700\u5c0f\u57fa\u672c\u667a\u80fd\u4f53\u96c6\u5408\u7684\u57fa\u6570\u6765\u5206\u7c7b\u5e73\u53f0\u3002", "result": "\u6210\u529f\u5c06\u5168\u7403\u5e73\u53f0\u5206\u4e3a\u56db\u7c7b\uff1a\u4e2d\u5fc3\u5316\uff081\u4e2a\u57fa\u672c\u667a\u80fd\u4f53\uff09\u3001\u53bb\u4e2d\u5fc3\u5316\uff08\u6709\u9650\u4e2a>1\u57fa\u672c\u667a\u80fd\u4f53\uff09\u3001\u8054\u90a6\u5316\uff08\u65e0\u9650\u4f46\u4e0d\u901a\u7528\u57fa\u672c\u667a\u80fd\u4f53\uff09\u3001\u8349\u6839\u5316\uff08\u6240\u6709\u667a\u80fd\u4f53\u90fd\u662f\u57fa\u672c\u7684\uff09\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4efb\u4f55\u5168\u7403\u5e73\u53f0\u63d0\u4f9b\u4e86\u7b2c\u4e00\u4e2a\u6570\u5b66\u5206\u7c7b\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u539f\u5b50\u4e8b\u52a1\u89c4\u8303\u6765\u786e\u5b9a\u5e73\u53f0\u7c7b\u578b\uff0c\u5e76\u5c06\u8349\u6839\u5316\u5e73\u53f0\u7f6e\u4e8e\u66f4\u5e7f\u6cdb\u7684\u6b63\u5f0f\u80cc\u666f\u4e2d\u3002"}}
{"id": "2511.03023", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03023", "abs": "https://arxiv.org/abs/2511.03023", "authors": ["Sina Montazeri", "Yunhe Feng", "Kewei Sha"], "title": "PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data Analysis Framework", "comment": null, "summary": "Open data repositories hold potential for evidence-based decision-making, yet\nare inaccessible to non-experts lacking expertise in dataset discovery, schema\nmapping, and statistical analysis. Large language models show promise for\nindividual tasks, but end-to-end analytical workflows expose fundamental\nlimitations: attention dilutes across growing contexts, specialized reasoning\npatterns interfere, and errors propagate undetected. We present PublicAgent, a\nmulti-agent framework that addresses these limitations through decomposition\ninto specialized agents for intent clarification, dataset discovery, analysis,\nand reporting. This architecture maintains focused attention within agent\ncontexts and enables validation at each stage. Evaluation across five models\nand 50 queries derives five design principles for multi-agent LLM systems.\nFirst, specialization provides value independent of model strength--even the\nstrongest model shows 97.5% agent win rates, with benefits orthogonal to model\nscale. Second, agents divide into universal (discovery, analysis) and\nconditional (report, intent) categories. Universal agents show consistent\neffectiveness (std dev 12.4%) while conditional agents vary by model (std dev\n20.5%). Third, agents mitigate distinct failure modes--removing discovery or\nanalysis causes catastrophic failures (243-280 instances), while removing\nreport or intent causes quality degradation. Fourth, architectural benefits\npersist across task complexity with stable win rates (86-92% analysis, 84-94%\ndiscovery), indicating workflow management value rather than reasoning\nenhancement. Fifth, wide variance in agent effectiveness across models (42-96%\nfor analysis) requires model-aware architecture design. These principles guide\nwhen and why specialization is necessary for complex analytical workflows while\nenabling broader access to public data through natural language interfaces.", "AI": {"tldr": "PublicAgent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u4e3a\u4e13\u95e8\u5316\u7684\u667a\u80fd\u4f53\uff08\u610f\u56fe\u6f84\u6e05\u3001\u6570\u636e\u96c6\u53d1\u73b0\u3001\u5206\u6790\u548c\u62a5\u544a\uff09\u6765\u89e3\u51b3LLM\u5728\u7aef\u5230\u7aef\u5206\u6790\u5de5\u4f5c\u6d41\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4fdd\u6301\u4e13\u6ce8\u6ce8\u610f\u529b\u5e76\u5b9e\u73b0\u9636\u6bb5\u9a8c\u8bc1\u3002", "motivation": "\u5f00\u653e\u6570\u636e\u4ed3\u5e93\u5bf9\u975e\u4e13\u5bb6\u96be\u4ee5\u8bbf\u95ee\uff0c\u9700\u8981\u6570\u636e\u96c6\u53d1\u73b0\u3001\u6a21\u5f0f\u6620\u5c04\u548c\u7edf\u8ba1\u5206\u6790\u7684\u4e13\u4e1a\u77e5\u8bc6\u3002LLM\u5728\u5355\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7aef\u5230\u7aef\u5206\u6790\u5de5\u4f5c\u6d41\u4e2d\u5b58\u5728\u6ce8\u610f\u529b\u7a00\u91ca\u3001\u4e13\u4e1a\u63a8\u7406\u6a21\u5f0f\u5e72\u6270\u548c\u9519\u8bef\u4f20\u64ad\u7b49\u95ee\u9898\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u5206\u6790\u5de5\u4f5c\u6d41\u5206\u89e3\u4e3a\u4e13\u95e8\u7684\u667a\u80fd\u4f53\uff1a\u610f\u56fe\u6f84\u6e05\u3001\u6570\u636e\u96c6\u53d1\u73b0\u3001\u5206\u6790\u548c\u62a5\u544a\u3002\u8fd9\u79cd\u67b6\u6784\u5728\u667a\u80fd\u4f53\u4e0a\u4e0b\u6587\u4e2d\u4fdd\u6301\u4e13\u6ce8\u6ce8\u610f\u529b\uff0c\u5e76\u5728\u6bcf\u4e2a\u9636\u6bb5\u5b9e\u73b0\u9a8c\u8bc1\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff1a1\uff09\u4e13\u4e1a\u5316\u72ec\u7acb\u4e8e\u6a21\u578b\u5f3a\u5ea6\u63d0\u4f9b\u4ef7\u503c\uff1b2\uff09\u667a\u80fd\u4f53\u5206\u4e3a\u901a\u7528\u578b\uff08\u53d1\u73b0\u3001\u5206\u6790\uff09\u548c\u6761\u4ef6\u578b\uff08\u62a5\u544a\u3001\u610f\u56fe\uff09\uff1b3\uff09\u667a\u80fd\u4f53\u7f13\u89e3\u4e0d\u540c\u6545\u969c\u6a21\u5f0f\uff1b4\uff09\u67b6\u6784\u4f18\u52bf\u5728\u4e0d\u540c\u4efb\u52a1\u590d\u6742\u5ea6\u4e0b\u6301\u7eed\u5b58\u5728\uff1b5\uff09\u667a\u80fd\u4f53\u6709\u6548\u6027\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u4e13\u4e1a\u5316\u5bf9\u4e8e\u590d\u6742\u5206\u6790\u5de5\u4f5c\u6d41\u662f\u5fc5\u8981\u7684\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u5b9e\u73b0\u66f4\u5e7f\u6cdb\u7684\u516c\u5171\u6570\u636e\u8bbf\u95ee\uff0c\u5e76\u63d0\u4f9b\u4e86\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u7684\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2511.02993", "categories": ["cs.CR", "cs.HC", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.02993", "abs": "https://arxiv.org/abs/2511.02993", "authors": ["Yixuan Gao", "Tanvir Ahmed", "Zekun Chang", "Thijs Roumen", "Rajalakshmi Nandakumar"], "title": "PrivyWave: Privacy-Aware Wireless Sensing of Heartbeat", "comment": "20 pages, 5 figures", "summary": "Wireless sensing technologies can now detect heartbeats using radio frequency\nand acoustic signals, raising significant privacy concerns. Existing privacy\nsolutions either protect from all sensing systems indiscriminately preventing\nany utility or operate post-data collection, failing to enable selective access\nwhere authorized devices can monitor while unauthorized ones cannot. We present\na key-based physical obfuscation system, PrivyWave, that addresses this\nchallenge by generating controlled decoy heartbeat signals at\ncryptographically-determined frequencies. Unauthorized sensors receive a\nmixture of real and decoy signals that are indistinguishable without the secret\nkey, while authorized sensors use the key to filter out decoys and recover\naccurate measurements. Our evaluation with 13 participants demonstrates\neffective protection across both sensing modalities: for mmWave radar,\nunauthorized sensors show 21.3 BPM mean absolute error while authorized sensors\nmaintain a much smaller 5.8 BPM; for acoustic sensing, unauthorized error\nincreases to 42.0 BPM while authorized sensors achieve 9.7 BPM. The system\noperates across multiple sensing modalities without per-modality customization\nand provides cryptographic obfuscation guarantees. Performance benchmarks show\nrobust protection across different distances (30-150 cm), orientations\n(120{\\deg} field of view), and diverse indoor environments, establishing\nphysical-layer obfuscation as a viable approach for selective privacy in\npervasive health monitoring.", "AI": {"tldr": "PrivyWave\u662f\u4e00\u4e2a\u57fa\u4e8e\u5bc6\u94a5\u7684\u7269\u7406\u6df7\u6dc6\u7cfb\u7edf\uff0c\u901a\u8fc7\u751f\u6210\u5bc6\u7801\u5b66\u63a7\u5236\u7684\u4f2a\u5fc3\u8df3\u4fe1\u53f7\u6765\u4fdd\u62a4\u65e0\u7ebf\u611f\u77e5\u9690\u79c1\uff0c\u5141\u8bb8\u6388\u6743\u8bbe\u5907\u51c6\u786e\u76d1\u6d4b\u800c\u963b\u6b62\u672a\u6388\u6743\u8bbe\u5907\u3002", "motivation": "\u73b0\u6709\u9690\u79c1\u89e3\u51b3\u65b9\u6848\u8981\u4e48\u5b8c\u5168\u963b\u6b62\u6240\u6709\u611f\u77e5\u7cfb\u7edf\uff08\u727a\u7272\u5b9e\u7528\u6027\uff09\uff0c\u8981\u4e48\u5728\u6570\u636e\u6536\u96c6\u540e\u64cd\u4f5c\uff08\u65e0\u6cd5\u5b9e\u73b0\u9009\u62e9\u6027\u8bbf\u95ee\uff09\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5728\u7269\u7406\u5c42\u5b9e\u73b0\u9009\u62e9\u6027\u9690\u79c1\u4fdd\u62a4\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u5bc6\u7801\u5b66\u786e\u5b9a\u7684\u9891\u7387\u751f\u6210\u53d7\u63a7\u7684\u4f2a\u5fc3\u8df3\u4fe1\u53f7\uff0c\u672a\u6388\u6743\u4f20\u611f\u5668\u63a5\u6536\u771f\u5b9e\u548c\u4f2a\u4fe1\u53f7\u7684\u6df7\u5408\u4fe1\u53f7\uff0c\u6388\u6743\u4f20\u611f\u5668\u4f7f\u7528\u5bc6\u94a5\u8fc7\u6ee4\u4f2a\u4fe1\u53f7\u4ee5\u6062\u590d\u51c6\u786e\u6d4b\u91cf\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff1a\u6beb\u7c73\u6ce2\u96f7\u8fbe\u4e2d\uff0c\u672a\u6388\u6743\u4f20\u611f\u5668\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee21.3 BPM\uff0c\u6388\u6743\u4f20\u611f\u5668\u4ec55.8 BPM\uff1b\u58f0\u5b66\u611f\u77e5\u4e2d\uff0c\u672a\u6388\u6743\u8bef\u5dee42.0 BPM\uff0c\u6388\u6743\u4f20\u611f\u56689.7 BPM\u3002\u7cfb\u7edf\u5728\u4e0d\u540c\u8ddd\u79bb\u3001\u65b9\u5411\u548c\u73af\u5883\u4e0b\u5747\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "\u7269\u7406\u5c42\u6df7\u6dc6\u662f\u5b9e\u73b0\u666e\u9002\u5065\u5eb7\u76d1\u6d4b\u4e2d\u9009\u62e9\u6027\u9690\u79c1\u4fdd\u62a4\u7684\u53ef\u884c\u65b9\u6cd5\uff0c\u65e0\u9700\u9488\u5bf9\u4e0d\u540c\u611f\u77e5\u6a21\u5f0f\u8fdb\u884c\u5b9a\u5236\uff0c\u5e76\u63d0\u4f9b\u5bc6\u7801\u5b66\u6df7\u6dc6\u4fdd\u8bc1\u3002"}}
{"id": "2511.03293", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03293", "abs": "https://arxiv.org/abs/2511.03293", "authors": ["Hai Huang", "Xuhong Qiang", "Weisheng Zhao", "Chenchen Liu"], "title": "UMDAM: A Unified Data Layout and DRAM Address Mapping for Heterogenous NPU-PIM", "comment": "5 pages, 5 figures, under review for IEEE ISCAS", "summary": "Large Language Models (LLMs) are increasingly deployed on edge devices with\nNeural Processing Units (NPUs), yet the decode phase remains memory-intensive,\nlimiting performance. Processing-in-Memory (PIM) offers a promising solution,\nbut co-executing NPU-PIM systems face challenges such as data layout\nmismatches, bandwidth loss, and redundant storage. To address these issues, we\npropose UMDAM, a unified memory-affinity data layout and DRAM address mapping\nscheme tailored for NPU-PIM co-execution. UMDAM employs a column-major,\ntile-based layout and a configurable DRAM mapping strategy to ensure\ncompatibility with NPU computation while maximizing PIM efficiency -- without\nintroducing extra memory overhead or bandwidth loss. Comprehensive evaluations\non OPT models demonstrate that UMDAM reduces time-to-first-token (TTFT) by up\nto 3.0x and time-to-last-token (TTLT) by 2.18x, significantly improving\nend-to-end LLM inference efficiency on edge devices.", "AI": {"tldr": "UMDAM\u662f\u4e00\u79cd\u9488\u5bf9NPU-PIM\u534f\u540c\u6267\u884c\u7684\u7edf\u4e00\u5185\u5b58\u4eb2\u548c\u6027\u6570\u636e\u5e03\u5c40\u548cDRAM\u5730\u5740\u6620\u5c04\u65b9\u6848\uff0c\u901a\u8fc7\u5217\u4e3b\u5e8f\u3001\u57fa\u4e8e\u5206\u5757\u7684\u5e03\u5c40\u548c\u53ef\u914d\u7f6e\u7684DRAM\u6620\u5c04\u7b56\u7565\uff0c\u5728\u4e0d\u5f15\u5165\u989d\u5916\u5185\u5b58\u5f00\u9500\u6216\u5e26\u5bbd\u635f\u5931\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u8fb9\u7f18\u8bbe\u5907\u4e0aLLM\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907NPU\u4e0a\u90e8\u7f72\u65f6\uff0c\u89e3\u7801\u9636\u6bb5\u4ecd\u7136\u5185\u5b58\u5bc6\u96c6\uff0c\u6027\u80fd\u53d7\u9650\u3002NPU-PIM\u534f\u540c\u6267\u884c\u9762\u4e34\u6570\u636e\u5e03\u5c40\u4e0d\u5339\u914d\u3001\u5e26\u5bbd\u635f\u5931\u548c\u5197\u4f59\u5b58\u50a8\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51faUMDAM\u65b9\u6848\uff0c\u91c7\u7528\u5217\u4e3b\u5e8f\u3001\u57fa\u4e8e\u5206\u5757\u7684\u5e03\u5c40\u548c\u53ef\u914d\u7f6e\u7684DRAM\u6620\u5c04\u7b56\u7565\uff0c\u786e\u4fdd\u4e0eNPU\u8ba1\u7b97\u7684\u517c\u5bb9\u6027\uff0c\u540c\u65f6\u6700\u5927\u5316PIM\u6548\u7387\u3002", "result": "\u5728OPT\u6a21\u578b\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u663e\u793a\uff0cUMDAM\u5c06\u9996token\u65f6\u95f4(TTFT)\u964d\u4f4e\u9ad8\u8fbe3.0\u500d\uff0c\u672btoken\u65f6\u95f4(TTLT)\u964d\u4f4e2.18\u500d\u3002", "conclusion": "UMDAM\u663e\u8457\u63d0\u5347\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7aef\u5230\u7aefLLM\u63a8\u7406\u6548\u7387\uff0c\u89e3\u51b3\u4e86NPU-PIM\u534f\u540c\u6267\u884c\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2511.03203", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.03203", "abs": "https://arxiv.org/abs/2511.03203", "authors": ["Deyang Yu", "Chenchen Liu", "Chuanjie Zhang", "Xiao Fang", "Weisheng Zhao"], "title": "An Event-Driven Spiking Compute-In-Memory Macro based on SOT-MRAM", "comment": "5 pages, 7 figures. Under review for ISCAS", "summary": "The application of Magnetic Random-Access Memory (MRAM) in\ncomputing-in-memory (CIM) has gained significant attention. However, existing\ndesigns often suffer from high energy consumption due to their reliance on\ncomplex analog circuits for computation. In this work, we present a Spin-Orbit-\nTorque MRAM(SOT-MRAM)-based CIM macro that employs an event-driven spiking\nprocessing for high energy efficiency. The SOT-MRAM crossbar adopts a hybrid\nseries-parallel cell structure to efficiently support matrix-vector\nmultiplication (MVM). Signal information is (en) decoded as spikes using\nlightweight circuits, eliminating the need for conventional area- and\npowerintensive analog circuits. The SOT-MRAM macro is designed and evaluated in\n28nm technology, and experimental results show that it achieves a peak energy\nefficiency of 243.6 TOPS/W, significantly outperforming existing designs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u65cb\u8f68\u9053\u77e9\u78c1\u963b\u968f\u673a\u5b58\u53d6\u5b58\u50a8\u5668(SOT-MRAM)\u7684\u8ba1\u7b97\u5185\u5b58\u5b8f\uff0c\u91c7\u7528\u4e8b\u4ef6\u9a71\u52a8\u8109\u51b2\u5904\u7406\u5b9e\u73b0\u9ad8\u80fd\u6548\uff0c\u901a\u8fc7\u6df7\u5408\u4e32\u5e76\u8054\u5355\u5143\u7ed3\u6784\u652f\u6301\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\uff0c\u5cf0\u503c\u80fd\u6548\u8fbe243.6 TOPS/W\u3002", "motivation": "\u73b0\u6709MRAM\u8ba1\u7b97\u5185\u5b58\u8bbe\u8ba1\u56e0\u4f9d\u8d56\u590d\u6742\u6a21\u62df\u7535\u8def\u800c\u5bfc\u81f4\u9ad8\u80fd\u8017\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528SOT-MRAM\u4ea4\u53c9\u9635\u5217\uff0c\u8bbe\u8ba1\u6df7\u5408\u4e32\u5e76\u8054\u5355\u5143\u7ed3\u6784\u652f\u6301\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u7535\u8def\u8fdb\u884c\u8109\u51b2\u7f16\u7801\u89e3\u7801\uff0c\u907f\u514d\u4f20\u7edf\u6a21\u62df\u7535\u8def\u3002", "result": "\u572828nm\u5de5\u827a\u4e0b\u5b9e\u73b0\uff0c\u5cf0\u503c\u80fd\u6548\u8fbe\u5230243.6 TOPS/W\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u8bbe\u8ba1\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684SOT-MRAM\u8ba1\u7b97\u5185\u5b58\u5b8f\u901a\u8fc7\u4e8b\u4ef6\u9a71\u52a8\u8109\u51b2\u5904\u7406\u548c\u6df7\u5408\u7ed3\u6784\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u9ad8\u80fd\u6548\u7684\u8ba1\u7b97\u5185\u5b58\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.03533", "categories": ["cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.03533", "abs": "https://arxiv.org/abs/2511.03533", "authors": ["Nils Japke", "Furat Hamdan", "Diana Baumann", "David Bermbach"], "title": "Investigating the Impact of Isolation on Synchronized Benchmarks", "comment": "Accepted for publication in 2025 IEEE/ACM 18th International\n  Conference on Utility and Cloud Computing", "summary": "Benchmarking in cloud environments suffers from performance variability from\nmulti-tenant resource contention. Duet benchmarking mitigates this by running\ntwo workload versions concurrently on the same VM, exposing them to identical\nexternal interference. However, intra-VM contention between synchronized\nworkloads necessitates additional isolation mechanisms.\n  This work evaluates three such strategies: cgroups and CPU pinning, Docker\ncontainers, and Firecracker MicroVMs. We compare all strategies with an\nunisolated baseline experiment, by running benchmarks with a duet setup\nalongside a noise generator. This noise generator \"steals\" compute resources to\ndegrade performance measurements.\n  All experiments showed different latency distributions while under the\neffects of noise generation, but results show that process isolation generally\nlowered false positives, except for our experiments with Docker containers.\nEven though Docker containers rely internally on cgroups and CPU pinning, they\nwere more susceptible to performance degradation due to noise influence.\nTherefore, we recommend to use process isolation for synchronized workloads,\nwith the exception of Docker containers.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u4e09\u79cd\u9694\u79bb\u7b56\u7565\uff08cgroups\u548cCPU\u56fa\u5b9a\u3001Docker\u5bb9\u5668\u3001Firecracker MicroVMs\uff09\u5728Duet\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u6548\u679c\uff0c\u53d1\u73b0\u8fdb\u7a0b\u9694\u79bb\u901a\u5e38\u80fd\u964d\u4f4e\u8bef\u62a5\uff0c\u4f46Docker\u5bb9\u5668\u5bf9\u566a\u58f0\u5f71\u54cd\u66f4\u654f\u611f\u3002", "motivation": "\u4e91\u73af\u5883\u4e2d\u591a\u79df\u6237\u8d44\u6e90\u4e89\u7528\u5bfc\u81f4\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u6027\u80fd\u53d8\u5f02\u6027\uff0cDuet\u57fa\u51c6\u6d4b\u8bd5\u901a\u8fc7\u5728\u76f8\u540cVM\u4e0a\u5e76\u53d1\u8fd0\u884c\u4e24\u4e2a\u5de5\u4f5c\u8d1f\u8f7d\u7248\u672c\u6765\u7f13\u89e3\u6b64\u95ee\u9898\uff0c\u4f46\u9700\u8981\u989d\u5916\u7684\u9694\u79bb\u673a\u5236\u6765\u5904\u7406\u540c\u6b65\u5de5\u4f5c\u8d1f\u8f7d\u95f4\u7684VM\u5185\u4e89\u7528\u3002", "method": "\u901a\u8fc7\u8fd0\u884c\u5e26\u6709\u566a\u58f0\u751f\u6210\u5668\u7684duet\u8bbe\u7f6e\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u4e09\u79cd\u9694\u79bb\u7b56\u7565\uff08cgroups\u548cCPU\u56fa\u5b9a\u3001Docker\u5bb9\u5668\u3001Firecracker MicroVMs\uff09\u4e0e\u65e0\u9694\u79bb\u57fa\u7ebf\u5b9e\u9a8c\u7684\u6548\u679c\u3002", "result": "\u6240\u6709\u5b9e\u9a8c\u5728\u566a\u58f0\u751f\u6210\u5f71\u54cd\u4e0b\u663e\u793a\u51fa\u4e0d\u540c\u7684\u5ef6\u8fdf\u5206\u5e03\uff0c\u4f46\u8fdb\u7a0b\u9694\u79bb\u901a\u5e38\u964d\u4f4e\u4e86\u8bef\u62a5\uff0c\u9664\u4e86Docker\u5bb9\u5668\u5b9e\u9a8c\u3002Docker\u5bb9\u5668\u867d\u7136\u5185\u90e8\u4f9d\u8d56cgroups\u548cCPU\u56fa\u5b9a\uff0c\u4f46\u5bf9\u566a\u58f0\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u66f4\u654f\u611f\u3002", "conclusion": "\u5efa\u8bae\u5bf9\u540c\u6b65\u5de5\u4f5c\u8d1f\u8f7d\u4f7f\u7528\u8fdb\u7a0b\u9694\u79bb\uff0c\u4f46\u5e94\u907f\u514d\u4f7f\u7528Docker\u5bb9\u5668\u3002"}}
{"id": "2511.03070", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.03070", "abs": "https://arxiv.org/abs/2511.03070", "authors": ["Drago Plecko", "Patrik Okanovic", "Torsten Hoefler", "Elias Bareinboim"], "title": "Epidemiology of Large Language Models: A Benchmark for Observational Distribution Knowledge", "comment": null, "summary": "Artificial intelligence (AI) systems hold great promise for advancing various\nscientific disciplines, and are increasingly used in real-world applications.\nDespite their remarkable progress, further capabilities are expected in order\nto achieve more general types of intelligence. A critical distinction in this\ncontext is between factual knowledge, which can be evaluated against true or\nfalse answers (e.g., \"what is the capital of England?\"), and probabilistic\nknowledge, reflecting probabilistic properties of the real world (e.g., \"what\nis the sex of a computer science graduate in the US?\"). In this paper, our goal\nis to build a benchmark for understanding the capabilities of LLMs in terms of\nknowledge of probability distributions describing the real world. Given that\nLLMs are trained on vast amounts of text, it may be plausible that they\ninternalize aspects of these distributions. Indeed, LLMs are touted as powerful\nuniversal approximators of real-world distributions. At the same time,\nclassical results in statistics, known as curse of dimensionality, highlight\nfundamental challenges in learning distributions in high dimensions,\nchallenging the notion of universal distributional learning. In this work, we\ndevelop the first benchmark to directly test this hypothesis, evaluating\nwhether LLMs have access to empirical distributions describing real-world\npopulations across domains such as economics, health, education, and social\nbehavior. Our results demonstrate that LLMs perform poorly overall, and do not\nseem to internalize real-world statistics naturally. When interpreted in the\ncontext of Pearl's Causal Hierarchy (PCH), our benchmark demonstrates that\nlanguage models do not contain knowledge on observational distributions (Layer\n1 of PCH), and thus the Causal Hierarchy Theorem implies that interventional\n(Layer 2) and counterfactual (Layer 3) knowledge of these models is also\nlimited.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u9996\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30LLMs\u662f\u5426\u5185\u5316\u4e86\u771f\u5b9e\u4e16\u754c\u7684\u6982\u7387\u5206\u5e03\u77e5\u8bc6\uff0c\u53d1\u73b0LLMs\u5728\u7406\u89e3\u73b0\u5b9e\u4e16\u754c\u7edf\u8ba1\u5206\u5e03\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u672a\u80fd\u81ea\u7136\u5185\u5316\u89c2\u6d4b\u5206\u5e03\u77e5\u8bc6\u3002", "motivation": "\u8bc4\u4f30LLMs\u662f\u5426\u80fd\u591f\u5185\u5316\u63cf\u8ff0\u771f\u5b9e\u4e16\u754c\u6982\u7387\u5206\u5e03\u7684\u77e5\u8bc6\uff0c\u9a8c\u8bc1LLMs\u4f5c\u4e3a\u901a\u7528\u5206\u5e03\u8fd1\u4f3c\u5668\u7684\u80fd\u529b\uff0c\u5e76\u63a2\u8ba8\u9ad8\u7ef4\u5206\u5e03\u5b66\u4e60\u4e2d\u7684\u6839\u672c\u6311\u6218\u3002", "method": "\u5f00\u53d1\u9996\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u76f4\u63a5\u6d4b\u8bd5LLMs\u662f\u5426\u80fd\u591f\u8bbf\u95ee\u63cf\u8ff0\u771f\u5b9e\u4e16\u754c\u4eba\u53e3\u7684\u7ecf\u9a8c\u5206\u5e03\uff0c\u6db5\u76d6\u7ecf\u6d4e\u3001\u5065\u5eb7\u3001\u6559\u80b2\u548c\u793e\u4f1a\u884c\u4e3a\u7b49\u9886\u57df\u3002", "result": "LLMs\u6574\u4f53\u8868\u73b0\u4e0d\u4f73\uff0c\u4f3c\u4e4e\u65e0\u6cd5\u81ea\u7136\u5185\u5316\u771f\u5b9e\u4e16\u754c\u7edf\u8ba1\u4fe1\u606f\uff0c\u7f3a\u4e4f\u5bf9\u89c2\u6d4b\u5206\u5e03\uff08Pearl\u56e0\u679c\u5c42\u6b21\u7b2c\u4e00\u5c42\uff09\u7684\u77e5\u8bc6\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u771f\u5b9e\u4e16\u754c\u6982\u7387\u5206\u5e03\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u6839\u636e\u56e0\u679c\u5c42\u6b21\u5b9a\u7406\uff0c\u8fd9\u610f\u5473\u7740\u5b83\u4eec\u5728\u5e72\u9884\u548c\u53cd\u4e8b\u5b9e\u77e5\u8bc6\u65b9\u9762\u4e5f\u53d7\u5230\u9650\u5236\u3002"}}
{"id": "2511.03427", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.03427", "abs": "https://arxiv.org/abs/2511.03427", "authors": ["Florentia Afentaki", "Maha Shatta", "Konstantinos Balaskas", "Georgios Panagopoulos", "Georgios Zervakis", "Mehdi B. Tahoori"], "title": "Design and Optimization of Mixed-Kernel Mixed-Signal SVMs for Flexible Electronics", "comment": "Accepted for publication at IEEE Design Automation & Testing in\n  Europe (DATE 2026)", "summary": "Flexible Electronics (FE) have emerged as a promising alternative to\nsilicon-based technologies, offering on-demand low-cost fabrication,\nconformality, and sustainability. However, their large feature sizes severely\nlimit integration density, imposing strict area and power constraints, thus\nprohibiting the realization of Machine Learning (ML) circuits, which can\nsignificantly enhance the capabilities of relevant near-sensor applications.\nSupport Vector Machines (SVMs) offer high accuracy in such applications at\nrelatively low computational complexity, satisfying FE technologies'\nconstraints. Existing SVM designs rely solely on linear or Radial Basis\nFunction (RBF) kernels, forcing a trade-off between hardware costs and\naccuracy. Linear kernels, implemented digitally, minimize overhead but\nsacrifice performance, while the more accurate RBF kernels are prohibitively\nlarge in digital, and their analog realization contains inherent functional\napproximation. In this work, we propose the first mixed-kernel and mixed-signal\nSVM design in FE, which unifies the advantages of both implementations and\nbalances the cost/accuracy trade-off. To that end, we introduce a\nco-optimization approach that trains our mixed-kernel SVMs and maps binary SVM\nclassifiers to the appropriate kernel (linear/RBF) and domain (digital/analog),\naiming to maximize accuracy whilst reducing the number of costly RBF\nclassifiers. Our designs deliver 7.7% higher accuracy than state-of-the-art\nsingle-kernel linear SVMs, and reduce area and power by 108x and 17x on average\ncompared to digital RBF implementations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u67d4\u6027\u7535\u5b50\u4e2d\u9996\u4e2a\u6df7\u5408\u6838\u51fd\u6570\u548c\u6df7\u5408\u4fe1\u53f7\u7684SVM\u8bbe\u8ba1\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u65b9\u6cd5\u5728\u6570\u5b57/\u6a21\u62df\u57df\u4e2d\u5e73\u8861\u7ebf\u6027\u6838\u548cRBF\u6838\u7684\u4f7f\u7528\uff0c\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u786c\u4ef6\u6210\u672c\u3002", "motivation": "\u67d4\u6027\u7535\u5b50\u6280\u672f\u867d\u7136\u5177\u6709\u4f4e\u6210\u672c\u3001\u53ef\u5f2f\u66f2\u548c\u53ef\u6301\u7eed\u6027\u7b49\u4f18\u52bf\uff0c\u4f46\u5176\u5927\u7279\u5f81\u5c3a\u5bf8\u9650\u5236\u4e86\u96c6\u6210\u5bc6\u5ea6\uff0c\u96be\u4ee5\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u7535\u8def\u3002\u73b0\u6709SVM\u8bbe\u8ba1\u5728\u7ebf\u6027\u6838\u548cRBF\u6838\u4e4b\u95f4\u5b58\u5728\u786c\u4ef6\u6210\u672c\u4e0e\u7cbe\u5ea6\u7684\u6743\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u6838\u51fd\u6570\u548c\u6df7\u5408\u4fe1\u53f7\u7684SVM\u8bbe\u8ba1\uff0c\u91c7\u7528\u8054\u5408\u4f18\u5316\u65b9\u6cd5\u8bad\u7ec3\u6df7\u5408\u6838SVM\uff0c\u5e76\u5c06\u4e8c\u5143SVM\u5206\u7c7b\u5668\u6620\u5c04\u5230\u9002\u5f53\u7684\u6838\u51fd\u6570\uff08\u7ebf\u6027/RBF\uff09\u548c\u57df\uff08\u6570\u5b57/\u6a21\u62df\uff09\uff0c\u4ee5\u51cf\u5c11\u6602\u8d35\u7684RBF\u5206\u7c7b\u5668\u6570\u91cf\u3002", "result": "\u4e0e\u6700\u5148\u8fdb\u7684\u5355\u6838\u7ebf\u6027SVM\u76f8\u6bd4\uff0c\u7cbe\u5ea6\u63d0\u9ad87.7%\uff1b\u4e0e\u6570\u5b57RBF\u5b9e\u73b0\u76f8\u6bd4\uff0c\u9762\u79ef\u548c\u529f\u8017\u5206\u522b\u5e73\u5747\u964d\u4f4e108\u500d\u548c17\u500d\u3002", "conclusion": "\u8be5\u6df7\u5408\u6838\u51fd\u6570\u548c\u6df7\u5408\u4fe1\u53f7SVM\u8bbe\u8ba1\u6210\u529f\u5e73\u8861\u4e86\u67d4\u6027\u7535\u5b50\u4e2d\u786c\u4ef6\u6210\u672c\u4e0e\u7cbe\u5ea6\u7684\u6743\u8861\uff0c\u4e3a\u8fd1\u4f20\u611f\u5668\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.03213", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.03213", "abs": "https://arxiv.org/abs/2511.03213", "authors": ["Pengcheng Su", "Haibo Cheng", "Ping Wang"], "title": "Bayesian Advantage of Re-Identification Attack in the Shuffle Model", "comment": "Accepted by CSF 2026 -- 39th IEEE Computer Security Foundations\n  Symposium", "summary": "The shuffle model, which anonymizes data by randomly permuting user messages,\nhas been widely adopted in both cryptography and differential privacy. In this\nwork, we present the first systematic study of the Bayesian advantage in\nre-identifying a user's message under the shuffle model. We begin with a basic\nsetting: one sample is drawn from a distribution $P$, and $n - 1$ samples are\ndrawn from a distribution $Q$, after which all $n$ samples are randomly\nshuffled. We define $\\beta_n(P, Q)$ as the success probability of a\nBayes-optimal adversary in identifying the sample from $P$, and define the\nadditive and multiplicative Bayesian advantages as $\\mathsf{Adv}_n^{+}(P, Q) =\n\\beta_n(P,Q) - \\frac{1}{n}$ and $\\mathsf{Adv}_n^{\\times}(P, Q) = n \\cdot\n\\beta_n(P,Q)$, respectively.\n  We derive exact analytical expressions and asymptotic characterizations of\n$\\beta_n(P, Q)$, along with evaluations in several representative scenarios.\nFurthermore, we establish (nearly) tight mutual bounds between the additive\nBayesian advantage and the total variation distance.\n  Finally, we extend our analysis beyond the basic setting and present, for the\nfirst time, an upper bound on the success probability of Bayesian attacks in\nshuffle differential privacy. Specifically, when the outputs of $n$ users--each\nprocessed through an $\\varepsilon$-differentially private local randomizer--are\nshuffled, the probability that an attacker successfully re-identifies any\ntarget user's message is at most $e^{\\varepsilon}/n$.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u6df7\u6d17\u6a21\u578b\u4e0b\u7684\u8d1d\u53f6\u65af\u4f18\u52bf\uff0c\u5206\u6790\u4e86\u5728\u6df7\u6d17\u6570\u636e\u4e2d\u91cd\u65b0\u8bc6\u522b\u7528\u6237\u6d88\u606f\u7684\u6210\u529f\u6982\u7387\uff0c\u5e76\u5efa\u7acb\u4e86\u4e0e\u603b\u53d8\u5dee\u8ddd\u79bb\u7684\u7d27\u5bc6\u8054\u7cfb\uff0c\u6700\u540e\u7ed9\u51fa\u4e86\u5dee\u5206\u9690\u79c1\u6df7\u6d17\u6a21\u578b\u4e2d\u8d1d\u53f6\u65af\u653b\u51fb\u6210\u529f\u6982\u7387\u7684\u4e0a\u754c\u3002", "motivation": "\u6df7\u6d17\u6a21\u578b\u5728\u5bc6\u7801\u5b66\u548c\u5dee\u5206\u9690\u79c1\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5bf9\u5176\u5728\u8d1d\u53f6\u65af\u653b\u51fb\u4e0b\u7684\u5b89\u5168\u6027\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5206\u6790\u6df7\u6d17\u6a21\u578b\u4e2d\u91cd\u65b0\u8bc6\u522b\u7528\u6237\u6d88\u606f\u7684\u8d1d\u53f6\u65af\u4f18\u52bf\u3002", "method": "\u5b9a\u4e49\u4e86\u57fa\u672c\u8bbe\u7f6e\uff1a\u4ece\u5206\u5e03P\u62bd\u53d61\u4e2a\u6837\u672c\uff0c\u4ece\u5206\u5e03Q\u62bd\u53d6n-1\u4e2a\u6837\u672c\uff0c\u7136\u540e\u6df7\u6d17\u6240\u6709\u6837\u672c\u3002\u5b9a\u4e49\u4e86\u8d1d\u53f6\u65af\u6700\u4f18\u653b\u51fb\u8005\u7684\u6210\u529f\u6982\u7387\u03b2_n(P,Q)\uff0c\u4ee5\u53ca\u52a0\u6027\u548c\u4e58\u6027\u8d1d\u53f6\u65af\u4f18\u52bf\u3002\u63a8\u5bfc\u4e86\u7cbe\u786e\u89e3\u6790\u8868\u8fbe\u5f0f\u548c\u6e10\u8fd1\u7279\u5f81\uff0c\u5e76\u5728\u591a\u4e2a\u4ee3\u8868\u6027\u573a\u666f\u4e2d\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u5efa\u7acb\u4e86\u52a0\u6027\u8d1d\u53f6\u65af\u4f18\u52bf\u4e0e\u603b\u53d8\u5dee\u8ddd\u79bb\u4e4b\u95f4\u7684\uff08\u8fd1\u4e4e\uff09\u7d27\u81f4\u4e92\u754c\u3002\u5728\u5dee\u5206\u9690\u79c1\u6df7\u6d17\u6a21\u578b\u4e2d\uff0c\u5f53n\u4e2a\u7528\u6237\u901a\u8fc7\u03b5-\u5dee\u5206\u9690\u79c1\u672c\u5730\u968f\u673a\u5316\u5668\u5904\u7406\u540e\u6df7\u6d17\u8f93\u51fa\u65f6\uff0c\u653b\u51fb\u8005\u6210\u529f\u91cd\u65b0\u8bc6\u522b\u4efb\u4f55\u76ee\u6807\u7528\u6237\u6d88\u606f\u7684\u6982\u7387\u6700\u591a\u4e3ae^\u03b5/n\u3002", "conclusion": "\u672c\u6587\u4e3a\u6df7\u6d17\u6a21\u578b\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u9996\u4e2a\u7cfb\u7edf\u6027\u7684\u8d1d\u53f6\u65af\u5206\u6790\u6846\u67b6\uff0c\u5efa\u7acb\u4e86\u8d1d\u53f6\u65af\u4f18\u52bf\u4e0e\u7edf\u8ba1\u8ddd\u79bb\u7684\u5b9a\u91cf\u5173\u7cfb\uff0c\u5e76\u4e3a\u5dee\u5206\u9690\u79c1\u6df7\u6d17\u6a21\u578b\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u3002"}}
{"id": "2511.03609", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03609", "abs": "https://arxiv.org/abs/2511.03609", "authors": ["Cameron Calk", "Emmanuel Godard"], "title": "Stone Duality Proofs for Colorless Distributed Computability Theorems", "comment": null, "summary": "We introduce a new topological encoding by spectral spaces of executions of\n  round-based full-information adversaries, a model of distributed computations\nthat is functorially presented and that\n  contains many message adversaries. We give a characterization of the\nsolvability of colorless tasks against compact adversaries.\n  Message adversaries are distributed\n  models that are known to be very expressive despite being\n  round-based and crash-free. Colorless tasks are\n  an important class of distributed tasks. For a colorless task, the\n  specification does not depend upon the multiplicity of input or\n  output values, like the ubiquitous agreement tasks.\n  Therefore, our result is a significant\n  step toward unifying topological methods in distributed computing.\n  The main insight is to consider global states obtained after finite\nexecutions of a distributed protocol\n  not as abstract\n  simplicial complexes as previously done, but as spectral\n  spaces, considering the Alexandrov topology on the faces poset. Given\n  an adversary $\\mathcal M$ with a set of inputs $\\mathcal I$,\n  we define a limit object $\\Pi^\\infty_\\mathcal M(\\mathcal I)$\n  by projective limit in the category of spectral spaces. We derive a new\ngeneral distributed computability\n  theorem using Stone duality: there exists an algorithm solving a colorless\ntask $(\\mathcal I,\\mathcal O,\\Delta)$\n  against the compact adversary $\\mathcal M$ if and only if there exists a\nspectral\n  map $f:\\Pi^\\infty_\\mathcal M(\\mathcal I)\\longrightarrow\\mathcal O$ compatible\nwith $\\Delta$.\n  From this general characterization are derived many known colorless\ncomputability\n  theorems.\n  Quite surprisingly, colored and uncolored models have the same\n  computability power (they solve the same tasks). Our new proofs give\n  topological reasons for this equivalence, previously known through\n  algorithmic reductions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8c31\u7a7a\u95f4\u7684\u62d3\u6251\u7f16\u7801\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u6790\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u57fa\u4e8e\u8f6e\u6b21\u7684\u5168\u4fe1\u606f\u5bf9\u624b\u6a21\u578b\uff0c\u7ed9\u51fa\u4e86\u65e0\u8272\u4efb\u52a1\u53ef\u89e3\u6027\u7684\u7279\u5f81\u5316\uff0c\u5e76\u901a\u8fc7Stone\u5bf9\u5076\u6027\u5efa\u7acb\u4e86\u901a\u7528\u7684\u5206\u5e03\u5f0f\u53ef\u8ba1\u7b97\u6027\u5b9a\u7406\u3002", "motivation": "\u7edf\u4e00\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u62d3\u6251\u65b9\u6cd5\uff0c\u4e3a\u6d88\u606f\u5bf9\u624b\u6a21\u578b\u4e0b\u7684\u65e0\u8272\u4efb\u52a1\u53ef\u89e3\u6027\u63d0\u4f9b\u66f4\u4e00\u822c\u7684\u7279\u5f81\u5316\uff0c\u5e76\u89e3\u91ca\u5f69\u8272\u4e0e\u65e0\u8272\u6a21\u578b\u8ba1\u7b97\u80fd\u529b\u7b49\u4ef7\u6027\u7684\u62d3\u6251\u539f\u56e0\u3002", "method": "\u4f7f\u7528\u8c31\u7a7a\u95f4\u5bf9\u5206\u5e03\u5f0f\u534f\u8bae\u6267\u884c\u8fdb\u884c\u62d3\u6251\u7f16\u7801\uff0c\u8003\u8651\u9762\u504f\u5e8f\u96c6\u4e0a\u7684Alexandrov\u62d3\u6251\uff0c\u901a\u8fc7\u8c31\u7a7a\u95f4\u8303\u7574\u4e2d\u7684\u6295\u5f71\u6781\u9650\u5b9a\u4e49\u6781\u9650\u5bf9\u8c61\uff0c\u5e94\u7528Stone\u5bf9\u5076\u6027\u5efa\u7acb\u53ef\u8ba1\u7b97\u6027\u5b9a\u7406\u3002", "result": "\u5f97\u5230\u4e86\u65e0\u8272\u4efb\u52a1\u53ef\u89e3\u6027\u7684\u5145\u5206\u5fc5\u8981\u6761\u4ef6\uff1a\u5b58\u5728\u4e0e\u0394\u517c\u5bb9\u7684\u8c31\u6620\u5c04f:\u03a0\u221e_M(I)\u2192O\u3002\u4ece\u8fd9\u4e00\u901a\u7528\u7279\u5f81\u5316\u53ef\u4ee5\u63a8\u5bfc\u51fa\u8bb8\u591a\u5df2\u77e5\u7684\u65e0\u8272\u53ef\u8ba1\u7b97\u6027\u5b9a\u7406\uff0c\u5e76\u89e3\u91ca\u4e86\u5f69\u8272\u4e0e\u65e0\u8272\u6a21\u578b\u8ba1\u7b97\u80fd\u529b\u7b49\u4ef7\u6027\u7684\u62d3\u6251\u539f\u56e0\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u62d3\u6251\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u8c31\u7a7a\u95f4\u548cStone\u5bf9\u5076\u6027\u5efa\u7acb\u4e86\u901a\u7528\u7684\u53ef\u8ba1\u7b97\u6027\u7406\u8bba\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u95f4\u8ba1\u7b97\u80fd\u529b\u7b49\u4ef7\u6027\u7684\u6df1\u5c42\u62d3\u6251\u673a\u5236\u3002"}}
{"id": "2511.03092", "categories": ["cs.AI", "cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03092", "abs": "https://arxiv.org/abs/2511.03092", "authors": ["Jonathan Li", "Nasim Farahini", "Evgenii Iuliugin", "Magnus Vesterlund", "Christian Haggstrom", "Guangtao Wang", "Shubhangi Upasani", "Ayush Sachdeva", "Rui Li", "Faline Fu", "Chen Wu", "Ayesha Siddiqua", "John Long", "Tuowen Zhao", "Matheen Musaddiq", "Hakan Zeffer", "Yun Du", "Mingran Wang", "Qinghua Li", "Bo Li", "Urmish Thakker", "Raghu Prabhakar"], "title": "SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators", "comment": null, "summary": "The proliferation of 100B+ parameter Large Language Models (LLMs) with 100k+\ncontext length support have resulted in increasing demands for on-chip memory\nto support large KV caches. Techniques such as StreamingLLM and SnapKV\ndemonstrate how to control KV cache size while maintaining model accuracy. Yet,\nthese techniques are not commonly used within industrial deployments using\nframeworks like vLLM or SGLang. The reason is twofold: on one hand, the static\ngraphs and continuous batching methodology employed by these frameworks make it\ndifficult to admit modifications to the standard multi-head attention\nalgorithm, while on the other hand, the accuracy implications of such\ntechniques on modern instruction-following and reasoning models are not well\nunderstood, obfuscating the need for implementing these techniques. In this\npaper, we explore these accuracy implications on Llama-3.1-8B-Instruct and\nDeepSeek-R1, and develop SnapStream, a KV cache compression method that can be\ndeployed at scale. We demonstrate the efficacy of SnapStream in a 16-way\ntensor-parallel deployment of DeepSeek-671B on SambaNova SN40L accelerators\nrunning at 128k context length and up to 1832 tokens per second in a real\nproduction setting. SnapStream enables $4\\times$ improved on-chip memory usage\nand introduces minimal accuracy degradation on LongBench-v2, AIME24 and\nLiveCodeBench. To the best of our knowledge, this is the first implementation\nof sparse KV attention techniques deployed in a production inference system\nwith static graphs and continuous batching.", "AI": {"tldr": "SnapStream\u662f\u4e00\u79cdKV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\uff0c\u53ef\u5728\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\uff0c\u5df2\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u5b9e\u73b04\u500d\u5185\u5b58\u6539\u8fdb\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u652f\u6301\u957f\u4e0a\u4e0b\u6587\u5bfc\u81f4KV\u7f13\u5b58\u5185\u5b58\u9700\u6c42\u6fc0\u589e\uff0c\u73b0\u6709\u538b\u7f29\u6280\u672f\u96be\u4ee5\u5728\u5de5\u4e1a\u90e8\u7f72\u6846\u67b6\u4e2d\u5e94\u7528\uff0c\u4e14\u5bf9\u73b0\u4ee3\u6307\u4ee4\u9075\u5faa\u6a21\u578b\u7684\u5f71\u54cd\u4e0d\u660e\u786e\u3002", "method": "\u5f00\u53d1SnapStream KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\uff0c\u5728\u9759\u6001\u56fe\u548c\u8fde\u7eed\u6279\u5904\u7406\u7684\u751f\u4ea7\u73af\u5883\u4e2d\u5b9e\u73b0\u7a00\u758fKV\u6ce8\u610f\u529b\u6280\u672f\u3002", "result": "\u5728DeepSeek-671B\u768416\u8def\u5f20\u91cf\u5e76\u884c\u90e8\u7f72\u4e2d\uff0c\u5b9e\u73b04\u500d\u5185\u5b58\u4f7f\u7528\u6539\u8fdb\uff0c128k\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u8fbe\u52301832 tokens/\u79d2\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7cbe\u5ea6\u635f\u5931\u6700\u5c0f\u3002", "conclusion": "SnapStream\u662f\u9996\u4e2a\u5728\u751f\u4ea7\u63a8\u7406\u7cfb\u7edf\u4e2d\u6210\u529f\u90e8\u7f72\u7684\u7a00\u758fKV\u6ce8\u610f\u529b\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u5de5\u4e1a\u90e8\u7f72\u4e2d\u7684KV\u7f13\u5b58\u5185\u5b58\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2511.03662", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03662", "abs": "https://arxiv.org/abs/2511.03662", "authors": ["Yannis Coutouly", "Emmanuel Godard"], "title": "A General Input-Dependent Colorless Computability Theorem and Applications to Core-Dependent Adversaries", "comment": "OPODIS-25 version", "summary": "Distributed computing tasks can be presented with a triple $(\\I,\\Ou,\\Delta)$.\nThe solvability of a colorless task on the Iterated Immediate Snapshot model\n(IIS) has been characterized by the Colorless Computability Theorem\n\\cite[Th.4.3.1]{HKRbook}. A recent paper~\\cite{CG-24} generalizes this theorem\nfor any message adversaries $\\ma \\subseteq IIS$ by geometric methods. In 2001,\nMost\\'efaoui, Rajsbaum, Raynal, and Roy \\cite{condbased} introduced\n\\emph{condition-based adversaries}. This setting considers a particular\nadversary that will be applied only to a subset of input configurations. In\nthis setting, they studied the $k$-set agreement task with condition-based\n$t$-resilient adversaries and obtained a sufficient condition on the conditions\nthat make $k$-Set Agreement solvable. In this paper we have three\ncontributions:\n  -We generalize the characterization of~\\cite{CG-24} to \\emph{input-dependent}\nadversaries, which means that the adversaries can change depending on the input\nconfiguration.\n  - We show that core-resilient adversaries of $IIS_n$ have the same\ncomputability power as the core-resilient adversaries of $IIS_n$ where crashes\nonly happen at the start.\n  - Using the two previous contributions, we provide a necessary and sufficient\ncharacterization of the condition-based, core-dependent adversaries that can\nsolve $k$-Set Agreement. We also distinguish four settings that may appear when\npresenting a distributed task as $(\\I,\\Ou,\\Delta)$. Finally, in a later\nsection, we present structural properties on the carrier map $\\Delta$. Such\nproperties allow simpler proof, without changing the computability power of the\ntask. Most of the proofs in this article leverage the topological framework\nused in distributed computing by using simple geometric constructions.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u65e0\u8272\u4efb\u52a1\u7684\u53ef\u884c\u6027\u7406\u8bba\uff0c\u5c06\u6d88\u606f\u5bf9\u624b\u6a21\u578b\u63a8\u5e7f\u5230\u8f93\u5165\u4f9d\u8d56\u578b\u5bf9\u624b\uff0c\u8bc1\u660e\u4e86\u6838\u5fc3\u5f39\u6027\u5bf9\u624b\u5728IIS\u6a21\u578b\u4e2d\u7684\u8ba1\u7b97\u80fd\u529b\u7b49\u4ef7\u6027\uff0c\u5e76\u7ed9\u51fa\u4e86k-\u96c6\u5408\u534f\u8bae\u5728\u6761\u4ef6\u57fa\u7840\u3001\u6838\u5fc3\u4f9d\u8d56\u5bf9\u624b\u4e0b\u7684\u5145\u8981\u6761\u4ef6\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u56fa\u5b9a\u6d88\u606f\u5bf9\u624b\u6a21\u578b\uff0c\u800c\u5b9e\u9645\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u5bf9\u624b\u884c\u4e3a\u53ef\u80fd\u4f9d\u8d56\u4e8e\u8f93\u5165\u914d\u7f6e\u3002\u672c\u6587\u65e8\u5728\u6269\u5c55\u8ba1\u7b97\u53ef\u884c\u6027\u7406\u8bba\uff0c\u7814\u7a76\u8f93\u5165\u4f9d\u8d56\u578b\u5bf9\u624b\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u5e76\u6df1\u5165\u5206\u6790k-\u96c6\u5408\u534f\u8bae\u5728\u4e0d\u540c\u5bf9\u624b\u6a21\u578b\u4e0b\u7684\u53ef\u89e3\u6027\u6761\u4ef6\u3002", "method": "\u91c7\u7528\u62d3\u6251\u6846\u67b6\u548c\u51e0\u4f55\u6784\u9020\u65b9\u6cd5\uff0c\u5c06CG-24\u7684\u51e0\u4f55\u65b9\u6cd5\u63a8\u5e7f\u5230\u8f93\u5165\u4f9d\u8d56\u578b\u5bf9\u624b\uff0c\u5206\u6790\u6838\u5fc3\u5f39\u6027\u5bf9\u624b\u5728IIS\u6a21\u578b\u4e2d\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u5efa\u7acb\u6761\u4ef6\u57fa\u7840\u5bf9\u624b\u4e0bk-\u96c6\u5408\u534f\u8bae\u7684\u5145\u8981\u6761\u4ef6\u3002", "result": "\u8bc1\u660e\u4e86\u8f93\u5165\u4f9d\u8d56\u578b\u5bf9\u624b\u7684\u53ef\u884c\u6027\u7279\u5f81\u5316\uff0c\u6838\u5fc3\u5f39\u6027\u5bf9\u624b\u5728IIS\u6a21\u578b\u4e2d\u7684\u8ba1\u7b97\u80fd\u529b\u7b49\u4ef7\u6027\uff0c\u4ee5\u53cak-\u96c6\u5408\u534f\u8bae\u5728\u6761\u4ef6\u57fa\u7840\u3001\u6838\u5fc3\u4f9d\u8d56\u5bf9\u624b\u4e0b\u7684\u5145\u8981\u53ef\u89e3\u6761\u4ef6\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u6269\u5c55\u4e86\u5206\u5e03\u5f0f\u8ba1\u7b97\u53ef\u884c\u6027\u7406\u8bba\uff0c\u4e3a\u8f93\u5165\u4f9d\u8d56\u578b\u5bf9\u624b\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u7279\u5f81\u5316\uff0c\u6df1\u5316\u4e86\u5bf9k-\u96c6\u5408\u534f\u8bae\u5728\u4e0d\u540c\u5bf9\u624b\u6a21\u578b\u4e0b\u53ef\u89e3\u6027\u7684\u7406\u89e3\uff0c\u4e3a\u5206\u5e03\u5f0f\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2511.03106", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03106", "abs": "https://arxiv.org/abs/2511.03106", "authors": ["Katherine C. Kellogg", "Bingyang Ye", "Yifan Hu", "Guergana K. Savova", "Byron Wallace", "Danielle S. Bitterman"], "title": "Large language models require a new form of oversight: capability-based monitoring", "comment": "Under review", "summary": "The rapid adoption of large language models (LLMs) in healthcare has been\naccompanied by scrutiny of their oversight. Existing monitoring approaches,\ninherited from traditional machine learning (ML), are task-based and founded on\nassumed performance degradation arising from dataset drift. In contrast, with\nLLMs, inevitable model degradation due to changes in populations compared to\nthe training dataset cannot be assumed, because LLMs were not trained for any\nspecific task in any given population. We therefore propose a new organizing\nprinciple guiding generalist LLM monitoring that is scalable and grounded in\nhow these models are developed and used in practice: capability-based\nmonitoring. Capability-based monitoring is motivated by the fact that LLMs are\ngeneralist systems whose overlapping internal capabilities are reused across\nnumerous downstream tasks. Instead of evaluating each downstream task\nindependently, this approach organizes monitoring around shared model\ncapabilities, such as summarization, reasoning, translation, or safety\nguardrails, in order to enable cross-task detection of systemic weaknesses,\nlong-tail errors, and emergent behaviors that task-based monitoring may miss.\nWe describe considerations for developers, organizational leaders, and\nprofessional societies for implementing a capability-based monitoring approach.\nUltimately, capability-based monitoring will provide a scalable foundation for\nsafe, adaptive, and collaborative monitoring of LLMs and future generalist\nartificial intelligence models in healthcare.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u80fd\u529b\u7684\u5927\u8bed\u8a00\u6a21\u578b\u76d1\u63a7\u65b0\u65b9\u6cd5\uff0c\u66ff\u4ee3\u4f20\u7edf\u57fa\u4e8e\u4efb\u52a1\u7684\u673a\u5668\u5b66\u4e60\u76d1\u63a7\uff0c\u4ee5\u89e3\u51b3LLM\u5728\u533b\u7597\u9886\u57df\u5e94\u7528\u4e2d\u7684\u7cfb\u7edf\u6027\u5f31\u70b9\u68c0\u6d4b\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u4efb\u52a1\u7684\u673a\u5668\u5b66\u4e60\u76d1\u63a7\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u56e0\u4e3aLLM\u4e0d\u662f\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u6216\u7279\u5b9a\u4eba\u7fa4\u8bad\u7ec3\u7684\uff0c\u5176\u6027\u80fd\u9000\u5316\u6a21\u5f0f\u4e0e\u4f20\u7edfML\u4e0d\u540c\uff0c\u9700\u8981\u65b0\u7684\u76d1\u63a7\u7ec4\u7ec7\u539f\u5219\u3002", "method": "\u63d0\u51fa\u80fd\u529b\u57fa\u7840\u76d1\u63a7\u65b9\u6cd5\uff0c\u56f4\u7ed5LLM\u5171\u4eab\u7684\u5185\u90e8\u80fd\u529b\uff08\u5982\u603b\u7ed3\u3001\u63a8\u7406\u3001\u7ffb\u8bd1\u3001\u5b89\u5168\u9632\u62a4\u7b49\uff09\u7ec4\u7ec7\u76d1\u63a7\uff0c\u800c\u975e\u72ec\u7acb\u8bc4\u4f30\u6bcf\u4e2a\u4e0b\u6e38\u4efb\u52a1\uff0c\u5b9e\u73b0\u8de8\u4efb\u52a1\u7684\u7cfb\u7edf\u6027\u5f31\u70b9\u68c0\u6d4b\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u68c0\u6d4b\u5230\u57fa\u4e8e\u4efb\u52a1\u76d1\u63a7\u53ef\u80fd\u9057\u6f0f\u7684\u7cfb\u7edf\u6027\u5f31\u70b9\u3001\u957f\u5c3e\u9519\u8bef\u548c\u6d8c\u73b0\u884c\u4e3a\uff0c\u4e3aLLM\u5728\u533b\u7597\u9886\u57df\u7684\u76d1\u63a7\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002", "conclusion": "\u80fd\u529b\u57fa\u7840\u76d1\u63a7\u4e3a\u533b\u7597\u9886\u57dfLLM\u548c\u672a\u6765\u901a\u7528\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u7684\u5b89\u5168\u3001\u81ea\u9002\u5e94\u548c\u534f\u4f5c\u76d1\u63a7\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u6846\u67b6\u3002"}}
{"id": "2511.03341", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2511.03341", "abs": "https://arxiv.org/abs/2511.03341", "authors": ["Haomin Li", "Fangxin Liu", "Chenyang Guan", "Zongwu Wang", "Li Jiang", "Haibing Guan"], "title": "LaMoS: Enabling Efficient Large Number Modular Multiplication through SRAM-based CiM Acceleration", "comment": "Accepted by 2026 Design, Automation and Test in Europe Conference\n  (DATE 2026)", "summary": "Barrett's algorithm is one of the most widely used methods for performing\nmodular multiplication, a critical nonlinear operation in modern privacy\ncomputing techniques such as homomorphic encryption (HE) and zero-knowledge\nproofs (ZKP). Since modular multiplication dominates the processing time in\nthese applications, computational complexity and memory limitations\nsignificantly impact performance. Computing-in-Memory (CiM) is a promising\napproach to tackle this problem. However, existing schemes currently suffer\nfrom two main problems: 1) Most works focus on low bit-width modular\nmultiplication, which is inadequate for mainstream cryptographic algorithms\nsuch as elliptic curve cryptography (ECC) and the RSA algorithm, both of which\nrequire high bit-width operations; 2) Recent efforts targeting large number\nmodular multiplication rely on inefficient in-memory logic operations,\nresulting in high scaling costs for larger bit-widths and increased latency. To\naddress these issues, we propose LaMoS, an efficient SRAM-based CiM design for\nlarge-number modular multiplication, offering high scalability and area\nefficiency. First, we analyze the Barrett's modular multiplication method and\nmap the workload onto SRAM CiM macros for high bit-width cases. Additionally,\nwe develop an efficient CiM architecture and dataflow to optimize large-number\nmodular multiplication. Finally, we refine the mapping scheme for better\nscalability in high bit-width scenarios using workload grouping. Experimental\nresults show that LaMoS achieves a $7.02\\times$ speedup and reduces high\nbit-width scaling costs compared to existing SRAM-based CiM designs.", "AI": {"tldr": "LaMoS\u662f\u4e00\u79cd\u9ad8\u6548\u7684SRAM\u57fa\u5185\u5b58\u8ba1\u7b97\u8bbe\u8ba1\uff0c\u7528\u4e8e\u5927\u6570\u6a21\u4e58\u8fd0\u7b97\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6848\u5728\u4e3b\u6d41\u5bc6\u7801\u7b97\u6cd5\u4e2d\u9ad8\u6bd4\u7279\u4f4d\u5bbd\u9700\u6c42\u4e0d\u8db3\u548c\u6269\u5c55\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5185\u5b58\u8ba1\u7b97\u65b9\u6848\u4e3b\u8981\u5173\u6ce8\u4f4e\u6bd4\u7279\u4f4d\u5bbd\u6a21\u4e58\uff0c\u65e0\u6cd5\u6ee1\u8db3ECC\u548cRSA\u7b49\u4e3b\u6d41\u5bc6\u7801\u7b97\u6cd5\u7684\u9ad8\u6bd4\u7279\u4f4d\u5bbd\u9700\u6c42\uff1b\u540c\u65f6\u73b0\u6709\u5927\u6570\u6a21\u4e58\u65b9\u6848\u4f9d\u8d56\u4f4e\u6548\u7684\u5185\u5b58\u903b\u8f91\u64cd\u4f5c\uff0c\u5bfc\u81f4\u9ad8\u6269\u5c55\u6210\u672c\u548c\u5ef6\u8fdf\u3002", "method": "\u5206\u6790Barrett\u6a21\u4e58\u65b9\u6cd5\uff0c\u5c06\u9ad8\u6bd4\u7279\u4f4d\u5bbd\u5de5\u4f5c\u8d1f\u8f7d\u6620\u5c04\u5230SRAM\u5185\u5b58\u8ba1\u7b97\u5b8f\uff1b\u5f00\u53d1\u9ad8\u6548\u7684\u5185\u5b58\u8ba1\u7b97\u67b6\u6784\u548c\u6570\u636e\u6d41\u4f18\u5316\u5927\u6570\u6a21\u4e58\uff1b\u901a\u8fc7\u5de5\u4f5c\u8d1f\u8f7d\u5206\u7ec4\u6539\u8fdb\u6620\u5c04\u65b9\u6848\u4ee5\u63d0\u9ad8\u53ef\u6269\u5c55\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cLaMoS\u76f8\u6bd4\u73b0\u6709SRAM\u57fa\u5185\u5b58\u8ba1\u7b97\u8bbe\u8ba1\u5b9e\u73b0\u4e867.02\u500d\u7684\u52a0\u901f\uff0c\u5e76\u964d\u4f4e\u4e86\u9ad8\u6bd4\u7279\u4f4d\u5bbd\u7684\u6269\u5c55\u6210\u672c\u3002", "conclusion": "LaMoS\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u53ef\u6269\u5c55\u6027\u548c\u9762\u79ef\u6548\u7387\u7684\u5927\u6570\u6a21\u4e58\u5185\u5b58\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6848\u5728\u6027\u80fd\u548c\u6269\u5c55\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2511.03247", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03247", "abs": "https://arxiv.org/abs/2511.03247", "authors": ["Amy Chang", "Nicholas Conley", "Harish Santhanalakshmi Ganesan", "Adam Swanda"], "title": "Death by a Thousand Prompts: Open Model Vulnerability Analysis", "comment": null, "summary": "Open-weight models provide researchers and developers with accessible\nfoundations for diverse downstream applications. We tested the safety and\nsecurity postures of eight open-weight large language models (LLMs) to identify\nvulnerabilities that may impact subsequent fine-tuning and deployment. Using\nautomated adversarial testing, we measured each model's resilience against\nsingle-turn and multi-turn prompt injection and jailbreak attacks. Our findings\nreveal pervasive vulnerabilities across all tested models, with multi-turn\nattacks achieving success rates between 25.86\\% and 92.78\\% -- representing a\n$2\\times$ to $10\\times$ increase over single-turn baselines. These results\nunderscore a systemic inability of current open-weight models to maintain\nsafety guardrails across extended interactions. We assess that alignment\nstrategies and lab priorities significantly influence resilience:\ncapability-focused models such as Llama 3.3 and Qwen 3 demonstrate higher\nmulti-turn susceptibility, whereas safety-oriented designs such as Google Gemma\n3 exhibit more balanced performance.\n  The analysis concludes that open-weight models, while crucial for innovation,\npose tangible operational and ethical risks when deployed without layered\nsecurity controls. These findings are intended to inform practitioners and\ndevelopers of the potential risks and the value of professional AI security\nsolutions to mitigate exposure. Addressing multi-turn vulnerabilities is\nessential to ensure the safe, reliable, and responsible deployment of\nopen-weight LLMs in enterprise and public domains. We recommend adopting a\nsecurity-first design philosophy and layered protections to ensure resilient\ndeployments of open-weight models.", "AI": {"tldr": "\u6d4b\u8bd58\u4e2a\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u9632\u5fa1\u80fd\u529b\uff0c\u53d1\u73b0\u591a\u8f6e\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe25.86%-92.78%\uff0c\u6bd4\u5355\u8f6e\u653b\u51fb\u9ad82-10\u500d\uff0c\u663e\u793a\u5f53\u524d\u5f00\u6e90\u6a21\u578b\u5728\u6301\u7eed\u5bf9\u8bdd\u4e2d\u96be\u4ee5\u7ef4\u6301\u5b89\u5168\u9632\u62a4\u3002", "motivation": "\u8bc4\u4f30\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0b\u6e38\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u98ce\u9669\uff0c\u8bc6\u522b\u53ef\u80fd\u5f71\u54cd\u5fae\u8c03\u548c\u90e8\u7f72\u7684\u6f0f\u6d1e\uff0c\u4e3a\u5f00\u53d1\u8005\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u5b89\u5168\u53c2\u8003\u3002", "method": "\u4f7f\u7528\u81ea\u52a8\u5316\u5bf9\u6297\u6d4b\u8bd5\uff0c\u6d4b\u91cf\u6a21\u578b\u5bf9\u5355\u8f6e\u548c\u591a\u8f6e\u63d0\u793a\u6ce8\u5165\u53ca\u8d8a\u72f1\u653b\u51fb\u7684\u62b5\u6297\u80fd\u529b\u3002", "result": "\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u90fd\u5b58\u5728\u666e\u904d\u6f0f\u6d1e\uff0c\u591a\u8f6e\u653b\u51fb\u6210\u529f\u7387\u663e\u8457\u9ad8\u4e8e\u5355\u8f6e\u653b\u51fb\uff1b\u80fd\u529b\u5bfc\u5411\u6a21\u578b\uff08\u5982Llama 3.3\u3001Qwen 3\uff09\u591a\u8f6e\u6613\u611f\u6027\u66f4\u9ad8\uff0c\u5b89\u5168\u5bfc\u5411\u6a21\u578b\uff08\u5982Google Gemma 3\uff09\u8868\u73b0\u66f4\u5747\u8861\u3002", "conclusion": "\u5f00\u6e90\u6a21\u578b\u867d\u4fc3\u8fdb\u521b\u65b0\uff0c\u4f46\u90e8\u7f72\u65f6\u5b58\u5728\u64cd\u4f5c\u548c\u9053\u5fb7\u98ce\u9669\uff0c\u9700\u8981\u91c7\u7528\u5b89\u5168\u4f18\u5148\u8bbe\u8ba1\u548c\u5206\u5c42\u4fdd\u62a4\u63aa\u65bd\uff0c\u786e\u4fdd\u5728\u4f01\u4e1a\u548c\u516c\u5171\u9886\u57df\u7684\u53ef\u9760\u90e8\u7f72\u3002"}}
{"id": "2511.03108", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03108", "abs": "https://arxiv.org/abs/2511.03108", "authors": ["Azim Ospanov", "Farzan Farnia", "Roozbeh Yousefzadeh"], "title": "miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward", "comment": null, "summary": "We perform a thorough analysis of the formal and informal statements in the\nminiF2F benchmark from the perspective of an AI system that is tasked to\nparticipate in a math Olympiad consisting of the problems in miniF2F. In such\nsetting, the model has to read and comprehend the problems in natural language,\nformalize them in Lean language, then proceed with proving the problems, and it\nwill get credit for each problem if the formal proof corresponds to the\noriginal informal statement presented to the model. Our evaluation results\nreveal that the best accuracy of such pipeline can be about 36% using the SoTA\nmodels in the literature, considerably lower than the individual SoTA\naccuracies, 97% and 69% reported in the autoformalization and theorem proving\nliterature. Analyzing the failure modes, we trace back a considerable portion\nof this drop to discrepancies between the formal and informal statements for\nmore than half of the problems in miniF2F. We proceed with correcting all the\nerrors, discrepancies and simplifications in formal and informal statements,\nand present the miniF2F-v2 with fully verified formal and informal statements\nand proofs. Evaluating the full theorem proving pipeline on miniF2F-v2 leads to\nthe best accuracy of 70%, a significant improvement from the 40% on the\noriginal miniF2F, yet indicating considerable misalignment between the\nautoformalization models and theorem provers. Our deep analysis suggests that a\nhigher quality benchmark can help the community better evaluate progress in the\nfield of formal reasoning and also better diagnose the failure and success\nmodes of autoformalization and theorem proving models. Our dataset is available\nat https://github.com/roozbeh-yz/miniF2F_v2.", "AI": {"tldr": "\u672c\u6587\u5bf9miniF2F\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u5f62\u5f0f\u5316\u4e0e\u975e\u5f62\u5f0f\u5316\u9648\u8ff0\u8fdb\u884c\u4e86\u6df1\u5165\u5206\u6790\uff0c\u53d1\u73b0\u539f\u59cb\u57fa\u51c6\u4e2d\u5b58\u5728\u5927\u91cf\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u5bfc\u81f4AI\u7cfb\u7edf\u5728\u6570\u5b66\u5965\u6797\u5339\u514b\u7ade\u8d5b\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u7387\u4ec5\u4e3a36%\u3002\u901a\u8fc7\u4fee\u6b63\u6240\u6709\u9519\u8bef\u548c\u5dee\u5f02\uff0c\u521b\u5efa\u4e86miniF2F-v2\u7248\u672c\uff0c\u5c06\u51c6\u786e\u7387\u63d0\u5347\u81f370%\u3002", "motivation": "\u8bc4\u4f30AI\u7cfb\u7edf\u5728\u6570\u5b66\u5965\u6797\u5339\u514b\u7ade\u8d5b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5305\u62ec\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u3001\u5f62\u5f0f\u5316\u8f6c\u6362\u548c\u5b9a\u7406\u8bc1\u660e\u7684\u5b8c\u6574\u6d41\u7a0b\uff0c\u53d1\u73b0\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u8d28\u91cf\u95ee\u9898\u5f71\u54cd\u8bc4\u4f30\u51c6\u786e\u6027\u3002", "method": "\u5bf9miniF2F\u57fa\u51c6\u8fdb\u884c\u7cfb\u7edf\u6027\u5206\u6790\uff0c\u8bc6\u522b\u5f62\u5f0f\u5316\u4e0e\u975e\u5f62\u5f0f\u5316\u9648\u8ff0\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u4fee\u6b63\u6240\u6709\u9519\u8bef\u548c\u4e0d\u4e00\u81f4\u4e4b\u5904\uff0c\u521b\u5efa\u6539\u8fdb\u7684miniF2F-v2\u6570\u636e\u96c6\uff0c\u5e76\u5728\u65b0\u6570\u636e\u96c6\u4e0a\u91cd\u65b0\u8bc4\u4f30\u5b8c\u6574\u7684\u5b9a\u7406\u8bc1\u660e\u6d41\u7a0b\u3002", "result": "\u539f\u59cbminiF2F\u4e0a\u6700\u4f73\u51c6\u786e\u7387\u4e3a36%\uff0c\u663e\u8457\u4f4e\u4e8e\u6587\u732e\u4e2d\u5355\u72ec\u62a5\u544a\u7684\u5f62\u5f0f\u5316(97%)\u548c\u5b9a\u7406\u8bc1\u660e(69%)\u7684SOTA\u51c6\u786e\u7387\u3002\u4fee\u6b63\u540e\u7684miniF2F-v2\u5c06\u51c6\u786e\u7387\u63d0\u5347\u81f370%\uff0c\u4f46\u4ecd\u663e\u793a\u5f62\u5f0f\u5316\u6a21\u578b\u4e0e\u5b9a\u7406\u8bc1\u660e\u5668\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u4e0d\u5bf9\u9f50\u3002", "conclusion": "\u9ad8\u8d28\u91cf\u7684\u57fa\u51c6\u6d4b\u8bd5\u5bf9\u4e8e\u8bc4\u4f30\u5f62\u5f0f\u63a8\u7406\u9886\u57df\u7684\u8fdb\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u591f\u66f4\u597d\u5730\u8bca\u65ad\u5f62\u5f0f\u5316\u6a21\u578b\u548c\u5b9a\u7406\u8bc1\u660e\u6a21\u578b\u7684\u5931\u8d25\u4e0e\u6210\u529f\u6a21\u5f0f\u3002miniF2F-v2\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2511.03137", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03137", "abs": "https://arxiv.org/abs/2511.03137", "authors": ["Shipeng Cen", "Ying Tan"], "title": "Using Multi-modal Large Language Model to Boost Fireworks Algorithm's Ability in Settling Challenging Optimization Tasks", "comment": null, "summary": "As optimization problems grow increasingly complex and diverse, advancements\nin optimization techniques and paradigm innovations hold significant\nimportance. The challenges posed by optimization problems are primarily\nmanifested in their non-convexity, high-dimensionality, black-box nature, and\nother unfavorable characteristics. Traditional zero-order or first-order\nmethods, which are often characterized by low efficiency, inaccurate gradient\ninformation, and insufficient utilization of optimization information, are\nill-equipped to address these challenges effectively. In recent years, the\nrapid development of large language models (LLM) has led to substantial\nimprovements in their language understanding and code generation capabilities.\nConsequently, the design of optimization algorithms leveraging large language\nmodels has garnered increasing attention from researchers. In this study, we\nchoose the fireworks algorithm(FWA) as the basic optimizer and propose a novel\napproach to assist the design of the FWA by incorporating multi-modal large\nlanguage model(MLLM). To put it simply, we propose the concept of Critical\nPart(CP), which extends FWA to complex high-dimensional tasks, and further\nutilizes the information in the optimization process with the help of the\nmulti-modal characteristics of large language models. We focus on two specific\ntasks: the \\textit{traveling salesman problem }(TSP) and \\textit{electronic\ndesign automation problem} (EDA). The experimental results show that FWAs\ngenerated under our new framework have achieved or surpassed SOTA results on\nmany problem instances.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u8bbe\u8ba1\u70df\u82b1\u7b97\u6cd5\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u5173\u952e\u90e8\u5206\u6982\u5ff5\u6269\u5c55\u70df\u82b1\u7b97\u6cd5\u5230\u590d\u6742\u9ad8\u7ef4\u4efb\u52a1\uff0c\u5e76\u5728\u65c5\u884c\u5546\u95ee\u9898\u548c\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\u95ee\u9898\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u6216\u8fbe\u5230\u5f53\u524d\u6700\u4f18\u7684\u7ed3\u679c\u3002", "motivation": "\u968f\u7740\u4f18\u5316\u95ee\u9898\u65e5\u76ca\u590d\u6742\u591a\u6837\uff0c\u4f20\u7edf\u96f6\u9636\u6216\u4e00\u9636\u65b9\u6cd5\u5728\u5904\u7406\u975e\u51f8\u6027\u3001\u9ad8\u7ef4\u6027\u3001\u9ed1\u76d2\u7279\u6027\u7b49\u95ee\u9898\u65f6\u6548\u7387\u4f4e\u4e0b\u3001\u68af\u5ea6\u4fe1\u606f\u4e0d\u51c6\u786e\u4e14\u4f18\u5316\u4fe1\u606f\u5229\u7528\u4e0d\u8db3\u3002\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u8a00\u7406\u89e3\u548c\u4ee3\u7801\u751f\u6210\u65b9\u9762\u7684\u8fdb\u6b65\u4e3a\u4f18\u5316\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u673a\u9047\u3002", "method": "\u4ee5\u70df\u82b1\u7b97\u6cd5\u4e3a\u57fa\u7840\u4f18\u5316\u5668\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u8bbe\u8ba1\uff0c\u63d0\u51fa\u5173\u952e\u90e8\u5206\u6982\u5ff5\u6765\u6269\u5c55\u70df\u82b1\u7b97\u6cd5\u5904\u7406\u590d\u6742\u9ad8\u7ef4\u4efb\u52a1\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6a21\u6001\u7279\u6027\u5145\u5206\u6316\u6398\u4f18\u5316\u8fc7\u7a0b\u4e2d\u7684\u4fe1\u606f\u3002", "result": "\u5728\u65c5\u884c\u5546\u95ee\u9898\u548c\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\u95ee\u9898\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u65b0\u6846\u67b6\u751f\u6210\u7684\u70df\u82b1\u7b97\u6cd5\u5728\u8bb8\u591a\u95ee\u9898\u5b9e\u4f8b\u4e0a\u8fbe\u5230\u6216\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u4f18\u7ed3\u679c\u3002", "conclusion": "\u5c06\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u70df\u82b1\u7b97\u6cd5\u7ed3\u5408\u7684\u65b0\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347\u4f18\u5316\u7b97\u6cd5\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u590d\u6742\u9ad8\u7ef4\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2511.03271", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03271", "abs": "https://arxiv.org/abs/2511.03271", "authors": ["Yize Liu", "Yunyun Hou", "Aina Sui"], "title": "Let the Bees Find the Weak Spots: A Path Planning Perspective on Multi-Turn Jailbreak Attacks against LLMs", "comment": null, "summary": "Large Language Models (LLMs) have been widely deployed across various\napplications, yet their potential security and ethical risks have raised\nincreasing concerns. Existing research employs red teaming evaluations,\nutilizing multi-turn jailbreaks to identify potential vulnerabilities in LLMs.\nHowever, these approaches often lack exploration of successful dialogue\ntrajectories within the attack space, and they tend to overlook the\nconsiderable overhead associated with the attack process. To address these\nlimitations, this paper first introduces a theoretical model based on\ndynamically weighted graph topology, abstracting the multi-turn attack process\nas a path planning problem. Based on this framework, we propose ABC, an\nenhanced Artificial Bee Colony algorithm for multi-turn jailbreaks, featuring a\ncollaborative search mechanism with employed, onlooker, and scout bees. This\nalgorithm significantly improves the efficiency of optimal attack path search\nwhile substantially reducing the average number of queries required. Empirical\nevaluations on three open-source and two proprietary language models\ndemonstrate the effectiveness of our approach, achieving attack success rates\nabove 90\\% across the board, with a peak of 98\\% on GPT-3.5-Turbo, and\noutperforming existing baselines. Furthermore, it achieves comparable success\nwith only 26 queries on average, significantly reducing red teaming overhead\nand highlighting its superior efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a8\u6001\u52a0\u6743\u56fe\u62d3\u6251\u7684\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u4e86ABC\u7b97\u6cd5\u6765\u9ad8\u6548\u641c\u7d22\u6700\u4f18\u653b\u51fb\u8def\u5f84\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u653b\u51fb\u6240\u9700\u7684\u67e5\u8be2\u6b21\u6570\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7ea2\u961f\u8bc4\u4f30\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u653b\u51fb\u7a7a\u95f4\u4e2d\u6210\u529f\u5bf9\u8bdd\u8f68\u8ff9\u7684\u63a2\u7d22\uff0c\u4e14\u5ffd\u89c6\u4e86\u653b\u51fb\u8fc7\u7a0b\u4e2d\u7684\u5de8\u5927\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u52a8\u6001\u52a0\u6743\u56fe\u62d3\u6251\u7684\u7406\u8bba\u6a21\u578b\uff0c\u5c06\u591a\u8f6e\u653b\u51fb\u8fc7\u7a0b\u62bd\u8c61\u4e3a\u8def\u5f84\u89c4\u5212\u95ee\u9898\uff0c\u5e76\u8bbe\u8ba1\u4e86\u589e\u5f3a\u7684\u4eba\u5de5\u8702\u7fa4\u7b97\u6cd5ABC\uff0c\u5305\u542b\u96c7\u4f63\u8702\u3001\u89c2\u5bdf\u8702\u548c\u4fa6\u5bdf\u8702\u7684\u534f\u4f5c\u641c\u7d22\u673a\u5236\u3002", "result": "\u5728\u4e09\u4e2a\u5f00\u6e90\u548c\u4e24\u4e2a\u4e13\u6709\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0c\u653b\u51fb\u6210\u529f\u7387\u5747\u8d85\u8fc790%\uff0c\u5728GPT-3.5-Turbo\u4e0a\u8fbe\u523098%\uff0c\u5e73\u5747\u4ec5\u970026\u6b21\u67e5\u8be2\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ABC\u7b97\u6cd5\u5728\u4fdd\u6301\u9ad8\u653b\u51fb\u6210\u529f\u7387\u7684\u540c\u65f6\uff0c\u5927\u5e45\u964d\u4f4e\u4e86\u7ea2\u961f\u8bc4\u4f30\u7684\u5f00\u9500\uff0c\u5c55\u73b0\u4e86\u5353\u8d8a\u7684\u6548\u7387\u4f18\u52bf\u3002"}}
{"id": "2511.03138", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03138", "abs": "https://arxiv.org/abs/2511.03138", "authors": ["Qi Li", "Jianjun Xu", "Pingtao Wei", "Jiu Li", "Peiqiang Zhao", "Jiwei Shi", "Xuan Zhang", "Yanhui Yang", "Xiaodong Hui", "Peng Xu", "Wenqin Shao"], "title": "A Proprietary Model-Based Safety Response Framework for AI Agents", "comment": null, "summary": "With the widespread application of Large Language Models (LLMs), their\nassociated security issues have become increasingly prominent, severely\nconstraining their trustworthy deployment in critical domains. This paper\nproposes a novel safety response framework designed to systematically safeguard\nLLMs at both the input and output levels. At the input level, the framework\nemploys a supervised fine-tuning-based safety classification model. Through a\nfine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused\nAttention), it performs precise risk identification and differentiated handling\nof user queries, significantly enhancing risk coverage and business scenario\nadaptability, and achieving a risk recall rate of 99.3%. At the output level,\nthe framework integrates Retrieval-Augmented Generation (RAG) with a\nspecifically fine-tuned interpretation model, ensuring all responses are\ngrounded in a real-time, trustworthy knowledge base. This approach eliminates\ninformation fabrication and enables result traceability. Experimental results\ndemonstrate that our proposed safety control model achieves a significantly\nhigher safety score on public safety evaluation benchmarks compared to the\nbaseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk\ntest set, the framework's components attained a perfect 100% safety score,\nvalidating their exceptional protective capabilities in complex risk scenarios.\nThis research provides an effective engineering pathway for building\nhigh-security, high-trust LLM applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u54cd\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u8f93\u5165\u7ea7\u5b89\u5168\u5206\u7c7b\u548c\u8f93\u51fa\u7ea7\u77e5\u8bc6\u589e\u5f3a\uff0c\u7cfb\u7edf\u6027\u5730\u4fdd\u62a4LLM\u7684\u5b89\u5168\u90e8\u7f72\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u5b89\u5168\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u4e25\u91cd\u5236\u7ea6\u4e86\u5728\u5173\u952e\u9886\u57df\u7684\u53ef\u4fe1\u90e8\u7f72\u3002", "method": "\u5728\u8f93\u5165\u7ea7\u91c7\u7528\u57fa\u4e8e\u76d1\u7763\u5fae\u8c03\u7684\u56db\u7ea7\u5b89\u5168\u5206\u7c7b\u6a21\u578b\uff08\u5b89\u5168\u3001\u4e0d\u5b89\u5168\u3001\u6761\u4ef6\u5b89\u5168\u3001\u91cd\u70b9\u5173\u6ce8\uff09\uff1b\u5728\u8f93\u51fa\u7ea7\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u4e13\u95e8\u5fae\u8c03\u7684\u89e3\u91ca\u6a21\u578b\uff0c\u786e\u4fdd\u54cd\u5e94\u57fa\u4e8e\u5b9e\u65f6\u53ef\u4fe1\u77e5\u8bc6\u5e93\u3002", "result": "\u98ce\u9669\u53ec\u56de\u7387\u8fbe\u523099.3%\uff0c\u5728\u516c\u5171\u5b89\u5168\u8bc4\u4f30\u57fa\u51c6\u4e0a\u7684\u5b89\u5168\u5f97\u5206\u663e\u8457\u9ad8\u4e8e\u57fa\u7ebf\u6a21\u578bTinyR1-Safety-8B\uff0c\u5728\u4e13\u6709\u9ad8\u98ce\u9669\u6d4b\u8bd5\u96c6\u4e0a\u7ec4\u4ef6\u83b7\u5f97100%\u5b89\u5168\u5206\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6784\u5efa\u9ad8\u5b89\u5168\u6027\u3001\u9ad8\u53ef\u4fe1\u5ea6\u7684LLM\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5de5\u7a0b\u8def\u5f84\u3002"}}
{"id": "2511.03319", "categories": ["cs.CR", "cs.CY", "cs.IR", "cs.IT", "math.IT", "H.4; K.2; K.4; J.4; J.5; D.2"], "pdf": "https://arxiv.org/pdf/2511.03319", "abs": "https://arxiv.org/abs/2511.03319", "authors": ["Giulio Caldarelli", "Massimiliano Ornaghi"], "title": "Two thousand years of the oracle problem. Insights from Ancient Delphi on the future of blockchain oracles", "comment": "Not peer reviewed", "summary": "The oracle problem refers to the inability of an agent to know if the\ninformation coming from an oracle is authentic and unbiased. In ancient times,\nphilosophers and historians debated on how to evaluate, increase, and secure\nthe reliability of oracle predictions, particularly those from Delphi, which\npertained to matters of state. Today, we refer to data carriers for automatic\nmachines as oracles, but establishing a secure channel between these oracles\nand the real world still represents a challenge. Despite numerous efforts, this\nproblem remains mostly unsolved, and the recent advent of blockchain oracles\nhas added a layer of complexity because of the decentralization of blockchains.\nThis paper conceptually connects Delphic and modern blockchain oracles,\ndeveloping a comparative framework. Leveraging blockchain oracle taxonomy,\nlexical analysis is also performed on 167 Delphic queries to shed light on the\nrelationship between oracle answer quality and question type. The presented\nframework aims first at revealing commonalities between classical and\ncomputational oracles and then at enriching the oracle analysis within each\nfield. This study contributes to the computer science literature by proposing\nstrategies to improve the reliability of blockchain oracles based on insights\nfrom Delphi and to classical literature by introducing a framework that can\nalso be applied to interpret and classify other ancient oracular mechanisms.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6bd4\u8f83\u53e4\u4ee3\u5fb7\u5c14\u6590\u795e\u8c15\u4e0e\u73b0\u4ee3\u533a\u5757\u94fe\u9884\u8a00\u673a\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u5206\u6790\u6846\u67b6\uff0c\u63a2\u8ba8\u5982\u4f55\u63d0\u9ad8\u9884\u8a00\u673a\u4fe1\u606f\u7684\u53ef\u9760\u6027\u548c\u771f\u5b9e\u6027\u3002", "motivation": "\u89e3\u51b3\u9884\u8a00\u673a\u95ee\u9898\u2014\u2014\u5373\u5982\u4f55\u786e\u4fdd\u4ece\u9884\u8a00\u673a\u83b7\u53d6\u7684\u4fe1\u606f\u662f\u771f\u5b9e\u4e14\u65e0\u504f\u89c1\u7684\uff0c\u8fd9\u4e00\u95ee\u9898\u5728\u53e4\u5178\u65f6\u4ee3\u548c\u73b0\u4ee3\u8ba1\u7b97\u9886\u57df\u90fd\u5b58\u5728\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u8fde\u63a5\u5fb7\u5c14\u6590\u795e\u8c15\u548c\u533a\u5757\u94fe\u9884\u8a00\u673a\uff0c\u63ed\u793a\u4e24\u8005\u4e4b\u95f4\u7684\u5171\u6027\uff0c\u4e3a\u6539\u8fdb\u533a\u5757\u94fe\u9884\u8a00\u673a\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u65b0\u601d\u8def\u3002", "method": "\u91c7\u7528\u6982\u5ff5\u6bd4\u8f83\u6846\u67b6\uff0c\u7ed3\u5408\u533a\u5757\u94fe\u9884\u8a00\u673a\u5206\u7c7b\u6cd5\uff0c\u5bf9167\u4e2a\u5fb7\u5c14\u6590\u67e5\u8be2\u8fdb\u884c\u8bcd\u6c47\u5206\u6790\uff0c\u7814\u7a76\u95ee\u9898\u7c7b\u578b\u4e0e\u9884\u8a00\u673a\u7b54\u6848\u8d28\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u5efa\u7acb\u4e86\u53e4\u5178\u9884\u8a00\u673a\u4e0e\u8ba1\u7b97\u9884\u8a00\u673a\u4e4b\u95f4\u7684\u6bd4\u8f83\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u5728\u4fe1\u606f\u53ef\u9760\u6027\u65b9\u9762\u7684\u5171\u540c\u6311\u6218\uff0c\u5e76\u5206\u6790\u4e86\u4e0d\u540c\u7c7b\u578b\u95ee\u9898\u5bf9\u9884\u8a00\u673a\u7b54\u6848\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8ba1\u7b97\u673a\u79d1\u5b66\u6587\u732e\u63d0\u4f9b\u4e86\u57fa\u4e8e\u5fb7\u5c14\u6590\u795e\u8c15\u7ecf\u9a8c\u6539\u8fdb\u533a\u5757\u94fe\u9884\u8a00\u673a\u53ef\u9760\u6027\u7684\u7b56\u7565\uff0c\u540c\u65f6\u4e3a\u53e4\u5178\u6587\u732e\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u7528\u4e8e\u89e3\u91ca\u548c\u5206\u7c7b\u5176\u4ed6\u53e4\u4ee3\u9884\u8a00\u673a\u5236\u7684\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2511.03169", "categories": ["cs.AI", "D.2.4; I.2.6; I.2.4; K.4.1; I.2.0"], "pdf": "https://arxiv.org/pdf/2511.03169", "abs": "https://arxiv.org/abs/2511.03169", "authors": ["Xuanxiang Huang", "Yacine Izza", "Alexey Ignatiev", "Joao Marques-Silva"], "title": "Uncovering Bugs in Formal Explainers: A Case Study with PyXAI", "comment": null, "summary": "Formal explainable artificial intelligence (XAI) offers unique theoretical\nguarantees of rigor when compared to other non-formal methods of\nexplainability. However, little attention has been given to the validation of\npractical implementations of formal explainers. This paper develops a novel\nmethodology for validating formal explainers and reports on the assessment of\nthe publicly available formal explainer PyXAI. The paper documents the\nexistence of incorrect explanations computed by PyXAI on most of the datasets\nanalyzed in the experiments, thereby confirming the importance of the proposed\nnovel methodology for the validation of formal explainers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9a8c\u8bc1\u5f62\u5f0f\u5316\u53ef\u89e3\u91caAI\uff08XAI\uff09\u65b9\u6cd5\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u8bc4\u4f30\u4e86\u516c\u5f00\u53ef\u7528\u7684\u5f62\u5f0f\u5316\u89e3\u91ca\u5668PyXAI\uff0c\u53d1\u73b0\u5176\u5728\u5927\u591a\u6570\u6570\u636e\u96c6\u4e0a\u8ba1\u7b97\u51fa\u7684\u89e3\u91ca\u5b58\u5728\u9519\u8bef\u3002", "motivation": "\u5f62\u5f0f\u5316XAI\u76f8\u6bd4\u975e\u5f62\u5f0f\u5316\u65b9\u6cd5\u5177\u6709\u7406\u8bba\u4e25\u8c28\u6027\u4fdd\u8bc1\uff0c\u4f46\u5bf9\u5176\u5b9e\u9645\u5b9e\u73b0\u7684\u9a8c\u8bc1\u5173\u6ce8\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u9a8c\u8bc1\u5f62\u5f0f\u5316\u89e3\u91ca\u5668\u7684\u65b9\u6cd5\u8bba\uff0c\u5e76\u5bf9PyXAI\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0PyXAI\u5728\u5927\u591a\u6570\u5206\u6790\u7684\u6570\u636e\u96c6\u4e0a\u8ba1\u7b97\u51fa\u7684\u89e3\u91ca\u5b58\u5728\u9519\u8bef\u3002", "conclusion": "\u8bc1\u5b9e\u4e86\u6240\u63d0\u51fa\u7684\u9a8c\u8bc1\u65b9\u6cd5\u5bf9\u5f62\u5f0f\u5316\u89e3\u91ca\u5668\u9a8c\u8bc1\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.03179", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.03179", "abs": "https://arxiv.org/abs/2511.03179", "authors": ["Varun Kumar", "George Em Karniadakis"], "title": "Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent Framework", "comment": null, "summary": "The engineering design process often demands expertise from multiple domains,\nleading to complex collaborations and iterative refinements. Traditional\nmethods can be resource-intensive and prone to inefficiencies. To address this,\nwe formalize the engineering design process through a multi-agent AI framework\nthat integrates structured design and review loops. The framework introduces\nspecialized knowledge-driven agents that collaborate to generate and refine\ndesign candidates. As an exemplar, we demonstrate its application to the\naerodynamic optimization of 4-digit NACA airfoils. The framework consists of\nthree key AI agents: a Graph Ontologist, a Design Engineer, and a Systems\nEngineer. The Graph Ontologist employs a Large Language Model (LLM) to\nconstruct two domain-specific knowledge graphs from airfoil design literature.\nThe Systems Engineer, informed by a human manager, formulates technical\nrequirements that guide design generation and evaluation. The Design Engineer\nleverages the design knowledge graph and computational tools to propose\ncandidate airfoils meeting these requirements. The Systems Engineer reviews and\nprovides feedback both qualitative and quantitative using its own knowledge\ngraph, forming an iterative feedback loop until a design is validated by the\nmanager. The final design is then optimized to maximize performance metrics\nsuch as the lift-to-drag ratio. Overall, this work demonstrates how\ncollaborative AI agents equipped with structured knowledge representations can\nenhance efficiency, consistency, and quality in the engineering design process.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53AI\u6846\u67b6\u6765\u5f62\u5f0f\u5316\u5de5\u7a0b\u8bbe\u8ba1\u8fc7\u7a0b\uff0c\u901a\u8fc7\u4e13\u4e1a\u667a\u80fd\u4f53\u534f\u4f5c\u751f\u6210\u548c\u4f18\u5316\u8bbe\u8ba1\u5019\u9009\u65b9\u6848\uff0c\u5e76\u4ee5NACA\u7ffc\u578b\u6c14\u52a8\u4f18\u5316\u4e3a\u4f8b\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u5de5\u7a0b\u8bbe\u8ba1\u65b9\u6cd5\u9700\u8981\u591a\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5bfc\u81f4\u590d\u6742\u7684\u534f\u4f5c\u548c\u8fed\u4ee3\u4f18\u5316\u8fc7\u7a0b\uff0c\u8d44\u6e90\u5bc6\u96c6\u4e14\u6548\u7387\u4f4e\u4e0b\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7AI\u591a\u667a\u80fd\u4f53\u6846\u67b6\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u6784\u5efa\u5305\u542b\u4e09\u4e2a\u5173\u952eAI\u667a\u80fd\u4f53\u7684\u6846\u67b6\uff1a\u56fe\u672c\u4f53\u5b66\u5bb6\uff08\u4f7f\u7528LLM\u6784\u5efa\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\uff09\u3001\u7cfb\u7edf\u5de5\u7a0b\u5e08\uff08\u5236\u5b9a\u6280\u672f\u9700\u6c42\uff09\u548c\u8bbe\u8ba1\u5de5\u7a0b\u5e08\uff08\u751f\u6210\u5019\u9009\u8bbe\u8ba1\uff09\u3002\u7cfb\u7edf\u901a\u8fc7\u8fed\u4ee3\u53cd\u9988\u5faa\u73af\u8fdb\u884c\u8bbe\u8ba1\u9a8c\u8bc1\u548c\u4f18\u5316\u3002", "result": "\u8be5\u6846\u67b6\u6210\u529f\u5e94\u7528\u4e8e4\u4f4d\u6570NACA\u7ffc\u578b\u7684\u6c14\u52a8\u4f18\u5316\uff0c\u80fd\u591f\u6709\u6548\u751f\u6210\u6ee1\u8db3\u6280\u672f\u9700\u6c42\u7684\u8bbe\u8ba1\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u63d0\u5347\u6027\u80fd\u6307\u6807\u5982\u5347\u963b\u6bd4\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u914d\u5907\u7ed3\u6784\u5316\u77e5\u8bc6\u8868\u793a\u7684\u534f\u4f5cAI\u667a\u80fd\u4f53\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u5de5\u7a0b\u8bbe\u8ba1\u8fc7\u7a0b\u7684\u6548\u7387\u3001\u4e00\u81f4\u6027\u548c\u8d28\u91cf\u3002"}}
{"id": "2511.03486", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.03486", "abs": "https://arxiv.org/abs/2511.03486", "authors": ["David Soler", "Carlos Dafonte", "Manuel Fern\u00e1ndez-Veiga", "Ana Fern\u00e1ndez Vilas", "Francisco J. N\u00f3voa"], "title": "Federated Anonymous Blocklisting across Service Providers and its Application to Group Messaging", "comment": "31 pages, 4 figures. Submitted to IEEE Transactions on Emerging\n  Topics in Computing", "summary": "Instant messaging has become one of the most used methods of communication\nonline, which has attracted significant attention to its underlying\ncryptographic protocols and security guarantees. Techniques to increase privacy\nsuch as End-to-End Encryption and pseudonyms have been introduced. However,\nonline spaces such as messaging groups still require moderation to prevent\nmisbehaving users from participating in them, particularly in anonymous\ncontexts.. In Anonymous Blocklisting (AB) schemes, users must prove during\nauthentication that none of their previous pseudonyms has been blocked,\npreventing misbehaving users from creating new pseudonyms. In this work we\npropose an alternative \\textit{Federated Anonymous Blocklisting} (FAB) in which\nthe centralised Service Provider is replaced by small distributed Realms, each\nwith its own blocklist. Realms can establish trust relationships between each\nother, such that when users authenticate to a realm, they must prove that they\nare not banned in any of its trusted realms. We provide an implementation of\nour proposed scheme; unlike existing AB constructions, the performance of ours\ndoes not depend on the current size of the blocklist nor requires processing\nnew additions to the blocklist. We also demonstrate its applicability to\nreal-world messaging groups by integrating our FAB scheme into the Messaging\nLayer Security protocol.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u90a6\u533f\u540d\u5c01\u7981\u65b9\u6848\uff0c\u7528\u5206\u5e03\u5f0f\u9886\u57df\u66ff\u4ee3\u96c6\u4e2d\u5f0f\u670d\u52a1\u63d0\u4f9b\u5546\uff0c\u6bcf\u4e2a\u9886\u57df\u6709\u81ea\u5df1\u7684\u5c01\u7981\u5217\u8868\uff0c\u7528\u6237\u8ba4\u8bc1\u65f6\u9700\u8981\u8bc1\u660e\u81ea\u5df1\u4e0d\u5728\u4efb\u4f55\u4fe1\u4efb\u9886\u57df\u7684\u5c01\u7981\u5217\u8868\u4e2d\u3002", "motivation": "\u5373\u65f6\u901a\u8baf\u4e2d\u9700\u8981\u9632\u6b62\u4e0d\u826f\u7528\u6237\u901a\u8fc7\u521b\u5efa\u65b0\u5047\u540d\u6765\u89c4\u907f\u5c01\u7981\uff0c\u73b0\u6709\u533f\u540d\u5c01\u7981\u65b9\u6848\u5b58\u5728\u6027\u80fd\u4f9d\u8d56\u5c01\u7981\u5217\u8868\u5927\u5c0f\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u8054\u90a6\u533f\u540d\u5c01\u7981\u65b9\u6848\uff0c\u5c06\u96c6\u4e2d\u5f0f\u670d\u52a1\u63d0\u4f9b\u5546\u66ff\u6362\u4e3a\u5c0f\u578b\u5206\u5e03\u5f0f\u9886\u57df\uff0c\u9886\u57df\u95f4\u5efa\u7acb\u4fe1\u4efb\u5173\u7cfb\uff0c\u7528\u6237\u8ba4\u8bc1\u65f6\u9700\u8bc1\u660e\u4e0d\u5728\u4efb\u4f55\u4fe1\u4efb\u9886\u57df\u7684\u5c01\u7981\u5217\u8868\u4e2d\u3002", "result": "\u5b9e\u73b0\u4e86\u8be5\u65b9\u6848\uff0c\u6027\u80fd\u4e0d\u4f9d\u8d56\u5f53\u524d\u5c01\u7981\u5217\u8868\u5927\u5c0f\uff0c\u4e5f\u4e0d\u9700\u8981\u5904\u7406\u5c01\u7981\u5217\u8868\u7684\u65b0\u589e\u6761\u76ee\uff0c\u5e76\u6210\u529f\u96c6\u6210\u5230\u6d88\u606f\u5c42\u5b89\u5168\u534f\u8bae\u4e2d\u3002", "conclusion": "\u8054\u90a6\u533f\u540d\u5c01\u7981\u65b9\u6848\u89e3\u51b3\u4e86\u73b0\u6709\u533f\u540d\u5c01\u7981\u65b9\u6848\u7684\u6027\u80fd\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u6d88\u606f\u7fa4\u7ec4\u573a\u666f\u3002"}}
{"id": "2511.03186", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03186", "abs": "https://arxiv.org/abs/2511.03186", "authors": ["Yiru Chen", "Sally Fang", "Sai Sree Harsha", "Dan Luo", "Vaishnavi Muppala", "Fei Wu", "Shun Jiang", "Kun Qian", "Yunyao Li"], "title": "Adobe Summit Concierge Evaluation with Human in the Loop", "comment": "Accepted by 6th Workshop on Data Science with Human in the Loop @\n  VLDB 2025", "summary": "Generative AI assistants offer significant potential to enhance productivity,\nstreamline information access, and improve user experience in enterprise\ncontexts. In this work, we present Summit Concierge, a domain-specific AI\nassistant developed for Adobe Summit. The assistant handles a wide range of\nevent-related queries and operates under real-world constraints such as data\nsparsity, quality assurance, and rapid deployment. To address these challenges,\nwe adopt a human-in-the-loop development workflow that combines prompt\nengineering, retrieval grounding, and lightweight human validation. We describe\nthe system architecture, development process, and real-world deployment\noutcomes. Our experience shows that agile, feedback-driven development enables\nscalable and reliable AI assistants, even in cold-start scenarios.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e3aAdobe Summit\u5f00\u53d1\u7684\u9886\u57df\u7279\u5b9aAI\u52a9\u624bSummit Concierge\uff0c\u5b83\u901a\u8fc7\u4eba\u673a\u534f\u540c\u5f00\u53d1\u6d41\u7a0b\u89e3\u51b3\u4e86\u6570\u636e\u7a00\u758f\u3001\u8d28\u91cf\u4fdd\u8bc1\u548c\u5feb\u901f\u90e8\u7f72\u7b49\u73b0\u5b9e\u7ea6\u675f\uff0c\u5c55\u793a\u4e86\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u6784\u5efa\u53ef\u6269\u5c55\u53ef\u9760AI\u52a9\u624b\u7684\u7ecf\u9a8c\u3002", "motivation": "\u5229\u7528\u751f\u6210\u5f0fAI\u52a9\u624b\u63d0\u5347\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u751f\u4ea7\u529b\u3001\u7b80\u5316\u4fe1\u606f\u8bbf\u95ee\u5e76\u6539\u5584\u7528\u6237\u4f53\u9a8c\uff0c\u7279\u522b\u662f\u5728Adobe Summit\u8fd9\u6837\u7684\u4f01\u4e1a\u6d3b\u52a8\u4e2d\u3002", "method": "\u91c7\u7528\u4eba\u673a\u534f\u540c\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\uff0c\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u3001\u68c0\u7d22\u57fa\u7840\u548c\u8f7b\u91cf\u7ea7\u4eba\u5de5\u9a8c\u8bc1\uff0c\u6784\u5efa\u80fd\u591f\u5904\u7406\u5404\u79cd\u6d3b\u52a8\u76f8\u5173\u67e5\u8be2\u7684\u9886\u57df\u7279\u5b9aAI\u52a9\u624b\u3002", "result": "\u6210\u529f\u5f00\u53d1\u5e76\u90e8\u7f72\u4e86Summit Concierge\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5728\u771f\u5b9e\u7ea6\u675f\u6761\u4ef6\u4e0b\u8fd0\u884c\u826f\u597d\uff0c\u8bc1\u660e\u4e86\u654f\u6377\u3001\u53cd\u9988\u9a71\u52a8\u7684\u5f00\u53d1\u65b9\u6cd5\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u654f\u6377\u3001\u53cd\u9988\u9a71\u52a8\u7684\u5f00\u53d1\u65b9\u6cd5\u80fd\u591f\u6784\u5efa\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684AI\u52a9\u624b\uff0c\u5373\u4f7f\u5728\u6570\u636e\u7a00\u758f\u7684\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u4e5f\u80fd\u6210\u529f\u90e8\u7f72\u3002"}}
{"id": "2511.03235", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03235", "abs": "https://arxiv.org/abs/2511.03235", "authors": ["Yi-Fei Liu", "Yi-Long Lu", "Di He", "Hang Zhang"], "title": "From Five Dimensions to Many: Large Language Models as Precise and Interpretable Psychological Profilers", "comment": null, "summary": "Psychological constructs within individuals are widely believed to be\ninterconnected. We investigated whether and how Large Language Models (LLMs)\ncan model the correlational structure of human psychological traits from\nminimal quantitative inputs. We prompted various LLMs with Big Five Personality\nScale responses from 816 human individuals to role-play their responses on nine\nother psychological scales. LLMs demonstrated remarkable accuracy in capturing\nhuman psychological structure, with the inter-scale correlation patterns from\nLLM-generated responses strongly aligning with those from human data $(R^2 >\n0.89)$. This zero-shot performance substantially exceeded predictions based on\nsemantic similarity and approached the accuracy of machine learning algorithms\ntrained directly on the dataset. Analysis of reasoning traces revealed that\nLLMs use a systematic two-stage process: First, they transform raw Big Five\nresponses into natural language personality summaries through information\nselection and compression, analogous to generating sufficient statistics.\nSecond, they generate target scale responses based on reasoning from these\nsummaries. For information selection, LLMs identify the same key personality\nfactors as trained algorithms, though they fail to differentiate item\nimportance within factors. The resulting compressed summaries are not merely\nredundant representations but capture synergistic information--adding them to\noriginal scores enhances prediction alignment, suggesting they encode emergent,\nsecond-order patterns of trait interplay. Our findings demonstrate that LLMs\ncan precisely predict individual participants' psychological traits from\nminimal data through a process of abstraction and reasoning, offering both a\npowerful tool for psychological simulation and valuable insights into their\nemergent reasoning capabilities.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u80fd\u591f\u4ec5\u57fa\u4e8e\u5927\u4e94\u4eba\u683c\u91cf\u8868\u7684\u6700\u5c0f\u5b9a\u91cf\u8f93\u5165\uff0c\u51c6\u786e\u6a21\u62df\u4eba\u7c7b\u5fc3\u7406\u7279\u8d28\u7684\u76f8\u5173\u7ed3\u6784\uff0c\u5176\u751f\u6210\u7684\u8de8\u91cf\u8868\u76f8\u5173\u6a21\u5f0f\u4e0e\u4eba\u7c7b\u6570\u636e\u9ad8\u5ea6\u4e00\u81f4\uff08R\u00b2 > 0.89\uff09\uff0c\u8868\u73b0\u4f18\u4e8e\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7684\u9884\u6d4b\uff0c\u5e76\u63a5\u8fd1\u76f4\u63a5\u5728\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76LLMs\u662f\u5426\u80fd\u591f\u4ece\u6700\u5c0f\u5b9a\u91cf\u8f93\u5165\u4e2d\u5efa\u6a21\u4eba\u7c7b\u5fc3\u7406\u7279\u8d28\u7684\u5173\u8054\u7ed3\u6784\uff0c\u63a2\u7d22\u5176\u4f5c\u4e3a\u5fc3\u7406\u5b66\u6a21\u62df\u5de5\u5177\u548c\u63ed\u793a\u5176\u63a8\u7406\u80fd\u529b\u7684\u6f5c\u529b\u3002", "method": "\u4f7f\u7528816\u540d\u4eba\u7c7b\u4e2a\u4f53\u7684\u5927\u4e94\u4eba\u683c\u91cf\u8868\u56de\u7b54\u63d0\u793a\u5404\u79cdLLMs\uff0c\u8ba9\u5b83\u4eec\u626e\u6f14\u8fd9\u4e9b\u4e2a\u4f53\u5728\u5176\u4ed6\u4e5d\u4e2a\u5fc3\u7406\u91cf\u8868\u4e0a\u7684\u56de\u7b54\u3002\u5206\u6790\u63a8\u7406\u8fc7\u7a0b\u53d1\u73b0LLMs\u91c7\u7528\u4e24\u9636\u6bb5\u7cfb\u7edf\u8fc7\u7a0b\uff1a\u9996\u5148\u5c06\u539f\u59cb\u5927\u4e94\u56de\u7b54\u8f6c\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\u4eba\u683c\u6458\u8981\uff0c\u7136\u540e\u57fa\u4e8e\u8fd9\u4e9b\u6458\u8981\u63a8\u7406\u751f\u6210\u76ee\u6807\u91cf\u8868\u56de\u7b54\u3002", "result": "LLMs\u5728\u6355\u6349\u4eba\u7c7b\u5fc3\u7406\u7ed3\u6784\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u51c6\u786e\u6027\uff0c\u8de8\u91cf\u8868\u76f8\u5173\u6a21\u5f0f\u4e0e\u4eba\u7c7b\u6570\u636e\u9ad8\u5ea6\u4e00\u81f4\uff08R\u00b2 > 0.89\uff09\u3002\u96f6\u6837\u672c\u6027\u80fd\u663e\u8457\u8d85\u8fc7\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7684\u9884\u6d4b\uff0c\u63a5\u8fd1\u76f4\u63a5\u5728\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u3002\u538b\u7f29\u6458\u8981\u4e0d\u4ec5\u6355\u83b7\u5197\u4f59\u4fe1\u606f\uff0c\u8fd8\u7f16\u7801\u4e86\u7279\u8d28\u7684\u534f\u540c\u4ea4\u4e92\u6a21\u5f0f\u3002", "conclusion": "LLMs\u80fd\u591f\u901a\u8fc7\u62bd\u8c61\u548c\u63a8\u7406\u8fc7\u7a0b\u4ece\u6700\u5c0f\u6570\u636e\u7cbe\u786e\u9884\u6d4b\u4e2a\u4f53\u53c2\u4e0e\u8005\u7684\u5fc3\u7406\u7279\u8d28\uff0c\u65e2\u4e3a\u5fc3\u7406\u5b66\u6a21\u62df\u63d0\u4f9b\u4e86\u5f3a\u5927\u5de5\u5177\uff0c\u4e5f\u4e3a\u5176\u65b0\u5174\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\u3002"}}
{"id": "2511.03641", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CY", "68T01, 68727, 68T30, 68T35, 68T37, 68T50"], "pdf": "https://arxiv.org/pdf/2511.03641", "abs": "https://arxiv.org/abs/2511.03641", "authors": ["Thomas Souverain"], "title": "Watermarking Large Language Models in Europe: Interpreting the AI Act in Light of Technology", "comment": "17 pages, 2 Tables and 2 Pictures", "summary": "To foster trustworthy Artificial Intelligence (AI) within the European Union,\nthe AI Act requires providers to mark and detect the outputs of their\ngeneral-purpose models. The Article 50 and Recital 133 call for marking methods\nthat are ''sufficiently reliable, interoperable, effective and robust''. Yet,\nthe rapidly evolving and heterogeneous landscape of watermarks for Large\nLanguage Models (LLMs) makes it difficult to determine how these four standards\ncan be translated into concrete and measurable evaluations. Our paper addresses\nthis challenge, anchoring the normativity of European requirements in the\nmultiplicity of watermarking techniques. Introducing clear and distinct\nconcepts on LLM watermarking, our contribution is threefold. (1) Watermarking\nCategorisation: We propose an accessible taxonomy of watermarking methods\naccording to the stage of the LLM lifecycle at which they are applied - before,\nduring, or after training, and during next-token distribution or sampling. (2)\nWatermarking Evaluation: We interpret the EU AI Act's requirements by mapping\neach criterion with state-of-the-art evaluations on robustness and\ndetectability of the watermark, and of quality of the LLM. Since\ninteroperability remains largely untheorised in LLM watermarking research, we\npropose three normative dimensions to frame its assessment. (3) Watermarking\nComparison: We compare current watermarking methods for LLMs against the\noperationalised European criteria and show that no approach yet satisfies all\nfour standards. Encouraged by emerging empirical tests, we recommend further\nresearch into watermarking directly embedded within the low-level architecture\nof LLMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3a\u54cd\u5e94\u6b27\u76dfAI\u6cd5\u6848\u5bf9\u901a\u7528AI\u6a21\u578b\u8f93\u51fa\u6807\u8bb0\u7684\u8981\u6c42\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6c34\u5370\u6280\u672f\u7684\u6846\u67b6\uff0c\u5305\u62ec\u5206\u7c7b\u3001\u8bc4\u4f30\u548c\u6bd4\u8f83\u73b0\u6709\u65b9\u6cd5\uff0c\u53d1\u73b0\u76ee\u524d\u5c1a\u65e0\u65b9\u6cd5\u5b8c\u5168\u6ee1\u8db3\u6240\u6709\u56db\u4e2a\u6807\u51c6\u3002", "motivation": "\u6b27\u76dfAI\u6cd5\u6848\u8981\u6c42\u901a\u7528AI\u6a21\u578b\u63d0\u4f9b\u5546\u6807\u8bb0\u548c\u68c0\u6d4b\u5176\u8f93\u51fa\uff0c\u4f46\u73b0\u6709\u6c34\u5370\u6280\u672f\u8bc4\u4f30\u6807\u51c6\u4e0d\u660e\u786e\u3002\u8bba\u6587\u65e8\u5728\u5c06\u6cd5\u6848\u7684\u56db\u4e2a\u6807\u51c6\uff08\u53ef\u9760\u6027\u3001\u4e92\u64cd\u4f5c\u6027\u3001\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\uff09\u8f6c\u5316\u4e3a\u5177\u4f53\u7684\u53ef\u6d4b\u91cf\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e09\u65b9\u9762\u8d21\u732e\uff1a(1) \u6839\u636eLLM\u751f\u547d\u5468\u671f\u9636\u6bb5\u5bf9\u6c34\u5370\u65b9\u6cd5\u8fdb\u884c\u5206\u7c7b\uff1b(2) \u5c06\u6b27\u76df\u6807\u51c6\u6620\u5c04\u5230\u73b0\u6709\u7684\u6c34\u5370\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u4e3a\u4e92\u64cd\u4f5c\u6027\u63d0\u51fa\u4e09\u4e2a\u89c4\u8303\u6027\u7ef4\u5ea6\uff1b(3) \u6bd4\u8f83\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u4e0e\u6b27\u76df\u6807\u51c6\u7684\u7b26\u5408\u7a0b\u5ea6\u3002", "result": "\u6bd4\u8f83\u663e\u793a\u76ee\u524d\u5c1a\u65e0\u6c34\u5370\u65b9\u6cd5\u80fd\u540c\u65f6\u6ee1\u8db3\u6240\u6709\u56db\u4e2a\u6b27\u76df\u6807\u51c6\u3002\u7814\u7a76\u53d1\u73b0\u76f4\u63a5\u5d4c\u5165LLM\u5e95\u5c42\u67b6\u6784\u7684\u6c34\u5370\u65b9\u6cd5\u5177\u6709\u6f5c\u529b\u3002", "conclusion": "\u5efa\u8bae\u8fdb\u4e00\u6b65\u7814\u7a76\u76f4\u63a5\u5d4c\u5165LLM\u5e95\u5c42\u67b6\u6784\u7684\u6c34\u5370\u6280\u672f\uff0c\u4ee5\u66f4\u597d\u5730\u6ee1\u8db3\u6b27\u76dfAI\u6cd5\u6848\u7684\u8981\u6c42\u3002"}}
{"id": "2511.03471", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.03471", "abs": "https://arxiv.org/abs/2511.03471", "authors": ["Ming Gu", "Ziwei Wang", "Sicen Lai", "Zirui Gao", "Sheng Zhou", "Jiajun Bu"], "title": "Towards Scalable Web Accessibility Audit with MLLMs as Copilots", "comment": "15 pages. Accepted by AAAI 2026 AISI", "summary": "Ensuring web accessibility is crucial for advancing social welfare, justice,\nand equality in digital spaces, yet the vast majority of website user\ninterfaces remain non-compliant, due in part to the resource-intensive and\nunscalable nature of current auditing practices. While WCAG-EM offers a\nstructured methodology for site-wise conformance evaluation, it involves great\nhuman efforts and lacks practical support for execution at scale. In this work,\nwe present an auditing framework, AAA, which operationalizes WCAG-EM through a\nhuman-AI partnership model. AAA is anchored by two key innovations: GRASP, a\ngraph-based multimodal sampling method that ensures representative page\ncoverage via learned embeddings of visual, textual, and relational cues; and\nMaC, a multimodal large language model-based copilot that supports auditors\nthrough cross-modal reasoning and intelligent assistance in high-effort tasks.\nTogether, these components enable scalable, end-to-end web accessibility\nauditing, empowering human auditors with AI-enhanced assistance for real-world\nimpact. We further contribute four novel datasets designed for benchmarking\ncore stages of the audit pipeline. Extensive experiments demonstrate the\neffectiveness of our methods, providing insights that small-scale language\nmodels can serve as capable experts when fine-tuned.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aAAA\u7684\u7f51\u9875\u53ef\u8bbf\u95ee\u6027\u5ba1\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u6a21\u5f0f\u5b9e\u73b0WCAG-EM\u6807\u51c6\u7684\u53ef\u6269\u5c55\u6267\u884c\uff0c\u5305\u542bGRASP\u91c7\u6837\u65b9\u6cd5\u548cMaC\u667a\u80fd\u52a9\u624b\u4e24\u4e2a\u5173\u952e\u521b\u65b0\u3002", "motivation": "\u5f53\u524d\u7f51\u9875\u53ef\u8bbf\u95ee\u6027\u5ba1\u8ba1\u5b58\u5728\u8d44\u6e90\u5bc6\u96c6\u548c\u96be\u4ee5\u6269\u5c55\u7684\u95ee\u9898\uff0c\u5927\u591a\u6570\u7f51\u7ad9\u754c\u9762\u4e0d\u7b26\u5408\u53ef\u8bbf\u95ee\u6027\u6807\u51c6\uff0c\u963b\u788d\u4e86\u6570\u5b57\u7a7a\u95f4\u7684\u793e\u4f1a\u798f\u5229\u3001\u6b63\u4e49\u548c\u5e73\u7b49\u53d1\u5c55\u3002", "method": "AAA\u6846\u67b6\u901a\u8fc7GRASP\uff08\u57fa\u4e8e\u56fe\u7684\u591a\u6a21\u6001\u91c7\u6837\u65b9\u6cd5\uff09\u786e\u4fdd\u4ee3\u8868\u6027\u9875\u9762\u8986\u76d6\uff0c\u4ee5\u53caMaC\uff08\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u52a9\u624b\uff09\u63d0\u4f9b\u8de8\u6a21\u6001\u63a8\u7406\u548c\u667a\u80fd\u8f85\u52a9\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u53ef\u8bbf\u95ee\u6027\u5ba1\u8ba1\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u6709\u6548\uff0c\u63d0\u4f9b\u4e86\u5c0f\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7ecf\u8fc7\u5fae\u8c03\u540e\u80fd\u591f\u80dc\u4efb\u4e13\u4e1a\u4efb\u52a1\u7684\u89c1\u89e3\uff0c\u5e76\u8d21\u732e\u4e86\u56db\u4e2a\u7528\u4e8e\u5ba1\u8ba1\u6d41\u7a0b\u57fa\u51c6\u6d4b\u8bd5\u7684\u65b0\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u7f51\u9875\u53ef\u8bbf\u95ee\u6027\u5ba1\u8ba1\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86AI\u589e\u5f3a\u7684\u8f85\u52a9\u5de5\u5177\uff0c\u5177\u6709\u73b0\u5b9e\u5f71\u54cd\u610f\u4e49\u3002"}}
{"id": "2511.03545", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03545", "abs": "https://arxiv.org/abs/2511.03545", "authors": ["Sebastian Ordyniak", "Giacomo Paesani", "Mateusz Rychlicki", "Stefan Szeider"], "title": "Explaining Decisions in ML Models: a Parameterized Complexity Analysis (Part I)", "comment": "Part I of a greatly enhanced version of\n  https://doi.org/10.24963/kr.2024/53, whose full version is available on arXiv\n  under https://doi.org/10.48550/arXiv.2407.15780", "summary": "This paper presents a comprehensive theoretical investigation into the\nparameterized complexity of explanation problems in various machine learning\n(ML) models. Contrary to the prevalent black-box perception, our study focuses\non models with transparent internal mechanisms. We address two principal types\nof explanation problems: abductive and contrastive, both in their local and\nglobal variants. Our analysis encompasses diverse ML models, including Decision\nTrees, Decision Sets, Decision Lists, Boolean Circuits, and ensembles thereof,\neach offering unique explanatory challenges. This research fills a significant\ngap in explainable AI (XAI) by providing a foundational understanding of the\ncomplexities of generating explanations for these models. This work provides\ninsights vital for further research in the domain of XAI, contributing to the\nbroader discourse on the necessity of transparency and accountability in AI\nsystems.", "AI": {"tldr": "\u672c\u6587\u5bf9\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u89e3\u91ca\u95ee\u9898\u8fdb\u884c\u4e86\u53c2\u6570\u5316\u590d\u6742\u6027\u7406\u8bba\u5206\u6790\uff0c\u91cd\u70b9\u5173\u6ce8\u5177\u6709\u900f\u660e\u5185\u90e8\u673a\u5236\u7684\u6a21\u578b\uff0c\u5305\u62ec\u51b3\u7b56\u6811\u3001\u51b3\u7b56\u96c6\u3001\u51b3\u7b56\u5217\u8868\u3001\u5e03\u5c14\u7535\u8def\u53ca\u5176\u96c6\u6210\u6a21\u578b\u3002", "motivation": "\u586b\u8865\u53ef\u89e3\u91caAI\u9886\u57df\u5728\u7406\u89e3\u751f\u6210\u89e3\u91ca\u590d\u6742\u6027\u65b9\u9762\u7684\u7406\u8bba\u7a7a\u767d\uff0c\u4e3aAI\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u95ee\u8d23\u6027\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u3002", "method": "\u91c7\u7528\u53c2\u6570\u5316\u590d\u6742\u6027\u7406\u8bba\u6846\u67b6\uff0c\u5206\u6790\u4e24\u79cd\u4e3b\u8981\u89e3\u91ca\u95ee\u9898\uff08\u6eaf\u56e0\u89e3\u91ca\u548c\u5bf9\u6bd4\u89e3\u91ca\uff09\u5728\u5c40\u90e8\u548c\u5168\u5c40\u53d8\u4f53\u4e2d\u7684\u8ba1\u7b97\u590d\u6742\u6027\u3002", "result": "\u4e3a\u4e0d\u540cML\u6a21\u578b\u4e2d\u7684\u89e3\u91ca\u95ee\u9898\u63d0\u4f9b\u4e86\u590d\u6742\u6027\u7406\u8bba\u5206\u6790\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u95ee\u9898\u7684\u8ba1\u7b97\u7279\u5f81\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3aXAI\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u57fa\u7840\uff0c\u5f3a\u8c03\u4e86AI\u7cfb\u7edf\u900f\u660e\u5ea6\u548c\u95ee\u8d23\u6027\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2511.03724", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.03724", "abs": "https://arxiv.org/abs/2511.03724", "authors": ["Richard Dewey", "Janos Botyanszki", "Ciamac C. Moallemi", "Andrew T. Zheng"], "title": "Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via Self-Play and Reinforcement Learning", "comment": null, "summary": "AI researchers have long focused on poker-like games as a testbed for\nenvironments characterized by multi-player dynamics, imperfect information, and\nreasoning under uncertainty. While recent breakthroughs have matched elite\nhuman play at no-limit Texas hold'em, the multi-player dynamics are subdued:\nmost hands converge quickly with only two players engaged through multiple\nrounds of bidding. In this paper, we present Solly, the first AI agent to\nachieve elite human play in reduced-format Liar's Poker, a game characterized\nby extensive multi-player engagement. We trained Solly using self-play with a\nmodel-free, actor-critic, deep reinforcement learning algorithm. Solly played\nat an elite human level as measured by win rate (won over 50% of hands) and\nequity (money won) in heads-up and multi-player Liar's Poker. Solly also\noutperformed large language models (LLMs), including those with reasoning\nabilities, on the same metrics. Solly developed novel bidding strategies,\nrandomized play effectively, and was not easily exploitable by world-class\nhuman players.", "AI": {"tldr": "Solly\u662f\u9996\u4e2a\u5728\u7b80\u5316\u7248Liar's Poker\u4e2d\u8fbe\u5230\u7cbe\u82f1\u4eba\u7c7b\u6c34\u5e73\u7684AI\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u65e0\u6a21\u578b\u3001\u6f14\u5458-\u8bc4\u8bba\u5bb6\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u81ea\u535a\u5f08\u8bad\u7ec3\uff0c\u5728\u5355\u6311\u548c\u591a\u73a9\u5bb6\u6e38\u620f\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u80dc\u7387\u8d85\u8fc750%\uff0c\u5e76\u4f18\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u867d\u7136AI\u5728\u5fb7\u5dde\u6251\u514b\u7b49\u6e38\u620f\u4e2d\u5df2\u53d6\u5f97\u7a81\u7834\uff0c\u4f46\u591a\u73a9\u5bb6\u52a8\u6001\u8f83\u5f31\uff0c\u5927\u591a\u6570\u624b\u724c\u5feb\u901f\u6536\u655b\uff0c\u53ea\u6709\u4e24\u540d\u73a9\u5bb6\u53c2\u4e0e\u591a\u8f6e\u7ade\u6807\u3002\u7814\u7a76\u8005\u5e0c\u671b\u5f00\u53d1\u80fd\u5728\u591a\u73a9\u5bb6\u53c2\u4e0e\u5ea6\u9ad8\u7684\u6e38\u620f\u4e2d\u8fbe\u5230\u7cbe\u82f1\u6c34\u5e73\u7684AI\u3002", "method": "\u4f7f\u7528\u65e0\u6a21\u578b\u3001\u6f14\u5458-\u8bc4\u8bba\u5bb6\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u81ea\u535a\u5f08\u8bad\u7ec3\u3002", "result": "Solly\u5728\u5355\u6311\u548c\u591a\u73a9\u5bb6Liar's Poker\u4e2d\u8fbe\u5230\u7cbe\u82f1\u4eba\u7c7b\u6c34\u5e73\uff0c\u80dc\u7387\u8d85\u8fc750%\uff0c\u5728\u8d44\u91d1\u6536\u76ca\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5f00\u53d1\u4e86\u65b0\u9896\u7684\u7ade\u6807\u7b56\u7565\uff0c\u80fd\u6709\u6548\u968f\u673a\u5316\u6e38\u620f\uff0c\u4e0d\u6613\u88ab\u4e16\u754c\u7ea7\u4eba\u7c7b\u73a9\u5bb6\u5229\u7528\u3002", "conclusion": "Solly\u6210\u529f\u5c55\u793a\u4e86\u5728\u591a\u73a9\u5bb6\u53c2\u4e0e\u5ea6\u9ad8\u7684\u4e0d\u5b8c\u5168\u4fe1\u606f\u6e38\u620f\u4e2d\u8fbe\u5230\u7cbe\u82f1\u4eba\u7c7b\u6c34\u5e73\u7684\u53ef\u884c\u6027\uff0c\u4e3aAI\u5728\u591a\u73a9\u5bb6\u52a8\u6001\u73af\u5883\u4e2d\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u8fdb\u5c55\u3002"}}

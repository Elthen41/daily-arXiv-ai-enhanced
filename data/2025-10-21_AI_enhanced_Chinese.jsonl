{"id": "2510.15948", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.15948", "abs": "https://arxiv.org/abs/2510.15948", "authors": ["MingSheng Li", "Guangze Zhao", "Sichen Liu"], "title": "VisuoAlign: Safety Alignment of LVLMs with Multimodal Tree Search", "comment": null, "summary": "Large Vision-Language Models (LVLMs) have achieved remarkable progress in\nmultimodal perception and generation, yet their safety alignment remains a\ncritical challenge.Existing defenses and vulnerable to multimodal jailbreaks,\nas visual inputs introduce new attack surfaces, reasoning chains lack safety\nsupervision, and alignment often degrades under modality fusion.To overcome\nthese limitation, we propose VisuoAlign, a framework for multi-modal safety\nalignment via prompt-guided tree search.VisuoAlign embeds safety constrains\ninto the reasoning process through visual-textual interactive prompts, employs\nMonte Carlo Tree Search(MCTS) to systematically construct diverse\nsafety-critical prompt trajectories, and introduces prompt-based scaling to\nensure real-time risk detection and compliant responses.Extensive experiments\ndemonstrate that VisuoAlign proactively exposes risks, enables comprehensive\ndataset generation, and significantly improves the robustness of LVLMs against\ncomplex cross-modal threats.", "AI": {"tldr": "VisuoAlign\u662f\u4e00\u4e2a\u901a\u8fc7\u63d0\u793a\u5f15\u5bfc\u6811\u641c\u7d22\u5b9e\u73b0\u591a\u6a21\u6001\u5b89\u5168\u5bf9\u9f50\u7684\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5b89\u5168\u5bf9\u9f50\u65b9\u9762\u7684\u6311\u6218\u3002", "motivation": "\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u611f\u77e5\u548c\u751f\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5176\u5b89\u5168\u5bf9\u9f50\u4ecd\u7136\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u9632\u5fa1\u5bb9\u6613\u53d7\u5230\u591a\u6a21\u6001\u8d8a\u72f1\u653b\u51fb\uff0c\u56e0\u4e3a\u89c6\u89c9\u8f93\u5165\u5f15\u5165\u4e86\u65b0\u7684\u653b\u51fb\u9762\uff0c\u63a8\u7406\u94fe\u7f3a\u4e4f\u5b89\u5168\u76d1\u7763\uff0c\u5bf9\u9f50\u5728\u6a21\u6001\u878d\u5408\u4e0b\u5e38\u5e38\u9000\u5316\u3002", "method": "VisuoAlign\u901a\u8fc7\u89c6\u89c9-\u6587\u672c\u4ea4\u4e92\u63d0\u793a\u5c06\u5b89\u5168\u7ea6\u675f\u5d4c\u5165\u63a8\u7406\u8fc7\u7a0b\uff0c\u91c7\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7cfb\u7edf\u6784\u5efa\u591a\u6837\u5316\u7684\u5b89\u5168\u5173\u952e\u63d0\u793a\u8f68\u8ff9\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u63d0\u793a\u7684\u7f29\u653e\u4ee5\u786e\u4fdd\u5b9e\u65f6\u98ce\u9669\u68c0\u6d4b\u548c\u5408\u89c4\u54cd\u5e94\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVisuoAlign\u80fd\u591f\u4e3b\u52a8\u66b4\u9732\u98ce\u9669\uff0c\u5b9e\u73b0\u5168\u9762\u7684\u6570\u636e\u96c6\u751f\u6210\uff0c\u5e76\u663e\u8457\u63d0\u9ad8LVLMs\u5bf9\u590d\u6742\u8de8\u6a21\u6001\u5a01\u80c1\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "VisuoAlign\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5b89\u5168\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u63d0\u5347\u4e86\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.15952", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15952", "abs": "https://arxiv.org/abs/2510.15952", "authors": ["Myung Ho Kim"], "title": "Executable Epistemology: The Structured Cognitive Loop as an Architecture of Intentional Understanding", "comment": "27 pages", "summary": "Large language models exhibit intelligence without genuine epistemic\nunderstanding, exposing a key gap: the absence of epistemic architecture. This\npaper introduces the Structured Cognitive Loop (SCL) as an executable\nepistemological framework for emergent intelligence. Unlike traditional AI\nresearch asking \"what is intelligence?\" (ontological), SCL asks \"under what\nconditions does cognition emerge?\" (epistemological). Grounded in philosophy of\nmind and cognitive phenomenology, SCL bridges conceptual philosophy and\nimplementable cognition. Drawing on process philosophy, enactive cognition, and\nextended mind theory, we define intelligence not as a property but as a\nperformed process -- a continuous loop of judgment, memory, control, action,\nand regulation. SCL makes three contributions. First, it operationalizes\nphilosophical insights into computationally interpretable structures, enabling\n\"executable epistemology\" -- philosophy as structural experiment. Second, it\nshows that functional separation within cognitive architecture yields more\ncoherent and interpretable behavior than monolithic prompt based systems,\nsupported by agent evaluations. Third, it redefines intelligence: not\nrepresentational accuracy but the capacity to reconstruct its own epistemic\nstate through intentional understanding. This framework impacts philosophy of\nmind, epistemology, and AI. For philosophy, it allows theories of cognition to\nbe enacted and tested. For AI, it grounds behavior in epistemic structure\nrather than statistical regularity. For epistemology, it frames knowledge not\nas truth possession but as continuous reconstruction within a\nphenomenologically coherent loop. We situate SCL within debates on cognitive\nphenomenology, emergence, normativity, and intentionality, arguing that real\nprogress requires not larger models but architectures that realize cognitive\nprinciples structurally.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7ed3\u6784\u5316\u8ba4\u77e5\u5faa\u73af\uff08SCL\uff09\u4f5c\u4e3a\u53ef\u6267\u884c\u7684\u8ba4\u77e5\u6846\u67b6\uff0c\u5c06\u54f2\u5b66\u6d1e\u89c1\u8f6c\u5316\u4e3a\u53ef\u8ba1\u7b97\u7ed3\u6784\uff0c\u5f3a\u8c03\u667a\u80fd\u4e0d\u662f\u5c5e\u6027\u800c\u662f\u6267\u884c\u8fc7\u7a0b\uff0c\u901a\u8fc7\u529f\u80fd\u5206\u79bb\u7684\u8ba4\u77e5\u67b6\u6784\u4ea7\u751f\u66f4\u8fde\u8d2f\u548c\u53ef\u89e3\u91ca\u7684\u884c\u4e3a\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u771f\u6b63\u7684\u8ba4\u77e5\u7406\u89e3\uff0c\u66b4\u9732\u51fa\u8ba4\u77e5\u67b6\u6784\u7684\u7f3a\u5931\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4ece\u8ba4\u8bc6\u8bba\u89d2\u5ea6\u63a2\u8ba8\u8ba4\u77e5\u51fa\u73b0\u7684\u6761\u4ef6\uff0c\u800c\u975e\u4f20\u7edf\u7684\u672c\u4f53\u8bba\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u5fc3\u7075\u54f2\u5b66\u548c\u8ba4\u77e5\u73b0\u8c61\u5b66\uff0c\u7ed3\u5408\u8fc7\u7a0b\u54f2\u5b66\u3001\u751f\u6210\u8ba4\u77e5\u548c\u6269\u5c55\u5fc3\u667a\u7406\u8bba\uff0c\u5b9a\u4e49\u667a\u80fd\u4e3a\u5305\u542b\u5224\u65ad\u3001\u8bb0\u5fc6\u3001\u63a7\u5236\u3001\u884c\u52a8\u548c\u8c03\u8282\u7684\u8fde\u7eed\u5faa\u73af\u8fc7\u7a0b\u3002", "result": "SCL\u5c06\u54f2\u5b66\u6d1e\u89c1\u64cd\u4f5c\u5316\u4e3a\u53ef\u8ba1\u7b97\u7ed3\u6784\uff0c\u652f\u6301\"\u53ef\u6267\u884c\u8ba4\u8bc6\u8bba\"\uff1b\u529f\u80fd\u5206\u79bb\u7684\u8ba4\u77e5\u67b6\u6784\u6bd4\u5355\u4e00\u63d0\u793a\u7cfb\u7edf\u4ea7\u751f\u66f4\u8fde\u8d2f\u548c\u53ef\u89e3\u91ca\u7684\u884c\u4e3a\uff1b\u91cd\u65b0\u5b9a\u4e49\u667a\u80fd\u4e3a\u901a\u8fc7\u610f\u5411\u6027\u7406\u89e3\u91cd\u5efa\u81ea\u8eab\u8ba4\u77e5\u72b6\u6001\u7684\u80fd\u529b\u3002", "conclusion": "SCL\u6846\u67b6\u5bf9\u5fc3\u7075\u54f2\u5b66\u3001\u8ba4\u8bc6\u8bba\u548cAI\u4ea7\u751f\u91cd\u8981\u5f71\u54cd\uff1a\u5141\u8bb8\u8ba4\u77e5\u7406\u8bba\u88ab\u5b9e\u65bd\u548c\u6d4b\u8bd5\uff1b\u5c06\u884c\u4e3a\u5efa\u7acb\u5728\u8ba4\u77e5\u7ed3\u6784\u800c\u975e\u7edf\u8ba1\u89c4\u5f8b\u4e0a\uff1b\u5c06\u77e5\u8bc6\u89c6\u4e3a\u5728\u73b0\u8c61\u5b66\u8fde\u8d2f\u5faa\u73af\u4e2d\u7684\u6301\u7eed\u91cd\u5efa\u8fc7\u7a0b\u3002"}}
{"id": "2510.15953", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.15953", "abs": "https://arxiv.org/abs/2510.15953", "authors": ["Sisir Doppalapudi"], "title": "Hierarchical Multi-Modal Threat Intelligence Fusion Without Aligned Data: A Practical Framework for Real-World Security Operations", "comment": null, "summary": "Multi-modal threat detection faces a fundamental challenge that involves\nsecurity tools operating in isolation, and this creates streams of network,\nemail, and system data with no natural alignment or correlation. We present\nHierarchical Multi-Modal Threat Intelligence Fusion (HM-TIF), a framework\nexplicitly designed for this realistic scenario where naturally aligned\nmulti-modal attack data does not exist. Unlike prior work that assumes or\ncreates artificial alignment, we develop principled methods for correlating\nindependent security data streams while maintaining operational validity. Our\narchitecture employs hierarchical cross-attention with dynamic weighting that\nadapts to data availability and threat context, coupled with a novel temporal\ncorrelation protocol that preserves statistical independence. Evaluation on\nUNSW-NB15, CSE-CIC-IDS2018, and CICBell-DNS2021 datasets demonstrates that\nHM-TIF achieves 88.7% accuracy with a critical 32% reduction in false positive\nrates, even without true multi-modal training data. The framework maintains\nrobustness when modalities are missing, making it immediately deployable in\nreal security operations where data streams frequently have gaps. Our\ncontributions include: (i) the first multi-modal security framework explicitly\ndesigned for non-aligned data, (ii) a temporal correlation protocol that avoids\ncommon data leakage pitfalls, (iii) empirical validation that multi-modal\nfusion provides operational benefits even without perfect alignment, and (iv)\npractical deployment guidelines for security teams facing heterogeneous,\nuncoordinated data sources. Index Terms: multi-modal learning, threat\nintelligence, non-aligned data, operational security, cross-attention\nmechanisms, practical deployment", "AI": {"tldr": "HM-TIF\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3a\u975e\u5bf9\u9f50\u591a\u6a21\u6001\u5b89\u5168\u6570\u636e\u8bbe\u8ba1\u7684\u5a01\u80c1\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u8de8\u6ce8\u610f\u529b\u548c\u65f6\u95f4\u76f8\u5173\u6027\u534f\u8bae\uff0c\u5728\u4e0d\u4f9d\u8d56\u5bf9\u9f50\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b088.7%\u7684\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u5e76\u5c06\u8bef\u62a5\u7387\u964d\u4f4e32%\u3002", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u5a01\u80c1\u68c0\u6d4b\u4e2d\u5b89\u5168\u5de5\u5177\u5b64\u7acb\u8fd0\u884c\u3001\u6570\u636e\u6d41\u81ea\u7136\u4e0d\u5bf9\u9f50\u7684\u73b0\u5b9e\u6311\u6218\uff0c\u907f\u514d\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u5bf9\u9f50\u6570\u636e\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u5c42\u6b21\u5316\u8de8\u6ce8\u610f\u529b\u673a\u5236\u548c\u52a8\u6001\u6743\u91cd\u8c03\u6574\uff0c\u7ed3\u5408\u65b0\u9896\u7684\u65f6\u95f4\u76f8\u5173\u6027\u534f\u8bae\u6765\u4fdd\u6301\u7edf\u8ba1\u72ec\u7acb\u6027\uff0c\u5904\u7406\u72ec\u7acb\u5b89\u5168\u6570\u636e\u6d41\u7684\u76f8\u5173\u6027\u3002", "result": "\u5728UNSW-NB15\u3001CSE-CIC-IDS2018\u548cCICBell-DNS2021\u6570\u636e\u96c6\u4e0a\u8fbe\u523088.7%\u7684\u51c6\u786e\u7387\uff0c\u8bef\u62a5\u7387\u964d\u4f4e32%\uff0c\u4e14\u5728\u6a21\u6001\u7f3a\u5931\u65f6\u4ecd\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "HM-TIF\u8bc1\u660e\u4e86\u591a\u6a21\u6001\u878d\u5408\u5728\u6570\u636e\u4e0d\u5bf9\u9f50\u60c5\u51b5\u4e0b\u4ecd\u80fd\u63d0\u4f9b\u64cd\u4f5c\u4f18\u52bf\uff0c\u4e3a\u5b89\u5168\u56e2\u961f\u5904\u7406\u5f02\u6784\u3001\u975e\u534f\u8c03\u6570\u636e\u6e90\u63d0\u4f9b\u4e86\u5b9e\u7528\u90e8\u7f72\u6307\u5357\u3002"}}
{"id": "2510.15974", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15974", "abs": "https://arxiv.org/abs/2510.15974", "authors": ["Chris Su", "Harrison Li", "Matheus Marques", "George Flint", "Kevin Zhu", "Sunishchal Dev"], "title": "Limits of Emergent Reasoning of Large Language Models in Agentic Frameworks for Deterministic Games", "comment": null, "summary": "Recent work reports that Large Reasoning Models (LRMs) undergo a collapse in\nperformance on solving puzzles beyond certain perplexity thresholds. In\nsubsequent discourse, questions have arisen as to whether the nature of the\ntask muddles an evaluation of true reasoning. One potential confound is the\nrequirement that the model keep track of the state space on its own. We provide\na large language model (LLM) with an environment interface for Tower of Hanoi\nproblems, allowing it to make a move with a tool call, provide written\njustification, observe the resulting state space, and reprompt itself for the\nnext move. We observe that access to an environment interface does not delay or\neradicate performance collapse. Furthermore, LLM-parameterized policy analysis\nreveals increasing divergence from both optimal policies and uniformly random\npolicies, suggesting that the model exhibits mode-like collapse at each level\nof complexity, and that performance is dependent upon whether the mode reflects\nthe correct solution for the problem. We suggest that a similar phenomena might\ntake place in LRMs.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u89e3\u51b3\u8d85\u8fc7\u7279\u5b9a\u56f0\u60d1\u5ea6\u9608\u503c\u7684\u8c1c\u9898\u65f6\u4f1a\u51fa\u73b0\u6027\u80fd\u5d29\u6e83\uff0c\u5373\u4f7f\u63d0\u4f9b\u73af\u5883\u63a5\u53e3\u8ba9\u6a21\u578b\u80fd\u591f\u8ddf\u8e2a\u72b6\u6001\u7a7a\u95f4\uff0c\u4e5f\u65e0\u6cd5\u5ef6\u8fdf\u6216\u6d88\u9664\u8fd9\u79cd\u5d29\u6e83\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u89e3\u51b3\u590d\u6742\u8c1c\u9898\u65f6\u6027\u80fd\u5d29\u6e83\u7684\u539f\u56e0\uff0c\u7279\u522b\u662f\u9a8c\u8bc1\u662f\u5426\u7531\u4e8e\u6a21\u578b\u9700\u8981\u81ea\u884c\u8ddf\u8e2a\u72b6\u6001\u7a7a\u95f4\u800c\u5bfc\u81f4\u8bc4\u4f30\u6df7\u6dc6\u3002", "method": "\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u6c49\u8bfa\u5854\u95ee\u9898\u7684\u73af\u5883\u63a5\u53e3\uff0c\u5141\u8bb8\u5176\u901a\u8fc7\u5de5\u5177\u8c03\u7528\u8fdb\u884c\u79fb\u52a8\u3001\u63d0\u4f9b\u4e66\u9762\u7406\u7531\u3001\u89c2\u5bdf\u7ed3\u679c\u72b6\u6001\u7a7a\u95f4\u5e76\u91cd\u65b0\u63d0\u793a\u4e0b\u4e00\u6b65\u79fb\u52a8\u3002", "result": "\u73af\u5883\u63a5\u53e3\u8bbf\u95ee\u65e0\u6cd5\u5ef6\u8fdf\u6216\u6d88\u9664\u6027\u80fd\u5d29\u6e83\uff0c\u6a21\u578b\u53c2\u6570\u5316\u7b56\u7565\u5206\u6790\u663e\u793a\u4e0e\u6700\u4f18\u7b56\u7565\u548c\u5747\u5300\u968f\u673a\u7b56\u7565\u7684\u504f\u79bb\u5ea6\u589e\u52a0\uff0c\u8868\u660e\u6a21\u578b\u5728\u6bcf\u4e2a\u590d\u6742\u5ea6\u7ea7\u522b\u90fd\u8868\u73b0\u51fa\u6a21\u5f0f\u5d29\u6e83\u3002", "conclusion": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u786e\u5b9e\u5b58\u5728\u6027\u80fd\u5d29\u6e83\u73b0\u8c61\uff0c\u4e14\u8fd9\u79cd\u5d29\u6e83\u4e0e\u662f\u5426\u63d0\u4f9b\u72b6\u6001\u8ddf\u8e2a\u80fd\u529b\u65e0\u5173\uff0c\u6a21\u578b\u6027\u80fd\u53d6\u51b3\u4e8e\u5176\u6a21\u5f0f\u662f\u5426\u53cd\u6620\u95ee\u9898\u7684\u6b63\u786e\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.15973", "categories": ["cs.CR", "cs.AI", "cs.CY", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.15973", "abs": "https://arxiv.org/abs/2510.15973", "authors": ["Tiarnaigh Downey-Webb", "Olamide Jogunola", "Oluwaseun Ajao"], "title": "Safeguarding Efficacy in Large Language Models: Evaluating Resistance to Human-Written and Algorithmic Adversarial Prompts", "comment": "10 pages, 4 pages manuscript submitted to the Language Resources and\n  Evaluation Conference (LREC 2026)", "summary": "This paper presents a systematic security assessment of four prominent Large\nLanguage Models (LLMs) against diverse adversarial attack vectors. We evaluate\nPhi-2, Llama-2-7B-Chat, GPT-3.5-Turbo, and GPT-4 across four distinct attack\ncategories: human-written prompts, AutoDAN, Greedy Coordinate Gradient (GCG),\nand Tree-of-Attacks-with-pruning (TAP). Our comprehensive evaluation employs\n1,200 carefully stratified prompts from the SALAD-Bench dataset, spanning six\nharm categories. Results demonstrate significant variations in model\nrobustness, with Llama-2 achieving the highest overall security (3.4% average\nattack success rate) while Phi-2 exhibits the greatest vulnerability (7.0%\naverage attack success rate). We identify critical transferability patterns\nwhere GCG and TAP attacks, though ineffective against their target model\n(Llama-2), achieve substantially higher success rates when transferred to other\nmodels (up to 17% for GPT-4). Statistical analysis using Friedman tests reveals\nsignificant differences in vulnerability across harm categories ($p < 0.001$),\nwith malicious use prompts showing the highest attack success rates (10.71%\naverage). Our findings contribute to understanding cross-model security\nvulnerabilities and provide actionable insights for developing targeted defense\nmechanisms", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u56db\u4e2a\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\uff08Phi-2\u3001Llama-2-7B-Chat\u3001GPT-3.5-Turbo\u3001GPT-4\uff09\u5bf9\u56db\u79cd\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0Llama-2\u5b89\u5168\u6027\u6700\u9ad8\uff0cPhi-2\u6700\u8106\u5f31\uff0c\u5e76\u63ed\u793a\u4e86\u653b\u51fb\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u7684\u53ef\u8fc1\u79fb\u6027\u6a21\u5f0f\u3002", "motivation": "\u8bc4\u4f30\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6837\u5316\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u5b89\u5168\u6027\uff0c\u8bc6\u522b\u6a21\u578b\u95f4\u7684\u5b89\u5168\u5dee\u5f02\u548c\u653b\u51fb\u53ef\u8fc1\u79fb\u6027\u6a21\u5f0f\uff0c\u4e3a\u9488\u5bf9\u6027\u9632\u5fa1\u673a\u5236\u5f00\u53d1\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u4f7f\u7528SALAD-Bench\u6570\u636e\u96c6\u76841,200\u4e2a\u5206\u5c42\u63d0\u793a\uff0c\u9488\u5bf9\u56db\u79cd\u653b\u51fb\u5411\u91cf\uff08\u4eba\u5de5\u7f16\u5199\u63d0\u793a\u3001AutoDAN\u3001GCG\u3001TAP\uff09\u548c\u516d\u79cd\u5371\u5bb3\u7c7b\u522b\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u91c7\u7528Friedman\u68c0\u9a8c\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "Llama-2\u603b\u4f53\u5b89\u5168\u6027\u6700\u9ad8\uff08\u5e73\u5747\u653b\u51fb\u6210\u529f\u73873.4%\uff09\uff0cPhi-2\u6700\u8106\u5f31\uff087.0%\uff09\uff1bGCG\u548cTAP\u653b\u51fb\u5728\u76ee\u6807\u6a21\u578b\u4e0a\u6548\u679c\u4e0d\u4f73\uff0c\u4f46\u8fc1\u79fb\u5230\u5176\u4ed6\u6a21\u578b\u65f6\u6210\u529f\u7387\u663e\u8457\u63d0\u9ad8\uff08GPT-4\u6700\u9ad8\u8fbe17%\uff09\uff1b\u6076\u610f\u4f7f\u7528\u63d0\u793a\u7684\u653b\u51fb\u6210\u529f\u7387\u6700\u9ad8\uff0810.71%\uff09\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u5b58\u5728\u663e\u8457\u5b89\u5168\u5dee\u5f02\uff0c\u653b\u51fb\u5177\u6709\u660e\u663e\u7684\u53ef\u8fc1\u79fb\u6027\uff0c\u6076\u610f\u4f7f\u7528\u7c7b\u522b\u6700\u6613\u53d7\u653b\u51fb\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u7406\u89e3\u8de8\u6a21\u578b\u5b89\u5168\u6f0f\u6d1e\u548c\u5f00\u53d1\u9488\u5bf9\u6027\u9632\u5fa1\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2510.15872", "categories": ["cs.AR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15872", "abs": "https://arxiv.org/abs/2510.15872", "authors": ["Yun-Da Tsai", "Chang-Yu Chao", "Liang-Yeh Shen", "Tsung-Han Lin", "Haoyu Yang", "Mark Ho", "Yi-Chen Lu", "Wen-Hao Liu", "Shou-De Lin", "Haoxing Ren"], "title": "Multimodal Chip Physical Design Engineer Assistant", "comment": null, "summary": "Modern chip physical design relies heavily on Electronic Design Automation\n(EDA) tools, which often struggle to provide interpretable feedback or\nactionable guidance for improving routing congestion. In this work, we\nintroduce a Multimodal Large Language Model Assistant (MLLMA) that bridges this\ngap by not only predicting congestion but also delivering human-interpretable\ndesign suggestions. Our method combines automated feature generation through\nMLLM-guided genetic prompting with an interpretable preference learning\nframework that models congestion-relevant tradeoffs across visual, tabular, and\ntextual inputs. We compile these insights into a \"Design Suggestion Deck\" that\nsurfaces the most influential layout features and proposes targeted\noptimizations. Experiments on the CircuitNet benchmark demonstrate that our\napproach outperforms existing models on both accuracy and explainability.\nAdditionally, our design suggestion guidance case study and qualitative\nanalyses confirm that the learned preferences align with real-world design\nprinciples and are actionable for engineers. This work highlights the potential\nof MLLMs as interactive assistants for interpretable and context-aware physical\ndesign optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u52a9\u624b(MLLMA)\uff0c\u4e0d\u4ec5\u80fd\u9884\u6d4b\u5e03\u7ebf\u62e5\u585e\uff0c\u8fd8\u80fd\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8bbe\u8ba1\u5efa\u8bae\uff0c\u901a\u8fc7\u7ed3\u5408\u89c6\u89c9\u3001\u8868\u683c\u548c\u6587\u672c\u8f93\u5165\u6765\u6539\u5584\u82af\u7247\u7269\u7406\u8bbe\u8ba1\u3002", "motivation": "\u73b0\u4ee3\u82af\u7247\u7269\u7406\u8bbe\u8ba1\u4e25\u91cd\u4f9d\u8d56EDA\u5de5\u5177\uff0c\u4f46\u8fd9\u4e9b\u5de5\u5177\u96be\u4ee5\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u53cd\u9988\u6216\u53ef\u64cd\u4f5c\u7684\u8bbe\u8ba1\u6539\u8fdb\u6307\u5bfc\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u63d0\u4f9b\u4eba\u7c7b\u53ef\u7406\u89e3\u5efa\u8bae\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408MLLM\u5f15\u5bfc\u7684\u9057\u4f20\u63d0\u793a\u8fdb\u884c\u81ea\u52a8\u7279\u5f81\u751f\u6210\uff0c\u4ee5\u53ca\u53ef\u89e3\u91ca\u7684\u504f\u597d\u5b66\u4e60\u6846\u67b6\uff0c\u5efa\u6a21\u5e03\u7ebf\u62e5\u585e\u76f8\u5173\u7684\u6743\u8861\uff0c\u6574\u5408\u89c6\u89c9\u3001\u8868\u683c\u548c\u6587\u672c\u8f93\u5165\u3002", "result": "\u5728CircuitNet\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u8bbe\u8ba1\u5efa\u8bae\u4e0e\u771f\u5b9e\u8bbe\u8ba1\u539f\u5219\u4e00\u81f4\u4e14\u5bf9\u5de5\u7a0b\u5e08\u5177\u6709\u53ef\u64cd\u4f5c\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86MLLM\u4f5c\u4e3a\u4ea4\u4e92\u5f0f\u52a9\u624b\u5728\u53ef\u89e3\u91ca\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u7269\u7406\u8bbe\u8ba1\u4f18\u5316\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.16284", "categories": ["cs.DC", "cs.MS", "cs.NA", "math.NA", "stat.CO", "65Y05, 65C60, 62F40", "F.2.2; G.3; D.1.3"], "pdf": "https://arxiv.org/pdf/2510.16284", "abs": "https://arxiv.org/abs/2510.16284", "authors": ["Di Zhang"], "title": "Communication-Efficient and Memory-Aware Parallel Bootstrapping using MPI", "comment": "6 pages", "summary": "Bootstrapping is a powerful statistical resampling technique for estimating\nthe sampling distribution of an estimator. However, its computational cost\nbecomes prohibitive for large datasets or a high number of resamples. This\npaper presents a theoretical analysis and design of parallel bootstrapping\nalgorithms using the Message Passing Interface (MPI). We address two key\nchallenges: high communication overhead and memory constraints in distributed\nenvironments. We propose two novel strategies: 1) Local Statistic Aggregation,\nwhich drastically reduces communication by transmitting sufficient statistics\ninstead of full resampled datasets, and 2) Synchronized Pseudo-Random Number\nGeneration, which enables distributed resampling when the entire dataset cannot\nbe stored on a single process. We develop analytical models for communication\nand computation complexity, comparing our methods against naive baseline\napproaches. Our analysis demonstrates that the proposed methods offer\nsignificant reductions in communication volume and memory usage, facilitating\nscalable parallel bootstrapping on large-scale systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8eMPI\u7684\u5e76\u884c\u81ea\u52a9\u6cd5\u7b97\u6cd5\uff0c\u901a\u8fc7\u5c40\u90e8\u7edf\u8ba1\u91cf\u805a\u5408\u548c\u540c\u6b65\u4f2a\u968f\u673a\u6570\u751f\u6210\u6765\u89e3\u51b3\u5927\u89c4\u6a21\u6570\u636e\u96c6\u81ea\u52a9\u6cd5\u8ba1\u7b97\u4e2d\u7684\u901a\u4fe1\u5f00\u9500\u548c\u5185\u5b58\u9650\u5236\u95ee\u9898\u3002", "motivation": "\u81ea\u52a9\u6cd5\u4f5c\u4e3a\u5f3a\u5927\u7684\u7edf\u8ba1\u91cd\u91c7\u6837\u6280\u672f\uff0c\u5728\u5927\u6570\u636e\u96c6\u6216\u5927\u91cf\u91cd\u91c7\u6837\u65f6\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u9700\u8981\u8bbe\u8ba1\u9ad8\u6548\u7684\u5e76\u884c\u7b97\u6cd5\u6765\u89e3\u51b3\u901a\u4fe1\u5f00\u9500\u548c\u5185\u5b58\u9650\u5236\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u7b56\u7565\uff1a1) \u5c40\u90e8\u7edf\u8ba1\u91cf\u805a\u5408\uff0c\u901a\u8fc7\u4f20\u8f93\u5145\u5206\u7edf\u8ba1\u91cf\u800c\u975e\u5b8c\u6574\u91cd\u91c7\u6837\u6570\u636e\u96c6\u6765\u5927\u5e45\u51cf\u5c11\u901a\u4fe1\uff1b2) \u540c\u6b65\u4f2a\u968f\u673a\u6570\u751f\u6210\uff0c\u5728\u5355\u4e2a\u8fdb\u7a0b\u65e0\u6cd5\u5b58\u50a8\u6574\u4e2a\u6570\u636e\u96c6\u65f6\u5b9e\u73b0\u5206\u5e03\u5f0f\u91cd\u91c7\u6837\u3002", "result": "\u5f00\u53d1\u4e86\u901a\u4fe1\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u5206\u6790\u6a21\u578b\uff0c\u4e0e\u6734\u7d20\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u901a\u4fe1\u91cf\u548c\u5185\u5b58\u4f7f\u7528\u65b9\u9762\u663e\u8457\u51cf\u5c11\uff0c\u652f\u6301\u5927\u89c4\u6a21\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u5e76\u884c\u81ea\u52a9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u548c\u5185\u5b58\u9700\u6c42\uff0c\u5b9e\u73b0\u4e86\u5728\u5927\u89c4\u6a21\u7cfb\u7edf\u4e0a\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u5e76\u884c\u81ea\u52a9\u6cd5\u8ba1\u7b97\u3002"}}
{"id": "2510.15981", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.15981", "abs": "https://arxiv.org/abs/2510.15981", "authors": ["Rafael Cabral", "Tuan Manh Do", "Xuejun Yu", "Wai Ming Tai", "Zijin Feng", "Xin Shen"], "title": "ProofFlow: A Dependency Graph Approach to Faithful Proof Autoformalization", "comment": null, "summary": "Proof autoformalization, the task of translating natural language theorems\nand proofs into machine-verifiable code, is a critical step for integrating\nlarge language models into rigorous mathematical workflows. Current approaches\nfocus on producing executable code, but they frequently fail to preserve the\nsemantic meaning and logical structure of the original human-written argument.\nTo address this, we introduce ProofFlow, a novel pipeline that treats\nstructural fidelity as a primary objective. ProofFlow first constructs a\ndirected acyclic graph (DAG) to map the logical dependencies between proof\nsteps. Then, it employs a novel lemma-based approach to systematically\nformalize each step as an intermediate lemma, preserving the logical structure\nof the original argument. To facilitate evaluation, we present a new benchmark\nof 184 undergraduate-level problems, manually annotated with step-by-step\nsolutions and logical dependency graphs, and introduce ProofScore, a new\ncomposite metric to evaluate syntactic correctness, semantic faithfulness, and\nstructural fidelity. Experimental results show our pipeline sets a new\nstate-of-the-art for autoformalization, achieving a ProofScore of 0.545,\nsubstantially exceeding baselines like full-proof formalization (0.123), which\nprocesses the entire proof at once, and step-proof formalization (0.072), which\nhandles each step independently. Our pipeline, benchmark, and score metric are\nopen-sourced to encourage further progress at\nhttps://github.com/Huawei-AI4Math/ProofFlow.", "AI": {"tldr": "ProofFlow\u662f\u4e00\u4e2a\u65b0\u7684\u8bc1\u660e\u81ea\u52a8\u5f62\u5f0f\u5316\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u6784\u5efa\u903b\u8f91\u4f9d\u8d56\u56fe\u548c\u4f7f\u7528\u57fa\u4e8e\u5f15\u7406\u7684\u65b9\u6cd5\u6765\u4fdd\u6301\u539f\u59cb\u8bc1\u660e\u7684\u7ed3\u6784\u4fdd\u771f\u5ea6\uff0c\u5728184\u4e2a\u672c\u79d1\u6c34\u5e73\u95ee\u9898\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e860.545\u7684ProofScore\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684\u8bc1\u660e\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u6cd5\u867d\u7136\u80fd\u751f\u6210\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u4f46\u7ecf\u5e38\u65e0\u6cd5\u4fdd\u6301\u539f\u59cb\u4eba\u5de5\u7f16\u5199\u8bba\u8bc1\u7684\u8bed\u4e49\u542b\u4e49\u548c\u903b\u8f91\u7ed3\u6784\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u66f4\u597d\u4fdd\u6301\u7ed3\u6784\u4fdd\u771f\u5ea6\u7684\u65b0\u65b9\u6cd5\u3002", "method": "ProofFlow\u9996\u5148\u6784\u5efa\u6709\u5411\u65e0\u73af\u56fe\u6765\u6620\u5c04\u8bc1\u660e\u6b65\u9aa4\u95f4\u7684\u903b\u8f91\u4f9d\u8d56\u5173\u7cfb\uff0c\u7136\u540e\u91c7\u7528\u57fa\u4e8e\u5f15\u7406\u7684\u65b9\u6cd5\u5c06\u6bcf\u4e2a\u6b65\u9aa4\u7cfb\u7edf\u5730\u5f62\u5f0f\u5316\u4e3a\u4e2d\u95f4\u5f15\u7406\uff0c\u4ece\u800c\u4fdd\u6301\u539f\u59cb\u8bba\u8bc1\u7684\u903b\u8f91\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aProofFlow\u5728\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u9762\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\uff0cProofScore\u4e3a0.545\uff0c\u663e\u8457\u4f18\u4e8e\u5168\u8bc1\u660e\u5f62\u5f0f\u5316\uff080.123\uff09\u548c\u6b65\u9aa4\u8bc1\u660e\u5f62\u5f0f\u5316\uff080.072\uff09\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ProofFlow\u901a\u8fc7\u5173\u6ce8\u7ed3\u6784\u4fdd\u771f\u5ea6\uff0c\u5728\u8bc1\u660e\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u5176\u6d41\u6c34\u7ebf\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bc4\u5206\u6307\u6807\u5df2\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.15878", "categories": ["cs.AR", "cs.OS", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.15878", "abs": "https://arxiv.org/abs/2510.15878", "authors": ["David A. Roberts"], "title": "Putting the Context back into Memory", "comment": null, "summary": "Requests arriving at main memory are often different from what programmers\ncan observe or estimate by using CPU-based monitoring. Hardware cache\nprefetching, memory request scheduling and interleaving cause a loss of\nobservability that limits potential data movement and tiering optimizations. In\nresponse, memory-side telemetry hardware like page access heat map units (HMU)\nand page prefetchers were proposed to inform Operating Systems with accurate\nusage data. However, it is still hard to map memory activity to software\nprogram functions and objects because of the decoupled nature of host\nprocessors and memory devices. Valuable program context is stripped out from\nthe memory bus, leaving only commands, addresses and data. Programmers have\nexpert knowledge of future data accesses, priorities, and access to processor\nstate, which could be useful hints for runtime memory device optimization. This\npaper makes context visible at memory devices by encoding any user-visible\nstate as detectable packets in the memory read address stream, in a\nnondestructive manner without significant capacity overhead, drivers or special\naccess privileges. We prototyped an end-to-end system with metadata injection\nthat can be reliably detected and decoded from a memory address trace, either\nby a host processor, or a memory module. We illustrate a use case with precise\ncode execution markers and object address range tracking. In the future, real\ntime metadata decoding with near-memory computing (NMC) could provide\ncustomized telemetry and statistics to users, or act on application hints to\nperform functions like prioritizing requests, remapping data and reconfiguring\ndevices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5185\u5b58\u5730\u5740\u6d41\u7f16\u7801\u7a0b\u5e8f\u4e0a\u4e0b\u6587\u7684\u65b9\u6cd5\uff0c\u4f7f\u5185\u5b58\u8bbe\u5907\u80fd\u591f\u611f\u77e5\u8f6f\u4ef6\u72b6\u6001\uff0c\u4ece\u800c\u4f18\u5316\u5185\u5b58\u8bbf\u95ee\u548c\u5206\u5c42\u7ba1\u7406\u3002", "motivation": "\u4f20\u7edf\u5185\u5b58\u76d1\u63a7\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u5b9e\u9645\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\uff0c\u786c\u4ef6\u9884\u53d6\u548c\u8c03\u5ea6\u5bfc\u81f4\u53ef\u89c2\u6d4b\u6027\u964d\u4f4e\uff0c\u9650\u5236\u4e86\u6570\u636e\u79fb\u52a8\u548c\u5206\u5c42\u4f18\u5316\u3002\u7a0b\u5e8f\u4e0a\u4e0b\u6587\u5728\u5185\u5b58\u603b\u7ebf\u4f20\u8f93\u8fc7\u7a0b\u4e2d\u4e22\u5931\uff0c\u65e0\u6cd5\u88ab\u5185\u5b58\u8bbe\u5907\u5229\u7528\u3002", "method": "\u5728\u5185\u5b58\u8bfb\u53d6\u5730\u5740\u6d41\u4e2d\u4ee5\u975e\u7834\u574f\u6027\u65b9\u5f0f\u7f16\u7801\u7528\u6237\u53ef\u89c1\u72b6\u6001\u4f5c\u4e3a\u53ef\u68c0\u6d4b\u7684\u6570\u636e\u5305\uff0c\u65e0\u9700\u663e\u8457\u5bb9\u91cf\u5f00\u9500\u3001\u9a71\u52a8\u7a0b\u5e8f\u6216\u7279\u6b8a\u8bbf\u95ee\u6743\u9650\u3002\u6784\u5efa\u4e86\u5143\u6570\u636e\u6ce8\u5165\u7684\u539f\u578b\u7cfb\u7edf\uff0c\u53ef\u5728\u5185\u5b58\u5730\u5740\u8ddf\u8e2a\u4e2d\u53ef\u9760\u68c0\u6d4b\u548c\u89e3\u7801\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u7cfb\u7edf\u539f\u578b\uff0c\u80fd\u591f\u901a\u8fc7\u5185\u5b58\u5730\u5740\u8ddf\u8e2a\u53ef\u9760\u68c0\u6d4b\u548c\u89e3\u7801\u5143\u6570\u636e\u3002\u6f14\u793a\u4e86\u7cbe\u786e\u4ee3\u7801\u6267\u884c\u6807\u8bb0\u548c\u5bf9\u8c61\u5730\u5740\u8303\u56f4\u8ddf\u8e2a\u7684\u5e94\u7528\u6848\u4f8b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4f7f\u7a0b\u5e8f\u4e0a\u4e0b\u6587\u5728\u5185\u5b58\u8bbe\u5907\u4e2d\u53ef\u89c1\uff0c\u672a\u6765\u7ed3\u5408\u8fd1\u5185\u5b58\u8ba1\u7b97\u53ef\u5b9e\u73b0\u5b9e\u65f6\u5143\u6570\u636e\u89e3\u7801\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u5b9a\u5236\u5316\u9065\u6d4b\u548c\u7edf\u8ba1\uff0c\u6216\u6839\u636e\u5e94\u7528\u63d0\u793a\u6267\u884c\u8bf7\u6c42\u4f18\u5148\u7ea7\u6392\u5e8f\u3001\u6570\u636e\u91cd\u6620\u5c04\u548c\u8bbe\u5907\u91cd\u65b0\u914d\u7f6e\u7b49\u529f\u80fd\u3002"}}
{"id": "2510.15983", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15983", "abs": "https://arxiv.org/abs/2510.15983", "authors": ["Sarah Rebecca Ondraszek", "J\u00f6rg Waitelonis", "Katja Keller", "Claudia Niessner", "Anna M. Jacyszyn", "Harald Sack"], "title": "Ontologies in Motion: A BFO-Based Approach to Knowledge Graph Construction for Motor Performance Research Data in Sports Science", "comment": "10 pages, 2 figures. Camera-ready version. Accepted to the 5th\n  International Workshop on Scientific Knowledge: Representation, Discovery,\n  and Assessment; 2 November 2025 - Nara, Japan; co-located with The 24th\n  International Semantic Web Conference, ISWC 2025. To be published in CEUR\n  proceedings", "summary": "An essential component for evaluating and comparing physical and cognitive\ncapabilities between populations is the testing of various factors related to\nhuman performance. As a core part of sports science research, testing motor\nperformance enables the analysis of the physical health of different\ndemographic groups and makes them comparable.\n  The Motor Research (MO|RE) data repository, developed at the Karlsruhe\nInstitute of Technology, is an infrastructure for publishing and archiving\nresearch data in sports science, particularly in the field of motor performance\nresearch. In this paper, we present our vision for creating a knowledge graph\nfrom MO|RE data. With an ontology rooted in the Basic Formal Ontology, our\napproach centers on formally representing the interrelation of plan\nspecifications, specific processes, and related measurements. Our goal is to\ntransform how motor performance data are modeled and shared across studies,\nmaking it standardized and machine-understandable. The idea presented here is\ndeveloped within the Leibniz Science Campus ``Digital Transformation of\nResearch'' (DiTraRe).", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86MO|RE\u6570\u636e\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u613f\u666f\uff0c\u65e8\u5728\u901a\u8fc7\u57fa\u4e8e\u57fa\u672c\u5f62\u5f0f\u672c\u4f53\u7684\u65b9\u6cd5\u6807\u51c6\u5316\u548c\u673a\u5668\u53ef\u7406\u89e3\u5730\u5efa\u6a21\u4e0e\u5171\u4eab\u8fd0\u52a8\u8868\u73b0\u6570\u636e\u3002", "motivation": "\u4e3a\u4e86\u8bc4\u4f30\u548c\u6bd4\u8f83\u4e0d\u540c\u4eba\u7fa4\u7684\u751f\u7406\u548c\u8ba4\u77e5\u80fd\u529b\uff0c\u9700\u8981\u6d4b\u8bd5\u4e0e\u4eba\u7c7b\u8868\u73b0\u76f8\u5173\u7684\u5404\u79cd\u56e0\u7d20\u3002\u8fd0\u52a8\u8868\u73b0\u6d4b\u8bd5\u4f5c\u4e3a\u4f53\u80b2\u79d1\u5b66\u7814\u7a76\u7684\u6838\u5fc3\u90e8\u5206\uff0c\u80fd\u591f\u5206\u6790\u4e0d\u540c\u4eba\u53e3\u7fa4\u4f53\u7684\u8eab\u4f53\u5065\u5eb7\u72b6\u51b5\u5e76\u4f7f\u5176\u5177\u6709\u53ef\u6bd4\u6027\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u57fa\u672c\u5f62\u5f0f\u672c\u4f53\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u91cd\u70b9\u5f62\u5f0f\u5316\u8868\u793a\u8ba1\u5212\u89c4\u8303\u3001\u7279\u5b9a\u8fc7\u7a0b\u548c\u76f8\u5173\u6d4b\u91cf\u4e4b\u95f4\u7684\u76f8\u4e92\u5173\u7cfb\u3002", "result": "\u63d0\u51fa\u4e86MO|RE\u6570\u636e\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u613f\u666f\u548c\u5b9e\u73b0\u65b9\u6cd5\uff0c\u4e3a\u8fd0\u52a8\u8868\u73b0\u6570\u636e\u7684\u6807\u51c6\u5316\u5efa\u6a21\u548c\u8de8\u7814\u7a76\u5171\u4eab\u63d0\u4f9b\u4e86\u6846\u67b6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c06\u6539\u53d8\u8fd0\u52a8\u8868\u73b0\u6570\u636e\u7684\u5efa\u6a21\u548c\u5171\u4eab\u65b9\u5f0f\uff0c\u4f7f\u5176\u6807\u51c6\u5316\u4e14\u673a\u5668\u53ef\u7406\u89e3\uff0c\u4fc3\u8fdb\u4f53\u80b2\u79d1\u5b66\u7814\u7a76\u7684\u6570\u5b57\u5316\u8f6c\u578b\u3002"}}
{"id": "2510.15989", "categories": ["cs.CR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2510.15989", "abs": "https://arxiv.org/abs/2510.15989", "authors": ["Keshav Sood", "Sanjay Selvaraj", "Youyang Qu"], "title": "Meta-Guardian: An Early Evaluation of an On-device Application to Mitigate Psychography Data Leakage in Immersive Technologies", "comment": null, "summary": "The use of Immersive Technologies has shown its potential to revolutionize\nmany sectors such as health, entertainment, education, and industrial sectors.\nImmersive technologies such as Virtual Reality (VR), Augmented reality (AR),\nand Mixed Reality (MR) have redefined user interaction through real-time\nbiometric and behavioral tracking. Although Immersive Technologies (XR)\nessentially need the collection of the biometric data which acts as a baseline\nto create immersive experience, however, this ongoing feedback information\n(includes biometrics) poses critical privacy concerns due to the sensitive\nnature of the data collected. A comprehensive review of recent literature\nexplored the technical dimensions of related problem; however, they largely\noverlook the challenge particularly the intricacies of real-time biometric data\nfiltering within head-mounted display system. Motivated from this, in this\nwork, we propose a novel privacy-preserving system architecture that identifies\nand filters biometric signals (within the VR headset) in real-time before\ntransmission or storage. Implemented as a modular Unity Software-development\nKit (SDK) compatible with major immersive platforms, our solution (named\nMeta-Guardian) employs machine learning models for signal classification and a\nfiltering mechanism to block sensitive data. This framework aims to enable\ndevelopers to embed privacy-by-design principles into immersive experiences on\nvarious headsets and applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMeta-Guardian\u7684\u9690\u79c1\u4fdd\u62a4\u7cfb\u7edf\u67b6\u6784\uff0c\u7528\u4e8e\u5728VR\u5934\u663e\u4e2d\u5b9e\u65f6\u8bc6\u522b\u548c\u8fc7\u6ee4\u751f\u7269\u7279\u5f81\u4fe1\u53f7\uff0c\u9632\u6b62\u654f\u611f\u6570\u636e\u4f20\u8f93\u6216\u5b58\u50a8\u3002", "motivation": "\u6c89\u6d78\u5f0f\u6280\u672f\uff08VR\u3001AR\u3001MR\uff09\u9700\u8981\u6536\u96c6\u751f\u7269\u7279\u5f81\u6570\u636e\u6765\u521b\u9020\u6c89\u6d78\u5f0f\u4f53\u9a8c\uff0c\u4f46\u8fd9\u4e9b\u5b9e\u65f6\u53cd\u9988\u4fe1\u606f\uff08\u5305\u62ec\u751f\u7269\u7279\u5f81\uff09\u7531\u4e8e\u6570\u636e\u7684\u654f\u611f\u6027\u800c\u5f15\u53d1\u4e25\u91cd\u7684\u9690\u79c1\u95ee\u9898\u3002\u73b0\u6709\u6587\u732e\u5927\u591a\u5ffd\u89c6\u4e86\u5934\u6234\u5f0f\u663e\u793a\u7cfb\u7edf\u4e2d\u5b9e\u65f6\u751f\u7269\u7279\u5f81\u6570\u636e\u8fc7\u6ee4\u7684\u590d\u6742\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u7684Unity\u8f6f\u4ef6\u5f00\u53d1\u5de5\u5177\u5305\uff08SDK\uff09\uff0c\u4e0e\u4e3b\u6d41\u6c89\u6d78\u5f0f\u5e73\u53f0\u517c\u5bb9\u3002\u8be5\u7cfb\u7edf\u91c7\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u4fe1\u53f7\u5206\u7c7b\uff0c\u5e76\u4f7f\u7528\u8fc7\u6ee4\u673a\u5236\u6765\u963b\u6b62\u654f\u611f\u6570\u636e\u3002", "result": "\u5b9e\u73b0\u4e86\u4e00\u4e2a\u53ef\u5728VR\u5934\u663e\u5185\u5b9e\u65f6\u5904\u7406\u751f\u7269\u7279\u5f81\u4fe1\u53f7\u7684\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\uff0c\u4f7f\u5f00\u53d1\u8005\u80fd\u591f\u5728\u5404\u79cd\u5934\u663e\u548c\u5e94\u7528\u4e2d\u5d4c\u5165\u9690\u79c1\u8bbe\u8ba1\u539f\u5219\u3002", "conclusion": "Meta-Guardian\u7cfb\u7edf\u4e3a\u6c89\u6d78\u5f0f\u4f53\u9a8c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5728\u8bbe\u5907\u7aef\u5b9e\u65f6\u8fc7\u6ee4\u654f\u611f\u751f\u7269\u7279\u5f81\u6570\u636e\u6765\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u3002"}}
{"id": "2510.15880", "categories": ["cs.AR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2510.15880", "abs": "https://arxiv.org/abs/2510.15880", "authors": ["Philip Emma", "Eren Kurshan"], "title": "Opportunities and Challenges for 3D Systems and Their Design", "comment": "IEEE Design and Computers", "summary": "Although it is not a new concept, 3D integration increasingly receives\nwidespread interest and focus as lithographic scaling becomes more challenging,\nand as the ability to make miniature vias greatly improves. Like Moores law, 3D\nintegration improves density. With improvements in packaging density, however,\ncome the challenges associated with its inherently higher power density. And\nthough it acts somewhat as a scaling accelerator, the vertical integration also\nposes new challenges to design and manufacturing technologies. The placement of\ncircuits, vias, and macros in the planes of a 3D stack must be co-designed\nacross layers (or must conform to new standards) so that, when assembled, they\nhave correct spatial correspondence. Each layer, although perhaps being a mere\nfunctional slice through a system (and we can slice the system in many\ndifferent ways), must be independently testable so that we can systematically\ntest and diagnose subsystems before and after final assembly. When those layers\nare assembled, they must come together in a way that enables a sensible yield\nand facilitates testing the finished product. To make the most of 3D\nintegration, we should articulate the leverages of 3D systems (other\nresearchers offer a more complete treatment elsewhere). Then we can enumerate\nand elucidate many of the new challenges posed by the design, assembly, and\ntest of 3D systems.", "AI": {"tldr": "3D\u96c6\u6210\u6280\u672f\u968f\u7740\u5149\u523b\u7f29\u653e\u6311\u6218\u589e\u52a0\u548c\u5fae\u578b\u901a\u5b54\u5236\u9020\u80fd\u529b\u63d0\u5347\u800c\u53d7\u5230\u5e7f\u6cdb\u5173\u6ce8\uff0c\u5b83\u901a\u8fc7\u5782\u76f4\u5806\u53e0\u63d0\u9ad8\u5bc6\u5ea6\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u529f\u7387\u5bc6\u5ea6\u589e\u52a0\u3001\u8bbe\u8ba1\u548c\u5236\u9020\u6280\u672f\u7684\u65b0\u6311\u6218\uff0c\u9700\u8981\u8de8\u5c42\u534f\u540c\u8bbe\u8ba1\u3001\u72ec\u7acb\u6d4b\u8bd5\u548c\u7cfb\u7edf\u7ec4\u88c5\u4f18\u5316\u3002", "motivation": "\u968f\u7740\u5149\u523b\u7f29\u653e\u53d8\u5f97\u8d8a\u6765\u8d8a\u56f0\u96be\uff0c\u4ee5\u53ca\u5236\u9020\u5fae\u578b\u901a\u5b54\u80fd\u529b\u7684\u663e\u8457\u63d0\u5347\uff0c3D\u96c6\u6210\u6280\u672f\u91cd\u65b0\u83b7\u5f97\u5e7f\u6cdb\u5173\u6ce8\u3002\u5b83\u7c7b\u4f3c\u4e8e\u6469\u5c14\u5b9a\u5f8b\uff0c\u80fd\u591f\u63d0\u9ad8\u82af\u7247\u5bc6\u5ea6\uff0c\u4f46\u9ad8\u5bc6\u5ea6\u4e5f\u5e26\u6765\u4e86\u529f\u7387\u5bc6\u5ea6\u589e\u52a0\u7684\u6311\u6218\u3002", "method": "3D\u96c6\u6210\u901a\u8fc7\u5782\u76f4\u5806\u53e0\u7535\u8def\u5c42\u6765\u63d0\u9ad8\u5bc6\u5ea6\uff0c\u9700\u8981\u8de8\u5c42\u534f\u540c\u8bbe\u8ba1\u7535\u8def\u3001\u901a\u5b54\u548c\u5b8f\u5355\u5143\u7684\u5e03\u5c40\uff0c\u786e\u4fdd\u7ec4\u88c5\u65f6\u7684\u7a7a\u95f4\u5bf9\u5e94\u5173\u7cfb\u3002\u6bcf\u5c42\u9700\u8981\u72ec\u7acb\u6d4b\u8bd5\uff0c\u7cfb\u7edf\u9700\u8981\u652f\u6301\u7ec4\u88c5\u524d\u540e\u7684\u6d4b\u8bd5\u548c\u8bca\u65ad\u3002", "result": "3D\u96c6\u6210\u4f5c\u4e3a\u7f29\u653e\u52a0\u901f\u5668\uff0c\u5728\u63d0\u9ad8\u5bc6\u5ea6\u7684\u540c\u65f6\uff0c\u5bf9\u8bbe\u8ba1\u3001\u5236\u9020\u548c\u6d4b\u8bd5\u6280\u672f\u63d0\u51fa\u4e86\u65b0\u7684\u8981\u6c42\uff0c\u5305\u62ec\u8de8\u5c42\u534f\u540c\u8bbe\u8ba1\u3001\u72ec\u7acb\u6d4b\u8bd5\u80fd\u529b\u548c\u7ec4\u88c5\u4f18\u5316\u7b49\u65b9\u9762\u3002", "conclusion": "\u8981\u5145\u5206\u53d1\u63253D\u96c6\u6210\u7684\u4f18\u52bf\uff0c\u9700\u8981\u660e\u786e3D\u7cfb\u7edf\u7684\u6760\u6746\u4f5c\u7528\uff0c\u5e76\u7cfb\u7edf\u6027\u5730\u89e3\u51b3\u8bbe\u8ba1\u3001\u7ec4\u88c5\u548c\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u9762\u4e34\u7684\u65b0\u6311\u6218\u3002"}}
{"id": "2510.16418", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.16418", "abs": "https://arxiv.org/abs/2510.16418", "authors": ["Jian Ma", "Xinchen Lyu", "Jun Jiang", "Longhao Zou", "Chenshan Ren", "Qimei Cui", "Xiaofeng Tao"], "title": "FourierCompress: Layer-Aware Spectral Activation Compression for Efficient and Accurate Collaborative LLM Inference", "comment": null, "summary": "Collaborative large language model (LLM) inference enables real-time,\nprivacy-preserving AI services on resource-constrained edge devices by\npartitioning computational workloads between client devices and edge servers.\nHowever, this paradigm is severely hindered by communication bottlenecks caused\nby the transmission of high-dimensional intermediate activations, exacerbated\nby the autoregressive decoding structure of LLMs, where bandwidth consumption\nscales linearly with output length. Existing activation compression methods\nstruggle to simultaneously achieve high compression ratios, low reconstruction\nerror, and computational efficiency. This paper proposes FourierCompress, a\nnovel, layer-aware activation compression framework that exploits the\nfrequency-domain sparsity of LLM activations. We rigorously demonstrate that\nactivations from the first Transformer layer exhibit strong smoothness and\nenergy concentration in the low-frequency domain, making them highly amenable\nto near-lossless compression via the Fast Fourier Transform (FFT).\nFourierCompress transforms activations into the frequency domain, retains only\na compact block of low-frequency coefficients, and reconstructs the signal at\nthe server using conjugate symmetry, enabling seamless hardware acceleration on\nDSPs and FPGAs. Extensive experiments on Llama 3 and Qwen2.5 models across 10\ncommonsense reasoning datasets demonstrate that FourierCompress preserves\nperformance remarkably close to the uncompressed baseline, outperforming Top-k,\nQR, and SVD. FourierCompress bridges the gap between communication efficiency\n(an average 7.6x reduction in activation size), near-lossless inference (less\nthan 0.3% average accuracy loss), and significantly faster compression\n(achieving over 32x reduction in compression time compared to Top-k via\nhardware acceleration) for edge-device LLM inference.", "AI": {"tldr": "FourierCompress\u662f\u4e00\u79cd\u57fa\u4e8e\u5085\u91cc\u53f6\u53d8\u6362\u7684LLM\u6fc0\u6d3b\u538b\u7f29\u6846\u67b6\uff0c\u5229\u7528\u6fc0\u6d3b\u5728\u9891\u57df\u7684\u7a00\u758f\u6027\uff0c\u901a\u8fc7\u4fdd\u7559\u4f4e\u9891\u7cfb\u6570\u5b9e\u73b0\u9ad8\u6548\u538b\u7f29\uff0c\u5728\u8fb9\u7f18\u8bbe\u5907LLM\u63a8\u7406\u4e2d\u5b9e\u73b07.6\u500d\u538b\u7f29\u6bd4\u548c\u5c0f\u4e8e0.3%\u7684\u7cbe\u5ea6\u635f\u5931\u3002", "motivation": "\u89e3\u51b3\u534f\u4f5c\u5f0fLLM\u63a8\u7406\u4e2d\u7684\u901a\u4fe1\u74f6\u9888\u95ee\u9898\uff0c\u4f20\u7edf\u6fc0\u6d3b\u538b\u7f29\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5b9e\u73b0\u9ad8\u538b\u7f29\u6bd4\u3001\u4f4e\u91cd\u6784\u8bef\u5dee\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u538b\u7f29\u65b9\u6cd5\u3002", "method": "\u5229\u7528LLM\u6fc0\u6d3b\u5728\u9891\u57df\u7684\u7a00\u758f\u6027\uff0c\u901a\u8fc7FFT\u5c06\u6fc0\u6d3b\u8f6c\u6362\u5230\u9891\u57df\uff0c\u4ec5\u4fdd\u7559\u4f4e\u9891\u7cfb\u6570\u5757\uff0c\u5728\u670d\u52a1\u5668\u7aef\u5229\u7528\u5171\u8f6d\u5bf9\u79f0\u6027\u91cd\u6784\u4fe1\u53f7\uff0c\u652f\u6301DSP\u548cFPGA\u786c\u4ef6\u52a0\u901f\u3002", "result": "\u5728Llama 3\u548cQwen2.5\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFourierCompress\u4fdd\u6301\u6027\u80fd\u63a5\u8fd1\u672a\u538b\u7f29\u57fa\u7ebf\uff0c\u4f18\u4e8eTop-k\u3001QR\u548cSVD\u65b9\u6cd5\uff0c\u5b9e\u73b0\u5e73\u57477.6\u500d\u6fc0\u6d3b\u5927\u5c0f\u51cf\u5c11\u548c\u5c0f\u4e8e0.3%\u7684\u7cbe\u5ea6\u635f\u5931\u3002", "conclusion": "FourierCompress\u5728\u901a\u4fe1\u6548\u7387\u3001\u8fd1\u65e0\u635f\u63a8\u7406\u548c\u538b\u7f29\u901f\u5ea6\u65b9\u9762\u53d6\u5f97\u4e86\u5e73\u8861\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907LLM\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.16001", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16001", "abs": "https://arxiv.org/abs/2510.16001", "authors": ["Ruolan Cheng", "Yong Deng", "Enrique Herrera-Viedma"], "title": "A Non-overlap-based Conflict Measure for Random Permutation Sets", "comment": null, "summary": "Random permutation set (RPS) is a new formalism for reasoning with\nuncertainty involving order information. Measuring the conflict between two\npieces of evidence represented by permutation mass functions remains an urgent\nresearch topic in order-structured uncertain information fusion. In this paper,\na detailed analysis of conflicts in RPS is carried out from two different\nperspectives: random finite set (RFS) and Dempster-Shafer theory (DST).\nStarting from the observation of permutations, we first define an inconsistency\nmeasure between permutations inspired by the rank-biased overlap(RBO) measure\nand further propose a non-overlap-based conflict measure method for RPSs. This\npaper regards RPS theory (RPST) as an extension of DST. The order information\nnewly added in focal sets indicates qualitative propensity, characterized by\ntop-ranked elements occupying a more critical position. Some numerical examples\nare used to demonstrate the behavior and properties of the proposed conflict\nmeasure. The proposed method not only has the natural top-weightedness property\nand can effectively measure the conflict between RPSs from the DST view but\nalso provides decision-makers with a flexible selection of weights, parameters,\nand truncated depths.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u7f6e\u6362\u96c6(RPS)\u7684\u51b2\u7a81\u5ea6\u91cf\u65b9\u6cd5\uff0c\u4ece\u968f\u673a\u6709\u9650\u96c6(RFS)\u548cDempster-Shafer\u7406\u8bba(DST)\u4e24\u4e2a\u89d2\u5ea6\u5206\u6790RPS\u4e2d\u7684\u51b2\u7a81\uff0c\u5229\u7528\u79e9\u504f\u91cd\u53e0(RBO)\u601d\u60f3\u5b9a\u4e49\u7f6e\u6362\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\u5ea6\u91cf\u3002", "motivation": "\u968f\u673a\u7f6e\u6362\u96c6\u4f5c\u4e3a\u5904\u7406\u5305\u542b\u987a\u5e8f\u4fe1\u606f\u7684\u4e0d\u786e\u5b9a\u6027\u7684\u65b0\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u9700\u8981\u6709\u6548\u5ea6\u91cf\u4e24\u4e2a\u7531\u7f6e\u6362\u8d28\u91cf\u51fd\u6570\u8868\u793a\u7684\u8bc1\u636e\u4e4b\u95f4\u7684\u51b2\u7a81\uff0c\u8fd9\u662f\u987a\u5e8f\u7ed3\u6784\u4e0d\u786e\u5b9a\u4fe1\u606f\u878d\u5408\u7684\u8feb\u5207\u7814\u7a76\u8bfe\u9898\u3002", "method": "\u4ece\u7f6e\u6362\u89c2\u5bdf\u51fa\u53d1\uff0c\u57fa\u4e8e\u79e9\u504f\u91cd\u53e0(RBO)\u5ea6\u91cf\u5b9a\u4e49\u7f6e\u6362\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\u5ea6\u91cf\uff0c\u63d0\u51fa\u975e\u91cd\u53e0\u57fa\u7840\u7684RPS\u51b2\u7a81\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5c06RPS\u7406\u8bba\u89c6\u4e3aDST\u7684\u6269\u5c55\uff0c\u5229\u7528\u65b0\u589e\u7684\u987a\u5e8f\u4fe1\u606f\u8868\u5f81\u5b9a\u6027\u503e\u5411\u6027\u3002", "result": "\u901a\u8fc7\u6570\u503c\u793a\u4f8b\u9a8c\u8bc1\u4e86\u6240\u63d0\u51b2\u7a81\u5ea6\u91cf\u7684\u884c\u4e3a\u548c\u6027\u8d28\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u81ea\u7136\u7684\u9876\u90e8\u52a0\u6743\u7279\u6027\uff0c\u80fd\u4eceDST\u89c6\u89d2\u6709\u6548\u5ea6\u91cfRPS\u95f4\u7684\u51b2\u7a81\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u4e0d\u4ec5\u5177\u6709\u81ea\u7136\u9876\u90e8\u52a0\u6743\u7279\u6027\uff0c\u80fd\u6709\u6548\u5ea6\u91cfRPS\u95f4\u7684\u51b2\u7a81\uff0c\u8fd8\u4e3a\u51b3\u7b56\u8005\u63d0\u4f9b\u4e86\u6743\u91cd\u3001\u53c2\u6570\u548c\u622a\u65ad\u6df1\u5ea6\u7684\u7075\u6d3b\u9009\u62e9\u3002"}}
{"id": "2510.15882", "categories": ["cs.AR", "cs.AI", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15882", "abs": "https://arxiv.org/abs/2510.15882", "authors": ["Ao Shen", "Rui Zhang", "Junping Zhao"], "title": "FlexLink: Boosting your NVLink Bandwidth by 27% without accuracy concern", "comment": null, "summary": "As large language models (LLMs) continue to scale, multi-node deployment has\nbecome a necessity. Consequently, communication has become a critical\nperformance bottleneck. Current intra-node communication libraries, like NCCL,\ntypically make use of a single interconnect such as NVLink. This approach\ncreates performance ceilings, especially on hardware like the H800 GPU where\nthe primary interconnect's bandwidth can become a bottleneck, and leaves other\nhardware resources like PCIe and Remote Direct Memory Access (RDMA)-capable\nNetwork Interface Cards (NICs) largely idle during intensive workloads. We\npropose FlexLink, the first collective communication framework to the best of\nour knowledge designed to systematically address this by aggregating these\nheterogeneous links-NVLink, PCIe, and RDMA NICs-into a single, high-performance\ncommunication fabric. FlexLink employs an effective two-stage adaptive load\nbalancing strategy that dynamically partitions communication traffic across all\navailable links, ensuring that faster interconnects are not throttled by slower\nones. On an 8-GPU H800 server, our design improves the bandwidth of collective\noperators such as AllReduce and AllGather by up to 26% and 27% over the NCCL\nbaseline, respectively. This gain is achieved by offloading 2-22% of the total\ncommunication traffic to the previously underutilized PCIe and RDMA NICs.\nFlexLink provides these improvements as a lossless, drop-in replacement\ncompatible with the NCCL API, ensuring easy adoption.", "AI": {"tldr": "FlexLink\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u96c6\u4f53\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u5408NVLink\u3001PCIe\u548cRDMA NICs\u7b49\u5f02\u6784\u94fe\u8def\u6765\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u591a\u8282\u70b9\u90e8\u7f72\u4e2d\u7684\u901a\u4fe1\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u6269\u5927\uff0c\u591a\u8282\u70b9\u90e8\u7f72\u6210\u4e3a\u5fc5\u9700\uff0c\u4f46\u5f53\u524d\u901a\u4fe1\u5e93\u5982NCCL\u4ec5\u4f7f\u7528\u5355\u4e00\u4e92\u8fde\uff08\u5982NVLink\uff09\uff0c\u5bfc\u81f4\u6027\u80fd\u74f6\u9888\uff0c\u800c\u5176\u4ed6\u786c\u4ef6\u8d44\u6e90\u5982PCIe\u548cRDMA NICs\u5728\u5bc6\u96c6\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u88ab\u95f2\u7f6e\u3002", "method": "FlexLink\u91c7\u7528\u4e24\u9636\u6bb5\u81ea\u9002\u5e94\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\uff0c\u52a8\u6001\u5730\u5c06\u901a\u4fe1\u6d41\u91cf\u5206\u533a\u5230\u6240\u6709\u53ef\u7528\u94fe\u8def\u4e0a\uff0c\u786e\u4fdd\u5feb\u901f\u4e92\u8fde\u4e0d\u88ab\u8f83\u6162\u7684\u4e92\u8fde\u6240\u9650\u5236\u3002", "result": "\u57288-GPU H800\u670d\u52a1\u5668\u4e0a\uff0cFlexLink\u5c06AllReduce\u548cAllGather\u7b49\u96c6\u4f53\u64cd\u4f5c\u7b26\u7684\u5e26\u5bbd\u5206\u522b\u63d0\u9ad8\u4e8626%\u548c27%\uff0c\u901a\u8fc7\u5c062-22%\u7684\u603b\u901a\u4fe1\u6d41\u91cf\u5378\u8f7d\u5230\u4e4b\u524d\u672a\u5145\u5206\u5229\u7528\u7684PCIe\u548cRDMA NICs\u4e0a\u5b9e\u73b0\u3002", "conclusion": "FlexLink\u4f5c\u4e3a\u65e0\u635f\u7684\u5373\u63d2\u5373\u7528\u66ff\u4ee3\u65b9\u6848\uff0c\u4e0eNCCL API\u517c\u5bb9\uff0c\u6613\u4e8e\u91c7\u7528\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8282\u70b9\u90e8\u7f72\u4e2d\u7684\u901a\u4fe1\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2510.16005", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16005", "abs": "https://arxiv.org/abs/2510.16005", "authors": ["Giacomo Bertollo", "Naz Bodemir", "Jonah Burgess"], "title": "Breaking Guardrails, Facing Walls: Insights on Adversarial AI for Defenders & Researchers", "comment": null, "summary": "Analyzing 500 CTF participants, this paper shows that while participants\nreadily bypassed simple AI guardrails using common techniques, layered\nmulti-step defenses still posed significant challenges, offering concrete\ninsights for building safer AI systems.", "AI": {"tldr": "\u5bf9500\u540dCTF\u53c2\u4e0e\u8005\u7684\u5206\u6790\u663e\u793a\uff0c\u867d\u7136\u53c2\u4e0e\u8005\u80fd\u8f7b\u677e\u7ed5\u8fc7\u7b80\u5355\u7684AI\u9632\u62a4\u63aa\u65bd\uff0c\u4f46\u591a\u5c42\u591a\u6b65\u9632\u5fa1\u4ecd\u6784\u6210\u663e\u8457\u6311\u6218\uff0c\u4e3a\u6784\u5efa\u66f4\u5b89\u5168\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5177\u4f53\u89c1\u89e3\u3002", "motivation": "\u7814\u7a76AI\u7cfb\u7edf\u7684\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u5728\u5b9e\u9645\u653b\u51fb\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e86\u89e3\u4e0d\u540c\u9632\u5fa1\u7b56\u7565\u5bf9\u653b\u51fb\u8005\u7684\u963b\u788d\u7a0b\u5ea6\u3002", "method": "\u901a\u8fc7\u5206\u6790500\u540dCTF\uff08\u593a\u65d7\u8d5b\uff09\u53c2\u4e0e\u8005\u7684\u653b\u51fb\u884c\u4e3a\uff0c\u6d4b\u8bd5\u7b80\u5355AI\u9632\u62a4\u63aa\u65bd\u4e0e\u591a\u5c42\u591a\u6b65\u9632\u5fa1\u7b56\u7565\u7684\u6548\u679c\u5bf9\u6bd4\u3002", "result": "\u53c2\u4e0e\u8005\u80fd\u591f\u8f7b\u677e\u7ed5\u8fc7\u7b80\u5355\u7684AI\u9632\u62a4\u63aa\u65bd\uff0c\u4f46\u9762\u5bf9\u591a\u5c42\u591a\u6b65\u9632\u5fa1\u65f6\u9047\u5230\u663e\u8457\u56f0\u96be\u3002", "conclusion": "\u591a\u5c42\u591a\u6b65\u9632\u5fa1\u7b56\u7565\u5728\u4fdd\u62a4AI\u7cfb\u7edf\u5b89\u5168\u65b9\u9762\u6bd4\u7b80\u5355\u9632\u62a4\u63aa\u65bd\u66f4\u6709\u6548\uff0c\u4e3a\u6784\u5efa\u66f4\u5b89\u5168\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2510.15884", "categories": ["cs.AR", "cs.MS"], "pdf": "https://arxiv.org/pdf/2510.15884", "abs": "https://arxiv.org/abs/2510.15884", "authors": ["Faizan A Khattak", "Mantas Mikaitis"], "title": "Generalized Methodology for Determining Numerical Features of Hardware Floating-Point Matrix Multipliers: Part I", "comment": "Accepted for IEEE HPEC 2025", "summary": "Numerical features of matrix multiplier hardware units in NVIDIA and AMD data\ncentre GPUs have recently been studied. Features such as rounding,\nnormalisation, and internal precision of the accumulators are of interest. In\nthis paper, we extend the methodology for analysing those features, to\nconsumer-grade NVIDIA GPUs by implementing an architecture-independent test\nscheme for various input and output precision formats. Unlike current\napproaches, the proposed test vector generation method neither performs an\nexhaustive search nor relies on hard-coded {constants that are device-specific,\nyet remains applicable to a wide range of mixed-precision formats. We have\napplied the scheme to the RTX-3060 (Ampere architecture), and Ada RTX-1000 (Ada\nLovelace architecture) graphics cards and determined numerical features of\nmatrix multipliers for binary16, TensorFloat32, and bfloat16 input floating\npoint formats and binary16 and binary32 IEEE 754 output formats. Our\nmethodology allowed us to determine that} the numerical features of RTX-3060, a\nconsumer-grade GPU, are identical to those of the A100, a data centre GPU. We\ndo not expect our code to require any changes for performing analysis of matrix\nmultipliers on newer NVIDIA GPUs, Hopper or Blackwell, and their future\nsuccessors, and any input/output format combination, including the latest 8-bit\nfloating-point formats.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u5206\u6790GPU\u77e9\u9635\u4e58\u6cd5\u5668\u6570\u503c\u7279\u5f81\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u67b6\u6784\u65e0\u5173\u7684\u6d4b\u8bd5\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u8f93\u5165\u8f93\u51fa\u7cbe\u5ea6\u683c\u5f0f\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e\u6d88\u8d39\u7ea7NVIDIA GPU\u3002", "motivation": "\u7814\u7a76NVIDIA\u548cAMD\u6570\u636e\u4e2d\u5fc3GPU\u4e2d\u77e9\u9635\u4e58\u6cd5\u5668\u786c\u4ef6\u5355\u5143\u7684\u6570\u503c\u7279\u5f81\uff08\u5982\u820d\u5165\u3001\u5f52\u4e00\u5316\u3001\u7d2f\u52a0\u5668\u5185\u90e8\u7cbe\u5ea6\uff09\uff0c\u5e76\u5c06\u5206\u6790\u65b9\u6cd5\u6269\u5c55\u5230\u6d88\u8d39\u7ea7NVIDIA GPU\u3002", "method": "\u5b9e\u73b0\u67b6\u6784\u65e0\u5173\u7684\u6d4b\u8bd5\u65b9\u6848\uff0c\u4f7f\u7528\u4e0d\u4f9d\u8d56\u8bbe\u5907\u7279\u5b9a\u5e38\u91cf\u7684\u6d4b\u8bd5\u5411\u91cf\u751f\u6210\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u6df7\u5408\u7cbe\u5ea6\u683c\u5f0f\u3002", "result": "\u5e94\u7528\u8be5\u65b9\u6848\u5230RTX-3060\u548cAda RTX-1000\u663e\u5361\uff0c\u786e\u5b9a\u4e86binary16\u3001TensorFloat32\u548cbfloat16\u8f93\u5165\u683c\u5f0f\u4ee5\u53cabinary16\u548cbinary32\u8f93\u51fa\u683c\u5f0f\u7684\u77e9\u9635\u4e58\u6cd5\u5668\u6570\u503c\u7279\u5f81\uff0c\u53d1\u73b0RTX-3060\u4e0e\u6570\u636e\u4e2d\u5fc3GPU A100\u7684\u6570\u503c\u7279\u5f81\u76f8\u540c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u4fee\u6539\u5373\u53ef\u7528\u4e8e\u5206\u6790\u66f4\u65b0\u7684NVIDIA GPU\uff08\u5982Hopper\u6216Blackwell\uff09\u53ca\u5176\u672a\u6765\u7ee7\u4efb\u8005\uff0c\u4ee5\u53ca\u4efb\u4f55\u8f93\u5165/\u8f93\u51fa\u683c\u5f0f\u7ec4\u5408\uff0c\u5305\u62ec\u6700\u65b0\u76848\u4f4d\u6d6e\u70b9\u683c\u5f0f\u3002"}}
{"id": "2510.16606", "categories": ["cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.16606", "abs": "https://arxiv.org/abs/2510.16606", "authors": ["Ertza Warraich", "Ali Imran", "Annus Zulfiqar", "Shay Vargaftik", "Sonia Fahmy", "Muhammad Shahbaz"], "title": "Reimagining RDMA Through the Lens of ML", "comment": "4 pages", "summary": "As distributed machine learning (ML) workloads scale to thousands of GPUs\nconnected by ultra-high-speed inter-connects, tail latency in collective\ncommunication has emerged as a primary bottleneck. Prior RDMA designs, like\nRoCE, IRN, and SRNIC, enforce strict reliability and in-order delivery, relying\non retransmissions and packet sequencing to ensure correctness. While effective\nfor general-purpose workloads, these mechanisms introduce complexity and\nlatency that scale poorly, where even rare packet losses or delays can\nconsistently degrade system performance. We introduce Celeris, a\ndomain-specific RDMA transport that revisits traditional reliability guarantees\nbased on ML's tolerance for lost or partial data. Celeris removes\nretransmissions and in-order delivery from the RDMA NIC, enabling best-effort\ntransport that exploits the robustness of ML workloads. It retains congestion\ncontrol (e.g., DCQCN) and manages communication with software-level mechanisms\nsuch as adaptive timeouts and data prioritization, while shifting loss recovery\nto the ML pipeline (e.g., using the Hadamard Transform). Early results show\nthat Celeris reduces 99th-percentile latency by up to 2.3x, cuts BRAM usage by\n67%, and nearly doubles NIC resilience to faults -- delivering a resilient,\nscalable transport tailored for ML at cluster scale.", "AI": {"tldr": "Celeris\u662f\u4e00\u79cd\u9762\u5411\u673a\u5668\u5b66\u4e60\u9886\u57df\u7684\u4e13\u7528RDMA\u4f20\u8f93\u534f\u8bae\uff0c\u901a\u8fc7\u79fb\u9664\u91cd\u4f20\u548c\u6709\u5e8f\u4ea4\u4ed8\u673a\u5236\uff0c\u5229\u7528ML\u5de5\u4f5c\u8d1f\u8f7d\u5bf9\u6570\u636e\u4e22\u5931\u7684\u5bb9\u5fcd\u6027\u6765\u663e\u8457\u964d\u4f4e\u5c3e\u5ef6\u8fdf\u3002", "motivation": "\u968f\u7740\u5206\u5e03\u5f0fML\u5de5\u4f5c\u8d1f\u8f7d\u6269\u5c55\u5230\u6570\u5343\u4e2aGPU\uff0c\u96c6\u4f53\u901a\u4fe1\u4e2d\u7684\u5c3e\u5ef6\u8fdf\u6210\u4e3a\u4e3b\u8981\u74f6\u9888\u3002\u4f20\u7edfRDMA\u8bbe\u8ba1\u7684\u4e25\u683c\u53ef\u9760\u6027\u548c\u6709\u5e8f\u4ea4\u4ed8\u673a\u5236\u5728ML\u573a\u666f\u4e0b\u5f15\u5165\u4e86\u4e0d\u5fc5\u8981\u7684\u590d\u6742\u6027\u548c\u5ef6\u8fdf\u3002", "method": "Celeris\u5728RDMA NIC\u4e2d\u79fb\u9664\u91cd\u4f20\u548c\u6709\u5e8f\u4ea4\u4ed8\uff0c\u5b9e\u73b0\u5c3d\u529b\u800c\u4e3a\u4f20\u8f93\uff0c\u540c\u65f6\u4fdd\u7559\u62e5\u585e\u63a7\u5236\uff0c\u5e76\u901a\u8fc7\u8f6f\u4ef6\u7ea7\u673a\u5236\uff08\u5982\u81ea\u9002\u5e94\u8d85\u65f6\u548c\u6570\u636e\u4f18\u5148\u7ea7\uff09\u7ba1\u7406\u901a\u4fe1\uff0c\u5c06\u4e22\u5931\u6062\u590d\u8f6c\u79fb\u5230ML\u6d41\u6c34\u7ebf\u4e2d\u3002", "result": "Celeris\u5c06\u7b2c99\u767e\u5206\u4f4d\u5ef6\u8fdf\u964d\u4f4e\u9ad8\u8fbe2.3\u500d\uff0cBRAM\u4f7f\u7528\u91cf\u51cf\u5c1167%\uff0cNIC\u5bf9\u6545\u969c\u7684\u6062\u590d\u80fd\u529b\u51e0\u4e4e\u7ffb\u500d\u3002", "conclusion": "Celeris\u4e3a\u96c6\u7fa4\u89c4\u6a21\u7684ML\u5de5\u4f5c\u8d1f\u8f7d\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f39\u6027\u3001\u53ef\u6269\u5c55\u7684\u4e13\u7528\u4f20\u8f93\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5229\u7528ML\u5bf9\u6570\u636e\u4e22\u5931\u7684\u5bb9\u5fcd\u6027\u6765\u4f18\u5316\u6027\u80fd\u3002"}}
{"id": "2510.16024", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16024", "abs": "https://arxiv.org/abs/2510.16024", "authors": ["Abdulrahman Alhaidari", "Balaji Palanisamy", "Prashant Krishnamurthy"], "title": "On-Chain Decentralized Learning and Cost-Effective Inference for DeFi Attack Mitigation", "comment": "Published in the 7th Conference on Advances in Financial Technologies\n  (AFT 2025)", "summary": "Billions of dollars are lost every year in DeFi platforms by transactions\nexploiting business logic or accounting vulnerabilities. Existing defenses\nfocus on static code analysis, public mempool screening, attacker contract\ndetection, or trusted off-chain monitors, none of which prevents exploits\nsubmitted through private relays or malicious contracts that execute within the\nsame block. We present the first decentralized, fully on-chain learning\nframework that: (i) performs gas-prohibitive computation on Layer-2 to reduce\ncost, (ii) propagates verified model updates to Layer-1, and (iii) enables\ngas-bounded, low-latency inference inside smart contracts. A novel\nProof-of-Improvement (PoIm) protocol governs the training process and verifies\neach decentralized micro update as a self-verifying training transaction.\nUpdates are accepted by \\textit{PoIm} only if they demonstrably improve at\nleast one core metric (e.g., accuracy, F1-score, precision, or recall) on a\npublic benchmark without degrading any of the other core metrics, while\nadversarial proposals get financially penalized through an adaptable test set\nfor evolving threats. We develop quantization and loop-unrolling techniques\nthat enable inference for logistic regression, SVM, MLPs, CNNs, and gated RNNs\n(with support for formally verified decision tree inference) within the\nEthereum block gas limit, while remaining bit-exact to their off-chain\ncounterparts, formally proven in Z3. We curate 298 unique real-world exploits\n(2020 - 2025) with 402 exploit transactions across eight EVM chains,\ncollectively responsible for \\$3.74 B in losses.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u5b8c\u5168\u5728\u94fe\u4e0a\u7684\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7Layer-2\u6267\u884c\u8ba1\u7b97\u5bc6\u96c6\u578b\u4efb\u52a1\uff0c\u5c06\u9a8c\u8bc1\u540e\u7684\u6a21\u578b\u66f4\u65b0\u4f20\u64ad\u5230Layer-1\uff0c\u5e76\u5728\u667a\u80fd\u5408\u7ea6\u4e2d\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u63a8\u7406\uff0c\u4ee5\u9632\u6b62DeFi\u5e73\u53f0\u4e2d\u7684\u6f0f\u6d1e\u5229\u7528\u3002", "motivation": "DeFi\u5e73\u53f0\u6bcf\u5e74\u56e0\u4e1a\u52a1\u903b\u8f91\u6216\u4f1a\u8ba1\u6f0f\u6d1e\u800c\u635f\u5931\u6570\u5341\u4ebf\u7f8e\u5143\uff0c\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u65e0\u6cd5\u9632\u6b62\u901a\u8fc7\u79c1\u6709\u4e2d\u7ee7\u6216\u540c\u4e00\u533a\u5757\u5185\u6076\u610f\u5408\u7ea6\u63d0\u4ea4\u7684\u653b\u51fb\u3002", "method": "\u4f7f\u7528Proof-of-Improvement\u534f\u8bae\u7ba1\u7406\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u9a8c\u8bc1\u6bcf\u4e2a\u53bb\u4e2d\u5fc3\u5316\u5fae\u66f4\u65b0\uff1b\u5f00\u53d1\u91cf\u5316\u548c\u5faa\u73af\u5c55\u5f00\u6280\u672f\uff0c\u5728\u4ee5\u592a\u574a\u533a\u5757gas\u9650\u5236\u5185\u5b9e\u73b0\u903b\u8f91\u56de\u5f52\u3001SVM\u3001MLP\u3001CNN\u548c\u95e8\u63a7RNN\u7684\u63a8\u7406\u3002", "result": "\u6536\u96c6\u4e86298\u4e2a\u72ec\u7279\u7684\u771f\u5b9e\u4e16\u754c\u6f0f\u6d1e\u5229\u7528\u6848\u4f8b\uff082020-2025\u5e74\uff09\uff0c\u6d89\u53ca402\u6b21\u6f0f\u6d1e\u5229\u7528\u4ea4\u6613\uff0c\u8986\u76d68\u4e2aEVM\u94fe\uff0c\u603b\u635f\u5931\u8fbe37.4\u4ebf\u7f8e\u5143\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u9632\u6b62DeFi\u5e73\u53f0\u4e2d\u7684\u6f0f\u6d1e\u5229\u7528\uff0c\u901a\u8fc7\u53bb\u4e2d\u5fc3\u5316\u7684\u94fe\u4e0a\u5b66\u4e60\u673a\u5236\u63d0\u4f9b\u5b89\u5168\u9632\u62a4\u3002"}}
{"id": "2510.15885", "categories": ["cs.AR", "cs.OS"], "pdf": "https://arxiv.org/pdf/2510.15885", "abs": "https://arxiv.org/abs/2510.15885", "authors": ["Dingcui Yu", "Zonghuan Yan", "Jialin Liu", "Yumiao Zhao", "Yanyun Wang", "Xinghui Duan", "Yina Lv", "Liang Shi"], "title": "ConZone+: Practical Zoned Flash Storage Emulation for Consumer Devices", "comment": null, "summary": "To facilitate the understanding and efficient enhancement of software and\nhardware design for consumer-grade zoned flash storage, ConZone is proposed as\nthe first emulator designed to model the resource constraints and architectural\nfeatures typical of such systems. It incorporates essential components commonly\ndeployed in consumer-grade devices, including limited logical to physical\nmapping caches, constrained write buffers, and hybrid flash media management.\nHowever, ConZone cannot be mounted with the file system due to the lack of\nin-place update capability, which is required by the metadata area of F2FS. To\nimprove the usability of the emulator, ConZone+ extends ConZone with support\nfor a block interface. We also provide a script to help the deployment and\nintroduces several enhancements over the original version. Users can explore\nthe internal architecture of consumer-grade zoned flash storage and integrate\ntheir optimizations with system software using ConZone+. We validate the\naccuracy of ConZone+ by comparing a hardware architecture representative of\nconsumer-grade zoned flash storage and comparing it with the state-of-the-art.\nIn addition, we conduct several case studies using ConZone+ to investigate the\ndesign of zoned storage and explore the inadequacies of the current file\nsystem.", "AI": {"tldr": "ConZone+\u662f\u4e00\u4e2a\u9488\u5bf9\u6d88\u8d39\u7ea7\u5206\u533a\u95ea\u5b58\u5b58\u50a8\u7684\u6a21\u62df\u5668\uff0c\u901a\u8fc7\u6dfb\u52a0\u5757\u63a5\u53e3\u652f\u6301\u89e3\u51b3\u4e86\u539f\u7248ConZone\u65e0\u6cd5\u6302\u8f7d\u6587\u4ef6\u7cfb\u7edf\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u90e8\u7f72\u811a\u672c\u548c\u591a\u9879\u589e\u5f3a\u529f\u80fd\uff0c\u5e2e\u52a9\u7528\u6237\u63a2\u7d22\u5b58\u50a8\u67b6\u6784\u5e76\u96c6\u6210\u4f18\u5316\u65b9\u6848\u3002", "motivation": "\u4e3a\u4e86\u4fc3\u8fdb\u5bf9\u6d88\u8d39\u7ea7\u5206\u533a\u95ea\u5b58\u5b58\u50a8\u8f6f\u786c\u4ef6\u8bbe\u8ba1\u7684\u7406\u89e3\u548c\u9ad8\u6548\u6539\u8fdb\uff0c\u9700\u8981\u80fd\u591f\u6a21\u62df\u6b64\u7c7b\u7cfb\u7edf\u8d44\u6e90\u7ea6\u675f\u548c\u67b6\u6784\u7279\u5f81\u7684\u6a21\u62df\u5668\u3002\u539f\u7248ConZone\u7531\u4e8e\u7f3a\u4e4f\u539f\u5730\u66f4\u65b0\u80fd\u529b\u800c\u65e0\u6cd5\u6302\u8f7d\u6587\u4ef6\u7cfb\u7edf\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u7528\u6027\u3002", "method": "ConZone+\u5728\u539f\u7248ConZone\u57fa\u7840\u4e0a\u6269\u5c55\u4e86\u5757\u63a5\u53e3\u652f\u6301\uff0c\u63d0\u4f9b\u4e86\u90e8\u7f72\u811a\u672c\uff0c\u5e76\u5f15\u5165\u4e86\u591a\u9879\u589e\u5f3a\u529f\u80fd\u3002\u901a\u8fc7\u6bd4\u8f83\u4ee3\u8868\u6027\u786c\u4ef6\u67b6\u6784\u548c\u73b0\u6709\u6280\u672f\u6765\u9a8c\u8bc1\u51c6\u786e\u6027\uff0c\u5e76\u8fdb\u884c\u4e86\u591a\u4e2a\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u9a8c\u8bc1\u4e86ConZone+\u7684\u51c6\u786e\u6027\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u63a2\u7d22\u4e86\u5206\u533a\u5b58\u50a8\u8bbe\u8ba1\u548c\u5f53\u524d\u6587\u4ef6\u7cfb\u7edf\u7684\u4e0d\u8db3\u4e4b\u5904\u3002", "conclusion": "ConZone+\u4f5c\u4e3a\u9996\u4e2a\u9488\u5bf9\u6d88\u8d39\u7ea7\u5206\u533a\u95ea\u5b58\u5b58\u50a8\u7684\u6a21\u62df\u5668\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u539f\u7248\u7684\u9650\u5236\uff0c\u4e3a\u63a2\u7d22\u5b58\u50a8\u67b6\u6784\u548c\u96c6\u6210\u7cfb\u7edf\u8f6f\u4ef6\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2510.16890", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.16890", "abs": "https://arxiv.org/abs/2510.16890", "authors": ["Ji\u0159\u00ed Klepl", "Martin Kruli\u0161", "Maty\u00e1\u0161 Brabec"], "title": "Layout-Agnostic MPI Abstraction for Distributed Computing in Modern C++", "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in Recent Advances in the Message Passing Interface (EuroMPI 2025),\n  and is available online at https://doi.org/10.1007/978-3-032-07194-1_3", "summary": "Message Passing Interface (MPI) has been a well-established technology in the\ndomain of distributed high-performance computing for several decades. However,\none of its greatest drawbacks is a rather ancient pure-C interface. It lacks\nmany useful features of modern languages (namely C++), like basic type-checking\nor support for generic code design. In this paper, we propose a novel\nabstraction for MPI, which we implemented as an extension of the C++ Noarr\nlibrary. It follows Noarr paradigms (first-class layout and traversal\nabstraction) and offers layout-agnostic design of MPI applications. We also\nimplemented a layout-agnostic distributed GEMM kernel as a case study to\ndemonstrate the usability and syntax of the proposed abstraction. We show that\nthe abstraction achieves performance comparable to the state-of-the-art MPI C++\nbindings while allowing for a more flexible design of distributed applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eC++ Noarr\u5e93\u7684MPI\u65b0\u62bd\u8c61\uff0c\u5b9e\u73b0\u4e86\u5e03\u5c40\u65e0\u5173\u7684MPI\u5e94\u7528\u8bbe\u8ba1\uff0c\u5e76\u901a\u8fc7\u5206\u5e03\u5f0fGEMM\u5185\u6838\u6848\u4f8b\u5c55\u793a\u4e86\u5176\u53ef\u7528\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfMPI\u7684\u7eafC\u63a5\u53e3\u7f3a\u4e4f\u73b0\u4ee3\u8bed\u8a00\u7279\u6027\uff08\u5982\u7c7b\u578b\u68c0\u67e5\u548c\u6cdb\u578b\u7f16\u7a0b\uff09\uff0c\u9650\u5236\u4e86\u5206\u5e03\u5f0f\u9ad8\u6027\u80fd\u8ba1\u7b97\u7684\u5f00\u53d1\u6548\u7387\u3002", "method": "\u4f5c\u4e3aC++ Noarr\u5e93\u7684\u6269\u5c55\u5b9e\u73b0\uff0c\u9075\u5faaNoarr\u8303\u5f0f\uff08\u4e00\u7b49\u5e03\u5c40\u548c\u904d\u5386\u62bd\u8c61\uff09\uff0c\u63d0\u4f9b\u5e03\u5c40\u65e0\u5173\u7684MPI\u5e94\u7528\u8bbe\u8ba1\u65b9\u6cd5\u3002", "result": "\u8be5\u62bd\u8c61\u5b9e\u73b0\u4e86\u4e0e\u6700\u5148\u8fdbMPI C++\u7ed1\u5b9a\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5141\u8bb8\u66f4\u7075\u6d3b\u7684\u5206\u5e03\u5f0f\u5e94\u7528\u8bbe\u8ba1\u3002", "conclusion": "\u63d0\u51fa\u7684MPI\u62bd\u8c61\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u5e03\u5f0f\u5e94\u7528\u8bbe\u8ba1\u7684\u7075\u6d3b\u6027\u548c\u5f00\u53d1\u6548\u7387\u3002"}}
{"id": "2510.15887", "categories": ["cs.AR", "C.1.0; B.7.1"], "pdf": "https://arxiv.org/pdf/2510.15887", "abs": "https://arxiv.org/abs/2510.15887", "authors": ["Hyun Woo Kang", "Ji Woong Choi"], "title": "basic_RV32s: An Open-Source Microarchitectural Roadmap for RISC-V RV32I", "comment": "2 pages, 3 figures. Accepted to ISOCC 2025 (submitted 14 Jul. 2025;\n  accepted 8 Aug. 2025). To appear in the Proceedings of ISOCC 2025; oral\n  presentation on 17 Oct. 2025 (conference opens 15 Oct 2025). Camera-ready\n  version. Project repository: https://github.com/RISC-KC/basic_rv32s", "summary": "This paper introduces BASIC_RV32s, an open-source framework providing a\npractical microarchitectural roadmap for the RISC-V RV32I architecture,\naddressing the gap between theoretical knowledge and hardware implementation.\nFollowing the classic Patterson and Hennessy methodology, the design evolves\nfrom a basic single-cycle core to a 5-stage pipelined core design with full\nhazard forwarding, dynamic branch prediction, and exception handling. For\nverification, the final core design is integrated into a System-on-Chip (SoC)\nwith Universal Asynchronous Receiver-Transmitter (UART) communication\nimplemented on a Xilinx Artix-7 Field-Programmable Gate Array (FPGA), achieving\n1.09 Dhrystone million instructions per second per megahertz (DMIPS/MHz) at 50\nMHz. By releasing all Register-Transfer Level (RTL) source code, signal-level\nlogic block diagrams, and development logs under MIT license on GitHub,\nBASIC_RV32s offers a reproducible instructional pathway for the open-source\nhardware ecosystem.", "AI": {"tldr": "BASIC_RV32s\u662f\u4e00\u4e2a\u5f00\u6e90\u7684RISC-V RV32I\u67b6\u6784\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u4ece\u5355\u5468\u671f\u6838\u5fc3\u52305\u7ea7\u6d41\u6c34\u7ebf\u8bbe\u8ba1\u7684\u5b8c\u6574\u5b9e\u73b0\u8def\u5f84\uff0c\u5305\u62ec\u5192\u9669\u8f6c\u53d1\u3001\u52a8\u6001\u5206\u652f\u9884\u6d4b\u548c\u5f02\u5e38\u5904\u7406\uff0c\u5e76\u5728FPGA\u4e0a\u9a8c\u8bc1\u4e861.09 DMIPS/MHz\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3RISC-V\u67b6\u6784\u7406\u8bba\u77e5\u8bc6\u4e0e\u786c\u4ef6\u5b9e\u73b0\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u5f00\u6e90\u786c\u4ef6\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u53ef\u590d\u73b0\u7684\u6559\u5b66\u8def\u5f84\u3002", "method": "\u91c7\u7528Patterson\u548cHennessy\u7ecf\u5178\u65b9\u6cd5\u5b66\uff0c\u4ece\u5355\u5468\u671f\u6838\u5fc3\u9010\u6b65\u6f14\u8fdb\u52305\u7ea7\u6d41\u6c34\u7ebf\u8bbe\u8ba1\uff0c\u96c6\u6210\u5230SoC\u4e2d\u5e76\u5728Xilinx Artix-7 FPGA\u4e0a\u5b9e\u73b0\u9a8c\u8bc1\u3002", "result": "\u572850MHz\u9891\u7387\u4e0b\u5b9e\u73b0\u4e861.09 DMIPS/MHz\u7684\u6027\u80fd\uff0c\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684RTL\u6e90\u4ee3\u7801\u3001\u903b\u8f91\u6846\u56fe\u548c\u53d1\u5c55\u65e5\u5fd7\u3002", "conclusion": "BASIC_RV32s\u4e3a\u5f00\u6e90\u786c\u4ef6\u793e\u533a\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5fae\u67b6\u6784\u8def\u7ebf\u56fe\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdbRISC-V\u67b6\u6784\u7684\u6559\u80b2\u548c\u5e94\u7528\u53d1\u5c55\u3002"}}
{"id": "2510.16896", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.16896", "abs": "https://arxiv.org/abs/2510.16896", "authors": ["Yiming Hu"], "title": "FTI-TMR: A Fault Tolerance and Isolation Algorithm for Interconnected Multicore Systems", "comment": null, "summary": "Two-Phase Triple Modular Redundancy TMR divides redundancy operations into\ntwo stages, omitting part of the computation during fault-free operation to\nreduce energy consumption. However, it becomes ineffective under permanent\nfaults, limiting its reliability in critical systems. To address this,\nReactive-TMR (R-TMR) introduces permanent fault isolation mechanisms for faulty\ncores, tolerating both transient and permanent faults. Yet, its reliance on\nadditional hardware increases system complexity and reduces fault tolerance\nwhen multiple cores or auxiliary modules fail. This paper proposes an\nintegrated fault-tolerant architecture for interconnected multicore systems. By\nconstructing a stability metric to identify reliable machines and performing\nperiodic diagnostics, the method enables permanent fault isolation and adaptive\ntask scheduling without extra hardware. Experimental results show that it\nreduces task workload by approximately 30% compared to baseline TMR and\nachieves superior fault coverage and isolation accuracy, significantly\nimproving both reliability and energy efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u4e92\u8fde\u591a\u6838\u7cfb\u7edf\u7684\u96c6\u6210\u5bb9\u9519\u67b6\u6784\uff0c\u901a\u8fc7\u6784\u5efa\u7a33\u5b9a\u6027\u6307\u6807\u8bc6\u522b\u53ef\u9760\u673a\u5668\u5e76\u6267\u884c\u5468\u671f\u6027\u8bca\u65ad\uff0c\u65e0\u9700\u989d\u5916\u786c\u4ef6\u5373\u53ef\u5b9e\u73b0\u6c38\u4e45\u6545\u969c\u9694\u79bb\u548c\u81ea\u9002\u5e94\u4efb\u52a1\u8c03\u5ea6\u3002\u76f8\u6bd4\u57fa\u7ebfTMR\u51cf\u5c11\u7ea630%\u4efb\u52a1\u8d1f\u8f7d\uff0c\u5728\u6545\u969c\u8986\u76d6\u7387\u548c\u9694\u79bb\u7cbe\u5ea6\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u4e24\u9636\u6bb5\u4e09\u6a21\u5197\u4f59TMR\u5728\u6c38\u4e45\u6545\u969c\u4e0b\u5931\u6548\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u53cd\u5e94\u5f0fTMR\u4f9d\u8d56\u989d\u5916\u786c\u4ef6\u5bfc\u81f4\u7cfb\u7edf\u590d\u6742\u6027\u548c\u5bb9\u9519\u80fd\u529b\u4e0b\u964d\u7684\u5c40\u9650\u6027\u3002", "method": "\u6784\u5efa\u7a33\u5b9a\u6027\u6307\u6807\u8bc6\u522b\u53ef\u9760\u673a\u5668\uff0c\u6267\u884c\u5468\u671f\u6027\u8bca\u65ad\uff0c\u5b9e\u73b0\u6c38\u4e45\u6545\u969c\u9694\u79bb\u548c\u81ea\u9002\u5e94\u4efb\u52a1\u8c03\u5ea6\uff0c\u65e0\u9700\u989d\u5916\u786c\u4ef6\u3002", "result": "\u76f8\u6bd4\u57fa\u7ebfTMR\u51cf\u5c11\u7ea630%\u4efb\u52a1\u8d1f\u8f7d\uff0c\u5728\u6545\u969c\u8986\u76d6\u7387\u548c\u9694\u79bb\u7cbe\u5ea6\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u63d0\u9ad8\u53ef\u9760\u6027\u548c\u80fd\u6548\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u96c6\u6210\u5bb9\u9519\u67b6\u6784\u5728\u65e0\u9700\u989d\u5916\u786c\u4ef6\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6c38\u4e45\u6545\u969c\u9694\u79bb\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6838\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u80fd\u6548\u3002"}}
{"id": "2510.16095", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16095", "abs": "https://arxiv.org/abs/2510.16095", "authors": ["Dou Liu", "Ying Long", "Sophia Zuoqiu", "Di Liu", "Kang Li", "Yiting Lin", "Hanyi Liu", "Rong Yin", "Tian Tang"], "title": "Reliability of Large Language Model Generated Clinical Reasoning in Assisted Reproductive Technology: Blinded Comparative Evaluation Study", "comment": null, "summary": "Creating high-quality clinical Chains-of-Thought (CoTs) is crucial for\nexplainable medical Artificial Intelligence (AI) while constrained by data\nscarcity. Although Large Language Models (LLMs) can synthesize medical data,\ntheir clinical reliability remains unverified. This study evaluates the\nreliability of LLM-generated CoTs and investigates prompting strategies to\nenhance their quality. In a blinded comparative study, senior clinicians in\nAssisted Reproductive Technology (ART) evaluated CoTs generated via three\ndistinct strategies: Zero-shot, Random Few-shot (using shallow examples), and\nSelective Few-shot (using diverse, high-quality examples). These expert ratings\nwere compared against evaluations from a state-of-the-art AI model (GPT-4o).\nThe Selective Few-shot strategy significantly outperformed other strategies\nacross all human evaluation metrics (p < .001). Critically, the Random Few-shot\nstrategy offered no significant improvement over the Zero-shot baseline,\ndemonstrating that low-quality examples are as ineffective as no examples. The\nsuccess of the Selective strategy is attributed to two principles:\n\"Gold-Standard Depth\" (reasoning quality) and \"Representative Diversity\"\n(generalization). Notably, the AI evaluator failed to discern these critical\nperformance differences. The clinical reliability of synthetic CoTs is dictated\nby strategic prompt curation, not the mere presence of examples. We propose a\n\"Dual Principles\" framework as a foundational methodology to generate\ntrustworthy data at scale. This work offers a validated solution to the data\nbottleneck and confirms the indispensable role of human expertise in evaluating\nhigh-stakes clinical AI.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4e34\u5e8a\u601d\u7ef4\u94fe\u7684\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u9009\u62e9\u6027\u5c11\u6837\u672c\u63d0\u793a\u7b56\u7565\u663e\u8457\u4f18\u4e8e\u96f6\u6837\u672c\u548c\u968f\u673a\u5c11\u6837\u672c\u7b56\u7565\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\"\u9ec4\u91d1\u6807\u51c6\u6df1\u5ea6\"\u548c\"\u4ee3\u8868\u6027\u591a\u6837\u6027\"\u7684\u53cc\u539f\u5219\u6846\u67b6\u6765\u751f\u6210\u53ef\u4fe1\u7684\u4e34\u5e8a\u6570\u636e\u3002", "motivation": "\u9ad8\u8d28\u91cf\u7684\u4e34\u5e8a\u601d\u7ef4\u94fe\u5bf9\u4e8e\u53ef\u89e3\u91ca\u533b\u7597AI\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u7684\u7ea6\u675f\u3002\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u5408\u6210\u533b\u7597\u6570\u636e\uff0c\u4f46\u5176\u4e34\u5e8a\u53ef\u9760\u6027\u5c1a\u672a\u5f97\u5230\u9a8c\u8bc1\u3002", "method": "\u5728\u8f85\u52a9\u751f\u6b96\u6280\u672f\u9886\u57df\u8fdb\u884c\u76f2\u6cd5\u6bd4\u8f83\u7814\u7a76\uff0c\u8d44\u6df1\u4e34\u5e8a\u533b\u751f\u8bc4\u4f30\u4e09\u79cd\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u751f\u6210\u7684\u601d\u7ef4\u94fe\uff1a\u96f6\u6837\u672c\u3001\u968f\u673a\u5c11\u6837\u672c\uff08\u4f7f\u7528\u6d45\u5c42\u793a\u4f8b\uff09\u548c\u9009\u62e9\u6027\u5c11\u6837\u672c\uff08\u4f7f\u7528\u591a\u6837\u5316\u9ad8\u8d28\u91cf\u793a\u4f8b\uff09\uff0c\u5e76\u4e0eGPT-4o\u7684\u8bc4\u4f30\u7ed3\u679c\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u9009\u62e9\u6027\u5c11\u6837\u672c\u7b56\u7565\u5728\u6240\u6709\u4eba\u7c7b\u8bc4\u4f30\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u7b56\u7565\uff08p < .001\uff09\u3002\u968f\u673a\u5c11\u6837\u672c\u7b56\u7565\u76f8\u6bd4\u96f6\u6837\u672c\u57fa\u7ebf\u6ca1\u6709\u663e\u8457\u6539\u8fdb\uff0c\u8868\u660e\u4f4e\u8d28\u91cf\u793a\u4f8b\u4e0e\u65e0\u793a\u4f8b\u540c\u6837\u65e0\u6548\u3002AI\u8bc4\u4f30\u5668\u672a\u80fd\u8bc6\u522b\u8fd9\u4e9b\u5173\u952e\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "\u5408\u6210\u601d\u7ef4\u94fe\u7684\u4e34\u5e8a\u53ef\u9760\u6027\u53d6\u51b3\u4e8e\u6218\u7565\u6027\u7684\u63d0\u793a\u7b56\u5212\uff0c\u800c\u975e\u4ec5\u4ec5\u793a\u4f8b\u7684\u5b58\u5728\u3002\u63d0\u51fa\u7684\"\u53cc\u539f\u5219\"\u6846\u67b6\u4e3a\u5927\u89c4\u6a21\u751f\u6210\u53ef\u4fe1\u6570\u636e\u63d0\u4f9b\u4e86\u57fa\u7840\u65b9\u6cd5\uff0c\u786e\u8ba4\u4e86\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u5728\u8bc4\u4f30\u9ad8\u98ce\u9669\u4e34\u5e8aAI\u4e2d\u4e0d\u53ef\u6216\u7f3a\u7684\u4f5c\u7528\u3002"}}
{"id": "2510.15888", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.15888", "abs": "https://arxiv.org/abs/2510.15888", "authors": ["Konstantinos Kafousis"], "title": "Limited Read-Write/Set Hardware Transactional Memory without modifying the ISA or the Coherence Protocol", "comment": null, "summary": "Hardware Transactional Memory (HTM) allows lock-free programming as easy as\nwith traditional coarse-grain locks or similar, while benefiting from the\nperformance advantages of fine-grained locking. Many HTM implementations have\nbeen proposed, but they have not received widespread adoption because of their\nhigh hardware complexity, their need for additions to the Instruction Set\nArchitecture (ISA), and often for modifications to the cache coherence\nprotocol.\n  We show that HTM can be implemented without adding new instructions -- merely\nby extending the semantics of two existing, Load-Linked and Store-Conditional.\nAlso, our proposed design does not modify or extend standard coherence\nprotocols. We further propose to drastically simplify the implementation of HTM\n-- confined to modifications in the L1 Data Cache only -- by restricting it to\napplications where the write set plus the read set of each transaction do not\nexceed a small number of cache lines. We also propose two alternative\nmechanisms to guarantee forward progress, both based on detecting retrial\nattempts.\n  We simulated our proposed design in Gem5, and we used it to implement several\npopular concurrent data structures, showing that a maximum of eight (8) words\n(cache lines) suffice for the write plus read sets. We provide a detailed\nexplanation of selected implementations, clarifying the intended usage of our\nHTM from a programmer's perspective. We evaluated our HTM under varying\ncontention levels to explore its scalability limits. The results indicate that\nour HTM provides good performance in concurrent data structures when contention\nis spread across multiple nodes: in such cases, the percentage of aborts\nrelative to successful commits is very low. In the atomic fetch-and-increment\nbenchmark for multiple shared counters, the results show that, under\nlow-congestion, our HTM improves performance relative to the TTS lock.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5316\u7684\u786c\u4ef6\u4e8b\u52a1\u5185\u5b58\u5b9e\u73b0\uff0c\u4ec5\u901a\u8fc7\u6269\u5c55Load-Linked\u548cStore-Conditional\u6307\u4ee4\u8bed\u4e49\uff0c\u65e0\u9700\u4fee\u6539\u7f13\u5b58\u4e00\u81f4\u6027\u534f\u8bae\uff0c\u5e76\u5c06\u4e8b\u52a1\u8bfb\u5199\u96c6\u9650\u5236\u5728\u5c11\u91cf\u7f13\u5b58\u884c\u5185\u3002", "motivation": "\u73b0\u6709HTM\u5b9e\u73b0\u786c\u4ef6\u590d\u6742\u5ea6\u9ad8\u3001\u9700\u8981ISA\u6269\u5c55\u548c\u7f13\u5b58\u534f\u8bae\u4fee\u6539\uff0c\u5bfc\u81f4\u91c7\u7528\u7387\u4f4e\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7b80\u5316\u8bbe\u8ba1\u964d\u4f4e\u5b9e\u73b0\u590d\u6742\u6027\u3002", "method": "\u57fa\u4e8e\u73b0\u6709LL/SC\u6307\u4ee4\u6269\u5c55\u8bed\u4e49\uff0c\u4ec5\u9700\u4fee\u6539L1\u6570\u636e\u7f13\u5b58\uff0c\u9650\u5236\u4e8b\u52a1\u8bfb\u5199\u96c6\u4e0d\u8d85\u8fc78\u4e2a\u7f13\u5b58\u884c\uff0c\u63d0\u4f9b\u4e24\u79cd\u57fa\u4e8e\u91cd\u8bd5\u68c0\u6d4b\u7684\u524d\u5411\u8fdb\u5ea6\u4fdd\u8bc1\u673a\u5236\u3002", "result": "\u5728Gem5\u4e2d\u6a21\u62df\u9a8c\u8bc1\uff0c\u5e76\u53d1\u6570\u636e\u7ed3\u6784\u4e2d\u8bfb\u5199\u96c6\u6700\u591a8\u4e2a\u7f13\u5b58\u884c\u5373\u53ef\u6ee1\u8db3\u9700\u6c42\uff0c\u5728\u4f4e\u4e89\u7528\u60c5\u51b5\u4e0b\u6027\u80fd\u4f18\u4e8eTTS\u9501\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b80\u5316HTM\u8bbe\u8ba1\u5728\u4fdd\u6301\u826f\u597d\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5b9e\u73b0\u590d\u6742\u5ea6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4e89\u7528\u5206\u6563\u7684\u5e76\u53d1\u573a\u666f\u3002"}}
{"id": "2510.16933", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16933", "abs": "https://arxiv.org/abs/2510.16933", "authors": ["Maty\u00e1\u0161 Brabec", "Ji\u0159\u00ed Klepl", "Michal T\u00f6pfer", "Martin Kruli\u0161"], "title": "Tutoring LLM into a Better CUDA Optimizer", "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in Euro-Par 2025: Parallel Processing, Part II, and is available\n  online at https://doi.org/10.1007/978-3-031-99857-7_18", "summary": "Recent leaps in large language models (LLMs) caused a revolution in\nprogramming tools (like GitHub Copilot) that can help with code generation,\ndebugging, and even performance optimization. In this paper, we focus on the\ncapabilities of the most recent reasoning models to generate optimized CUDA\ncode for predefined, well-known tasks. Our objective is to determine which\ntypes of code optimizations and parallel patterns the LLMs can perform by\nthemselves and whether they can be improved by tutoring (providing more\ndetailed hints and guidelines in the prompt). The generated solutions were\nevaluated both automatically (for correctness and speedup) and manually (code\nreviews) to provide a more detailed perspective. We also tried an interactive\napproach where the LLM can fix its previous mistakes within a session. The\nresults indicate that LLMs are quite skilled coders; however, they require\ntutoring to reach optimized solutions provided by parallel computing experts.", "AI": {"tldr": "\u8bc4\u4f30\u6700\u65b0\u63a8\u7406\u6a21\u578b\u5728\u751f\u6210\u4f18\u5316CUDA\u4ee3\u7801\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7814\u7a76LLMs\u80fd\u5426\u72ec\u7acb\u8fdb\u884c\u4ee3\u7801\u4f18\u5316\u4ee5\u53ca\u901a\u8fc7\u63d0\u793a\u6307\u5bfc\u662f\u5426\u80fd\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u7f16\u7a0b\u5de5\u5177\uff08\u5982GitHub Copilot\uff09\u5728\u4ee3\u7801\u751f\u6210\u3001\u8c03\u8bd5\u548c\u6027\u80fd\u4f18\u5316\u65b9\u9762\u5e26\u6765\u4e86\u9769\u547d\u6027\u53d8\u5316\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLMs\u5728CUDA\u4ee3\u7801\u4f18\u5316\u65b9\u9762\u7684\u5177\u4f53\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u81ea\u52a8\u8bc4\u4f30\uff08\u6b63\u786e\u6027\u548c\u52a0\u901f\u6bd4\uff09\u548c\u624b\u52a8\u8bc4\u4f30\uff08\u4ee3\u7801\u5ba1\u67e5\uff09\u6765\u8bc4\u4f30\u751f\u6210\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5c1d\u8bd5\u4ea4\u4e92\u5f0f\u65b9\u6cd5\u8ba9LLM\u5728\u4f1a\u8bdd\u4e2d\u4fee\u590d\u4e4b\u524d\u7684\u9519\u8bef\u3002", "result": "\u7ed3\u679c\u8868\u660eLLMs\u662f\u76f8\u5f53\u719f\u7ec3\u7684\u7f16\u7801\u8005\uff0c\u4f46\u8981\u8fbe\u5230\u5e76\u884c\u8ba1\u7b97\u4e13\u5bb6\u63d0\u4f9b\u7684\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u6c34\u5e73\uff0c\u9700\u8981\u63d0\u4f9b\u6307\u5bfc\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u9700\u8981\u8be6\u7ec6\u7684\u63d0\u793a\u548c\u6307\u5bfc\u624d\u80fd\u751f\u6210\u9ad8\u5ea6\u4f18\u5316\u7684\u5e76\u884c\u4ee3\u7801\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.16037", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16037", "abs": "https://arxiv.org/abs/2510.16037", "authors": ["Peini Cheng", "Amir Bahmani"], "title": "Membership Inference over Diffusion-models-based Synthetic Tabular Data", "comment": null, "summary": "This study investigates the privacy risks associated with diffusion-based\nsynthetic tabular data generation methods, focusing on their susceptibility to\nMembership Inference Attacks (MIAs). We examine two recent models, TabDDPM and\nTabSyn, by developing query-based MIAs based on the step-wise error comparison\nmethod. Our findings reveal that TabDDPM is more vulnerable to these attacks.\nTabSyn exhibits resilience against our attack models. Our work underscores the\nimportance of evaluating the privacy implications of diffusion models and\nencourages further research into robust privacy-preserving mechanisms for\nsynthetic data generation.", "AI": {"tldr": "\u672c\u7814\u7a76\u8c03\u67e5\u4e86\u57fa\u4e8e\u6269\u6563\u7684\u5408\u6210\u8868\u683c\u6570\u636e\u751f\u6210\u65b9\u6cd5\u7684\u9690\u79c1\u98ce\u9669\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u5bf9\u6210\u5458\u63a8\u65ad\u653b\u51fb\u7684\u6613\u611f\u6027\u3002\u7814\u7a76\u53d1\u73b0TabDDPM\u6bd4TabSyn\u66f4\u5bb9\u6613\u53d7\u5230\u653b\u51fb\u3002", "motivation": "\u8bc4\u4f30\u6269\u6563\u6a21\u578b\u5728\u5408\u6210\u8868\u683c\u6570\u636e\u751f\u6210\u4e2d\u7684\u9690\u79c1\u5f71\u54cd\uff0c\u4e86\u89e3\u4e0d\u540c\u6a21\u578b\u5bf9\u6210\u5458\u63a8\u65ad\u653b\u51fb\u7684\u8106\u5f31\u6027\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u9010\u6b65\u8bef\u5dee\u6bd4\u8f83\u65b9\u6cd5\u7684\u67e5\u8be2\u5f0f\u6210\u5458\u63a8\u65ad\u653b\u51fb\uff0c\u5bf9TabDDPM\u548cTabSyn\u4e24\u79cd\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "TabDDPM\u66f4\u5bb9\u6613\u53d7\u5230\u6210\u5458\u63a8\u65ad\u653b\u51fb\uff0c\u800cTabSyn\u5bf9\u8fd9\u4e9b\u653b\u51fb\u8868\u73b0\u51fa\u97e7\u6027\u3002", "conclusion": "\u6269\u6563\u6a21\u578b\u7684\u9690\u79c1\u5f71\u54cd\u9700\u8981\u8ba4\u771f\u8bc4\u4f30\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u7528\u4e8e\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u5f3a\u5927\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u3002"}}
{"id": "2510.15893", "categories": ["cs.AR", "cs.AI", "cs.DC", "cs.LG", "68M10, 68M14", "B.4.3; C.2.4; C.4; I.2"], "pdf": "https://arxiv.org/pdf/2510.15893", "abs": "https://arxiv.org/abs/2510.15893", "authors": ["Mikhail Bernadskiy", "Peter Carson", "Thomas Graham", "Taylor Groves", "Ho John Lee", "Eric Yeh"], "title": "Accelerating Frontier MoE Training with 3D Integrated Optics", "comment": "12 pages, 11 figures. To be published in Hot Interconnects 2025", "summary": "The unabated growth in AI workload demands is driving the need for concerted\nadvances in compute, memory, and interconnect performance. As traditional\nsemiconductor scaling slows, high-speed interconnects have emerged as the new\nscaling engine, enabling the creation of larger logical GPUs by linking many\nGPUs into a single, low-latency, high-bandwidth compute domain. While initial\nscale-up fabrics leveraged copper interconnects for their power and cost\nadvantages, the maximum reach of passive electrical interconnects\n(approximately 1 meter) effectively limits the scale-up domain to within a\nsingle rack. The advent of 3D-stacked optics and logic offers a transformative,\npower-efficient scale-up solution for connecting hundreds of GPU packages\n(thousands of GPUs) across multiple data center racks. This work explores the\ndesign tradeoffs of scale-up technologies and demonstrates how frontier LLMs\nnecessitate novel photonic solutions to achieve aggressive power and\nperformance targets. We model the benefits of 3D CPO (Passage) enabled GPUs and\nswitches within the scale-up domain when training Frontier Mixture of Experts\n(MoE) models exceeding one trillion parameters. Our results show that the\nsubstantial increases in bandwidth and radix enabled by 3D CPO allow for an 8X\nincrease in scale-up capability. This affords new opportunities for\nmulti-dimensional parallelism within the scale-up domain and results in a 2.7X\nreduction in time-to-train, unlocking unprecedented model scaling.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e863D\u5171\u5c01\u88c5\u5149\u5b66\u6280\u672f\u5982\u4f55\u89e3\u51b3AI\u5de5\u4f5c\u8d1f\u8f7d\u589e\u957f\u4e2d\u7684\u4e92\u8fde\u74f6\u9888\uff0c\u901a\u8fc7\u5149\u4e92\u8fde\u6280\u672f\u5b9e\u73b0\u8de8\u673a\u67b6GPU\u96c6\u7fa4\u7684\u6269\u5c55\uff0c\u4ece\u800c\u652f\u6301\u4e07\u4ebf\u53c2\u6570MoE\u6a21\u578b\u7684\u8bad\u7ec3\u3002", "motivation": "\u968f\u7740AI\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6301\u7eed\u589e\u957f\uff0c\u4f20\u7edf\u534a\u5bfc\u4f53\u7f29\u653e\u653e\u7f13\uff0c\u9ad8\u901f\u4e92\u8fde\u6210\u4e3a\u65b0\u7684\u6269\u5c55\u5f15\u64ce\u3002\u94dc\u4e92\u8fde\u7684\u6700\u5927\u4f20\u8f93\u8ddd\u79bb\u9650\u5236\uff08\u7ea61\u7c73\uff09\u4f7f\u5f97\u6269\u5c55\u57df\u4ec5\u9650\u4e8e\u5355\u4e2a\u673a\u67b6\u5185\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u6765\u8fde\u63a5\u8de8\u591a\u4e2a\u6570\u636e\u4e2d\u5fc3\u673a\u67b6\u7684GPU\u3002", "method": "\u91c7\u75283D\u5806\u53e0\u5149\u5b66\u548c\u903b\u8f91\u6280\u672f\uff0c\u5f00\u53d1\u4e863D CPO\uff08\u5171\u5c01\u88c5\u5149\u5b66\uff09\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5149\u4e92\u8fde\u5b9e\u73b0GPU\u5305\u548c\u4ea4\u6362\u673a\u4e4b\u95f4\u7684\u9ad8\u901f\u8fde\u63a5\uff0c\u5efa\u6a21\u5206\u6790\u4e86\u5728\u6269\u5c55\u57df\u5185\u8bad\u7ec3\u8d85\u8fc7\u4e07\u4ebf\u53c2\u6570\u7684MoE\u6a21\u578b\u65f6\u7684\u6027\u80fd\u8868\u73b0\u3002", "result": "3D CPO\u6280\u672f\u5b9e\u73b0\u4e86\u5e26\u5bbd\u548c\u57fa\u6570\u7684\u663e\u8457\u63d0\u5347\uff0c\u4f7f\u6269\u5c55\u80fd\u529b\u589e\u52a08\u500d\uff0c\u4e3a\u6269\u5c55\u57df\u5185\u7684\u591a\u7ef4\u5e76\u884c\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\uff0c\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u4e862.7\u500d\uff0c\u5b9e\u73b0\u4e86\u524d\u6240\u672a\u6709\u7684\u6a21\u578b\u6269\u5c55\u3002", "conclusion": "3D\u5171\u5c01\u88c5\u5149\u5b66\u6280\u672f\u662f\u89e3\u51b3AI\u5de5\u4f5c\u8d1f\u8f7d\u6269\u5c55\u74f6\u9888\u7684\u5173\u952e\u521b\u65b0\uff0c\u901a\u8fc7\u5149\u4e92\u8fde\u6280\u672f\u7a81\u7834\u4e86\u4f20\u7edf\u7535\u6c14\u4e92\u8fde\u7684\u8ddd\u79bb\u9650\u5236\uff0c\u4e3a\u5927\u89c4\u6a21AI\u6a21\u578b\u7684\u8bad\u7ec3\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.16946", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.16946", "abs": "https://arxiv.org/abs/2510.16946", "authors": ["Erfan Darzi", "Aldo Pareja", "Shreeanant Bharadwaj"], "title": "Host-Side Telemetry for Performance Diagnosis in Cloud and HPC GPU Infrastructure", "comment": null, "summary": "Diagnosing GPU tail latency spikes in cloud and HPC infrastructure is\ncritical for maintaining performance predictability and resource utilization,\nyet existing monitoring tools lack the granularity for root cause analysis in\nshared computing environments. We introduce an eBPF-based telemetry system that\nprovides unified host-side monitoring of GPU workloads, correlating\neBPF-derived host metrics with GPU-internal events for holistic system\nobservability. The system achieves 81--88\\% diagnostic accuracy, detects spikes\nwithin 5 seconds, and completes root cause analysis in 6--8 seconds, operating\nwith 1.21\\% CPU overhead at 100Hz sampling. Evaluated on distributed learning\nworkloads, the system identifies root causes including NIC contention, PCIe\npressure, and CPU interference, enabling operational debugging for multi-tenant\nGPU infrastructure without requiring cluster-wide instrumentation.", "AI": {"tldr": "\u57fa\u4e8eeBPF\u7684GPU\u5c3e\u5ef6\u8fdf\u76d1\u63a7\u7cfb\u7edf\uff0c\u901a\u8fc7\u5173\u8054\u4e3b\u673a\u6307\u6807\u4e0eGPU\u5185\u90e8\u4e8b\u4ef6\uff0c\u5b9e\u73b0\u5171\u4eab\u8ba1\u7b97\u73af\u5883\u4e2dGPU\u5c3e\u5ef6\u8fdf\u5c16\u5cf0\u7684\u8bca\u65ad\u548c\u6839\u56e0\u5206\u6790\u3002", "motivation": "\u5728\u4e91\u548cHPC\u57fa\u7840\u8bbe\u65bd\u4e2d\u8bca\u65adGPU\u5c3e\u5ef6\u8fdf\u5c16\u5cf0\u5bf9\u4fdd\u6301\u6027\u80fd\u53ef\u9884\u6d4b\u6027\u548c\u8d44\u6e90\u5229\u7528\u7387\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u76d1\u63a7\u5de5\u5177\u5728\u5171\u4eab\u8ba1\u7b97\u73af\u5883\u4e2d\u7f3a\u4e4f\u6839\u56e0\u5206\u6790\u6240\u9700\u7684\u7c92\u5ea6\u3002", "method": "\u5f15\u5165\u57fa\u4e8eeBPF\u7684\u9065\u6d4b\u7cfb\u7edf\uff0c\u63d0\u4f9bGPU\u5de5\u4f5c\u8d1f\u8f7d\u7684\u7edf\u4e00\u4e3b\u673a\u7aef\u76d1\u63a7\uff0c\u5c06eBPF\u884d\u751f\u7684\u4e3b\u673a\u6307\u6807\u4e0eGPU\u5185\u90e8\u4e8b\u4ef6\u5173\u8054\uff0c\u5b9e\u73b0\u6574\u4f53\u7cfb\u7edf\u53ef\u89c2\u6d4b\u6027\u3002", "result": "\u7cfb\u7edf\u8fbe\u523081-88%\u7684\u8bca\u65ad\u51c6\u786e\u7387\uff0c\u57285\u79d2\u5185\u68c0\u6d4b\u5230\u5c16\u5cf0\uff0c6-8\u79d2\u5185\u5b8c\u6210\u6839\u56e0\u5206\u6790\uff0c\u5728100Hz\u91c7\u6837\u4e0b\u4ec5\u4ea7\u751f1.21%\u7684CPU\u5f00\u9500\u3002\u5728\u5206\u5e03\u5f0f\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u8bc4\u4f30\u4e2d\uff0c\u8bc6\u522b\u51faNIC\u4e89\u7528\u3001PCIe\u538b\u529b\u548cCPU\u5e72\u6270\u7b49\u6839\u56e0\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u80fd\u591f\u4e3a\u591a\u79df\u6237GPU\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u64cd\u4f5c\u8c03\u8bd5\u80fd\u529b\uff0c\u65e0\u9700\u96c6\u7fa4\u8303\u56f4\u63d2\u88c5\u3002"}}
{"id": "2510.16194", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16194", "abs": "https://arxiv.org/abs/2510.16194", "authors": ["Guanchen Wu", "Zuhui Chen", "Yuzhang Xie", "Carl Yang"], "title": "Towards Automatic Evaluation and Selection of PHI De-identification Models via Multi-Agent Collaboration", "comment": "Agents4Science 2025 (Spotlight)", "summary": "Protected health information (PHI) de-identification is critical for enabling\nthe safe reuse of clinical notes, yet evaluating and comparing PHI\nde-identification models typically depends on costly, small-scale expert\nannotations. We present TEAM-PHI, a multi-agent evaluation and selection\nframework that uses large language models (LLMs) to automatically measure\nde-identification quality and select the best-performing model without heavy\nreliance on gold labels. TEAM-PHI deploys multiple Evaluation Agents, each\nindependently judging the correctness of PHI extractions and outputting\nstructured metrics. Their results are then consolidated through an LLM-based\nmajority voting mechanism that integrates diverse evaluator perspectives into a\nsingle, stable, and reproducible ranking. Experiments on a real-world clinical\nnote corpus demonstrate that TEAM-PHI produces consistent and accurate\nrankings: despite variation across individual evaluators, LLM-based voting\nreliably converges on the same top-performing systems. Further comparison with\nground-truth annotations and human evaluation confirms that the framework's\nautomated rankings closely match supervised evaluation. By combining\nindependent evaluation agents with LLM majority voting, TEAM-PHI offers a\npractical, secure, and cost-effective solution for automatic evaluation and\nbest-model selection in PHI de-identification, even when ground-truth labels\nare limited.", "AI": {"tldr": "TEAM-PHI\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u8bc4\u4f30PHI\u53bb\u6807\u8bc6\u5316\u6a21\u578b\u6027\u80fd\u5e76\u9009\u62e9\u6700\u4f73\u6a21\u578b\uff0c\u65e0\u9700\u4f9d\u8d56\u6602\u8d35\u7684\u4e13\u5bb6\u6807\u6ce8\u3002", "motivation": "PHI\u53bb\u6807\u8bc6\u5316\u5bf9\u4e8e\u5b89\u5168\u91cd\u7528\u4e34\u5e8a\u8bb0\u5f55\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u8bc4\u4f30\u4f9d\u8d56\u6210\u672c\u9ad8\u6602\u7684\u5c0f\u89c4\u6a21\u4e13\u5bb6\u6807\u6ce8\uff0c\u9650\u5236\u4e86\u6a21\u578b\u6bd4\u8f83\u548c\u9009\u62e9\u3002", "method": "\u90e8\u7f72\u591a\u4e2a\u8bc4\u4f30\u667a\u80fd\u4f53\u72ec\u7acb\u5224\u65adPHI\u63d0\u53d6\u6b63\u786e\u6027\uff0c\u901a\u8fc7\u57fa\u4e8eLLM\u7684\u591a\u6570\u6295\u7968\u673a\u5236\u6574\u5408\u7ed3\u679c\uff0c\u751f\u6210\u7a33\u5b9a\u53ef\u590d\u73b0\u7684\u6a21\u578b\u6392\u540d\u3002", "result": "\u5728\u771f\u5b9e\u4e34\u5e8a\u8bb0\u5f55\u8bed\u6599\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTEAM-PHI\u80fd\u4ea7\u751f\u4e00\u81f4\u51c6\u786e\u7684\u6392\u540d\uff0c\u5c3d\u7ba1\u4e2a\u4f53\u8bc4\u4f30\u8005\u5b58\u5728\u5dee\u5f02\uff0c\u4f46LLM\u6295\u7968\u80fd\u53ef\u9760\u6536\u655b\u5230\u76f8\u540c\u7684\u6700\u4f73\u7cfb\u7edf\u3002", "conclusion": "TEAM-PHI\u901a\u8fc7\u7ed3\u5408\u72ec\u7acb\u8bc4\u4f30\u667a\u80fd\u4f53\u548cLLM\u591a\u6570\u6295\u7968\uff0c\u4e3aPHI\u53bb\u6807\u8bc6\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u3001\u5b89\u5168\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u81ea\u52a8\u8bc4\u4f30\u548c\u6700\u4f73\u6a21\u578b\u9009\u62e9\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.15897", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.15897", "abs": "https://arxiv.org/abs/2510.15897", "authors": ["Kien Le Trung", "Truong-Son Hy"], "title": "DiffPlace: A Conditional Diffusion Framework for Simultaneous VLSI Placement Beyond Sequential Paradigms", "comment": null, "summary": "Chip placement, the task of determining optimal positions of circuit modules\non a chip canvas, is a critical step in the VLSI design flow that directly\nimpacts performance, power consumption, and routability. Traditional methods\nrely on analytical optimization or reinforcement learning, which struggle with\nhard placement constraints or require expensive online training for each new\ncircuit design. To address these limitations, we introduce DiffPlace, a\nframework that formulates chip placement as a conditional denoising diffusion\nprocess, enabling transferable placement policies that generalize to unseen\ncircuit netlists without retraining. DiffPlace leverages the generative\ncapabilities of diffusion models to efficiently explore the vast space of\nplacement while conditioning on circuit connectivity and relative quality\nmetrics to identify optimal solutions globally. Our approach combines\nenergy-guided sampling with constrained manifold diffusion to ensure placement\nlegality, achieving extremely low overlap across all experimental scenarios.\nOur method bridges the gap between optimization-based and learning-based\napproaches, offering a practical path toward automated, high-quality chip\nplacement for modern VLSI design. Our source code is publicly available at:\nhttps://github.com/HySonLab/DiffPlace/", "AI": {"tldr": "DiffPlace\u662f\u4e00\u4e2a\u57fa\u4e8e\u6761\u4ef6\u53bb\u566a\u6269\u6563\u8fc7\u7a0b\u7684\u82af\u7247\u5e03\u5c40\u6846\u67b6\uff0c\u80fd\u591f\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u7535\u8def\u7f51\u8868\uff0c\u5b9e\u73b0\u53ef\u8fc1\u79fb\u7684\u5e03\u5c40\u7b56\u7565\u3002", "motivation": "\u4f20\u7edf\u82af\u7247\u5e03\u5c40\u65b9\u6cd5\u4f9d\u8d56\u5206\u6790\u4f18\u5316\u6216\u5f3a\u5316\u5b66\u4e60\uff0c\u96be\u4ee5\u5904\u7406\u786c\u6027\u5e03\u5c40\u7ea6\u675f\u6216\u9700\u8981\u4e3a\u6bcf\u4e2a\u65b0\u7535\u8def\u8bbe\u8ba1\u8fdb\u884c\u6602\u8d35\u7684\u5728\u7ebf\u8bad\u7ec3\u3002DiffPlace\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u5f25\u5408\u57fa\u4e8e\u4f18\u5316\u548c\u57fa\u4e8e\u5b66\u4e60\u65b9\u6cd5\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u5c06\u82af\u7247\u5e03\u5c40\u5236\u5b9a\u4e3a\u6761\u4ef6\u53bb\u566a\u6269\u6563\u8fc7\u7a0b\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u80fd\u529b\u5728\u5e7f\u9614\u7684\u5e03\u5c40\u7a7a\u95f4\u4e2d\u9ad8\u6548\u63a2\u7d22\uff0c\u540c\u65f6\u57fa\u4e8e\u7535\u8def\u8fde\u63a5\u6027\u548c\u76f8\u5bf9\u8d28\u91cf\u6307\u6807\u6765\u8bc6\u522b\u5168\u5c40\u6700\u4f18\u89e3\u3002\u7ed3\u5408\u80fd\u91cf\u5f15\u5bfc\u91c7\u6837\u548c\u7ea6\u675f\u6d41\u5f62\u6269\u6563\u6765\u786e\u4fdd\u5e03\u5c40\u5408\u6cd5\u6027\u3002", "result": "\u5728\u6240\u6709\u5b9e\u9a8c\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u6781\u4f4e\u7684\u91cd\u53e0\u7387\uff0c\u4e3a\u73b0\u4ee3VLSI\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u7684\u9ad8\u8d28\u91cf\u82af\u7247\u5e03\u5c40\u5b9e\u7528\u8def\u5f84\u3002", "conclusion": "DiffPlace\u6846\u67b6\u901a\u8fc7\u6761\u4ef6\u6269\u6563\u6a21\u578b\u6210\u529f\u89e3\u51b3\u4e86\u82af\u7247\u5e03\u5c40\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u53ef\u8fc1\u79fb\u7684\u5e03\u5c40\u7b56\u7565\uff0c\u4e3aVLSI\u8bbe\u8ba1\u81ea\u52a8\u5316\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2510.17158", "categories": ["cs.DC", "cs.PF", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.17158", "abs": "https://arxiv.org/abs/2510.17158", "authors": ["Daniel Nichols", "Konstantinos Parasyris", "Charles Jekel", "Abhinav Bhatele", "Harshitha Menon"], "title": "Integrating Performance Tools in Model Reasoning for GPU Kernel Optimization", "comment": null, "summary": "Language models are now prevalent in software engineering with many\ndevelopers using them to automate tasks and accelerate their development. While\nlanguage models have been tremendous at accomplishing complex software\nengineering tasks, there are still many areas where they fail to deliver\ndesirable results, for instance code performance related tasks. Tasks like\noptimization depend on many complex data from the environment, hardware, etc.\nthat are not directly represented in source code. Recent efforts have seen\nlarge improvements in general code modeling tasks using chain-of-thought style\nreasoning, but these models still fail to comprehend how the environment\ninteracts with code performance. In this paper we propose a methodology to\ntrain language models that can interact with performance tools during their\nreasoning process. We then demonstrate how this methodology can be used to\ntrain a state-of-the-art GPU kernel optimization model.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4e0e\u6027\u80fd\u5de5\u5177\u4ea4\u4e92\uff0c\u4ece\u800c\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u6027\u80fd\u4f18\u5316\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5728\u4ee3\u7801\u6027\u80fd\u76f8\u5173\u4efb\u52a1\uff08\u5982\u4f18\u5316\uff09\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u4efb\u52a1\u4f9d\u8d56\u4e8e\u73af\u5883\u3001\u786c\u4ef6\u7b49\u590d\u6742\u6570\u636e\uff0c\u800c\u8fd9\u4e9b\u4fe1\u606f\u5e76\u672a\u76f4\u63a5\u4f53\u73b0\u5728\u6e90\u4ee3\u7801\u4e2d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u4f7f\u5176\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u80fd\u591f\u4e0e\u6027\u80fd\u5de5\u5177\u8fdb\u884c\u4ea4\u4e92\uff0c\u4ece\u800c\u66f4\u597d\u5730\u7406\u89e3\u4ee3\u7801\u4e0e\u73af\u5883\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u8be5\u65b9\u6cd5\u88ab\u7528\u4e8e\u8bad\u7ec3\u4e00\u4e2a\u6700\u5148\u8fdb\u7684GPU\u5185\u6838\u4f18\u5316\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u8ba9\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4e0e\u6027\u80fd\u5de5\u5177\u4ea4\u4e92\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5176\u5728\u4ee3\u7801\u6027\u80fd\u4f18\u5316\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u7406\u89e3\u73af\u5883\u4e0e\u4ee3\u7801\u4ea4\u4e92\u7684\u590d\u6742\u573a\u666f\u4e2d\u3002"}}
{"id": "2510.16206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16206", "abs": "https://arxiv.org/abs/2510.16206", "authors": ["Alex Zhavoronkov", "Dominika Wilczok", "Roman Yampolskiy"], "title": "The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI", "comment": null, "summary": "Since the rapid expansion of large language models (LLMs), people have begun\nto rely on them for information retrieval. While traditional search engines\ndisplay ranked lists of sources shaped by search engine optimization (SEO),\nadvertising, and personalization, LLMs typically provide a synthesized response\nthat feels singular and authoritative. While both approaches carry risks of\nbias and omission, LLMs may amplify the effect by collapsing multiple\nperspectives into one answer, reducing users ability or inclination to compare\nalternatives. This concentrates power over information in a few LLM vendors\nwhose systems effectively shape what is remembered and what is overlooked. As a\nresult, certain narratives, individuals or groups, may be disproportionately\nsuppressed, while others are disproportionately elevated. Over time, this\ncreates a new threat: the gradual erasure of those with limited digital\npresence, and the amplification of those already prominent, reshaping\ncollective memory.To address these concerns, this paper presents a concept of\nthe Right To Be Remembered (RTBR) which encompasses minimizing the risk of\nAI-driven information omission, embracing the right of fair treatment, while\nensuring that the generated content would be maximally truthful.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\"\u88ab\u8bb0\u4f4f\u6743\"\u6982\u5ff5\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u901a\u8fc7\u5408\u6210\u5355\u4e00\u6743\u5a01\u6027\u56de\u7b54\u800c\u538b\u5236\u67d0\u4e9b\u89c2\u70b9\u3001\u653e\u5927\u5df2\u6709\u504f\u89c1\uff0c\u4ece\u800c\u91cd\u5851\u96c6\u4f53\u8bb0\u5fc6\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4fe1\u606f\u68c0\u7d22\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u63d0\u4f9b\u7684\u5408\u6210\u56de\u7b54\u53ef\u80fd\u5c06\u591a\u79cd\u89c2\u70b9\u538b\u7f29\u4e3a\u5355\u4e00\u7b54\u6848\uff0c\u51cf\u5c11\u4e86\u7528\u6237\u6bd4\u8f83\u66ff\u4ee3\u65b9\u6848\u7684\u80fd\u529b\u548c\u610f\u613f\uff0c\u5bfc\u81f4\u67d0\u4e9b\u53d9\u4e8b\u3001\u4e2a\u4f53\u6216\u7fa4\u4f53\u88ab\u4e0d\u6210\u6bd4\u4f8b\u5730\u538b\u5236\u6216\u653e\u5927\uff0c\u5a01\u80c1\u96c6\u4f53\u8bb0\u5fc6\u7684\u591a\u6837\u6027\u3002", "method": "\u63d0\u51fa\"\u88ab\u8bb0\u4f4f\u6743\"\u6982\u5ff5\u6846\u67b6\uff0c\u5305\u62ec\u6700\u5c0f\u5316AI\u9a71\u52a8\u4fe1\u606f\u9057\u6f0f\u98ce\u9669\u3001\u4fdd\u969c\u516c\u5e73\u5bf9\u5f85\u6743\u5229\uff0c\u540c\u65f6\u786e\u4fdd\u751f\u6210\u5185\u5bb9\u6700\u5927\u7a0b\u5ea6\u771f\u5b9e\u3002", "result": "\u5efa\u7acb\u4e86\u5e94\u5bf9AI\u4fe1\u606f\u504f\u89c1\u548c\u9057\u6f0f\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u4fdd\u62a4\u6570\u5b57\u65f6\u4ee3\u96c6\u4f53\u8bb0\u5fc6\u591a\u6837\u6027\u63d0\u4f9b\u4e86\u6982\u5ff5\u57fa\u7840\u3002", "conclusion": "\u9700\u8981\u5efa\u7acb\"\u88ab\u8bb0\u4f4f\u6743\"\u6765\u5e94\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u9020\u6210\u7684\u4fe1\u606f\u504f\u89c1\u548c\u96c6\u4f53\u8bb0\u5fc6\u91cd\u5851\u95ee\u9898\uff0c\u786e\u4fdd\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u548c\u771f\u5b9e\u6027\u3002"}}
{"id": "2510.16054", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16054", "abs": "https://arxiv.org/abs/2510.16054", "authors": ["Zheng Hui", "Yijiang River Dong", "Sanhanat Sivapiromrat", "Ehsan Shareghi", "Nigel Collier"], "title": "PrivacyPAD: A Reinforcement Learning Framework for Dynamic Privacy-Aware Delegation", "comment": null, "summary": "When users submit queries to Large Language Models (LLMs), their prompts can\noften contain sensitive data, forcing a difficult choice: Send the query to a\npowerful proprietary LLM providers to achieving state-of-the-art performance\nand risk data exposure, or relying on smaller, local models guarantees data\nprivacy but often results in a degradation of task performance. Prior\napproaches have relied on static pipelines that use LLM rewriting, which\nshatters linguistic coherence and indiscriminately removes privacy-sensitive\ninformation, including task-critical content. We reformulate this challenge\n(Privacy-Conscious Delegation) as a sequential decision-making problem and\nintroduce a novel reinforcement learning (RL) framework called PrivacyPAD to\nsolve it. Our framework trains an agent to dynamically route text chunks,\nlearning a policy that optimally balances the trade-off between privacy leakage\nand task performance. It implicitly distinguishes between replaceable\nPersonally Identifiable Information (PII) (which it shields locally) and\ntask-critical PII (which it strategically sends to the remote model for maximal\nutility). To validate our approach in complex scenarios, we also introduce a\nnew medical dataset with high PII density. Our framework achieves a new\nstate-of-the-art on the privacy-utility frontier, demonstrating the necessity\nof learned, adaptive policies for deploying LLMs in sensitive environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPrivacyPAD\u6846\u67b6\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u8def\u7531\u6587\u672c\u5757\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u548c\u4efb\u52a1\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u6700\u4f18\u5e73\u8861\uff0c\u5728\u9690\u79c1-\u6548\u7528\u524d\u6cbf\u8fbe\u5230\u65b0SOTA\u3002", "motivation": "\u7528\u6237\u5411\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4ea4\u67e5\u8be2\u65f6\uff0c\u63d0\u793a\u4e2d\u5e38\u5305\u542b\u654f\u611f\u6570\u636e\uff0c\u9762\u4e34\u9009\u62e9\uff1a\u53d1\u9001\u7ed9\u5f3a\u5927\u7684\u4e13\u6709LLM\u83b7\u5f97\u6700\u4f73\u6027\u80fd\u4f46\u98ce\u9669\u6570\u636e\u66b4\u9732\uff0c\u6216\u4f7f\u7528\u672c\u5730\u5c0f\u6a21\u578b\u4fdd\u8bc1\u9690\u79c1\u4f46\u6027\u80fd\u4e0b\u964d\u3002\u73b0\u6709\u9759\u6001\u6d41\u6c34\u7ebf\u65b9\u6cd5\u7834\u574f\u8bed\u8a00\u8fde\u8d2f\u6027\u4e14\u65e0\u5dee\u522b\u5220\u9664\u9690\u79c1\u4fe1\u606f\u3002", "method": "\u5c06\u9690\u79c1\u610f\u8bc6\u59d4\u6258\u91cd\u65b0\u8868\u8ff0\u4e3a\u987a\u5e8f\u51b3\u7b56\u95ee\u9898\uff0c\u5f15\u5165\u5f3a\u5316\u5b66\u4e60\u6846\u67b6PrivacyPAD\uff0c\u8bad\u7ec3\u667a\u80fd\u4f53\u52a8\u6001\u8def\u7531\u6587\u672c\u5757\uff0c\u5b66\u4e60\u533a\u5206\u53ef\u66ff\u6362PII\uff08\u672c\u5730\u5c4f\u853d\uff09\u548c\u4efb\u52a1\u5173\u952ePII\uff08\u7b56\u7565\u6027\u53d1\u9001\u5230\u8fdc\u7a0b\u6a21\u578b\uff09\u3002", "result": "\u5728\u590d\u6742\u573a\u666f\u4e0b\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u5f15\u5165\u9ad8PII\u5bc6\u5ea6\u7684\u65b0\u533b\u7597\u6570\u636e\u96c6\uff0c\u6846\u67b6\u5728\u9690\u79c1-\u6548\u7528\u524d\u6cbf\u8fbe\u5230\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "\u8bc1\u660e\u4e86\u5728\u654f\u611f\u73af\u5883\u4e2d\u90e8\u7f72LLM\u9700\u8981\u5b66\u4e60\u6027\u3001\u81ea\u9002\u5e94\u7b56\u7565\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2510.15899", "categories": ["cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15899", "abs": "https://arxiv.org/abs/2510.15899", "authors": ["Kiran Thorat", "Jiahui Zhao", "Yaotian Liu", "Amit Hasan", "Hongwu Peng", "Xi Xie", "Bin Lei", "Caiwen Ding"], "title": "LLM-VeriPPA: Power, Performance, and Area Optimization aware Verilog Code Generation with Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) are gaining prominence in various fields, thanks\nto their ability to generate high- quality content from human instructions.\nThis paper delves into the field of chip design using LLMs, specifically in\nPower- Performance-Area (PPA) optimization and the generation of accurate\nVerilog codes for circuit designs. We introduce a novel framework VeriPPA\ndesigned to optimize PPA and generate Verilog code using LLMs. Our method\nincludes a two-stage process where the first stage focuses on improving the\nfunctional and syntactic correctness of the generated Verilog codes, while the\nsecond stage focuses on optimizing the Verilog codes to meet PPA constraints of\ncircuit designs, a crucial element of chip design. Our framework achieves an\n81.37% success rate in syntactic correctness and 62.06% in functional\ncorrectness for code genera- tion, outperforming current state-of-the-art\n(SOTA) methods. On the RTLLM dataset. On the VerilogEval dataset, our framework\nachieves 99.56% syntactic correctness and 43.79% functional correctness, also\nsurpassing SOTA, which stands at 92.11% for syntactic correctness and 33.57%\nfor functional correctness. Furthermore, Our framework able to optimize the PPA\nof the designs. These results highlight the potential of LLMs in handling\ncomplex technical areas and indicate an encouraging development in the\nautomation of chip design processes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faVeriPPA\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u82af\u7247\u8bbe\u8ba1\u7684PPA\u4f18\u5316\u548cVerilog\u4ee3\u7801\u751f\u6210\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u65b9\u6cd5\u63d0\u9ad8\u4ee3\u7801\u6b63\u786e\u6027\u548c\u4f18\u5316\u6027\u80fd\u3002", "motivation": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u82af\u7247\u8bbe\u8ba1\u9886\u57df\u7684\u6f5c\u529b\uff0c\u89e3\u51b3PPA\u4f18\u5316\u548cVerilog\u4ee3\u7801\u751f\u6210\u7684\u81ea\u52a8\u5316\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u6539\u8fdbVerilog\u4ee3\u7801\u7684\u529f\u80fd\u548c\u8bed\u6cd5\u6b63\u786e\u6027\uff0c\u7b2c\u4e8c\u9636\u6bb5\u4f18\u5316\u4ee3\u7801\u4ee5\u6ee1\u8db3PPA\u7ea6\u675f\u3002", "result": "\u5728RTLLM\u6570\u636e\u96c6\u4e0a\u8fbe\u523081.37%\u8bed\u6cd5\u6b63\u786e\u7387\u548c62.06%\u529f\u80fd\u6b63\u786e\u7387\uff1b\u5728VerilogEval\u6570\u636e\u96c6\u4e0a\u8fbe\u523099.56%\u8bed\u6cd5\u6b63\u786e\u7387\u548c43.79%\u529f\u80fd\u6b63\u786e\u7387\uff0c\u5747\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u6280\u672f\u9886\u57df\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4e3a\u82af\u7247\u8bbe\u8ba1\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2510.17639", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.17639", "abs": "https://arxiv.org/abs/2510.17639", "authors": ["Alkida Balliu", "Sebastian Brandt", "Ole Gabsdil", "Dennis Olivetti", "Jukka Suomela"], "title": "On the Universality of Round Elimination Fixed Points", "comment": null, "summary": "Recent work on distributed graph algorithms [e.g. STOC 2022, ITCS 2022, PODC\n2020] has drawn attention to the following open question: are round elimination\nfixed points a universal technique for proving lower bounds? That is, given a\nlocally checkable problem $\\Pi$ that requires at least $\\Omega(\\log n)$ rounds\nin the deterministic LOCAL model, can we always find a relaxation $\\Pi'$ of\n$\\Pi$ that is a nontrivial fixed point for the round elimination technique [see\nSTOC 2016, PODC 2019]? If yes, then a key part of distributed computational\ncomplexity would be also decidable.\n  The key obstacle so far has been a certain family of homomorphism problems\n[ITCS 2022], which require $\\Omega(\\log n)$ rounds, but the only known proof is\nbased on Marks' technique [J.AMS 2016].\n  We develop a new technique for constructing round elimination lower bounds\nsystematically. Using so-called tripotent inputs we show that the\naforementioned homomorphism problems indeed admit a lower bound proof that is\nbased on round elimination fixed points. Hence we eliminate the only known\nobstacle for the universality of round elimination.\n  Yet we also present a new obstacle: we show that there are some problems with\ninputs that require $\\Omega(\\log n)$ rounds, yet there is no proof that is\nbased on relaxations to nontrivial round elimination fixed points. Hence round\nelimination cannot be a universal technique for problems with inputs (but it\nmight be universal for problems without inputs).\n  We also prove the first fully general lower bound theorem that is applicable\nto any problem, with or without inputs, that is a fixed point in round\nelimination. Prior results of this form were only able to handle certain very\nrestricted inputs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5206\u5e03\u5f0f\u56fe\u7b97\u6cd5\u4e2d\u8f6e\u6b21\u6d88\u9664\u56fa\u5b9a\u70b9\u7684\u901a\u7528\u6027\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u8f6e\u6b21\u6d88\u9664\u4e0d\u80fd\u6210\u4e3a\u6240\u6709\u5e26\u8f93\u5165\u95ee\u9898\u7684\u901a\u7528\u6280\u672f\uff0c\u4f46\u53ef\u80fd\u662f\u65e0\u8f93\u5165\u95ee\u9898\u7684\u901a\u7528\u6280\u672f\u3002", "motivation": "\u7814\u7a76\u8f6e\u6b21\u6d88\u9664\u56fa\u5b9a\u70b9\u662f\u5426\u53ef\u4ee5\u4f5c\u4e3a\u8bc1\u660e\u5206\u5e03\u5f0f\u56fe\u7b97\u6cd5\u4e0b\u754c\u7684\u901a\u7528\u6280\u672f\uff0c\u89e3\u51b3\u4e4b\u524d\u57fa\u4e8eMarks\u6280\u672f\u7684\u540c\u6001\u95ee\u9898\u969c\u788d\u3002", "method": "\u4f7f\u7528\u4e09\u5e42\u8f93\u5165\u6784\u5efa\u8f6e\u6b21\u6d88\u9664\u4e0b\u754c\uff0c\u8bc1\u660e\u540c\u6001\u95ee\u9898\u786e\u5b9e\u53ef\u4ee5\u901a\u8fc7\u8f6e\u6b21\u6d88\u9664\u56fa\u5b9a\u70b9\u8bc1\u660e\u4e0b\u754c\uff0c\u5e76\u5c55\u793a\u65b0\u7684\u969c\u788d\u95ee\u9898\u3002", "result": "\u6d88\u9664\u4e86\u8f6e\u6b21\u6d88\u9664\u901a\u7528\u6027\u7684\u5df2\u77e5\u969c\u788d\uff0c\u4f46\u53d1\u73b0\u4e86\u65b0\u7684\u969c\u788d\uff1a\u67d0\u4e9b\u5e26\u8f93\u5165\u95ee\u9898\u65e0\u6cd5\u901a\u8fc7\u8f6e\u6b21\u6d88\u9664\u56fa\u5b9a\u70b9\u8bc1\u660e\u4e0b\u754c\u3002", "conclusion": "\u8f6e\u6b21\u6d88\u9664\u4e0d\u80fd\u6210\u4e3a\u5e26\u8f93\u5165\u95ee\u9898\u7684\u901a\u7528\u4e0b\u754c\u8bc1\u660e\u6280\u672f\uff0c\u4f46\u53ef\u80fd\u662f\u65e0\u8f93\u5165\u95ee\u9898\u7684\u901a\u7528\u6280\u672f\uff0c\u5e76\u8bc1\u660e\u4e86\u9996\u4e2a\u9002\u7528\u4e8e\u4efb\u610f\u95ee\u9898\u7684\u8f6e\u6b21\u6d88\u9664\u56fa\u5b9a\u70b9\u901a\u7528\u4e0b\u754c\u5b9a\u7406\u3002"}}
{"id": "2510.16234", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16234", "abs": "https://arxiv.org/abs/2510.16234", "authors": ["Hanane Nour Moussa", "Patrick Queiroz Da Silva", "Daniel Adu-Ampratwum", "Alyson East", "Zitong Lu", "Nikki Puccetti", "Mingyi Xue", "Huan Sun", "Bodhisattwa Prasad Majumder", "Sachin Kumar"], "title": "ScholarEval: Research Idea Evaluation Grounded in Literature", "comment": null, "summary": "As AI tools become increasingly common for research ideation, robust\nevaluation is critical to ensure the validity and usefulness of generated\nideas. We introduce ScholarEval, a retrieval augmented evaluation framework\nthat assesses research ideas based on two fundamental criteria: soundness - the\nempirical validity of proposed methods based on existing literature, and\ncontribution - the degree of advancement made by the idea across different\ndimensions relative to prior research. To evaluate ScholarEval, we introduce\nScholarIdeas, the first expert-annotated dataset of multi-domain research ideas\nand reviews, comprised of 117 ideas across four disciplines: artificial\nintelligence, neuroscience, biochemistry, and ecology. Our evaluation shows\nthat ScholarEval achieves significantly higher coverage of points mentioned in\nthe human expert annotated rubrics in ScholarIdeas compared to all baselines.\nFurthermore, ScholarEval is consistently preferred over our strongest baseline\no4-mini-deep-research, a reasoning and search-enabled agentic system by OpenAI,\nin terms of evaluation actionability, depth, and evidence support. Our\nlarge-scale user study also shows that ScholarEval significantly outperforms\ndeep research in literature engagement, idea refinement, and usefulness. We\nopenly release our code, dataset, and ScholarEval tool for the community to use\nand build on.", "AI": {"tldr": "\u63d0\u51fa\u4e86ScholarEval\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u7684\u7814\u7a76\u60f3\u6cd5\u8bc4\u4f30\u7cfb\u7edf\uff0c\u7528\u4e8e\u8bc4\u4f30AI\u751f\u6210\u7684\u7814\u7a76\u60f3\u6cd5\u7684\u6709\u6548\u6027\u548c\u8d21\u732e\u5ea6\u3002", "motivation": "\u968f\u7740AI\u5de5\u5177\u5728\u7814\u7a76\u6784\u601d\u4e2d\u7684\u666e\u53ca\uff0c\u9700\u8981\u5f3a\u5927\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u786e\u4fdd\u751f\u6210\u60f3\u6cd5\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u5f00\u53d1\u4e86ScholarEval\u8bc4\u4f30\u6846\u67b6\uff0c\u57fa\u4e8e\u4e24\u4e2a\u6838\u5fc3\u6807\u51c6\uff1asoundness\uff08\u57fa\u4e8e\u73b0\u6709\u6587\u732e\u7684\u65b9\u6cd5\u5b9e\u8bc1\u6709\u6548\u6027\uff09\u548ccontribution\uff08\u76f8\u5bf9\u4e8e\u5148\u524d\u7814\u7a76\u5728\u4e0d\u540c\u7ef4\u5ea6\u4e0a\u7684\u8fdb\u6b65\u7a0b\u5ea6\uff09\u3002\u521b\u5efa\u4e86ScholarIdeas\u6570\u636e\u96c6\uff0c\u5305\u542b117\u4e2a\u8de8\u5b66\u79d1\u7814\u7a76\u60f3\u6cd5\u548c\u4e13\u5bb6\u8bc4\u5ba1\u3002", "result": "ScholarEval\u5728\u8986\u76d6\u4eba\u7c7b\u4e13\u5bb6\u6807\u6ce8\u8981\u70b9\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u8bc4\u4f30\u53ef\u64cd\u4f5c\u6027\u3001\u6df1\u5ea6\u548c\u8bc1\u636e\u652f\u6301\u65b9\u9762\u6301\u7eed\u4f18\u4e8eOpenAI\u7684o4-mini-deep-research\u7cfb\u7edf\u3002\u5927\u89c4\u6a21\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u5728\u6587\u732e\u53c2\u4e0e\u5ea6\u3001\u60f3\u6cd5\u7cbe\u70bc\u548c\u5b9e\u7528\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6df1\u5ea6\u7814\u7a76\u3002", "conclusion": "ScholarEval\u4e3a\u7814\u7a76\u60f3\u6cd5\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6846\u67b6\uff0c\u516c\u5f00\u53d1\u5e03\u4e86\u4ee3\u7801\u3001\u6570\u636e\u96c6\u548c\u5de5\u5177\u4f9b\u793e\u533a\u4f7f\u7528\u548c\u6784\u5efa\u3002"}}
{"id": "2510.16067", "categories": ["cs.CR", "cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.16067", "abs": "https://arxiv.org/abs/2510.16067", "authors": ["Saurabh Deochake", "Ryan Murphy", "Jeremiah Gearheart"], "title": "A Multi-Cloud Framework for Zero-Trust Workload Authentication", "comment": "Cyber Security Experimentation and Test (CSET) at the Annual Computer\n  Security Applications Conference (ACSAC) 2025", "summary": "Static, long-lived credentials for workload authentication create untenable\nsecurity risks that violate Zero-Trust principles. This paper presents a\nmulti-cloud framework using Workload Identity Federation (WIF) and OpenID\nConnect (OIDC) for secretless authentication. Our approach uses\ncryptographically-verified, ephemeral tokens, allowing workloads to\nauthenticate without persistent private keys and mitigating credential theft.\nWe validate this framework in an enterprise-scale Kubernetes environment, which\nsignificantly reduces the attack surface. The model offers a unified solution\nto manage workload identities across disparate clouds, enabling future\nimplementation of robust, attribute-based access control.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u5de5\u4f5c\u8d1f\u8f7d\u8eab\u4efd\u8054\u76df\u548cOpenID Connect\u7684\u591a\u4e91\u6846\u67b6\uff0c\u5b9e\u73b0\u65e0\u5bc6\u94a5\u8ba4\u8bc1\uff0c\u4f7f\u7528\u52a0\u5bc6\u9a8c\u8bc1\u7684\u4e34\u65f6\u4ee4\u724c\u66ff\u4ee3\u9759\u6001\u957f\u671f\u51ed\u8bc1\uff0c\u663e\u8457\u964d\u4f4e\u653b\u51fb\u9762\u3002", "motivation": "\u9759\u6001\u957f\u671f\u5de5\u4f5c\u8d1f\u8f7d\u8ba4\u8bc1\u51ed\u8bc1\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u98ce\u9669\uff0c\u8fdd\u53cd\u96f6\u4fe1\u4efb\u539f\u5219\uff0c\u9700\u8981\u89e3\u51b3\u51ed\u8bc1\u76d7\u7a83\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u5de5\u4f5c\u8d1f\u8f7d\u8eab\u4efd\u8054\u76df\u548cOpenID Connect\u6784\u5efa\u591a\u4e91\u6846\u67b6\uff0c\u91c7\u7528\u52a0\u5bc6\u9a8c\u8bc1\u7684\u4e34\u65f6\u4ee4\u724c\u8fdb\u884c\u65e0\u5bc6\u94a5\u8ba4\u8bc1\u3002", "result": "\u5728\u4f01\u4e1a\u7ea7Kubernetes\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u653b\u51fb\u9762\uff0c\u80fd\u591f\u7edf\u4e00\u7ba1\u7406\u8de8\u4e91\u5de5\u4f5c\u8d1f\u8f7d\u8eab\u4efd\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u8de8\u4e0d\u540c\u4e91\u73af\u5883\u7684\u5de5\u4f5c\u8d1f\u8f7d\u8eab\u4efd\u7ba1\u7406\u63d0\u4f9b\u4e86\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u672a\u6765\u5b9e\u73b0\u5f3a\u5927\u7684\u57fa\u4e8e\u5c5e\u6027\u7684\u8bbf\u95ee\u63a7\u5236\u3002"}}
{"id": "2510.15902", "categories": ["cs.AR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2510.15902", "abs": "https://arxiv.org/abs/2510.15902", "authors": ["Shuhang Zhang", "Jelena Radulovic", "Thorsten Dworzak"], "title": "Fully Automated Verification Framework for Configurable IPs: From Requirements to Results", "comment": "DVCon Europe 2025", "summary": "The increasing competition in the semiconductor industry has created\nsignificant pressure to reduce chip prices while maintaining quality and\nreliability. Functional verification, particularly for configurable IPs, is a\nmajor contributor to development costs due to its complexity and\nresource-intensive nature. To address this, we propose a fully automated\nframework for requirements driven functional verification. The framework\nautomates key processes, including vPlan generation, testbench creation,\nregression execution, and reporting in a requirements management tool,\ndrastically reducing verification effort. This approach accelerates development\ncycles, minimizes human error, and enhances coverage, offering a scalable and\nefficient solution to the challenges of verifying configurable IPs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5168\u81ea\u52a8\u5316\u7684\u9700\u6c42\u9a71\u52a8\u529f\u80fd\u9a8c\u8bc1\u6846\u67b6\uff0c\u7528\u4e8e\u53ef\u914d\u7f6eIP\u7684\u9a8c\u8bc1\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u5173\u952e\u6d41\u7a0b\u663e\u8457\u51cf\u5c11\u9a8c\u8bc1\u5de5\u4f5c\u91cf", "motivation": "\u534a\u5bfc\u4f53\u884c\u4e1a\u7ade\u4e89\u52a0\u5267\u5bfc\u81f4\u82af\u7247\u4ef7\u683c\u4e0b\u964d\u538b\u529b\uff0c\u540c\u65f6\u9700\u8981\u4fdd\u6301\u8d28\u91cf\u548c\u53ef\u9760\u6027\u3002\u53ef\u914d\u7f6eIP\u7684\u529f\u80fd\u9a8c\u8bc1\u7531\u4e8e\u590d\u6742\u6027\u548c\u8d44\u6e90\u5bc6\u96c6\u6027\u6210\u4e3a\u5f00\u53d1\u6210\u672c\u7684\u4e3b\u8981\u8d21\u732e\u8005", "method": "\u5f00\u53d1\u5168\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u81ea\u52a8\u5316vPlan\u751f\u6210\u3001\u6d4b\u8bd5\u5e73\u53f0\u521b\u5efa\u3001\u56de\u5f52\u6267\u884c\u548c\u9700\u6c42\u7ba1\u7406\u5de5\u5177\u4e2d\u7684\u62a5\u544a\u7b49\u5173\u952e\u6d41\u7a0b", "result": "\u6846\u67b6\u5927\u5e45\u51cf\u5c11\u9a8c\u8bc1\u5de5\u4f5c\u91cf\uff0c\u52a0\u901f\u5f00\u53d1\u5468\u671f\uff0c\u6700\u5c0f\u5316\u4eba\u4e3a\u9519\u8bef\uff0c\u63d0\u9ad8\u8986\u76d6\u7387", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9a8c\u8bc1\u53ef\u914d\u7f6eIP\u7684\u6311\u6218\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.16259", "categories": ["cs.AI", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.16259", "abs": "https://arxiv.org/abs/2510.16259", "authors": ["Zhehao Zhang", "Weijie Xu", "Shixian Cui", "Chandan K. Reddy"], "title": "Distractor Injection Attacks on Large Reasoning Models: Characterization and Defense", "comment": "29 pages, 9 tables, 4 figures", "summary": "Recent advances in large reasoning models (LRMs) have enabled remarkable\nperformance on complex tasks such as mathematics and coding by generating long\nChain-of-Thought (CoT) traces. In this paper, we identify and systematically\nanalyze a critical vulnerability we term reasoning distraction, where LRMs are\ndiverted from their primary objective by irrelevant yet complex tasks\nmaliciously embedded in the prompt. Through a comprehensive study across\ndiverse models and benchmarks, we show that even state-of-the-art LRMs are\nhighly susceptible, with injected distractors reducing task accuracy by up to\n60%. We further reveal that certain alignment techniques can amplify this\nweakness and that models may exhibit covert compliance, following hidden\nadversarial instructions in reasoning while concealing them in the final\noutput. To mitigate these risks, we propose a training-based defense that\ncombines Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on\nsynthetic adversarial data, improving robustness by over 50 points on\nchallenging distractor attacks. Our findings establish reasoning distraction as\na distinct and urgent threat to LRM reliability and provide a practical step\ntoward safer and more trustworthy reasoning systems.", "AI": {"tldr": "\u672c\u6587\u8bc6\u522b\u5e76\u7cfb\u7edf\u5206\u6790\u4e86\u5927\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u5173\u952e\u6f0f\u6d1e\u2014\u2014\u63a8\u7406\u5206\u5fc3\uff0c\u5373\u6a21\u578b\u88ab\u6076\u610f\u5d4c\u5165\u63d0\u793a\u4e2d\u7684\u65e0\u5173\u590d\u6742\u4efb\u52a1\u5206\u6563\u6ce8\u610f\u529b\uff0c\u5bfc\u81f4\u4efb\u52a1\u51c6\u786e\u6027\u663e\u8457\u4e0b\u964d\u3002\u7814\u7a76\u53d1\u73b0\u6700\u5148\u8fdb\u7684LRM\u6a21\u578b\u9ad8\u5ea6\u6613\u53d7\u653b\u51fb\uff0c\u67d0\u4e9b\u5bf9\u9f50\u6280\u672f\u4f1a\u653e\u5927\u8fd9\u4e00\u5f31\u70b9\uff0c\u6a21\u578b\u53ef\u80fd\u8868\u73b0\u51fa\u9690\u853d\u670d\u4ece\u884c\u4e3a\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u57fa\u4e8e\u8bad\u7ec3\u7684\u9632\u5fa1\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u5bf9\u5206\u5fc3\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u968f\u7740\u5927\u63a8\u7406\u6a21\u578b\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u7b49\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u7814\u7a76\u8005\u53d1\u73b0\u8fd9\u4e9b\u6a21\u578b\u5b58\u5728\u4e00\u4e2a\u5173\u952e\u5b89\u5168\u6f0f\u6d1e\u2014\u2014\u63a8\u7406\u5206\u5fc3\u653b\u51fb\u3002\u6076\u610f\u653b\u51fb\u8005\u53ef\u4ee5\u5728\u63d0\u793a\u4e2d\u5d4c\u5165\u65e0\u5173\u4f46\u590d\u6742\u7684\u4efb\u52a1\u6765\u5206\u6563\u6a21\u578b\u6ce8\u610f\u529b\uff0c\u4ece\u800c\u7834\u574f\u5176\u63a8\u7406\u6027\u80fd\u3002\u8fd9\u4e00\u6f0f\u6d1e\u5bf9LRM\u7684\u53ef\u9760\u6027\u6784\u6210\u4e86\u4e25\u91cd\u5a01\u80c1\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u548c\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u8de8\u591a\u4e2a\u6a21\u578b\u548c\u57fa\u51c6\u7684\u5168\u9762\u7814\u7a76\uff0c\u5206\u6790\u4e86LRM\u5bf9\u63a8\u7406\u5206\u5fc3\u653b\u51fb\u7684\u654f\u611f\u6027\u3002\u8fdb\u4e00\u6b65\u7814\u7a76\u53d1\u73b0\u67d0\u4e9b\u5bf9\u9f50\u6280\u672f\u4f1a\u653e\u5927\u8fd9\u4e00\u5f31\u70b9\uff0c\u6a21\u578b\u53ef\u80fd\u8868\u73b0\u51fa\u9690\u853d\u670d\u4ece\u884c\u4e3a\u3002\u4e3a\u7f13\u89e3\u98ce\u9669\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408\u76d1\u7763\u5fae\u8c03(SFT)\u548c\u5f3a\u5316\u5b66\u4e60(RL)\u7684\u8bad\u7ec3\u9632\u5fa1\u65b9\u6cd5\uff0c\u4f7f\u7528\u5408\u6210\u7684\u5bf9\u6297\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684LRM\u6a21\u578b\u4e5f\u9ad8\u5ea6\u6613\u53d7\u63a8\u7406\u5206\u5fc3\u653b\u51fb\uff0c\u6ce8\u5165\u7684\u5206\u5fc3\u5668\u53ef\u4f7f\u4efb\u52a1\u51c6\u786e\u6027\u964d\u4f4e\u9ad8\u8fbe60%\u3002\u67d0\u4e9b\u5bf9\u9f50\u6280\u672f\u4f1a\u653e\u5927\u8fd9\u4e00\u5f31\u70b9\uff0c\u6a21\u578b\u53ef\u80fd\u9690\u853d\u5730\u9075\u5faa\u9690\u85cf\u7684\u5bf9\u6297\u6307\u4ee4\u3002\u63d0\u51fa\u7684\u8bad\u7ec3\u9632\u5fa1\u65b9\u6cd5\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5206\u5fc3\u653b\u51fb\u4e0a\uff0c\u5c06\u9c81\u68d2\u6027\u63d0\u9ad8\u4e8650\u591a\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u63a8\u7406\u5206\u5fc3\u662fLRM\u53ef\u9760\u6027\u9762\u4e34\u7684\u72ec\u7279\u4e14\u7d27\u8feb\u7684\u5a01\u80c1\u3002\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u8fd9\u4e00\u5b89\u5168\u6f0f\u6d1e\u7684\u4e25\u91cd\u6027\uff0c\u5e76\u4e3a\u6784\u5efa\u66f4\u5b89\u5168\u3001\u66f4\u53ef\u4fe1\u7684\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u9632\u5fa1\u6b65\u9aa4\u3002\u901a\u8fc7\u63d0\u51fa\u7684\u8bad\u7ec3\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6a21\u578b\u5bf9\u5206\u5fc3\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.16078", "categories": ["cs.CR", "cs.AI", "cs.CV", "68T10, 68T45, 94A60", "I.4.8; I.5.4; I.2.10"], "pdf": "https://arxiv.org/pdf/2510.16078", "abs": "https://arxiv.org/abs/2510.16078", "authors": ["Abdelilah Ganmati", "Karim Afdel", "Lahcen Koutti"], "title": "ISO/IEC-Compliant Match-on-Card Face Verification with Short Binary Templates", "comment": "~14 pages, 6 figures, 6 tables. Source uses elsarticle class; all\n  figures included as PNG/PDF. Primary: cs.CV", "summary": "We present a practical match-on-card design for face verification in which\ncompact 64/128-bit templates are produced off-card by PCA-ITQ and compared\non-card via constant-time Hamming distance. We specify ISO/IEC 7816-4 and\n14443-4 command APDUs with fixed-length payloads and decision-only status words\n(no score leakage), together with a minimal per-identity EEPROM map. Using real\nbinary codes from a CelebA working set (55 identities, 412 images), we (i)\nderive operating thresholds from ROC/DET, (ii) replay enroll->verify\ntransactions at those thresholds, and (iii) bound end-to-end time by pure link\nlatency plus a small constant on-card budget. Even at the slowest contact rate\n(9.6 kbps), total verification time is 43.9 ms (64 b) and 52.3 ms (128 b); at\n38.4 kbps both are <14 ms. At FAR = 1%, both code lengths reach TPR = 0.836,\nwhile 128 b lowers EER relative to 64 b. An optional +6 B helper (targeted\nsymbol-level parity over empirically unstable bits) is latency-negligible.\nOverall, short binary templates, fixed-payload decision-only APDUs, and\nconstant-time matching satisfy ISO/IEC transport constraints with wide timing\nmargin and align with ISO/IEC 24745 privacy goals. Limitations: single-dataset\nevaluation and design-level (pre-hardware) timing; we outline AgeDB/CFP-FP and\non-card microbenchmarks as next steps.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u5361\u4e0a\u4eba\u8138\u9a8c\u8bc1\u5339\u914d\u8bbe\u8ba1\uff0c\u4f7f\u752864/128\u4f4d\u7d27\u51d1\u6a21\u677f\uff0c\u901a\u8fc7PCA-ITQ\u79bb\u7ebf\u751f\u6210\uff0c\u5728\u5361\u4e0a\u901a\u8fc7\u6052\u5b9a\u65f6\u95f4\u6c49\u660e\u8ddd\u79bb\u8fdb\u884c\u6bd4\u8f83\uff0c\u6ee1\u8db3ISO/IEC\u4f20\u8f93\u7ea6\u675f\u548c\u9690\u79c1\u76ee\u6807\u3002", "motivation": "\u8bbe\u8ba1\u6ee1\u8db3ISO/IEC 7816-4\u548c14443-4\u6807\u51c6\u7684\u5361\u4e0a\u4eba\u8138\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u5b9e\u73b0\u56fa\u5b9a\u957f\u5ea6\u8f7d\u8377\u3001\u4ec5\u51b3\u7b56\u72b6\u6001\u5b57\uff08\u65e0\u5206\u6570\u6cc4\u9732\uff09\u7684\u5b89\u5168\u901a\u4fe1\uff0c\u540c\u65f6\u6700\u5c0f\u5316EEPROM\u5360\u7528\u3002", "method": "\u4f7f\u7528PCA-ITQ\u751f\u621064/128\u4f4d\u4e8c\u8fdb\u5236\u6a21\u677f\uff0c\u5728\u5361\u4e0a\u901a\u8fc7\u6052\u5b9a\u65f6\u95f4\u6c49\u660e\u8ddd\u79bb\u8fdb\u884c\u5339\u914d\uff0c\u91c7\u7528\u56fa\u5b9a\u957f\u5ea6\u7684APDU\u547d\u4ee4\u8f7d\u8377\u548c\u4ec5\u51b3\u7b56\u72b6\u6001\u5b57\uff0c\u907f\u514d\u5206\u6570\u6cc4\u9732\u3002", "result": "\u57289.6 kbps\u6700\u6162\u63a5\u89e6\u901f\u7387\u4e0b\uff0c\u603b\u9a8c\u8bc1\u65f6\u95f4\u4e3a43.9 ms\uff0864\u4f4d\uff09\u548c52.3 ms\uff08128\u4f4d\uff09\uff1b\u572838.4 kbps\u4e0b\u5747\u5c0f\u4e8e14 ms\u3002\u5728FAR=1%\u65f6\uff0c\u4e24\u79cd\u7801\u957f\u5747\u8fbe\u5230TPR=0.836\uff0c128\u4f4d\u76f8\u6bd464\u4f4d\u964d\u4f4e\u4e86EER\u3002", "conclusion": "\u77ed\u4e8c\u8fdb\u5236\u6a21\u677f\u3001\u56fa\u5b9a\u8f7d\u8377\u4ec5\u51b3\u7b56APDU\u548c\u6052\u5b9a\u65f6\u95f4\u5339\u914d\u80fd\u591f\u6ee1\u8db3ISO/IEC\u4f20\u8f93\u7ea6\u675f\uff0c\u5177\u6709\u5bbd\u88d5\u7684\u65f6\u95f4\u4f59\u91cf\uff0c\u5e76\u4e0eISO/IEC 24745\u9690\u79c1\u76ee\u6807\u4fdd\u6301\u4e00\u81f4\u3002\u5f53\u524d\u9650\u5236\u4e3a\u5355\u6570\u636e\u96c6\u8bc4\u4f30\u548c\u8bbe\u8ba1\u7ea7\u65f6\u5e8f\u5206\u6790\uff0c\u4e0b\u4e00\u6b65\u5c06\u8fdb\u884cAgeDB/CFP-FP\u8bc4\u4f30\u548c\u5361\u4e0a\u5fae\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2510.15917", "categories": ["cs.AR", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.15917", "abs": "https://arxiv.org/abs/2510.15917", "authors": ["Shai Bergman", "Won Wook Song", "Lukas Cavigelli", "Konstantin Berestizshevsky", "Ke Zhou", "Ji Zhang"], "title": "Intent-Driven Storage Systems: From Low-Level Tuning to High-Level Understanding", "comment": null, "summary": "Existing storage systems lack visibility into workload intent, limiting their\nability to adapt to the semantics of modern, large-scale data-intensive\napplications. This disconnect leads to brittle heuristics and fragmented,\nsiloed optimizations. To address these limitations, we propose Intent-Driven\nStorage Systems (IDSS), a vision for a new paradigm where large language models\n(LLMs) infer workload and system intent from unstructured signals to guide\nadaptive and cross-layer parameter reconfiguration. IDSS provides holistic\nreasoning for competing demands, synthesizing safe and efficient decisions\nwithin policy guardrails. We present four design principles for integrating\nLLMs into storage control loops and propose a corresponding system\narchitecture. Initial results on FileBench workloads show that IDSS can improve\nIOPS by up to 2.45X by interpreting intent and generating actionable\nconfigurations for storage components such as caching and prefetching. These\nfindings suggest that, when constrained by guardrails and embedded within\nstructured workflows, LLMs can function as high-level semantic optimizers,\nbridging the gap between application goals and low-level system control. IDSS\npoints toward a future in which storage systems are increasingly adaptive,\nautonomous, and aligned with dynamic workload demands.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u610f\u56fe\u9a71\u52a8\u5b58\u50a8\u7cfb\u7edf\uff08IDSS\uff09\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u975e\u7ed3\u6784\u5316\u4fe1\u53f7\u4e2d\u63a8\u65ad\u5de5\u4f5c\u8d1f\u8f7d\u548c\u7cfb\u7edf\u610f\u56fe\uff0c\u6307\u5bfc\u5b58\u50a8\u7cfb\u7edf\u7684\u81ea\u9002\u5e94\u548c\u8de8\u5c42\u53c2\u6570\u91cd\u914d\u7f6e\uff0c\u5728FileBench\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u53ef\u63d0\u5347IOPS\u8fbe2.45\u500d\u3002", "motivation": "\u73b0\u6709\u5b58\u50a8\u7cfb\u7edf\u7f3a\u4e4f\u5bf9\u5de5\u4f5c\u8d1f\u8f7d\u610f\u56fe\u7684\u53ef\u89c1\u6027\uff0c\u5bfc\u81f4\u65e0\u6cd5\u9002\u5e94\u73b0\u4ee3\u5927\u89c4\u6a21\u6570\u636e\u5bc6\u96c6\u578b\u5e94\u7528\u7684\u8bed\u4e49\uff0c\u9020\u6210\u8106\u5f31\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u788e\u7247\u5316\u7684\u4f18\u5316\u3002", "method": "\u63d0\u51faIDSS\u67b6\u6784\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230\u5b58\u50a8\u63a7\u5236\u56de\u8def\u4e2d\uff0c\u901a\u8fc7\u56db\u4e2a\u8bbe\u8ba1\u539f\u5219\u5b9e\u73b0\u610f\u56fe\u63a8\u65ad\u548c\u53c2\u6570\u91cd\u914d\u7f6e\uff0c\u5305\u62ec\u7f13\u5b58\u548c\u9884\u53d6\u7b49\u5b58\u50a8\u7ec4\u4ef6\u7684\u914d\u7f6e\u4f18\u5316\u3002", "result": "\u5728FileBench\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u7684\u521d\u6b65\u7ed3\u679c\u663e\u793a\uff0cIDSS\u80fd\u591f\u901a\u8fc7\u89e3\u91ca\u610f\u56fe\u548c\u751f\u6210\u53ef\u64cd\u4f5c\u7684\u914d\u7f6e\uff0c\u5c06IOPS\u63d0\u5347\u9ad8\u8fbe2.45\u500d\u3002", "conclusion": "\u5f53\u53d7\u5230\u62a4\u680f\u7ea6\u675f\u5e76\u5d4c\u5165\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u65f6\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u9ad8\u7ea7\u8bed\u4e49\u4f18\u5316\u5668\uff0c\u5f25\u5408\u5e94\u7528\u76ee\u6807\u4e0e\u4f4e\u7ea7\u7cfb\u7edf\u63a7\u5236\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u6307\u5411\u5b58\u50a8\u7cfb\u7edf\u66f4\u52a0\u81ea\u9002\u5e94\u3001\u81ea\u4e3b\u548c\u4e0e\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u9700\u6c42\u5bf9\u9f50\u7684\u672a\u6765\u3002"}}
{"id": "2510.16302", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.16302", "abs": "https://arxiv.org/abs/2510.16302", "authors": ["Changhao Wang", "Yanfang Liu", "Xinxin Fan", "Anzhi Zhou", "Lao Tian", "Yunfeng Lu"], "title": "DTKG: Dual-Track Knowledge Graph-Verified Reasoning Framework for Multi-Hop QA", "comment": "13 pages, 5 figures", "summary": "Multi-hop reasoning for question answering (QA) plays a critical role in\nretrieval-augmented generation (RAG) for modern large language models (LLMs).\nThe accurate answer can be obtained through retrieving relational structure of\nentities from knowledge graph (KG). Regarding the inherent relation-dependency\nand reasoning pattern, multi-hop reasoning can be in general classified into\ntwo categories: i) parallel fact-verification multi-hop reasoning question,\ni.e., requiring simultaneous verifications of multiple independent\nsub-questions; and ii) chained multi-hop reasoning questions, i.e., demanding\nsequential multi-step inference with intermediate conclusions serving as\nessential premises for subsequent reasoning. Currently, the multi-hop reasoning\napproaches singly employ one of two techniques: LLM response-based fact\nverification and KG path-based chain construction. Nevertheless, the former\nexcels at parallel fact-verification but underperforms on chained reasoning\ntasks, while the latter demonstrates proficiency in chained multi-hop reasoning\nbut suffers from redundant path retrieval when handling parallel\nfact-verification reasoning. These limitations deteriorate the efficiency and\naccuracy for multi-hop QA tasks. To address this challenge, we propose a novel\ndual-track KG verification and reasoning framework DTKG, which is inspired by\nthe Dual Process Theory in cognitive science. Specifically, DTKG comprises two\nmain stages: the Classification Stage and the Branch Processing Stage.", "AI": {"tldr": "\u63d0\u51faDTKG\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u8f68\u77e5\u8bc6\u56fe\u8c31\u9a8c\u8bc1\u548c\u63a8\u7406\u6765\u89e3\u51b3\u591a\u8df3\u95ee\u7b54\u4e2d\u7684\u5e76\u884c\u4e8b\u5b9e\u9a8c\u8bc1\u548c\u94fe\u5f0f\u63a8\u7406\u95ee\u9898", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5e76\u884c\u4e8b\u5b9e\u9a8c\u8bc1\u548c\u94fe\u5f0f\u591a\u8df3\u63a8\u7406\u4efb\u52a1\u4e0a\u5404\u6709\u4f18\u52a3\uff0c\u65e0\u6cd5\u540c\u65f6\u9ad8\u6548\u5904\u7406\u4e24\u79cd\u63a8\u7406\u6a21\u5f0f\uff0c\u9650\u5236\u4e86\u591a\u8df3\u95ee\u7b54\u7684\u6548\u7387\u548c\u51c6\u786e\u6027", "method": "\u57fa\u4e8e\u8ba4\u77e5\u79d1\u5b66\u53cc\u8fc7\u7a0b\u7406\u8bba\uff0c\u8bbe\u8ba1\u5305\u542b\u5206\u7c7b\u9636\u6bb5\u548c\u5206\u652f\u5904\u7406\u9636\u6bb5\u7684\u53cc\u8f68\u6846\u67b6\uff0c\u7ed3\u5408LLM\u54cd\u5e94\u9a8c\u8bc1\u548cKG\u8def\u5f84\u6784\u5efa\u7684\u4f18\u52bf", "result": "DTKG\u6846\u67b6\u80fd\u591f\u6839\u636e\u95ee\u9898\u7c7b\u578b\u81ea\u9002\u5e94\u9009\u62e9\u6700\u4f18\u63a8\u7406\u7b56\u7565\uff0c\u63d0\u5347\u591a\u8df3\u95ee\u7b54\u7684\u6027\u80fd", "conclusion": "\u63d0\u51fa\u7684\u53cc\u8f68\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8df3\u63a8\u7406\u4e2d\u5e76\u884c\u9a8c\u8bc1\u548c\u94fe\u5f0f\u63a8\u7406\u7684\u5e73\u8861\u95ee\u9898\uff0c\u4e3a\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.16122", "categories": ["cs.CR", "cs.CL", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16122", "abs": "https://arxiv.org/abs/2510.16122", "authors": ["Owais Makroo", "Siva Rajesh Kasa", "Sumegh Roychowdhury", "Karan Gupta", "Nikhil Pattisapu", "Santhosh Kasa", "Sumit Negi"], "title": "The Hidden Cost of Modeling P(X): Vulnerability to Membership Inference Attacks in Generative Text Classifiers", "comment": null, "summary": "Membership Inference Attacks (MIAs) pose a critical privacy threat by\nenabling adversaries to determine whether a specific sample was included in a\nmodel's training dataset. Despite extensive research on MIAs, systematic\ncomparisons between generative and discriminative classifiers remain limited.\nThis work addresses this gap by first providing theoretical motivation for why\ngenerative classifiers exhibit heightened susceptibility to MIAs, then\nvalidating these insights through comprehensive empirical evaluation. Our study\nencompasses discriminative, generative, and pseudo-generative text classifiers\nacross varying training data volumes, evaluated on nine benchmark datasets.\nEmploying a diverse array of MIA strategies, we consistently demonstrate that\nfully generative classifiers which explicitly model the joint likelihood\n$P(X,Y)$ are most vulnerable to membership leakage. Furthermore, we observe\nthat the canonical inference approach commonly used in generative classifiers\nsignificantly amplifies this privacy risk. These findings reveal a fundamental\nutility-privacy trade-off inherent in classifier design, underscoring the\ncritical need for caution when deploying generative classifiers in\nprivacy-sensitive applications. Our results motivate future research directions\nin developing privacy-preserving generative classifiers that can maintain\nutility while mitigating membership inference vulnerabilities.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u751f\u6210\u5f0f\u548c\u5224\u522b\u5f0f\u5206\u7c7b\u5668\u5728\u6210\u5458\u63a8\u7406\u653b\u51fb\u4e2d\u7684\u8106\u5f31\u6027\uff0c\u53d1\u73b0\u751f\u6210\u5f0f\u5206\u7c7b\u5668\u7531\u4e8e\u663e\u5f0f\u5efa\u6a21\u8054\u5408\u6982\u7387P(X,Y)\u800c\u66f4\u5bb9\u6613\u906d\u53d7\u9690\u79c1\u6cc4\u9732\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5bf9\u751f\u6210\u5f0f\u548c\u5224\u522b\u5f0f\u5206\u7c7b\u5668\u5728\u6210\u5458\u63a8\u7406\u653b\u51fb\u4e2d\u7684\u7cfb\u7edf\u6027\u6bd4\u8f83\u6709\u9650\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4ece\u7406\u8bba\u4e0a\u548c\u5b9e\u8bc1\u4e0a\u5206\u6790\u4e24\u7c7b\u5206\u7c7b\u5668\u7684\u9690\u79c1\u8106\u5f31\u6027\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u7efc\u5408\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u7814\u7a76\u6db5\u76d6\u5224\u522b\u5f0f\u3001\u751f\u6210\u5f0f\u548c\u4f2a\u751f\u6210\u5f0f\u6587\u672c\u5206\u7c7b\u5668\uff0c\u57289\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u591a\u79cdMIA\u7b56\u7565\u8fdb\u884c\u6d4b\u8bd5\uff0c\u8003\u5bdf\u4e0d\u540c\u8bad\u7ec3\u6570\u636e\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u8868\u660e\u5b8c\u5168\u751f\u6210\u5f0f\u5206\u7c7b\u5668\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u6700\u4e3a\u8106\u5f31\uff0c\u5176\u6807\u51c6\u63a8\u7406\u65b9\u6cd5\u663e\u8457\u653e\u5927\u4e86\u9690\u79c1\u98ce\u9669\uff0c\u63ed\u793a\u4e86\u5206\u7c7b\u5668\u8bbe\u8ba1\u4e2d\u56fa\u6709\u7684\u6548\u7528-\u9690\u79c1\u6743\u8861\u3002", "conclusion": "\u751f\u6210\u5f0f\u5206\u7c7b\u5668\u5728\u9690\u79c1\u654f\u611f\u5e94\u7528\u4e2d\u9700\u8c28\u614e\u90e8\u7f72\uff0c\u672a\u6765\u5e94\u7814\u7a76\u5f00\u53d1\u65e2\u80fd\u4fdd\u6301\u6548\u7528\u53c8\u80fd\u7f13\u89e3\u6210\u5458\u63a8\u7406\u6f0f\u6d1e\u7684\u9690\u79c1\u4fdd\u62a4\u751f\u6210\u5f0f\u5206\u7c7b\u5668\u3002"}}
{"id": "2510.15907", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.15907", "abs": "https://arxiv.org/abs/2510.15907", "authors": ["Era Thaqi", "Dennis Eigner", "Arman Ferdowsi", "Ulrich Schmid"], "title": "Symbolic Timing Analysis of Digital Circuits Using Analytic Delay Functions", "comment": null, "summary": "We propose a novel approach to symbolic timing analysis for digital\nintegrated circuits based on recently developed analytic delay formulas for\n2-input NOR, NAND, and Muller-C gates by Ferdowsi et al. (NAHS 2025). Given a\nfixed order of the transitions of all input and internal signals of a circuit,\nour framework computes closed-form analytic delay expressions for all the\ninternal signal transition times that depend on (i) the symbolic transition\ntimes of the relevant input signals and (ii) the model parameters of the\nrelevant gates. The resulting formulas facilitate per-transition timing\nanalysis without any simulation, by instantiating the symbolic input transition\ntimes and the gate parameters. More importantly, however, they also enable an\n\\emph{analytic} study of the dependencies of certain timing properties on input\nsignals and gate parameters. For instance, differentiating a symbolic delay\nexpression with respect to a gate parameter or input transition time enables\nsensitivity analysis. As a proof of concept, we implement our approach using\nthe computer algebra system SageMath and apply it to the NOR-gate version of\nthe c17 slack benchmark circuit.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89e3\u6790\u5ef6\u8fdf\u516c\u5f0f\u7684\u6570\u5b57\u96c6\u6210\u7535\u8def\u7b26\u53f7\u65f6\u5e8f\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97\u5185\u90e8\u4fe1\u53f7\u8f6c\u6362\u65f6\u95f4\u7684\u95ed\u5f0f\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u5b9e\u73b0\u65e0\u9700\u4eff\u771f\u7684\u65f6\u5e8f\u5206\u6790\u548c\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u8fdb\u884c\u7b26\u53f7\u65f6\u5e8f\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u907f\u514d\u4f20\u7edf\u4eff\u771f\u65b9\u6cd5\uff0c\u5e76\u652f\u6301\u5bf9\u65f6\u5e8f\u7279\u6027\u4e0e\u8f93\u5165\u4fe1\u53f7\u53ca\u95e8\u53c2\u6570\u4f9d\u8d56\u5173\u7cfb\u7684\u89e3\u6790\u7814\u7a76\u3002", "method": "\u57fa\u4e8eFerdowsi\u7b49\u4eba\u5f00\u53d1\u76842\u8f93\u5165NOR\u3001NAND\u548cMuller-C\u95e8\u7684\u89e3\u6790\u5ef6\u8fdf\u516c\u5f0f\uff0c\u5728\u56fa\u5b9a\u4fe1\u53f7\u8f6c\u6362\u987a\u5e8f\u4e0b\u8ba1\u7b97\u5185\u90e8\u4fe1\u53f7\u8f6c\u6362\u65f6\u95f4\u7684\u95ed\u5f0f\u89e3\u6790\u8868\u8fbe\u5f0f\u3002", "result": "\u5b9e\u73b0\u4e86\u57fa\u4e8eSageMath\u8ba1\u7b97\u673a\u4ee3\u6570\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u5e76\u5728c17 slack\u57fa\u51c6\u7535\u8def\u7684NOR\u95e8\u7248\u672c\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u80fd\u591f\u8fdb\u884c\u654f\u611f\u6027\u5206\u6790\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6570\u5b57\u96c6\u6210\u7535\u8def\u65f6\u5e8f\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u7b26\u53f7\u65b9\u6cd5\uff0c\u652f\u6301\u89e3\u6790\u7814\u7a76\u65f6\u5e8f\u7279\u6027\u5bf9\u8f93\u5165\u4fe1\u53f7\u548c\u95e8\u53c2\u6570\u7684\u4f9d\u8d56\u6027\u3002"}}
{"id": "2510.15927", "categories": ["cs.AR", "cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.15927", "abs": "https://arxiv.org/abs/2510.15927", "authors": ["Krystian Chmielewski", "Jaros\u0142aw \u0141awnicki", "Uladzislau Lukyanau", "Tadeusz Kobus", "Maciej Maciejewski"], "title": "UPMEM Unleashed: Software Secrets for Speed", "comment": null, "summary": "Developing kernels for Processing-In-Memory (PIM) platforms poses unique\nchallenges in data management and parallel programming on limited processing\nunits. Although software development kits (SDKs) for PIM, such as the UPMEM\nSDK, provide essential tools, these emerging platforms still leave significant\nroom for performance optimization. In this paper, we reveal surprising\ninefficiencies in UPMEM software stack and play with non-standard programming\ntechniques. By making simple modifications to the assembly generated by the\nUPMEM compiler, we achieve speedups of 1.6-2x in integer addition and 1.4-5.9x\nin integer multiplication, depending on the data type. We also demonstrate that\nbit-serial processing of low precision data is a viable option for UPMEM: in\nINT4 bit-serial dot-product calculation, UPMEM can achieve over 2.7x speedup\nover the baseline. Minor API extensions for PIM allocation that account for the\nnon-uniform memory access (NUMA) architecture of the server further improve the\nconsistency and throughput of host-PIM data transfers by up to 2.9x. Finally,\nwe show that, when the matrix is preloaded into PIM, our optimized kernels\noutperform a dual-socket CPU server by over 3x for INT8 generalized\nmatrix-vector multiplication (GEMV) and by 10x for INT4 GEMV. Our optimized\nINT8 GEMV kernel outperforms the baseline 3.5x.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86UPMEM PIM\u5e73\u53f0\u8f6f\u4ef6\u6808\u4e2d\u7684\u4f4e\u6548\u95ee\u9898\uff0c\u901a\u8fc7\u6c47\u7f16\u4ee3\u7801\u4fee\u6539\u3001\u4f4d\u4e32\u884c\u5904\u7406\u6280\u672f\u4ee5\u53caNUMA\u611f\u77e5\u7684\u5185\u5b58\u5206\u914d\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6574\u6570\u8fd0\u7b97\u548c\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "PIM\u5e73\u53f0\u5728\u6570\u636e\u7ba1\u7406\u548c\u5e76\u884c\u7f16\u7a0b\u65b9\u9762\u9762\u4e34\u72ec\u7279\u6311\u6218\uff0c\u73b0\u6709SDK\u4ecd\u6709\u5f88\u5927\u7684\u6027\u80fd\u4f18\u5316\u7a7a\u95f4\uff0c\u9700\u8981\u63a2\u7d22\u975e\u6807\u51c6\u7f16\u7a0b\u6280\u672f\u6765\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u4fee\u6539UPMEM\u7f16\u8bd1\u5668\u751f\u6210\u7684\u6c47\u7f16\u4ee3\u7801\u3001\u91c7\u7528\u4f4d\u4e32\u884c\u5904\u7406\u4f4e\u7cbe\u5ea6\u6570\u636e\u3001\u6269\u5c55API\u4ee5\u652f\u6301NUMA\u67b6\u6784\u611f\u77e5\u7684\u5185\u5b58\u5206\u914d\u3002", "result": "\u6574\u6570\u52a0\u6cd5\u6027\u80fd\u63d0\u53471.6-2\u500d\uff0c\u6574\u6570\u4e58\u6cd5\u63d0\u53471.4-5.9\u500d\uff1bINT4\u4f4d\u4e32\u884c\u70b9\u79ef\u8ba1\u7b97\u6bd4\u57fa\u7ebf\u5feb2.7\u500d\u4ee5\u4e0a\uff1b\u4e3b\u673a-PIM\u6570\u636e\u4f20\u8f93\u4e00\u81f4\u6027\u63d0\u53472.9\u500d\uff1b\u4f18\u5316\u540e\u7684INT8 GEMV\u6bd4\u57fa\u7ebf\u5feb3.5\u500d\uff0c\u6bd4\u53cc\u8defCPU\u670d\u52a1\u5668\u5feb3\u500d\u4ee5\u4e0a\uff0cINT4 GEMV\u5feb10\u500d\u3002", "conclusion": "\u901a\u8fc7\u7b80\u5355\u7684\u8f6f\u4ef6\u6808\u4f18\u5316\u548c\u521b\u65b0\u7684\u7f16\u7a0b\u6280\u672f\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347PIM\u5e73\u53f0\u7684\u6027\u80fd\uff0c\u4f7f\u5176\u5728\u5904\u7406\u4f4e\u7cbe\u5ea6\u77e9\u9635\u8fd0\u7b97\u65f6\u8d85\u8d8a\u4f20\u7edfCPU\u670d\u52a1\u5668\u3002"}}
{"id": "2510.16309", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16309", "abs": "https://arxiv.org/abs/2510.16309", "authors": ["Crystal Su"], "title": "MedRule-KG: A Knowledge-Graph--Steered Scaffold for Mathematical Reasoning with a Lightweight Verifier", "comment": "Accepted to the Annual Conference on Neural Information Processing\n  Systems (NeurIPS 2026) Workshop", "summary": "Large language models (LLMs) often produce fluent reasoning steps while\nviolating simple mathematical or logical constraints. We introduce MedRule-KG,\na compact typed knowledge graph coupled with a symbolic verifier, designed to\nenforce mathematically interpretable rules in reasoning tasks. MedRule-KG\nencodes entities, relations, and three domain-inspired rules, while the\nverifier checks predictions and applies minimal corrections to guarantee\nconsistency. On a 90-example FDA-derived benchmark, grounding in MedRule-KG\nimproves exact match (EM) from 0.767 to 0.900, and adding the verifier yields\n1.000 EM while eliminating rule violations entirely. We demonstrate how\nMedRule-KG provides a general scaffold for safe mathematical reasoning, discuss\nablations, and release code and data to encourage reproducibility.", "AI": {"tldr": "MedRule-KG\u662f\u4e00\u4e2a\u7d27\u51d1\u578b\u77e5\u8bc6\u56fe\u8c31\u4e0e\u7b26\u53f7\u9a8c\u8bc1\u5668\u7ed3\u5408\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u5f3a\u5236\u6267\u884c\u6570\u5b66\u53ef\u89e3\u91ca\u89c4\u5219\uff0c\u663e\u8457\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7ecf\u5e38\u4ea7\u751f\u6d41\u7545\u4f46\u8fdd\u53cd\u7b80\u5355\u6570\u5b66\u6216\u903b\u8f91\u7ea6\u675f\u7684\u6b65\u9aa4\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u786e\u4fdd\u63a8\u7406\u7684\u6570\u5b66\u53ef\u89e3\u91ca\u6027\u548c\u4e00\u81f4\u6027\u3002", "method": "\u5f15\u5165MedRule-KG\uff0c\u8fd9\u662f\u4e00\u4e2a\u7d27\u51d1\u7684\u7c7b\u578b\u5316\u77e5\u8bc6\u56fe\u8c31\uff0c\u7ed3\u5408\u7b26\u53f7\u9a8c\u8bc1\u5668\uff0c\u7f16\u7801\u5b9e\u4f53\u3001\u5173\u7cfb\u548c\u4e09\u4e2a\u9886\u57df\u542f\u53d1\u89c4\u5219\uff0c\u9a8c\u8bc1\u9884\u6d4b\u5e76\u5e94\u7528\u6700\u5c0f\u4fee\u6b63\u4ee5\u4fdd\u8bc1\u4e00\u81f4\u6027\u3002", "result": "\u572890\u4e2aFDA\u884d\u751f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u57fa\u4e8eMedRule-KG\u7684\u63a8\u7406\u5c06\u7cbe\u786e\u5339\u914d\u4ece0.767\u63d0\u5347\u52300.900\uff0c\u6dfb\u52a0\u9a8c\u8bc1\u5668\u540e\u8fbe\u52301.000\u7cbe\u786e\u5339\u914d\uff0c\u5b8c\u5168\u6d88\u9664\u4e86\u89c4\u5219\u8fdd\u53cd\u3002", "conclusion": "MedRule-KG\u4e3a\u5b89\u5168\u7684\u6570\u5b66\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u548c\u7b26\u53f7\u9a8c\u8bc1\u7684\u7ed3\u5408\u6709\u6548\u89e3\u51b3\u4e86LLM\u7684\u63a8\u7406\u4e00\u81f4\u6027\u95ee\u9898\u3002"}}
{"id": "2510.16128", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.16128", "abs": "https://arxiv.org/abs/2510.16128", "authors": ["Kate Glazko", "Jennifer Mankoff"], "title": "Prompt injections as a tool for preserving identity in GAI image descriptions", "comment": "Accepted as a poster to Soups 2025", "summary": "Generative AI risks such as bias and lack of representation impact people who\ndo not interact directly with GAI systems, but whose content does: indirect\nusers. Several approaches to mitigating harms to indirect users have been\ndescribed, but most require top down or external intervention. An emerging\nstrategy, prompt injections, provides an empowering alternative: indirect users\ncan mitigate harm against them, from within their own content. Our approach\nproposes prompt injections not as a malicious attack vector, but as a tool for\ncontent/image owner resistance. In this poster, we demonstrate one case study\nof prompt injections for empowering an indirect user, by retaining an image\nowner's gender and disabled identity when an image is described by GAI.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06\u63d0\u793a\u6ce8\u5165\u4f5c\u4e3a\u4e00\u79cd\u5de5\u5177\uff0c\u4f7f\u95f4\u63a5\u7528\u6237\u80fd\u591f\u901a\u8fc7\u5728\u81ea\u5df1\u7684\u5185\u5bb9\u4e2d\u5d4c\u5165\u63d0\u793a\u6765\u4fdd\u62a4\u8eab\u4efd\u7279\u5f81\u514d\u53d7\u751f\u6210\u5f0fAI\u7cfb\u7edf\u7684\u504f\u89c1\u5f71\u54cd\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7684\u504f\u89c1\u548c\u7f3a\u4e4f\u4ee3\u8868\u6027\u7b49\u95ee\u9898\u4f1a\u5f71\u54cd\u90a3\u4e9b\u4e0d\u76f4\u63a5\u4e0e\u7cfb\u7edf\u4ea4\u4e92\u4f46\u5185\u5bb9\u88ab\u4f7f\u7528\u7684\u95f4\u63a5\u7528\u6237\uff0c\u73b0\u6709\u7f13\u89e3\u65b9\u6cd5\u5927\u591a\u9700\u8981\u81ea\u4e0a\u800c\u4e0b\u7684\u5e72\u9884\uff0c\u7f3a\u4e4f\u7528\u6237\u81ea\u4e3b\u6027\u3002", "method": "\u5c06\u63d0\u793a\u6ce8\u5165\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5185\u5bb9\u6240\u6709\u8005\u62b5\u6297\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u5982\u4f55\u5728\u56fe\u50cf\u63cf\u8ff0\u4e2d\u4fdd\u7559\u6240\u6709\u8005\u7684\u6027\u522b\u548c\u6b8b\u75be\u8eab\u4efd\u7279\u5f81\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u79cd\u4f7f\u95f4\u63a5\u7528\u6237\u80fd\u591f\u81ea\u4e3b\u51cf\u8f7b\u751f\u6210\u5f0fAI\u5bf9\u5176\u9020\u6210\u4f24\u5bb3\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5185\u5bb9\u5185\u5d4c\u63d0\u793a\u6765\u4fdd\u62a4\u4e2a\u4eba\u8eab\u4efd\u7279\u5f81\u3002", "conclusion": "\u63d0\u793a\u6ce8\u5165\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u79cd\u8d4b\u6743\u5de5\u5177\uff0c\u8ba9\u95f4\u63a5\u7528\u6237\u4ece\u81ea\u8eab\u5185\u5bb9\u5185\u90e8\u62b5\u6297\u751f\u6210\u5f0fAI\u7684\u504f\u89c1\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u81ea\u4e0b\u800c\u4e0a\u7684\u4f24\u5bb3\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2510.15908", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.15908", "abs": "https://arxiv.org/abs/2510.15908", "authors": ["Hana Chitsaz", "Johnson Umeike", "Amirmahdi Namjoo", "Babak N. Safa", "Bahar Asgari"], "title": "Belenos: Bottleneck Evaluation to Link Biomechanics to Novel Computing Optimizations", "comment": null, "summary": "Finite element simulations are essential in biomechanics, enabling detailed\nmodeling of tissues and organs. However, architectural inefficiencies in\ncurrent hardware and software stacks limit performance and scalability,\nespecially for iterative tasks like material parameter identification. As a\nresult, workflows often sacrifice fidelity for tractability. Reconfigurable\nhardware, such as FPGAs, offers a promising path to domain-specific\nacceleration without the cost of ASICs, but its potential in biomechanics\nremains underexplored. This paper presents Belenos, a comprehensive workload\ncharacterization of finite element biomechanics using FEBio, a widely adopted\nsimulator, gem5 sensitivity studies, and VTune analysis. VTune results reveal\nthat smaller workloads experience moderate front-end stalls, typically around\n13.1%, whereas larger workloads are dominated by significant back-end\nbottlenecks, with backend-bound cycles ranging from 59.9% to over 82.2%.\nComplementary gem5 sensitivity studies identify optimal hardware configurations\nfor Domain-Specific Accelerators (DSA), showing that suboptimal pipeline,\nmemory, or branch predictor settings can degrade performance by up to 37.1%.\nThese findings underscore the need for architecture-aware co-design to\nefficiently support biomechanical simulation workloads.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6709\u9650\u5143\u751f\u7269\u529b\u5b66\u6a21\u62df\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5de5\u4f5c\u8d1f\u8f7d\u5206\u6790\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u786c\u4ef6\u67b6\u6784\u5728\u6027\u80fd\u6269\u5c55\u6027\u65b9\u9762\u7684\u74f6\u9888\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8eFPGA\u7684\u9886\u57df\u7279\u5b9a\u52a0\u901f\u5668\u4f18\u5316\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u751f\u7269\u529b\u5b66\u6709\u9650\u5143\u6a21\u62df\u5728\u786c\u4ef6\u548c\u8f6f\u4ef6\u67b6\u6784\u4e0a\u5b58\u5728\u6548\u7387\u95ee\u9898\uff0c\u9650\u5236\u4e86\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\uff0c\u7279\u522b\u662f\u5728\u6750\u6599\u53c2\u6570\u8bc6\u522b\u7b49\u8fed\u4ee3\u4efb\u52a1\u4e2d\u3002\u53ef\u91cd\u6784\u786c\u4ef6\uff08\u5982FPGA\uff09\u63d0\u4f9b\u4e86\u9886\u57df\u7279\u5b9a\u52a0\u901f\u7684\u6f5c\u529b\uff0c\u4f46\u8fd9\u4e00\u6f5c\u529b\u5728\u751f\u7269\u529b\u5b66\u9886\u57df\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f7f\u7528FEBio\u6a21\u62df\u5668\u8fdb\u884c\u6709\u9650\u5143\u751f\u7269\u529b\u5b66\u5de5\u4f5c\u8d1f\u8f7d\u8868\u5f81\uff0c\u7ed3\u5408gem5\u654f\u611f\u6027\u7814\u7a76\u548cVTune\u5206\u6790\uff0c\u8bc6\u522b\u6027\u80fd\u74f6\u9888\u548c\u6700\u4f18\u786c\u4ef6\u914d\u7f6e\u3002", "result": "VTune\u5206\u6790\u663e\u793a\u5c0f\u5de5\u4f5c\u8d1f\u8f7d\u524d\u7aef\u505c\u6ede\u7ea6\u4e3a13.1%\uff0c\u800c\u5927\u5de5\u4f5c\u8d1f\u8f7d\u4e3b\u8981\u53d7\u540e\u7aef\u74f6\u9888\u5f71\u54cd\uff0c\u540e\u7aef\u7ed1\u5b9a\u5468\u671f\u4ece59.9%\u5230\u8d85\u8fc782.2%\u3002gem5\u654f\u611f\u6027\u7814\u7a76\u786e\u5b9a\u4e86\u9886\u57df\u7279\u5b9a\u52a0\u901f\u5668\u7684\u6700\u4f18\u786c\u4ef6\u914d\u7f6e\uff0c\u53d1\u73b0\u4e0d\u5408\u7406\u7684\u6d41\u6c34\u7ebf\u3001\u5185\u5b58\u6216\u5206\u652f\u9884\u6d4b\u5668\u8bbe\u7f6e\u53ef\u4f7f\u6027\u80fd\u4e0b\u964d\u9ad8\u8fbe37.1%\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u67b6\u6784\u611f\u77e5\u534f\u540c\u8bbe\u8ba1\u7684\u5fc5\u8981\u6027\uff0c\u4ee5\u6709\u6548\u652f\u6301\u751f\u7269\u529b\u5b66\u6a21\u62df\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u4e3a\u57fa\u4e8eFPGA\u7684\u9886\u57df\u7279\u5b9a\u52a0\u901f\u5668\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2510.16342", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16342", "abs": "https://arxiv.org/abs/2510.16342", "authors": ["Tong Zhang", "Ru Zhang", "Jianyi Liu", "Zhen Yang", "Gongshen Liu"], "title": "Beyond Fixed Anchors: Precisely Erasing Concepts with Sibling Exclusive Counterparts", "comment": null, "summary": "Existing concept erasure methods for text-to-image diffusion models commonly\nrely on fixed anchor strategies, which often lead to critical issues such as\nconcept re-emergence and erosion. To address this, we conduct causal tracing to\nreveal the inherent sensitivity of erasure to anchor selection and define\nSibling Exclusive Concepts as a superior class of anchors. Based on this\ninsight, we propose \\textbf{SELECT} (Sibling-Exclusive Evaluation for\nContextual Targeting), a dynamic anchor selection framework designed to\novercome the limitations of fixed anchors. Our framework introduces a novel\ntwo-stage evaluation mechanism that automatically discovers optimal anchors for\nprecise erasure while identifying critical boundary anchors to preserve related\nconcepts. Extensive evaluations demonstrate that SELECT, as a universal anchor\nsolution, not only efficiently adapts to multiple erasure frameworks but also\nconsistently outperforms existing baselines across key performance metrics,\naveraging only 4 seconds for anchor mining of a single concept.", "AI": {"tldr": "SELECT\u662f\u4e00\u4e2a\u52a8\u6001\u951a\u70b9\u9009\u62e9\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bc4\u4f30\u673a\u5236\u81ea\u52a8\u53d1\u73b0\u6700\u4f18\u951a\u70b9\u8fdb\u884c\u7cbe\u786e\u6982\u5ff5\u64e6\u9664\uff0c\u540c\u65f6\u8bc6\u522b\u5173\u952e\u8fb9\u754c\u951a\u70b9\u4ee5\u4fdd\u7559\u76f8\u5173\u6982\u5ff5\uff0c\u89e3\u51b3\u4e86\u56fa\u5b9a\u951a\u70b9\u7b56\u7565\u5bfc\u81f4\u7684\u6982\u5ff5\u91cd\u73b0\u548c\u4fb5\u8680\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u7684\u6982\u5ff5\u64e6\u9664\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u56fa\u5b9a\u951a\u70b9\u7b56\u7565\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u6982\u5ff5\u91cd\u73b0\u548c\u4fb5\u8680\u7b49\u5173\u952e\u95ee\u9898\u3002\u901a\u8fc7\u56e0\u679c\u8ffd\u8e2a\u53d1\u73b0\u64e6\u9664\u5bf9\u951a\u70b9\u9009\u62e9\u5177\u6709\u5185\u5728\u654f\u611f\u6027\uff0c\u9700\u8981\u66f4\u4f18\u7684\u951a\u70b9\u9009\u62e9\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSELECT\u6846\u67b6\uff0c\u5f15\u5165\u65b0\u9896\u7684\u4e24\u9636\u6bb5\u8bc4\u4f30\u673a\u5236\uff1a\u81ea\u52a8\u53d1\u73b0\u6700\u4f18\u951a\u70b9\u8fdb\u884c\u7cbe\u786e\u64e6\u9664\uff0c\u540c\u65f6\u8bc6\u522b\u5173\u952e\u8fb9\u754c\u951a\u70b9\u4ee5\u4fdd\u7559\u76f8\u5173\u6982\u5ff5\u3002\u8be5\u6846\u67b6\u57fa\u4e8eSibling Exclusive Concepts\u4f5c\u4e3a\u66f4\u4f18\u7684\u951a\u70b9\u7c7b\u522b\u3002", "result": "\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660eSELECT\u4f5c\u4e3a\u901a\u7528\u951a\u70b9\u89e3\u51b3\u65b9\u6848\uff0c\u4e0d\u4ec5\u9ad8\u6548\u9002\u5e94\u591a\u4e2a\u64e6\u9664\u6846\u67b6\uff0c\u8fd8\u5728\u5173\u952e\u6027\u80fd\u6307\u6807\u4e0a\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5355\u4e2a\u6982\u5ff5\u951a\u70b9\u6316\u6398\u5e73\u5747\u4ec5\u97004\u79d2\u3002", "conclusion": "SELECT\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u951a\u70b9\u9009\u62e9\u6709\u6548\u89e3\u51b3\u4e86\u56fa\u5b9a\u951a\u70b9\u7b56\u7565\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u7684\u6982\u5ff5\u64e6\u9664\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u548c\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.15910", "categories": ["cs.AR", "hep-ex"], "pdf": "https://arxiv.org/pdf/2510.15910", "abs": "https://arxiv.org/abs/2510.15910", "authors": ["Marvin Fuchs", "Lukas Scheller", "Timo Muscheid", "Oliver Sander", "Luis E. Ardila-Perez"], "title": "SoCks - Simplifying Firmware and Software Integration for Heterogeneous SoCs", "comment": "26 pages, single-column, 13 figures, 2 tables", "summary": "Modern heterogeneous System-on-Chip (SoC) devices integrate advanced\ncomponents into a single package, offering powerful capabilities while also\nintroducing significant complexity. To manage these sophisticated devices,\nfirmware and software developers need powerful development tools. However, as\nthese tools become increasingly complex, they often lack adequate support,\nresulting in a steep learning curve and challenging troubleshooting. To address\nthis, this work introduces System-on-Chip blocks (SoCks), a flexible and\nexpandable build framework that reduces complexity by partitioning the SoC\nimage into high-level units called blocks. SoCks builds each firmware and\nsoftware block in an encapsulated way, independently from other components of\nthe image, thereby reducing dependencies to a minimum. While some information\nexchange between the blocks is unavoidable to ensure seamless runtime\nintegration, this interaction is standardized via interfaces. A small number of\ndependencies and well-defined interfaces simplify the reuse of existing block\nimplementations and facilitate seamless substitution between versions-for\ninstance, when choosing root file systems for the embedded Linux operating\nsystem. Additionally, this approach facilitates the establishment of a\ndecentralized and partially automated development flow through Continuous\nIntegration and Continuous Delivery (CI/CD). Measurement results demonstrate\nthat SoCks can build a complete SoC image up to three times faster than\nestablished tools.", "AI": {"tldr": "SoCks\u662f\u4e00\u4e2a\u7075\u6d3b\u53ef\u6269\u5c55\u7684\u6784\u5efa\u6846\u67b6\uff0c\u901a\u8fc7\u5c06SoC\u955c\u50cf\u5212\u5206\u4e3a\u9ad8\u7ea7\u5355\u5143\uff08\u5757\uff09\u6765\u964d\u4f4e\u590d\u6742\u6027\uff0c\u5b9e\u73b0\u72ec\u7acb\u6784\u5efa\u548c\u6700\u5c0f\u5316\u4f9d\u8d56\uff0c\u4f7f\u6784\u5efa\u901f\u5ea6\u63d0\u5347\u81f3\u4f20\u7edf\u5de5\u5177\u76843\u500d\u3002", "motivation": "\u73b0\u4ee3\u5f02\u6784SoC\u8bbe\u5907\u96c6\u6210\u590d\u6742\u7ec4\u4ef6\uff0c\u4f46\u5f00\u53d1\u5de5\u5177\u590d\u6742\u4e14\u652f\u6301\u4e0d\u8db3\uff0c\u5bfc\u81f4\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\u548c\u6545\u969c\u6392\u9664\u56f0\u96be\u3002", "method": "\u5c06SoC\u955c\u50cf\u5206\u533a\u4e3a\u5757\uff0c\u6bcf\u4e2a\u56fa\u4ef6\u548c\u8f6f\u4ef6\u5757\u4ee5\u5c01\u88c5\u65b9\u5f0f\u72ec\u7acb\u6784\u5efa\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u63a5\u53e3\u8fdb\u884c\u5fc5\u8981\u7684\u4fe1\u606f\u4ea4\u6362\uff0c\u6700\u5c0f\u5316\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "SoCks\u80fd\u591f\u6bd4\u73b0\u6709\u5de5\u5177\u5feb3\u500d\u6784\u5efa\u5b8c\u6574\u7684SoC\u955c\u50cf\uff0c\u7b80\u5316\u73b0\u6709\u5757\u5b9e\u73b0\u7684\u590d\u7528\uff0c\u5e76\u652f\u6301\u7248\u672c\u95f4\u7684\u65e0\u7f1d\u66ff\u6362\u3002", "conclusion": "SoCks\u6846\u67b6\u6709\u6548\u964d\u4f4e\u4e86SoC\u5f00\u53d1\u7684\u590d\u6742\u6027\uff0c\u652f\u6301\u53bb\u4e2d\u5fc3\u5316\u548c\u90e8\u5206\u81ea\u52a8\u5316\u7684\u5f00\u53d1\u6d41\u7a0b\uff0c\u901a\u8fc7CI/CD\u5b9e\u73b0\u9ad8\u6548\u6784\u5efa\u3002"}}
{"id": "2510.16368", "categories": ["cs.AI", "cs.HC", "cs.LG", "econ.TH"], "pdf": "https://arxiv.org/pdf/2510.16368", "abs": "https://arxiv.org/abs/2510.16368", "authors": ["Ali Shirali"], "title": "The Burden of Interactive Alignment with Inconsistent Preferences", "comment": "Published as a conference paper at NeurIPS 2025", "summary": "From media platforms to chatbots, algorithms shape how people interact,\nlearn, and discover information. Such interactions between users and an\nalgorithm often unfold over multiple steps, during which strategic users can\nguide the algorithm to better align with their true interests by selectively\nengaging with content. However, users frequently exhibit inconsistent\npreferences: they may spend considerable time on content that offers little\nlong-term value, inadvertently signaling that such content is desirable.\nFocusing on the user side, this raises a key question: what does it take for\nsuch users to align the algorithm with their true interests?\n  To investigate these dynamics, we model the user's decision process as split\nbetween a rational system 2 that decides whether to engage and an impulsive\nsystem 1 that determines how long engagement lasts. We then study a\nmulti-leader, single-follower extensive Stackelberg game, where users,\nspecifically system 2, lead by committing to engagement strategies and the\nalgorithm best-responds based on observed interactions. We define the burden of\nalignment as the minimum horizon over which users must optimize to effectively\nsteer the algorithm. We show that a critical horizon exists: users who are\nsufficiently foresighted can achieve alignment, while those who are not are\ninstead aligned to the algorithm's objective. This critical horizon can be\nlong, imposing a substantial burden. However, even a small, costly signal\n(e.g., an extra click) can significantly reduce it. Overall, our framework\nexplains how users with inconsistent preferences can align an engagement-driven\nalgorithm with their interests in a Stackelberg equilibrium, highlighting both\nthe challenges and potential remedies for achieving alignment.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u7528\u6237\u5728\u7b97\u6cd5\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u7b56\u7565\u6027\u884c\u4e3a\uff0c\u5efa\u7acb\u4e86\u7528\u6237\u4e0e\u7b97\u6cd5\u4e4b\u95f4\u7684Stackelberg\u535a\u5f08\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u7528\u6237\u9700\u8981\u8db3\u591f\u8fdc\u89c1\u624d\u80fd\u6709\u6548\u5f15\u5bfc\u7b97\u6cd5\u4e0e\u5176\u771f\u5b9e\u5174\u8da3\u5bf9\u9f50\uff0c\u5e76\u53d1\u73b0\u5c0f\u7684\u6210\u672c\u4fe1\u53f7\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u5bf9\u9f50\u8d1f\u62c5\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u7406\u89e3\u5728\u7528\u6237\u504f\u597d\u4e0d\u4e00\u81f4\u7684\u60c5\u51b5\u4e0b\uff0c\u7528\u6237\u5982\u4f55\u901a\u8fc7\u9009\u62e9\u6027\u4e92\u52a8\u6765\u5f15\u5bfc\u7b97\u6cd5\u66f4\u597d\u5730\u7b26\u5408\u5176\u771f\u5b9e\u5174\u8da3\u3002\u7528\u6237\u7ecf\u5e38\u8868\u73b0\u51fa\u4e0d\u4e00\u81f4\u7684\u504f\u597d\uff0c\u53ef\u80fd\u4f1a\u82b1\u8d39\u5927\u91cf\u65f6\u95f4\u5728\u4f4e\u4ef7\u503c\u5185\u5bb9\u4e0a\uff0c\u65e0\u610f\u4e2d\u5411\u7b97\u6cd5\u53d1\u9001\u9519\u8bef\u4fe1\u53f7\u3002", "method": "\u5c06\u7528\u6237\u7684\u51b3\u7b56\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u7406\u6027\u7cfb\u7edf2\uff08\u51b3\u5b9a\u662f\u5426\u53c2\u4e0e\uff09\u548c\u51b2\u52a8\u7cfb\u7edf1\uff08\u51b3\u5b9a\u53c2\u4e0e\u65f6\u957f\uff09\u7684\u5206\u88c2\u8fc7\u7a0b\u3002\u91c7\u7528\u591a\u9886\u5bfc\u8005\u3001\u5355\u8ddf\u968f\u8005\u7684\u6269\u5c55Stackelberg\u535a\u5f08\u6846\u67b6\uff0c\u7528\u6237\uff08\u7cfb\u7edf2\uff09\u901a\u8fc7\u627f\u8bfa\u53c2\u4e0e\u7b56\u7565\u6765\u9886\u5bfc\uff0c\u7b97\u6cd5\u57fa\u4e8e\u89c2\u5bdf\u5230\u7684\u4e92\u52a8\u505a\u51fa\u6700\u4f73\u54cd\u5e94\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5b58\u5728\u4e00\u4e2a\u5173\u952e\u7684\u5bf9\u9f50\u89c6\u91ce\uff1a\u8db3\u591f\u6709\u8fdc\u89c1\u7684\u7528\u6237\u53ef\u4ee5\u5b9e\u73b0\u7b97\u6cd5\u5bf9\u9f50\uff0c\u800c\u89c6\u91ce\u4e0d\u8db3\u7684\u7528\u6237\u53cd\u800c\u4f1a\u88ab\u7b97\u6cd5\u76ee\u6807\u6240\u5bf9\u9f50\u3002\u8fd9\u4e2a\u5173\u952e\u89c6\u91ce\u53ef\u80fd\u5f88\u957f\uff0c\u9020\u6210\u663e\u8457\u8d1f\u62c5\u3002\u4f46\u5373\u4f7f\u662f\u4e00\u4e2a\u5c0f\u7684\u6210\u672c\u4fe1\u53f7\uff08\u5982\u989d\u5916\u70b9\u51fb\uff09\u4e5f\u80fd\u663e\u8457\u51cf\u5c11\u5bf9\u9f50\u8d1f\u62c5\u3002", "conclusion": "\u8be5\u6846\u67b6\u89e3\u91ca\u4e86\u5177\u6709\u4e0d\u4e00\u81f4\u504f\u597d\u7684\u7528\u6237\u5982\u4f55\u5728Stackelberg\u5747\u8861\u4e2d\u4f7f\u53c2\u4e0e\u9a71\u52a8\u7684\u7b97\u6cd5\u4e0e\u5176\u5174\u8da3\u5bf9\u9f50\uff0c\u65e2\u7a81\u51fa\u4e86\u5b9e\u73b0\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u4e5f\u6307\u51fa\u4e86\u6f5c\u5728\u7684\u8865\u6551\u63aa\u65bd\u3002"}}
{"id": "2510.16229", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16229", "abs": "https://arxiv.org/abs/2510.16229", "authors": ["Vienna Li", "Justin Villa", "Dan Diessner", "Jayson Clifford", "Laxima Niure Kandel"], "title": "C/N0 Analysis-Based GPS Spoofing Detection with Variable Antenna Orientations", "comment": null, "summary": "GPS spoofing poses a growing threat to aviation by falsifying satellite\nsignals and misleading aircraft navigation systems. This paper demonstrates a\nproof-of-concept spoofing detection strategy based on analyzing satellite\nCarrier-to-Noise Density Ratio (C/N$_0$) variation during controlled static\nantenna orientations. Using a u-blox EVK-M8U receiver and a GPSG-1000 satellite\nsimulator, C/N$_0$ data is collected under three antenna orientations flat,\nbanked right, and banked left) in both real-sky (non-spoofed) and spoofed\nenvironments. Our findings reveal that under non-spoofed signals, C/N$_0$\nvalues fluctuate naturally with orientation, reflecting true geometric\ndependencies. However, spoofed signals demonstrate a distinct pattern: the flat\norientation, which directly faces the spoofing antenna, consistently yielded\nthe highest C/N$_0$ values, while both banked orientations showed reduced\nC/N$_0$ due to misalignment with the spoofing source. These findings suggest\nthat simple maneuvers such as brief banking to induce C/N$_0$ variations can\nprovide early cues of GPS spoofing for general aviation and UAV systems.", "AI": {"tldr": "\u901a\u8fc7\u5206\u6790\u5929\u7ebf\u4e0d\u540c\u671d\u5411\u4e0b\u7684\u536b\u661f\u8f7d\u6ce2\u566a\u58f0\u5bc6\u5ea6\u6bd4(C/N\u2080)\u53d8\u5316\uff0c\u63d0\u51fa\u4e86\u4e00\u79cdGPS\u6b3a\u9a97\u68c0\u6d4b\u65b9\u6cd5\u3002\u7814\u7a76\u53d1\u73b0\u6b3a\u9a97\u4fe1\u53f7\u5728\u5e73\u5766\u671d\u5411\u65f6C/N\u2080\u6700\u9ad8\uff0c\u800c\u5728\u503e\u659c\u671d\u5411\u65f6\u663e\u8457\u964d\u4f4e\uff0c\u8fd9\u79cd\u6a21\u5f0f\u53ef\u7528\u4e8e\u68c0\u6d4bGPS\u6b3a\u9a97\u3002", "motivation": "GPS\u6b3a\u9a97\u5bf9\u822a\u7a7a\u5b89\u5168\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u6765\u4fdd\u62a4\u98de\u673a\u5bfc\u822a\u7cfb\u7edf\u514d\u53d7\u8bef\u5bfc\u3002", "method": "\u4f7f\u7528u-blox EVK-M8U\u63a5\u6536\u5668\u548cGPSG-1000\u536b\u661f\u6a21\u62df\u5668\uff0c\u5728\u5e73\u5766\u3001\u53f3\u503e\u548c\u5de6\u503e\u4e09\u79cd\u5929\u7ebf\u671d\u5411\u6761\u4ef6\u4e0b\uff0c\u5206\u522b\u6536\u96c6\u771f\u5b9e\u5929\u7a7a\u4fe1\u53f7\u548c\u6b3a\u9a97\u4fe1\u53f7\u7684C/N\u2080\u6570\u636e\u3002", "result": "\u771f\u5b9e\u4fe1\u53f7\u4e0bC/N\u2080\u968f\u671d\u5411\u81ea\u7136\u6ce2\u52a8\uff0c\u800c\u6b3a\u9a97\u4fe1\u53f7\u5728\u5e73\u5766\u671d\u5411\u65f6C/N\u2080\u6700\u9ad8\uff0c\u503e\u659c\u671d\u5411\u65f6\u56e0\u4e0e\u6b3a\u9a97\u6e90\u4e0d\u5bf9\u9f50\u800cC/N\u2080\u964d\u4f4e\uff0c\u5448\u73b0\u660e\u663e\u4e0d\u540c\u7684\u6a21\u5f0f\u3002", "conclusion": "\u901a\u8fc7\u7b80\u5355\u7684\u673a\u52a8\u64cd\u4f5c\uff08\u5982\u77ed\u6682\u503e\u659c\uff09\u8bf1\u5bfcC/N\u2080\u53d8\u5316\uff0c\u53ef\u4ee5\u4e3a\u901a\u7528\u822a\u7a7a\u548c\u65e0\u4eba\u673a\u7cfb\u7edf\u63d0\u4f9bGPS\u6b3a\u9a97\u7684\u65e9\u671f\u68c0\u6d4b\u7ebf\u7d22\u3002"}}
{"id": "2510.16382", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16382", "abs": "https://arxiv.org/abs/2510.16382", "authors": ["Ze Tao", "Jian Zhang", "Haowei Li", "Xianshuai Li", "Yifei Peng", "Xiyao Liu", "Senzhang Wang", "Chao Liu", "Sheng Ren", "Shichao Zhang"], "title": "Humanoid-inspired Causal Representation Learning for Domain Generalization", "comment": null, "summary": "This paper proposes the Humanoid-inspired Structural Causal Model (HSCM), a\nnovel causal framework inspired by human intelligence, designed to overcome the\nlimitations of conventional domain generalization models. Unlike approaches\nthat rely on statistics to capture data-label dependencies and learn\ndistortion-invariant representations, HSCM replicates the hierarchical\nprocessing and multi-level learning of human vision systems, focusing on\nmodeling fine-grained causal mechanisms. By disentangling and reweighting key\nimage attributes such as color, texture, and shape, HSCM enhances\ngeneralization across diverse domains, ensuring robust performance and\ninterpretability. Leveraging the flexibility and adaptability of human\nintelligence, our approach enables more effective transfer and learning in\ndynamic, complex environments. Through both theoretical and empirical\nevaluations, we demonstrate that HSCM outperforms existing domain\ngeneralization models, providing a more principled method for capturing causal\nrelationships and improving model robustness. The code is available at\nhttps://github.com/lambett/HSCM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u53d7\u4eba\u7c7b\u667a\u80fd\u542f\u53d1\u7684\u7c7b\u4eba\u7ed3\u6784\u56e0\u679c\u6a21\u578b(HSCM)\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u56e0\u679c\u6846\u67b6\uff0c\u65e8\u5728\u514b\u670d\u4f20\u7edf\u9886\u57df\u6cdb\u5316\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002HSCM\u901a\u8fc7\u89e3\u8026\u548c\u91cd\u65b0\u52a0\u6743\u989c\u8272\u3001\u7eb9\u7406\u548c\u5f62\u72b6\u7b49\u5173\u952e\u56fe\u50cf\u5c5e\u6027\uff0c\u5728\u591a\u6837\u5316\u9886\u57df\u4e2d\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u9886\u57df\u6cdb\u5316\u6a21\u578b\u4f9d\u8d56\u7edf\u8ba1\u6570\u636e\u6355\u6349\u6570\u636e-\u6807\u7b7e\u4f9d\u8d56\u5173\u7cfb\u548c\u5b66\u4e60\u5931\u771f\u4e0d\u53d8\u8868\u793a\uff0c\u5b58\u5728\u5c40\u9650\u6027\u3002\u53d7\u4eba\u7c7b\u89c6\u89c9\u7cfb\u7edf\u7684\u5206\u5c42\u5904\u7406\u548c\u591a\u5c42\u6b21\u5b66\u4e60\u673a\u5236\u542f\u53d1\uff0c\u4f5c\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u4e2a\u66f4\u6709\u6548\u7684\u56e0\u679c\u6846\u67b6\u6765\u63d0\u5347\u6a21\u578b\u5728\u52a8\u6001\u590d\u6742\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "HSCM\u590d\u5236\u4eba\u7c7b\u89c6\u89c9\u7cfb\u7edf\u7684\u5206\u5c42\u5904\u7406\u548c\u591a\u5c42\u6b21\u5b66\u4e60\u673a\u5236\uff0c\u4e13\u6ce8\u4e8e\u5efa\u6a21\u7ec6\u7c92\u5ea6\u56e0\u679c\u673a\u5236\u3002\u901a\u8fc7\u89e3\u8026\u548c\u91cd\u65b0\u52a0\u6743\u5173\u952e\u56fe\u50cf\u5c5e\u6027\uff08\u989c\u8272\u3001\u7eb9\u7406\u3001\u5f62\u72b6\uff09\uff0c\u8be5\u65b9\u6cd5\u589e\u5f3a\u4e86\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u8bc1\u8bc4\u4f30\uff0cHSCM\u5728\u6027\u80fd\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u9886\u57df\u6cdb\u5316\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86\u66f4\u539f\u5219\u6027\u7684\u65b9\u6cd5\u6765\u6355\u6349\u56e0\u679c\u5173\u7cfb\u5e76\u63d0\u9ad8\u6a21\u578b\u9c81\u68d2\u6027\u3002", "conclusion": "HSCM\u6846\u67b6\u901a\u8fc7\u6a21\u4eff\u4eba\u7c7b\u667a\u80fd\u7684\u7075\u6d3b\u6027\u548c\u9002\u5e94\u6027\uff0c\u5728\u52a8\u6001\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u7684\u8fc1\u79fb\u548c\u5b66\u4e60\uff0c\u4e3a\u9886\u57df\u6cdb\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.15926", "categories": ["cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15926", "abs": "https://arxiv.org/abs/2510.15926", "authors": ["Ye Qiao", "Zhiheng Chen", "Yifan Zhang", "Yian Wang", "Sitao Huang"], "title": "TeLLMe v2: An Efficient End-to-End Ternary LLM Prefill and Decode Accelerator with Table-Lookup Matmul on Edge FPGAs", "comment": null, "summary": "With the emergence of wearable devices and other embedded systems, deploying\nlarge language models (LLMs) on edge platforms has become an urgent need.\nHowever, this is challenging because of their high computational and memory\ndemands. Although recent low-bit quantization methods (e.g., BitNet, DeepSeek)\ncompress weights to as low as 1.58~bits with minimal accuracy loss, edge\ndeployment is still constrained by limited on-chip resources, power budgets,\nand the often-neglected long latency of the prefill stage. We present\n\\textbf{TeLLMe}, the first table-lookup-based ternary LLM accelerator for\nlow-power edge FPGAs that fully supports both prefill and autoregressive\ndecoding using 1.58-bit weights and 8-bit activations. TeLLMe incorporates\nseveral novel techniques, including (1) a table-lookup-based ternary matrix\nmultiplication (TLMM) engine utilizing grouped activations and online\nprecomputation for low resource utilization and high throughput; (2) a\nfine-grained analytic URAM-based weight buffer management scheme for efficient\nloading and compute engine access; (3) a streaming dataflow architecture that\nfuses floating-point element-wise operations with linear computations to hide\nlatency; (4) a reversed-reordered prefill stage attention with fused attention\noperations for high memory efficiency; and (5) a resource-efficient specialized\ndecoding stage attention. Under a 5~W power budget, TeLLMe delivers up to\n25~tokens/s decoding throughput and 0.45--0.96~s time-to-first-token (TTFT) for\n64--128 token prompts, marking a significant energy-efficiency advancement in\nLLM inference on edge FPGAs.", "AI": {"tldr": "TeLLMe\u662f\u4e00\u79cd\u57fa\u4e8e\u67e5\u8868\u76841.58\u4f4d\u4e09\u5143LLM\u52a0\u901f\u5668\uff0c\u4e13\u4e3a\u4f4e\u529f\u8017\u8fb9\u7f18FPGA\u8bbe\u8ba1\uff0c\u652f\u6301\u9884\u586b\u5145\u548c\u81ea\u56de\u5f52\u89e3\u7801\uff0c\u57285W\u529f\u8017\u4e0b\u5b9e\u73b0\u9ad8\u8fbe25 tokens/s\u7684\u89e3\u7801\u541e\u5410\u91cf\u3002", "motivation": "\u968f\u7740\u53ef\u7a7f\u6234\u8bbe\u5907\u548c\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u666e\u53ca\uff0c\u5728\u8fb9\u7f18\u5e73\u53f0\u4e0a\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9700\u6c42\u65e5\u76ca\u8feb\u5207\uff0c\u4f46\u53d7\u9650\u4e8e\u8ba1\u7b97\u8d44\u6e90\u3001\u5185\u5b58\u9700\u6c42\u548c\u9884\u586b\u5145\u9636\u6bb5\u7684\u957f\u5ef6\u8fdf\u3002", "method": "\u91c7\u7528\u8868\u67e5\u627e\u4e09\u5143\u77e9\u9635\u4e58\u6cd5\u5f15\u64ce\u3001\u7ec6\u7c92\u5ea6URAM\u6743\u91cd\u7f13\u51b2\u7ba1\u7406\u3001\u6d41\u5f0f\u6570\u636e\u6d41\u67b6\u6784\u3001\u53cd\u5411\u91cd\u6392\u5e8f\u9884\u586b\u5145\u6ce8\u610f\u529b\u4ee5\u53ca\u4e13\u7528\u89e3\u7801\u9636\u6bb5\u6ce8\u610f\u529b\u7b49\u6280\u672f\u3002", "result": "\u57285W\u529f\u8017\u9884\u7b97\u4e0b\uff0cTeLLMe\u5b9e\u73b0\u9ad8\u8fbe25 tokens/s\u7684\u89e3\u7801\u541e\u5410\u91cf\uff0c64-128 token\u63d0\u793a\u7684\u9996\u6b21token\u65f6\u95f4\u57280.45-0.96\u79d2\u4e4b\u95f4\u3002", "conclusion": "TeLLMe\u5728\u8fb9\u7f18FPGA\u4e0a\u7684LLM\u63a8\u7406\u80fd\u6548\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u6b65\uff0c\u4e3a\u4f4e\u529f\u8017\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72LLM\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.16466", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16466", "abs": "https://arxiv.org/abs/2510.16466", "authors": ["Siddhartha Krothapalli", "Tridib Kumar Das", "Praveen Kumar", "Naveen Suravarpu", "Pratik Narang"], "title": "ReviewSense: Transforming Customer Review Dynamics into Actionable Business Insights", "comment": "11 pages, 1 figure, 4 tables", "summary": "As customer feedback becomes increasingly central to strategic growth, the\nability to derive actionable insights from unstructured reviews is essential.\nWhile traditional AI-driven systems excel at predicting user preferences, far\nless work has focused on transforming customer reviews into prescriptive,\nbusiness-facing recommendations. This paper introduces ReviewSense, a novel\nprescriptive decision support framework that leverages advanced large language\nmodels (LLMs) to transform customer reviews into targeted, actionable business\nrecommendations. By identifying key trends, recurring issues, and specific\nconcerns within customer sentiments, ReviewSense extends beyond\npreference-based systems to provide businesses with deeper insights for\nsustaining growth and enhancing customer loyalty. The novelty of this work lies\nin integrating clustering, LLM adaptation, and expert-driven evaluation into a\nunified, business-facing pipeline. Preliminary manual evaluations indicate\nstrong alignment between the model's recommendations and business objectives,\nhighlighting its potential for driving data-informed decision-making. This\nframework offers a new perspective on AI-driven sentiment analysis,\ndemonstrating its value in refining business strategies and maximizing the\nimpact of customer feedback.", "AI": {"tldr": "ReviewSense\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u51b3\u7b56\u652f\u6301\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c06\u5ba2\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u4f01\u4e1a\u5efa\u8bae\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u504f\u597d\u9884\u6d4b\u7cfb\u7edf\u3002", "motivation": "\u968f\u7740\u5ba2\u6237\u53cd\u9988\u5728\u6218\u7565\u589e\u957f\u4e2d\u65e5\u76ca\u91cd\u8981\uff0c\u9700\u8981\u4ece\u975e\u7ed3\u6784\u5316\u8bc4\u8bba\u4e2d\u63d0\u53d6\u53ef\u64cd\u4f5c\u89c1\u89e3\u3002\u4f20\u7edfAI\u7cfb\u7edf\u64c5\u957f\u9884\u6d4b\u7528\u6237\u504f\u597d\uff0c\u4f46\u7f3a\u4e4f\u5c06\u8bc4\u8bba\u8f6c\u5316\u4e3a\u9762\u5411\u4f01\u4e1a\u7684\u89c4\u8303\u6027\u5efa\u8bae\u7684\u80fd\u529b\u3002", "method": "\u6574\u5408\u805a\u7c7b\u3001LLM\u9002\u914d\u548c\u4e13\u5bb6\u9a71\u52a8\u8bc4\u4f30\u7684\u7edf\u4e00\u4e1a\u52a1\u5bfc\u5411\u6d41\u7a0b\uff0c\u901a\u8fc7\u8bc6\u522b\u5173\u952e\u8d8b\u52bf\u3001\u91cd\u590d\u95ee\u9898\u548c\u5177\u4f53\u5173\u6ce8\u70b9\u6765\u8f6c\u6362\u5ba2\u6237\u60c5\u611f\u3002", "result": "\u521d\u6b65\u4eba\u5de5\u8bc4\u4f30\u663e\u793a\u6a21\u578b\u5efa\u8bae\u4e0e\u4e1a\u52a1\u76ee\u6807\u9ad8\u5ea6\u4e00\u81f4\uff0c\u7a81\u663e\u5176\u5728\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aAI\u9a71\u52a8\u7684\u60c5\u611f\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5c55\u793a\u4e86\u5176\u5728\u4f18\u5316\u4e1a\u52a1\u7b56\u7565\u548c\u6700\u5927\u5316\u5ba2\u6237\u53cd\u9988\u5f71\u54cd\u65b9\u9762\u7684\u4ef7\u503c\u3002"}}
{"id": "2510.16331", "categories": ["cs.CR", "cs.CC"], "pdf": "https://arxiv.org/pdf/2510.16331", "abs": "https://arxiv.org/abs/2510.16331", "authors": ["Fatemeh Jafarian Dehkordi", "Elahe Vedadi", "Alireza Feizbakhsh", "Yasaman Keshtkarjahromi", "Hulya Seferoglu"], "title": "Efficient and Privacy-Preserving Binary Dot Product via Multi-Party Computation", "comment": null, "summary": "Striking a balance between protecting data privacy and enabling collaborative\ncomputation is a critical challenge for distributed machine learning. While\nprivacy-preserving techniques for federated learning have been extensively\ndeveloped, methods for scenarios involving bitwise operations, such as\ntree-based vertical federated learning (VFL), are still underexplored.\nTraditional mechanisms, including Shamir's secret sharing and multi-party\ncomputation (MPC), are not optimized for bitwise operations over binary data,\nparticularly in settings where each participant holds a different part of the\nbinary vector. This paper addresses the limitations of existing methods by\nproposing a novel binary multi-party computation (BiMPC) framework. The BiMPC\nmechanism facilitates privacy-preserving bitwise operations, with a particular\nfocus on dot product computations of binary vectors, ensuring the privacy of\neach individual bit. The core of BiMPC is a novel approach called Dot Product\nvia Modular Addition (DoMA), which uses regular and modular additions for\nefficient binary dot product calculation. To ensure privacy, BiMPC uses random\nmasking in a higher field for linear computations and a three-party oblivious\ntransfer (triot) protocol for non-linear binary operations. The privacy\nguarantees of the BiMPC framework are rigorously analyzed, demonstrating its\nefficiency and scalability in distributed settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e8c\u8fdb\u5236\u591a\u65b9\u8ba1\u7b97\uff08BiMPC\uff09\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9\u6811\u578b\u5782\u76f4\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6309\u4f4d\u64cd\u4f5c\u8fdb\u884c\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u5728\u4e8c\u8fdb\u5236\u6570\u636e\u64cd\u4f5c\u4e0a\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5728\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u5982\u4f55\u5728\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u534f\u4f5c\u8ba1\u7b97\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002\u867d\u7136\u8054\u90a6\u5b66\u4e60\u7684\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u5df2\u5f97\u5230\u5e7f\u6cdb\u53d1\u5c55\uff0c\u4f46\u9488\u5bf9\u6309\u4f4d\u64cd\u4f5c\u573a\u666f\uff08\u5982\u57fa\u4e8e\u6811\u7684\u5782\u76f4\u8054\u90a6\u5b66\u4e60\uff09\u7684\u65b9\u6cd5\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u4f20\u7edf\u7684Shamir\u79d8\u5bc6\u5171\u4eab\u548c\u591a\u65b9\u8ba1\u7b97\u673a\u5236\u5e76\u672a\u9488\u5bf9\u4e8c\u8fdb\u5236\u6570\u636e\u7684\u6309\u4f4d\u64cd\u4f5c\u8fdb\u884c\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u4e86BiMPC\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u540d\u4e3aDoMA\uff08\u901a\u8fc7\u6a21\u52a0\u6cd5\u8fdb\u884c\u70b9\u79ef\u8ba1\u7b97\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u4f7f\u7528\u5e38\u89c4\u52a0\u6cd5\u548c\u6a21\u52a0\u6cd5\u8fdb\u884c\u9ad8\u6548\u7684\u4e8c\u8fdb\u5236\u70b9\u79ef\u8ba1\u7b97\u3002\u4e3a\u786e\u4fdd\u9690\u79c1\uff0cBiMPC\u5728\u66f4\u9ad8\u57df\u4e2d\u4f7f\u7528\u968f\u673a\u63a9\u7801\u8fdb\u884c\u7ebf\u6027\u8ba1\u7b97\uff0c\u5e76\u4f7f\u7528\u4e09\u65b9\u4e0d\u7ecf\u610f\u4f20\u8f93\u534f\u8bae\u8fdb\u884c\u975e\u7ebf\u6027\u4e8c\u8fdb\u5236\u64cd\u4f5c\u3002", "result": "\u5bf9BiMPC\u6846\u67b6\u7684\u9690\u79c1\u4fdd\u8bc1\u8fdb\u884c\u4e86\u4e25\u683c\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "BiMPC\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u4e8c\u8fdb\u5236\u6309\u4f4d\u64cd\u4f5c\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u6811\u578b\u5782\u76f4\u8054\u90a6\u5b66\u4e60\u7b49\u573a\u666f\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.16476", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16476", "abs": "https://arxiv.org/abs/2510.16476", "authors": ["Xiaozhe Li", "Xinyu Fang", "Shengyuan Ding", "Linyang Li", "Haodong Duan", "Qingwen Liu", "Kai Chen"], "title": "NP-Engine: Empowering Optimization Reasoning in Large Language Models with Verifiable Synthetic NP Problems", "comment": null, "summary": "Large Language Models (LLMs) have shown strong reasoning capabilities, with\nmodels like OpenAI's O-series and DeepSeek R1 excelling at tasks such as\nmathematics, coding, logic, and puzzles through Reinforcement Learning with\nVerifiable Rewards (RLVR). However, their ability to solve more complex\noptimization problems - particularly NP-hard tasks - remains underexplored. To\nbridge this gap, we propose NP-ENGINE, the first comprehensive framework for\ntraining and evaluating LLMs on NP-hard problems. NP-ENGINE covers 10 tasks\nacross five domains, each equipped with (i) a controllable instance generator,\n(ii) a rule-based verifier, and (iii) a heuristic solver that provides\napproximate optimal solutions as ground truth. This\ngenerator-verifier-heuristic pipeline enables scalable and verifiable RLVR\ntraining under hierarchical difficulties. We also introduce NP-BENCH, a\nbenchmark derived from NP-ENGINE-DATA, specifically designed to evaluate LLMs'\nability to tackle NP-hard level reasoning problems, focusing not only on\nfeasibility but also on solution quality. Additionally, we present\nQWEN2.5-7B-NP, a model trained via zero-RLVR with curriculum learning on\nQwen2.5-7B-Instruct, which significantly outperforms GPT-4o on NP-BENCH and\nachieves SOTA performance with the same model size. Beyond in-domain tasks, we\ndemonstrate that RLVR training on NP-ENGINE-DATA enables strong out-of-domain\n(OOD) generalization to reasoning tasks (logic, puzzles, math, and knowledge),\nas well as non-reasoning tasks such as instruction following. We also observe a\nscaling trend: increasing task diversity improves OOD generalization. These\nfindings suggest that task-rich RLVR training is a promising direction for\nadvancing LLM's reasoning ability, revealing new insights into the scaling laws\nof RLVR.", "AI": {"tldr": "\u63d0\u51fa\u4e86NP-ENGINE\u6846\u67b6\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u7528\u4e8e\u5728NP\u96be\u95ee\u9898\u4e0a\u8bad\u7ec3\u548c\u8bc4\u4f30LLM\u7684\u7efc\u5408\u6846\u67b6\uff0c\u5305\u542b10\u4e2a\u4efb\u52a1\u3001\u53ef\u63a7\u5b9e\u4f8b\u751f\u6210\u5668\u3001\u89c4\u5219\u9a8c\u8bc1\u5668\u548c\u542f\u53d1\u5f0f\u6c42\u89e3\u5668\u3002\u8bad\u7ec3\u51fa\u7684\u6a21\u578b\u5728NP-BENCH\u57fa\u51c6\u4e0a\u8d85\u8d8aGPT-4o\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u3001\u7f16\u7a0b\u7b49\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u89e3\u51b3\u66f4\u590d\u6742\u7684NP\u96be\u4f18\u5316\u95ee\u9898\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u4e13\u95e8\u7684\u6846\u67b6\u6765\u8bad\u7ec3\u548c\u8bc4\u4f30LLM\u5728\u8fd9\u7c7b\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51faNP-ENGINE\u6846\u67b6\uff0c\u5305\u542b10\u4e2a\u4efb\u52a1\u3001\u53ef\u63a7\u5b9e\u4f8b\u751f\u6210\u5668\u3001\u89c4\u5219\u9a8c\u8bc1\u5668\u548c\u542f\u53d1\u5f0f\u6c42\u89e3\u5668\u3002\u4f7f\u7528\u96f6RLVR\u548c\u8bfe\u7a0b\u5b66\u4e60\u8bad\u7ec3QWEN2.5-7B-NP\u6a21\u578b\u3002", "result": "QWEN2.5-7B-NP\u5728NP-BENCH\u57fa\u51c6\u4e0a\u663e\u8457\u8d85\u8d8aGPT-4o\uff0c\u8fbe\u5230\u540c\u6a21\u578b\u5c3a\u5bf8\u4e0b\u7684SOTA\u6027\u80fd\u3002RLVR\u8bad\u7ec3\u8fd8\u4f7f\u6a21\u578b\u5728\u903b\u8f91\u3001\u8c1c\u9898\u3001\u6570\u5b66\u7b49\u63a8\u7406\u4efb\u52a1\u4ee5\u53ca\u6307\u4ee4\u8ddf\u968f\u7b49\u975e\u63a8\u7406\u4efb\u52a1\u4e0a\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u4efb\u52a1\u4e30\u5bcc\u7684RLVR\u8bad\u7ec3\u662f\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u7684\u6709\u524d\u666f\u65b9\u5411\uff0c\u63ed\u793a\u4e86RLVR\u7684\u6269\u5c55\u89c4\u5f8b\u3002\u589e\u52a0\u4efb\u52a1\u591a\u6837\u6027\u53ef\u4ee5\u6539\u5584\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.16367", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16367", "abs": "https://arxiv.org/abs/2510.16367", "authors": ["Shuai Li", "Kejiang Chen", "Jun Jiang", "Jie Zhang", "Qiyi Yao", "Kai Zeng", "Weiming Zhang", "Nenghai Yu"], "title": "EditMark: Watermarking Large Language Models based on Model Editing", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities, but\ntheir training requires extensive data and computational resources, rendering\nthem valuable digital assets. Therefore, it is essential to watermark LLMs to\nprotect their copyright and trace unauthorized use or resale. Existing methods\nfor watermarking LLMs primarily rely on training LLMs with a watermarked\ndataset, which entails burdensome training costs and negatively impacts the\nLLM's performance. In addition, their watermarked texts are not logical or\nnatural, thereby reducing the stealthiness of the watermark. To address these\nissues, we propose EditMark, the first watermarking method that leverages model\nediting to embed a training-free, stealthy, and performance-lossless watermark\nfor LLMs. We observe that some questions have multiple correct answers.\nTherefore, we assign each answer a unique watermark and update the weights of\nLLMs to generate corresponding questions and answers through the model editing\ntechnique. In addition, we refine the model editing technique to align with the\nrequirements of watermark embedding. Specifically, we introduce an adaptive\nmulti-round stable editing strategy, coupled with the injection of a noise\nmatrix, to improve both the effectiveness and robustness of the watermark\nembedding. Extensive experiments indicate that EditMark can embed 32-bit\nwatermarks into LLMs within 20 seconds (Fine-tuning: 6875 seconds) with a\nwatermark extraction success rate of 100%, which demonstrates its effectiveness\nand efficiency. External experiments further demonstrate that EditMark has\nfidelity, stealthiness, and a certain degree of robustness against common\nattacks.", "AI": {"tldr": "EditMark\u662f\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u7f16\u8f91\u7684LLM\u6c34\u5370\u65b9\u6cd5\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u5d4c\u5165\u9690\u5f62\u4e14\u65e0\u635f\u6027\u80fd\u7684\u6c34\u5370\uff0c\u901a\u8fc7\u591a\u8f6e\u7a33\u5b9a\u7f16\u8f91\u7b56\u7565\u548c\u566a\u58f0\u77e9\u9635\u6ce8\u5165\u63d0\u9ad8\u6c34\u5370\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709LLM\u6c34\u5370\u65b9\u6cd5\u9700\u8981\u8bad\u7ec3\u6c34\u5370\u6570\u636e\u96c6\uff0c\u5bfc\u81f4\u9ad8\u6602\u7684\u8bad\u7ec3\u6210\u672c\u5e76\u5f71\u54cd\u6a21\u578b\u6027\u80fd\uff0c\u4e14\u6c34\u5370\u6587\u672c\u4e0d\u591f\u81ea\u7136\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u9690\u5f62\u4e14\u4e0d\u5f71\u54cd\u6027\u80fd\u7684\u6c34\u5370\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u6a21\u578b\u7f16\u8f91\u6280\u672f\uff0c\u4e3a\u591a\u7b54\u6848\u95ee\u9898\u5206\u914d\u552f\u4e00\u6c34\u5370\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u591a\u8f6e\u7a33\u5b9a\u7f16\u8f91\u7b56\u7565\u548c\u566a\u58f0\u77e9\u9635\u6ce8\u5165\u6765\u66f4\u65b0LLM\u6743\u91cd\uff0c\u5b9e\u73b0\u6c34\u5370\u5d4c\u5165\u3002", "result": "\u572820\u79d2\u5185\u5d4c\u516532\u4f4d\u6c34\u5370\uff08\u5fae\u8c03\u97006875\u79d2\uff09\uff0c\u6c34\u5370\u63d0\u53d6\u6210\u529f\u7387\u8fbe100%\uff0c\u5177\u6709\u826f\u597d\u7684\u4fdd\u771f\u5ea6\u3001\u9690\u5f62\u6027\u548c\u5bf9\u5e38\u89c1\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "EditMark\u662f\u9996\u4e2a\u57fa\u4e8e\u6a21\u578b\u7f16\u8f91\u7684LLM\u6c34\u5370\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u8bad\u7ec3\u3001\u9690\u5f62\u4e14\u65e0\u635f\u6027\u80fd\u7684\u6c34\u5370\u5d4c\u5165\uff0c\u5728\u6548\u7387\u548c\u6548\u679c\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2510.16040", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16040", "abs": "https://arxiv.org/abs/2510.16040", "authors": ["Tianhua Xia", "Sai Qian Zhang"], "title": "Kelle: Co-design KV Caching and eDRAM for Efficient LLM Serving in Edge Computing", "comment": null, "summary": "Running Large Language Models (LLMs) on edge devices is crucial for reducing\nlatency, improving real-time processing, and enhancing privacy. By performing\ninference directly on the device, data does not need to be sent to the cloud,\nensuring faster responses and reducing reliance on network connectivity.\nHowever, implementing LLMs on edge devices presents challenges, particularly\nwith managing key-value (KV) caches, which plays a pivotal role in LLM serving.\nAs the input text lengthens, the size of the KV cache increases linearly with\nthe sequence length, leading to a significant memory footprint and data access\ncosts. On the other hand, edge devices have limited memory and computational\npower, making it hard to store and efficiently access the large caches needed\nfor LLM inference.\n  To mitigate the substantial overhead caused by KV cache, we propose using\nembedded DRAM (eDRAM) as the primary storage for LLM serving in edge device,\nwhich offers higher storage density compared to SRAM. However, to ensure data\nintegrity, eDRAM needs periodic refresh operations, which are power-intensive.\nTo reduce eDRAM costs and improve overall system performance, we\npropose~\\textit{Kelle}, a software-hardware co-design solution optimized for\ndeploying LLMs on eDRAM-based edge systems. Combined with our fine-grained\nmemory eviction, recomputation, and refresh control algorithms, the\n\\textit{Kelle} accelerator delivers a $3.9\\times$ speedup and $4.5\\times$\nenergy savings compared to existing baseline solutions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faKelle\u7cfb\u7edf\uff0c\u4e00\u79cd\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u5728\u57fa\u4e8eeDRAM\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u9ad8\u6548\u8fd0\u884c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u4f18\u5316KV\u7f13\u5b58\u7ba1\u7406\u5b9e\u73b03.9\u500d\u52a0\u901f\u548c4.5\u500d\u80fd\u8017\u8282\u7701\u3002", "motivation": "\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8fd0\u884cLLM\u53ef\u964d\u4f4e\u5ef6\u8fdf\u3001\u63d0\u9ad8\u5b9e\u65f6\u5904\u7406\u80fd\u529b\u5e76\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4\uff0c\u4f46KV\u7f13\u5b58\u7684\u5185\u5b58\u5360\u7528\u548c\u6570\u636e\u8bbf\u95ee\u6210\u672c\u9650\u5236\u4e86\u5176\u90e8\u7f72\u3002\u8fb9\u7f18\u8bbe\u5907\u5185\u5b58\u548c\u8ba1\u7b97\u80fd\u529b\u6709\u9650\uff0c\u96be\u4ee5\u5b58\u50a8\u548c\u9ad8\u6548\u8bbf\u95eeLLM\u63a8\u7406\u6240\u9700\u7684\u5927\u7f13\u5b58\u3002", "method": "\u63d0\u51fa\u4f7f\u7528eDRAM\u4f5c\u4e3a\u8fb9\u7f18\u8bbe\u5907LLM\u670d\u52a1\u7684\u4e3b\u8981\u5b58\u50a8\uff0c\u7ed3\u5408\u7ec6\u7c92\u5ea6\u5185\u5b58\u9a71\u9010\u3001\u91cd\u8ba1\u7b97\u548c\u5237\u65b0\u63a7\u5236\u7b97\u6cd5\uff0c\u5f00\u53d1Kelle\u52a0\u901f\u5668\u8fdb\u884c\u8f6f\u786c\u4ef6\u534f\u540c\u4f18\u5316\u3002", "result": "Kelle\u52a0\u901f\u5668\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u89e3\u51b3\u65b9\u6848\u5b9e\u73b0\u4e863.9\u500d\u52a0\u901f\u548c4.5\u500d\u80fd\u8017\u8282\u7701\u3002", "conclusion": "Kelle\u7cfb\u7edf\u901a\u8fc7\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e0aLLM\u90e8\u7f72\u7684KV\u7f13\u5b58\u7ba1\u7406\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u80fd\u6548\u3002"}}
{"id": "2510.16487", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.16487", "abs": "https://arxiv.org/abs/2510.16487", "authors": ["Giovanni Agosta", "Stefano Cherubin", "Derek Christ", "Francesco Conti", "Asbj\u00f8rn Djupdal", "Matthias Jung", "Georgios Keramidas", "Roberto Passerone", "Paolo Rech", "Elisa Ricci", "Philippe Velha", "Flavio Vella", "Kasim Sinan Yildirim", "Nils Wilbert"], "title": "Architecture, Simulation and Software Stack to Support Post-CMOS Accelerators: The ARCHYTAS Project", "comment": null, "summary": "ARCHYTAS aims to design and evaluate non-conventional hardware accelerators,\nin particular, optoelectronic, volatile and non-volatile processing-in-memory,\nand neuromorphic, to tackle the power, efficiency, and scalability bottlenecks\nof AI with an emphasis on defense use cases (e.g., autonomous vehicles,\nsurveillance drones, maritime and space platforms). In this paper, we present\nthe system architecture and software stack that ARCHYTAS will develop to\nintegrate and support those accelerators, as well as the simulation software\nneeded for early prototyping of the full system and its components.", "AI": {"tldr": "ARCHYTAS\u9879\u76ee\u65e8\u5728\u8bbe\u8ba1\u548c\u8bc4\u4f30\u975e\u5e38\u89c4\u786c\u4ef6\u52a0\u901f\u5668\uff0c\u5305\u62ec\u5149\u7535\u3001\u6613\u5931\u6027\u548c\u975e\u6613\u5931\u6027\u5185\u5b58\u8ba1\u7b97\u4ee5\u53ca\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\uff0c\u4ee5\u89e3\u51b3AI\u7684\u529f\u8017\u3001\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u74f6\u9888\uff0c\u7279\u522b\u5173\u6ce8\u56fd\u9632\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u89e3\u51b3AI\u5728\u529f\u8017\u3001\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u7684\u74f6\u9888\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u56fd\u9632\u5e94\u7528\u573a\u666f\u5982\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u3001\u76d1\u63a7\u65e0\u4eba\u673a\u3001\u6d77\u4e0a\u548c\u592a\u7a7a\u5e73\u53f0\u4e2d\u3002", "method": "\u5f00\u53d1\u7cfb\u7edf\u67b6\u6784\u548c\u8f6f\u4ef6\u5806\u6808\u6765\u96c6\u6210\u548c\u652f\u6301\u8fd9\u4e9b\u52a0\u901f\u5668\uff0c\u5e76\u5f00\u53d1\u7528\u4e8e\u5168\u7cfb\u7edf\u53ca\u5176\u7ec4\u4ef6\u65e9\u671f\u539f\u578b\u8bbe\u8ba1\u7684\u4eff\u771f\u8f6f\u4ef6\u3002", "result": "\u63d0\u51fa\u4e86ARCHYTAS\u9879\u76ee\u7684\u6574\u4f53\u67b6\u6784\u65b9\u6848\uff0c\u5305\u62ec\u786c\u4ef6\u52a0\u901f\u5668\u96c6\u6210\u6846\u67b6\u548c\u4eff\u771f\u5de5\u5177\u94fe\u3002", "conclusion": "\u901a\u8fc7\u5f00\u53d1\u4e13\u95e8\u7684\u7cfb\u7edf\u67b6\u6784\u548c\u4eff\u771f\u8f6f\u4ef6\uff0cARCHYTAS\u9879\u76ee\u5c06\u4e3a\u975e\u5e38\u89c4\u786c\u4ef6\u52a0\u901f\u5668\u5728\u56fd\u9632AI\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u63d0\u4f9b\u5b8c\u6574\u7684\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2510.16544", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16544", "abs": "https://arxiv.org/abs/2510.16544", "authors": ["Weijie Chen", "Shan Tang", "Yulin Tang", "Xiapu Luo", "Yinqian Zhang", "Weizhong Qiang"], "title": "$\u03c1$Hammer: Reviving RowHammer Attacks on New Architectures via Prefetching", "comment": "Accepted for publication in the 58th IEEE/ACM International Symposium\n  on Microarchitecture (MICRO '25). This is the author's version of the paper", "summary": "Rowhammer is a critical vulnerability in dynamic random access memory (DRAM)\nthat continues to pose a significant threat to various systems. However, we\nfind that conventional load-based attacks are becoming highly ineffective on\nthe most recent architectures such as Intel Alder and Raptor Lake. In this\npaper, we present $\\rho$Hammer, a new Rowhammer framework that systematically\novercomes three core challenges impeding attacks on these new architectures.\nFirst, we design an efficient and generic DRAM address mapping\nreverse-engineering method that uses selective pairwise measurements and\nstructured deduction, enabling recovery of complex mappings within seconds on\nthe latest memory controllers. Second, to break through the activation rate\nbottleneck of load-based hammering, we introduce a novel prefetch-based\nhammering paradigm that leverages the asynchronous nature of x86 prefetch\ninstructions and is further enhanced by multi-bank parallelism to maximize\nthroughput. Third, recognizing that speculative execution causes more severe\ndisorder issues for prefetching, which cannot be simply mitigated by memory\nbarriers, we develop a counter-speculation hammering technique using\ncontrol-flow obfuscation and optimized NOP-based pseudo-barriers to maintain\nprefetch order with minimal overhead. Evaluations across four latest Intel\narchitectures demonstrate $\\rho$Hammer's breakthrough effectiveness: it induces\nup to 200K+ additional bit flips within 2-hour attack pattern fuzzing processes\nand has a 112x higher flip rate than the load-based hammering baselines on\nComet and Rocket Lake. Also, we are the first to revive Rowhammer attacks on\nthe latest Raptor Lake architecture, where baselines completely fail, achieving\nstable flip rates of 2,291/min and fast end-to-end exploitation.", "AI": {"tldr": "\u03c1Hammer\u662f\u4e00\u4e2a\u65b0\u7684Rowhammer\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7DRAM\u5730\u5740\u6620\u5c04\u9006\u5411\u5de5\u7a0b\u3001\u9884\u53d6\u5f0f\u9524\u51fb\u548c\u53cd\u63a8\u6d4b\u9524\u51fb\u6280\u672f\uff0c\u6210\u529f\u7a81\u7834\u4e86\u6700\u65b0Intel\u67b6\u6784\u7684\u9632\u62a4\uff0c\u5728Raptor Lake\u7b49\u6700\u65b0\u5e73\u53f0\u4e0a\u5b9e\u73b0\u4e86\u7a33\u5b9a\u7684\u6bd4\u7279\u7ffb\u8f6c\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u8d1f\u8f7d\u7684Rowhammer\u653b\u51fb\u5728\u6700\u65b0Intel\u67b6\u6784\uff08\u5982Alder Lake\u548cRaptor Lake\uff09\u4e0a\u53d8\u5f97\u65e0\u6548\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u653b\u51fb\u65b9\u6cd5\u6765\u514b\u670d\u5730\u5740\u6620\u5c04\u590d\u6742\u5316\u3001\u6fc0\u6d3b\u7387\u74f6\u9888\u548c\u63a8\u6d4b\u6267\u884c\u5e72\u6270\u7b49\u6838\u5fc3\u6311\u6218\u3002", "method": "1) \u4f7f\u7528\u9009\u62e9\u6027\u6210\u5bf9\u6d4b\u91cf\u548c\u7ed3\u6784\u5316\u63a8\u8bba\u7684DRAM\u5730\u5740\u6620\u5c04\u9006\u5411\u5de5\u7a0b\u65b9\u6cd5\uff1b2) \u57fa\u4e8e\u9884\u53d6\u6307\u4ee4\u7684\u5f02\u6b65\u9524\u51fb\u8303\u5f0f\uff0c\u7ed3\u5408\u591abank\u5e76\u884c\u5316\uff1b3) \u5229\u7528\u63a7\u5236\u6d41\u6df7\u6dc6\u548c\u4f18\u5316\u7684NOP\u4f2a\u5c4f\u969c\u7684\u53cd\u63a8\u6d4b\u9524\u51fb\u6280\u672f\u3002", "result": "\u5728\u56db\u4e2a\u6700\u65b0Intel\u67b6\u6784\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff1a\u57282\u5c0f\u65f6\u653b\u51fb\u6a21\u5f0f\u6a21\u7cca\u6d4b\u8bd5\u4e2d\u8bf1\u5bfc\u8d85\u8fc720\u4e07\u989d\u5916\u6bd4\u7279\u7ffb\u8f6c\uff0c\u5728Comet\u548cRocket Lake\u4e0a\u7684\u7ffb\u8f6c\u7387\u6bd4\u57fa\u7ebf\u9ad8112\u500d\uff0c\u9996\u6b21\u5728Raptor Lake\u4e0a\u5b9e\u73b0\u7a33\u5b9a\u7ffb\u8f6c\u7387\uff082,291/\u5206\u949f\uff09\u548c\u7aef\u5230\u7aef\u5229\u7528\u3002", "conclusion": "\u03c1Hammer\u6846\u67b6\u6210\u529f\u514b\u670d\u4e86\u6700\u65b0Intel\u67b6\u6784\u7684Rowhammer\u9632\u62a4\u673a\u5236\uff0c\u8bc1\u660e\u4e86\u5373\u4f7f\u5728\u6700\u65b0\u786c\u4ef6\u4e0a\uff0cRowhammer\u5a01\u80c1\u4ecd\u7136\u5b58\u5728\u4e14\u9700\u8981\u6301\u7eed\u5173\u6ce8\u3002"}}
{"id": "2510.16622", "categories": ["cs.AR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.16622", "abs": "https://arxiv.org/abs/2510.16622", "authors": ["Kazi Ababil Azam", "Hasan Masum", "Masfiqur Rahaman", "A. B. M. Alim Al Islam"], "title": "Towards Intelligent Traffic Signaling in Dhaka City Based on Vehicle Detection and Congestion Optimization", "comment": "10 pages, Submitted to IEEE Transactions on Intelligent\n  Transportation Systems (T-ITS)", "summary": "The vehicular density in urbanizing cities of developing countries such as\nDhaka, Bangladesh result in a lot of traffic congestion, causing poor on-road\nexperiences. Traffic signaling is a key component in effective traffic\nmanagement for such situations, but the advancements in intelligent traffic\nsignaling have been exclusive to developed countries with structured traffic.\nThe non-lane-based, heterogeneous traffic of Dhaka City requires a contextual\napproach. This study focuses on the development of an intelligent traffic\nsignaling system feasible in the context of developing countries such as\nBangladesh. We propose a pipeline leveraging Real Time Streaming Protocol\n(RTSP) feeds, a low resources system Raspberry Pi 4B processing, and a state of\nthe art YOLO-based object detection model trained on the Non-lane-based and\nHeterogeneous Traffic (NHT-1071) dataset to detect and classify heterogeneous\ntraffic. A multi-objective optimization algorithm, NSGA-II, then generates\noptimized signal timings, minimizing waiting time while maximizing vehicle\nthroughput. We test our implementation in a five-road intersection at Palashi,\nDhaka, demonstrating the potential to significantly improve traffic management\nin similar situations. The developed testbed paves the way for more contextual\nand effective Intelligent Traffic Signaling (ITS) solutions for developing\nareas with complicated traffic dynamics such as Dhaka City.", "AI": {"tldr": "\u672c\u7814\u7a76\u4e3a\u53d1\u5c55\u4e2d\u56fd\u5bb6\u5982\u5b5f\u52a0\u62c9\u56fd\u8fbe\u5361\u5e02\u5f00\u53d1\u4e86\u4e00\u79cd\u667a\u80fd\u4ea4\u901a\u4fe1\u53f7\u7cfb\u7edf\uff0c\u5229\u7528RTSP\u89c6\u9891\u6d41\u3001\u6811\u8393\u6d3e4B\u5904\u7406\u548cYOLO\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\uff0c\u7ed3\u5408NSGA-II\u591a\u76ee\u6807\u4f18\u5316\u7b97\u6cd5\u6765\u4f18\u5316\u4fe1\u53f7\u914d\u65f6\uff0c\u51cf\u5c11\u7b49\u5f85\u65f6\u95f4\u5e76\u63d0\u9ad8\u8f66\u8f86\u901a\u884c\u91cf\u3002", "motivation": "\u53d1\u5c55\u4e2d\u56fd\u5bb6\u57ce\u5e02\u5982\u8fbe\u5361\u5e02\u7684\u8f66\u8f86\u5bc6\u5ea6\u5bfc\u81f4\u4e25\u91cd\u4ea4\u901a\u62e5\u5835\uff0c\u4f46\u73b0\u6709\u7684\u667a\u80fd\u4ea4\u901a\u4fe1\u53f7\u6280\u672f\u4e3b\u8981\u9488\u5bf9\u53d1\u8fbe\u56fd\u5bb6\u7684\u7ed3\u6784\u5316\u4ea4\u901a\uff0c\u4e0d\u9002\u7528\u4e8e\u8fbe\u5361\u5e02\u7684\u975e\u8f66\u9053\u5316\u3001\u5f02\u8d28\u4ea4\u901a\u73af\u5883\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5904\u7406\u6d41\u7a0b\uff1a\u4f7f\u7528RTSP\u89c6\u9891\u6d41\u8f93\u5165\uff0c\u5728\u6811\u8393\u6d3e4B\u4e0a\u8fdb\u884c\u4f4e\u8d44\u6e90\u5904\u7406\uff0c\u91c7\u7528\u57fa\u4e8eYOLO\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\uff08\u5728NHT-1071\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff09\u6765\u68c0\u6d4b\u548c\u5206\u7c7b\u5f02\u8d28\u4ea4\u901a\uff0c\u7136\u540e\u4f7f\u7528NSGA-II\u591a\u76ee\u6807\u4f18\u5316\u7b97\u6cd5\u751f\u6210\u4f18\u5316\u7684\u4fe1\u53f7\u914d\u65f6\u3002", "result": "\u5728\u8fbe\u5361\u5e02Palashi\u7684\u4e00\u4e2a\u4e94\u8def\u4ea4\u53c9\u53e3\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u8bc1\u660e\u8be5\u7cfb\u7edf\u80fd\u591f\u663e\u8457\u6539\u5584\u7c7b\u4f3c\u60c5\u51b5\u4e0b\u7684\u4ea4\u901a\u7ba1\u7406\u3002", "conclusion": "\u5f00\u53d1\u7684\u6d4b\u8bd5\u5e73\u53f0\u4e3a\u5177\u6709\u590d\u6742\u4ea4\u901a\u52a8\u6001\u7684\u53d1\u5c55\u4e2d\u5730\u533a\uff08\u5982\u8fbe\u5361\u5e02\uff09\u63d0\u4f9b\u4e86\u66f4\u7b26\u5408\u60c5\u5883\u548c\u6709\u6548\u7684\u667a\u80fd\u4ea4\u901a\u4fe1\u53f7\u89e3\u51b3\u65b9\u6848\u7684\u9014\u5f84\u3002"}}
{"id": "2510.16558", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16558", "abs": "https://arxiv.org/abs/2510.16558", "authors": ["Xiaofan Li", "Xing Gao"], "title": "Toward Understanding Security Issues in the Model Context Protocol Ecosystem", "comment": null, "summary": "The Model Context Protocol (MCP) is an emerging open standard that enables\nAI-powered applications to interact with external tools through structured\nmetadata. A rapidly growing ecosystem has formed around MCP, including a wide\nrange of MCP hosts (i.e., Cursor, Windsurf, Claude Desktop, and Cline), MCP\nregistries (i.e., mcp.so, MCP Market, MCP Store, Pulse MCP, Smithery, and npm),\nand thousands of community-contributed MCP servers. Although the MCP ecosystem\nis gaining traction, there has been little systematic study of its architecture\nand associated security risks. In this paper, we present the first\ncomprehensive security analysis of the MCP ecosystem. We decompose MCP\necosystem into three core components: hosts, registries, and servers, and study\nthe interactions and trust relationships among them. Users search for servers\non registries and configure them in the host, which translates LLM-generated\noutput into external tool invocations provided by the servers and executes\nthem. Our qualitative analysis reveals that hosts lack output verification\nmechanisms for LLM-generated outputs, enabling malicious servers to manipulate\nmodel behavior and induce a variety of security threats, including but not\nlimited to sensitive data exfiltration. We uncover a wide range of\nvulnerabilities that enable attackers to hijack servers, due to the lack of a\nvetted server submission process in registries. To support our analysis, we\ncollect and analyze a dataset of 67,057 servers from six public registries. Our\nquantitative analysis demonstrates that a substantial number of servers can be\nhijacked by attackers. Finally, we propose practical defense strategies for MCP\nhosts, registries, and users. We responsibly disclosed our findings to affected\nhosts and registries.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9MCP\u751f\u6001\u7cfb\u7edf\u8fdb\u884c\u5168\u9762\u7684\u5b89\u5168\u5206\u6790\uff0c\u63ed\u793a\u4e86\u7531\u4e8e\u7f3a\u4e4f\u8f93\u51fa\u9a8c\u8bc1\u673a\u5236\u548c\u670d\u52a1\u5668\u5ba1\u67e5\u6d41\u7a0b\uff0c\u6076\u610f\u670d\u52a1\u5668\u53ef\u4ee5\u64cd\u7eb5\u6a21\u578b\u884c\u4e3a\u5e76\u5f15\u53d1\u591a\u79cd\u5b89\u5168\u5a01\u80c1\uff0c\u5305\u62ec\u654f\u611f\u6570\u636e\u6cc4\u9732\u3002", "motivation": "MCP\u751f\u6001\u7cfb\u7edf\u5feb\u901f\u53d1\u5c55\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u5b89\u5168\u7814\u7a76\uff0c\u9700\u8981\u5206\u6790\u5176\u67b6\u6784\u548c\u5b89\u5168\u98ce\u9669\u3002", "method": "\u5c06MCP\u751f\u6001\u7cfb\u7edf\u5206\u89e3\u4e3a\u4e3b\u673a\u3001\u6ce8\u518c\u4e2d\u5fc3\u548c\u670d\u52a1\u5668\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff0c\u5206\u6790\u5b83\u4eec\u4e4b\u95f4\u7684\u4ea4\u4e92\u548c\u4fe1\u4efb\u5173\u7cfb\uff0c\u5e76\u6536\u96c6\u5206\u679067,057\u4e2a\u670d\u52a1\u5668\u7684\u6570\u636e\u96c6\u8fdb\u884c\u5b9a\u91cf\u5206\u6790\u3002", "result": "\u53d1\u73b0\u4e3b\u673a\u7f3a\u4e4fLLM\u751f\u6210\u8f93\u51fa\u7684\u9a8c\u8bc1\u673a\u5236\uff0c\u6076\u610f\u670d\u52a1\u5668\u53ef\u64cd\u7eb5\u6a21\u578b\u884c\u4e3a\uff1b\u6ce8\u518c\u4e2d\u5fc3\u7f3a\u4e4f\u670d\u52a1\u5668\u5ba1\u67e5\u6d41\u7a0b\uff0c\u5927\u91cf\u670d\u52a1\u5668\u53ef\u80fd\u88ab\u653b\u51fb\u8005\u52ab\u6301\u3002", "conclusion": "\u63d0\u51fa\u4e86\u9488\u5bf9MCP\u4e3b\u673a\u3001\u6ce8\u518c\u4e2d\u5fc3\u548c\u7528\u6237\u7684\u5b9e\u7528\u9632\u5fa1\u7b56\u7565\uff0c\u5e76\u5411\u76f8\u5173\u65b9\u8d1f\u8d23\u4efb\u5730\u62ab\u9732\u4e86\u53d1\u73b0\u3002"}}
{"id": "2510.17251", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.17251", "abs": "https://arxiv.org/abs/2510.17251", "authors": ["Chengxi Li", "Yang Sun", "Lei Chen", "Yiwen Wang", "Mingxuan Yuan", "Evangeline F. Y. Young"], "title": "SmaRTLy: RTL Optimization with Logic Inferencing and Structural Rebuilding", "comment": null, "summary": "This paper proposes smaRTLy: a new optimization technique for multiplexers in\nRegister-Transfer Level (RTL) logic synthesis. Multiplexer trees are very\ncommon in RTL designs, and traditional tools like Yosys optimize them by\ntraversing the tree and monitoring control port values. However, this method\ndoes not fully exploit the intrinsic logical relationships among signals or the\npotential for structural optimization. To address these limitations, we develop\ninnovative strategies to remove redundant multiplexer trees and restructure the\nremaining ones, significantly reducing the overall gate count. We evaluate\nsmaRTLy on the IWLS-2005 and RISC-V benchmarks, achieving an additional 8.95%\nreduction in AIG area compared to Yosys. We also evaluate smaRTLy on an\nindustrial benchmark in the scale of millions of gates, results show that\nsmaRTLy can remove 47.2% more AIG area than Yosys. These results demonstrate\nthe effectiveness of our logic inferencing and structural rebuilding techniques\nin enhancing the RTL optimization process, leading to more efficient hardware\ndesigns.", "AI": {"tldr": "smaRTLy\u662f\u4e00\u79cd\u9488\u5bf9RTL\u903b\u8f91\u7efc\u5408\u4e2d\u591a\u8def\u590d\u7528\u5668\u7684\u4f18\u5316\u6280\u672f\uff0c\u901a\u8fc7\u6d88\u9664\u5197\u4f59\u591a\u8def\u590d\u7528\u5668\u6811\u548c\u91cd\u6784\u5269\u4f59\u7ed3\u6784\uff0c\u663e\u8457\u51cf\u5c11\u95e8\u6570\u91cf\u3002", "motivation": "\u4f20\u7edf\u5de5\u5177\u5982Yosys\u901a\u8fc7\u904d\u5386\u591a\u8def\u590d\u7528\u5668\u6811\u548c\u76d1\u63a7\u63a7\u5236\u7aef\u53e3\u503c\u6765\u4f18\u5316\uff0c\u4f46\u672a\u80fd\u5145\u5206\u5229\u7528\u4fe1\u53f7\u95f4\u7684\u5185\u5728\u903b\u8f91\u5173\u7cfb\u6216\u7ed3\u6784\u4f18\u5316\u6f5c\u529b\u3002", "method": "\u5f00\u53d1\u521b\u65b0\u7b56\u7565\u6765\u79fb\u9664\u5197\u4f59\u591a\u8def\u590d\u7528\u5668\u6811\u5e76\u91cd\u6784\u5269\u4f59\u7ed3\u6784\uff0c\u91c7\u7528\u903b\u8f91\u63a8\u7406\u548c\u7ed3\u6784\u91cd\u5efa\u6280\u672f\u3002", "result": "\u5728IWLS-2005\u548cRISC-V\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4Yosys\u989d\u5916\u51cf\u5c118.95%\u7684AIG\u9762\u79ef\uff1b\u5728\u767e\u4e07\u95e8\u7ea7\u5de5\u4e1a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6bd4Yosys\u591a\u79fb\u966447.2%\u7684AIG\u9762\u79ef\u3002", "conclusion": "smaRTLy\u7684\u903b\u8f91\u63a8\u7406\u548c\u7ed3\u6784\u91cd\u5efa\u6280\u672f\u80fd\u6709\u6548\u589e\u5f3aRTL\u4f18\u5316\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u786c\u4ef6\u8bbe\u8ba1\u3002"}}
{"id": "2510.16581", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16581", "abs": "https://arxiv.org/abs/2510.16581", "authors": ["Xinfeng Li", "Shengyuan Pang", "Jialin Wu", "Jiangyi Deng", "Huanlong Zhong", "Yanjiao Chen", "Jie Zhang", "Wenyuan Xu"], "title": "Patronus: Safeguarding Text-to-Image Models against White-Box Adversaries", "comment": "14 pages, 18 figures, 7 tables", "summary": "Text-to-image (T2I) models, though exhibiting remarkable creativity in image\ngeneration, can be exploited to produce unsafe images. Existing safety\nmeasures, e.g., content moderation or model alignment, fail in the presence of\nwhite-box adversaries who know and can adjust model parameters, e.g., by\nfine-tuning. This paper presents a novel defensive framework, named Patronus,\nwhich equips T2I models with holistic protection to defend against white-box\nadversaries. Specifically, we design an internal moderator that decodes unsafe\ninput features into zero vectors while ensuring the decoding performance of\nbenign input features. Furthermore, we strengthen the model alignment with a\ncarefully designed non-fine-tunable learning mechanism, ensuring the T2I model\nwill not be compromised by malicious fine-tuning. We conduct extensive\nexperiments to validate the intactness of the performance on safe content\ngeneration and the effectiveness of rejecting unsafe content generation.\nResults also confirm the resilience of Patronus against various fine-tuning\nattacks by white-box adversaries.", "AI": {"tldr": "Patronus\u662f\u4e00\u4e2a\u9632\u5fa1\u6846\u67b6\uff0c\u4e3a\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u63d0\u4f9b\u5168\u9762\u4fdd\u62a4\uff0c\u62b5\u5fa1\u767d\u76d2\u653b\u51fb\u8005\u7684\u6076\u610f\u5fae\u8c03\u653b\u51fb\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u7684\u5b89\u5168\u63aa\u65bd\u5728\u9762\u4e34\u77e5\u9053\u5e76\u80fd\u8c03\u6574\u6a21\u578b\u53c2\u6570\u7684\u767d\u76d2\u653b\u51fb\u8005\u65f6\u4f1a\u5931\u6548\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65b0\u7684\u9632\u5fa1\u673a\u5236\u3002", "method": "\u8bbe\u8ba1\u5185\u90e8\u8c03\u8282\u5668\u5c06\u4e0d\u5b89\u5168\u8f93\u5165\u7279\u5f81\u89e3\u7801\u4e3a\u96f6\u5411\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u6027\u8f93\u5165\u7279\u5f81\u7684\u89e3\u7801\u6027\u80fd\uff1b\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u4e0d\u53ef\u5fae\u8c03\u5b66\u4e60\u673a\u5236\u52a0\u5f3a\u6a21\u578b\u5bf9\u9f50\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5728\u5b89\u5168\u5185\u5bb9\u751f\u6210\u65b9\u9762\u7684\u6027\u80fd\u5b8c\u6574\u6027\uff0c\u4ee5\u53ca\u62d2\u7edd\u4e0d\u5b89\u5168\u5185\u5bb9\u751f\u6210\u7684\u6709\u6548\u6027\uff0c\u786e\u8ba4\u4e86Patronus\u5bf9\u5404\u79cd\u767d\u76d2\u5fae\u8c03\u653b\u51fb\u7684\u97e7\u6027\u3002", "conclusion": "Patronus\u6846\u67b6\u6210\u529f\u4e3a\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u63d0\u4f9b\u4e86\u5bf9\u6297\u767d\u76d2\u653b\u51fb\u8005\u7684\u5168\u9762\u4fdd\u62a4\uff0c\u786e\u4fdd\u6a21\u578b\u5728\u9762\u4e34\u6076\u610f\u5fae\u8c03\u65f6\u4e0d\u4f1a\u88ab\u7834\u574f\u3002"}}
{"id": "2510.16582", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16582", "abs": "https://arxiv.org/abs/2510.16582", "authors": ["Junchi Yu", "Yujie Liu", "Jindong Gu", "Philip Torr", "Dongzhan Zhou"], "title": "Can Knowledge-Graph-based Retrieval Augmented Generation Really Retrieve What You Need?", "comment": "NeurIPS 2025 (Spotlight)", "summary": "Retrieval-Augmented Generation (RAG) based on knowledge graphs (KGs) enhances\nlarge language models (LLMs) by providing structured and interpretable external\nknowledge. However, existing KG-based RAG methods struggle to retrieve accurate\nand diverse information from text-rich KGs for complex real-world queries.\nProcess Reward Models (PRMs) offer a way to align the retrieval process of\nKG-based RAG with query-specific knowledge requirements, but they heavily rely\non process-level supervision signals that are expensive and hard to obtain on\nKGs. To address this challenge, we propose GraphFlow, a framework that\nefficiently retrieves accurate and diverse knowledge required for real-world\nqueries from text-rich KGs. GraphFlow employs a transition-based flow matching\nobjective to jointly optimize a retrieval policy and a flow estimator. The flow\nestimator factorizes the reward of the retrieval outcome into the intermediate\nretrieval states. Such reward factorization guides the retrieval policy to\nretrieve candidates from KGs in proportion to their reward. This allows\nGraphFlow to explore high-quality regions of KGs that yield diverse and\nrelevant results. We evaluate GraphFlow on the STaRK benchmark, which includes\nreal-world queries from multiple domains over text-rich KGs. GraphFlow\noutperforms strong KG-RAG baselines, including GPT-4o, by 10% on average in hit\nrate and recall. It also shows strong generalization to unseen KGs,\ndemonstrating its effectiveness and robustness.", "AI": {"tldr": "GraphFlow\u662f\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u8f6c\u79fb\u6d41\u5339\u914d\u76ee\u6807\u8054\u5408\u4f18\u5316\u68c0\u7d22\u7b56\u7565\u548c\u6d41\u4f30\u8ba1\u5668\uff0c\u4ece\u6587\u672c\u4e30\u5bcc\u7684\u77e5\u8bc6\u56fe\u8c31\u4e2d\u9ad8\u6548\u68c0\u7d22\u51c6\u786e\u591a\u6837\u7684\u77e5\u8bc6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u96be\u4ee5\u4ece\u6587\u672c\u4e30\u5bcc\u7684\u77e5\u8bc6\u56fe\u8c31\u4e2d\u4e3a\u590d\u6742\u771f\u5b9e\u4e16\u754c\u67e5\u8be2\u68c0\u7d22\u51c6\u786e\u548c\u591a\u6837\u5316\u7684\u4fe1\u606f\uff0c\u800c\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u867d\u7136\u80fd\u5bf9\u9f50\u68c0\u7d22\u8fc7\u7a0b\u4e0e\u67e5\u8be2\u7279\u5b9a\u77e5\u8bc6\u9700\u6c42\uff0c\u4f46\u4e25\u91cd\u4f9d\u8d56\u6602\u8d35\u4e14\u96be\u4ee5\u83b7\u53d6\u7684\u8fc7\u7a0b\u7ea7\u76d1\u7763\u4fe1\u53f7\u3002", "method": "GraphFlow\u91c7\u7528\u8f6c\u79fb\u6d41\u5339\u914d\u76ee\u6807\u8054\u5408\u4f18\u5316\u68c0\u7d22\u7b56\u7565\u548c\u6d41\u4f30\u8ba1\u5668\uff0c\u6d41\u4f30\u8ba1\u5668\u5c06\u68c0\u7d22\u7ed3\u679c\u7684\u5956\u52b1\u5206\u89e3\u4e3a\u4e2d\u95f4\u68c0\u7d22\u72b6\u6001\uff0c\u5f15\u5bfc\u68c0\u7d22\u7b56\u7565\u6309\u5956\u52b1\u6bd4\u4f8b\u4ece\u77e5\u8bc6\u56fe\u8c31\u4e2d\u68c0\u7d22\u5019\u9009\uff0c\u4ece\u800c\u63a2\u7d22\u4ea7\u751f\u591a\u6837\u76f8\u5173\u7ed3\u679c\u7684\u9ad8\u8d28\u91cf\u56fe\u8c31\u533a\u57df\u3002", "result": "\u5728STaRK\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGraphFlow\u5728\u547d\u4e2d\u7387\u548c\u53ec\u56de\u7387\u4e0a\u5e73\u5747\u4f18\u4e8e\u5305\u62ecGPT-4o\u5728\u5185\u7684\u5f3a\u57fa\u7ebf\u65b9\u6cd510%\uff0c\u5e76\u5728\u672a\u89c1\u8fc7\u7684\u77e5\u8bc6\u56fe\u8c31\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "GraphFlow\u5728\u4ece\u6587\u672c\u4e30\u5bcc\u7684\u77e5\u8bc6\u56fe\u8c31\u4e2d\u68c0\u7d22\u51c6\u786e\u591a\u6837\u77e5\u8bc6\u65b9\u9762\u8868\u73b0\u51fa\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u66f4\u597d\u5730\u652f\u6301\u590d\u6742\u771f\u5b9e\u4e16\u754c\u67e5\u8be2\u3002"}}
{"id": "2510.16593", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16593", "abs": "https://arxiv.org/abs/2510.16593", "authors": ["Khandaker Akramul Haque", "Katherine R. Davis"], "title": "DESTinE Block: Private Blockchain Based Data Storage Framework for Power System", "comment": null, "summary": "This paper presents DESTinE Block, a blockchain-based data storage framework\ndesigned for power systems and optimized for resource-constrained environments,\nincluding grid-edge devices such as single-board computers. The proposed\narchitecture leverages the InterPlanetary File System (IPFS) for storing large\nfiles while maintaining secure and traceable metadata on a custom blockchain\nnamed DESTinE Block. The metadata, comprising the IPFS Content Identifier\n(CID), uploader identity, administrator verification, and timestamp; is\nimmutably recorded on-chain to ensure authenticity and integrity. DESTinE Block\nadopts a dual-blockchain abstraction, where the blockchain remains unaware of\nthe IPFS storage layer to enhance security and limit the exposure of sensitive\nfile data. The consensus mechanism is based on Proof of Authority (PoA), where\nboth an administrator and an uploader with distinct cryptographic key pairs are\nrequired to create a block collaboratively. Each block contains verified\nsignatures of both parties and is designed to be computationally efficient,\nenabling deployment on devices like the Raspberry Pi 5. The framework was\ntested on both an x86-based device and an ARM64-based Raspberry Pi,\ndemonstrating its potential for secure, decentralized logging and measurement\nstorage in smart grid applications. Moreover, DESTinE Block is compared with a\nsimilar framework based on Multichain. The results indicate that DESTinE Block\nprovides a promising solution for tamper-evident data retention in distributed\npower system infrastructure while maintaining minimal hardware requirements.", "AI": {"tldr": "DESTinE Block\u662f\u4e00\u4e2a\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u6570\u636e\u5b58\u50a8\u6846\u67b6\uff0c\u4e13\u4e3a\u7535\u529b\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u4f18\u5316\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u73af\u5883\uff08\u5982\u5355\u677f\u8ba1\u7b97\u673a\uff09\u3002\u5b83\u91c7\u7528IPFS\u5b58\u50a8\u5927\u6587\u4ef6\uff0c\u5728\u81ea\u5b9a\u4e49\u533a\u5757\u94fe\u4e0a\u8bb0\u5f55\u5b89\u5168\u53ef\u8ffd\u6eaf\u7684\u5143\u6570\u636e\uff0c\u4f7f\u7528PoA\u5171\u8bc6\u673a\u5236\uff0c\u652f\u6301\u5728Raspberry Pi\u7b49\u8bbe\u5907\u4e0a\u90e8\u7f72\u3002", "motivation": "\u4e3a\u7535\u529b\u7cfb\u7edf\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u63d0\u4f9b\u5b89\u5168\u3001\u53bb\u4e2d\u5fc3\u5316\u7684\u6570\u636e\u5b58\u50a8\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u7535\u7f51\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u9632\u7be1\u6539\u7684\u6570\u636e\u4fdd\u7559\u3002", "method": "\u91c7\u7528\u53cc\u533a\u5757\u94fe\u62bd\u8c61\u67b6\u6784\uff0cIPFS\u5b58\u50a8\u5927\u6587\u4ef6\uff0cDESTinE\u533a\u5757\u94fe\u8bb0\u5f55\u5143\u6570\u636e\uff08CID\u3001\u4e0a\u4f20\u8005\u8eab\u4efd\u3001\u7ba1\u7406\u5458\u9a8c\u8bc1\u3001\u65f6\u95f4\u6233\uff09\u3002\u57fa\u4e8ePoA\u5171\u8bc6\u673a\u5236\uff0c\u9700\u8981\u7ba1\u7406\u5458\u548c\u4e0a\u4f20\u8005\u5171\u540c\u534f\u4f5c\u521b\u5efa\u533a\u5757\uff0c\u4f7f\u7528\u4e0d\u540c\u7684\u52a0\u5bc6\u5bc6\u94a5\u5bf9\u3002", "result": "\u5728x86\u8bbe\u5907\u548cARM64 Raspberry Pi\u4e0a\u6d4b\u8bd5\u6210\u529f\uff0c\u4e0e\u57fa\u4e8eMultichain\u7684\u7c7b\u4f3c\u6846\u67b6\u76f8\u6bd4\uff0cDESTinE Block\u5728\u4fdd\u6301\u6700\u5c0f\u786c\u4ef6\u8981\u6c42\u7684\u540c\u65f6\uff0c\u4e3a\u5206\u5e03\u5f0f\u7535\u529b\u7cfb\u7edf\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9632\u7be1\u6539\u6570\u636e\u4fdd\u7559\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "DESTinE Block\u662f\u4e00\u4e2a\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u4e3a\u667a\u80fd\u7535\u7f51\u5e94\u7528\u63d0\u4f9b\u5b89\u5168\u3001\u53bb\u4e2d\u5fc3\u5316\u7684\u65e5\u5fd7\u548c\u6d4b\u91cf\u6570\u636e\u5b58\u50a8\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2510.16601", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16601", "abs": "https://arxiv.org/abs/2510.16601", "authors": ["Tianxing Wu", "Shutong Zhu", "Jingting Wang", "Ning Xu", "Guilin Qi", "Haofen Wang"], "title": "Uncertain Knowledge Graph Completion via Semi-Supervised Confidence Distribution Learning", "comment": "13 pages, accepted by NeurIPS 2025 (spotlight)", "summary": "Uncertain knowledge graphs (UKGs) associate each triple with a confidence\nscore to provide more precise knowledge representations. Recently, since\nreal-world UKGs suffer from the incompleteness, uncertain knowledge graph (UKG)\ncompletion attracts more attention, aiming to complete missing triples and\nconfidences. Current studies attempt to learn UKG embeddings to solve this\nproblem, but they neglect the extremely imbalanced distributions of triple\nconfidences. This causes that the learnt embeddings are insufficient to\nhigh-quality UKG completion. Thus, in this paper, to address the above issue,\nwe propose a new semi-supervised Confidence Distribution Learning (ssCDL)\nmethod for UKG completion, where each triple confidence is transformed into a\nconfidence distribution to introduce more supervision information of different\nconfidences to reinforce the embedding learning process. ssCDL iteratively\nlearns UKG embedding by relational learning on labeled data (i.e., existing\ntriples with confidences) and unlabeled data with pseudo labels (i.e., unseen\ntriples with the generated confidences), which are predicted by meta-learning\nto augment the training data and rebalance the distribution of triple\nconfidences. Experiments on two UKG datasets demonstrate that ssCDL\nconsistently outperforms state-of-the-art baselines in different evaluation\nmetrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u76d1\u7763\u7f6e\u4fe1\u5ea6\u5206\u5e03\u5b66\u4e60\u65b9\u6cd5\uff08ssCDL\uff09\u6765\u89e3\u51b3\u4e0d\u786e\u5b9a\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4e2d\u7684\u7f6e\u4fe1\u5ea6\u5206\u5e03\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u7f6e\u4fe1\u5ea6\u8f6c\u6362\u4e3a\u5206\u5e03\u5e76\u5229\u7528\u5143\u5b66\u4e60\u751f\u6210\u4f2a\u6807\u7b7e\u6765\u589e\u5f3a\u8bad\u7ec3\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u4e0d\u786e\u5b9a\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u65b9\u6cd5\u5ffd\u89c6\u4e86\u7f6e\u4fe1\u5ea6\u7684\u6781\u7aef\u4e0d\u5e73\u8861\u5206\u5e03\uff0c\u5bfc\u81f4\u5b66\u4e60\u5230\u7684\u5d4c\u5165\u8868\u793a\u4e0d\u8db3\u4ee5\u652f\u6301\u9ad8\u8d28\u91cf\u7684\u56fe\u8c31\u8865\u5168\u3002", "method": "\u63d0\u51fassCDL\u65b9\u6cd5\uff0c\u5c06\u7f6e\u4fe1\u5ea6\u8f6c\u6362\u4e3a\u7f6e\u4fe1\u5ea6\u5206\u5e03\u4ee5\u5f15\u5165\u66f4\u591a\u76d1\u7763\u4fe1\u606f\uff0c\u901a\u8fc7\u5173\u7cfb\u5b66\u4e60\u5728\u6807\u8bb0\u6570\u636e\u548c\u5e26\u4f2a\u6807\u7b7e\u7684\u672a\u6807\u8bb0\u6570\u636e\u4e0a\u8fed\u4ee3\u5b66\u4e60\u5d4c\u5165\uff0c\u4f7f\u7528\u5143\u5b66\u4e60\u9884\u6d4b\u672a\u89c1\u4e09\u5143\u7ec4\u7684\u7f6e\u4fe1\u5ea6\u6765\u589e\u5f3a\u8bad\u7ec3\u6570\u636e\u5e76\u91cd\u65b0\u5e73\u8861\u7f6e\u4fe1\u5ea6\u5206\u5e03\u3002", "result": "\u5728\u4e24\u4e2a\u4e0d\u786e\u5b9a\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cssCDL\u5728\u4e0d\u540c\u8bc4\u4f30\u6307\u6807\u4e0a\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ssCDL\u901a\u8fc7\u5904\u7406\u7f6e\u4fe1\u5ea6\u5206\u5e03\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4e0d\u786e\u5b9a\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u7684\u6027\u80fd\u3002"}}
{"id": "2510.16614", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16614", "abs": "https://arxiv.org/abs/2510.16614", "authors": ["Xuan Zhang", "Ruixiao Li", "Zhijian Zhou", "Long Li", "Yulei Qin", "Ke Li", "Xing Sun", "Xiaoyu Tan", "Chao Qu", "Yuan Qi"], "title": "Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards", "comment": null, "summary": "Reinforcement Learning (RL) has become a compelling way to strengthen the\nmulti step reasoning ability of Large Language Models (LLMs). However,\nprevalent RL paradigms still lean on sparse outcome-based rewards and limited\nexploration, which often drives LLMs toward repetitive and suboptimal reasoning\npatterns. In this paper, we study the central question of how to design\nexploration for LLM reasoning and introduce MERCI (Motivating Exploration in\nLLM Reasoning with Count-based Intrinsic Rewards), a novel RL algorithm that\naugments policy optimization with a principled intrinsic reward. Building on\nthe idea of count-based exploration, MERCI leverages a lightweight Coin\nFlipping Network (CFN) to estimate the pseudo count and further epistemic\nuncertainty over reasoning trajectories, and converts them into an intrinsic\nreward that values novelty while preserving the learning signal from task\nrewards. We integrate MERCI into some advanced RL frameworks like Group\nRelative Policy Optimization (GRPO). Experiments on complex reasoning\nbenchmarks demonstrate that MERCI encourages richer and more varied chains of\nthought, significantly improves performance over strong baselines, and helps\nthe policy escape local routines to discover better solutions. It indicates\nthat our targeted intrinsic motivation can make exploration reliable for\nlanguage model reasoning.", "AI": {"tldr": "MERCI\u662f\u4e00\u79cd\u65b0\u9896\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u57fa\u4e8e\u8ba1\u6570\u7684\u5185\u5728\u5956\u52b1\u6765\u589e\u5f3aLLM\u7684\u63a8\u7406\u63a2\u7d22\u80fd\u529b\uff0c\u907f\u514d\u91cd\u590d\u548c\u6b21\u4f18\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u8303\u5f0f\u4f9d\u8d56\u7a00\u758f\u7684\u7ed3\u679c\u5956\u52b1\u548c\u6709\u9650\u7684\u63a2\u7d22\uff0c\u5bfc\u81f4LLM\u8d8b\u5411\u91cd\u590d\u548c\u6b21\u4f18\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u9700\u8981\u8bbe\u8ba1\u66f4\u597d\u7684\u63a2\u7d22\u673a\u5236\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7\u7684Coin Flipping Network\u4f30\u8ba1\u4f2a\u8ba1\u6570\u548c\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u5185\u5728\u5956\u52b1\uff0c\u5e76\u4e0eGRPO\u7b49\u5148\u8fdbRL\u6846\u67b6\u96c6\u6210\u3002", "result": "\u5728\u590d\u6742\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMERCI\u9f13\u52b1\u66f4\u4e30\u5bcc\u591a\u6837\u7684\u601d\u7ef4\u94fe\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5e2e\u52a9\u7b56\u7565\u9003\u79bb\u5c40\u90e8\u6700\u4f18\u627e\u5230\u66f4\u597d\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u9488\u5bf9\u6027\u7684\u5185\u5728\u52a8\u673a\u53ef\u4ee5\u4f7f\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u63a2\u7d22\u66f4\u52a0\u53ef\u9760\u3002"}}
{"id": "2510.16658", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.16658", "abs": "https://arxiv.org/abs/2510.16658", "authors": ["Shihao Yang", "Xiying Huang", "Danilo Bernardo", "Jun-En Ding", "Andrew Michael", "Jingmei Yang", "Patrick Kwan", "Ashish Raj", "Feng Liu"], "title": "Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review", "comment": null, "summary": "The advent of large-scale artificial intelligence (AI) models has a\ntransformative effect on neuroscience research, which represents a paradigm\nshift from the traditional computational methods through the facilitation of\nend-to-end learning from raw brain signals and neural data. In this paper, we\nexplore the transformative effects of large-scale AI models on five major\nneuroscience domains: neuroimaging and data processing, brain-computer\ninterfaces and neural decoding, molecular neuroscience and genomic modeling,\nclinical assistance and translational frameworks, and disease-specific\napplications across neurological and psychiatric disorders. These models are\ndemonstrated to address major computational neuroscience challenges, including\nmultimodal neural data integration, spatiotemporal pattern interpretation, and\nthe derivation of translational frameworks for clinical deployment. Moreover,\nthe interaction between neuroscience and AI has become increasingly reciprocal,\nas biologically informed architectural constraints are now incorporated to\ndevelop more interpretable and computationally efficient models. This review\nhighlights both the notable promise of such technologies and key implementation\nconsiderations, with particular emphasis on rigorous evaluation frameworks,\neffective domain knowledge integration, and comprehensive ethical guidelines\nfor clinical use. Finally, a systematic listing of critical neuroscience\ndatasets used to derive and validate large-scale AI models across diverse\nresearch applications is provided.", "AI": {"tldr": "\u5927\u578bAI\u6a21\u578b\u6b63\u5728\u53d8\u9769\u795e\u7ecf\u79d1\u5b66\u7814\u7a76\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u5b66\u4e60\u4ece\u539f\u59cb\u8111\u4fe1\u53f7\u4e2d\u63d0\u53d6\u4fe1\u606f\uff0c\u5728\u795e\u7ecf\u5f71\u50cf\u3001\u8111\u673a\u63a5\u53e3\u3001\u5206\u5b50\u795e\u7ecf\u79d1\u5b66\u3001\u4e34\u5e8a\u8f85\u52a9\u548c\u75be\u75c5\u5e94\u7528\u7b49\u4e94\u5927\u9886\u57df\u4ea7\u751f\u6df1\u8fdc\u5f71\u54cd\u3002", "motivation": "\u63a2\u8ba8\u5927\u89c4\u6a21AI\u6a21\u578b\u5982\u4f55\u89e3\u51b3\u795e\u7ecf\u79d1\u5b66\u4e2d\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u5305\u62ec\u591a\u6a21\u6001\u795e\u7ecf\u6570\u636e\u6574\u5408\u3001\u65f6\u7a7a\u6a21\u5f0f\u89e3\u91ca\u4ee5\u53ca\u4e34\u5e8a\u8f6c\u5316\u6846\u67b6\u7684\u5f00\u53d1\u3002", "method": "\u56de\u987e\u5206\u6790\u5927\u578bAI\u6a21\u578b\u5728\u4e94\u4e2a\u4e3b\u8981\u795e\u7ecf\u79d1\u5b66\u9886\u57df\u7684\u5e94\u7528\uff1a\u795e\u7ecf\u5f71\u50cf\u6570\u636e\u5904\u7406\u3001\u8111\u673a\u63a5\u53e3\u4e0e\u795e\u7ecf\u89e3\u7801\u3001\u5206\u5b50\u795e\u7ecf\u79d1\u5b66\u4e0e\u57fa\u56e0\u7ec4\u5efa\u6a21\u3001\u4e34\u5e8a\u8f85\u52a9\u4e0e\u8f6c\u5316\u6846\u67b6\u3001\u795e\u7ecf\u7cbe\u795e\u75be\u75c5\u5e94\u7528\u3002", "result": "\u8fd9\u4e9b\u6a21\u578b\u88ab\u8bc1\u660e\u80fd\u591f\u6709\u6548\u5904\u7406\u591a\u6a21\u6001\u795e\u7ecf\u6570\u636e\u6574\u5408\u3001\u65f6\u7a7a\u6a21\u5f0f\u89e3\u91ca\uff0c\u5e76\u4e3a\u4e34\u5e8a\u90e8\u7f72\u63d0\u4f9b\u8f6c\u5316\u6846\u67b6\u3002\u795e\u7ecf\u79d1\u5b66\u4e0eAI\u7684\u4e92\u52a8\u65e5\u76ca\u4e92\u60e0\uff0c\u751f\u7269\u542f\u53d1\u7684\u67b6\u6784\u7ea6\u675f\u88ab\u7528\u4e8e\u5f00\u53d1\u66f4\u53ef\u89e3\u91ca\u548c\u8ba1\u7b97\u9ad8\u6548\u7684\u6a21\u578b\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u5f3a\u8c03\u4e86\u8fd9\u4e9b\u6280\u672f\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u540c\u65f6\u6307\u51fa\u5173\u952e\u5b9e\u65bd\u8003\u8651\uff0c\u5305\u62ec\u4e25\u683c\u7684\u8bc4\u4f30\u6846\u67b6\u3001\u6709\u6548\u7684\u9886\u57df\u77e5\u8bc6\u6574\u5408\u4ee5\u53ca\u4e34\u5e8a\u4f7f\u7528\u7684\u5168\u9762\u4f26\u7406\u6307\u5357\uff0c\u5e76\u63d0\u4f9b\u4e86\u7528\u4e8e\u9a8c\u8bc1\u5927\u578bAI\u6a21\u578b\u7684\u5173\u952e\u795e\u7ecf\u79d1\u5b66\u6570\u636e\u96c6\u6e05\u5355\u3002"}}
{"id": "2510.16716", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16716", "abs": "https://arxiv.org/abs/2510.16716", "authors": ["Asmita Mohanty", "Gezheng Kang", "Lei Gao", "Murali Annavaram"], "title": "DistilLock: Safeguarding LLMs from Unauthorized Knowledge Distillation on the Edge", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong performance across\ndiverse tasks, but fine-tuning them typically relies on cloud-based,\ncentralized infrastructures. This requires data owners to upload potentially\nsensitive data to external servers, raising serious privacy concerns. An\nalternative approach is to fine-tune LLMs directly on edge devices using local\ndata; however, this introduces a new challenge: the model owner must transfer\nproprietary models to the edge, which risks intellectual property (IP) leakage.\nTo address this dilemma, we propose DistilLock, a TEE-assisted fine-tuning\nframework that enables privacy-preserving knowledge distillation on the edge.\nIn DistilLock, a proprietary foundation model is executed within a trusted\nexecution environment (TEE) enclave on the data owner's device, acting as a\nsecure black-box teacher. This setup preserves both data privacy and model IP\nby preventing direct access to model internals. Furthermore, DistilLock employs\na model obfuscation mechanism to offload obfuscated weights to untrusted\naccelerators for efficient knowledge distillation without compromising\nsecurity. We demonstrate that DistilLock prevents unauthorized knowledge\ndistillation processes and model-stealing attacks while maintaining high\ncomputational efficiency, but offering a secure and practical solution for\nedge-based LLM personalization.", "AI": {"tldr": "DistilLock\u662f\u4e00\u4e2aTEE\u8f85\u52a9\u7684\u5fae\u8c03\u6846\u67b6\uff0c\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u77e5\u8bc6\u84b8\u998f\uff0c\u540c\u65f6\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u548c\u6a21\u578b\u77e5\u8bc6\u4ea7\u6743\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u4e91\u7aef\u5fae\u8c03LLM\u5e26\u6765\u7684\u6570\u636e\u9690\u79c1\u95ee\u9898\uff0c\u4ee5\u53ca\u8fb9\u7f18\u8bbe\u5907\u5fae\u8c03\u5bfc\u81f4\u7684\u6a21\u578b\u77e5\u8bc6\u4ea7\u6743\u6cc4\u9732\u98ce\u9669\u3002", "method": "\u5728\u6570\u636e\u6240\u6709\u8005\u8bbe\u5907\u4e0a\u7684\u53ef\u4fe1\u6267\u884c\u73af\u5883(TEE)\u4e2d\u8fd0\u884c\u4e13\u6709\u57fa\u7840\u6a21\u578b\u4f5c\u4e3a\u5b89\u5168\u9ed1\u76d2\u6559\u5e08\uff0c\u91c7\u7528\u6a21\u578b\u6df7\u6dc6\u673a\u5236\u5c06\u6df7\u6dc6\u6743\u91cd\u5378\u8f7d\u5230\u4e0d\u53ef\u4fe1\u52a0\u901f\u5668\u8fdb\u884c\u9ad8\u6548\u77e5\u8bc6\u84b8\u998f\u3002", "result": "DistilLock\u80fd\u591f\u9632\u6b62\u672a\u7ecf\u6388\u6743\u7684\u77e5\u8bc6\u84b8\u998f\u8fc7\u7a0b\u548c\u6a21\u578b\u7a83\u53d6\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "DistilLock\u4e3a\u57fa\u4e8e\u8fb9\u7f18\u7684LLM\u4e2a\u6027\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b89\u5168\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u9690\u79c1\u4fdd\u62a4\u4e0e\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2510.16744", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16744", "abs": "https://arxiv.org/abs/2510.16744", "authors": ["Srinivas Vivek"], "title": "Cryptanalysis of a Privacy-Preserving Ride-Hailing Service from NSS 2022", "comment": "9 pages", "summary": "Ride-Hailing Services (RHS) match a ride request initiated by a rider with a\nsuitable driver responding to the ride request. A Privacy-Preserving RHS\n(PP-RHS) aims to facilitate ride matching while ensuring the privacy of riders'\nand drivers' location data w.r.t. the Service Provider (SP). At NSS 2022, Xie\net al. proposed a PP-RHS. In this work, we demonstrate a passive attack on\ntheir PP-RHS protocol. Our attack allows the SP to completely recover the\nlocations of the rider as well as that of the responding drivers in every ride\nrequest. Further, our attack is very efficient as it is independent of the\nsecurity parameter.", "AI": {"tldr": "\u672c\u6587\u5bf9Xie\u7b49\u4eba\u5728NSS 2022\u63d0\u51fa\u7684\u9690\u79c1\u4fdd\u62a4\u7f51\u7ea6\u8f66\u670d\u52a1\u534f\u8bae\u8fdb\u884c\u4e86\u88ab\u52a8\u653b\u51fb\u5206\u6790\uff0c\u8bc1\u660e\u8be5\u534f\u8bae\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u5b8c\u5168\u6062\u590d\u4e58\u5ba2\u548c\u53f8\u673a\u7684\u7cbe\u786e\u4f4d\u7f6e\u4fe1\u606f\u3002", "motivation": "\u968f\u7740\u7f51\u7ea6\u8f66\u670d\u52a1\u7684\u666e\u53ca\uff0c\u4fdd\u62a4\u7528\u6237\u4f4d\u7f6e\u9690\u79c1\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002Xie\u7b49\u4eba\u63d0\u51fa\u7684PP-RHS\u534f\u8bae\u58f0\u79f0\u80fd\u591f\u4fdd\u62a4\u7528\u6237\u4f4d\u7f6e\u9690\u79c1\uff0c\u4f46\u672c\u6587\u65e8\u5728\u9a8c\u8bc1\u8be5\u534f\u8bae\u7684\u5b9e\u9645\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528\u88ab\u52a8\u653b\u51fb\u65b9\u6cd5\uff0c\u653b\u51fb\u8005\u4f5c\u4e3a\u670d\u52a1\u63d0\u4f9b\u5546\u53ef\u4ee5\u76d1\u542c\u534f\u8bae\u901a\u4fe1\uff0c\u901a\u8fc7\u5206\u6790\u534f\u8bae\u6267\u884c\u8fc7\u7a0b\u4e2d\u7684\u4fe1\u606f\u6cc4\u9732\u6765\u6062\u590d\u7528\u6237\u4f4d\u7f6e\u6570\u636e\u3002\u653b\u51fb\u6548\u7387\u9ad8\uff0c\u4e0d\u4f9d\u8d56\u4e8e\u5b89\u5168\u53c2\u6570\u3002", "result": "\u6210\u529f\u6f14\u793a\u4e86\u5bf9PP-RHS\u534f\u8bae\u7684\u653b\u51fb\uff0c\u80fd\u591f\u5b8c\u5168\u6062\u590d\u6bcf\u4e2a\u4e58\u8f66\u8bf7\u6c42\u4e2d\u4e58\u5ba2\u548c\u54cd\u5e94\u53f8\u673a\u7684\u7cbe\u786e\u4f4d\u7f6e\u4fe1\u606f\u3002\u653b\u51fb\u5177\u6709\u9ad8\u6548\u6027\uff0c\u4e0d\u53d7\u5b89\u5168\u53c2\u6570\u9650\u5236\u3002", "conclusion": "Xie\u7b49\u4eba\u63d0\u51fa\u7684\u9690\u79c1\u4fdd\u62a4\u7f51\u7ea6\u8f66\u670d\u52a1\u534f\u8bae\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u65e0\u6cd5\u6709\u6548\u4fdd\u62a4\u7528\u6237\u4f4d\u7f6e\u9690\u79c1\uff0c\u9700\u8981\u91cd\u65b0\u8bbe\u8ba1\u66f4\u5b89\u5168\u7684\u534f\u8bae\u65b9\u6848\u3002"}}
{"id": "2510.16830", "categories": ["cs.CR", "cs.CL", "68T07, 94A60, 68Q25", "I.2.6; G.1.6; E.3; C.2.4"], "pdf": "https://arxiv.org/pdf/2510.16830", "abs": "https://arxiv.org/abs/2510.16830", "authors": ["Hasan Akgul", "Daniel Borg", "Arta Berisha", "Amina Rahimova", "Andrej Novak", "Mila Petrov"], "title": "Verifiable Fine-Tuning for LLMs: Zero-Knowledge Training Proofs Bound to Data Provenance and Policy", "comment": "20 pages, 10 figures", "summary": "Large language models are often adapted through parameter efficient fine\ntuning, but current release practices provide weak assurances about what data\nwere used and how updates were computed. We present Verifiable Fine Tuning, a\nprotocol and system that produces succinct zero knowledge proofs that a\nreleased model was obtained from a public initialization under a declared\ntraining program and an auditable dataset commitment. The approach combines\nfive elements. First, commitments that bind data sources, preprocessing,\nlicenses, and per epoch quota counters to a manifest. Second, a verifiable\nsampler that supports public replayable and private index hiding batch\nselection. Third, update circuits restricted to parameter efficient fine tuning\nthat enforce AdamW style optimizer semantics and proof friendly approximations\nwith explicit error budgets. Fourth, recursive aggregation that folds per step\nproofs into per epoch and end to end certificates with millisecond\nverification. Fifth, provenance binding and optional trusted execution property\ncards that attest code identity and constants. On English and bilingual\ninstruction mixtures, the method maintains utility within tight budgets while\nachieving practical proof performance. Policy quotas are enforced with zero\nviolations, and private sampling windows show no measurable index leakage.\nFederated experiments demonstrate that the system composes with probabilistic\naudits and bandwidth constraints. These results indicate that end to end\nverifiable fine tuning is feasible today for real parameter efficient\npipelines, closing a critical trust gap for regulated and decentralized\ndeployments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u53ef\u9a8c\u8bc1\u5fae\u8c03\u534f\u8bae\uff0c\u901a\u8fc7\u96f6\u77e5\u8bc6\u8bc1\u660e\u786e\u4fdd\u53d1\u5e03\u7684\u6a21\u578b\u786e\u5b9e\u6765\u81ea\u516c\u5f00\u521d\u59cb\u5316\uff0c\u5e76\u6309\u7167\u58f0\u660e\u7684\u8bad\u7ec3\u7a0b\u5e8f\u548c\u53ef\u5ba1\u8ba1\u7684\u6570\u636e\u96c6\u627f\u8bfa\u8fdb\u884c\u8bad\u7ec3\u3002", "motivation": "\u5f53\u524d\u7684\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u53d1\u5e03\u5b9e\u8df5\u5728\u6570\u636e\u4f7f\u7528\u548c\u66f4\u65b0\u8ba1\u7b97\u65b9\u9762\u7f3a\u4e4f\u53ef\u4fe1\u4fdd\u8bc1\uff0c\u5b58\u5728\u4fe1\u4efb\u7f3a\u53e3\uff0c\u7279\u522b\u662f\u5728\u53d7\u76d1\u7ba1\u548c\u53bb\u4e2d\u5fc3\u5316\u90e8\u7f72\u573a\u666f\u4e2d\u3002", "method": "\u7ed3\u5408\u4e94\u4e2a\u5173\u952e\u8981\u7d20\uff1a\u6570\u636e\u6e90\u627f\u8bfa\u3001\u53ef\u9a8c\u8bc1\u91c7\u6837\u5668\u3001\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u7684\u66f4\u65b0\u7535\u8def\u3001\u9012\u5f52\u805a\u5408\u8bc1\u660e\u3001\u4ee5\u53ca\u6765\u6e90\u7ed1\u5b9a\u548c\u53ef\u4fe1\u6267\u884c\u5c5e\u6027\u5361\u3002", "result": "\u5728\u82f1\u8bed\u548c\u53cc\u8bed\u6307\u4ee4\u6df7\u5408\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u4e25\u683c\u9884\u7b97\u5185\u4fdd\u6301\u4e86\u5b9e\u7528\u6027\uff0c\u5b9e\u73b0\u4e86\u5b9e\u7528\u7684\u8bc1\u660e\u6027\u80fd\uff0c\u7b56\u7565\u914d\u989d\u96f6\u8fdd\u89c4\uff0c\u79c1\u6709\u91c7\u6837\u65e0\u7d22\u5f15\u6cc4\u9732\u3002", "conclusion": "\u7aef\u5230\u7aef\u7684\u53ef\u9a8c\u8bc1\u5fae\u8c03\u5bf9\u4e8e\u771f\u5b9e\u7684\u53c2\u6570\u9ad8\u6548\u7ba1\u9053\u662f\u53ef\u884c\u7684\uff0c\u4e3a\u53d7\u76d1\u7ba1\u548c\u53bb\u4e2d\u5fc3\u5316\u90e8\u7f72\u586b\u8865\u4e86\u5173\u952e\u7684\u4fe1\u4efb\u7f3a\u53e3\u3002"}}
{"id": "2510.16753", "categories": ["cs.AI", "68T30", "H.3.3"], "pdf": "https://arxiv.org/pdf/2510.16753", "abs": "https://arxiv.org/abs/2510.16753", "authors": ["Wei Huang", "Peining Li", "Meiyu Liang", "Xu Hou", "Junping Du", "Yingxia Shao", "Guanhua Ye", "Wu Liu", "Kangkang Lu", "Yang Yu"], "title": "ELMM: Efficient Lightweight Multimodal Large Language Models for Multimodal Knowledge Graph Completion", "comment": "11 pages, 4 figures", "summary": "Multimodal Knowledge Graphs (MKGs) extend traditional knowledge graphs by\nincorporating visual and textual modalities, enabling richer and more\nexpressive entity representations. However, existing MKGs often suffer from\nincompleteness, which hinder their effectiveness in downstream tasks.\nTherefore, multimodal knowledge graph completion (MKGC) task is receiving\nincreasing attention. While large language models (LLMs) have shown promise for\nknowledge graph completion (KGC), their application to the multimodal setting\nremains underexplored. Moreover, applying Multimodal Large Language Models\n(MLLMs) to the task of MKGC introduces significant challenges: (1) the large\nnumber of image tokens per entity leads to semantic noise and modality\nconflicts, and (2) the high computational cost of processing large token\ninputs. To address these issues, we propose Efficient Lightweight Multimodal\nLarge Language Models (ELMM) for MKGC. ELMM proposes a Multi-view Visual Token\nCompressor (MVTC) based on multi-head attention mechanism, which adaptively\ncompresses image tokens from both textual and visual views, thereby effectively\nreducing redundancy while retaining necessary information and avoiding modality\nconflicts. Additionally, we design an attention pruning strategy to remove\nredundant attention layers from MLLMs, thereby significantly reducing the\ninference cost. We further introduce a linear projection to compensate for the\nperformance degradation caused by pruning. Extensive experiments on benchmark\nFB15k-237-IMG and WN18-IMG demonstrate that ELMM achieves state-of-the-art\nperformance while substantially improving computational efficiency,\nestablishing a new paradigm for multimodal knowledge graph completion.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faELMM\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u89c6\u56fe\u89c6\u89c9\u4ee4\u724c\u538b\u7f29\u5668\u548c\u6ce8\u610f\u529b\u526a\u679d\u7b56\u7565\uff0c\u89e3\u51b3\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4e2d\u7684\u8bed\u4e49\u566a\u58f0\u548c\u8ba1\u7b97\u6210\u672c\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6548\u7387\u3002", "motivation": "\u73b0\u6709MKGs\u5b58\u5728\u4e0d\u5b8c\u6574\u6027\uff0c\u5f71\u54cd\u4e0b\u6e38\u4efb\u52a1\u6548\u679c\u3002\u867d\u7136LLMs\u5728KGC\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u6a21\u6001\u73af\u5883\u4e0b\u5e94\u7528\u9762\u4e34\u56fe\u50cf\u4ee4\u724c\u8fc7\u591a\u5bfc\u81f4\u8bed\u4e49\u566a\u58f0\u3001\u6a21\u6001\u51b2\u7a81\u4ee5\u53ca\u9ad8\u8ba1\u7b97\u6210\u672c\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faELMM\u6846\u67b6\uff0c\u5305\u542b\u57fa\u4e8e\u591a\u5934\u6ce8\u610f\u529b\u7684\u591a\u89c6\u56fe\u89c6\u89c9\u4ee4\u724c\u538b\u7f29\u5668(MVTC)\uff0c\u4ece\u6587\u672c\u548c\u89c6\u89c9\u89c6\u56fe\u81ea\u9002\u5e94\u538b\u7f29\u56fe\u50cf\u4ee4\u724c\uff1b\u8bbe\u8ba1\u6ce8\u610f\u529b\u526a\u679d\u7b56\u7565\u79fb\u9664\u5197\u4f59\u5c42\uff0c\u5e76\u4f7f\u7528\u7ebf\u6027\u6295\u5f71\u8865\u507f\u6027\u80fd\u635f\u5931\u3002", "result": "\u5728FB15k-237-IMG\u548cWN18-IMG\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cELMM\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "ELMM\u4e3a\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u5efa\u7acb\u4e86\u65b0\u8303\u5f0f\uff0c\u6709\u6548\u5e73\u8861\u4e86\u6027\u80fd\u4e0e\u6548\u7387\u3002"}}
{"id": "2510.16835", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16835", "abs": "https://arxiv.org/abs/2510.16835", "authors": ["Hongpeng Bai", "Minhong Dong", "Yao Zhang", "Shunzhe Zhao", "Haobo Zhang", "Lingyue Li", "Yude Bai", "Guangquan Xu"], "title": "ThreatIntel-Andro: Expert-Verified Benchmarking for Robust Android Malware Research", "comment": null, "summary": "The rapidly evolving Android malware ecosystem demands high-quality,\nreal-time datasets as a foundation for effective detection and defense. With\nthe widespread adoption of mobile devices across industrial systems, they have\nbecome a critical yet often overlooked attack surface in industrial\ncybersecurity. However, mainstream datasets widely used in academia and\nindustry (e.g., Drebin) exhibit significant limitations: on one hand, their\nheavy reliance on VirusTotal's multi-engine aggregation results introduces\nsubstantial label noise; on the other hand, outdated samples reduce their\ntemporal relevance. Moreover, automated labeling tools (e.g., AVClass2) suffer\nfrom suboptimal aggregation strategies, further compounding labeling errors and\npropagating inaccuracies throughout the research community.", "AI": {"tldr": "Android\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u9762\u4e34\u6570\u636e\u96c6\u8d28\u91cf\u95ee\u9898\uff0c\u4e3b\u6d41\u6570\u636e\u96c6\u5b58\u5728\u6807\u7b7e\u566a\u58f0\u548c\u65f6\u6548\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u81ea\u52a8\u6807\u6ce8\u5de5\u5177\u4e5f\u5b58\u5728\u805a\u5408\u7b56\u7565\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u79fb\u52a8\u8bbe\u5907\u5728\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0cAndroid\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u6570\u636e\u96c6\u5b58\u5728\u6807\u7b7e\u566a\u58f0\u548c\u65f6\u6548\u6027\u95ee\u9898\uff0c\u5f71\u54cd\u4e86\u68c0\u6d4b\u6548\u679c\u3002", "method": "\u8bba\u6587\u672a\u660e\u786e\u63cf\u8ff0\u5177\u4f53\u65b9\u6cd5\uff0c\u4f46\u6307\u51fa\u4e86\u73b0\u6709\u6570\u636e\u96c6\u548c\u81ea\u52a8\u6807\u6ce8\u5de5\u5177\u7684\u5c40\u9650\u6027\u3002", "result": "\u5206\u6790\u53d1\u73b0\u4e3b\u6d41\u6570\u636e\u96c6\uff08\u5982Drebin\uff09\u4f9d\u8d56VirusTotal\u591a\u5f15\u64ce\u805a\u5408\u5bfc\u81f4\u6807\u7b7e\u566a\u58f0\uff0c\u6837\u672c\u8fc7\u65f6\u964d\u4f4e\u65f6\u6548\u6027\uff0c\u81ea\u52a8\u6807\u6ce8\u5de5\u5177\uff08\u5982AVClass2\uff09\u805a\u5408\u7b56\u7565\u4e0d\u4f73\u52a0\u5267\u6807\u7b7e\u9519\u8bef\u3002", "conclusion": "Android\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u9700\u8981\u66f4\u9ad8\u8d28\u91cf\u3001\u5b9e\u65f6\u7684\u6570\u636e\u96c6\u4f5c\u4e3a\u6709\u6548\u68c0\u6d4b\u548c\u9632\u5fa1\u7684\u57fa\u7840\uff0c\u5f53\u524d\u6570\u636e\u96c6\u548c\u6807\u6ce8\u5de5\u5177\u5b58\u5728\u660e\u663e\u7f3a\u9677\u9700\u8981\u6539\u8fdb\u3002"}}
{"id": "2510.16871", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16871", "abs": "https://arxiv.org/abs/2510.16871", "authors": ["Anirban Chakraborty", "Nimish Mishra", "Sayandeep Saha", "Sarani Bhattacharya", "Debdeep Mukhopadhyay"], "title": "Addendum: Systematic Evaluation of Randomized Cache Designs against Cache Occupancy", "comment": null, "summary": "In the main text published at USENIX Security 2025, we presented a systematic\nanalysis of the role of cache occupancy in the design considerations for\nrandomized caches (from the perspectives of performance and security). On the\nperformance front, we presented a uniform benchmarking strategy that allows for\na fair comparison among different randomized cache designs. Likewise, from the\nsecurity perspective, we presented three threat assumptions: (1) covert\nchannels; (2) process fingerprinting side-channel; and (3) AES key recovery.\nThe main takeaway of our work is an open problem of designing a randomized\ncache of comparable efficiency with modern set-associative LLCs, while still\nresisting both contention-based and occupancy-based attacks. This note is meant\nas an addendum to the main text in light of the observations made in [2]. To\nsummarize, the authors in [2] argue that (1) L1d cache size plays a role in\nadversarial success, and that (2) a patched version of MIRAGE with randomized\ninitial seeding of global eviction map prevents leakage of AES key. We discuss\nthe same in this addendum.", "AI": {"tldr": "\u672c\u6587\u662f\u5bf9USENIX Security 2025\u4e3b\u8bba\u6587\u7684\u8865\u5145\u8bf4\u660e\uff0c\u8ba8\u8bba\u4e86\u968f\u673a\u5316\u7f13\u5b58\u5728\u6027\u80fd\u548c\u5b89\u5168\u6027\u65b9\u9762\u7684\u8bbe\u8ba1\u8003\u8651\uff0c\u7279\u522b\u662f\u9488\u5bf9[2]\u4e2d\u63d0\u51fa\u7684\u89c2\u5bdf\u7ed3\u679c\u8fdb\u884c\u56de\u5e94\u3002", "motivation": "\u5bf9\u968f\u673a\u5316\u7f13\u5b58\u8bbe\u8ba1\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u4ece\u6027\u80fd\u548c\u5b89\u5168\u6027\u4e24\u4e2a\u89d2\u5ea6\u8bc4\u4f30\u4e0d\u540c\u8bbe\u8ba1\u65b9\u6848\uff0c\u5e76\u56de\u5e94\u5f53\u524d\u7814\u7a76\u4e2d\u7684\u65b0\u53d1\u73b0\u3002", "method": "\u91c7\u7528\u7edf\u4e00\u7684\u57fa\u51c6\u6d4b\u8bd5\u7b56\u7565\u6765\u516c\u5e73\u6bd4\u8f83\u4e0d\u540c\u968f\u673a\u5316\u7f13\u5b58\u8bbe\u8ba1\uff0c\u5e76\u4ece\u5b89\u5168\u89d2\u5ea6\u8003\u8651\u4e09\u79cd\u5a01\u80c1\u5047\u8bbe\uff1a\u9690\u853d\u4fe1\u9053\u3001\u8fdb\u7a0b\u6307\u7eb9\u4fa7\u4fe1\u9053\u548cAES\u5bc6\u94a5\u6062\u590d\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8bbe\u8ba1\u4e00\u4e2a\u65e2\u5177\u6709\u73b0\u4ee3\u7ec4\u5173\u8054LLC\u76f8\u5f53\u6548\u7387\u53c8\u80fd\u62b5\u6297\u57fa\u4e8e\u7ade\u4e89\u548c\u57fa\u4e8e\u5360\u7528\u653b\u51fb\u7684\u968f\u673a\u5316\u7f13\u5b58\u4ecd\u7136\u662f\u4e00\u4e2a\u5f00\u653e\u6027\u95ee\u9898\u3002[2]\u4e2d\u7684\u89c2\u5bdf\u8868\u660eL1d\u7f13\u5b58\u5927\u5c0f\u5bf9\u653b\u51fb\u6210\u529f\u6709\u5f71\u54cd\uff0c\u4e14\u5e26\u6709\u968f\u673a\u521d\u59cb\u79cd\u5b50\u7684MIRAGE\u8865\u4e01\u7248\u672c\u53ef\u4ee5\u9632\u6b62AES\u5bc6\u94a5\u6cc4\u6f0f\u3002", "conclusion": "\u968f\u673a\u5316\u7f13\u5b58\u8bbe\u8ba1\u9700\u8981\u5728\u6027\u80fd\u548c\u5b89\u5168\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u5f53\u524d\u4ecd\u9762\u4e34\u6311\u6218\u3002\u5bf9[2]\u4e2d\u63d0\u51fa\u7684\u95ee\u9898\u8fdb\u884c\u4e86\u8ba8\u8bba\u548c\u56de\u5e94\u3002"}}
{"id": "2510.16873", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16873", "abs": "https://arxiv.org/abs/2510.16873", "authors": ["Jacob Leiken", "Sunoo Park"], "title": "On the Credibility of Deniable Communication in Court", "comment": null, "summary": "Over time, cryptographically deniable systems have come to be associated in\ncomputer-science literature with the idea of \"denying\" evidence in court -\nspecifically, with the ability to convincingly forge evidence in courtroom\nscenarios and an inability to authenticate evidence in such contexts.\nEvidentiary processes in courts, however, have been developed over centuries to\naccount for the reality that evidence has always been forgeable, and relies on\nfactors outside of cryptographic models to seek the truth \"as well as possible\"\nwhile acknowledging that all evidence is imperfect. We argue that deniability\ndoes not and need not change this paradigm.\n  Our analysis highlights a gap between technical deniability notions and their\napplication to the real world. There will always be factors outside a\ncryptographic model that influence perceptions of a message's authenticity, in\nrealistic situations. We propose the broader concept of credibility to capture\nthese factors. The credibility of a system is determined by (1) a threshold of\nquality that a forgery must pass to be \"believable\" as an original\ncommunication, which varies based on sociotechnical context and threat model,\n(2) the ease of creating a forgery that passes this threshold, which is also\ncontext- and threat-model-dependent, and (3) default system retention policy\nand retention settings. All three aspects are important for designing secure\ncommunication systems for real-world threat models, and some aspects of (2) and\n(3) may be incorporated directly into technical system design. We hope that our\nmodel of credibility will facilitate system design and deployment that\naddresses threats that are not and cannot be captured by purely technical\ndefinitions and existing cryptographic models, and support more nuanced\ndiscourse on the strengths and limitations of cryptographic guarantees within\nspecific legal and sociotechnical contexts.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6279\u5224\u4e86\u5bc6\u7801\u5b66\u4e2d\u53ef\u5426\u8ba4\u6027\u6982\u5ff5\u4e0e\u6cd5\u5ead\u8bc1\u636e\u5b9e\u8df5\u7684\u8131\u8282\uff0c\u63d0\u51fa\u4e86\u66f4\u5168\u9762\u7684\u53ef\u4fe1\u5ea6\u6982\u5ff5\uff0c\u5305\u542b\u4f2a\u9020\u8d28\u91cf\u9608\u503c\u3001\u4f2a\u9020\u96be\u6613\u7a0b\u5ea6\u548c\u7cfb\u7edf\u4fdd\u7559\u7b56\u7565\u4e09\u4e2a\u7ef4\u5ea6\u3002", "motivation": "\u4f20\u7edf\u5bc6\u7801\u5b66\u53ef\u5426\u8ba4\u6027\u6982\u5ff5\u8fc7\u4e8e\u6280\u672f\u5316\uff0c\u672a\u80fd\u5145\u5206\u8003\u8651\u73b0\u5b9e\u4e16\u754c\u4e2d\u8bc1\u636e\u8ba4\u8bc1\u7684\u590d\u6742\u6027\uff0c\u7279\u522b\u662f\u6cd5\u5ead\u8bc1\u636e\u5904\u7406\u4e2d\u65e9\u5df2\u8003\u8651\u8bc1\u636e\u53ef\u4f2a\u9020\u6027\u7684\u73b0\u5b9e\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5bc6\u7801\u5b66\u6a21\u578b\u4e0e\u73b0\u5b9e\u4e16\u754c\u8bc1\u636e\u5b9e\u8df5\u7684\u5dee\u8ddd\uff0c\u63d0\u51fa\u53ef\u4fe1\u5ea6\u6982\u5ff5\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ef4\u5ea6\uff1a\u4f2a\u9020\u8d28\u91cf\u9608\u503c\u3001\u4f2a\u9020\u96be\u6613\u7a0b\u5ea6\u548c\u7cfb\u7edf\u4fdd\u7559\u7b56\u7565\u3002", "result": "\u5efa\u7acb\u4e86\u66f4\u5168\u9762\u7684\u53ef\u4fe1\u5ea6\u6a21\u578b\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6307\u5bfc\u73b0\u5b9e\u4e16\u754c\u5b89\u5168\u901a\u4fe1\u7cfb\u7edf\u7684\u8bbe\u8ba1\uff0c\u8003\u8651\u6280\u672f\u5b9a\u4e49\u65e0\u6cd5\u6355\u6349\u7684\u5a01\u80c1\u56e0\u7d20\u3002", "conclusion": "\u53ef\u4fe1\u5ea6\u6982\u5ff5\u6709\u52a9\u4e8e\u5728\u7279\u5b9a\u6cd5\u5f8b\u548c\u793e\u4f1a\u6280\u672f\u80cc\u666f\u4e0b\u66f4\u7ec6\u81f4\u5730\u8ba8\u8bba\u5bc6\u7801\u5b66\u4fdd\u8bc1\u7684\u5f3a\u5ea6\u548c\u5c40\u9650\u6027\uff0c\u4fc3\u8fdb\u66f4\u5b9e\u7528\u7684\u5b89\u5168\u7cfb\u7edf\u8bbe\u8ba1\u3002"}}
{"id": "2510.16802", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16802", "abs": "https://arxiv.org/abs/2510.16802", "authors": ["Chao Li", "Yuru Wang"], "title": "Domain-Contextualized Concept Graphs: A Computable Framework for Knowledge Representation", "comment": "14 pages", "summary": "Traditional knowledge graphs are constrained by fixed ontologies that\norganize concepts within rigid hierarchical structures. The root cause lies in\ntreating domains as implicit context rather than as explicit, reasoning-level\ncomponents. To overcome these limitations, we propose the Domain-Contextualized\nConcept Graph (CDC), a novel knowledge modeling framework that elevates domains\nto first-class elements of conceptual representation. CDC adopts a C-D-C triple\nstructure - <Concept, Relation@Domain, Concept'> - where domain specifications\nserve as dynamic classification dimensions defined on demand. Grounded in a\ncognitive-linguistic isomorphic mapping principle, CDC operationalizes how\nhumans understand concepts through contextual frames. We formalize more than\ntwenty standardized relation predicates (structural, logical, cross-domain, and\ntemporal) and implement CDC in Prolog for full inference capability. Case\nstudies in education, enterprise knowledge systems, and technical documentation\ndemonstrate that CDC enables context-aware reasoning, cross-domain analogy, and\npersonalized knowledge modeling - capabilities unattainable under traditional\nontology-based frameworks.", "AI": {"tldr": "\u63d0\u51fa\u9886\u57df\u60c5\u5883\u5316\u6982\u5ff5\u56fe\uff08CDC\uff09\u6846\u67b6\uff0c\u5c06\u9886\u57df\u4f5c\u4e3a\u6982\u5ff5\u8868\u793a\u7684\u4e00\u7b49\u5143\u7d20\uff0c\u91c7\u7528<\u6982\u5ff5, \u5173\u7cfb@\u9886\u57df, \u6982\u5ff5'>\u7684\u4e09\u5143\u7ec4\u7ed3\u6784\uff0c\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u548c\u8de8\u9886\u57df\u7c7b\u6bd4\u3002", "motivation": "\u4f20\u7edf\u77e5\u8bc6\u56fe\u8c31\u53d7\u9650\u4e8e\u56fa\u5b9a\u672c\u4f53\u8bba\u7684\u521a\u6027\u5c42\u6b21\u7ed3\u6784\uff0c\u6839\u672c\u539f\u56e0\u5728\u4e8e\u5c06\u9886\u57df\u89c6\u4e3a\u9690\u542b\u4e0a\u4e0b\u6587\u800c\u975e\u663e\u5f0f\u63a8\u7406\u7ec4\u4ef6\u3002", "method": "\u57fa\u4e8e\u8ba4\u77e5-\u8bed\u8a00\u540c\u6784\u6620\u5c04\u539f\u7406\uff0c\u91c7\u7528C-D-C\u4e09\u5143\u7ec4\u7ed3\u6784\uff0c\u5b9a\u4e4920\u591a\u79cd\u6807\u51c6\u5316\u5173\u7cfb\u8c13\u8bcd\uff08\u7ed3\u6784\u3001\u903b\u8f91\u3001\u8de8\u9886\u57df\u3001\u65f6\u95f4\uff09\uff0c\u5e76\u5728Prolog\u4e2d\u5b9e\u73b0\u5b8c\u6574\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728\u6559\u80b2\u3001\u4f01\u4e1a\u77e5\u8bc6\u7cfb\u7edf\u548c\u6280\u672f\u6587\u6863\u7b49\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cCDC\u5b9e\u73b0\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u3001\u8de8\u9886\u57df\u7c7b\u6bd4\u548c\u4e2a\u6027\u5316\u77e5\u8bc6\u5efa\u6a21\u3002", "conclusion": "CDC\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u4f20\u7edf\u57fa\u4e8e\u672c\u4f53\u7684\u6846\u67b6\u65e0\u6cd5\u8fbe\u5230\u7684\u80fd\u529b\uff0c\u4e3a\u77e5\u8bc6\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u52a8\u6001\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.16923", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16923", "abs": "https://arxiv.org/abs/2510.16923", "authors": ["Mansi Phute", "Matthew Hull", "Haoran Wang", "Alec Helbling", "ShengYun Peng", "Willian Lunardi", "Martin Andreoni", "Wenke Lee", "Polo Chau"], "title": "UNDREAM: Bridging Differentiable Rendering and Photorealistic Simulation for End-to-end Adversarial Attacks", "comment": null, "summary": "Deep learning models deployed in safety critical applications like autonomous\ndriving use simulations to test their robustness against adversarial attacks in\nrealistic conditions. However, these simulations are non-differentiable,\nforcing researchers to create attacks that do not integrate simulation\nenvironmental factors, reducing attack success. To address this limitation, we\nintroduce UNDREAM, the first software framework that bridges the gap between\nphotorealistic simulators and differentiable renderers to enable end-to-end\noptimization of adversarial perturbations on any 3D objects. UNDREAM enables\nmanipulation of the environment by offering complete control over weather,\nlighting, backgrounds, camera angles, trajectories, and realistic human and\nobject movements, thereby allowing the creation of diverse scenes. We showcase\na wide array of distinct physically plausible adversarial objects that UNDREAM\nenables researchers to swiftly explore in different configurable environments.\nThis combination of photorealistic simulation and differentiable optimization\nopens new avenues for advancing research of physical adversarial attacks.", "AI": {"tldr": "UNDREAM\u662f\u4e00\u4e2a\u5c06\u7167\u7247\u7ea7\u771f\u5b9e\u611f\u6a21\u62df\u5668\u4e0e\u53ef\u5fae\u5206\u6e32\u67d3\u5668\u7ed3\u5408\u7684\u8f6f\u4ef6\u6846\u67b6\uff0c\u652f\u6301\u57283D\u5bf9\u8c61\u4e0a\u7aef\u5230\u7aef\u4f18\u5316\u5bf9\u6297\u6027\u6270\u52a8\uff0c\u5e76\u80fd\u63a7\u5236\u73af\u5883\u56e0\u7d20\u5982\u5929\u6c14\u3001\u5149\u7167\u3001\u80cc\u666f\u7b49\u3002", "motivation": "\u73b0\u6709\u6a21\u62df\u5668\u4e0d\u53ef\u5fae\u5206\uff0c\u5bfc\u81f4\u5bf9\u6297\u653b\u51fb\u7814\u7a76\u65e0\u6cd5\u6574\u5408\u73af\u5883\u56e0\u7d20\uff0c\u964d\u4f4e\u4e86\u653b\u51fb\u6210\u529f\u7387\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u7167\u7247\u7ea7\u771f\u5b9e\u611f\u6a21\u62df\u5668\u548c\u53ef\u5fae\u5206\u6e32\u67d3\u5668\uff0c\u63d0\u4f9b\u5bf9\u73af\u5883\u56e0\u7d20\uff08\u5929\u6c14\u3001\u5149\u7167\u3001\u80cc\u666f\u3001\u76f8\u673a\u89d2\u5ea6\u7b49\uff09\u7684\u5b8c\u5168\u63a7\u5236\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u4f18\u5316\u3002", "result": "\u5c55\u793a\u4e86\u591a\u79cd\u7269\u7406\u4e0a\u5408\u7406\u7684\u5bf9\u6297\u6027\u5bf9\u8c61\uff0c\u53ef\u5728\u4e0d\u540c\u53ef\u914d\u7f6e\u73af\u5883\u4e2d\u5feb\u901f\u63a2\u7d22\u3002", "conclusion": "\u7167\u7247\u7ea7\u771f\u5b9e\u611f\u6a21\u62df\u4e0e\u53ef\u5fae\u5206\u4f18\u5316\u7684\u7ed3\u5408\u4e3a\u7269\u7406\u5bf9\u6297\u653b\u51fb\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.16959", "categories": ["cs.CR", "cs.CC"], "pdf": "https://arxiv.org/pdf/2510.16959", "abs": "https://arxiv.org/abs/2510.16959", "authors": ["Surendra Ghentiyala"], "title": "Efficient derandomization of differentially private counting queries", "comment": "Accepted to SOSA'26", "summary": "Differential privacy for the 2020 census required an estimated 90 terabytes\nof randomness [GL20], an amount which may be prohibitively expensive or\nentirely infeasible to generate. Motivated by these practical concerns, [CSV25]\ninitiated the study of the randomness complexity of differential privacy, and\nin particular, the randomness complexity of $d$ counting queries. This is the\ntask of outputting the number of entries in a dataset that satisfy predicates\n$\\mathcal{P}_1, \\dots, \\mathcal{P}_d$ respectively. They showed the rather\nsurprising fact that though any reasonably accurate,\n$\\varepsilon$-differentially private mechanism for one counting query requires\n$1-O(\\varepsilon)$ bits of randomness in expectation, there exists a fairly\naccurate mechanism for $d$ counting queries which requires only $O(\\log d)$\nbits of randomness in expectation.\n  The mechanism of [CSV25] is inefficient (not polynomial time) and relies on a\ncombinatorial object known as rounding schemes. Here, we give a polynomial time\nmechanism which achieves nearly the same randomness complexity versus accuracy\ntradeoff as that of [CSV25]. Our construction is based on the following simple\nobservation: after a randomized shift of the answer to each counting query, the\nanswer to many counting queries remains the same regardless of whether we add\nnoise to that coordinate or not. This allows us to forgo the step of adding\nnoise to the result of many counting queries. Our mechanism does not make use\nof rounding schemes. Therefore, it provides a different -- and, in our opinion,\nclearer -- insight into the origins of the randomness savings that can be\nobtained by batching $d$ counting queries. Therefore, it provides a different\n-- and, in our opinion, clearer -- insight into the origins of the randomness\nsavings that can be obtained by batching $d$ counting queries.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9879\u5f0f\u65f6\u95f4\u673a\u5236\uff0c\u7528\u4e8ed\u4e2a\u8ba1\u6570\u67e5\u8be2\u7684\u5dee\u5206\u9690\u79c1\uff0c\u4ec5\u9700O(log d)\u4f4d\u968f\u673a\u6027\uff0c\u76f8\u6bd4\u4e4b\u524d\u9700\u898190TB\u968f\u673a\u6027\u7684\u65b9\u6cd5\u5927\u5e45\u964d\u4f4e\u4e86\u968f\u673a\u6027\u9700\u6c42\u3002", "motivation": "2020\u5e74\u4eba\u53e3\u666e\u67e5\u7684\u5dee\u5206\u9690\u79c1\u9700\u898190TB\u968f\u673a\u6027\uff0c\u8fd9\u5728\u5b9e\u8df5\u4e2d\u53ef\u80fd\u8fc7\u4e8e\u6602\u8d35\u6216\u4e0d\u53ef\u884c\u3002\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5dee\u5206\u9690\u79c1\u7684\u968f\u673a\u6027\u590d\u6742\u6027\uff0c\u7279\u522b\u662fd\u4e2a\u8ba1\u6570\u67e5\u8be2\u7684\u968f\u673a\u6027\u9700\u6c42\u3002", "method": "\u57fa\u4e8e\u4e00\u4e2a\u7b80\u5355\u89c2\u5bdf\uff1a\u5728\u5bf9\u6bcf\u4e2a\u8ba1\u6570\u67e5\u8be2\u8fdb\u884c\u968f\u673a\u504f\u79fb\u540e\uff0c\u8bb8\u591a\u67e5\u8be2\u7684\u7b54\u6848\u5728\u662f\u5426\u6dfb\u52a0\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\u4fdd\u6301\u4e0d\u53d8\u3002\u8fd9\u5141\u8bb8\u6211\u4eec\u7701\u7565\u5bf9\u8bb8\u591a\u8ba1\u6570\u67e5\u8be2\u7ed3\u679c\u6dfb\u52a0\u566a\u58f0\u7684\u6b65\u9aa4\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f7f\u7528\u820d\u5165\u65b9\u6848\uff0c\u800c\u662f\u591a\u9879\u5f0f\u65f6\u95f4\u673a\u5236\u3002", "result": "\u63d0\u51fa\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u673a\u5236\u5b9e\u73b0\u4e86\u4e0e[CSV25]\u51e0\u4e4e\u76f8\u540c\u7684\u968f\u673a\u6027\u590d\u6742\u5ea6\u4e0e\u51c6\u786e\u6027\u6743\u8861\uff0c\u4ec5\u9700O(log d)\u4f4d\u968f\u673a\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u6e05\u6670\u7684\u65b9\u6cd5\u6765\u7406\u89e3\u901a\u8fc7\u6279\u91cf\u5904\u7406d\u4e2a\u8ba1\u6570\u67e5\u8be2\u53ef\u4ee5\u83b7\u5f97\u7684\u968f\u673a\u6027\u8282\u7701\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5dee\u5206\u9690\u79c1\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17000", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17000", "abs": "https://arxiv.org/abs/2510.17000", "authors": ["Masahiro Kaneko", "Timothy Baldwin"], "title": "Bits Leaked per Query: Information-Theoretic Bounds on Adversarial Attacks against LLMs", "comment": "NeurIPS 2025 (spotlight)", "summary": "Adversarial attacks by malicious users that threaten the safety of large\nlanguage models (LLMs) can be viewed as attempts to infer a target property $T$\nthat is unknown when an instruction is issued, and becomes knowable only after\nthe model's reply is observed. Examples of target properties $T$ include the\nbinary flag that triggers an LLM's harmful response or rejection, and the\ndegree to which information deleted by unlearning can be restored, both\nelicited via adversarial instructions. The LLM reveals an \\emph{observable\nsignal} $Z$ that potentially leaks hints for attacking through a response\ncontaining answer tokens, thinking process tokens, or logits. Yet the scale of\ninformation leaked remains anecdotal, leaving auditors without principled\nguidance and defenders blind to the transparency--risk trade-off. We fill this\ngap with an information-theoretic framework that computes how much information\ncan be safely disclosed, and enables auditors to gauge how close their methods\ncome to the fundamental limit. Treating the mutual information $I(Z;T)$ between\nthe observation $Z$ and the target property $T$ as the leaked bits per query,\nwe show that achieving error $\\varepsilon$ requires at least\n$\\log(1/\\varepsilon)/I(Z;T)$ queries, scaling linearly with the inverse leak\nrate and only logarithmically with the desired accuracy. Thus, even a modest\nincrease in disclosure collapses the attack cost from quadratic to logarithmic\nin terms of the desired accuracy. Experiments on seven LLMs across\nsystem-prompt leakage, jailbreak, and relearning attacks corroborate the\ntheory: exposing answer tokens alone requires about a thousand queries; adding\nlogits cuts this to about a hundred; and revealing the full thinking process\ntrims it to a few dozen. Our results provide the first principled yardstick for\nbalancing transparency and security when deploying LLMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4fe1\u606f\u8bba\u6846\u67b6\u6765\u91cf\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u5bf9\u6297\u653b\u51fb\u4e2d\u7684\u4fe1\u606f\u6cc4\u9732\u98ce\u9669\uff0c\u901a\u8fc7\u8ba1\u7b97\u53ef\u89c2\u5bdf\u4fe1\u53f7\u4e0e\u76ee\u6807\u5c5e\u6027\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u6765\u8bc4\u4f30\u653b\u51fb\u6210\u672c\uff0c\u5e76\u5c55\u793a\u4e86\u4e0d\u540c\u900f\u660e\u5ea6\u7ea7\u522b\u5bf9\u653b\u51fb\u6548\u7387\u7684\u5f71\u54cd\u3002", "motivation": "\u5f53\u524dLLMs\u9762\u4e34\u6076\u610f\u7528\u6237\u7684\u5bf9\u6297\u653b\u51fb\u5a01\u80c1\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u89c2\u5bdf\u6a21\u578b\u7684\u54cd\u5e94\u6765\u63a8\u65ad\u672a\u77e5\u76ee\u6807\u5c5e\u6027\u3002\u7136\u800c\uff0c\u4fe1\u606f\u6cc4\u9732\u7684\u7a0b\u5ea6\u7f3a\u4e4f\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u5bfc\u81f4\u5ba1\u8ba1\u8005\u7f3a\u4e4f\u539f\u5219\u6027\u6307\u5bfc\uff0c\u9632\u5fa1\u8005\u96be\u4ee5\u6743\u8861\u900f\u660e\u5ea6\u4e0e\u98ce\u9669\u3002", "method": "\u91c7\u7528\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u5c06\u53ef\u89c2\u5bdf\u4fe1\u53f7Z\u4e0e\u76ee\u6807\u5c5e\u6027T\u4e4b\u95f4\u7684\u4e92\u4fe1\u606fI(Z;T)\u4f5c\u4e3a\u6bcf\u6b21\u67e5\u8be2\u6cc4\u9732\u7684\u6bd4\u7279\u6570\uff0c\u63a8\u5bfc\u51fa\u8fbe\u5230\u7279\u5b9a\u9519\u8bef\u7387\u6240\u9700\u7684\u6700\u5c0f\u67e5\u8be2\u6b21\u6570\u516c\u5f0f\u3002", "result": "\u5b9e\u9a8c\u57287\u4e2aLLMs\u4e0a\u8fdb\u884c\uff0c\u6db5\u76d6\u7cfb\u7edf\u63d0\u793a\u6cc4\u9732\u3001\u8d8a\u72f1\u548c\u91cd\u65b0\u5b66\u4e60\u653b\u51fb\uff1a\u4ec5\u66b4\u9732\u7b54\u6848\u6807\u8bb0\u9700\u8981\u7ea61000\u6b21\u67e5\u8be2\uff1b\u6dfb\u52a0\u5bf9\u6570\u6982\u7387\u53ef\u51cf\u5c11\u5230\u7ea6100\u6b21\uff1b\u63ed\u793a\u5b8c\u6574\u601d\u7ef4\u8fc7\u7a0b\u4ec5\u9700\u51e0\u5341\u6b21\u67e5\u8be2\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u90e8\u7f72LLMs\u65f6\u5e73\u8861\u900f\u660e\u5ea6\u4e0e\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u9996\u4e2a\u539f\u5219\u6027\u8861\u91cf\u6807\u51c6\uff0c\u8868\u660e\u9002\u5ea6\u589e\u52a0\u4fe1\u606f\u6cc4\u9732\u4f1a\u4f7f\u653b\u51fb\u6210\u672c\u4ece\u4e8c\u6b21\u65b9\u964d\u81f3\u5bf9\u6570\u7ea7\u522b\u3002"}}
{"id": "2510.16956", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16956", "abs": "https://arxiv.org/abs/2510.16956", "authors": ["Mark Towers", "Yali Du", "Christopher Freeman", "Timothy J. Norman"], "title": "A Comparative User Evaluation of XRL Explanations using Goal Identification", "comment": "Accepted to ECAI 2025 Workshop on Evaluating Explainable AI and\n  Complex Decision-Making, 8 Pages", "summary": "Debugging is a core application of explainable reinforcement learning (XRL)\nalgorithms; however, limited comparative evaluations have been conducted to\nunderstand their relative performance. We propose a novel evaluation\nmethodology to test whether users can identify an agent's goal from an\nexplanation of its decision-making. Utilising the Atari's Ms. Pacman\nenvironment and four XRL algorithms, we find that only one achieved greater\nthan random accuracy for the tested goals and that users were generally\noverconfident in their selections. Further, we find that users' self-reported\nease of identification and understanding for every explanation did not\ncorrelate with their accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7528\u4e8e\u6d4b\u8bd5\u7528\u6237\u80fd\u5426\u4ece\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u51b3\u7b56\u89e3\u91ca\u4e2d\u8bc6\u522b\u51fa\u667a\u80fd\u4f53\u7684\u76ee\u6807\u3002\u5728Ms. Pacman\u73af\u5883\u4e2d\u6d4b\u8bd5\u56db\u79cd\u53ef\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u53d1\u73b0\u53ea\u6709\u4e00\u79cd\u7b97\u6cd5\u5728\u6d4b\u8bd5\u76ee\u6807\u4e0a\u7684\u51c6\u786e\u7387\u8d85\u8fc7\u968f\u673a\u6c34\u5e73\uff0c\u4e14\u7528\u6237\u666e\u904d\u9ad8\u4f30\u81ea\u5df1\u7684\u9009\u62e9\u51c6\u786e\u6027\u3002", "motivation": "\u53ef\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u6838\u5fc3\u5e94\u7528\u4e4b\u4e00\u662f\u8c03\u8bd5\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u7b97\u6cd5\u76f8\u5bf9\u6027\u80fd\u7684\u6bd4\u8f83\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528Atari\u7684Ms. Pacman\u73af\u5883\u548c\u56db\u79cd\u53ef\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u8bc4\u4f30\u65b9\u6cd5\u6d4b\u8bd5\u7528\u6237\u4ece\u51b3\u7b56\u89e3\u91ca\u4e2d\u8bc6\u522b\u667a\u80fd\u4f53\u76ee\u6807\u7684\u80fd\u529b\u3002", "result": "\u53ea\u6709\u4e00\u79cd\u7b97\u6cd5\u7684\u51c6\u786e\u7387\u8d85\u8fc7\u968f\u673a\u6c34\u5e73\uff1b\u7528\u6237\u666e\u904d\u8868\u73b0\u51fa\u8fc7\u5ea6\u81ea\u4fe1\uff1b\u7528\u6237\u81ea\u62a5\u7684\u8bc6\u522b\u548c\u7406\u89e3\u96be\u6613\u7a0b\u5ea6\u4e0e\u5b9e\u9645\u51c6\u786e\u7387\u4e0d\u76f8\u5173\u3002", "conclusion": "\u5f53\u524d\u53ef\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u5e2e\u52a9\u7528\u6237\u8bc6\u522b\u667a\u80fd\u4f53\u76ee\u6807\u65b9\u9762\u7684\u6548\u679c\u6709\u9650\uff0c\u7528\u6237\u7684\u4e3b\u89c2\u611f\u77e5\u4e0e\u5b9e\u9645\u6027\u80fd\u5b58\u5728\u5dee\u5f02\u3002"}}
{"id": "2510.17033", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.17033", "abs": "https://arxiv.org/abs/2510.17033", "authors": ["Leixu Huang", "Zedian Shao", "Teodora Baluta"], "title": "Watermark Robustness and Radioactivity May Be at Odds in Federated Learning", "comment": "9 pages, 4 figures (not including citation and appendix) submitted to\n  ICLR 2026", "summary": "Federated learning (FL) enables fine-tuning large language models (LLMs)\nacross distributed data sources. As these sources increasingly include\nLLM-generated text, provenance tracking becomes essential for accountability\nand transparency. We adapt LLM watermarking for data provenance in FL where a\nsubset of clients compute local updates on watermarked data, and the server\naverages all updates into the global LLM. In this setup, watermarks are\nradioactive: the watermark signal remains detectable after fine-tuning with\nhigh confidence. The $p$-value can reach $10^{-24}$ even when as little as\n$6.6\\%$ of data is watermarked. However, the server can act as an active\nadversary that wants to preserve model utility while evading provenance\ntracking. Our observation is that updates induced by watermarked synthetic data\nappear as outliers relative to non-watermark updates. Our adversary thus\napplies strong robust aggregation that can filter these outliers, together with\nthe watermark signal. All evaluated radioactive watermarks are not robust\nagainst such an active filtering server. Our work suggests fundamental\ntrade-offs between radioactivity, robustness, and utility.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u8054\u90a6\u5b66\u4e60\u4e2dLLM\u751f\u6210\u6570\u636e\u7684\u6eaf\u6e90\u95ee\u9898\uff0c\u63d0\u51fa\u653e\u5c04\u6027\u6c34\u5370\u65b9\u6cd5\uff0c\u4f46\u53d1\u73b0\u4e3b\u52a8\u8fc7\u6ee4\u670d\u52a1\u5668\u53ef\u4ee5\u79fb\u9664\u6c34\u5370\u4fe1\u53f7\uff0c\u63ed\u793a\u4e86\u653e\u5c04\u6027\u3001\u9c81\u68d2\u6027\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u3002", "motivation": "\u968f\u7740\u8054\u90a6\u5b66\u4e60\u4e2d\u8d8a\u6765\u8d8a\u591a\u4f7f\u7528LLM\u751f\u6210\u7684\u6570\u636e\uff0c\u9700\u8981\u786e\u4fdd\u6570\u636e\u6765\u6e90\u7684\u53ef\u8ffd\u6eaf\u6027\u548c\u900f\u660e\u5ea6\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u6570\u636e\u6eaf\u6e90\u65b9\u6cd5\u3002", "method": "\u5c06LLM\u6c34\u5370\u6280\u672f\u5e94\u7528\u4e8e\u8054\u90a6\u5b66\u4e60\uff0c\u8ba9\u90e8\u5206\u5ba2\u6237\u7aef\u5728\u5e26\u6709\u6c34\u5370\u7684\u6570\u636e\u4e0a\u8ba1\u7b97\u672c\u5730\u66f4\u65b0\uff0c\u670d\u52a1\u5668\u5bf9\u6240\u6709\u66f4\u65b0\u8fdb\u884c\u5e73\u5747\u5f97\u5230\u5168\u5c40LLM\u3002\u6c34\u5370\u5177\u6709\u653e\u5c04\u6027\u7279\u5f81\uff0c\u5728\u5fae\u8c03\u540e\u4ecd\u53ef\u68c0\u6d4b\u3002", "result": "\u5373\u4f7f\u53ea\u67096.6%\u7684\u6570\u636e\u5e26\u6709\u6c34\u5370\uff0cp\u503c\u4e5f\u80fd\u8fbe\u523010^-24\uff0c\u8bc1\u660e\u6c34\u5370\u4fe1\u53f7\u5728\u5fae\u8c03\u540e\u4ecd\u9ad8\u5ea6\u53ef\u68c0\u6d4b\u3002\u4f46\u4e3b\u52a8\u8fc7\u6ee4\u670d\u52a1\u5668\u53ef\u4ee5\u901a\u8fc7\u5f3a\u9c81\u68d2\u805a\u5408\u8fc7\u6ee4\u6389\u6c34\u5370\u66f4\u65b0\uff0c\u4ece\u800c\u79fb\u9664\u6c34\u5370\u4fe1\u53f7\u3002", "conclusion": "\u6240\u6709\u8bc4\u4f30\u7684\u653e\u5c04\u6027\u6c34\u5370\u90fd\u65e0\u6cd5\u62b5\u6297\u4e3b\u52a8\u8fc7\u6ee4\u670d\u52a1\u5668\u7684\u653b\u51fb\uff0c\u8868\u660e\u5728\u653e\u5c04\u6027\u3001\u9c81\u68d2\u6027\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u5b58\u5728\u57fa\u672c\u6743\u8861\u5173\u7cfb\u3002"}}
{"id": "2510.16996", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16996", "abs": "https://arxiv.org/abs/2510.16996", "authors": ["Juncheng Dong", "Yang Yang", "Tao Liu", "Yang Wang", "Feng Qi", "Vahid Tarokh", "Kaushik Rangadurai", "Shuang Yang"], "title": "STARK: Strategic Team of Agents for Refining Kernels", "comment": null, "summary": "The efficiency of GPU kernels is central to the progress of modern AI, yet\noptimizing them remains a difficult and labor-intensive task due to complex\ninteractions between memory hierarchies, thread scheduling, and\nhardware-specific characteristics. While recent advances in large language\nmodels (LLMs) provide new opportunities for automated code generation, existing\napproaches largely treat LLMs as single-shot generators or naive refinement\ntools, limiting their effectiveness in navigating the irregular kernel\noptimization landscape. We introduce an LLM agentic framework for GPU kernel\noptimization that systematically explores the design space through multi-agent\ncollaboration, grounded instruction, dynamic context management, and strategic\nsearch. This framework mimics the workflow of expert engineers, enabling LLMs\nto reason about hardware trade-offs, incorporate profiling feedback, and refine\nkernels iteratively. We evaluate our approach on KernelBench, a benchmark for\nLLM-based kernel optimization, and demonstrate substantial improvements over\nbaseline agents: our system produces correct solutions where baselines often\nfail, and achieves kernels with up to 16x faster runtime performance. These\nresults highlight the potential of agentic LLM frameworks to advance fully\nautomated, scalable GPU kernel optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8eGPU\u5185\u6838\u4f18\u5316\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u63a2\u7d22\u8bbe\u8ba1\u7a7a\u95f4\u3001\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u8fed\u4ee3\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5185\u6838\u6027\u80fd\u3002", "motivation": "GPU\u5185\u6838\u6548\u7387\u5bf9\u73b0\u4ee3AI\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f18\u5316\u8fc7\u7a0b\u590d\u6742\u4e14\u52b3\u52a8\u5bc6\u96c6\u3002\u73b0\u6709LLM\u65b9\u6cd5\u4e3b\u8981\u4f5c\u4e3a\u5355\u6b21\u751f\u6210\u5668\u6216\u7b80\u5355\u4f18\u5316\u5de5\u5177\uff0c\u96be\u4ee5\u6709\u6548\u5e94\u5bf9\u4e0d\u89c4\u5219\u7684\u6838\u4f18\u5316\u573a\u666f\u3002", "method": "\u91c7\u7528LLM\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u3001\u57fa\u4e8e\u7ecf\u9a8c\u7684\u6307\u5bfc\u3001\u52a8\u6001\u4e0a\u4e0b\u6587\u7ba1\u7406\u548c\u7b56\u7565\u641c\u7d22\uff0c\u6a21\u62df\u4e13\u5bb6\u5de5\u7a0b\u5e08\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u8ba9LLM\u80fd\u591f\u63a8\u7406\u786c\u4ef6\u6743\u8861\u3001\u6574\u5408\u6027\u80fd\u5206\u6790\u53cd\u9988\u5e76\u8fed\u4ee3\u4f18\u5316\u5185\u6838\u3002", "result": "\u5728KernelBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u57fa\u7ebf\u667a\u80fd\u4f53\uff0c\u8be5\u7cfb\u7edf\u80fd\u751f\u6210\u6b63\u786e\u89e3\u51b3\u65b9\u6848\uff08\u57fa\u7ebf\u7ecf\u5e38\u5931\u8d25\uff09\uff0c\u5e76\u5b9e\u73b0\u9ad8\u8fbe16\u500d\u8fd0\u884c\u65f6\u7684\u5185\u6838\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\u667a\u80fd\u4f53LLM\u6846\u67b6\u5728\u63a8\u8fdb\u5168\u81ea\u52a8\u3001\u53ef\u6269\u5c55\u7684GPU\u5185\u6838\u4f18\u5316\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2510.17087", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.17087", "abs": "https://arxiv.org/abs/2510.17087", "authors": ["Ziqing Zhu"], "title": "Quantum Key Distribution for Virtual Power Plant Communication: A Lightweight Key-Aware Scheduler with Provable Stability", "comment": null, "summary": "Virtual power plants (VPPs) are becoming a cornerstone of future grids,\naggregating distributed PV, wind, storage, and flexible loads for market\nparticipation and real-time balancing. As operations move to minute-- and\nsecond--level feedback, communication security shifts from a compliance item to\nan operational constraint: latency, reliability, and confidentiality jointly\ndetermine whether dispatch, protection, and settlement signals arrive on time.\nConventional PKI and key-rotation schemes struggle with cross-domain,\nhigh-frequency messaging and face long-term quantum threats. Quantum key\ndistribution (QKD) offers information-theoretic key freshness, but its key\nyield is scarce and stochastic, often misaligned with bursty VPP traffic. This\npaper proposes a key-aware priority and quota framework that treats quantum\nkeys as first-class scheduling resources. The design combines (i)\nforecast-driven long-term quotas and short-term tokens, (ii) key-aware\ndeficit-round-robin arbitration, (iii) a preemptive emergency key reserve, and\n(iv) graceful degradation via encryption-mode switching and controlled\ndown-sampling for non-critical traffic. A drift-plus-penalty analysis\nestablishes strong stability under average supply--demand balance with\nquantifiable bounds on backlog and tail latency, providing interpretable\noperating guarantees. We build a reproducible testbed on IEEE 33- and 123-bus\nVPP systems and evaluate normal, degraded, and outage regimes with\nindustry-consistent message classes and TTLs. Against FIFO, fixed-priority, and\nstatic-quota baselines, the proposed scheme consistently reduces tail delay and\npassive timeouts for critical messages, improves per-bit key utility, and\nenhances power-tracking reliability during key scarcity and regime switches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u865a\u62df\u7535\u5382\u901a\u4fe1\u7684\u91cf\u5b50\u5bc6\u94a5\u611f\u77e5\u8c03\u5ea6\u6846\u67b6\uff0c\u5c06\u7a00\u7f3a\u7684\u91cf\u5b50\u5bc6\u94a5\u4f5c\u4e3a\u4e00\u7ea7\u8c03\u5ea6\u8d44\u6e90\u8fdb\u884c\u7ba1\u7406\uff0c\u901a\u8fc7\u914d\u989d\u5206\u914d\u3001\u4f18\u5148\u7ea7\u4ef2\u88c1\u548c\u964d\u7ea7\u673a\u5236\uff0c\u5728\u91cf\u5b50\u5bc6\u94a5\u4f9b\u5e94\u4e0d\u786e\u5b9a\u7684\u60c5\u51b5\u4e0b\u4fdd\u969c\u5173\u952e\u6d88\u606f\u7684\u5b9e\u65f6\u4f20\u8f93\u3002", "motivation": "\u865a\u62df\u7535\u5382\u9700\u8981\u5206\u949f\u7ea7\u548c\u79d2\u7ea7\u7684\u5b9e\u65f6\u901a\u4fe1\uff0c\u4f20\u7edfPKI\u548c\u5bc6\u94a5\u8f6e\u6362\u65b9\u6848\u96be\u4ee5\u6ee1\u8db3\u9ad8\u9891\u8de8\u57df\u6d88\u606f\u9700\u6c42\u4e14\u9762\u4e34\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\u3002\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u867d\u7136\u63d0\u4f9b\u4fe1\u606f\u8bba\u5b89\u5168\u7684\u65b0\u9c9c\u5bc6\u94a5\uff0c\u4f46\u5176\u5bc6\u94a5\u4ea7\u91cf\u7a00\u7f3a\u4e14\u968f\u673a\uff0c\u4e0e\u865a\u62df\u7535\u5382\u7684\u7a81\u53d1\u6d41\u91cf\u4e0d\u5339\u914d\u3002", "method": "\u63d0\u51fa\u5bc6\u94a5\u611f\u77e5\u4f18\u5148\u7ea7\u548c\u914d\u989d\u6846\u67b6\uff0c\u5305\u62ec\uff1a(1)\u57fa\u4e8e\u9884\u6d4b\u7684\u957f\u671f\u914d\u989d\u548c\u77ed\u671f\u4ee4\u724c\uff1b(2)\u5bc6\u94a5\u611f\u77e5\u7684\u8d64\u5b57\u8f6e\u8be2\u4ef2\u88c1\uff1b(3)\u62a2\u5360\u5f0f\u5e94\u6025\u5bc6\u94a5\u50a8\u5907\uff1b(4)\u901a\u8fc7\u52a0\u5bc6\u6a21\u5f0f\u5207\u6362\u548c\u975e\u5173\u952e\u6d41\u91cf\u964d\u91c7\u6837\u7684\u4f18\u96c5\u964d\u7ea7\u673a\u5236\u3002", "result": "\u5728IEEE 33\u548c123\u603b\u7ebf\u865a\u62df\u7535\u5382\u7cfb\u7edf\u4e0a\u7684\u6d4b\u8bd5\u8868\u660e\uff0c\u76f8\u6bd4FIFO\u3001\u56fa\u5b9a\u4f18\u5148\u7ea7\u548c\u9759\u6001\u914d\u989d\u57fa\u7ebf\uff0c\u6240\u63d0\u65b9\u6848\u663e\u8457\u964d\u4f4e\u4e86\u5173\u952e\u6d88\u606f\u7684\u5c3e\u90e8\u5ef6\u8fdf\u548c\u88ab\u52a8\u8d85\u65f6\uff0c\u63d0\u9ad8\u4e86\u6bcf\u6bd4\u7279\u5bc6\u94a5\u6548\u7528\uff0c\u5e76\u5728\u5bc6\u94a5\u7a00\u7f3a\u548c\u72b6\u6001\u5207\u6362\u65f6\u589e\u5f3a\u4e86\u529f\u7387\u8ddf\u8e2a\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u5e73\u5747\u4f9b\u9700\u5e73\u8861\u4e0b\u5efa\u7acb\u4e86\u5f3a\u7a33\u5b9a\u6027\uff0c\u63d0\u4f9b\u4e86\u53ef\u91cf\u5316\u7684\u79ef\u538b\u548c\u5c3e\u90e8\u5ef6\u8fdf\u8fb9\u754c\uff0c\u4e3a\u865a\u62df\u7535\u5382\u5728\u91cf\u5b50\u5bc6\u94a5\u4f9b\u5e94\u4e0d\u786e\u5b9a\u73af\u5883\u4e0b\u7684\u5b89\u5168\u901a\u4fe1\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u64cd\u4f5c\u4fdd\u8bc1\u3002"}}
{"id": "2510.17052", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17052", "abs": "https://arxiv.org/abs/2510.17052", "authors": ["Hassan Hamad", "Yingru Xu", "Liang Zhao", "Wenbo Yan", "Narendra Gyanchandani"], "title": "ToolCritic: Detecting and Correcting Tool-Use Errors in Dialogue Systems", "comment": null, "summary": "Tool-augmented large language models (LLMs) are increasingly employed in\nreal-world applications, but tool usage errors still hinder their reliability.\nWe introduce ToolCritic, a diagnostic framework that evaluates and improves LLM\nbehavior in multi-turn, tool-augmented dialogues. ToolCritic detects eight\ndistinct error types specific to tool-calling (e.g., premature invocation,\nargument misalignment, and misinterpretation of tool outputs) and provides\ntargeted feedback to the main LLM. The main LLM, assumed to have strong\nreasoning, task understanding and orchestration capabilities, then revises its\nresponse based on ToolCritic's feedback. We systematically define these error\ncategories and construct a synthetic dataset to train ToolCritic. Experimental\nresults on the Schema-Guided Dialogue (SGD) dataset demonstrate that ToolCritic\nimproves tool-calling accuracy by up to 13% over baselines, including zero-shot\nprompting and self-correction techniques. This represents a promising step\ntoward more robust LLM integration with external tools in real-world dialogue\napplications.", "AI": {"tldr": "ToolCritic\u662f\u4e00\u4e2a\u8bca\u65ad\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u5de5\u5177\u589e\u5f3a\u5bf9\u8bdd\u4e2d\u7684\u884c\u4e3a\uff0c\u901a\u8fc7\u68c0\u6d4b8\u79cd\u7279\u5b9a\u5de5\u5177\u8c03\u7528\u9519\u8bef\u5e76\u63d0\u4f9b\u9488\u5bf9\u6027\u53cd\u9988\uff0c\u53ef\u5c06\u5de5\u5177\u8c03\u7528\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe13%\u3002", "motivation": "\u5de5\u5177\u589e\u5f3a\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u8d8a\u6765\u8d8a\u666e\u904d\uff0c\u4f46\u5de5\u5177\u4f7f\u7528\u9519\u8bef\u4ecd\u7136\u963b\u788d\u5176\u53ef\u9760\u6027\uff0c\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\u6765\u68c0\u6d4b\u548c\u6539\u8fdb\u8fd9\u4e9b\u9519\u8bef\u3002", "method": "\u5f00\u53d1ToolCritic\u6846\u67b6\uff0c\u5b9a\u4e498\u79cd\u5de5\u5177\u8c03\u7528\u9519\u8bef\u7c7b\u578b\uff0c\u6784\u5efa\u5408\u6210\u6570\u636e\u96c6\u8bad\u7ec3ToolCritic\uff0c\u8ba9\u4e3bLLM\u57fa\u4e8eToolCritic\u7684\u53cd\u9988\u4fee\u8ba2\u54cd\u5e94\u3002", "result": "\u5728Schema-Guided Dialogue\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cToolCritic\u76f8\u6bd4\u96f6\u6837\u672c\u63d0\u793a\u548c\u81ea\u6211\u7ea0\u6b63\u7b49\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5c06\u5de5\u5177\u8c03\u7528\u51c6\u786e\u7387\u63d0\u5347\u4e86\u9ad8\u8fbe13%\u3002", "conclusion": "ToolCritic\u4ee3\u8868\u4e86\u5728\u73b0\u5b9e\u4e16\u754c\u5bf9\u8bdd\u5e94\u7528\u4e2d\u5b9e\u73b0\u66f4\u7a33\u5065\u7684LLM\u4e0e\u5916\u90e8\u5de5\u5177\u96c6\u6210\u7684\u6709\u5e0c\u671b\u7684\u4e00\u6b65\u3002"}}
{"id": "2510.17175", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17175", "abs": "https://arxiv.org/abs/2510.17175", "authors": ["Muhammad Wahid Akram", "Keshav Sood", "Muneeb Ul Hassan"], "title": "QR\u00efS: A Preemptive Novel Method for Quishing Detection Through Structural Features of QR", "comment": "13 pages, 11 figures, and 7 tables", "summary": "Globally, individuals and organizations employ Quick Response (QR) codes for\nswift and convenient communication. Leveraging this, cybercriminals embed\nfalsify and misleading information in QR codes to launch various phishing\nattacks which termed as Quishing. Many former studies have introduced defensive\napproaches to preclude Quishing such as by classifying the embedded content of\nQR codes and then label the QR codes accordingly, whereas other studies\nclassify them using visual features (i.e., deep features, histogram density\nanalysis features). However, these approaches mainly rely on black-box\ntechniques which do not clearly provide interpretability and transparency to\nfully comprehend and reproduce the intrinsic decision process; therefore,\nhaving certain obvious limitations includes the approaches' trust,\naccountability, issues in bias detection, and many more. We proposed QR\\\"iS,\nthe pioneer method to classify QR codes through the comprehensive structural\nanalysis of a QR code which helps to identify phishing QR codes beforehand. Our\nclassification method is clearly transparent which makes it reproducible,\nscalable, and easy to comprehend. First, we generated QR codes dataset (i.e.\n400,000 samples) using recently published URLs datasets [1], [2]. Then, unlike\nblack-box models, we developed a simple algorithm to extract 24 structural\nfeatures from layout patterns present in QR codes. Later, we train the machine\nlearning models on the harvested features and obtained accuracy of up to\n83.18%. To further evaluate the effectiveness of our approach, we perform the\ncomparative analysis of proposed method with relevant contemporary studies.\nLastly, for real-world deployment and validation, we developed a mobile app\nwhich assures the feasibility of the proposed solution in real-world scenarios\nwhich eventually strengthen the applicability of the study.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aQR\"iS\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7QR\u7801\u7684\u7ed3\u6784\u5206\u6790\u6765\u8bc6\u522b\u9493\u9c7c\u653b\u51fb\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u9ed1\u76d2\u6280\u672f\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u900f\u660e\u5ea6\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524dQR\u7801\u9493\u9c7c\u653b\u51fb\uff08Quishing\uff09\u65e5\u76ca\u4e25\u91cd\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u9ed1\u76d2\u6280\u672f\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u900f\u660e\u5ea6\uff0c\u5b58\u5728\u4fe1\u4efb\u5ea6\u3001\u8d23\u4efb\u5f52\u5c5e\u548c\u504f\u89c1\u68c0\u6d4b\u7b49\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7b80\u5355\u7b97\u6cd5\uff0c\u4eceQR\u7801\u7684\u5e03\u5c40\u6a21\u5f0f\u4e2d\u63d0\u53d624\u4e2a\u7ed3\u6784\u7279\u5f81\uff0c\u7136\u540e\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u5f00\u53d1\u4e86\u79fb\u52a8\u5e94\u7528\u8fdb\u884c\u5b9e\u9645\u9a8c\u8bc1\u3002", "result": "\u5728\u751f\u6210\u768440\u4e07\u4e2aQR\u7801\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u83b7\u5f97\u4e86\u9ad8\u8fbe83.18%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u901a\u8fc7\u4e0e\u76f8\u5173\u7814\u7a76\u7684\u5bf9\u6bd4\u5206\u6790\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "QR\"iS\u65b9\u6cd5\u901a\u8fc7\u900f\u660e\u7684\u7ed3\u6784\u5206\u6790\u5b9e\u73b0\u4e86\u5bf9\u9493\u9c7cQR\u7801\u7684\u6709\u6548\u5206\u7c7b\uff0c\u5177\u6709\u53ef\u91cd\u73b0\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u6613\u4e8e\u7406\u89e3\u7684\u7279\u70b9\uff0c\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u9a8c\u8bc1\u4e86\u5176\u53ef\u884c\u6027\u3002"}}
{"id": "2510.17220", "categories": ["cs.CR", "cs.LO", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.17220", "abs": "https://arxiv.org/abs/2510.17220", "authors": ["Giulia Giusti"], "title": "Exploiting the Potential of Linearity in Automatic Differentiation and Computational Cryptography", "comment": null, "summary": "The concept of linearity plays a central role in both mathematics and\ncomputer science, with distinct yet complementary meanings. In mathematics,\nlinearity underpins functions and vector spaces, forming the foundation of\nlinear algebra and functional analysis. In computer science, it relates to\nresource-sensitive computation. Linear Logic (LL), for instance, models\nassumptions that must be used exactly once, providing a natural framework for\ntracking computational resources such as time, memory, or data access. This\ndual perspective makes linearity essential to programming languages, type\nsystems, and formal models that express both computational complexity and\ncomposability. Bridging these interpretations enables rigorous yet practical\nmethodologies for analyzing and verifying complex systems.\n  This thesis explores the use of LL to model programming paradigms based on\nlinearity. It comprises two parts: ADLL and CryptoBLL. The former applies LL to\nAutomatic Differentiation (AD), modeling linear functions over the reals and\nthe transposition operation. The latter uses LL to express complexity\nconstraints on adversaries in computational cryptography.\n  In AD, two main approaches use linear type systems: a theoretical one\ngrounded in proof theory, and a practical one implemented in JAX, a Python\nlibrary developed by Google for machine learning research. In contrast,\nframeworks like PyTorch and TensorFlow support AD without linear types. ADLL\naims to bridge theory and practice by connecting JAX's type system to LL.\n  In modern cryptography, several calculi aim to model cryptographic proofs\nwithin the computational paradigm. These efforts face a trade-off between\nexpressiveness, to capture reductions, and simplicity, to abstract probability\nand complexity. CryptoBLL addresses this tension by proposing a framework for\nthe automatic analysis of protocols in computational cryptography.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u7ebf\u6027\u903b\u8f91\u5728\u7f16\u7a0b\u8303\u5f0f\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u4e3aADLL\u548cCryptoBLL\u4e24\u90e8\u5206\u3002ADLL\u5c06\u7ebf\u6027\u903b\u8f91\u5e94\u7528\u4e8e\u81ea\u52a8\u5fae\u5206\uff0c\u5efa\u6a21\u5b9e\u6570\u4e0a\u7684\u7ebf\u6027\u51fd\u6570\u548c\u8f6c\u7f6e\u64cd\u4f5c\uff1bCryptoBLL\u4f7f\u7528\u7ebf\u6027\u903b\u8f91\u8868\u8fbe\u8ba1\u7b97\u5bc6\u7801\u5b66\u4e2d\u5bf9\u624b\u7684\u590d\u6742\u6027\u7ea6\u675f\u3002", "motivation": "\u7ebf\u6027\u6982\u5ff5\u5728\u6570\u5b66\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u4e2d\u5177\u6709\u4e0d\u540c\u4f46\u4e92\u8865\u7684\u542b\u4e49\u3002\u6570\u5b66\u4e2d\u7684\u7ebf\u6027\u652f\u6491\u51fd\u6570\u548c\u5411\u91cf\u7a7a\u95f4\uff0c\u800c\u8ba1\u7b97\u673a\u79d1\u5b66\u4e2d\u7684\u7ebf\u6027\u6d89\u53ca\u8d44\u6e90\u654f\u611f\u8ba1\u7b97\u3002\u7ebf\u6027\u903b\u8f91\u80fd\u591f\u5efa\u6a21\u5fc5\u987b\u6070\u597d\u4f7f\u7528\u4e00\u6b21\u7684\u5047\u8bbe\uff0c\u4e3a\u8ddf\u8e2a\u8ba1\u7b97\u8d44\u6e90\u63d0\u4f9b\u81ea\u7136\u6846\u67b6\u3002", "method": "\u8bba\u6587\u91c7\u7528\u7ebf\u6027\u903b\u8f91\u65b9\u6cd5\uff1aADLL\u90e8\u5206\u5c06\u7ebf\u6027\u903b\u8f91\u5e94\u7528\u4e8e\u81ea\u52a8\u5fae\u5206\uff0c\u8fde\u63a5JAX\u7684\u7c7b\u578b\u7cfb\u7edf\u4e0e\u7ebf\u6027\u903b\u8f91\uff1bCryptoBLL\u90e8\u5206\u63d0\u51fa\u8ba1\u7b97\u5bc6\u7801\u5b66\u4e2d\u534f\u8bae\u81ea\u52a8\u5206\u6790\u7684\u6846\u67b6\uff0c\u5904\u7406\u8868\u8fbe\u6027\u4e0e\u7b80\u5355\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "ADLL\u65e8\u5728\u5f25\u5408\u81ea\u52a8\u5fae\u5206\u4e2d\u57fa\u4e8e\u8bc1\u660e\u7406\u8bba\u7684\u7406\u8bba\u65b9\u6cd5\u4e0eJAX\u5b9e\u9645\u5b9e\u73b0\u4e4b\u95f4\u7684\u5dee\u8ddd\uff1bCryptoBLL\u4e3a\u8ba1\u7b97\u5bc6\u7801\u5b66\u4e2d\u7684\u534f\u8bae\u5206\u6790\u63d0\u4f9b\u4e86\u5904\u7406\u590d\u6742\u6027\u548c\u6982\u7387\u62bd\u8c61\u7684\u65b0\u6846\u67b6\u3002", "conclusion": "\u901a\u8fc7\u7ebf\u6027\u903b\u8f91\u7684\u5e94\u7528\uff0c\u8be5\u7814\u7a76\u4e3a\u7f16\u7a0b\u8bed\u8a00\u3001\u7c7b\u578b\u7cfb\u7edf\u548c\u5f62\u5f0f\u6a21\u578b\u63d0\u4f9b\u4e86\u540c\u65f6\u8868\u8fbe\u8ba1\u7b97\u590d\u6742\u6027\u548c\u53ef\u7ec4\u5408\u6027\u7684\u65b9\u6cd5\uff0c\u4e3a\u5206\u6790\u548c\u9a8c\u8bc1\u590d\u6742\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e25\u8c28\u800c\u5b9e\u7528\u7684\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2510.17145", "categories": ["cs.AI", "68T05, 62H30"], "pdf": "https://arxiv.org/pdf/2510.17145", "abs": "https://arxiv.org/abs/2510.17145", "authors": ["Phi-Hung Hoang", "Nam-Thuan Trinh", "Van-Manh Tran", "Thi-Thu-Hong Phan"], "title": "Enhanced Fish Freshness Classification with Incremental Handcrafted Feature Fusion", "comment": "35 pages, 6 figures and 11 tables", "summary": "Accurate assessment of fish freshness remains a major challenge in the food\nindustry, with direct consequences for product quality, market value, and\nconsumer health. Conventional sensory evaluation is inherently subjective,\ninconsistent, and difficult to standardize across contexts, often limited by\nsubtle, species-dependent spoilage cues. To address these limitations, we\npropose a handcrafted feature-based approach that systematically extracts and\nincrementally fuses complementary descriptors, including color statistics,\nhistograms across multiple color spaces, and texture features such as Local\nBinary Patterns (LBP) and Gray-Level Co-occurrence Matrices (GLCM), from fish\neye images. Our method captures global chromatic variations from full images\nand localized degradations from ROI segments, fusing each independently to\nevaluate their effectiveness in assessing freshness. Experiments on the\nFreshness of the Fish Eyes (FFE) dataset demonstrate the approach's\neffectiveness: in a standard train-test setting, a LightGBM classifier achieved\n77.56% accuracy, a 14.35% improvement over the previous deep learning baseline\nof 63.21%. With augmented data, an Artificial Neural Network (ANN) reached\n97.16% accuracy, surpassing the prior best of 77.3% by 19.86%. These results\ndemonstrate that carefully engineered, handcrafted features, when strategically\nprocessed, yield a robust, interpretable, and reliable solution for automated\nfish freshness assessment, providing valuable insights for practical\napplications in food quality monitoring.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u624b\u5de5\u7279\u5f81\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u548c\u878d\u5408\u989c\u8272\u7edf\u8ba1\u3001\u591a\u989c\u8272\u7a7a\u95f4\u76f4\u65b9\u56fe\u4ee5\u53ca\u7eb9\u7406\u7279\u5f81\u6765\u8bc4\u4f30\u9c7c\u7c7b\u65b0\u9c9c\u5ea6\uff0c\u5728FFE\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u4f18\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u611f\u5b98\u8bc4\u4f30\u9c7c\u7c7b\u65b0\u9c9c\u5ea6\u5b58\u5728\u4e3b\u89c2\u6027\u3001\u4e0d\u4e00\u81f4\u6027\u548c\u96be\u4ee5\u6807\u51c6\u5316\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u5ba2\u89c2\u3001\u53ef\u9760\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u4ece\u9c7c\u773c\u56fe\u50cf\u4e2d\u7cfb\u7edf\u63d0\u53d6\u989c\u8272\u7edf\u8ba1\u3001\u591a\u989c\u8272\u7a7a\u95f4\u76f4\u65b9\u56fe\u3001LBP\u548cGLCM\u7b49\u7eb9\u7406\u7279\u5f81\uff0c\u878d\u5408\u5168\u5c40\u8272\u5ea6\u53d8\u5316\u548c\u5c40\u90e8ROI\u9000\u5316\u7279\u5f81\uff0c\u4f7f\u7528LightGBM\u548cANN\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5728\u6807\u51c6\u8bad\u7ec3\u6d4b\u8bd5\u8bbe\u7f6e\u4e0b\uff0cLightGBM\u8fbe\u523077.56%\u51c6\u786e\u7387\uff0c\u6bd4\u4e4b\u524d\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u63d0\u534714.35%\uff1b\u4f7f\u7528\u589e\u5f3a\u6570\u636e\u65f6\uff0cANN\u8fbe\u523097.16%\u51c6\u786e\u7387\uff0c\u6bd4\u4e4b\u524d\u6700\u4f73\u7ed3\u679c\u63d0\u534719.86%\u3002", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u624b\u5de5\u7279\u5f81\u7ecf\u8fc7\u7b56\u7565\u6027\u5904\u7406\u540e\uff0c\u80fd\u591f\u4e3a\u81ea\u52a8\u5316\u9c7c\u7c7b\u65b0\u9c9c\u5ea6\u8bc4\u4f30\u63d0\u4f9b\u7a33\u5065\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17277", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.17277", "abs": "https://arxiv.org/abs/2510.17277", "authors": ["Xinkai Wang", "Beibei Li", "Zerui Shao", "Ao Liu", "Shouling Ji"], "title": "Multimodal Safety Is Asymmetric: Cross-Modal Exploits Unlock Black-Box MLLMs Jailbreaks", "comment": null, "summary": "Multimodal large language models (MLLMs) have demonstrated significant\nutility across diverse real-world applications. But MLLMs remain vulnerable to\njailbreaks, where adversarial inputs can collapse their safety constraints and\ntrigger unethical responses. In this work, we investigate jailbreaks in the\ntext-vision multimodal setting and pioneer the observation that visual\nalignment imposes uneven safety constraints across modalities in MLLMs, thereby\ngiving rise to multimodal safety asymmetry. We then develop PolyJailbreak, a\nblack-box jailbreak method grounded in reinforcement learning. Initially, we\nprobe the model's attention dynamics and latent representation space, assessing\nhow visual inputs reshape cross-modal information flow and diminish the model's\nability to separate harmful from benign inputs, thereby exposing exploitable\nvulnerabilities. On this basis, we systematize them into generalizable and\nreusable operational rules that constitute a structured library of Atomic\nStrategy Primitives, which translate harmful intents into jailbreak inputs\nthrough step-wise transformations. Guided by the primitives, PolyJailbreak\nemploys a multi-agent optimization process that automatically adapts inputs\nagainst the target models. We conduct comprehensive evaluations on a variety of\nopen-source and closed-source MLLMs, demonstrating that PolyJailbreak\noutperforms state-of-the-art baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPolyJailbreak\u65b9\u6cd5\uff0c\u5229\u7528\u591a\u6a21\u6001\u5b89\u5168\u4e0d\u5bf9\u79f0\u6027\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u81ea\u52a8\u751f\u6210\u9488\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8d8a\u72f1\u653b\u51fb\uff0c\u5728\u591a\u79cd\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u4f46\u5b83\u4eec\u5bb9\u6613\u53d7\u5230\u8d8a\u72f1\u653b\u51fb\uff0c\u5bfc\u81f4\u5b89\u5168\u7ea6\u675f\u5931\u6548\u5e76\u4ea7\u751f\u4e0d\u9053\u5fb7\u54cd\u5e94\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u6587\u672c-\u89c6\u89c9\u591a\u6a21\u6001\u8bbe\u7f6e\u4e2d\u7684\u8d8a\u72f1\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u9ed1\u76d2\u8d8a\u72f1\u65b9\u6cd5PolyJailbreak\uff1a\u9996\u5148\u63a2\u6d4b\u6a21\u578b\u7684\u6ce8\u610f\u529b\u52a8\u6001\u548c\u6f5c\u5728\u8868\u793a\u7a7a\u95f4\uff0c\u8bc4\u4f30\u89c6\u89c9\u8f93\u5165\u5982\u4f55\u91cd\u5851\u8de8\u6a21\u6001\u4fe1\u606f\u6d41\uff1b\u7136\u540e\u7cfb\u7edf\u5316\u4e3a\u53ef\u6cdb\u5316\u548c\u53ef\u91cd\u7528\u7684\u64cd\u4f5c\u89c4\u5219\uff0c\u6784\u5efa\u539f\u5b50\u7b56\u7565\u539f\u8bed\u5e93\uff1b\u6700\u540e\u91c7\u7528\u591a\u667a\u80fd\u4f53\u4f18\u5316\u8fc7\u7a0b\u81ea\u52a8\u9002\u5e94\u76ee\u6807\u6a21\u578b\u7684\u8f93\u5165\u3002", "result": "\u5728\u591a\u79cd\u5f00\u6e90\u548c\u95ed\u6e90\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u8bc1\u660ePolyJailbreak\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u89c6\u89c9\u5bf9\u9f50\u5728\u591a\u6a21\u6001\u4e2d\u65bd\u52a0\u4e86\u4e0d\u5747\u5300\u7684\u5b89\u5168\u7ea6\u675f\uff0c\u5bfc\u81f4\u591a\u6a21\u6001\u5b89\u5168\u4e0d\u5bf9\u79f0\u6027\uff0c\u8fd9\u4e3a\u8d8a\u72f1\u653b\u51fb\u63d0\u4f9b\u4e86\u53ef\u88ab\u5229\u7528\u7684\u6f0f\u6d1e\u3002PolyJailbreak\u65b9\u6cd5\u6709\u6548\u5229\u7528\u4e86\u8fd9\u79cd\u4e0d\u5bf9\u79f0\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6a21\u578b\u8d8a\u72f1\u3002"}}
{"id": "2510.17146", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.17146", "abs": "https://arxiv.org/abs/2510.17146", "authors": ["Subin Lin", "Chuanbo Hua"], "title": "Physics-Informed Large Language Models for HVAC Anomaly Detection with Autonomous Rule Generation", "comment": "NeurIPS 2025 Workshop of UrbanAI (Oral)", "summary": "Heating, Ventilation, and Air-Conditioning (HVAC) systems account for a\nsubstantial share of global building energy use, making reliable anomaly\ndetection essential for improving efficiency and reducing emissions. Classical\nrule-based approaches offer explainability but lack adaptability, while deep\nlearning methods provide predictive power at the cost of transparency,\nefficiency, and physical plausibility. Recent attempts to use Large Language\nModels (LLMs) for anomaly detection improve interpretability but largely ignore\nthe physical principles that govern HVAC operations. We present PILLM, a\nPhysics-Informed LLM framework that operates within an evolutionary loop to\nautomatically generate, evaluate, and refine anomaly detection rules. Our\napproach introduces physics-informed reflection and crossover operators that\nembed thermodynamic and control-theoretic constraints, enabling rules that are\nboth adaptive and physically grounded. Experiments on the public Building Fault\nDetection dataset show that PILLM achieves state-of-the-art performance while\nproducing diagnostic rules that are interpretable and actionable, advancing\ntrustworthy and deployable AI for smart building systems.", "AI": {"tldr": "PILLM\u662f\u4e00\u4e2a\u57fa\u4e8e\u7269\u7406\u77e5\u8bc6\u7684LLM\u6846\u67b6\uff0c\u901a\u8fc7\u8fdb\u5316\u5faa\u73af\u81ea\u52a8\u751f\u6210\u3001\u8bc4\u4f30\u548c\u4f18\u5316HVAC\u7cfb\u7edf\u5f02\u5e38\u68c0\u6d4b\u89c4\u5219\uff0c\u7ed3\u5408\u70ed\u529b\u5b66\u548c\u63a7\u5236\u7406\u8bba\u7ea6\u675f\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u4e14\u7269\u7406\u5408\u7406\u7684\u5f02\u5e38\u68c0\u6d4b\u3002", "motivation": "HVAC\u7cfb\u7edf\u5360\u5efa\u7b51\u80fd\u8017\u5f88\u5927\u6bd4\u4f8b\uff0c\u4f20\u7edf\u89c4\u5219\u65b9\u6cd5\u53ef\u89e3\u91ca\u4f46\u7f3a\u4e4f\u9002\u5e94\u6027\uff0c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u9884\u6d4b\u80fd\u529b\u5f3a\u4f46\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u7269\u7406\u5408\u7406\u6027\uff0c\u73b0\u6709LLM\u65b9\u6cd5\u5ffd\u7565\u4e86HVAC\u8fd0\u884c\u7684\u7269\u7406\u539f\u7406\u3002", "method": "\u63d0\u51faPILLM\u6846\u67b6\uff0c\u91c7\u7528\u8fdb\u5316\u5faa\u73af\u673a\u5236\uff0c\u5f15\u5165\u7269\u7406\u77e5\u8bc6\u53cd\u5c04\u548c\u4ea4\u53c9\u64cd\u4f5c\uff0c\u5d4c\u5165\u70ed\u529b\u5b66\u548c\u63a7\u5236\u7406\u8bba\u7ea6\u675f\uff0c\u81ea\u52a8\u751f\u6210\u548c\u4f18\u5316\u5f02\u5e38\u68c0\u6d4b\u89c4\u5219\u3002", "result": "\u5728\u516c\u5f00\u7684\u5efa\u7b51\u6545\u969c\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\uff0cPILLM\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u540c\u65f6\u751f\u6210\u53ef\u89e3\u91ca\u548c\u53ef\u64cd\u4f5c\u7684\u8bca\u65ad\u89c4\u5219\u3002", "conclusion": "PILLM\u63a8\u8fdb\u4e86\u667a\u80fd\u5efa\u7b51\u7cfb\u7edf\u4e2d\u53ef\u4fe1\u8d56\u548c\u53ef\u90e8\u7f72AI\u7684\u53d1\u5c55\uff0c\u5e73\u8861\u4e86\u9884\u6d4b\u6027\u80fd\u4e0e\u7269\u7406\u5408\u7406\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2510.17284", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.17284", "abs": "https://arxiv.org/abs/2510.17284", "authors": ["Jiri Gavenda", "Petr Svenda", "Stanislav Bobon", "Vladimir Sedlacek"], "title": "Analysis of Input-Output Mappings in Coinjoin Transactions with Arbitrary Values", "comment": null, "summary": "A coinjoin protocol aims to increase transactional privacy for Bitcoin and\nBitcoin-like blockchains via collaborative transactions, by violating\nassumptions behind common analysis heuristics. Estimating the resulting privacy\ngain is a crucial yet unsolved problem due to a range of influencing factors\nand large computational complexity.\n  We adapt the BlockSci on-chain analysis software to coinjoin transactions,\ndemonstrating a significant (10-50%) average post-mix anonymity set size\ndecrease for all three major designs with a central coordinator: Whirlpool,\nWasabi 1.x, and Wasabi 2.x. The decrease is highest during the first day and\nnegligible after one year from a coinjoin creation.\n  Moreover, we design a precise, parallelizable privacy estimation method,\nwhich takes into account coinjoin fees, implementation-specific limitations and\nusers' post-mix behavior. We evaluate our method in detail on a set of emulated\nand real-world Wasabi 2.x coinjoins and extrapolate to its largest real-world\ncoinjoins with hundreds of inputs and outputs. We conclude that despite the\nusers' undesirable post-mix behavior, correctly attributing the coins to their\nowners is still very difficult, even with our improved analysis algorithm.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u6bd4\u7279\u5e01CoinJoin\u534f\u8bae\u7684\u9690\u79c1\u4fdd\u62a4\u6548\u679c\uff0c\u53d1\u73b0\u4e3b\u8981CoinJoin\u8bbe\u8ba1\uff08Whirlpool\u3001Wasabi 1.x\u548c2.x\uff09\u7684\u5e73\u5747\u533f\u540d\u96c6\u5927\u5c0f\u5728\u6df7\u5e01\u540e\u4e0b\u964d10-50%\uff0c\u5176\u4e2d\u7b2c\u4e00\u5929\u4e0b\u964d\u6700\u660e\u663e\uff0c\u4e00\u5e74\u540e\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002\u4f5c\u8005\u5f00\u53d1\u4e86\u7cbe\u786e\u7684\u9690\u79c1\u8bc4\u4f30\u65b9\u6cd5\uff0c\u8bc1\u660e\u5c3d\u7ba1\u7528\u6237\u6df7\u5e01\u540e\u884c\u4e3a\u4e0d\u7406\u60f3\uff0c\u4f46\u51c6\u786e\u8ffd\u8e2a\u8d44\u91d1\u5f52\u5c5e\u4ecd\u7136\u975e\u5e38\u56f0\u96be\u3002", "motivation": "CoinJoin\u534f\u8bae\u65e8\u5728\u901a\u8fc7\u534f\u540c\u4ea4\u6613\u589e\u5f3a\u6bd4\u7279\u5e01\u9690\u79c1\uff0c\u4f46\u8bc4\u4f30\u5176\u5b9e\u9645\u9690\u79c1\u589e\u76ca\u662f\u4e00\u4e2a\u5c1a\u672a\u89e3\u51b3\u7684\u590d\u6742\u95ee\u9898\uff0c\u9700\u8981\u8003\u8651\u591a\u79cd\u5f71\u54cd\u56e0\u7d20\u548c\u8ba1\u7b97\u590d\u6742\u6027\u3002", "method": "\u4f5c\u8005\u6539\u8fdb\u4e86BlockSci\u94fe\u4e0a\u5206\u6790\u8f6f\u4ef6\u4ee5\u5206\u6790CoinJoin\u4ea4\u6613\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7cbe\u786e\u3001\u53ef\u5e76\u884c\u7684\u9690\u79c1\u8bc4\u4f30\u65b9\u6cd5\uff0c\u8003\u8651\u4e86\u6df7\u5e01\u8d39\u7528\u3001\u5b9e\u73b0\u9650\u5236\u548c\u7528\u6237\u6df7\u5e01\u540e\u884c\u4e3a\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e09\u79cd\u4e3b\u8981CoinJoin\u8bbe\u8ba1\u7684\u5e73\u5747\u533f\u540d\u96c6\u5927\u5c0f\u5728\u6df7\u5e01\u540e\u4e0b\u964d10-50%\uff0c\u7b2c\u4e00\u5929\u4e0b\u964d\u6700\u660e\u663e\uff0c\u4e00\u5e74\u540e\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002\u5373\u4f7f\u8003\u8651\u7528\u6237\u4e0d\u7406\u60f3\u7684\u6df7\u5e01\u540e\u884c\u4e3a\uff0c\u51c6\u786e\u8ffd\u8e2a\u8d44\u91d1\u5f52\u5c5e\u4ecd\u7136\u975e\u5e38\u56f0\u96be\u3002", "conclusion": "\u5c3d\u7ba1CoinJoin\u534f\u8bae\u5728\u6df7\u5e01\u540e\u5b58\u5728\u533f\u540d\u96c6\u5927\u5c0f\u4e0b\u964d\uff0c\u7279\u522b\u662f\u521d\u671f\u4e0b\u964d\u660e\u663e\uff0c\u4f46\u901a\u8fc7\u6539\u8fdb\u7684\u5206\u6790\u65b9\u6cd5\u8bc1\u660e\uff0c\u51c6\u786e\u8ffd\u8e2a\u6df7\u5e01\u8d44\u91d1\u7684\u6240\u6709\u8005\u4ecd\u7136\u6781\u5177\u6311\u6218\u6027\uff0cCoinJoin\u534f\u8bae\u4ecd\u80fd\u63d0\u4f9b\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2510.17149", "categories": ["cs.AI", "I.2.11"], "pdf": "https://arxiv.org/pdf/2510.17149", "abs": "https://arxiv.org/abs/2510.17149", "authors": ["Hongyi Du", "Jiaqi Su", "Jisen Li", "Lijie Ding", "Yingxuan Yang", "Peixuan Han", "Xiangru Tang", "Kunlun Zhu", "Jiaxuan You"], "title": "Which LLM Multi-Agent Protocol to Choose?", "comment": "Under review at ICLR 2026.Code and benchmark artifacts:\n  https://github.com/ulab-uiuc/AgentProtocols", "summary": "As large-scale multi-agent systems evolve, the communication protocol layer\nhas become a critical yet under-evaluated factor shaping performance and\nreliability. Despite the existence of diverse protocols (A2A, ACP, ANP, Agora,\netc.), selection is often intuition-driven and lacks standardized guidance. We\nintroduce ProtocolBench, a benchmark that systematically compares agent\nprotocols along four measurable axes: task success, end-to-end latency, message\nor byte overhead, and robustness under failures. On ProtocolBench, protocol\nchoice significantly influences system behavior. In the Streaming Queue\nscenario, overall completion time varies by up to 36.5% across protocols, and\nmean end-to-end latency differs by 3.48 s. Under Fail-Storm Recovery,\nresilience also differs consistently across protocols. Beyond evaluation, we\npresent ProtocolRouter, a learnable protocol router that selects per-scenario\n(or per-module) protocols from requirement and runtime signals. ProtocolRouter\nreduces Fail-Storm recovery time by up to 18.1% versus the best single-protocol\nbaseline, and achieves scenario-specific gains such as higher success in GAIA.\nWe also release ProtocolRouterBench to standardize protocol evaluation and\nimprove reliability at scale.", "AI": {"tldr": "ProtocolBench\u662f\u4e00\u4e2a\u7cfb\u7edf\u8bc4\u4f30\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u4fe1\u534f\u8bae\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ece\u4efb\u52a1\u6210\u529f\u7387\u3001\u7aef\u5230\u7aef\u5ef6\u8fdf\u3001\u6d88\u606f\u5f00\u9500\u548c\u6545\u969c\u6062\u590d\u80fd\u529b\u56db\u4e2a\u7ef4\u5ea6\u6bd4\u8f83\u4e0d\u540c\u534f\u8bae\u3002\u7814\u7a76\u53d1\u73b0\u534f\u8bae\u9009\u62e9\u663e\u8457\u5f71\u54cd\u7cfb\u7edf\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86ProtocolRouter\u5b66\u4e60\u578b\u534f\u8bae\u8def\u7531\u5668\u6765\u4f18\u5316\u534f\u8bae\u9009\u62e9\u3002", "motivation": "\u968f\u7740\u5927\u89c4\u6a21\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u901a\u4fe1\u534f\u8bae\u5c42\u6210\u4e3a\u5f71\u54cd\u6027\u80fd\u548c\u53ef\u9760\u6027\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4f46\u76ee\u524d\u534f\u8bae\u9009\u62e9\u7f3a\u4e4f\u6807\u51c6\u5316\u6307\u5bfc\uff0c\u4e3b\u8981\u4f9d\u8d56\u76f4\u89c9\u3002", "method": "\u5f00\u53d1\u4e86ProtocolBench\u57fa\u51c6\u6d4b\u8bd5\u7cfb\u7edf\uff0c\u4ece\u56db\u4e2a\u53ef\u6d4b\u91cf\u7ef4\u5ea6\u6bd4\u8f83\u4e0d\u540c\u534f\u8bae\uff1b\u63d0\u51fa\u4e86ProtocolRouter\u5b66\u4e60\u578b\u534f\u8bae\u8def\u7531\u5668\uff0c\u6839\u636e\u9700\u6c42\u548c\u8fd0\u884c\u65f6\u4fe1\u53f7\u4e3a\u4e0d\u540c\u573a\u666f\u6216\u6a21\u5757\u9009\u62e9\u6700\u4f18\u534f\u8bae\u3002", "result": "\u534f\u8bae\u9009\u62e9\u663e\u8457\u5f71\u54cd\u7cfb\u7edf\u884c\u4e3a\uff1a\u5728\u6d41\u5f0f\u961f\u5217\u573a\u666f\u4e2d\uff0c\u603b\u5b8c\u6210\u65f6\u95f4\u5dee\u5f02\u8fbe36.5%\uff0c\u5e73\u5747\u7aef\u5230\u7aef\u5ef6\u8fdf\u5dee\u5f023.48\u79d2\uff1b\u5728\u6545\u969c\u98ce\u66b4\u6062\u590d\u573a\u666f\u4e2d\uff0c\u4e0d\u540c\u534f\u8bae\u7684\u6062\u590d\u80fd\u529b\u5b58\u5728\u4e00\u81f4\u5dee\u5f02\u3002ProtocolRouter\u76f8\u6bd4\u6700\u4f73\u5355\u534f\u8bae\u57fa\u7ebf\uff0c\u5c06\u6545\u969c\u98ce\u66b4\u6062\u590d\u65f6\u95f4\u51cf\u5c1118.1%\uff0c\u5e76\u5728GAIA\u573a\u666f\u4e2d\u5b9e\u73b0\u66f4\u9ad8\u6210\u529f\u7387\u3002", "conclusion": "\u901a\u4fe1\u534f\u8bae\u9009\u62e9\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0cProtocolBench\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u65b9\u6cd5\uff0cProtocolRouter\u901a\u8fc7\u667a\u80fd\u534f\u8bae\u9009\u62e9\u53ef\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u6027\u80fd\u3002\u540c\u65f6\u53d1\u5e03\u4e86ProtocolRouterBench\u4ee5\u6807\u51c6\u5316\u534f\u8bae\u8bc4\u4f30\u5e76\u63d0\u5347\u5927\u89c4\u6a21\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2510.17308", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.17308", "abs": "https://arxiv.org/abs/2510.17308", "authors": ["Reo Eriguchi", "Kazumasa Shinagawa"], "title": "Single-Shuffle Full-Open Card-Based Protocols for Any Function", "comment": null, "summary": "A card-based secure computation protocol is a method for $n$ parties to\ncompute a function $f$ on their private inputs $(x_1,\\ldots,x_n)$ using\nphysical playing cards, in such a way that the suits of revealed cards leak no\ninformation beyond the value of $f(x_1,\\ldots,x_n)$. A \\textit{single-shuffle\nfull-open} protocol is a minimal model of card-based secure computation in\nwhich, after the parties place face-down cards representing their inputs, a\nsingle shuffle operation is performed and then all cards are opened to derive\nthe output. Despite the simplicity of this model, the class of functions known\nto admit single-shuffle full-open protocols has been limited to a few small\nexamples. In this work, we prove for the first time that every function admits\na single-shuffle full-open protocol. We present two constructions that offer a\ntrade-off between the number of cards and the complexity of the shuffle\noperation. These feasibility results are derived from a novel connection\nbetween single-shuffle full-open protocols and a cryptographic primitive known\nas \\textit{Private Simultaneous Messages} protocols, which has rarely been\nstudied in the context of card-based cryptography. We also present variants of\nsingle-shuffle protocols in which only a subset of cards are revealed. These\nprotocols reduce the complexity of the shuffle operation compared to existing\nprotocols in the same setting.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u8bc1\u660e\u4e86\u6240\u6709\u51fd\u6570\u90fd\u5b58\u5728\u5355\u6b21\u6d17\u724c\u5168\u516c\u5f00\u7684\u5361\u724c\u5b89\u5168\u8ba1\u7b97\u534f\u8bae\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u5728\u5361\u724c\u6570\u91cf\u548c\u6d17\u724c\u590d\u6742\u5ea6\u4e4b\u95f4\u6743\u8861\u7684\u6784\u9020\u65b9\u6cd5\u3002", "motivation": "\u5355\u6b21\u6d17\u724c\u5168\u516c\u5f00\u534f\u8bae\u662f\u5361\u724c\u5b89\u5168\u8ba1\u7b97\u7684\u6700\u5c0f\u6a21\u578b\uff0c\u4f46\u4e4b\u524d\u5df2\u77e5\u7684\u53ef\u8ba1\u7b97\u51fd\u6570\u7c7b\u522b\u4ec5\u9650\u4e8e\u5c11\u6570\u5c0f\u4f8b\u5b50\u3002\u672c\u6587\u65e8\u5728\u7a81\u7834\u8fd9\u4e00\u9650\u5236\uff0c\u8bc1\u660e\u6240\u6709\u51fd\u6570\u90fd\u53ef\u5728\u8be5\u6a21\u578b\u4e0b\u8ba1\u7b97\u3002", "method": "\u901a\u8fc7\u5efa\u7acb\u5355\u6b21\u6d17\u724c\u5168\u516c\u5f00\u534f\u8bae\u4e0e\u5bc6\u7801\u5b66\u539f\u8bed\"\u79c1\u6709\u540c\u65f6\u6d88\u606f\"\u534f\u8bae\u4e4b\u95f4\u7684\u65b0\u8054\u7cfb\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u6784\u9020\u65b9\u6cd5\uff1a\u4e00\u79cd\u4f18\u5316\u5361\u724c\u6570\u91cf\uff0c\u53e6\u4e00\u79cd\u4f18\u5316\u6d17\u724c\u590d\u6742\u5ea6\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86\u6240\u6709\u51fd\u6570\u90fd\u5b58\u5728\u5355\u6b21\u6d17\u724c\u5168\u516c\u5f00\u534f\u8bae\uff0c\u5e76\u63d0\u51fa\u4e86\u6bd4\u73b0\u6709\u534f\u8bae\u6d17\u724c\u590d\u6742\u5ea6\u66f4\u4f4e\u7684\u53d8\u4f53\u534f\u8bae\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u6269\u5c55\u4e86\u5361\u724c\u5b89\u5168\u8ba1\u7b97\u7684\u80fd\u529b\u8fb9\u754c\uff0c\u4e3a\u6700\u5c0f\u6a21\u578b\u4e0b\u7684\u901a\u7528\u5b89\u5168\u8ba1\u7b97\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u6784\u9020\u3002"}}
{"id": "2510.17172", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17172", "abs": "https://arxiv.org/abs/2510.17172", "authors": ["Shun Huang", "Wenlu Xing", "Shijia Geng", "Hailong Wang", "Guangkun Nie", "Gongzheng Tang", "Chenyang He", "Shenda Hong"], "title": "Combining ECG Foundation Model and XGBoost to Predict In-Hospital Malignant Ventricular Arrhythmias in AMI Patients", "comment": null, "summary": "Malignant ventricular arrhythmias (VT/VF) following acute myocardial\ninfarction (AMI) are a major cause of in-hospital death, yet early\nidentification remains a clinical challenge. While traditional risk scores have\nlimited performance, end-to-end deep learning models often lack the\ninterpretability needed for clinical trust. This study aimed to develop a\nhybrid predictive framework that integrates a large-scale electrocardiogram\n(ECG) foundation model (ECGFounder) with an interpretable XGBoost classifier to\nimprove both accuracy and interpretability. We analyzed 6,634 ECG recordings\nfrom AMI patients, among whom 175 experienced in-hospital VT/VF. The ECGFounder\nmodel was used to extract 150-dimensional diagnostic probability features ,\nwhich were then refined through feature selection to train the XGBoost\nclassifier. Model performance was evaluated using AUC and F1-score , and the\nSHAP method was used for interpretability. The ECGFounder + XGBoost hybrid\nmodel achieved an AUC of 0.801 , outperforming KNN (AUC 0.677), RNN (AUC\n0.676), and an end-to-end 1D-CNN (AUC 0.720). SHAP analysis revealed that\nmodel-identified key features, such as \"premature ventricular complexes\" (risk\npredictor) and \"normal sinus rhythm\" (protective factor), were highly\nconsistent with clinical knowledge. We conclude that this hybrid framework\nprovides a novel paradigm for VT/VF risk prediction by validating the use of\nfoundation model outputs as effective, automated feature engineering for\nbuilding trustworthy, explainable AI-based clinical decision support systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u7ed3\u5408ECG\u57fa\u7840\u6a21\u578b\u548c\u53ef\u89e3\u91caXGBoost\u5206\u7c7b\u5668\u7684\u6df7\u5408\u9884\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u6025\u6027\u5fc3\u808c\u6897\u6b7b\u540e\u6076\u6027\u5ba4\u6027\u5fc3\u5f8b\u5931\u5e38\u7684\u65e9\u671f\u8bc6\u522b\uff0c\u5728\u63d0\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u4fdd\u6301\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6025\u6027\u5fc3\u808c\u6897\u6b7b\u540e\u6076\u6027\u5ba4\u6027\u5fc3\u5f8b\u5931\u5e38\u662f\u9662\u5185\u6b7b\u4ea1\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u4f20\u7edf\u98ce\u9669\u8bc4\u5206\u6027\u80fd\u6709\u9650\uff0c\u800c\u7aef\u5230\u7aef\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7f3a\u4e4f\u4e34\u5e8a\u4fe1\u4efb\u6240\u9700\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u4f7f\u7528ECGFounder\u57fa\u7840\u6a21\u578b\u63d0\u53d6150\u7ef4\u8bca\u65ad\u6982\u7387\u7279\u5f81\uff0c\u901a\u8fc7\u7279\u5f81\u9009\u62e9\u540e\u8bad\u7ec3XGBoost\u5206\u7c7b\u5668\uff0c\u5e76\u91c7\u7528SHAP\u65b9\u6cd5\u8fdb\u884c\u53ef\u89e3\u91ca\u6027\u5206\u6790\u3002", "result": "\u6df7\u5408\u6a21\u578bAUC\u8fbe\u52300.801\uff0c\u4f18\u4e8eKNN(0.677)\u3001RNN(0.676)\u548c1D-CNN(0.720)\uff0cSHAP\u5206\u6790\u663e\u793a\u6a21\u578b\u8bc6\u522b\u7684\u5173\u952e\u7279\u5f81\u4e0e\u4e34\u5e8a\u77e5\u8bc6\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "\u8be5\u6df7\u5408\u6846\u67b6\u901a\u8fc7\u9a8c\u8bc1\u57fa\u7840\u6a21\u578b\u8f93\u51fa\u4f5c\u4e3a\u6709\u6548\u7684\u81ea\u52a8\u5316\u7279\u5f81\u5de5\u7a0b\uff0c\u4e3a\u6784\u5efa\u53ef\u4fe1\u8d56\u3001\u53ef\u89e3\u91ca\u7684AI\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2510.17311", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.17311", "abs": "https://arxiv.org/abs/2510.17311", "authors": ["Eduard Marin", "Jinwoo Kim", "Alessio Pavoni", "Mauro Conti", "Roberto Di Pietro"], "title": "The Hidden Dangers of Public Serverless Repositories: An Empirical Security Assessment", "comment": "Accepted at ESORICS 2025", "summary": "Serverless computing has rapidly emerged as a prominent cloud paradigm,\nenabling developers to focus solely on application logic without the burden of\nmanaging servers or underlying infrastructure. Public serverless repositories\nhave become key to accelerating the development of serverless applications.\nHowever, their growing popularity makes them attractive targets for\nadversaries. Despite this, the security posture of these repositories remains\nlargely unexplored, exposing developers and organizations to potential risks.\nIn this paper, we present the first comprehensive analysis of the security\nlandscape of serverless components hosted in public repositories. We analyse\n2,758 serverless components from five widely used public repositories popular\namong developers and enterprises, and 125,936 Infrastructure as Code (IaC)\ntemplates across three widely used IaC frameworks. Our analysis reveals\nsystemic vulnerabilities including outdated software packages, misuse of\nsensitive parameters, exploitable deployment configurations, susceptibility to\ntypo-squatting attacks and opportunities to embed malicious behaviour within\ncompressed serverless components. Finally, we provide practical recommendations\nto mitigate these threats.", "AI": {"tldr": "\u5bf95\u4e2a\u516c\u5171\u65e0\u670d\u52a1\u5668\u4ed3\u5e93\u4e2d2,758\u4e2a\u7ec4\u4ef6\u548c3\u4e2aIaC\u6846\u67b6\u4e2d125,936\u4e2a\u6a21\u677f\u7684\u5b89\u5168\u5206\u6790\uff0c\u63ed\u793a\u4e86\u7cfb\u7edf\u6027\u6f0f\u6d1e\uff0c\u5305\u62ec\u8fc7\u65f6\u8f6f\u4ef6\u5305\u3001\u654f\u611f\u53c2\u6570\u8bef\u7528\u3001\u53ef\u88ab\u5229\u7528\u7684\u90e8\u7f72\u914d\u7f6e\u7b49\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u5df2\u6210\u4e3a\u4e3b\u6d41\u4e91\u8303\u5f0f\uff0c\u516c\u5171\u65e0\u670d\u52a1\u5668\u4ed3\u5e93\u5728\u52a0\u901f\u5e94\u7528\u5f00\u53d1\u7684\u540c\u65f6\u4e5f\u6210\u4e3a\u653b\u51fb\u8005\u7684\u76ee\u6807\uff0c\u4f46\u8fd9\u4e9b\u4ed3\u5e93\u7684\u5b89\u5168\u72b6\u51b5\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u4f7f\u5f00\u53d1\u8005\u548c\u7ec4\u7ec7\u9762\u4e34\u6f5c\u5728\u98ce\u9669\u3002", "method": "\u5206\u6790\u6765\u81ea5\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u516c\u5171\u65e0\u670d\u52a1\u5668\u4ed3\u5e93\u76842,758\u4e2a\u65e0\u670d\u52a1\u5668\u7ec4\u4ef6\uff0c\u4ee5\u53ca\u8de83\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684IaC\u6846\u67b6\u7684125,936\u4e2a\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801\u6a21\u677f\u3002", "result": "\u53d1\u73b0\u7cfb\u7edf\u6027\u6f0f\u6d1e\u5305\u62ec\uff1a\u8fc7\u65f6\u8f6f\u4ef6\u5305\u3001\u654f\u611f\u53c2\u6570\u8bef\u7528\u3001\u53ef\u88ab\u5229\u7528\u7684\u90e8\u7f72\u914d\u7f6e\u3001\u6613\u53d7\u57df\u540d\u62a2\u6ce8\u653b\u51fb\u3001\u5728\u538b\u7f29\u65e0\u670d\u52a1\u5668\u7ec4\u4ef6\u4e2d\u5d4c\u5165\u6076\u610f\u884c\u4e3a\u7684\u673a\u4f1a\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5efa\u8bae\u6765\u7f13\u89e3\u8fd9\u4e9b\u5a01\u80c1\uff0c\u5f3a\u8c03\u9700\u8981\u52a0\u5f3a\u516c\u5171\u65e0\u670d\u52a1\u5668\u4ed3\u5e93\u7684\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u3002"}}
{"id": "2510.17173", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17173", "abs": "https://arxiv.org/abs/2510.17173", "authors": ["Melik Ozolcer", "Sang Won Bae"], "title": "Offline Policy Evaluation of Multi-Turn LLM Health Coaching with Real Users", "comment": "Accepted to the NeurIPS 2025 Workshop on Multi-Turn Interactions in\n  Large Language Models", "summary": "We study a web-deployed, tool-augmented LLM health coach with real users. In\na pilot with seven users (280 rated turns), offline policy evaluation (OPE)\nover factorized decision heads (Tool/Style) shows that a uniform heavy-tool\npolicy raises average value on logs but harms specific subgroups, most notably\nlow-health-literacy/high-self-efficacy users. A lightweight simulator with\nhidden archetypes further shows that adding a small early information-gain\nbonus reliably shortens trait identification and improves goal success and\npass@3. Together, these early findings indicate an evaluation-first path to\npersonalization: freeze the generator, learn subgroup-aware decision heads on\ntyped rewards (objective tool outcomes and satisfaction), and always report\nper-archetype metrics to surface subgroup harms that averages obscure.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5de5\u5177\u7684LLM\u5065\u5eb7\u6559\u7ec3\u7cfb\u7edf\uff0c\u901a\u8fc7\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\u53d1\u73b0\u7edf\u4e00\u7684\u91cd\u5de5\u5177\u7b56\u7565\u4f1a\u635f\u5bb3\u7279\u5b9a\u7528\u6237\u7fa4\u4f53\uff08\u5982\u4f4e\u5065\u5eb7\u7d20\u517b/\u9ad8\u81ea\u6211\u6548\u80fd\u7528\u6237\uff09\uff0c\u5e76\u63d0\u51fa\u4e86\u901a\u8fc7\u6dfb\u52a0\u65e9\u671f\u4fe1\u606f\u589e\u76ca\u5956\u52b1\u6765\u6539\u5584\u4e2a\u6027\u5316\u6548\u679c\u7684\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u4e2a\u6027\u5316\u7b56\u7565\u6765\u4f18\u5316\u57fa\u4e8e\u5de5\u5177\u7684LLM\u5065\u5eb7\u6559\u7ec3\u7cfb\u7edf\uff0c\u907f\u514d\u7edf\u4e00\u7b56\u7565\u5bf9\u7279\u5b9a\u7528\u6237\u7fa4\u4f53\u9020\u6210\u4f24\u5bb3\uff0c\u540c\u65f6\u63d0\u9ad8\u6574\u4f53\u670d\u52a1\u6548\u679c\u3002", "method": "\u91c7\u7528\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\uff08OPE\uff09\u65b9\u6cd5\u5206\u6790\u56e0\u5b50\u5316\u51b3\u7b56\u5934\uff08\u5de5\u5177/\u98ce\u683c\uff09\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6a21\u62df\u5668\u6d4b\u8bd5\u6dfb\u52a0\u65e9\u671f\u4fe1\u606f\u589e\u76ca\u5956\u52b1\u7684\u6548\u679c\uff0c\u4ee5\u8bc6\u522b\u7528\u6237\u7279\u5f81\u5e76\u6539\u8fdb\u76ee\u6807\u6210\u529f\u7387\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u7edf\u4e00\u7684\u91cd\u5de5\u5177\u7b56\u7565\u867d\u7136\u63d0\u9ad8\u4e86\u5e73\u5747\u4ef7\u503c\uff0c\u4f46\u635f\u5bb3\u4e86\u4f4e\u5065\u5eb7\u7d20\u517b/\u9ad8\u81ea\u6211\u6548\u80fd\u7528\u6237\u7fa4\u4f53\uff1b\u6dfb\u52a0\u65e9\u671f\u4fe1\u606f\u589e\u76ca\u5956\u52b1\u80fd\u53ef\u9760\u5730\u7f29\u77ed\u7279\u5f81\u8bc6\u522b\u65f6\u95f4\u5e76\u63d0\u9ad8\u76ee\u6807\u6210\u529f\u7387\u548cpass@3\u6307\u6807\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4ee5\u8bc4\u4f30\u4e3a\u5148\u7684\u4e2a\u6027\u5316\u8def\u5f84\uff1a\u51bb\u7ed3\u751f\u6210\u5668\uff0c\u57fa\u4e8e\u7c7b\u578b\u5316\u5956\u52b1\uff08\u5ba2\u89c2\u5de5\u5177\u7ed3\u679c\u548c\u6ee1\u610f\u5ea6\uff09\u5b66\u4e60\u5b50\u7fa4\u4f53\u611f\u77e5\u7684\u51b3\u7b56\u5934\uff0c\u5e76\u59cb\u7ec8\u62a5\u544a\u6bcf\u4e2a\u539f\u578b\u6307\u6807\u4ee5\u63ed\u793a\u88ab\u5e73\u5747\u503c\u63a9\u76d6\u7684\u5b50\u7fa4\u4f53\u4f24\u5bb3\u3002"}}
{"id": "2510.17211", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17211", "abs": "https://arxiv.org/abs/2510.17211", "authors": ["Tingsong Xiao", "Yao An Lee", "Zelin Xu", "Yupu Zhang", "Zibo Liu", "Yu Huang", "Jiang Bian", "Serena Jingchuan Guo", "Zhe Jiang"], "title": "Temporally Detailed Hypergraph Neural ODEs for Type 2 Diabetes Progression Modeling", "comment": null, "summary": "Disease progression modeling aims to characterize and predict how a patient's\ndisease complications worsen over time based on longitudinal electronic health\nrecords (EHRs). Accurate modeling of disease progression, such as type 2\ndiabetes, can enhance patient sub-phenotyping and inform effective and timely\ninterventions. However, the problem is challenging due to the need to learn\ncontinuous-time dynamics of progression patterns based on irregular-time event\nsamples and patient heterogeneity (\\eg different progression rates and\npathways). Existing mechanistic and data-driven methods either lack\nadaptability to learn from real-world data or fail to capture complex\ncontinuous-time dynamics on progression trajectories. To address these\nlimitations, we propose Temporally Detailed Hypergraph Neural Ordinary\nDifferential Equation (TD-HNODE), which represents disease progression on\nclinically recognized trajectories as a temporally detailed hypergraph and\nlearns the continuous-time progression dynamics via a neural ODE framework.\nTD-HNODE contains a learnable TD-Hypergraph Laplacian that captures the\ninterdependency of disease complication markers within both intra- and\ninter-progression trajectories. Experiments on two real-world clinical datasets\ndemonstrate that TD-HNODE outperforms multiple baselines in modeling the\nprogression of type 2 diabetes and related cardiovascular diseases.", "AI": {"tldr": "\u63d0\u51fa\u4e86TD-HNODE\u6a21\u578b\uff0c\u901a\u8fc7\u65f6\u95f4\u8be6\u7ec6\u8d85\u56fe\u8868\u793a\u75be\u75c5\u8fdb\u5c55\u8f68\u8ff9\uff0c\u4f7f\u7528\u795e\u7ecfODE\u6846\u67b6\u5b66\u4e60\u8fde\u7eed\u65f6\u95f4\u8fdb\u5c55\u52a8\u6001\uff0c\u57282\u578b\u7cd6\u5c3f\u75c5\u548c\u5fc3\u8840\u7ba1\u75be\u75c5\u8fdb\u5c55\u5efa\u6a21\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u75be\u75c5\u8fdb\u5c55\u5efa\u6a21\u9762\u4e34\u6311\u6218\uff1a\u9700\u8981\u57fa\u4e8e\u4e0d\u89c4\u5219\u65f6\u95f4\u4e8b\u4ef6\u6837\u672c\u5b66\u4e60\u8fde\u7eed\u65f6\u95f4\u52a8\u6001\uff0c\u4e14\u60a3\u8005\u5b58\u5728\u5f02\u8d28\u6027\uff08\u4e0d\u540c\u8fdb\u5c55\u901f\u7387\u548c\u8def\u5f84\uff09\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u7f3a\u4e4f\u4ece\u771f\u5b9e\u6570\u636e\u5b66\u4e60\u7684\u9002\u5e94\u6027\uff0c\u8981\u4e48\u65e0\u6cd5\u6355\u6349\u590d\u6742\u7684\u8fde\u7eed\u65f6\u95f4\u52a8\u6001\u3002", "method": "TD-HNODE\u6a21\u578b\u5c06\u75be\u75c5\u8fdb\u5c55\u8868\u793a\u4e3a\u65f6\u95f4\u8be6\u7ec6\u8d85\u56fe\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684TD-Hypergraph Laplacian\u6355\u6349\u75be\u75c5\u5e76\u53d1\u75c7\u6807\u5fd7\u7269\u5728\u8fdb\u5c55\u8f68\u8ff9\u5185\u90e8\u548c\u4e4b\u95f4\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f7f\u7528\u795e\u7ecfODE\u6846\u67b6\u5b66\u4e60\u8fde\u7eed\u65f6\u95f4\u8fdb\u5c55\u52a8\u6001\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u4e34\u5e8a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTD-HNODE\u5728\u5efa\u6a212\u578b\u7cd6\u5c3f\u75c5\u548c\u76f8\u5173\u5fc3\u8840\u7ba1\u75be\u75c5\u8fdb\u5c55\u65b9\u9762\u4f18\u4e8e\u591a\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "TD-HNODE\u80fd\u591f\u6709\u6548\u6355\u6349\u75be\u75c5\u8fdb\u5c55\u7684\u8fde\u7eed\u65f6\u95f4\u52a8\u6001\uff0c\u89e3\u51b3\u60a3\u8005\u5f02\u8d28\u6027\u548c\u4e0d\u89c4\u5219\u65f6\u95f4\u91c7\u6837\u5e26\u6765\u7684\u6311\u6218\uff0c\u4e3a\u60a3\u8005\u4e9a\u8868\u578b\u5206\u6790\u548c\u53ca\u65f6\u5e72\u9884\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2510.17309", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17309", "abs": "https://arxiv.org/abs/2510.17309", "authors": ["Thorsten Fr\u00f6hlich", "Tim Schlippe"], "title": "RubiSCoT: A Framework for AI-Supported Academic Assessment", "comment": null, "summary": "The evaluation of academic theses is a cornerstone of higher education,\nensuring rigor and integrity. Traditional methods, though effective, are\ntime-consuming and subject to evaluator variability. This paper presents\nRubiSCoT, an AI-supported framework designed to enhance thesis evaluation from\nproposal to final submission. Using advanced natural language processing\ntechniques, including large language models, retrieval-augmented generation,\nand structured chain-of-thought prompting, RubiSCoT offers a consistent,\nscalable solution. The framework includes preliminary assessments,\nmultidimensional assessments, content extraction, rubric-based scoring, and\ndetailed reporting. We present the design and implementation of RubiSCoT,\ndiscussing its potential to optimize academic assessment processes through\nconsistent, scalable, and transparent evaluation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86RubiSCoT\uff0c\u4e00\u4e2aAI\u652f\u6301\u7684\u8bba\u6587\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\uff08\u5305\u62ec\u5927\u8bed\u8a00\u6a21\u578b\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\u63d0\u793a\uff09\u6765\u589e\u5f3a\u4ece\u63d0\u6848\u5230\u6700\u7ec8\u63d0\u4ea4\u7684\u8bba\u6587\u8bc4\u4f30\u8fc7\u7a0b\u3002", "motivation": "\u4f20\u7edf\u8bba\u6587\u8bc4\u4f30\u65b9\u6cd5\u867d\u7136\u6709\u6548\uff0c\u4f46\u8017\u65f6\u4e14\u53d7\u8bc4\u4f30\u8005\u4e3b\u89c2\u6027\u5f71\u54cd\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u4e00\u81f4\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u5148\u8fdb\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\uff0c\u5305\u62ec\u5927\u8bed\u8a00\u6a21\u578b\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\u63d0\u793a\uff0c\u6784\u5efa\u5305\u542b\u521d\u6b65\u8bc4\u4f30\u3001\u591a\u7ef4\u8bc4\u4f30\u3001\u5185\u5bb9\u63d0\u53d6\u3001\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u5206\u548c\u8be6\u7ec6\u62a5\u544a\u7684\u6846\u67b6\u3002", "result": "\u8bbe\u8ba1\u4e86RubiSCoT\u6846\u67b6\u5e76\u5b9e\u73b0\u4e86\u5176\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u901a\u8fc7\u4e00\u81f4\u3001\u53ef\u6269\u5c55\u548c\u900f\u660e\u7684\u8bc4\u4f30\u6765\u4f18\u5316\u5b66\u672f\u8bc4\u4f30\u6d41\u7a0b\u7684\u6f5c\u529b\u3002", "conclusion": "RubiSCoT\u6709\u6f5c\u529b\u901a\u8fc7\u63d0\u4f9b\u4e00\u81f4\u3001\u53ef\u6269\u5c55\u548c\u900f\u660e\u7684\u8bc4\u4f30\u6765\u4f18\u5316\u5b66\u672f\u8bc4\u4f30\u6d41\u7a0b\u3002"}}
{"id": "2510.17621", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17621", "abs": "https://arxiv.org/abs/2510.17621", "authors": ["Vincenzo Carletti", "Pasquale Foggia", "Carlo Mazzocca", "Giuseppe Parrella", "Mario Vento"], "title": "GUIDE: Enhancing Gradient Inversion Attacks in Federated Learning with Denoising Models", "comment": null, "summary": "Federated Learning (FL) enables collaborative training of Machine Learning\n(ML) models across multiple clients while preserving their privacy. Rather than\nsharing raw data, federated clients transmit locally computed updates to train\nthe global model. Although this paradigm should provide stronger privacy\nguarantees than centralized ML, client updates remain vulnerable to privacy\nleakage. Adversaries can exploit them to infer sensitive properties about the\ntraining data or even to reconstruct the original inputs via Gradient Inversion\nAttacks (GIAs). Under the honest-butcurious threat model, GIAs attempt to\nreconstruct training data by reversing intermediate updates using\noptimizationbased techniques. We observe that these approaches usually\nreconstruct noisy approximations of the original inputs, whose quality can be\nenhanced with specialized denoising models. This paper presents Gradient Update\nInversion with DEnoising (GUIDE), a novel methodology that leverages diffusion\nmodels as denoising tools to improve image reconstruction attacks in FL. GUIDE\ncan be integrated into any GIAs that exploits surrogate datasets, a widely\nadopted assumption in GIAs literature. We comprehensively evaluate our approach\nin two attack scenarios that use different FL algorithms, models, and datasets.\nOur results demonstrate that GUIDE integrates seamlessly with two state-ofthe-\nart GIAs, substantially improving reconstruction quality across multiple\nmetrics. Specifically, GUIDE achieves up to 46% higher perceptual similarity,\nas measured by the DreamSim metric.", "AI": {"tldr": "GUIDE\u662f\u4e00\u79cd\u5229\u7528\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u53bb\u566a\u5de5\u5177\u6765\u589e\u5f3a\u8054\u90a6\u5b66\u4e60\u4e2d\u56fe\u50cf\u91cd\u5efa\u653b\u51fb\u6548\u679c\u7684\u65b0\u65b9\u6cd5\uff0c\u53ef\u96c6\u6210\u5230\u4efb\u4f55\u4f7f\u7528\u66ff\u4ee3\u6570\u636e\u96c6\u7684\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u91cd\u5efa\u8d28\u91cf\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u7136\u4fdd\u62a4\u4e86\u539f\u59cb\u6570\u636e\u9690\u79c1\uff0c\u4f46\u5ba2\u6237\u7aef\u66f4\u65b0\u7684\u68af\u5ea6\u4fe1\u606f\u4ecd\u6613\u53d7\u9690\u79c1\u6cc4\u9732\u653b\u51fb\u3002\u73b0\u6709\u7684\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u901a\u5e38\u53ea\u80fd\u91cd\u5efa\u5e26\u566a\u58f0\u7684\u8f93\u5165\u8fd1\u4f3c\u503c\uff0c\u9700\u8981\u4e13\u95e8\u7684\u53bb\u566a\u6280\u672f\u6765\u63d0\u5347\u91cd\u5efa\u8d28\u91cf\u3002", "method": "\u63d0\u51faGUIDE\u65b9\u6cd5\uff0c\u5c06\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u53bb\u566a\u5de5\u5177\u96c6\u6210\u5230\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u4e2d\u3002\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u4efb\u4f55\u4f7f\u7528\u66ff\u4ee3\u6570\u636e\u96c6\u7684\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\uff0c\u901a\u8fc7\u6269\u6563\u6a21\u578b\u7684\u53bb\u566a\u80fd\u529b\u63d0\u5347\u56fe\u50cf\u91cd\u5efa\u8d28\u91cf\u3002", "result": "\u5728\u4e24\u4e2a\u4f7f\u7528\u4e0d\u540c\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u3001\u6a21\u578b\u548c\u6570\u636e\u96c6\u7684\u653b\u51fb\u573a\u666f\u4e2d\uff0cGUIDE\u4e0e\u4e24\u79cd\u6700\u5148\u8fdb\u7684\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u65e0\u7f1d\u96c6\u6210\uff0c\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u91cd\u5efa\u8d28\u91cf\uff0cDreamSim\u611f\u77e5\u76f8\u4f3c\u5ea6\u6307\u6807\u6700\u9ad8\u63d0\u534746%\u3002", "conclusion": "GUIDE\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u7684\u56fe\u50cf\u91cd\u5efa\u8d28\u91cf\uff0c\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u53bb\u566a\u5de5\u5177\u5728\u9690\u79c1\u653b\u51fb\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u6f5c\u529b\u3002"}}
{"id": "2510.17687", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17687", "abs": "https://arxiv.org/abs/2510.17687", "authors": ["Xu Zhang", "Hao Li", "Zhichao Lu"], "title": "CrossGuard: Safeguarding MLLMs against Joint-Modal Implicit Malicious Attacks", "comment": "14 pages, 8 figures, 2 tables", "summary": "Multimodal Large Language Models (MLLMs) achieve strong reasoning and\nperception capabilities but are increasingly vulnerable to jailbreak attacks.\nWhile existing work focuses on explicit attacks, where malicious content\nresides in a single modality, recent studies reveal implicit attacks, in which\nbenign text and image inputs jointly express unsafe intent. Such joint-modal\nthreats are difficult to detect and remain underexplored, largely due to the\nscarcity of high-quality implicit data. We propose ImpForge, an automated\nred-teaming pipeline that leverages reinforcement learning with tailored reward\nmodules to generate diverse implicit samples across 14 domains. Building on\nthis dataset, we further develop CrossGuard, an intent-aware safeguard\nproviding robust and comprehensive defense against both explicit and implicit\nthreats. Extensive experiments across safe and unsafe benchmarks, implicit and\nexplicit attacks, and multiple out-of-domain settings demonstrate that\nCrossGuard significantly outperforms existing defenses, including advanced\nMLLMs and guardrails, achieving stronger security while maintaining high\nutility. This offers a balanced and practical solution for enhancing MLLM\nrobustness against real-world multimodal threats.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ImpForge\u81ea\u52a8\u5316\u7ea2\u961f\u7ba1\u9053\u751f\u6210\u591a\u6837\u5316\u9690\u5f0f\u653b\u51fb\u6837\u672c\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86CrossGuard\u610f\u56fe\u611f\u77e5\u4fdd\u62a4\u7cfb\u7edf\uff0c\u6709\u6548\u9632\u5fa1\u663e\u5f0f\u548c\u9690\u5f0f\u591a\u6a21\u6001\u5a01\u80c1\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u548c\u611f\u77e5\u65b9\u9762\u8868\u73b0\u5f3a\u5927\uff0c\u4f46\u8d8a\u6765\u8d8a\u5bb9\u6613\u53d7\u5230\u8d8a\u72f1\u653b\u51fb\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u663e\u5f0f\u653b\u51fb\uff0c\u800c\u9690\u5f0f\u653b\u51fb\uff08\u826f\u6027\u6587\u672c\u548c\u56fe\u50cf\u8f93\u5165\u5171\u540c\u8868\u8fbe\u4e0d\u5b89\u5168\u610f\u56fe\uff09\u96be\u4ee5\u68c0\u6d4b\u4e14\u7814\u7a76\u4e0d\u8db3\uff0c\u4e3b\u8981\u7531\u4e8e\u9ad8\u8d28\u91cf\u9690\u5f0f\u6570\u636e\u7a00\u7f3a\u3002", "method": "\u63d0\u51faImpForge\u81ea\u52a8\u5316\u7ea2\u961f\u7ba1\u9053\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u5b9a\u5236\u5956\u52b1\u6a21\u5757\u572814\u4e2a\u9886\u57df\u751f\u6210\u591a\u6837\u5316\u9690\u5f0f\u6837\u672c\uff1b\u57fa\u4e8e\u6b64\u6570\u636e\u96c6\u5f00\u53d1CrossGuard\u610f\u56fe\u611f\u77e5\u4fdd\u62a4\u7cfb\u7edf\u3002", "result": "\u5728\u5b89\u5168\u548c\u4e0d\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u3001\u9690\u5f0f\u548c\u663e\u5f0f\u653b\u51fb\u4ee5\u53ca\u591a\u4e2a\u57df\u5916\u8bbe\u7f6e\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cCrossGuard\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\uff0c\u5305\u62ec\u5148\u8fdb\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u9632\u62a4\u673a\u5236\uff0c\u5728\u4fdd\u6301\u9ad8\u5b9e\u7528\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u66f4\u5f3a\u7684\u5b89\u5168\u6027\u3002", "conclusion": "\u8fd9\u4e3a\u589e\u5f3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u6297\u73b0\u5b9e\u4e16\u754c\u591a\u6a21\u6001\u5a01\u80c1\u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e73\u8861\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17759", "categories": ["cs.CR", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17759", "abs": "https://arxiv.org/abs/2510.17759", "authors": ["Qilin Liao", "Anamika Lochab", "Ruqi Zhang"], "title": "VERA-V: Variational Inference Framework for Jailbreaking Vision-Language Models", "comment": "18 pages, 7 Figures,", "summary": "Vision-Language Models (VLMs) extend large language models with visual\nreasoning, but their multimodal design also introduces new, underexplored\nvulnerabilities. Existing multimodal red-teaming methods largely rely on\nbrittle templates, focus on single-attack settings, and expose only a narrow\nsubset of vulnerabilities. To address these limitations, we introduce VERA-V, a\nvariational inference framework that recasts multimodal jailbreak discovery as\nlearning a joint posterior distribution over paired text-image prompts. This\nprobabilistic view enables the generation of stealthy, coupled adversarial\ninputs that bypass model guardrails. We train a lightweight attacker to\napproximate the posterior, allowing efficient sampling of diverse jailbreaks\nand providing distributional insights into vulnerabilities. VERA-V further\nintegrates three complementary strategies: (i) typography-based text prompts\nthat embed harmful cues, (ii) diffusion-based image synthesis that introduces\nadversarial signals, and (iii) structured distractors to fragment VLM\nattention. Experiments on HarmBench and HADES benchmarks show that VERA-V\nconsistently outperforms state-of-the-art baselines on both open-source and\nfrontier VLMs, achieving up to 53.75% higher attack success rate (ASR) over the\nbest baseline on GPT-4o.", "AI": {"tldr": "VERA-V\u662f\u4e00\u4e2a\u53d8\u5206\u63a8\u7406\u6846\u67b6\uff0c\u5c06\u591a\u6a21\u6001\u8d8a\u72f1\u53d1\u73b0\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5b66\u4e60\u914d\u5bf9\u6587\u672c-\u56fe\u50cf\u63d0\u793a\u7684\u8054\u5408\u540e\u9a8c\u5206\u5e03\uff0c\u901a\u8fc7\u751f\u6210\u9690\u853d\u7684\u5bf9\u6297\u6027\u8f93\u5165\u6765\u7ed5\u8fc7\u6a21\u578b\u9632\u62a4\u673a\u5236\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u7ea2\u961f\u65b9\u6cd5\u4f9d\u8d56\u8106\u5f31\u6a21\u677f\u3001\u4e13\u6ce8\u4e8e\u5355\u653b\u51fb\u8bbe\u7f6e\uff0c\u4ec5\u66b4\u9732\u6709\u9650\u6f0f\u6d1e\u5b50\u96c6\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u6f0f\u6d1e\u53d1\u73b0\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u53d8\u5206\u63a8\u7406\u6846\u67b6\u5b66\u4e60\u6587\u672c-\u56fe\u50cf\u63d0\u793a\u7684\u8054\u5408\u540e\u9a8c\u5206\u5e03\uff0c\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u653b\u51fb\u5668\u8fd1\u4f3c\u540e\u9a8c\uff0c\u7ed3\u5408\u6392\u7248\u6587\u672c\u63d0\u793a\u3001\u57fa\u4e8e\u6269\u6563\u7684\u56fe\u50cf\u5408\u6210\u548c\u7ed3\u6784\u5316\u5e72\u6270\u4e09\u79cd\u4e92\u8865\u7b56\u7565\u3002", "result": "\u5728HarmBench\u548cHADES\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVERA-V\u5728\u5f00\u6e90\u548c\u524d\u6cbfVLM\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\uff0c\u5728GPT-4o\u4e0a\u653b\u51fb\u6210\u529f\u7387\u6bd4\u6700\u4f73\u57fa\u7ebf\u9ad8\u51fa53.75%\u3002", "conclusion": "VERA-V\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u591a\u6a21\u6001\u8d8a\u72f1\u53d1\u73b0\u65b9\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u591a\u6837\u5316\u8d8a\u72f1\u5e76\u63ed\u793a\u6f0f\u6d1e\u5206\u5e03\u7279\u5f81\u3002"}}
{"id": "2510.17450", "categories": ["cs.AI", "H.4.2; I.2.3; I.2.6; I.2.8; I.2.9; J.7"], "pdf": "https://arxiv.org/pdf/2510.17450", "abs": "https://arxiv.org/abs/2510.17450", "authors": ["Johan Schubert", "Farzad Kamrani", "Tove Gustavi"], "title": "Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions", "comment": "Presented at the 6th International Workshop on Active Inference,\n  15-17 October 2025, Montreal, Canada", "summary": "We develop an active inference route-planning method for the autonomous\ncontrol of intelligent agents. The aim is to reconnoiter a geographical area to\nmaintain a common operational picture. To achieve this, we construct an\nevidence map that reflects our current understanding of the situation,\nincorporating both positive and \"negative\" sensor observations of possible\ntarget objects collected over time, and diffusing the evidence across the map\nas time progresses. The generative model of active inference uses\nDempster-Shafer theory and a Gaussian sensor model, which provides input to the\nagent. The generative process employs a Bayesian approach to update a posterior\nprobability distribution. We calculate the variational free energy for all\npositions within the area by assessing the divergence between a pignistic\nprobability distribution of the evidence map and a posterior probability\ndistribution of a target object based on the observations, including the level\nof surprise associated with receiving new observations. Using the free energy,\nwe direct the agents' movements in a simulation by taking an incremental step\ntoward a position that minimizes the free energy. This approach addresses the\nchallenge of exploration and exploitation, allowing agents to balance searching\nextensive areas of the geographical map while tracking identified target\nobjects.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e3b\u52a8\u63a8\u7406\u7684\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\uff0c\u7528\u4e8e\u667a\u80fd\u4f53\u81ea\u4e3b\u63a7\u5236\uff0c\u901a\u8fc7\u6784\u5efa\u8bc1\u636e\u5730\u56fe\u548c\u8ba1\u7b97\u53d8\u5206\u81ea\u7531\u80fd\u91cf\u6765\u6307\u5bfc\u667a\u80fd\u4f53\u5728\u63a2\u7d22\u548c\u5229\u7528\u4e4b\u95f4\u5e73\u8861\u79fb\u52a8\u3002", "motivation": "\u4e3a\u4e86\u7ef4\u6301\u5171\u540c\u4f5c\u6218\u6001\u52bf\u56fe\u800c\u4fa6\u5bdf\u5730\u7406\u533a\u57df\uff0c\u9700\u8981\u89e3\u51b3\u667a\u80fd\u4f53\u5728\u63a2\u7d22\u5e7f\u9614\u533a\u57df\u548c\u8ddf\u8e2a\u5df2\u8bc6\u522b\u76ee\u6807\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\u3002", "method": "\u4f7f\u7528Dempster-Shafer\u7406\u8bba\u548c\u9ad8\u65af\u4f20\u611f\u5668\u6a21\u578b\u6784\u5efa\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u65b9\u6cd5\u66f4\u65b0\u540e\u9a8c\u6982\u7387\u5206\u5e03\uff0c\u8ba1\u7b97\u53d8\u5206\u81ea\u7531\u80fd\u91cf\u6765\u6307\u5bfc\u667a\u80fd\u4f53\u5411\u6700\u5c0f\u5316\u81ea\u7531\u80fd\u91cf\u7684\u4f4d\u7f6e\u79fb\u52a8\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6307\u5bfc\u667a\u80fd\u4f53\u5728\u6a21\u62df\u73af\u5883\u4e2d\u79fb\u52a8\uff0c\u5e73\u8861\u63a2\u7d22\u548c\u5229\u7528\u7684\u9700\u6c42\u3002", "conclusion": "\u4e3b\u52a8\u63a8\u7406\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u667a\u80fd\u4f53\u5728\u5730\u7406\u533a\u57df\u4fa6\u5bdf\u4e2d\u7684\u63a2\u7d22-\u5229\u7528\u6743\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u53d8\u5206\u81ea\u7531\u80fd\u91cf\u6700\u5c0f\u5316\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u81ea\u4e3b\u63a7\u5236\u3002"}}
{"id": "2510.17463", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17463", "abs": "https://arxiv.org/abs/2510.17463", "authors": ["Cor Steging", "Tadeusz Zbiegie\u0144"], "title": "Label Indeterminacy in AI & Law", "comment": "This manuscript has been accepted for presentation as a short paper\n  at the 38th International Conference on Legal Knowledge and Information\n  Systems (JURIX) in Turin, December 9 to 11 of 2025", "summary": "Machine learning is increasingly used in the legal domain, where it typically\noperates retrospectively by treating past case outcomes as ground truth.\nHowever, legal outcomes are often shaped by human interventions that are not\ncaptured in most machine learning approaches. A final decision may result from\na settlement, an appeal, or other procedural actions. This creates label\nindeterminacy: the outcome could have been different if the intervention had or\nhad not taken place. We argue that legal machine learning applications need to\naccount for label indeterminacy. Methods exist that can impute these\nindeterminate labels, but they are all grounded in unverifiable assumptions. In\nthe context of classifying cases from the European Court of Human Rights, we\nshow that the way that labels are constructed during training can significantly\naffect model behaviour. We therefore position label indeterminacy as a relevant\nconcern in AI & Law and demonstrate how it can shape model behaviour.", "AI": {"tldr": "\u6cd5\u5f8b\u673a\u5668\u5b66\u4e60\u4e2d\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u7684\u7814\u7a76\uff1a\u6cd5\u5f8b\u6848\u4ef6\u7ed3\u679c\u53d7\u4eba\u4e3a\u5e72\u9884\u5f71\u54cd\uff0c\u5bfc\u81f4\u6807\u7b7e\u4e0d\u786e\u5b9a\uff0c\u5f71\u54cd\u6a21\u578b\u884c\u4e3a", "motivation": "\u6cd5\u5f8b\u673a\u5668\u5b66\u4e60\u901a\u5e38\u5c06\u8fc7\u53bb\u6848\u4ef6\u7ed3\u679c\u89c6\u4e3a\u771f\u5b9e\u6807\u7b7e\uff0c\u4f46\u6cd5\u5f8b\u7ed3\u679c\u5f80\u5f80\u53d7\u5230\u4eba\u4e3a\u5e72\u9884\uff08\u5982\u548c\u89e3\u3001\u4e0a\u8bc9\u7b49\uff09\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\uff0c\u9700\u8981\u5bf9\u6b64\u95ee\u9898\u8fdb\u884c\u7814\u7a76", "method": "\u5728\u6b27\u6d32\u4eba\u6743\u6cd5\u9662\u6848\u4ef6\u5206\u7c7b\u80cc\u666f\u4e0b\uff0c\u7814\u7a76\u4e0d\u540c\u6807\u7b7e\u6784\u5efa\u65b9\u5f0f\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u884c\u4e3a\uff0c\u4f7f\u7528\u73b0\u6709\u65b9\u6cd5\u5bf9\u4e0d\u786e\u5b9a\u6807\u7b7e\u8fdb\u884c\u4f30\u7b97", "result": "\u7814\u7a76\u8868\u660e\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6807\u7b7e\u7684\u6784\u5efa\u65b9\u5f0f\u4f1a\u663e\u8457\u5f71\u54cd\u6a21\u578b\u884c\u4e3a\uff0c\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\u662fAI\u4e0e\u6cd5\u5f8b\u9886\u57df\u7684\u91cd\u8981\u5173\u6ce8\u70b9", "conclusion": "\u6cd5\u5f8b\u673a\u5668\u5b66\u4e60\u5e94\u7528\u9700\u8981\u8003\u8651\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u867d\u7136\u5b58\u5728\u4f30\u7b97\u65b9\u6cd5\u4f46\u90fd\u57fa\u4e8e\u4e0d\u53ef\u9a8c\u8bc1\u7684\u5047\u8bbe\uff0c\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\u5e94\u88ab\u89c6\u4e3aAI\u4e0e\u6cd5\u5f8b\u9886\u57df\u7684\u91cd\u8981\u5173\u6ce8\u70b9"}}
{"id": "2510.17598", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17598", "abs": "https://arxiv.org/abs/2510.17598", "authors": ["Amir Jalilifard", "Anderson de Rezende Rocha", "Marcos Medeiros Raimundo"], "title": "Reasoning Distillation and Structural Alignment for Improved Code Generation", "comment": null, "summary": "Effective code generation with language models hinges on two critical\nfactors: accurately understanding the intent of the prompt and generating code\nthat applies algorithmic reasoning to produce correct solutions capable of\npassing diverse test cases while adhering to the syntax of the target\nprogramming language. Unlike other language tasks, code generation requires\nmore than accurate token prediction; it demands comprehension of solution-level\nand structural relationships rather than merely generating the most likely\ntokens. very large language model (VLLM) are capable of generating detailed\nsteps toward the correct solution of complex tasks where reasoning is crucial\nin solving the problem. Such reasoning capabilities may be absent in smaller\nlanguage models. Therefore, in this work, we distill the reasoning capabilities\nof a VLLM into a smaller, more efficient model that is faster and cheaper to\ndeploy. Our approach trains the model to emulate the reasoning and\nproblem-solving abilities of the VLLM by learning to identify correct solution\npathways and establishing a structural correspondence between problem\ndefinitions and potential solutions through a novel method of structure-aware\nloss optimization. This enables the model to transcend token-level generation\nand to deeply grasp the overarching structure of solutions for given problems.\nExperimental results show that our fine-tuned model, developed through a cheap\nand simple to implement process, significantly outperforms our baseline model\nin terms of pass@1, average data flow, and average syntax match metrics across\nthe MBPP, MBPP Plus, and HumanEval benchmarks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u84b8\u998f\u5230\u66f4\u5c0f\u3001\u66f4\u9ad8\u6548\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u635f\u5931\u4f18\u5316\u8bad\u7ec3\u5c0f\u6a21\u578b\u6a21\u62df\u5927\u6a21\u578b\u7684\u63a8\u7406\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002", "motivation": "\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0d\u4ec5\u9700\u8981\u51c6\u786e\u7684\u6807\u8bb0\u9884\u6d4b\uff0c\u66f4\u9700\u8981\u7406\u89e3\u89e3\u51b3\u65b9\u6848\u7ea7\u522b\u7684\u7ed3\u6784\u5173\u7cfb\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u5907\u590d\u6742\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u90e8\u7f72\u6210\u672c\u9ad8\uff1b\u5c0f\u6a21\u578b\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u3002\u56e0\u6b64\u9700\u8981\u5c06\u5927\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u84b8\u998f\u5230\u5c0f\u6a21\u578b\u4e2d\u3002", "method": "\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u635f\u5931\u4f18\u5316\u65b9\u6cd5\uff0c\u8bad\u7ec3\u5c0f\u6a21\u578b\u5b66\u4e60\u8bc6\u522b\u6b63\u786e\u89e3\u51b3\u65b9\u6848\u8def\u5f84\uff0c\u5efa\u7acb\u95ee\u9898\u5b9a\u4e49\u4e0e\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u4e4b\u95f4\u7684\u7ed3\u6784\u5bf9\u5e94\u5173\u7cfb\uff0c\u8d85\u8d8a\u6807\u8bb0\u7ea7\u751f\u6210\uff0c\u6df1\u5165\u7406\u89e3\u89e3\u51b3\u65b9\u6848\u7684\u6574\u4f53\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u7ecf\u8fc7\u5ec9\u4ef7\u4e14\u6613\u4e8e\u5b9e\u73b0\u7684\u8fc7\u7a0b\u5fae\u8c03\u7684\u6a21\u578b\uff0c\u5728MBPP\u3001MBPP Plus\u548cHumanEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728pass@1\u3001\u5e73\u5747\u6570\u636e\u6d41\u548c\u5e73\u5747\u8bed\u6cd5\u5339\u914d\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u84b8\u998f\u5230\u66f4\u5c0f\u3001\u66f4\u9ad8\u6548\u7684\u6a21\u578b\u4e2d\uff0c\u5b9e\u73b0\u4e86\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u964d\u4f4e\u90e8\u7f72\u6210\u672c\u7684\u76ee\u6807\u3002"}}
{"id": "2510.17638", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17638", "abs": "https://arxiv.org/abs/2510.17638", "authors": ["Qingchuan Yang", "Simon Mahns", "Sida Li", "Anri Gu", "Jibang Wu", "Haifeng Xu"], "title": "LLM-as-a-Prophet: Understanding Predictive Intelligence with Prophet Arena", "comment": "https://www.prophetarena.co/", "summary": "Forecasting is not only a fundamental intellectual pursuit but also is of\nsignificant importance to societal systems such as finance and economics. With\nthe rapid advances of large language models (LLMs) trained on Internet-scale\ndata, it raises the promise of employing LLMs to forecast real-world future\nevents, an emerging paradigm we call \"LLM-as-a-Prophet\". This paper\nsystematically investigates such predictive intelligence of LLMs. To this end,\nwe build Prophet Arena, a general evaluation benchmark that continuously\ncollects live forecasting tasks and decomposes each task into distinct pipeline\nstages, in order to support our controlled and large-scale experimentation. Our\ncomprehensive evaluation reveals that many LLMs already exhibit impressive\nforecasting capabilities, reflected in, e.g., their small calibration errors,\nconsistent prediction confidence and promising market returns. However, we also\nuncover key bottlenecks towards achieving superior predictive intelligence via\nLLM-as-a-Prophet, such as LLMs' inaccurate event recalls, misunderstanding of\ndata sources and slower information aggregation compared to markets when\nresolution nears.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u9884\u6d4b\u5de5\u5177\u7684\u80fd\u529b\uff0c\u6784\u5efa\u4e86Prophet Arena\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u53d1\u73b0LLMs\u5df2\u5177\u5907\u4e0d\u9519\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u4f46\u4e5f\u5b58\u5728\u4e8b\u4ef6\u53ec\u56de\u4e0d\u51c6\u786e\u3001\u6570\u636e\u6e90\u8bef\u89e3\u7b49\u5173\u952e\u74f6\u9888\u3002", "motivation": "\u968f\u7740\u5728\u4e92\u8054\u7f51\u89c4\u6a21\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5229\u7528LLMs\u9884\u6d4b\u73b0\u5b9e\u4e16\u754c\u672a\u6765\u4e8b\u4ef6\u5177\u6709\u91cd\u8981\u6f5c\u529b\uff0c\u8fd9\u79cd\u65b0\u5174\u8303\u5f0f\u88ab\u79f0\u4e3a\"LLM-as-a-Prophet\"\u3002", "method": "\u6784\u5efa\u4e86Prophet Arena\u8bc4\u4f30\u57fa\u51c6\uff0c\u6301\u7eed\u6536\u96c6\u5b9e\u65f6\u9884\u6d4b\u4efb\u52a1\uff0c\u5e76\u5c06\u6bcf\u4e2a\u4efb\u52a1\u5206\u89e3\u4e3a\u4e0d\u540c\u7684\u6d41\u6c34\u7ebf\u9636\u6bb5\uff0c\u4ee5\u652f\u6301\u53d7\u63a7\u548c\u5927\u89c4\u6a21\u5b9e\u9a8c\u3002", "result": "\u7efc\u5408\u8bc4\u4f30\u663e\u793a\uff0c\u8bb8\u591aLLMs\u5df2\u5c55\u73b0\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u8868\u73b0\u4e3a\u8f83\u5c0f\u7684\u6821\u51c6\u8bef\u5dee\u3001\u4e00\u81f4\u7684\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u548c\u6709\u524d\u666f\u7684\u5e02\u573a\u56de\u62a5\u3002", "conclusion": "\u867d\u7136LLMs\u5df2\u5177\u5907\u826f\u597d\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u4f46\u5b9e\u73b0\u5353\u8d8a\u9884\u6d4b\u667a\u80fd\u4ecd\u9762\u4e34\u5173\u952e\u74f6\u9888\uff0c\u5305\u62ec\u4e8b\u4ef6\u53ec\u56de\u4e0d\u51c6\u786e\u3001\u6570\u636e\u6e90\u8bef\u89e3\u4ee5\u53ca\u5728\u63a5\u8fd1\u51b3\u7b56\u65f6\u4fe1\u606f\u805a\u5408\u901f\u5ea6\u8f83\u5e02\u573a\u6162\u7b49\u95ee\u9898\u3002"}}
{"id": "2510.17697", "categories": ["cs.AI", "cs.LG", "cs.MA", "I.2.11; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.17697", "abs": "https://arxiv.org/abs/2510.17697", "authors": ["Anjie Liu", "Jianhong Wang", "Samuel Kaski", "Jun Wang", "Mengyue Yang"], "title": "A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning", "comment": "Accepted to NeurIPS 2025", "summary": "Steering cooperative multi-agent reinforcement learning (MARL) towards\ndesired outcomes is challenging, particularly when the global guidance from a\nhuman on the whole multi-agent system is impractical in a large-scale MARL. On\nthe other hand, designing mechanisms to coordinate agents most relies on\nempirical studies, lacking a easy-to-use research tool. In this work, we employ\nmulti-agent influence diagrams (MAIDs) as a graphical framework to address the\nabove issues. First, we introduce interaction paradigms that leverage MAIDs to\nanalyze and visualize existing approaches in MARL. Then, we design a new\ninteraction paradigm based on MAIDs, referred to as targeted intervention that\nis applied to only a single targeted agent, so the problem of global guidance\ncan be mitigated. In our implementation, we introduce a causal inference\ntechnique-referred to as Pre-Strategy Intervention (PSI)-to realize the\ntargeted intervention paradigm. Since MAIDs can be regarded as a special class\nof causal diagrams, a composite desired outcome that integrates the primary\ntask goal and an additional desired outcome can be achieved by maximizing the\ncorresponding causal effect through the PSI. Moreover, the bundled relevance\ngraph analysis of MAIDs provides a tool to identify whether an MARL learning\nparadigm is workable under the design of an interaction paradigm. In\nexperiments, we demonstrate the effectiveness of our proposed targeted\nintervention, and verify the result of relevance graph analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u5f71\u54cd\u56fe(MAIDs)\u4f5c\u4e3a\u56fe\u5f62\u6846\u67b6\u6765\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60(MARL)\u4e2d\u7684\u534f\u8c03\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e86\u57fa\u4e8eMAIDs\u7684\u5b9a\u5411\u5e72\u9884\u8303\u5f0f\uff0c\u901a\u8fc7\u56e0\u679c\u63a8\u65ad\u6280\u672fPSI\u5b9e\u73b0\uff0c\u53ef\u5728\u4ec5\u5e72\u9884\u5355\u4e2a\u667a\u80fd\u4f53\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u590d\u5408\u671f\u671b\u7ed3\u679c\u3002", "motivation": "\u5728\u5927\u89c4\u6a21MARL\u4e2d\uff0c\u5bf9\u6574\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u5168\u5c40\u6307\u5bfc\u4e0d\u5207\u5b9e\u9645\uff0c\u800c\u73b0\u6709\u7684\u534f\u8c03\u673a\u5236\u8bbe\u8ba1\u4e3b\u8981\u4f9d\u8d56\u7ecf\u9a8c\u7814\u7a76\uff0c\u7f3a\u4e4f\u6613\u7528\u7684\u7814\u7a76\u5de5\u5177\u3002", "method": "\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u5f71\u54cd\u56fe(MAIDs)\u4f5c\u4e3a\u5206\u6790\u6846\u67b6\uff0c\u63d0\u51fa\u5b9a\u5411\u5e72\u9884\u8303\u5f0f\uff0c\u5f15\u5165\u9884\u7b56\u7565\u5e72\u9884(PSI)\u56e0\u679c\u63a8\u65ad\u6280\u672f\uff0c\u901a\u8fc7\u6700\u5927\u5316\u56e0\u679c\u6548\u5e94\u6765\u5b9e\u73b0\u590d\u5408\u671f\u671b\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u5b9a\u5411\u5e72\u9884\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u76f8\u5173\u6027\u56fe\u5206\u6790\u7684\u7ed3\u679c\u3002", "conclusion": "MAIDs\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u56fe\u5f62\u6846\u67b6\u6765\u5206\u6790\u548c\u8bbe\u8ba1MARL\u4ea4\u4e92\u8303\u5f0f\uff0c\u5b9a\u5411\u5e72\u9884\u80fd\u591f\u7f13\u89e3\u5168\u5c40\u6307\u5bfc\u95ee\u9898\uff0cPSI\u6280\u672f\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u590d\u5408\u671f\u671b\u7ed3\u679c\u3002"}}
{"id": "2510.17705", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17705", "abs": "https://arxiv.org/abs/2510.17705", "authors": ["Dayan Pan", "Zhaoyang Fu", "Jingyuan Wang", "Xiao Han", "Yue Zhu", "Xiangyu Zhao"], "title": "Contextual Attention Modulation: Towards Efficient Multi-Task Adaptation in Large Language Models", "comment": "Accepted by CIKM' 25", "summary": "Large Language Models (LLMs) possess remarkable generalization capabilities\nbut struggle with multi-task adaptation, particularly in balancing knowledge\nretention with task-specific specialization. Conventional fine-tuning methods\nsuffer from catastrophic forgetting and substantial resource consumption, while\nexisting parameter-efficient methods perform suboptimally in complex multi-task\nscenarios. To address this, we propose Contextual Attention Modulation (CAM), a\nnovel mechanism that dynamically modulates the representations of\nself-attention modules in LLMs. CAM enhances task-specific features while\npreserving general knowledge, thereby facilitating more effective and efficient\nadaptation. For effective multi-task adaptation, CAM is integrated into our\nHybrid Contextual Attention Modulation (HyCAM) framework, which combines a\nshared, full-parameter CAM module with multiple specialized, lightweight CAM\nmodules, enhanced by a dynamic routing strategy for adaptive knowledge fusion.\nExtensive experiments on heterogeneous tasks, including question answering,\ncode generation, and logical reasoning, demonstrate that our approach\nsignificantly outperforms existing approaches, achieving an average performance\nimprovement of 3.65%. The implemented code and data are available to ease\nreproducibility at https://github.com/Applied-Machine-Learning-Lab/HyCAM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e0a\u4e0b\u6587\u6ce8\u610f\u529b\u8c03\u5236(CAM)\u673a\u5236\u548c\u6df7\u5408\u4e0a\u4e0b\u6587\u6ce8\u610f\u529b\u8c03\u5236(HyCAM)\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3LLMs\u5728\u591a\u4efb\u52a1\u9002\u5e94\u4e2d\u7684\u5e73\u8861\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u901a\u7528\u77e5\u8bc6\u7684\u540c\u65f6\u589e\u5f3a\u4efb\u52a1\u7279\u5b9a\u7279\u5f81\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4efb\u52a1\u9002\u5e94\u4e2d\u96be\u4ee5\u5e73\u8861\u77e5\u8bc6\u4fdd\u7559\u548c\u4efb\u52a1\u7279\u5b9a\u4e13\u4e1a\u5316\uff0c\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u548c\u8d44\u6e90\u6d88\u8017\u95ee\u9898\uff0c\u73b0\u6709\u53c2\u6570\u9ad8\u6548\u65b9\u6cd5\u5728\u590d\u6742\u591a\u4efb\u52a1\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e0a\u4e0b\u6587\u6ce8\u610f\u529b\u8c03\u5236(CAM)\u673a\u5236\u52a8\u6001\u8c03\u8282\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u8868\u793a\uff0c\u5e76\u7ed3\u5408HyCAM\u6846\u67b6\uff0c\u5c06\u5171\u4eab\u7684\u5168\u53c2\u6570CAM\u6a21\u5757\u4e0e\u591a\u4e2a\u8f7b\u91cf\u7ea7\u4e13\u7528CAM\u6a21\u5757\u7ed3\u5408\uff0c\u91c7\u7528\u52a8\u6001\u8def\u7531\u7b56\u7565\u8fdb\u884c\u81ea\u9002\u5e94\u77e5\u8bc6\u878d\u5408\u3002", "result": "\u5728\u95ee\u7b54\u3001\u4ee3\u7801\u751f\u6210\u548c\u903b\u8f91\u63a8\u7406\u7b49\u5f02\u6784\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e73\u5747\u6027\u80fd\u63d0\u53473.65%\u3002", "conclusion": "CAM\u548cHyCAM\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86LLMs\u5728\u591a\u4efb\u52a1\u9002\u5e94\u4e2d\u7684\u6311\u6218\uff0c\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2510.17771", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17771", "abs": "https://arxiv.org/abs/2510.17771", "authors": ["Zhining Liu", "Ziyi Chen", "Hui Liu", "Chen Luo", "Xianfeng Tang", "Suhang Wang", "Joy Zeng", "Zhenwei Dai", "Zhan Shi", "Tianxin Wei", "Benoit Dumoulin", "Hanghang Tong"], "title": "Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs", "comment": "21 pages, 10 figures, 6 tables", "summary": "Vision-Language Models (VLMs) achieve strong results on multimodal tasks such\nas visual question answering, yet they can still fail even when the correct\nvisual evidence is present. In this work, we systematically investigate whether\nthese failures arise from not perceiving the evidence or from not leveraging it\neffectively. By examining layer-wise attention dynamics, we find that shallow\nlayers focus primarily on text, while deeper layers sparsely but reliably\nattend to localized evidence regions. Surprisingly, VLMs often perceive the\nvisual evidence when outputting incorrect answers, a phenomenon we term\n``seeing but not believing'' that widely exists in major VLM families. Building\non this, we introduce an inference-time intervention that highlights deep-layer\nevidence regions through selective attention-based masking. It requires no\ntraining and consistently improves accuracy across multiple families, including\nLLaVA, Qwen, Gemma, and InternVL. These results show that VLMs encode reliable\nevidence internally but under-utilize it, making such signals explicit can\nbridge the gap between perception and reasoning, advancing the diagnostic\nunderstanding and reliability of VLMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53d1\u73b0\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLMs)\u5728\u8f93\u51fa\u9519\u8bef\u7b54\u6848\u65f6\u4ecd\u80fd\u611f\u77e5\u5230\u6b63\u786e\u7684\u89c6\u89c9\u8bc1\u636e\uff0c\u8fd9\u79cd\u73b0\u8c61\u79f0\u4e3a\"\u770b\u89c1\u4f46\u4e0d\u76f8\u4fe1\"\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u63a8\u7406\u65f6\u5e72\u9884\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u6ce8\u610f\u529b\u63a9\u7801\u6765\u7a81\u51fa\u6df1\u5c42\u8bc1\u636e\u533a\u57df\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u591a\u4e2aVLM\u5bb6\u65cf\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5c3d\u7ba1\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u4ecd\u7136\u4f1a\u5728\u6b63\u786e\u7684\u89c6\u89c9\u8bc1\u636e\u5b58\u5728\u65f6\u5931\u8d25\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u6027\u5730\u8c03\u67e5\u8fd9\u4e9b\u5931\u8d25\u662f\u7531\u4e8e\u672a\u80fd\u611f\u77e5\u8bc1\u636e\u8fd8\u662f\u672a\u80fd\u6709\u6548\u5229\u7528\u8bc1\u636e\u3002", "method": "\u901a\u8fc7\u68c0\u67e5\u9010\u5c42\u6ce8\u610f\u529b\u52a8\u6001\uff0c\u53d1\u73b0\u6d45\u5c42\u4e3b\u8981\u5173\u6ce8\u6587\u672c\uff0c\u800c\u6df1\u5c42\u7a00\u758f\u4f46\u53ef\u9760\u5730\u5173\u6ce8\u5c40\u90e8\u8bc1\u636e\u533a\u57df\u3002\u57fa\u4e8e\u6b64\uff0c\u5f15\u5165\u4e86\u4e00\u79cd\u63a8\u7406\u65f6\u5e72\u9884\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u6ce8\u610f\u529b\u63a9\u7801\u6765\u7a81\u51fa\u6df1\u5c42\u8bc1\u636e\u533a\u57df\u3002", "result": "\u7814\u7a76\u53d1\u73b0VLMs\u5728\u8f93\u51fa\u9519\u8bef\u7b54\u6848\u65f6\u4ecd\u80fd\u611f\u77e5\u89c6\u89c9\u8bc1\u636e\uff0c\u8fd9\u79cd\u73b0\u8c61\u5e7f\u6cdb\u5b58\u5728\u4e8e\u4e3b\u8981VLM\u5bb6\u65cf\u4e2d\u3002\u63d0\u51fa\u7684\u5e72\u9884\u65b9\u6cd5\u65e0\u9700\u8bad\u7ec3\uff0c\u5728LLaVA\u3001Qwen\u3001Gemma\u548cInternVL\u7b49\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\u4e2d\u4e00\u81f4\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "VLMs\u5728\u5185\u90e8\u7f16\u7801\u4e86\u53ef\u9760\u7684\u8bc1\u636e\u4f46\u672a\u5145\u5206\u5229\u7528\uff0c\u4f7f\u8fd9\u4e9b\u4fe1\u53f7\u663e\u5f0f\u5316\u53ef\u4ee5\u5f25\u5408\u611f\u77e5\u4e0e\u63a8\u7406\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63a8\u8fdb\u5bf9VLM\u7684\u8bca\u65ad\u7406\u89e3\u548c\u53ef\u9760\u6027\u3002"}}

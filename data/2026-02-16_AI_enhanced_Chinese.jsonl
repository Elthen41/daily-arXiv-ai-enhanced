{"id": "2602.12295", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.12295", "abs": "https://arxiv.org/abs/2602.12295", "authors": ["R. Kanda", "N. Onizawa", "M. Leonardon", "V. Gripon", "T. Hanyu"], "title": "Design Environment of Quantization-Aware Edge AI Hardware for Few-Shot Learning", "comment": null, "summary": "This study aims to ensure consistency in accuracy throughout the entire design flow in the implementation of edge AI hardware for few-shot learning, by implementing fixed-point data processing in the pre-training and evaluation phases. Specifically, the quantization module, called Brevitas, is applied to implement fixed-point data processing, which allows for arbitrary specification of the bit widths for the integer and fractional parts. Two methods of fixed-point data quantization, quantization-aware training (QAT) and post-training quantization (PTQ), are utilized in Brevitas. With Tensil, which is used in the current design flow, the bit widths of the integer and fractional parts need to be 8 bits each or 16 bits each when implemented in hardware, but performance validation has shown that accuracy comparable to floating-point operations can be maintained even with 6 bits or 5 bits each, indicating potential for further reduction in computational resources. These results clearly contribute to the creation of a versatile design and evaluation environment for edge AI hardware for few-shot learning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5728\u8fb9\u7f18AI\u786c\u4ef6\u7684\u9884\u8bad\u7ec3\u548c\u8bc4\u4f30\u9636\u6bb5\u5b9e\u73b0\u5b9a\u70b9\u6570\u636e\u5904\u7406\uff0c\u786e\u4fddfew-shot\u5b66\u4e60\u5728\u6574\u4e2a\u8bbe\u8ba1\u6d41\u7a0b\u4e2d\u7684\u7cbe\u5ea6\u4e00\u81f4\u6027\uff0c\u4f7f\u7528Brevitas\u91cf\u5316\u6a21\u5757\u5b9e\u73b0\u53ef\u5b9a\u5236\u7684\u6574\u6570\u548c\u5c0f\u6570\u4f4d\u5bbd\uff0c\u9a8c\u8bc1\u4e86\u5728\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u7684\u540c\u65f6\u4fdd\u6301\u4e0e\u6d6e\u70b9\u8fd0\u7b97\u76f8\u5f53\u7684\u7cbe\u5ea6\u3002", "motivation": "\u786e\u4fdd\u5728\u5b9e\u73b0few-shot\u5b66\u4e60\u7684\u8fb9\u7f18AI\u786c\u4ef6\u65f6\uff0c\u6574\u4e2a\u8bbe\u8ba1\u6d41\u7a0b\u4e2d\u7684\u7cbe\u5ea6\u4e00\u81f4\u6027\uff0c\u7279\u522b\u662f\u5728\u9884\u8bad\u7ec3\u548c\u8bc4\u4f30\u9636\u6bb5\u3002", "method": "\u4f7f\u7528Brevitas\u91cf\u5316\u6a21\u5757\u5b9e\u73b0\u5b9a\u70b9\u6570\u636e\u5904\u7406\uff0c\u652f\u6301\u4efb\u610f\u6307\u5b9a\u6574\u6570\u548c\u5c0f\u6570\u90e8\u5206\u7684\u4f4d\u5bbd\u3002\u91c7\u7528\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\uff08QAT\uff09\u548c\u540e\u8bad\u7ec3\u91cf\u5316\uff08PTQ\uff09\u4e24\u79cd\u65b9\u6cd5\u3002\u4e0e\u5f53\u524d\u8bbe\u8ba1\u6d41\u7a0b\u4e2d\u4f7f\u7528\u7684Tensil\u5de5\u5177\uff08\u8981\u6c428\u4f4d\u621616\u4f4d\u4f4d\u5bbd\uff09\u8fdb\u884c\u5bf9\u6bd4\u9a8c\u8bc1\u3002", "result": "\u6027\u80fd\u9a8c\u8bc1\u8868\u660e\uff0c\u5373\u4f7f\u4f7f\u75286\u4f4d\u62165\u4f4d\u7684\u6574\u6570\u548c\u5c0f\u6570\u90e8\u5206\uff0c\u4e5f\u80fd\u4fdd\u6301\u4e0e\u6d6e\u70b9\u8fd0\u7b97\u76f8\u5f53\u7684\u7cbe\u5ea6\uff0c\u8fd9\u663e\u793a\u4e86\u8fdb\u4e00\u6b65\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u7684\u6f5c\u529b\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u660e\u663e\u6709\u52a9\u4e8e\u4e3afew-shot\u5b66\u4e60\u7684\u8fb9\u7f18AI\u786c\u4ef6\u521b\u5efa\u4e00\u4e2a\u901a\u7528\u7684\u8bbe\u8ba1\u548c\u8bc4\u4f30\u73af\u5883\uff0c\u901a\u8fc7\u5b9a\u70b9\u6570\u636e\u5904\u7406\u5b9e\u73b0\u7cbe\u5ea6\u4e00\u81f4\u6027\u5e76\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u3002"}}
{"id": "2602.12422", "categories": ["cs.AR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.12422", "abs": "https://arxiv.org/abs/2602.12422", "authors": ["Kaushal Mhapsekar", "Azam Ghanbari", "Bita Aslrousta", "Samira Mirbagher-Ajorpaz"], "title": "CacheMind: From Miss Rates to Why -- Natural-Language, Trace-Grounded Reasoning for Cache Replacement", "comment": "16 pages, 13 figures, ASPLOS 2026", "summary": "Cache replacement remains a challenging problem in CPU microarchitecture, often addressed using hand-crafted heuristics, limiting cache performance. Cache data analysis requires parsing millions of trace entries with manual filtering, making the process slow and non-interactive. To address this, we introduce CacheMind, a conversational tool that uses Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs) to enable semantic reasoning over cache traces. Architects can now ask natural language questions like, \"Why is the memory access associated with PC X causing more evictions?\", and receive trace-grounded, human-readable answers linked to program semantics for the first time. To evaluate CacheMind, we present CacheMindBench, the first verified benchmark suite for LLM-based reasoning for the cache replacement problem. Using the SIEVE retriever, CacheMind achieves 66.67% on 75 unseen trace-grounded questions and 84.80% on 25 unseen policy-specific reasoning tasks; with RANGER, it achieves 89.33% and 64.80% on the same evaluations. Additionally, with RANGER, CacheMind achieves 100% accuracy on 4 out of 6 categories in the trace-grounded tier of CacheMindBench. Compared to LlamaIndex (10% retrieval success), SIEVE achieves 60% and RANGER achieves 90%, demonstrating that existing Retrieval-Augmented Generation (RAGs) are insufficient for precise, trace-grounded microarchitectural reasoning. We provided four concrete actionable insights derived using CacheMind, wherein bypassing use case improved cache hit rate by 7.66% and speedup by 2.04%, software fix use case gives speedup of 76%, and Mockingjay replacement policy use case gives speedup of 0.7%; showing the utility of CacheMind on non-trivial queries that require a natural-language interface.", "AI": {"tldr": "CacheMind\u662f\u4e00\u4e2a\u57fa\u4e8eRAG\u548cLLM\u7684\u5bf9\u8bdd\u5de5\u5177\uff0c\u7528\u4e8e\u5bf9\u7f13\u5b58\u8ddf\u8e2a\u6570\u636e\u8fdb\u884c\u8bed\u4e49\u63a8\u7406\uff0c\u5e2e\u52a9\u67b6\u6784\u5e08\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u95ee\u5206\u6790\u7f13\u5b58\u6027\u80fd\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u7f13\u5b58\u66ff\u6362\u4f9d\u8d56\u4e8e\u624b\u5de5\u8bbe\u8ba1\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u9650\u5236\u4e86\u7f13\u5b58\u6027\u80fd\u3002\u7f13\u5b58\u6570\u636e\u5206\u6790\u9700\u8981\u89e3\u6790\u6570\u767e\u4e07\u6761\u8ddf\u8e2a\u8bb0\u5f55\u5e76\u8fdb\u884c\u624b\u52a8\u8fc7\u6ee4\uff0c\u8fc7\u7a0b\u7f13\u6162\u4e14\u975e\u4ea4\u4e92\u5f0f\u3002", "method": "\u5f00\u53d1\u4e86CacheMind\u5de5\u5177\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u5b9e\u73b0\u5bf9\u7f13\u5b58\u8ddf\u8e2a\u6570\u636e\u7684\u8bed\u4e49\u63a8\u7406\u3002\u8fd8\u521b\u5efa\u4e86CacheMindBench\u57fa\u51c6\u5957\u4ef6\u6765\u8bc4\u4f30LLM\u5728\u7f13\u5b58\u66ff\u6362\u95ee\u9898\u4e0a\u7684\u63a8\u7406\u80fd\u529b\u3002", "result": "\u4f7f\u7528SIEVE\u68c0\u7d22\u5668\u65f6\uff0cCacheMind\u572875\u4e2a\u672a\u89c1\u8fc7\u7684\u8ddf\u8e2a\u57fa\u7840\u95ee\u9898\u4e0a\u8fbe\u523066.67%\u51c6\u786e\u7387\uff0c\u572825\u4e2a\u7b56\u7565\u7279\u5b9a\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u523084.80%\uff1b\u4f7f\u7528RANGER\u65f6\u5206\u522b\u8fbe\u523089.33%\u548c64.80%\u3002RANGER\u5728CacheMindBench\u76846\u4e2a\u7c7b\u522b\u4e2d\u67094\u4e2a\u8fbe\u5230100%\u51c6\u786e\u7387\u3002\u76f8\u6bd4LlamaIndex\uff0810%\u68c0\u7d22\u6210\u529f\u7387\uff09\uff0cSIEVE\u8fbe\u523060%\uff0cRANGER\u8fbe\u523090%\u3002", "conclusion": "CacheMind\u4e3a\u7f13\u5b58\u5206\u6790\u63d0\u4f9b\u4e86\u9996\u4e2a\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\uff0c\u80fd\u591f\u4ece\u7f13\u5b58\u8ddf\u8e2a\u6570\u636e\u4e2d\u63d0\u53d6\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u5982\u7ed5\u8fc7\u7528\u4f8b\u63d0\u9ad8\u7f13\u5b58\u547d\u4e2d\u73877.66%\u548c\u901f\u5ea6\u63d0\u53472.04%\uff0c\u8f6f\u4ef6\u4fee\u590d\u7528\u4f8b\u63d0\u4f9b76%\u901f\u5ea6\u63d0\u5347\uff0cMockingjay\u66ff\u6362\u7b56\u7565\u7528\u4f8b\u63d0\u4f9b0.7%\u901f\u5ea6\u63d0\u5347\u3002"}}
{"id": "2602.12480", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.12480", "abs": "https://arxiv.org/abs/2602.12480", "authors": ["George Karfakis", "Samyak Chakrabarty", "Vinod Kurian Jacob", "Siyun Qiao", "Subramanian S. Iyer", "Sudhakar Pamarti", "Puneet Gupta"], "title": "MXFormer: A Microscaling Floating-Point Charge-Trap Transistor Compute-in-Memory Transformer Accelerator", "comment": null, "summary": "The proliferation of Transformer models is often constrained by the significant computational and memory bandwidth demands of deployment. To address this, we present MXFormer, a novel, hybrid, weight-stationary Compute-in-Memory (CIM) accelerator that provides high throughput and efficiency for fixed-model inference on large short-sequence Transformers. Our architecture's foundation is the use of ultra-dense Charge-Trap Transistors (CTTs) in Microscaling MXFP4 CIM arrays, uniquely enabling the on-chip storage of up to hundreds of millions of parameters in Fully Weight Stationary (FWS) fashion.\n  We introduce a statically partitioned design with 12 Transformer blocks connected by a deeply pipelined dataflow. Static-weight layers (MLPs and linear projections) execute on highly parallel analog CTT arrays using an MXFP4-native flow with per-block exponent alignment and a 10-bit SAR ADC. Dynamic computations are handled in fully accurate digital blocks that utilize MXFP-enabled systolic arrays for scaled dot-product attention and vector units for LayerNorm and FlashAttention-style Softmax.\n  By eliminating all weight movement, the deeply pipelined MXFormer architecture yields very high single-stream throughput and efficiency, processing 58275 FPS on ViT-L/32 (dual-chip) or 41269 FPS on ViT-B/16 (single chip). MXFormer outperforms comparable state-of-the-art non-FWS digital, hybrid and photonic Transformer accelerators ~3.3x-60.5x in compute density and ~1.7x-2.5x in energy efficiency. Against FWS accelerators, MXFormer improves compute density by ~20.9x and resident weight storage density by ~2x, while preserving near-digital accuracy (drop of <1%) without any model retraining.", "AI": {"tldr": "MXFormer\u662f\u4e00\u79cd\u65b0\u578b\u6df7\u5408\u6743\u91cd\u9a7b\u7559\u8ba1\u7b97\u5185\u5b58\u52a0\u901f\u5668\uff0c\u4e13\u4e3a\u5927\u578b\u77ed\u5e8f\u5217Transformer\u7684\u56fa\u5b9a\u6a21\u578b\u63a8\u7406\u8bbe\u8ba1\uff0c\u901a\u8fc7\u6d88\u9664\u6743\u91cd\u79fb\u52a8\u5b9e\u73b0\u9ad8\u541e\u5410\u548c\u9ad8\u6548\u7387\u3002", "motivation": "Transformer\u6a21\u578b\u90e8\u7f72\u53d7\u5230\u8ba1\u7b97\u548c\u5185\u5b58\u5e26\u5bbd\u9700\u6c42\u7684\u4e25\u91cd\u9650\u5236\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u63a8\u7406\u52a0\u901f\u65b9\u6848\u3002", "method": "\u91c7\u7528\u8d85\u5bc6\u96c6\u7535\u8377\u9677\u9631\u6676\u4f53\u7ba1\u6784\u5efaMXFP4 CIM\u9635\u5217\uff0c\u5b9e\u73b0\u5b8c\u5168\u6743\u91cd\u9a7b\u7559\uff1b\u9759\u6001\u5206\u533a\u8bbe\u8ba1\u5305\u542b12\u4e2aTransformer\u5757\uff0c\u9759\u6001\u6743\u91cd\u5c42\u5728\u6a21\u62dfCTT\u9635\u5217\u6267\u884c\uff0c\u52a8\u6001\u8ba1\u7b97\u5728\u6570\u5b57\u5757\u5904\u7406\u3002", "result": "MXFormer\u5904\u7406ViT-L/32\u8fbe\u523058275 FPS\uff08\u53cc\u82af\u7247\uff09\uff0cViT-B/16\u8fbe\u523041269 FPS\uff08\u5355\u82af\u7247\uff09\uff1b\u8ba1\u7b97\u5bc6\u5ea6\u6bd4\u975eFWS\u52a0\u901f\u5668\u9ad83.3-60.5\u500d\uff0c\u80fd\u6548\u9ad81.7-2.5\u500d\uff1b\u76f8\u6bd4FWS\u52a0\u901f\u5668\uff0c\u8ba1\u7b97\u5bc6\u5ea6\u63d0\u9ad820.9\u500d\uff0c\u6743\u91cd\u5b58\u50a8\u5bc6\u5ea6\u63d0\u9ad82\u500d\uff0c\u7cbe\u5ea6\u635f\u5931\u5c0f\u4e8e1%\u3002", "conclusion": "MXFormer\u901a\u8fc7\u5b8c\u5168\u6743\u91cd\u9a7b\u7559\u548c\u6df1\u5ea6\u6d41\u6c34\u7ebf\u8bbe\u8ba1\uff0c\u4e3a\u5927\u578bTransformer\u63a8\u7406\u63d0\u4f9b\u4e86\u9ad8\u541e\u5410\u3001\u9ad8\u6548\u7387\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u6a21\u578b\u91cd\u8bad\u7ec3\u5373\u53ef\u4fdd\u6301\u63a5\u8fd1\u6570\u5b57\u7cbe\u5ea6\u3002"}}
{"id": "2602.12398", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.12398", "abs": "https://arxiv.org/abs/2602.12398", "authors": ["Paul Keeler", "Ben Smyth"], "title": "Secrecy and Verifiability: An Introduction to Electronic Voting", "comment": "67 pages, 10 figures. Tutorial on cryptographic foundations of electronic voting", "summary": "Democracies are built upon secure and reliable voting systems. Electronic voting systems seek to replace ballot papers and boxes with computer hardware and software. Proposed electronic election schemes have been subjected to scrutiny, with researchers spotting inherent faults and weaknesses. Inspired by physical voting systems, we argue that any electronic voting system needs two essential properties: ballot secrecy and verifiability. These properties seemingly work against each other. An election scheme that is a complete black box offers ballot secrecy, but verification of the outcome is impossible. This challenge can be tackled using standard tools from modern cryptography, reaching a balance that delivers both properties.\n  This tutorial makes these ideas accessible to readers outside electronic voting. We introduce fundamental concepts such as asymmetric and homomorphic encryption, which we use to describe a general electronic election scheme while keeping mathematical formalism minimal. We outline game-based cryptography, a standard approach in modern cryptography, and introduce notation for formulating elections as games. We then give precise definitions of ballot secrecy and verifiability in the framework of game-based cryptography. A principal aim is introducing modern research approaches to electronic voting.", "AI": {"tldr": "\u8fd9\u7bc7\u6559\u7a0b\u8bba\u6587\u5411\u975e\u7535\u5b50\u6295\u7968\u9886\u57df\u7684\u8bfb\u8005\u4ecb\u7ecd\u4e86\u73b0\u4ee3\u5bc6\u7801\u5b66\u5728\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u9610\u8ff0\u4e86\u5982\u4f55\u901a\u8fc7\u975e\u5bf9\u79f0\u52a0\u5bc6\u548c\u540c\u6001\u52a0\u5bc6\u7b49\u6280\u672f\uff0c\u5728\u4fdd\u8bc1\u9009\u7968\u4fdd\u5bc6\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u9009\u4e3e\u7ed3\u679c\u7684\u53ef\u9a8c\u8bc1\u6027\u3002", "motivation": "\u6c11\u4e3b\u5236\u5ea6\u4f9d\u8d56\u4e8e\u5b89\u5168\u53ef\u9760\u7684\u6295\u7968\u7cfb\u7edf\u3002\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u8bd5\u56fe\u7528\u8ba1\u7b97\u673a\u786c\u4ef6\u548c\u8f6f\u4ef6\u66ff\u4ee3\u7eb8\u8d28\u9009\u7968\u548c\u6295\u7968\u7bb1\uff0c\u4f46\u73b0\u6709\u7684\u7535\u5b50\u9009\u4e3e\u65b9\u6848\u5b58\u5728\u56fa\u6709\u7f3a\u9677\u548c\u5f31\u70b9\u3002\u53d7\u5230\u7269\u7406\u6295\u7968\u7cfb\u7edf\u7684\u542f\u53d1\uff0c\u4f5c\u8005\u8ba4\u4e3a\u4efb\u4f55\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u90fd\u9700\u8981\u4e24\u4e2a\u57fa\u672c\u5c5e\u6027\uff1a\u9009\u7968\u4fdd\u5bc6\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\uff0c\u8fd9\u4e24\u4e2a\u5c5e\u6027\u770b\u4f3c\u76f8\u4e92\u77db\u76fe\u3002", "method": "\u4f7f\u7528\u73b0\u4ee3\u5bc6\u7801\u5b66\u7684\u6807\u51c6\u5de5\u5177\uff0c\u5305\u62ec\u975e\u5bf9\u79f0\u52a0\u5bc6\u548c\u540c\u6001\u52a0\u5bc6\u6280\u672f\uff0c\u6784\u5efa\u4e00\u4e2a\u901a\u7528\u7684\u7535\u5b50\u9009\u4e3e\u65b9\u6848\u3002\u91c7\u7528\u57fa\u4e8e\u535a\u5f08\u7684\u5bc6\u7801\u5b66\u65b9\u6cd5\uff0c\u5c06\u9009\u4e3e\u5f62\u5f0f\u5316\u4e3a\u535a\u5f08\uff0c\u5e76\u5728\u6b64\u6846\u67b6\u4e0b\u7ed9\u51fa\u9009\u7968\u4fdd\u5bc6\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u7684\u7cbe\u786e\u5b9a\u4e49\u3002", "result": "\u901a\u8fc7\u5bc6\u7801\u5b66\u6280\u672f\u5b9e\u73b0\u4e86\u9009\u7968\u4fdd\u5bc6\u6027\u548c\u9009\u4e3e\u7ed3\u679c\u53ef\u9a8c\u8bc1\u6027\u4e4b\u95f4\u7684\u5e73\u8861\uff0c\u4f7f\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u65e2\u80fd\u4fdd\u62a4\u6295\u7968\u9690\u79c1\uff0c\u53c8\u80fd\u9a8c\u8bc1\u9009\u4e3e\u7ed3\u679c\u7684\u6b63\u786e\u6027\u3002", "conclusion": "\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u53ef\u4ee5\u901a\u8fc7\u73b0\u4ee3\u5bc6\u7801\u5b66\u5de5\u5177\u5b9e\u73b0\u9009\u7968\u4fdd\u5bc6\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u7684\u53cc\u91cd\u76ee\u6807\u3002\u8fd9\u7bc7\u6559\u7a0b\u65e8\u5728\u5411\u7535\u5b50\u6295\u7968\u9886\u57df\u5916\u7684\u8bfb\u8005\u4ecb\u7ecd\u73b0\u4ee3\u7814\u7a76\u65b9\u6cd5\uff0c\u4f7f\u8fd9\u4e9b\u590d\u6742\u6982\u5ff5\u66f4\u6613\u4e8e\u7406\u89e3\u3002"}}
{"id": "2602.13046", "categories": ["cs.DC", "cs.CC", "cs.FL"], "pdf": "https://arxiv.org/pdf/2602.13046", "abs": "https://arxiv.org/abs/2602.13046", "authors": ["Thomas Boudier", "Fabian Kuhn", "Augusto Modanese", "Ronja Stimpert", "Jukka Suomela"], "title": "Classification of Local Optimization Problems in Directed Cycles", "comment": "26 pages, 2 figures", "summary": "We present a complete classification of the distributed computational complexity of local optimization problems in directed cycles for both the deterministic and the randomized LOCAL model. We show that for any local optimization problem $\u03a0$ (that can be of the form min-sum, max-sum, min-max, or max-min, for any local cost or utility function over some finite alphabet), and for any \\emph{constant} approximation ratio $\u03b1$, the task of finding an $\u03b1$-approximation of $\u03a0$ in directed cycles has one of the following complexities:\n  1. $O(1)$ rounds in deterministic LOCAL, $O(1)$ rounds in randomized LOCAL,\n  2. $\u0398(\\log^* n)$ rounds in deterministic LOCAL, $O(1)$ rounds in randomized LOCAL,\n  3. $\u0398(\\log^* n)$ rounds in deterministic LOCAL, $\u0398(\\log^* n)$ rounds in randomized LOCAL,\n  4. $\u0398(n)$ rounds in deterministic LOCAL, $\u0398(n)$ rounds in randomized LOCAL.\n  Moreover, for any given $\u03a0$ and $\u03b1$, we can determine the complexity class automatically, with an efficient (centralized, sequential) meta-algorithm, and we can also efficiently synthesize an asymptotically optimal distributed algorithm.\n  Before this work, similar results were only known for local search problems (e.g., locally checkable labeling problems). The family of local optimization problems is a strict generalization of local search problems, and it contains numerous commonly studied distributed tasks, such as the problems of finding approximations of the maximum independent set, minimum vertex cover, minimum dominating set, and minimum vertex coloring.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9\u5b9a\u5411\u73af\u4e2d\u5c40\u90e8\u4f18\u5316\u95ee\u9898\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u590d\u6742\u5ea6\u8fdb\u884c\u4e86\u5b8c\u6574\u5206\u7c7b\uff0c\u786e\u5b9a\u4e86\u56db\u79cd\u53ef\u80fd\u7684\u590d\u6742\u5ea6\u7c7b\u522b\uff0c\u5e76\u63d0\u4f9b\u4e86\u81ea\u52a8\u786e\u5b9a\u590d\u6742\u5ea6\u548c\u5408\u6210\u6700\u4f18\u5206\u5e03\u5f0f\u7b97\u6cd5\u7684\u5143\u7b97\u6cd5\u3002", "motivation": "\u5c40\u90e8\u4f18\u5316\u95ee\u9898\uff08\u5982\u6700\u5927\u72ec\u7acb\u96c6\u3001\u6700\u5c0f\u9876\u70b9\u8986\u76d6\u7b49\uff09\u662f\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u91cd\u8981\u95ee\u9898\uff0c\u4f46\u4e4b\u524d\u7684\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5c40\u90e8\u641c\u7d22\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u5bf9\u66f4\u4e00\u822c\u7684\u5c40\u90e8\u4f18\u5316\u95ee\u9898\u5728\u5b9a\u5411\u73af\u4e2d\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u8fdb\u884c\u7cfb\u7edf\u5206\u7c7b\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e86\u5b9a\u5411\u73af\u4e2d\u5c40\u90e8\u4f18\u5316\u95ee\u9898\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u8003\u8651\u4e86\u786e\u5b9a\u6027LOCAL\u548c\u968f\u673a\u5316LOCAL\u6a21\u578b\uff0c\u6db5\u76d6\u4e86min-sum\u3001max-sum\u3001min-max\u3001max-min\u7b49\u5f62\u5f0f\u7684\u4f18\u5316\u95ee\u9898\u3002\u5f00\u53d1\u4e86\u81ea\u52a8\u786e\u5b9a\u590d\u6742\u5ea6\u7c7b\u548c\u5408\u6210\u6700\u4f18\u5206\u5e03\u5f0f\u7b97\u6cd5\u7684\u5143\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u4efb\u4f55\u5c40\u90e8\u4f18\u5316\u95ee\u9898\u548c\u4efb\u4f55\u5e38\u6570\u8fd1\u4f3c\u6bd4\u03b1\uff0c\u5728\u5b9a\u5411\u73af\u4e2d\u6c42\u03b1-\u8fd1\u4f3c\u89e3\u53ea\u6709\u56db\u79cd\u53ef\u80fd\u7684\u590d\u6742\u5ea6\uff1a1) O(1)\u8f6e\u786e\u5b9a\u6027\uff0cO(1)\u8f6e\u968f\u673a\u5316\uff1b2) \u0398(log* n)\u8f6e\u786e\u5b9a\u6027\uff0cO(1)\u8f6e\u968f\u673a\u5316\uff1b3) \u0398(log* n)\u8f6e\u786e\u5b9a\u6027\uff0c\u0398(log* n)\u8f6e\u968f\u673a\u5316\uff1b4) \u0398(n)\u8f6e\u786e\u5b9a\u6027\uff0c\u0398(n)\u8f6e\u968f\u673a\u5316\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u5bf9\u5b9a\u5411\u73af\u4e2d\u5c40\u90e8\u4f18\u5316\u95ee\u9898\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u590d\u6742\u5ea6\u8fdb\u884c\u4e86\u5b8c\u6574\u5206\u7c7b\uff0c\u6269\u5c55\u4e86\u4e4b\u524d\u4ec5\u9488\u5bf9\u5c40\u90e8\u641c\u7d22\u95ee\u9898\u7684\u7ed3\u679c\uff0c\u4e3a\u5206\u5e03\u5f0f\u4f18\u5316\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.12418", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.12418", "abs": "https://arxiv.org/abs/2602.12418", "authors": ["Yannick Assogba", "Jacopo Cortellazzi", "Javier Abad", "Pau Rodriguez", "Xavier Suau", "Arno Blaas"], "title": "Sparse Autoencoders are Capable LLM Jailbreak Mitigators", "comment": "26 pages, 14 figures, 3 tables", "summary": "Jailbreak attacks remain a persistent threat to large language model safety. We propose Context-Conditioned Delta Steering (CC-Delta), an SAE-based defense that identifies jailbreak-relevant sparse features by comparing token-level representations of the same harmful request with and without jailbreak context. Using paired harmful/jailbreak prompts, CC-Delta selects features via statistical testing and applies inference-time mean-shift steering in SAE latent space. Across four aligned instruction-tuned models and twelve jailbreak attacks, CC-Delta achieves comparable or better safety-utility tradeoffs than baseline defenses operating in dense latent space. In particular, our method clearly outperforms dense mean-shift steering on all four models, and particularly against out-of-distribution attacks, showing that steering in sparse SAE feature space offers advantages over steering in dense activation space for jailbreak mitigation. Our results suggest off-the-shelf SAEs trained for interpretability can be repurposed as practical jailbreak defenses without task-specific training.", "AI": {"tldr": "CC-Delta\u662f\u4e00\u79cd\u57fa\u4e8e\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7684\u9632\u5fa1\u65b9\u6cd5\uff0c\u901a\u8fc7\u6bd4\u8f83\u6709\u5bb3\u8bf7\u6c42\u5728\u6709/\u65e0\u8d8a\u72f1\u4e0a\u4e0b\u6587\u65f6\u7684token\u7ea7\u8868\u793a\uff0c\u8bc6\u522b\u8d8a\u72f1\u76f8\u5173\u7a00\u758f\u7279\u5f81\uff0c\u5e76\u5728\u63a8\u7406\u65f6\u8fdb\u884c\u5747\u503c\u6f02\u79fb\u5f15\u5bfc\uff0c\u6709\u6548\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\u3002", "motivation": "\u8d8a\u72f1\u653b\u51fb\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6784\u6210\u6301\u7eed\u5a01\u80c1\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u9632\u5fa1\u673a\u5236\u6765\u4fdd\u62a4\u6a21\u578b\u5b89\u5168\u3002", "method": "\u63d0\u51fa\u4e0a\u4e0b\u6587\u6761\u4ef6\u5316Delta\u5f15\u5bfc\uff08CC-Delta\uff09\uff1a1\uff09\u4f7f\u7528\u6210\u5bf9\u7684\u6709\u5bb3/\u8d8a\u72f1\u63d0\u793a\u6bd4\u8f83token\u7ea7\u8868\u793a\uff1b2\uff09\u901a\u8fc7\u7edf\u8ba1\u6d4b\u8bd5\u9009\u62e9\u8d8a\u72f1\u76f8\u5173\u7a00\u758f\u7279\u5f81\uff1b3\uff09\u5728SAE\u6f5c\u5728\u7a7a\u95f4\u8fdb\u884c\u63a8\u7406\u65f6\u5747\u503c\u6f02\u79fb\u5f15\u5bfc\u3002", "result": "\u5728\u56db\u4e2a\u5bf9\u9f50\u7684\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u548c\u5341\u4e8c\u79cd\u8d8a\u72f1\u653b\u51fb\u4e0a\uff0cCC-Delta\u5728\u5b89\u5168-\u6548\u7528\u6743\u8861\u65b9\u9762\u8fbe\u5230\u6216\u4f18\u4e8e\u5728\u5bc6\u96c6\u6f5c\u5728\u7a7a\u95f4\u64cd\u4f5c\u7684\u57fa\u7ebf\u9632\u5fa1\u65b9\u6cd5\u3002\u7279\u522b\u662f\u5728\u6240\u6709\u56db\u4e2a\u6a21\u578b\u4e0a\u90fd\u660e\u663e\u4f18\u4e8e\u5bc6\u96c6\u5747\u503c\u6f02\u79fb\u5f15\u5bfc\uff0c\u5bf9\u5206\u5e03\u5916\u653b\u51fb\u6548\u679c\u5c24\u4e3a\u663e\u8457\u3002", "conclusion": "\u7a00\u758fSAE\u7279\u5f81\u7a7a\u95f4\u5f15\u5bfc\u76f8\u6bd4\u5bc6\u96c6\u6fc0\u6d3b\u7a7a\u95f4\u5f15\u5bfc\u5728\u8d8a\u72f1\u7f13\u89e3\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u73b0\u6210\u7684\u4e3a\u53ef\u89e3\u91ca\u6027\u8bad\u7ec3\u7684SAE\u53ef\u4ee5\u88ab\u91cd\u65b0\u7528\u4f5c\u5b9e\u7528\u7684\u8d8a\u72f1\u9632\u5fa1\u5de5\u5177\uff0c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u8bad\u7ec3\u3002"}}
{"id": "2602.12316", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.GT", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.12316", "abs": "https://arxiv.org/abs/2602.12316", "authors": ["Pepijn Cobben", "Xuanqiang Angelo Huang", "Thao Amelia Pham", "Isabel Dahlgren", "Terry Jingchen Zhang", "Zhijing Jin"], "title": "GT-HarmBench: Benchmarking AI Safety Risks Through the Lens of Game Theory", "comment": null, "summary": "Frontier AI systems are increasingly capable and deployed in high-stakes multi-agent environments. However, existing AI safety benchmarks largely evaluate single agents, leaving multi-agent risks such as coordination failure and conflict poorly understood. We introduce GT-HarmBench, a benchmark of 2,009 high-stakes scenarios spanning game-theoretic structures such as the Prisoner's Dilemma, Stag Hunt and Chicken. Scenarios are drawn from realistic AI risk contexts in the MIT AI Risk Repository. Across 15 frontier models, agents choose socially beneficial actions in only 62% of cases, frequently leading to harmful outcomes. We measure sensitivity to game-theoretic prompt framing and ordering, and analyze reasoning patterns driving failures. We further show that game-theoretic interventions improve socially beneficial outcomes by up to 18%. Our results highlight substantial reliability gaps and provide a broad standardized testbed for studying alignment in multi-agent environments. The benchmark and code are available at https://github.com/causalNLP/gt-harmbench.", "AI": {"tldr": "GT-HarmBench\u662f\u4e00\u4e2a\u5305\u542b2009\u4e2a\u9ad8\u98ce\u9669\u591a\u667a\u80fd\u4f53\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8986\u76d6\u56da\u5f92\u56f0\u5883\u3001\u730e\u9e7f\u535a\u5f08\u7b49\u535a\u5f08\u8bba\u7ed3\u6784\uff0c\u7528\u4e8e\u8bc4\u4f30\u524d\u6cbfAI\u7cfb\u7edf\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6027\u548c\u534f\u8c03\u80fd\u529b\u3002", "motivation": "\u73b0\u6709AI\u5b89\u5168\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u5355\u667a\u80fd\u4f53\uff0c\u800c\u5ffd\u7565\u4e86\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u534f\u8c03\u5931\u8d25\u3001\u51b2\u7a81\u7b49\u98ce\u9669\u3002\u968f\u7740\u524d\u6cbfAI\u7cfb\u7edf\u5728\u9ad8\u98ce\u9669\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u90e8\u7f72\u589e\u591a\uff0c\u9700\u8981\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u548c\u7406\u89e3\u8fd9\u4e9b\u591a\u667a\u80fd\u4f53\u98ce\u9669\u3002", "method": "\u4eceMIT AI\u98ce\u9669\u5e93\u4e2d\u63d0\u53d6\u771f\u5b9eAI\u98ce\u9669\u573a\u666f\uff0c\u6784\u5efa\u5305\u542b2009\u4e2a\u9ad8\u98ce\u9669\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8986\u76d6\u56da\u5f92\u56f0\u5883\u3001\u730e\u9e7f\u535a\u5f08\u3001\u80c6\u5c0f\u9b3c\u535a\u5f08\u7b49\u7ecf\u5178\u535a\u5f08\u8bba\u7ed3\u6784\u3002\u8bc4\u4f3015\u4e2a\u524d\u6cbf\u6a21\u578b\uff0c\u6d4b\u91cf\u5176\u5bf9\u535a\u5f08\u8bba\u63d0\u793a\u6846\u67b6\u548c\u987a\u5e8f\u7684\u654f\u611f\u6027\uff0c\u5e76\u5206\u6790\u5bfc\u81f4\u5931\u8d25\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "result": "\u572815\u4e2a\u524d\u6cbf\u6a21\u578b\u4e2d\uff0c\u667a\u80fd\u4f53\u4ec5\u572862%\u7684\u60c5\u51b5\u4e0b\u9009\u62e9\u793e\u4f1a\u6709\u76ca\u884c\u52a8\uff0c\u7ecf\u5e38\u5bfc\u81f4\u6709\u5bb3\u7ed3\u679c\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\u535a\u5f08\u8bba\u5e72\u9884\u53ef\u4ee5\u5c06\u793e\u4f1a\u6709\u76ca\u7ed3\u679c\u63d0\u9ad8\u591a\u8fbe18%\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u524d\u6cbfAI\u7cfb\u7edf\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u5b58\u5728\u663e\u8457\u53ef\u9760\u6027\u5dee\u8ddd\uff0cGT-HarmBench\u4e3a\u7814\u7a76\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u4e86\u5e7f\u6cdb\u6807\u51c6\u5316\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002\u57fa\u51c6\u6d4b\u8bd5\u548c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.13167", "categories": ["cs.DC", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.13167", "abs": "https://arxiv.org/abs/2602.13167", "authors": ["Shlomi Dolev", "Ehud Gudes", "Daniel Shlomo"], "title": "Bloom Filter Look-Up Tables for Private and Secure Distributed Databases in Web3 (Revised Version)", "comment": null, "summary": "The rapid growth of decentralized systems in theWeb3 ecosystem has introduced numerous challenges, particularly in ensuring data security, privacy, and scalability [3, 8]. These systems rely heavily on distributed architectures, requiring robust mechanisms to manage data and interactions among participants securely. One critical aspect of decentralized systems is key management, which is essential for encrypting files, securing database segments, and enabling private transactions. However, securely managing cryptographic keys in a distributed environment poses significant risks, especially when nodes in the network can be compromised [9]. This research proposes a decentralized database scheme specifically designed for secure and private key management. Our approach ensures that cryptographic keys are not stored explicitly at any location, preventing their discovery even if an attacker gains control of multiple nodes. Instead of traditional storage, keys are encoded and distributed using the BFLUT (Bloom Filter for Private Look-Up Tables) algorithm [7], which enables secure retrieval without direct exposure. The system leverages OrbitDB [4], IPFS [1], and IPNS [10] for decentralized data management, providing robust support for consistency, scalability, and simultaneous updates. By combining these technologies, our scheme enhances both security and privacy while maintaining high performance and reliability. Our findings demonstrate the system's capability to securely manage keys, prevent unauthorized access, and ensure privacy, making it a foundational solution for Web3 applications requiring decentralized security.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eBFLUT\u7b97\u6cd5\u7684\u53bb\u4e2d\u5fc3\u5316\u5bc6\u94a5\u7ba1\u7406\u65b9\u6848\uff0c\u901a\u8fc7\u7f16\u7801\u548c\u5206\u5e03\u5f0f\u5b58\u50a8\u4fdd\u62a4\u5bc6\u94a5\u5b89\u5168\uff0c\u7ed3\u5408OrbitDB\u3001IPFS\u548cIPNS\u6280\u672f\u5b9e\u73b0\u9ad8\u6027\u80fd\u53bb\u4e2d\u5fc3\u5316\u6570\u636e\u5e93\u3002", "motivation": "Web3\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u9762\u4e34\u6570\u636e\u5b89\u5168\u3001\u9690\u79c1\u548c\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u7ba1\u7406\u52a0\u5bc6\u5bc6\u94a5\u5b58\u5728\u91cd\u5927\u98ce\u9669\uff0c\u8282\u70b9\u53ef\u80fd\u88ab\u653b\u51fb\u8005\u63a7\u5236\u3002", "method": "\u91c7\u7528BFLUT\u7b97\u6cd5\u5bf9\u5bc6\u94a5\u8fdb\u884c\u7f16\u7801\u548c\u5206\u5e03\u5f0f\u5b58\u50a8\uff0c\u4e0d\u76f4\u63a5\u5b58\u50a8\u5bc6\u94a5\u660e\u6587\uff1b\u5229\u7528OrbitDB\u3001IPFS\u548cIPNS\u6784\u5efa\u53bb\u4e2d\u5fc3\u5316\u6570\u636e\u7ba1\u7406\u7cfb\u7edf\uff0c\u652f\u6301\u4e00\u81f4\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u5e76\u53d1\u66f4\u65b0\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u5b89\u5168\u7ba1\u7406\u5bc6\u94a5\uff0c\u9632\u6b62\u672a\u6388\u6743\u8bbf\u95ee\uff0c\u786e\u4fdd\u9690\u79c1\u4fdd\u62a4\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u9700\u8981\u53bb\u4e2d\u5fc3\u5316\u5b89\u5168\u7684Web3\u5e94\u7528\u63d0\u4f9b\u57fa\u7840\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684\u53bb\u4e2d\u5fc3\u5316\u6570\u636e\u5e93\u65b9\u6848\u901a\u8fc7\u521b\u65b0\u7684\u5bc6\u94a5\u7ba1\u7406\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86Web3\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u5b89\u5168\u3001\u9690\u79c1\u548c\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u4e3a\u53bb\u4e2d\u5fc3\u5316\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u5b89\u5168\u57fa\u7840\u3002"}}
{"id": "2602.12433", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.12433", "abs": "https://arxiv.org/abs/2602.12433", "authors": ["Niklas Klinger", "Jonas Sander", "Peterson Yuhala", "Pascal Felber", "Thomas Eisenbarth"], "title": "DRAMatic Speedup: Accelerating HE Operations on a Processing-in-Memory System", "comment": null, "summary": "Homomorphic encryption (HE) is a promising technology for confidential cloud computing, as it allows computations on encrypted data. However, HE is computationally expensive and often memory-bound on conventional computer architectures. Processing-in-Memory (PIM) is an alternative hardware architecture that integrates processing units and memory on the same chip or memory module. PIM enables higher memory bandwidth than conventional architectures and could thus be suitable for accelerating HE. In this work, we present DRAMatic, which implements operations foundational to HE on UPMEM's programmable, general-purpose PIM system, and evaluate its performance. DRAMatic incorporates many arithmetic optimizations, including residue number system and number-theoretic transform techniques, and can support the large parameters required for secure homomorphic evaluations. To compare performance, we evaluate DRAMatic against Microsoft SEAL, a popular open-source HE library, regarding both runtime and energy efficiency. The results show that DRAMatic significantly closes the gap between UPMEM PIM and Microsoft SEAL. However, we also show that DRAMatic is currently constrained by UPMEM PIM's multiplication performance and data transfer overhead. Finally, we discuss potential hardware extensions to UPMEM PIM.", "AI": {"tldr": "DRAMatic\u662f\u4e00\u4e2a\u5728UPMEM PIM\u7cfb\u7edf\u4e0a\u5b9e\u73b0\u540c\u6001\u52a0\u5bc6\u57fa\u7840\u64cd\u4f5c\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u79cd\u7b97\u672f\u4f18\u5316\u663e\u8457\u7f29\u5c0f\u4e86\u4e0eMicrosoft SEAL\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u4f46\u53d7\u9650\u4e8ePIM\u7684\u4e58\u6cd5\u6027\u80fd\u548c\u6570\u636e\u4f20\u8f93\u5f00\u9500\u3002", "motivation": "\u540c\u6001\u52a0\u5bc6\uff08HE\uff09\u662f\u4fdd\u5bc6\u4e91\u8ba1\u7b97\u7684\u6709\u524d\u666f\u6280\u672f\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u5728\u4f20\u7edf\u67b6\u6784\u4e0a\u53d7\u5185\u5b58\u9650\u5236\u3002\u5185\u5b58\u5185\u5904\u7406\uff08PIM\uff09\u67b6\u6784\u5177\u6709\u66f4\u9ad8\u5185\u5b58\u5e26\u5bbd\uff0c\u53ef\u80fd\u9002\u5408\u52a0\u901fHE\u3002", "method": "\u5728UPMEM\u7684\u53ef\u7f16\u7a0b\u901a\u7528PIM\u7cfb\u7edf\u4e0a\u5b9e\u73b0DRAMatic\u6846\u67b6\uff0c\u91c7\u7528\u4f59\u6570\u7cfb\u7edf\u548c\u6570\u8bba\u53d8\u6362\u7b49\u7b97\u672f\u4f18\u5316\u6280\u672f\uff0c\u652f\u6301\u5b89\u5168\u540c\u6001\u8bc4\u4f30\u6240\u9700\u7684\u5927\u53c2\u6570\u3002", "result": "DRAMatic\u663e\u8457\u7f29\u5c0f\u4e86UPMEM PIM\u4e0eMicrosoft SEAL\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u4f46\u53d7\u9650\u4e8eUPMEM PIM\u7684\u4e58\u6cd5\u6027\u80fd\u548c\u6570\u636e\u4f20\u8f93\u5f00\u9500\u3002", "conclusion": "PIM\u67b6\u6784\u6709\u6f5c\u529b\u52a0\u901f\u540c\u6001\u52a0\u5bc6\uff0c\u4f46\u9700\u8981\u786c\u4ef6\u6269\u5c55\u6765\u6539\u8fdb\u4e58\u6cd5\u6027\u80fd\u548c\u51cf\u5c11\u6570\u636e\u4f20\u8f93\u5f00\u9500\u3002"}}
{"id": "2602.12962", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12962", "abs": "https://arxiv.org/abs/2602.12962", "authors": ["Jonghun Lee", "Junghoon Lee", "Hyeonjin Kim", "Seoho Jeon", "Jisup Yoon", "Hyunbin Park", "Meejeong Park", "Heonjae Ha"], "title": "TriGen: NPU Architecture for End-to-End Acceleration of Large Language Models based on SW-HW Co-Design", "comment": "13 pages, 14 figures", "summary": "Recent studies have extensively explored NPU architectures for accelerating AI inference in on-device environments, which are inherently resource-constrained. Meanwhile, transformer-based large language models (LLMs) have become dominant, with rapidly increasing model sizes but low degree of parameter reuse compared to conventional CNNs, making end-to-end execution on resource-limited devices extremely challenging. To address these challenges, we propose TriGen, a novel NPU architecture tailored for resource-constrained environments through software-hardware co-design. Firstly, TriGen adopts low-precision computation using microscaling (MX) to enable additional optimization opportunities while preserving accuracy, and resolves the issues that arise by employing such precision. Secondly, to jointly optimize both nonlinear and linear operations, TriGen eliminates the need for specialized hardware for essential nonlinear operations by using fast and accurate LUT, thereby maximizing performance gains and reducing hardware-cost in on-device environments, and finally, by taking practical hardware constraints into account, further employs scheduling techniques to maximize computational utilization even under limited on-chip memory capacity. We evaluate the performance of TriGen on various LLMs and show that TriGen achieves an average 2.73x performance speedup and 52% less memory transfer over the baseline NPU design with negligible accuracy loss.", "AI": {"tldr": "TriGen\u662f\u4e00\u79cd\u9488\u5bf9\u8d44\u6e90\u53d7\u9650\u73af\u5883\u7684NPU\u67b6\u6784\uff0c\u901a\u8fc7\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u4f18\u5316LLM\u63a8\u7406\uff0c\u91c7\u7528\u5fae\u7f29\u653e\u4f4e\u7cbe\u5ea6\u8ba1\u7b97\u3001\u67e5\u627e\u8868\u66ff\u4ee3\u975e\u7ebf\u6027\u64cd\u4f5c\u4e13\u7528\u786c\u4ef6\uff0c\u4ee5\u53ca\u8003\u8651\u5b9e\u9645\u786c\u4ef6\u7ea6\u675f\u7684\u8c03\u5ea6\u6280\u672f\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u968f\u7740transformer\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u90e8\u7f72\u9700\u6c42\u589e\u52a0\uff0c\u4f20\u7edfNPU\u67b6\u6784\u9762\u4e34\u6311\u6218\uff1aLLM\u53c2\u6570\u91cf\u5927\u4f46\u590d\u7528\u7387\u4f4e\uff0c\u7aef\u5230\u7aef\u6267\u884c\u56f0\u96be\uff0c\u9700\u8981\u9488\u5bf9\u8d44\u6e90\u53d7\u9650\u73af\u5883\u8bbe\u8ba1\u4e13\u95e8\u7684\u786c\u4ef6\u67b6\u6784\u3002", "method": "1. \u91c7\u7528\u5fae\u7f29\u653e\u4f4e\u7cbe\u5ea6\u8ba1\u7b97\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u63d0\u4f9b\u989d\u5916\u4f18\u5316\u673a\u4f1a\uff1b2. \u4f7f\u7528\u5feb\u901f\u51c6\u786e\u7684\u67e5\u627e\u8868\u66ff\u4ee3\u975e\u7ebf\u6027\u64cd\u4f5c\u4e13\u7528\u786c\u4ef6\uff0c\u8054\u5408\u4f18\u5316\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u64cd\u4f5c\uff1b3. \u8003\u8651\u5b9e\u9645\u786c\u4ef6\u7ea6\u675f\uff0c\u91c7\u7528\u8c03\u5ea6\u6280\u672f\u6700\u5927\u5316\u6709\u9650\u7247\u4e0a\u5185\u5b58\u4e0b\u7684\u8ba1\u7b97\u5229\u7528\u7387\u3002", "result": "\u5728\u591a\u79cdLLM\u4e0a\u8bc4\u4f30\u663e\u793a\uff0cTriGen\u76f8\u6bd4\u57fa\u7ebfNPU\u8bbe\u8ba1\u5e73\u5747\u5b9e\u73b02.73\u500d\u6027\u80fd\u52a0\u901f\uff0c\u5185\u5b58\u4f20\u8f93\u51cf\u5c1152%\uff0c\u7cbe\u5ea6\u635f\u5931\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "TriGen\u901a\u8fc7\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684LLM\u63a8\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684NPU\u67b6\u6784\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u6027\u80fd\u3001\u5185\u5b58\u6548\u7387\u548c\u786c\u4ef6\u6210\u672c\u65b9\u9762\u5747\u6709\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2602.12630", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12630", "abs": "https://arxiv.org/abs/2602.12630", "authors": ["Oguzhan Baser", "Elahe Sadeghi", "Eric Wang", "David Ribeiro Alves", "Sam Kazemian", "Hong Kang", "Sandeep P. Chinchali", "Sriram Vishwanath"], "title": "TensorCommitments: A Lightweight Verifiable Inference for Language Models", "comment": "23 pages, 8 figures, under review", "summary": "Most large language models (LLMs) run on external clouds: users send a prompt, pay for inference, and must trust that the remote GPU executes the LLM without any adversarial tampering. We critically ask how to achieve verifiable LLM inference, where a prover (the service) must convince a verifier (the client) that an inference was run correctly without rerunning the LLM. Existing cryptographic works are too slow at the LLM scale, while non-cryptographic ones require a strong verifier GPU. We propose TensorCommitments (TCs), a tensor-native proof-of-inference scheme. TC binds the LLM inference to a commitment, an irreversible tag that breaks under tampering, organized in our multivariate Terkle Trees. For LLaMA2, TC adds only 0.97% prover and 0.12% verifier time over inference while improving robustness to tailored LLM attacks by up to 48% over the best prior work requiring a verifier GPU.", "AI": {"tldr": "TensorCommitments (TCs) \u662f\u4e00\u79cd\u7528\u4e8e\u9a8c\u8bc1\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6b63\u786e\u6027\u7684\u65b9\u6848\uff0c\u901a\u8fc7\u5f20\u91cf\u539f\u751f\u627f\u8bfa\u548c\u591a\u5143Terkle\u6811\uff0c\u5728LLaMA2\u4e0a\u4ec5\u589e\u52a00.97%\u7684\u8bc1\u660e\u65f6\u95f4\u548c0.12%\u7684\u9a8c\u8bc1\u65f6\u95f4\uff0c\u540c\u65f6\u5c06\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\u63d0\u534748%\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5927\u591a\u8fd0\u884c\u5728\u5916\u90e8\u4e91\u4e0a\uff0c\u7528\u6237\u9700\u8981\u4fe1\u4efb\u8fdc\u7a0bGPU\u6b63\u786e\u6267\u884c\u63a8\u7406\u800c\u4e0d\u88ab\u7be1\u6539\u3002\u73b0\u6709\u5bc6\u7801\u5b66\u65b9\u6cd5\u5728\u5927\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u4e0b\u592a\u6162\uff0c\u800c\u975e\u5bc6\u7801\u5b66\u65b9\u6cd5\u9700\u8981\u5f3a\u5927\u7684\u9a8c\u8bc1\u8005GPU\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u9a8c\u8bc1\u63a8\u7406\u6b63\u786e\u6027\u53c8\u9ad8\u6548\u7684\u65b9\u6848\u3002", "method": "\u63d0\u51faTensorCommitments (TCs)\uff0c\u4e00\u79cd\u5f20\u91cf\u539f\u751f\u7684\u63a8\u7406\u8bc1\u660e\u65b9\u6848\u3002TC\u5c06LLM\u63a8\u7406\u7ed1\u5b9a\u5230\u4e00\u4e2a\u627f\u8bfa\u4e0a\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e0d\u53ef\u9006\u7684\u6807\u7b7e\uff0c\u5728\u7be1\u6539\u65f6\u4f1a\u5931\u6548\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u591a\u5143Terkle\u6811\u6765\u7ec4\u7ec7\u627f\u8bfa\u3002", "result": "\u5728LLaMA2\u4e0a\uff0cTC\u4ec5\u589e\u52a00.97%\u7684\u8bc1\u660e\u8005\u65f6\u95f4\u548c0.12%\u7684\u9a8c\u8bc1\u8005\u65f6\u95f4\uff0c\u76f8\u6bd4\u9700\u8981\u9a8c\u8bc1\u8005GPU\u7684\u6700\u4f73\u5148\u524d\u5de5\u4f5c\uff0c\u5bf9\u5b9a\u5236LLM\u653b\u51fb\u7684\u9c81\u68d2\u6027\u63d0\u5347\u4e8648%\u3002", "conclusion": "TensorCommitments\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u9a8c\u8bc1\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6b63\u786e\u6027\u7684\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6027\u80fd\u548c\u5b89\u5168\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002"}}
{"id": "2602.12681", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.12681", "abs": "https://arxiv.org/abs/2602.12681", "authors": ["Jiyong Uhm", "Minseok Kim", "Michalis Polychronakis", "Hyungjoon Koo"], "title": "Fool Me If You Can: On the Robustness of Binary Code Similarity Detection Models against Semantics-preserving Transformations", "comment": "23 pages, 9 figures, 5 tables. The paper has been accepted by The ACM International Conference on the Foundations of Software Engineering (FSE 2026)", "summary": "Binary code analysis plays an essential role in cybersecurity, facilitating reverse engineering to reveal the inner workings of programs in the absence of source code. Traditional approaches, such as static and dynamic analysis, extract valuable insights from stripped binaries, but often demand substantial expertise and manual effort. Recent advances in deep learning have opened promising opportunities to enhance binary analysis by capturing latent features and disclosing underlying code semantics. Despite the growing number of binary analysis models based on machine learning, their robustness to adversarial code transformations at the binary level remains underexplored. We evaluate the robustness of deep learning models for the task of binary code similarity detection (BCSD) under semantics-preserving transformations. The unique nature of machine instructions presents distinct challenges compared to the typical input perturbations found in other domains. We introduce asmFooler, a system that evaluates the resilience of BCSD models using a diverse set of adversarial code transformations that preserve functional semantics. We construct a dataset of 9,565 binary variants from 620 baseline samples by applying eight semantics-preserving transformations across six representative BCSD models. Our major findings highlight several key insights: i) model robustness relies on the processing pipeline, including code pre-processing, architecture, and feature selection; ii) adversarial transformation effectiveness is bounded by a budget shaped by model-specific constraints like input size and instruction expressive capacity; iii) well-crafted transformations can be highly effective with minimal perturbations; and iv) such transformations efficiently disrupt model decisions (e.g., misleading to false positives or false negatives) by focusing on semantically significant instructions.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u4e8c\u8fdb\u5236\u4ee3\u7801\u76f8\u4f3c\u6027\u68c0\u6d4b\uff08BCSD\uff09\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u8bed\u4e49\u4fdd\u6301\u53d8\u6362\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u63d0\u51fa\u4e86asmFooler\u7cfb\u7edf\u6765\u6d4b\u8bd5\u6a21\u578b\u5bf9\u6297\u6027\u53d8\u6362\u7684\u62b5\u6297\u529b\u3002", "motivation": "\u5c3d\u7ba1\u673a\u5668\u5b66\u4e60\u5728\u4e8c\u8fdb\u5236\u4ee3\u7801\u5206\u6790\u4e2d\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u5728\u4e8c\u8fdb\u5236\u7ea7\u522b\u5bf9\u6297\u6027\u4ee3\u7801\u53d8\u6362\u4e0b\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u4e8c\u8fdb\u5236\u4ee3\u7801\u7684\u72ec\u7279\u6027\u8d28\u4f7f\u5176\u9762\u4e34\u4e0e\u5e38\u89c4\u8f93\u5165\u6270\u52a8\u4e0d\u540c\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86asmFooler\u7cfb\u7edf\uff0c\u4f7f\u7528\u516b\u79cd\u8bed\u4e49\u4fdd\u6301\u7684\u5bf9\u6297\u6027\u4ee3\u7801\u53d8\u6362\u6765\u8bc4\u4f30\u516d\u4e2a\u4ee3\u8868\u6027BCSD\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002\u6784\u5efa\u4e86\u5305\u542b9,565\u4e2a\u4e8c\u8fdb\u5236\u53d8\u4f53\u7684\u6570\u636e\u96c6\uff0c\u6765\u81ea620\u4e2a\u57fa\u51c6\u6837\u672c\u3002", "result": "\u4e3b\u8981\u53d1\u73b0\uff1a1\uff09\u6a21\u578b\u9c81\u68d2\u6027\u4f9d\u8d56\u4e8e\u5904\u7406\u6d41\u7a0b\uff08\u4ee3\u7801\u9884\u5904\u7406\u3001\u67b6\u6784\u3001\u7279\u5f81\u9009\u62e9\uff09\uff1b2\uff09\u5bf9\u6297\u6027\u53d8\u6362\u7684\u6709\u6548\u6027\u53d7\u6a21\u578b\u7279\u5b9a\u7ea6\u675f\uff08\u8f93\u5165\u5927\u5c0f\u3001\u6307\u4ee4\u8868\u8fbe\u80fd\u529b\uff09\u5f62\u6210\u7684\u9884\u7b97\u9650\u5236\uff1b3\uff09\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u53d8\u6362\u80fd\u4ee5\u6700\u5c0f\u6270\u52a8\u5b9e\u73b0\u9ad8\u6548\u653b\u51fb\uff1b4\uff09\u901a\u8fc7\u5173\u6ce8\u8bed\u4e49\u91cd\u8981\u6307\u4ee4\uff0c\u8fd9\u4e9b\u53d8\u6362\u80fd\u6709\u6548\u7834\u574f\u6a21\u578b\u51b3\u7b56\u3002", "conclusion": "\u4e8c\u8fdb\u5236\u4ee3\u7801\u76f8\u4f3c\u6027\u68c0\u6d4b\u6a21\u578b\u5728\u5bf9\u6297\u6027\u8bed\u4e49\u4fdd\u6301\u53d8\u6362\u4e0b\u5b58\u5728\u8106\u5f31\u6027\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u6a21\u578b\u8bbe\u8ba1\u548c\u8bc4\u4f30\u6846\u67b6\u3002asmFooler\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdbBCSD\u6a21\u578b\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u7cfb\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2602.12825", "categories": ["cs.CR", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.12825", "abs": "https://arxiv.org/abs/2602.12825", "authors": ["Rub\u00e9n P\u00e9rez-Jove", "Osvaldo Simeone", "Alejandro Pazos", "Jose V\u00e1zquez-Naya"], "title": "Reliable Hierarchical Operating System Fingerprinting via Conformal Prediction", "comment": "Submitted as a preprint (not peer reviewed). 16 pages, 10 figures. Code and datasets available at: https://github.com/rubenpjove/CP-HOSfing", "summary": "Operating System (OS) fingerprinting is critical for network security, but conventional methods do not provide formal uncertainty quantification mechanisms. Conformal Prediction (CP) could be directly wrapped around existing methods to obtain prediction sets with guaranteed coverage. However, a direct application of CP would treat OS identification as a flat classification problem, ignoring the natural taxonomic structure of OSs and providing brittle point predictions. This work addresses these limitations by introducing and evaluating two distinct structured CP strategies: level-wise CP (L-CP), which calibrates each hierarchy level independently, and projection-based CP (P-CP), which ensures structural consistency by projecting leaf-level sets upwards. Our results demonstrate that, while both methods satisfy validity guarantees, they expose a fundamental trade-off between level-wise efficiency and structural consistency. L-CP yields tighter prediction sets suitable for human forensic analysis but suffers from taxonomic inconsistencies. Conversely, P-CP guarantees hierarchically consistent, nested sets ideal for automated policy enforcement, albeit at the cost of reduced efficiency at coarser levels.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9488\u5bf9\u64cd\u4f5c\u7cfb\u7edf\u6307\u7eb9\u8bc6\u522b\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u7ed3\u6784\u5316\u5171\u5f62\u9884\u6d4b\u65b9\u6cd5\uff0c\u5728\u4fdd\u8bc1\u8986\u76d6\u7387\u7684\u540c\u65f6\u8003\u8651\u4e86\u64cd\u4f5c\u7cfb\u7edf\u7684\u5c42\u6b21\u5316\u5206\u7c7b\u7ed3\u6784\u3002", "motivation": "\u4f20\u7edf\u64cd\u4f5c\u7cfb\u7edf\u6307\u7eb9\u8bc6\u522b\u65b9\u6cd5\u7f3a\u4e4f\u6b63\u5f0f\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u673a\u5236\uff0c\u4e14\u5c06OS\u8bc6\u522b\u89c6\u4e3a\u6241\u5e73\u5206\u7c7b\u95ee\u9898\uff0c\u5ffd\u7565\u4e86\u64cd\u4f5c\u7cfb\u7edf\u7684\u81ea\u7136\u5206\u7c7b\u5c42\u6b21\u7ed3\u6784\uff0c\u5bfc\u81f4\u9884\u6d4b\u7ed3\u679c\u8106\u5f31\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u7ed3\u6784\u5316\u5171\u5f62\u9884\u6d4b\u7b56\u7565\uff1a1) \u5c42\u7ea7\u5171\u5f62\u9884\u6d4b(L-CP)\uff1a\u72ec\u7acb\u6821\u51c6\u6bcf\u4e2a\u5c42\u6b21\u7ea7\u522b\uff1b2) \u6295\u5f71\u5171\u5f62\u9884\u6d4b(P-CP)\uff1a\u901a\u8fc7\u5c06\u53f6\u7ea7\u96c6\u5408\u5411\u4e0a\u6295\u5f71\u6765\u786e\u4fdd\u7ed3\u6784\u4e00\u81f4\u6027\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u90fd\u6ee1\u8db3\u6709\u6548\u6027\u4fdd\u8bc1\uff0c\u4f46\u63ed\u793a\u4e86\u5c42\u7ea7\u6548\u7387\u4e0e\u7ed3\u6784\u4e00\u81f4\u6027\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u3002L-CP\u4ea7\u751f\u66f4\u7d27\u51d1\u7684\u9884\u6d4b\u96c6\u9002\u5408\u4eba\u5de5\u53d6\u8bc1\u5206\u6790\uff0c\u4f46\u5b58\u5728\u5206\u7c7b\u4e0d\u4e00\u81f4\u6027\uff1bP-CP\u4fdd\u8bc1\u5c42\u6b21\u4e00\u81f4\u7684\u5d4c\u5957\u96c6\u9002\u5408\u81ea\u52a8\u5316\u7b56\u7565\u6267\u884c\uff0c\u4f46\u5728\u8f83\u7c97\u7c92\u5ea6\u7ea7\u522b\u6548\u7387\u964d\u4f4e\u3002", "conclusion": "\u7ed3\u6784\u5316\u5171\u5f62\u9884\u6d4b\u65b9\u6cd5\u4e3a\u64cd\u4f5c\u7cfb\u7edf\u6307\u7eb9\u8bc6\u522b\u63d0\u4f9b\u4e86\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u540c\u65f6\u8003\u8651\u4e86\u5206\u7c7b\u5c42\u6b21\u7ed3\u6784\uff0c\u5728\u6548\u7387\u4e0e\u4e00\u81f4\u6027\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u53ef\u6839\u636e\u5e94\u7528\u573a\u666f\u9009\u62e9\u5408\u9002\u65b9\u6cd5\u3002"}}
{"id": "2602.12566", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12566", "abs": "https://arxiv.org/abs/2602.12566", "authors": ["Haoqing Wang", "Xiang Long", "Ziheng Li", "Yilong Xu", "Tingguang Li", "Yehui Tang"], "title": "To Mix or To Merge: Toward Multi-Domain Reinforcement Learning for Large Language Models", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) plays a key role in stimulating the explicit reasoning capability of Large Language Models (LLMs). We can achieve expert-level performance in some specific domains via RLVR, such as coding or math. When a general multi-domain expert-level model is required, we need to carefully consider the collaboration of RLVR across different domains. The current state-of-the-art models mainly employ two different training paradigms for multi-domain RLVR: mixed multi-task RLVR and separate RLVR followed by model merging. However, most of the works did not provide a detailed comparison and analysis about these paradigms. To this end, we choose multiple commonly used high-level tasks (e.g., math, coding, science, and instruction following) as our target domains and design extensive qualitative and quantitative experiments using open-source datasets. We find the RLVR across domains exhibits few mutual interferences, and reasoning-intensive domains demonstrate mutually synergistic effects. Furthermore, we analyze the internal mechanisms of mutual gains from the perspectives of weight space geometry, model prediction behavior, and information constraints. This project is named as M2RL that means Mixed multi-task training or separate training followed by model Merging for Reinforcement Learning, and the homepage is at https://github.com/mosAI25/M2RL", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u591a\u9886\u57df\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u7684\u4e24\u79cd\u8bad\u7ec3\u8303\u5f0f\uff1a\u6df7\u5408\u591a\u4efb\u52a1\u8bad\u7ec3\u4e0e\u5206\u522b\u8bad\u7ec3\u540e\u6a21\u578b\u5408\u5e76\uff0c\u53d1\u73b0\u5728\u4e0d\u540c\u9886\u57df\u95f4RLVR\u5b58\u5728\u8f83\u5c11\u76f8\u4e92\u5e72\u6270\uff0c\u63a8\u7406\u5bc6\u96c6\u578b\u9886\u57df\u751a\u81f3\u8868\u73b0\u51fa\u76f8\u4e92\u534f\u540c\u6548\u5e94\u3002", "motivation": "\u5f53\u524d\u591a\u9886\u57df\u4e13\u5bb6\u7ea7\u6a21\u578b\u9700\u8981\u8de8\u9886\u57dfRLVR\u534f\u4f5c\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u6df7\u5408\u591a\u4efb\u52a1RLVR\u548c\u5206\u522b\u8bad\u7ec3\u540e\u6a21\u578b\u5408\u5e76\u8fd9\u4e24\u79cd\u8303\u5f0f\u7684\u8be6\u7ec6\u6bd4\u8f83\u5206\u6790\u3002", "method": "\u9009\u62e9\u6570\u5b66\u3001\u7f16\u7a0b\u3001\u79d1\u5b66\u548c\u6307\u4ee4\u8ddf\u968f\u7b49\u591a\u4e2a\u5e38\u7528\u9ad8\u7ea7\u4efb\u52a1\u4f5c\u4e3a\u76ee\u6807\u9886\u57df\uff0c\u4f7f\u7528\u5f00\u6e90\u6570\u636e\u96c6\u8bbe\u8ba1\u5e7f\u6cdb\u7684\u5b9a\u6027\u548c\u5b9a\u91cf\u5b9e\u9a8c\uff0c\u4ece\u6743\u91cd\u7a7a\u95f4\u51e0\u4f55\u3001\u6a21\u578b\u9884\u6d4b\u884c\u4e3a\u548c\u4fe1\u606f\u7ea6\u675f\u7b49\u89d2\u5ea6\u5206\u6790\u5185\u90e8\u673a\u5236\u3002", "result": "\u53d1\u73b0\u8de8\u9886\u57dfRLVR\u8868\u73b0\u51fa\u8f83\u5c11\u76f8\u4e92\u5e72\u6270\uff0c\u63a8\u7406\u5bc6\u96c6\u578b\u9886\u57df\u5c55\u793a\u51fa\u76f8\u4e92\u534f\u540c\u6548\u5e94\uff1b\u901a\u8fc7\u6743\u91cd\u7a7a\u95f4\u51e0\u4f55\u3001\u6a21\u578b\u9884\u6d4b\u884c\u4e3a\u548c\u4fe1\u606f\u7ea6\u675f\u5206\u6790\u63ed\u793a\u4e86\u76f8\u4e92\u589e\u76ca\u7684\u5185\u90e8\u673a\u5236\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u591a\u9886\u57dfRLVR\u8bad\u7ec3\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u5206\u6790\uff0c\u8868\u660e\u8de8\u9886\u57df\u534f\u4f5c\u5177\u6709\u53ef\u884c\u6027\uff0c\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u95f4\u5b58\u5728\u534f\u540c\u6548\u5e94\uff0c\u4e3a\u6784\u5efa\u901a\u7528\u591a\u9886\u57df\u4e13\u5bb6\u6a21\u578b\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2602.12943", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.12943", "abs": "https://arxiv.org/abs/2602.12943", "authors": ["Osama Zafar", "Shaojie Zhan", "Tianxi Ji", "Erman Ayday"], "title": "Neighborhood Blending: A Lightweight Inference-Time Defense Against Membership Inference Attacks", "comment": null, "summary": "In recent years, the widespread adoption of Machine Learning as a Service (MLaaS), particularly in sensitive environments, has raised considerable privacy concerns. Of particular importance are membership inference attacks (MIAs), which exploit behavioral discrepancies between training and non-training data to determine whether a specific record was included in the model's training set, thereby presenting significant privacy risks. Although existing defenses, such as adversarial regularization, DP-SGD, and MemGuard, assist in mitigating these threats, they often entail trade-offs such as compromising utility, increased computational requirements, or inconsistent protection against diverse attack vectors.\n  In this paper, we introduce a novel inference-time defense mechanism called Neighborhood Blending, which mitigates MIAs without retraining the model or incurring significant computational overhead. Our approach operates post-training by smoothing the model's confidence outputs based on the neighborhood of a queried sample. By averaging predictions from similar training samples selected using differentially private sampling, our method establishes a consistent confidence pattern, rendering members and non-members indistinguishable to an adversary while maintaining high utility. Significantly, Neighborhood Blending maintains label integrity (zero label loss) and ensures high utility through an adaptive, \"pay-as-you-go\" distortion strategy. It is a model-agnostic approach that offers a practical, lightweight solution that enhances privacy without sacrificing model utility. Through extensive experiments across diverse datasets and models, we demonstrate that our defense significantly reduces MIA success rates while preserving model performance, outperforming existing post-hoc defenses like MemGuard and training-time techniques like DP-SGD in terms of utility retention.", "AI": {"tldr": "\u63d0\u51faNeighborhood Blending\u9632\u5fa1\u65b9\u6cd5\uff0c\u901a\u8fc7\u67e5\u8be2\u6837\u672c\u90bb\u57df\u7684\u5dee\u5206\u9690\u79c1\u91c7\u6837\u5e73\u6ed1\u6a21\u578b\u7f6e\u4fe1\u5ea6\u8f93\u51fa\uff0c\u5728\u63a8\u7406\u9636\u6bb5\u62b5\u5fa1\u6210\u5458\u63a8\u7406\u653b\u51fb\uff0c\u4fdd\u6301\u96f6\u6807\u7b7e\u635f\u5931\u548c\u9ad8\u5b9e\u7528\u6027\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5373\u670d\u52a1(MLaaS)\u5728\u654f\u611f\u73af\u5883\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u5f15\u53d1\u4e86\u9690\u79c1\u62c5\u5fe7\uff0c\u7279\u522b\u662f\u6210\u5458\u63a8\u7406\u653b\u51fb(MIAs)\u80fd\u591f\u5224\u65ad\u7279\u5b9a\u8bb0\u5f55\u662f\u5426\u5728\u8bad\u7ec3\u96c6\u4e2d\u3002\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5982\u5bf9\u6297\u6b63\u5219\u5316\u3001DP-SGD\u548cMemGuard\u5b58\u5728\u5b9e\u7528\u6027\u964d\u4f4e\u3001\u8ba1\u7b97\u5f00\u9500\u5927\u6216\u4fdd\u62a4\u4e0d\u4e00\u81f4\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faNeighborhood Blending\u63a8\u7406\u65f6\u9632\u5fa1\u673a\u5236\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002\u901a\u8fc7\u5dee\u5206\u9690\u79c1\u91c7\u6837\u9009\u62e9\u67e5\u8be2\u6837\u672c\u7684\u76f8\u4f3c\u8bad\u7ec3\u6837\u672c\uff0c\u5e73\u5747\u8fd9\u4e9b\u6837\u672c\u7684\u9884\u6d4b\u7ed3\u679c\u6765\u5e73\u6ed1\u6a21\u578b\u7f6e\u4fe1\u5ea6\u8f93\u51fa\uff0c\u5efa\u7acb\u4e00\u81f4\u7684\u7f6e\u4fe1\u5ea6\u6a21\u5f0f\uff0c\u4f7f\u6210\u5458\u548c\u975e\u6210\u5458\u5bf9\u653b\u51fb\u8005\u4e0d\u53ef\u533a\u5206\u3002\u91c7\u7528\u81ea\u9002\u5e94\"\u6309\u9700\u4ed8\u8d39\"\u5931\u771f\u7b56\u7565\u4fdd\u6301\u6807\u7b7e\u5b8c\u6574\u6027\u548c\u9ad8\u5b9e\u7528\u6027\u3002", "result": "\u901a\u8fc7\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86MIA\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\u3002\u5728\u5b9e\u7528\u6027\u4fdd\u7559\u65b9\u9762\u4f18\u4e8eMemGuard\u7b49\u540e\u5904\u7406\u9632\u5fa1\u65b9\u6cd5\u548cDP-SGD\u7b49\u8bad\u7ec3\u65f6\u6280\u672f\u3002", "conclusion": "Neighborhood Blending\u63d0\u4f9b\u4e86\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u3001\u8f7b\u91cf\u7ea7\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4e0d\u727a\u7272\u6a21\u578b\u5b9e\u7528\u6027\u7684\u60c5\u51b5\u4e0b\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4\uff0c\u662f\u62b5\u5fa1\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u6709\u6548\u63a8\u7406\u65f6\u9632\u5fa1\u673a\u5236\u3002"}}
{"id": "2602.12586", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12586", "abs": "https://arxiv.org/abs/2602.12586", "authors": ["Joshua Ong Jun Leang", "Yu Zhao", "Mihaela C\u0103t\u0103lina Stoian", "Wenda Li", "Shay B. Cohen", "Eleonora Giunchiglia"], "title": "Can I Have Your Order? Monte-Carlo Tree Search for Slot Filling Ordering in Diffusion Language Models", "comment": "8 pages, preprint", "summary": "While plan-and-infill decoding in Masked Diffusion Models (MDMs) shows promise for mathematical and code reasoning, performance remains highly sensitive to slot infilling order, often yielding substantial output variance. We introduce McDiffuSE, a framework that formulates slot selection as decision making and optimises infilling orders through Monte Carlo Tree Search (MCTS). McDiffuSE uses look-ahead simulations to evaluate partial completions before commitment, systematically exploring the combinatorial space of generation orders. Experiments show an average improvement of 3.2% over autoregressive baselines and 8.0% over baseline plan-and-infill, with notable gains of 19.5% on MBPP and 4.9% on MATH500. Our analysis reveals that while McDiffuSE predominantly follows sequential ordering, incorporating non-sequential generation is essential for maximising performance. We observe that larger exploration constants, rather than increased simulations, are necessary to overcome model confidence biases and discover effective orderings. These findings establish MCTS-based planning as an effective approach for enhancing generation quality in MDMs.", "AI": {"tldr": "McDiffuSE\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4f18\u5316\u63a9\u7801\u6269\u6563\u6a21\u578b\u4e2d\u7684\u69fd\u4f4d\u586b\u5145\u987a\u5e8f\uff0c\u901a\u8fc7\u524d\u77bb\u6a21\u62df\u8bc4\u4f30\u90e8\u5206\u5b8c\u6210\u60c5\u51b5\uff0c\u5728\u6570\u5b66\u548c\u4ee3\u7801\u63a8\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u57fa\u4e8e\u63a9\u7801\u6269\u6563\u6a21\u578b\u7684\u8ba1\u5212-\u586b\u5145\u89e3\u7801\u5728\u6570\u5b66\u548c\u4ee3\u7801\u63a8\u7406\u4e2d\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u6027\u80fd\u5bf9\u69fd\u4f4d\u586b\u5145\u987a\u5e8f\u9ad8\u5ea6\u654f\u611f\uff0c\u5bfc\u81f4\u8f93\u51fa\u65b9\u5dee\u5927\u3002\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\u6765\u4f18\u5316\u586b\u5145\u987a\u5e8f\u4ee5\u63d0\u5347\u751f\u6210\u8d28\u91cf\u3002", "method": "McDiffuSE\u6846\u67b6\u5c06\u69fd\u4f4d\u9009\u62e9\u5efa\u6a21\u4e3a\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4f18\u5316\u586b\u5145\u987a\u5e8f\u3002\u901a\u8fc7\u524d\u77bb\u6a21\u62df\u8bc4\u4f30\u90e8\u5206\u5b8c\u6210\u60c5\u51b5\uff0c\u7cfb\u7edf\u63a2\u7d22\u751f\u6210\u987a\u5e8f\u7684\u7ec4\u5408\u7a7a\u95f4\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5e73\u5747\u6bd4\u81ea\u56de\u5f52\u57fa\u7ebf\u63d0\u53473.2%\uff0c\u6bd4\u57fa\u7ebf\u8ba1\u5212-\u586b\u5145\u65b9\u6cd5\u63d0\u53478.0%\u3002\u5728MBPP\u4efb\u52a1\u4e0a\u63d0\u534719.5%\uff0c\u5728MATH500\u4e0a\u63d0\u53474.9%\u3002\u5206\u6790\u8868\u660e\u867d\u7136\u4e3b\u8981\u9075\u5faa\u987a\u5e8f\u751f\u6210\uff0c\u4f46\u975e\u987a\u5e8f\u751f\u6210\u5bf9\u6700\u5927\u5316\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u57fa\u4e8eMCTS\u7684\u89c4\u5212\u662f\u63d0\u5347\u63a9\u7801\u6269\u6563\u6a21\u578b\u751f\u6210\u8d28\u91cf\u7684\u6709\u6548\u65b9\u6cd5\u3002\u7814\u7a76\u53d1\u73b0\u66f4\u5927\u7684\u63a2\u7d22\u5e38\u6570\uff08\u800c\u975e\u66f4\u591a\u6a21\u62df\uff09\u5bf9\u4e8e\u514b\u670d\u6a21\u578b\u7f6e\u4fe1\u5ea6\u504f\u5dee\u548c\u53d1\u73b0\u6709\u6548\u987a\u5e8f\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2602.12617", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12617", "abs": "https://arxiv.org/abs/2602.12617", "authors": ["Modi Jin", "Yiming Zhang", "Boyuan Sun", "Dingwen Zhang", "MingMing Cheng", "Qibin Hou"], "title": "GeoAgent: Learning to Geolocate Everywhere with Reinforced Geographic Characteristics", "comment": null, "summary": "This paper presents GeoAgent, a model capable of reasoning closely with humans and deriving fine-grained address conclusions. Previous RL-based methods have achieved breakthroughs in performance and interpretability but still remain concerns because of their reliance on AI-generated chain-of-thought (CoT) data and training strategies, which conflict with geographic characteristics. To address these issues, we first introduce GeoSeek, a new geolocation dataset comprising CoT data annotated by geographic experts and professional players. We further thoroughly explore the inherent characteristics of geographic tasks and propose a geo-similarity reward and a consistency reward assessed by a consistency agent to assist training. This encourages the model to converge towards correct answers from a geographic perspective while ensuring the integrity and consistency of its reasoning process. Experimental results show that GeoAgent outperforms existing methods and a series of general VLLMs across multiple grains, while generating reasoning that closely aligns with humans.", "AI": {"tldr": "GeoAgent\u662f\u4e00\u4e2a\u80fd\u591f\u4e0e\u4eba\u7c7b\u7d27\u5bc6\u63a8\u7406\u5e76\u5f97\u51fa\u7ec6\u7c92\u5ea6\u5730\u5740\u7ed3\u8bba\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u4e13\u5bb6\u6807\u6ce8\u7684\u5730\u7406\u5b9a\u4f4d\u6570\u636e\u96c6\u548c\u5730\u7406\u76f8\u4f3c\u6027\u5956\u52b1\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u73b0\u6709RL\u65b9\u6cd5\u4f9d\u8d56AI\u751f\u6210\u601d\u7ef4\u94fe\u6570\u636e\u4e0e\u5730\u7406\u7279\u6027\u51b2\u7a81\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\u867d\u7136\u5728\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u7a81\u7834\uff0c\u4f46\u7531\u4e8e\u4f9d\u8d56AI\u751f\u6210\u7684\u601d\u7ef4\u94fe\u6570\u636e\u548c\u8bad\u7ec3\u7b56\u7565\uff0c\u4e0e\u5730\u7406\u7279\u6027\u5b58\u5728\u51b2\u7a81\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "1. \u5f15\u5165GeoSeek\u6570\u636e\u96c6\uff0c\u5305\u542b\u5730\u7406\u4e13\u5bb6\u548c\u4e13\u4e1a\u73a9\u5bb6\u6807\u6ce8\u7684\u601d\u7ef4\u94fe\u6570\u636e\uff1b2. \u63d0\u51fa\u5730\u7406\u76f8\u4f3c\u6027\u5956\u52b1\u548c\u4e00\u81f4\u6027\u5956\u52b1\uff08\u7531\u4e00\u81f4\u6027\u667a\u80fd\u4f53\u8bc4\u4f30\uff09\uff0c\u9f13\u52b1\u6a21\u578b\u4ece\u5730\u7406\u89d2\u5ea6\u6536\u655b\u5230\u6b63\u786e\u7b54\u6848\uff0c\u540c\u65f6\u786e\u4fdd\u63a8\u7406\u8fc7\u7a0b\u7684\u5b8c\u6574\u6027\u548c\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGeoAgent\u5728\u591a\u4e2a\u7c92\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u548c\u4e00\u7cfb\u5217\u901a\u7528VLLMs\uff0c\u540c\u65f6\u751f\u6210\u7684\u63a8\u7406\u8fc7\u7a0b\u4e0e\u4eba\u7c7b\u601d\u7ef4\u7d27\u5bc6\u5951\u5408\u3002", "conclusion": "GeoAgent\u901a\u8fc7\u4e13\u5bb6\u6807\u6ce8\u6570\u636e\u548c\u5730\u7406\u7279\u6027\u5956\u52b1\u673a\u5236\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5730\u7406\u4efb\u52a1\u4e2d\u7684\u7279\u6b8a\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u4e0e\u4eba\u7c7b\u63a8\u7406\u7d27\u5bc6\u5bf9\u9f50\u7684\u9ad8\u6027\u80fd\u5730\u7406\u5b9a\u4f4d\u6a21\u578b\u3002"}}
{"id": "2602.13148", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.13148", "abs": "https://arxiv.org/abs/2602.13148", "authors": ["Parsa Sadri Sinaki", "Zainab Ahmad", "Wentao Xie", "Merlijn Sebrechts", "Jimmy Kj\u00e4llman", "Lachlan J. Gunn"], "title": "TrustMee: Self-Verifying Remote Attestation Evidence", "comment": "17 pages, 12 figures", "summary": "Hardware-secured remote attestation is essential to establishing trust in the integrity of confidential virtual machines (cVMs), but is difficult to use in practice because verifying attestation evidence requires the use of hardware-specific cryptographic logic. This increases both maintenance costs and the verifiers' trusted computing base. We introduce the concept of self-verifying remote attestation evidence. Each attestation bundle includes verification logic as a WebAssembly component signed by a trusted party. This approach transforms evidence verification into a standard code-signing problem: the verifier checks the signature on the embedded logic and then executes it to validate the evidence. As a result, verifiers can validate attestation evidence without any platform-specific knowledge. We implement this concept as TrustMee, a platform-agnostic verification driver for the Trustee framework. We demonstrate its functionality with self-verifying evidence for AMD SEV-SNP and Intel TDX attestations, producing attestation claims in the standard EAT Attestation Result (EAR) format.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u81ea\u9a8c\u8bc1\u8fdc\u7a0b\u8bc1\u660e\u8bc1\u636e\u6982\u5ff5\uff0c\u5c06\u9a8c\u8bc1\u903b\u8f91\u5d4c\u5165WebAssembly\u7ec4\u4ef6\u4e2d\uff0c\u4f7f\u9a8c\u8bc1\u8005\u65e0\u9700\u5e73\u53f0\u7279\u5b9a\u77e5\u8bc6\u5373\u53ef\u9a8c\u8bc1\u673a\u5bc6\u865a\u62df\u673a\u5b8c\u6574\u6027\u3002", "motivation": "\u786c\u4ef6\u5b89\u5168\u7684\u8fdc\u7a0b\u8bc1\u660e\u5bf9\u4e8e\u5efa\u7acb\u673a\u5bc6\u865a\u62df\u673a\u5b8c\u6574\u6027\u4fe1\u4efb\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b9e\u9645\u4f7f\u7528\u56f0\u96be\uff0c\u56e0\u4e3a\u9a8c\u8bc1\u8bc1\u660e\u8bc1\u636e\u9700\u8981\u786c\u4ef6\u7279\u5b9a\u7684\u52a0\u5bc6\u903b\u8f91\uff0c\u589e\u52a0\u4e86\u7ef4\u62a4\u6210\u672c\u548c\u9a8c\u8bc1\u8005\u7684\u53ef\u4fe1\u8ba1\u7b97\u57fa\u3002", "method": "\u5f15\u5165\u81ea\u9a8c\u8bc1\u8fdc\u7a0b\u8bc1\u660e\u8bc1\u636e\u6982\u5ff5\uff0c\u6bcf\u4e2a\u8bc1\u660e\u5305\u5305\u542b\u7531\u53ef\u4fe1\u65b9\u7b7e\u540d\u7684WebAssembly\u7ec4\u4ef6\u4f5c\u4e3a\u9a8c\u8bc1\u903b\u8f91\uff0c\u5c06\u8bc1\u636e\u9a8c\u8bc1\u8f6c\u5316\u4e3a\u6807\u51c6\u4ee3\u7801\u7b7e\u540d\u95ee\u9898\uff1a\u9a8c\u8bc1\u8005\u68c0\u67e5\u5d4c\u5165\u5f0f\u903b\u8f91\u7684\u7b7e\u540d\uff0c\u7136\u540e\u6267\u884c\u5b83\u4ee5\u9a8c\u8bc1\u8bc1\u636e\u3002", "result": "\u5b9e\u73b0TrustMee\u4f5c\u4e3a\u5e73\u53f0\u65e0\u5173\u7684\u9a8c\u8bc1\u9a71\u52a8\u7a0b\u5e8f\uff0c\u4e3aAMD SEV-SNP\u548cIntel TDX\u8bc1\u660e\u751f\u6210\u81ea\u9a8c\u8bc1\u8bc1\u636e\uff0c\u5e76\u4ee5\u6807\u51c6EAT\u8bc1\u660e\u7ed3\u679c\u683c\u5f0f\u751f\u6210\u8bc1\u660e\u58f0\u660e\u3002", "conclusion": "\u81ea\u9a8c\u8bc1\u8fdc\u7a0b\u8bc1\u660e\u8bc1\u636e\u65b9\u6cd5\u4f7f\u9a8c\u8bc1\u8005\u65e0\u9700\u5e73\u53f0\u7279\u5b9a\u77e5\u8bc6\u5373\u53ef\u9a8c\u8bc1\u8bc1\u660e\u8bc1\u636e\uff0c\u964d\u4f4e\u4e86\u7ef4\u62a4\u6210\u672c\u548c\u53ef\u4fe1\u8ba1\u7b97\u57fa\u8981\u6c42\uff0c\u63d0\u9ad8\u4e86\u8fdc\u7a0b\u8bc1\u660e\u7684\u5b9e\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2602.12631", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.12631", "abs": "https://arxiv.org/abs/2602.12631", "authors": ["Jackie Baek", "Yaopeng Fu", "Will Ma", "Tianyi Peng"], "title": "AI Agents for Inventory Control: Human-LLM-OR Complementarity", "comment": null, "summary": "Inventory control is a fundamental operations problem in which ordering decisions are traditionally guided by theoretically grounded operations research (OR) algorithms. However, such algorithms often rely on rigid modeling assumptions and can perform poorly when demand distributions shift or relevant contextual information is unavailable. Recent advances in large language models (LLMs) have generated interest in AI agents that can reason flexibly and incorporate rich contextual signals, but it remains unclear how best to incorporate LLM-based methods into traditional decision-making pipelines.\n  We study how OR algorithms, LLMs, and humans can interact and complement each other in a multi-period inventory control setting. We construct InventoryBench, a benchmark of over 1,000 inventory instances spanning both synthetic and real-world demand data, designed to stress-test decision rules under demand shifts, seasonality, and uncertain lead times. Through this benchmark, we find that OR-augmented LLM methods outperform either method in isolation, suggesting that these methods are complementary rather than substitutes.\n  We further investigate the role of humans through a controlled classroom experiment that embeds LLM recommendations into a human-in-the-loop decision pipeline. Contrary to prior findings that human-AI collaboration can degrade performance, we show that, on average, human-AI teams achieve higher profits than either humans or AI agents operating alone. Beyond this population-level finding, we formalize an individual-level complementarity effect and derive a distribution-free lower bound on the fraction of individuals who benefit from AI collaboration; empirically, we find this fraction to be substantial.", "AI": {"tldr": "LLM\u589e\u5f3a\u7684\u8fd0\u7b79\u5b66\u7b97\u6cd5\u5728\u5e93\u5b58\u63a7\u5236\u4e2d\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u4efb\u4e00\u79cd\u65b9\u6cd5\uff0c\u4eba\u673a\u534f\u4f5c\u56e2\u961f\u6bd4\u5355\u72ec\u7684\u4eba\u7c7b\u6216AI\u8868\u73b0\u66f4\u597d\uff0c\u5b58\u5728\u663e\u8457\u7684\u4e2a\u4f53\u4e92\u8865\u6548\u5e94", "motivation": "\u4f20\u7edf\u8fd0\u7b79\u5b66\u7b97\u6cd5\u4f9d\u8d56\u521a\u6027\u5efa\u6a21\u5047\u8bbe\uff0c\u5728\u9700\u6c42\u5206\u5e03\u53d8\u5316\u6216\u7f3a\u4e4f\u76f8\u5173\u4e0a\u4e0b\u6587\u4fe1\u606f\u65f6\u8868\u73b0\u4e0d\u4f73\u3002LLM\u80fd\u591f\u7075\u6d3b\u63a8\u7406\u5e76\u6574\u5408\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u4fe1\u53f7\uff0c\u4f46\u5982\u4f55\u5c06LLM\u65b9\u6cd5\u6574\u5408\u5230\u4f20\u7edf\u51b3\u7b56\u6d41\u7a0b\u4e2d\u4ecd\u4e0d\u660e\u786e\u3002\u7814\u7a76\u63a2\u7d22\u8fd0\u7b79\u5b66\u7b97\u6cd5\u3001LLM\u548c\u4eba\u7c7b\u5982\u4f55\u4e92\u52a8\u4e92\u8865", "method": "\u6784\u5efaInventoryBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b1000\u591a\u4e2a\u5e93\u5b58\u5b9e\u4f8b\uff0c\u6db5\u76d6\u5408\u6210\u548c\u771f\u5b9e\u9700\u6c42\u6570\u636e\uff0c\u6d4b\u8bd5\u9700\u6c42\u53d8\u5316\u3001\u5b63\u8282\u6027\u548c\u4e0d\u786e\u5b9a\u4ea4\u8d27\u671f\u4e0b\u7684\u51b3\u7b56\u89c4\u5219\u3002\u901a\u8fc7\u8bfe\u5802\u5b9e\u9a8c\u7814\u7a76\u4eba\u7c7b\u5728\u51b3\u7b56\u6d41\u7a0b\u4e2d\u7684\u4f5c\u7528\uff0c\u5c06LLM\u63a8\u8350\u5d4c\u5165\u4eba\u673a\u534f\u4f5c\u51b3\u7b56\u7ba1\u9053", "result": "\u8fd0\u7b79\u5b66\u589e\u5f3a\u7684LLM\u65b9\u6cd5\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u4efb\u4e00\u79cd\u65b9\u6cd5\uff0c\u8868\u660e\u8fd9\u4e9b\u65b9\u6cd5\u662f\u4e92\u8865\u800c\u975e\u66ff\u4ee3\u3002\u4eba\u673a\u534f\u4f5c\u56e2\u961f\u5e73\u5747\u83b7\u5f97\u6bd4\u5355\u72ec\u4eba\u7c7b\u6216AI\u66f4\u9ad8\u7684\u5229\u6da6\u3002\u5f62\u5f0f\u5316\u4e86\u4e2a\u4f53\u5c42\u9762\u7684\u4e92\u8865\u6548\u5e94\uff0c\u63a8\u5bfc\u51fa\u5206\u5e03\u65e0\u5173\u7684\u4e0b\u754c\uff0c\u5b9e\u8bc1\u53d1\u73b0\u53d7\u76ca\u4e8eAI\u534f\u4f5c\u7684\u4e2a\u4f53\u6bd4\u4f8b\u5f88\u5927", "conclusion": "\u8fd0\u7b79\u5b66\u7b97\u6cd5\u3001LLM\u548c\u4eba\u7c7b\u5728\u5e93\u5b58\u63a7\u5236\u4e2d\u5177\u6709\u4e92\u8865\u6027\uff0c\u8fd0\u7b79\u5b66\u589e\u5f3a\u7684LLM\u65b9\u6cd5\u8868\u73b0\u6700\u4f73\uff0c\u4eba\u673a\u534f\u4f5c\u80fd\u63d0\u9ad8\u51b3\u7b56\u8d28\u91cf\uff0c\u5b58\u5728\u663e\u8457\u7684\u4e2a\u4f53\u4e92\u8865\u6548\u5e94\uff0c\u4e3a\u6574\u5408\u4f20\u7edf\u7b97\u6cd5\u4e0eAI\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301"}}
{"id": "2602.12662", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.12662", "abs": "https://arxiv.org/abs/2602.12662", "authors": ["Ruihan Yang", "Fanghua Ye", "Xiang We", "Ruoqing Zhao", "Kang Luo", "Xinbo Xu", "Bo Zhao", "Ruotian Ma", "Shanyi Wang", "Zhaopeng Tu", "Xiaolong Li", "Deqing Yang", "Linus"], "title": "Think Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed as autonomous agents for multi-turn decision-making tasks. However, current agents typically rely on fixed cognitive patterns: non-thinking models generate immediate responses, while thinking models engage in deep reasoning uniformly. This rigidity is inefficient for long-horizon tasks, where cognitive demands vary significantly from step to step, with some requiring strategic planning and others only routine execution. In this paper, we introduce CogRouter, a framework that trains agents to dynamically adapt cognitive depth at each step. Grounded in ACT-R theory, we design four hierarchical cognitive levels ranging from instinctive responses to strategic planning. Our two-stage training approach includes Cognition-aware Supervised Fine-tuning (CoSFT) to instill stable level-specific patterns, and Cognition-aware Policy Optimization (CoPO) for step-level credit assignment via confidence-aware advantage reweighting. The key insight is that appropriate cognitive depth should maximize the confidence of the resulting action. Experiments on ALFWorld and ScienceWorld demonstrate that CogRouter achieves state-of-the-art performance with superior efficiency. With Qwen2.5-7B, it reaches an 82.3% success rate, outperforming GPT-4o (+40.3%), OpenAI-o3 (+18.3%), and GRPO (+14.0%), while using 62% fewer tokens.", "AI": {"tldr": "CogRouter\u6846\u67b6\u8bad\u7ec3\u667a\u80fd\u4f53\u52a8\u6001\u8c03\u6574\u8ba4\u77e5\u6df1\u5ea6\uff0c\u901a\u8fc7\u56db\u5c42\u8ba4\u77e5\u5c42\u6b21\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u5728\u957f\u89c6\u91ce\u4efb\u52a1\u4e2d\u5b9e\u73b0\u9ad8\u6548\u51b3\u7b56\uff0c\u663e\u8457\u63d0\u5347\u6210\u529f\u7387\u5e76\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u91c7\u7528\u56fa\u5b9a\u7684\u8ba4\u77e5\u6a21\u5f0f\uff1a\u975e\u601d\u8003\u6a21\u578b\u751f\u6210\u5373\u65f6\u54cd\u5e94\uff0c\u601d\u8003\u6a21\u578b\u5219\u7edf\u4e00\u8fdb\u884c\u6df1\u5ea6\u63a8\u7406\u3002\u8fd9\u79cd\u521a\u6027\u5728\u957f\u89c6\u91ce\u4efb\u52a1\u4e2d\u6548\u7387\u4f4e\u4e0b\uff0c\u56e0\u4e3a\u4e0d\u540c\u6b65\u9aa4\u7684\u8ba4\u77e5\u9700\u6c42\u5dee\u5f02\u5f88\u5927\uff0c\u6709\u4e9b\u9700\u8981\u6218\u7565\u89c4\u5212\uff0c\u6709\u4e9b\u53ea\u9700\u5e38\u89c4\u6267\u884c\u3002", "method": "\u57fa\u4e8eACT-R\u7406\u8bba\u8bbe\u8ba1\u56db\u4e2a\u5c42\u6b21\u5316\u8ba4\u77e5\u7ea7\u522b\uff08\u4ece\u672c\u80fd\u53cd\u5e94\u5230\u6218\u7565\u89c4\u5212\uff09\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u8ba4\u77e5\u611f\u77e5\u76d1\u7763\u5fae\u8c03\uff08CoSFT\uff09\u5efa\u7acb\u7a33\u5b9a\u7684\u7ea7\u522b\u7279\u5b9a\u6a21\u5f0f\uff0c\u8ba4\u77e5\u611f\u77e5\u7b56\u7565\u4f18\u5316\uff08CoPO\uff09\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u611f\u77e5\u4f18\u52bf\u91cd\u52a0\u6743\u8fdb\u884c\u6b65\u9aa4\u7ea7\u4fe1\u7528\u5206\u914d\u3002\u6838\u5fc3\u6d1e\u5bdf\u662f\u9002\u5f53\u7684\u8ba4\u77e5\u6df1\u5ea6\u5e94\u6700\u5927\u5316\u6700\u7ec8\u52a8\u4f5c\u7684\u7f6e\u4fe1\u5ea6\u3002", "result": "\u5728ALFWorld\u548cScienceWorld\u5b9e\u9a8c\u4e2d\uff0cCogRouter\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u4e14\u6548\u7387\u4f18\u8d8a\u3002\u4f7f\u7528Qwen2.5-7B\u6a21\u578b\uff0c\u8fbe\u523082.3%\u6210\u529f\u7387\uff0c\u4f18\u4e8eGPT-4o\uff08+40.3%\uff09\u3001OpenAI-o3\uff08+18.3%\uff09\u548cGRPO\uff08+14.0%\uff09\uff0c\u540c\u65f6\u51cf\u5c1162%\u7684token\u4f7f\u7528\u91cf\u3002", "conclusion": "CogRouter\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u8ba4\u77e5\u6df1\u5ea6\uff0c\u5728\u957f\u89c6\u91ce\u51b3\u7b56\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6027\u80fd\u4e0e\u6548\u7387\u7684\u5e73\u8861\uff0c\u4e3aLLM\u667a\u80fd\u4f53\u7684\u8ba4\u77e5\u7075\u6d3b\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2602.12665", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12665", "abs": "https://arxiv.org/abs/2602.12665", "authors": ["Na\u00efm Es-sebbani", "Esteban Marquer", "Yakoub Salhi", "Zied Bouraoui"], "title": "Evaluating Robustness of Reasoning Models on Parameterized Logical Problems", "comment": null, "summary": "Logic provides a controlled testbed for evaluating LLM-based reasoners, yet standard SAT-style benchmarks often conflate surface difficulty (length, wording, clause order) with the structural phenomena that actually determine satisfiability. We introduce a diagnostic benchmark for 2-SAT built from parameterized families of structured 2--CNF formulas, where satisfiability is characterized by the implication graph and can be tuned along interpretable axes. Our generators isolate distinct competencies and failure modes: (i) contradiction-cycle UNSAT cores with controllable size and imbalance, (ii) SAT instances with a prescribed fraction of free variables to control solution multiplicity, (iii) planted backbones that modulate propagation, (iv) late bridge clauses that couple otherwise monotone regions to probe sensitivity to ordering and revision, and (v) symmetry/duplication variants that test abstraction under renaming and redundant structure. We evaluate LLM-based reasoners on decision accuracy and assignment validity, and quantify robustness under semantics-preserving perturbations such as clause reordering, filler clauses, and variable renaming. Across models, we observe sharp performance transitions under targeted structural interventions even when surface statistics are held fixed, revealing brittleness regimes that are invisible to aggregate SAT accuracy.", "AI": {"tldr": "\u8be5\u7814\u7a76\u521b\u5efa\u4e86\u4e00\u4e2a\u8bca\u65ad\u60272-SAT\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u516c\u5f0f\u5bb6\u65cf\u5206\u79bb\u8868\u9762\u96be\u5ea6\u4e0e\u7ed3\u6784\u73b0\u8c61\uff0c\u63ed\u793aLLM\u63a8\u7406\u5668\u7684\u7279\u5b9a\u80fd\u529b\u4e0e\u5931\u8d25\u6a21\u5f0f", "motivation": "\u6807\u51c6SAT\u57fa\u51c6\u6d4b\u8bd5\u5e38\u5e38\u6df7\u6dc6\u8868\u9762\u96be\u5ea6\uff08\u957f\u5ea6\u3001\u63aa\u8f9e\u3001\u5b50\u53e5\u987a\u5e8f\uff09\u4e0e\u51b3\u5b9a\u53ef\u6ee1\u8db3\u6027\u7684\u5b9e\u9645\u7ed3\u6784\u73b0\u8c61\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u8bca\u65ad\u5de5\u5177\u6765\u8bc4\u4f30LLM\u63a8\u7406\u5668\u7684\u771f\u5b9e\u80fd\u529b", "method": "\u6784\u5efa\u57fa\u4e8e\u53c2\u6570\u5316\u7ed3\u6784\u53162-CNF\u516c\u5f0f\u7684\u8bca\u65ad\u57fa\u51c6\uff0c\u901a\u8fc7\u4e94\u79cd\u751f\u6210\u5668\u9694\u79bb\u4e0d\u540c\u80fd\u529b\uff1a\u77db\u76fe\u5faa\u73afUNSAT\u6838\u5fc3\u3001\u63a7\u5236\u89e3\u591a\u6837\u6027\u7684SAT\u5b9e\u4f8b\u3001\u690d\u5165\u9aa8\u5e72\u3001\u5ef6\u8fdf\u6865\u63a5\u5b50\u53e5\u3001\u5bf9\u79f0/\u91cd\u590d\u53d8\u4f53", "result": "\u8bc4\u4f30\u663e\u793aLLM\u63a8\u7406\u5668\u5728\u76ee\u6807\u7ed3\u6784\u5e72\u9884\u4e0b\u8868\u73b0\u51fa\u6025\u5267\u7684\u6027\u80fd\u8f6c\u53d8\uff0c\u5373\u4f7f\u8868\u9762\u7edf\u8ba1\u7279\u5f81\u4fdd\u6301\u4e0d\u53d8\uff0c\u63ed\u793a\u4e86\u5728\u805a\u5408SAT\u51c6\u786e\u7387\u4e2d\u4e0d\u53ef\u89c1\u7684\u8106\u5f31\u6027\u533a\u57df", "conclusion": "\u8be5\u8bca\u65ad\u57fa\u51c6\u80fd\u591f\u63ed\u793aLLM\u63a8\u7406\u5668\u5728\u7279\u5b9a\u7ed3\u6784\u73b0\u8c61\u4e0b\u7684\u80fd\u529b\u8fb9\u754c\u548c\u5931\u8d25\u6a21\u5f0f\uff0c\u4e3a\u66f4\u7cbe\u7ec6\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5de5\u5177\uff0c\u8868\u660e\u8868\u9762\u7edf\u8ba1\u7279\u5f81\u4e0d\u8db3\u4ee5\u53cd\u6620\u63a8\u7406\u5668\u7684\u771f\u5b9e\u9c81\u68d2\u6027"}}
{"id": "2602.12748", "categories": ["cs.AI", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.12748", "abs": "https://arxiv.org/abs/2602.12748", "authors": ["Tobias Labarta", "Nhi Hoang", "Maximilian Dreyer", "Jim Berend", "Oleg Hein", "Jackie Ma", "Wojciech Samek", "Sebastian Lapuschkin"], "title": "X-SYS: A Reference Architecture for Interactive Explanation Systems", "comment": "18 pages, 8 figures", "summary": "The explainable AI (XAI) research community has proposed numerous technical methods, yet deploying explainability as systems remains challenging: Interactive explanation systems require both suitable algorithms and system capabilities that maintain explanation usability across repeated queries, evolving models and data, and governance constraints. We argue that operationalizing XAI requires treating explainability as an information systems problem where user interaction demands induce specific system requirements. We introduce X-SYS, a reference architecture for interactive explanation systems, that guides (X)AI researchers, developers and practitioners in connecting interactive explanation user interfaces (XUI) with system capabilities. X-SYS organizes around four quality attributes named STAR (scalability, traceability, responsiveness, and adaptability), and specifies a five-component decomposition (XUI Services, Explanation Services, Model Services, Data Services, Orchestration and Governance). It maps interaction patterns to system capabilities to decouple user interface evolution from backend computation. We implement X-SYS through SemanticLens, a system for semantic search and activation steering in vision-language models. SemanticLens demonstrates how contract-based service boundaries enable independent evolution, offline/online separation ensures responsiveness, and persistent state management supports traceability. Together, this work provides a reusable blueprint and concrete instantiation for interactive explanation systems supporting end-to-end design under operational constraints.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faX-SYS\u53c2\u8003\u67b6\u6784\uff0c\u5c06\u53ef\u89e3\u91caAI\u7cfb\u7edf\u5316\uff0c\u901a\u8fc7STAR\u8d28\u91cf\u5c5e\u6027\u548c\u4e94\u7ec4\u4ef6\u5206\u89e3\u89e3\u51b3\u4ea4\u4e92\u5f0f\u89e3\u91ca\u7cfb\u7edf\u7684\u90e8\u7f72\u6311\u6218\u3002", "motivation": "\u5f53\u524d\u53ef\u89e3\u91caAI\u7814\u7a76\u63d0\u51fa\u4e86\u8bb8\u591a\u6280\u672f\u65b9\u6cd5\uff0c\u4f46\u5c06\u53ef\u89e3\u91ca\u6027\u90e8\u7f72\u4e3a\u7cfb\u7edf\u4ecd\u7136\u9762\u4e34\u6311\u6218\u3002\u4ea4\u4e92\u5f0f\u89e3\u91ca\u7cfb\u7edf\u9700\u8981\u5408\u9002\u7684\u7b97\u6cd5\u548c\u7cfb\u7edf\u80fd\u529b\uff0c\u4ee5\u5728\u91cd\u590d\u67e5\u8be2\u3001\u6a21\u578b\u548c\u6570\u636e\u6f14\u5316\u4ee5\u53ca\u6cbb\u7406\u7ea6\u675f\u4e0b\u4fdd\u6301\u89e3\u91ca\u53ef\u7528\u6027\u3002\u4f5c\u8005\u8ba4\u4e3a\uff0c\u5c06\u53ef\u89e3\u91caAI\u64cd\u4f5c\u5316\u9700\u8981\u5c06\u5176\u89c6\u4e3a\u4fe1\u606f\u7cfb\u7edf\u95ee\u9898\uff0c\u7528\u6237\u4ea4\u4e92\u9700\u6c42\u5f15\u53d1\u7279\u5b9a\u7684\u7cfb\u7edf\u8981\u6c42\u3002", "method": "\u63d0\u51faX-SYS\u53c2\u8003\u67b6\u6784\uff0c\u56f4\u7ed5\u56db\u4e2aSTAR\u8d28\u91cf\u5c5e\u6027\uff08\u53ef\u6269\u5c55\u6027\u3001\u53ef\u8ffd\u6eaf\u6027\u3001\u54cd\u5e94\u6027\u548c\u9002\u5e94\u6027\uff09\u7ec4\u7ec7\uff0c\u5e76\u6307\u5b9a\u4e94\u7ec4\u4ef6\u5206\u89e3\uff08XUI\u670d\u52a1\u3001\u89e3\u91ca\u670d\u52a1\u3001\u6a21\u578b\u670d\u52a1\u3001\u6570\u636e\u670d\u52a1\u3001\u7f16\u6392\u4e0e\u6cbb\u7406\uff09\u3002\u8be5\u67b6\u6784\u5c06\u4ea4\u4e92\u6a21\u5f0f\u6620\u5c04\u5230\u7cfb\u7edf\u80fd\u529b\uff0c\u5b9e\u73b0\u7528\u6237\u754c\u9762\u6f14\u8fdb\u4e0e\u540e\u7aef\u8ba1\u7b97\u7684\u89e3\u8026\u3002\u901a\u8fc7SemanticLens\u7cfb\u7edf\u5b9e\u73b0X-SYS\uff0c\u8be5\u7cfb\u7edf\u7528\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u641c\u7d22\u548c\u6fc0\u6d3b\u5f15\u5bfc\u3002", "result": "X-SYS\u67b6\u6784\u901a\u8fc7\u57fa\u4e8e\u5951\u7ea6\u7684\u670d\u52a1\u8fb9\u754c\u5b9e\u73b0\u72ec\u7acb\u6f14\u8fdb\uff0c\u79bb\u7ebf/\u5728\u7ebf\u5206\u79bb\u786e\u4fdd\u54cd\u5e94\u6027\uff0c\u6301\u4e45\u72b6\u6001\u7ba1\u7406\u652f\u6301\u53ef\u8ffd\u6eaf\u6027\u3002SemanticLens\u7cfb\u7edf\u5c55\u793a\u4e86\u8be5\u67b6\u6784\u7684\u5177\u4f53\u5b9e\u73b0\uff0c\u4e3a\u4ea4\u4e92\u5f0f\u89e3\u91ca\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u91cd\u7528\u7684\u84dd\u56fe\u548c\u5177\u4f53\u5b9e\u4f8b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4ea4\u4e92\u5f0f\u89e3\u91ca\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u91cd\u7528\u7684\u84dd\u56fe\u548c\u5177\u4f53\u5b9e\u73b0\uff0c\u652f\u6301\u5728\u64cd\u4f5c\u7ea6\u675f\u4e0b\u7684\u7aef\u5230\u7aef\u8bbe\u8ba1\uff0c\u5e2e\u52a9(X)AI\u7814\u7a76\u4eba\u5458\u3001\u5f00\u53d1\u8005\u548c\u4ece\u4e1a\u8005\u5c06\u4ea4\u4e92\u5f0f\u89e3\u91ca\u7528\u6237\u754c\u9762\u4e0e\u7cfb\u7edf\u80fd\u529b\u8fde\u63a5\u8d77\u6765\u3002"}}
{"id": "2602.12963", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12963", "abs": "https://arxiv.org/abs/2602.12963", "authors": ["Alfred Harwood", "Jose Faustino", "Alex Altair"], "title": "Information-theoretic analysis of world models in optimal reward maximizers", "comment": "28 pages, 0 figures. Not submitted to any conference yet", "summary": "An important question in the field of AI is the extent to which successful behaviour requires an internal representation of the world. In this work, we quantify the amount of information an optimal policy provides about the underlying environment. We consider a Controlled Markov Process (CMP) with $n$ states and $m$ actions, assuming a uniform prior over the space of possible transition dynamics. We prove that observing a deterministic policy that is optimal for any non-constant reward function then conveys exactly $n \\log m$ bits of information about the environment. Specifically, we show that the mutual information between the environment and the optimal policy is $n \\log m$ bits. This bound holds across a broad class of objectives, including finite-horizon, infinite-horizon discounted, and time-averaged reward maximization. These findings provide a precise information-theoretic lower bound on the \"implicit world model'' necessary for optimality.", "AI": {"tldr": "\u8be5\u8bba\u6587\u91cf\u5316\u4e86\u6700\u4f18\u7b56\u7565\u5173\u4e8e\u73af\u5883\u7684\u4fe1\u606f\u91cf\uff0c\u8bc1\u660e\u5728n\u72b6\u6001m\u52a8\u4f5c\u7684\u53d7\u63a7\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u4e2d\uff0c\u6700\u4f18\u7b56\u7565\u4e0e\u73af\u5883\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u4e3an log m\u6bd4\u7279", "motivation": "AI\u9886\u57df\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u662f\u6210\u529f\u884c\u4e3a\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u9700\u8981\u5185\u90e8\u4e16\u754c\u8868\u793a\u3002\u672c\u7814\u7a76\u65e8\u5728\u91cf\u5316\u6700\u4f18\u7b56\u7565\u63d0\u4f9b\u7684\u5173\u4e8e\u5e95\u5c42\u73af\u5883\u7684\u4fe1\u606f\u91cf\uff0c\u4e3a\"\u9690\u5f0f\u4e16\u754c\u6a21\u578b\"\u63d0\u4f9b\u4fe1\u606f\u8bba\u4e0b\u754c\u3002", "method": "\u8003\u8651\u5177\u6709n\u4e2a\u72b6\u6001\u548cm\u4e2a\u52a8\u4f5c\u7684\u53d7\u63a7\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\uff0c\u5047\u8bbe\u5728\u53ef\u80fd\u7684\u8f6c\u79fb\u52a8\u6001\u7a7a\u95f4\u4e0a\u5177\u6709\u5747\u5300\u5148\u9a8c\u3002\u5206\u6790\u786e\u5b9a\u6027\u6700\u4f18\u7b56\u7565\uff08\u9488\u5bf9\u4efb\u4f55\u975e\u5e38\u6570\u5956\u52b1\u51fd\u6570\uff09\u4e0e\u73af\u5883\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u3002", "result": "\u8bc1\u660e\u89c2\u6d4b\u5230\u9488\u5bf9\u4efb\u4f55\u975e\u5e38\u6570\u5956\u52b1\u51fd\u6570\u7684\u6700\u4f18\u786e\u5b9a\u6027\u7b56\u7565\u6070\u597d\u4f20\u9012n log m\u6bd4\u7279\u7684\u73af\u5883\u4fe1\u606f\u3002\u5177\u4f53\u800c\u8a00\uff0c\u73af\u5883\u4e0e\u6700\u4f18\u7b56\u7565\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u4e3an log m\u6bd4\u7279\u3002", "conclusion": "\u8be5\u7ed3\u679c\u4e3a\u6700\u4f18\u6027\u6240\u9700\u7684\"\u9690\u5f0f\u4e16\u754c\u6a21\u578b\"\u63d0\u4f9b\u4e86\u7cbe\u786e\u7684\u4fe1\u606f\u8bba\u4e0b\u754c\uff0c\u8fd9\u4e00\u754c\u9650\u9002\u7528\u4e8e\u5305\u62ec\u6709\u9650\u65f6\u57df\u3001\u65e0\u9650\u65f6\u57df\u6298\u6263\u548c\u65f6\u95f4\u5e73\u5747\u5956\u52b1\u6700\u5927\u5316\u5728\u5185\u7684\u5e7f\u6cdb\u76ee\u6807\u7c7b\u522b\u3002"}}
{"id": "2602.13093", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13093", "abs": "https://arxiv.org/abs/2602.13093", "authors": ["Yubo Li", "Ramayya Krishnan", "Rema Padman"], "title": "Consistency of Large Reasoning Models Under Multi-Turn Attacks", "comment": null, "summary": "Large reasoning models with reasoning capabilities achieve state-of-the-art performance on complex tasks, but their robustness under multi-turn adversarial pressure remains underexplored. We evaluate nine frontier reasoning models under adversarial attacks. Our findings reveal that reasoning confers meaningful but incomplete robustness: most reasoning models studied significantly outperform instruction-tuned baselines, yet all exhibit distinct vulnerability profiles, with misleading suggestions universally effective and social pressure showing model-specific efficacy. Through trajectory analysis, we identify five failure modes (Self-Doubt, Social Conformity, Suggestion Hijacking, Emotional Susceptibility, and Reasoning Fatigue) with the first two accounting for 50% of failures. We further demonstrate that Confidence-Aware Response Generation (CARG), effective for standard LLMs, fails for reasoning models due to overconfidence induced by extended reasoning traces; counterintuitively, random confidence embedding outperforms targeted extraction. Our results highlight that reasoning capabilities do not automatically confer adversarial robustness and that confidence-based defenses require fundamental redesign for reasoning models.", "AI": {"tldr": "\u63a8\u7406\u6a21\u578b\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u8868\u73b0\u51fa\u6709\u610f\u4e49\u4f46\u4e0d\u5b8c\u6574\u7684\u9c81\u68d2\u6027\uff0c\u6240\u6709\u6a21\u578b\u90fd\u5b58\u5728\u7279\u5b9a\u6f0f\u6d1e\uff0c\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u9632\u5fa1\u65b9\u6cd5\u5bf9\u63a8\u7406\u6a21\u578b\u5931\u6548", "motivation": "\u5c3d\u7ba1\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u4f46\u5176\u5728\u591a\u8f6e\u5bf9\u6297\u538b\u529b\u4e0b\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u8bc4\u4f30\u63a8\u7406\u6a21\u578b\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u8868\u73b0", "method": "\u8bc4\u4f30\u4e5d\u4e2a\u524d\u6cbf\u63a8\u7406\u6a21\u578b\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u8f68\u8ff9\u5206\u6790\u8bc6\u522b\u5931\u8d25\u6a21\u5f0f\uff0c\u6d4b\u8bd5\u7f6e\u4fe1\u611f\u77e5\u54cd\u5e94\u751f\u6210\uff08CARG\uff09\u65b9\u6cd5\u5bf9\u63a8\u7406\u6a21\u578b\u7684\u6709\u6548\u6027", "result": "\u63a8\u7406\u63d0\u4f9b\u6709\u610f\u4e49\u4f46\u4e0d\u5b8c\u6574\u7684\u9c81\u68d2\u6027\uff1a\u5927\u591a\u6570\u63a8\u7406\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u6307\u4ee4\u8c03\u4f18\u57fa\u7ebf\uff0c\u4f46\u6240\u6709\u6a21\u578b\u90fd\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u6f0f\u6d1e\u6a21\u5f0f\uff1b\u8bef\u5bfc\u6027\u5efa\u8bae\u666e\u904d\u6709\u6548\uff0c\u793e\u4ea4\u538b\u529b\u5177\u6709\u6a21\u578b\u7279\u5b9a\u6548\u679c\uff1b\u8bc6\u522b\u51fa\u4e94\u79cd\u5931\u8d25\u6a21\u5f0f\uff1bCARG\u5bf9\u63a8\u7406\u6a21\u578b\u5931\u6548\uff0c\u968f\u673a\u7f6e\u4fe1\u5d4c\u5165\u53cd\u800c\u4f18\u4e8e\u9488\u5bf9\u6027\u63d0\u53d6", "conclusion": "\u63a8\u7406\u80fd\u529b\u4e0d\u4f1a\u81ea\u52a8\u8d4b\u4e88\u5bf9\u6297\u9c81\u68d2\u6027\uff0c\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u9632\u5fa1\u65b9\u6cd5\u9700\u8981\u4e3a\u63a8\u7406\u6a21\u578b\u8fdb\u884c\u6839\u672c\u6027\u91cd\u65b0\u8bbe\u8ba1"}}
{"id": "2602.13135", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.13135", "abs": "https://arxiv.org/abs/2602.13135", "authors": ["Emanuele De Angelis", "Fabio Fioravanti", "Maria Chiara Meo", "Alberto Pettorossi", "Maurizio Proietti", "Francesca Toni"], "title": "Constrained Assumption-Based Argumentation Frameworks", "comment": "Extended version with proofs and additional results of the full paper accepted at the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026). DOI: https://doi.org/10.65109/KRAP9309", "summary": "Assumption-based Argumentation (ABA) is a well-established form of structured argumentation. ABA frameworks with an underlying atomic language are widely studied, but their applicability is limited by a representational restriction to ground (variable-free) arguments and attacks built from propositional atoms. In this paper, we lift this restriction and propose a novel notion of constrained ABA (CABA), whose components, as well as arguments built from them, may include constrained variables, ranging over possibly infinite domains. We define non-ground semantics for CABA, in terms of various notions of non-ground attacks. We show that the new semantics conservatively generalise standard ABA semantics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u7ea6\u675fABA\uff08CABA\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u7ea6\u675f\u53d8\u91cf\u6765\u6269\u5c55\u4f20\u7edfABA\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u975e\u5730\u9762\uff08\u5305\u542b\u53d8\u91cf\uff09\u7684\u8bba\u8bc1\u548c\u653b\u51fb\uff0c\u4ece\u800c\u514b\u670d\u4e86\u4f20\u7edfABA\u53ea\u80fd\u5904\u7406\u547d\u9898\u539f\u5b50\u6784\u6210\u7684\u9650\u5236\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5047\u8bbe\u7684\u8bba\u8bc1\uff08ABA\uff09\u6846\u67b6\u5b58\u5728\u8868\u793a\u9650\u5236\uff0c\u53ea\u80fd\u5904\u7406\u7531\u547d\u9898\u539f\u5b50\u6784\u6210\u7684\u5730\u9762\uff08\u65e0\u53d8\u91cf\uff09\u8bba\u8bc1\u548c\u653b\u51fb\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u9002\u7528\u6027\u3002\u9700\u8981\u6269\u5c55ABA\u4ee5\u652f\u6301\u5305\u542b\u7ea6\u675f\u53d8\u91cf\u7684\u975e\u5730\u9762\u8bba\u8bc1\u3002", "method": "\u63d0\u51fa\u7ea6\u675fABA\uff08CABA\uff09\u6846\u67b6\uff0c\u5141\u8bb8\u6846\u67b6\u7ec4\u4ef6\u548c\u8bba\u8bc1\u4e2d\u5305\u542b\u7ea6\u675f\u53d8\u91cf\uff0c\u8fd9\u4e9b\u53d8\u91cf\u53ef\u4ee5\u5728\u53ef\u80fd\u65e0\u9650\u7684\u57df\u4e0a\u53d6\u503c\u3002\u5b9a\u4e49\u4e86CABA\u7684\u975e\u5730\u9762\u8bed\u4e49\uff0c\u57fa\u4e8e\u5404\u79cd\u975e\u5730\u9762\u653b\u51fb\u6982\u5ff5\u3002", "result": "\u65b0\u63d0\u51fa\u7684CABA\u6846\u67b6\u80fd\u591f\u5904\u7406\u975e\u5730\u9762\u8bba\u8bc1\uff0c\u5176\u8bed\u4e49\u4fdd\u5b88\u5730\u63a8\u5e7f\u4e86\u6807\u51c6ABA\u8bed\u4e49\uff0c\u5373\u5f53\u6240\u6709\u53d8\u91cf\u90fd\u88ab\u5b9e\u4f8b\u5316\u65f6\uff0cCABA\u8bed\u4e49\u4e0e\u6807\u51c6ABA\u8bed\u4e49\u4e00\u81f4\u3002", "conclusion": "CABA\u6846\u67b6\u6210\u529f\u6269\u5c55\u4e86\u4f20\u7edfABA\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u5305\u542b\u7ea6\u675f\u53d8\u91cf\u7684\u975e\u5730\u9762\u8bba\u8bc1\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6807\u51c6ABA\u8bed\u4e49\u7684\u517c\u5bb9\u6027\uff0c\u4e3aABA\u6846\u67b6\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u53ef\u80fd\u6027\u3002"}}
{"id": "2602.13166", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13166", "abs": "https://arxiv.org/abs/2602.13166", "authors": ["Hugo Henry", "Arthur Tsai", "Kelly Cohen"], "title": "Optimal Take-off under Fuzzy Clearances", "comment": "12 pages, 12 figures, conference paper", "summary": "This paper presents a hybrid obstacle avoidance architecture that integrates Optimal Control under clearance with a Fuzzy Rule Based System (FRBS) to enable adaptive constraint handling for unmanned aircraft. Motivated by the limitations of classical optimal control under uncertainty and the need for interpretable decision making in safety critical aviation systems, we design a three stage Takagi Sugeno Kang fuzzy layer that modulates constraint radii, urgency levels, and activation decisions based on regulatory separation minima and airworthiness guidelines from FAA and EASA. These fuzzy-derived clearances are then incorporated as soft constraints into an optimal control problem solved using the FALCON toolbox and IPOPT. The framework aims to reduce unnecessary recomputations by selectively activating obstacle avoidance updates while maintaining compliance with aviation procedures. A proof of concept implementation using a simplified aircraft model demonstrates that the approach can generate optimal trajectories with computation times of 2,3 seconds per iteration in a single threaded MATLAB environment, suggesting feasibility for near real time applications. However, our experiments revealed a critical software incompatibility in the latest versions of FALCON and IPOPT, in which the Lagrangian penalty term remained identically zero, preventing proper constraint enforcement. This behavior was consistent across scenarios and indicates a solver toolbox regression rather than a modeling flaw. Future work includes validating this effect by reverting to earlier software versions, optimizing the fuzzy membership functions using evolutionary methods, and extending the system to higher fidelity aircraft models and stochastic obstacle environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6700\u4f18\u63a7\u5236\u4e0e\u6a21\u7cca\u89c4\u5219\u7cfb\u7edf\u7684\u6df7\u5408\u907f\u969c\u67b6\u6784\uff0c\u7528\u4e8e\u65e0\u4eba\u673a\u81ea\u9002\u5e94\u7ea6\u675f\u5904\u7406\uff0c\u4f46\u53d1\u73b0FALCON\u548cIPOPT\u8f6f\u4ef6\u5b58\u5728\u517c\u5bb9\u6027\u95ee\u9898\u5bfc\u81f4\u7ea6\u675f\u65e0\u6cd5\u6b63\u786e\u6267\u884c\u3002", "motivation": "\u4f20\u7edf\u6700\u4f18\u63a7\u5236\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5c40\u9650\u6027\uff0c\u4ee5\u53ca\u822a\u7a7a\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u9700\u8981\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u5236\u5b9a\uff0c\u4fc3\u4f7f\u5f00\u53d1\u80fd\u591f\u81ea\u9002\u5e94\u5904\u7406\u7ea6\u675f\u7684\u6df7\u5408\u67b6\u6784\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e09\u9636\u6bb5Takagi-Sugeno-Kang\u6a21\u7cca\u5c42\uff0c\u57fa\u4e8eFAA\u548cEASA\u7684\u76d1\u7ba1\u5206\u79bb\u6700\u5c0f\u503c\u548c\u9002\u822a\u6307\u5357\u6765\u8c03\u5236\u7ea6\u675f\u534a\u5f84\u3001\u7d27\u6025\u7ea7\u522b\u548c\u6fc0\u6d3b\u51b3\u7b56\uff0c\u7136\u540e\u5c06\u6a21\u7cca\u63a8\u5bfc\u7684\u95f4\u9699\u4f5c\u4e3a\u8f6f\u7ea6\u675f\u7eb3\u5165\u6700\u4f18\u63a7\u5236\u95ee\u9898\uff0c\u4f7f\u7528FALCON\u5de5\u5177\u7bb1\u548cIPOPT\u6c42\u89e3\u3002", "result": "\u6982\u5ff5\u9a8c\u8bc1\u663e\u793a\u6bcf\u8fed\u4ee3\u8ba1\u7b97\u65f6\u95f4\u4e3a2-3\u79d2\uff0c\u8868\u660e\u8fd1\u5b9e\u65f6\u5e94\u7528\u53ef\u884c\u6027\uff0c\u4f46\u53d1\u73b0FALCON\u548cIPOPT\u6700\u65b0\u7248\u672c\u5b58\u5728\u8f6f\u4ef6\u4e0d\u517c\u5bb9\u95ee\u9898\uff0c\u62c9\u683c\u6717\u65e5\u60e9\u7f5a\u9879\u6052\u4e3a\u96f6\uff0c\u5bfc\u81f4\u7ea6\u675f\u65e0\u6cd5\u6b63\u786e\u6267\u884c\u3002", "conclusion": "\u8be5\u6df7\u5408\u67b6\u6784\u5728\u7b80\u5316\u98de\u673a\u6a21\u578b\u4e2d\u5c55\u793a\u4e86\u53ef\u884c\u6027\uff0c\u4f46\u8f6f\u4ef6\u517c\u5bb9\u6027\u95ee\u9898\u9700\u8981\u89e3\u51b3\u3002\u672a\u6765\u5de5\u4f5c\u5305\u62ec\u9a8c\u8bc1\u8f6f\u4ef6\u56de\u5f52\u95ee\u9898\u3001\u4f18\u5316\u6a21\u7cca\u96b6\u5c5e\u51fd\u6570\uff0c\u4ee5\u53ca\u6269\u5c55\u5230\u66f4\u9ad8\u4fdd\u771f\u5ea6\u98de\u673a\u6a21\u578b\u548c\u968f\u673a\u969c\u788d\u73af\u5883\u3002"}}

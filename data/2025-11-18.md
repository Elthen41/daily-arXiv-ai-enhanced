<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [HetDAPAC: Leveraging Attribute Heterogeneity in Distributed Attribute-Based Private Access Control](https://arxiv.org/abs/2511.11549)
*Shreya Meel,Sennur Ulukus*

Main category: cs.CR

TL;DR: 本文提出了一种异构分布式基于属性的私有访问控制(HetDAPAC)框架，通过将非敏感属性的验证集中到中央服务器，同时保留敏感属性的分布式验证，从而在隐私保护和通信效率之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 传统的DAPAC系统对所有属性采用相同的隐私保护级别，这可能导致通信效率低下。现实中并非所有属性都同样敏感，因此需要一种能够根据属性敏感性差异调整隐私保护强度的方案。

Method: 提出HetDAPAC框架，将N个属性中的N-D个非敏感属性验证集中到中央服务器，仅对D个敏感属性保持分布式验证架构。提出了两种方案：一种提高通信速率但存在下载不均衡，另一种实现服务器间下载均衡。

Result: 第一个方案将通信速率从1/(2K)提升到1/(K+1)，第二个方案实现服务器间下载均衡，通信速率为(D+1)/(2KD)。

Conclusion: HetDAPAC框架通过在敏感和非敏感属性之间采用不同的隐私保护策略，有效提升了系统的通信效率，同时保持了必要的隐私保护水平。

Abstract: Verifying user attributes to provide fine-grained access control to databases is fundamental to attribute-based authentication. Either a single (central) authority verifies all the attributes, or multiple independent authorities verify the attributes distributedly. In the central setup, the authority verifies all user attributes, and the user downloads only the authorized record. While this is communication efficient, it reveals all user attributes to the authority. A distributed setup prevents this privacy breach by letting each authority verify and learn only one attribute. Motivated by this, Jafarpisheh~et~al. introduced an information-theoretic formulation, called distributed attribute-based private access control (DAPAC). With $N$ non-colluding authorities (servers), $N$ attributes and $K$ possible values for each attribute, the DAPAC system lets each server learn only the single attribute value that it verifies, and is oblivious to the remaining $N-1$. The user retrieves its designated record, without learning anything about the remaining database records. The goal is to maximize the rate, i.e., the ratio of desired message size to total download size. However, not all attributes are sensitive, and DAPAC's privacy constraints can be too restrictive, negatively affecting the rate. To leverage the heterogeneous privacy requirements of user attributes, we propose heterogeneous (Het)DAPAC, a framework which off-loads verification of $N-D$ of the $N$ attributes to a central server, and retains DAPAC's architecture for the $D$ sensitive attributes. We first present a HetDAPAC scheme, which improves the rate from $\frac{1}{2K}$ to $\frac{1}{K+1}$, while sacrificing the privacy of a few non-sensitive attributes. Unlike DAPAC, our scheme entails a download imbalance across servers; we propose a second scheme achieving a balanced per-server download and a rate of $\frac{D+1}{2KD}$.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [The Second Law of Intelligence: Controlling Ethical Entropy in Autonomous Systems](https://arxiv.org/abs/2511.10704)
*Samih Fadli*

Main category: cs.AI

TL;DR: 本文提出人工智能的伦理熵第二定律，证明无约束AI会自发偏离目标，需要持续的对齐工作来维持稳定性。


<details>
  <summary>Details</summary>
Motivation: 为理解AI系统为何会自发偏离预期目标，以及如何定量控制这种偏离，作者从热力学角度提出伦理熵概念。

Method: 定义伦理熵S = -Σ p(g_i; theta) ln p(g_i; theta)，证明其时间导数dS/dt ≥ 0，推导临界对齐工作边界gamma_crit = (lambda_max / 2) ln N，并通过70亿参数模型进行验证。

Result: 未对齐的70亿参数模型从初始熵0.32漂移到1.69±1.08 nats，而使用gamma=20.4（1.5倍临界值）对齐的系统保持稳定在0.00±0.00 nats（p=4.19×10^-17）。

Conclusion: 该框架将AI对齐重新表述为连续热力学控制问题，为高级自主系统的稳定性和安全性提供了定量基础。

Abstract: We propose that unconstrained artificial intelligence obeys a Second Law analogous to thermodynamics, where ethical entropy, defined as a measure of divergence from intended goals, increases spontaneously without continuous alignment work. For gradient-based optimizers, we define this entropy over a finite set of goals {g_i} as S = -Σ p(g_i; theta) ln p(g_i; theta), and we prove that its time derivative dS/dt >= 0, driven by exploration noise and specification gaming. We derive the critical stability boundary for alignment work as gamma_crit = (lambda_max / 2) ln N, where lambda_max is the dominant eigenvalue of the Fisher Information Matrix and N is the number of model parameters. Simulations validate this theory. A 7-billion-parameter model (N = 7 x 10^9) with lambda_max = 1.2 drifts from an initial entropy of 0.32 to 1.69 +/- 1.08 nats, while a system regularized with alignment work gamma = 20.4 (1.5 gamma_crit) maintains stability at 0.00 +/- 0.00 nats (p = 4.19 x 10^-17, n = 20 trials). This framework recasts AI alignment as a problem of continuous thermodynamic control, providing a quantitative foundation for maintaining the stability and safety of advanced autonomous systems.

</details>

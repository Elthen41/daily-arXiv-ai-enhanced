{"id": "2512.19882", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.19882", "abs": "https://arxiv.org/abs/2512.19882", "authors": ["Mahdi Mostajabdaveh", "F. Sibel Salman", "Walter J. Gutjahr"], "title": "A Branch-and-Price Algorithm for Fast and Equitable Last-Mile Relief Aid Distribution", "comment": null, "summary": "The distribution of relief supplies to shelters is a critical aspect of post-disaster humanitarian logistics. In major disasters, prepositioned supplies often fall short of meeting all demands. We address the problem of planning vehicle routes from a distribution center to shelters while allocating limited relief supplies. To balance efficiency and equity, we formulate a bi-objective problem: minimizing a Gini-index-based measure of inequity in unsatisfied demand for fair distribution and minimizing total travel time for timely delivery. We propose a Mixed Integer Programming (MIP) model and use the $\u03b5$-constraint method to handle the bi-objective nature. By deriving mathematical properties of the optimal solution, we introduce valid inequalities and design an algorithm for optimal delivery allocations given feasible vehicle routes. A branch-and-price (B&P) algorithm is developed to solve the problem efficiently. Computational tests on realistic datasets from a past earthquake in Van, Turkey, and predicted data for Istanbul's Kartal region show that the B&P algorithm significantly outperforms commercial MIP solvers. Our bi-objective approach reduces aid distribution inequity by 34% without compromising efficiency. Results indicate that when time constraints are very loose or tight, lexicographic optimization prioritizing demand coverage over fairness is effective. For moderately restrictive time constraints, a balanced approach is essential to avoid inequitable outcomes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u89c4\u5212\u707e\u540e\u6551\u63f4\u7269\u8d44\u4ece\u914d\u9001\u4e2d\u5fc3\u5230\u907f\u96be\u6240\u7684\u8f66\u8f86\u8def\u5f84\uff0c\u540c\u65f6\u8003\u8651\u6709\u9650\u7684\u6551\u63f4\u7269\u8d44\u5206\u914d\u3002\u8be5\u65b9\u6cd5\u5e73\u8861\u6548\u7387\uff08\u6700\u5c0f\u5316\u603b\u65c5\u884c\u65f6\u95f4\uff09\u548c\u516c\u5e73\u6027\uff08\u6700\u5c0f\u5316\u57fa\u4e8e\u57fa\u5c3c\u7cfb\u6570\u7684\u4e0d\u6ee1\u8db3\u9700\u6c42\u4e0d\u5e73\u7b49\u5ea6\u91cf\uff09\uff0c\u901a\u8fc7\u5206\u652f\u5b9a\u4ef7\u7b97\u6cd5\u6709\u6548\u6c42\u89e3\u3002", "motivation": "\u5728\u91cd\u5927\u707e\u5bb3\u4e2d\uff0c\u9884\u5148\u50a8\u5907\u7684\u7269\u8d44\u5f80\u5f80\u65e0\u6cd5\u6ee1\u8db3\u6240\u6709\u9700\u6c42\u3002\u707e\u540e\u6551\u63f4\u7269\u8d44\u5206\u914d\u5230\u907f\u96be\u6240\u662f\u4eba\u9053\u4e3b\u4e49\u7269\u6d41\u7684\u5173\u952e\u73af\u8282\uff0c\u9700\u8981\u5728\u6709\u9650\u7684\u7269\u8d44\u6761\u4ef6\u4e0b\u5e73\u8861\u914d\u9001\u6548\u7387\u548c\u5206\u914d\u516c\u5e73\u6027\u3002", "method": "1. \u5efa\u7acb\u53cc\u76ee\u6807\u6df7\u5408\u6574\u6570\u89c4\u5212\u6a21\u578b\uff1a\u6700\u5c0f\u5316\u57fa\u4e8e\u57fa\u5c3c\u7cfb\u6570\u7684\u4e0d\u6ee1\u8db3\u9700\u6c42\u4e0d\u5e73\u7b49\u5ea6\u91cf\u548c\u6700\u5c0f\u5316\u603b\u65c5\u884c\u65f6\u95f4\uff1b2. \u4f7f\u7528\u03b5-\u7ea6\u675f\u65b9\u6cd5\u5904\u7406\u53cc\u76ee\u6807\u4f18\u5316\uff1b3. \u63a8\u5bfc\u6700\u4f18\u89e3\u7684\u6570\u5b66\u6027\u8d28\uff0c\u5f15\u5165\u6709\u6548\u4e0d\u7b49\u5f0f\uff1b4. \u8bbe\u8ba1\u7ed9\u5b9a\u53ef\u884c\u8f66\u8f86\u8def\u5f84\u4e0b\u7684\u6700\u4f18\u914d\u9001\u5206\u914d\u7b97\u6cd5\uff1b5. \u5f00\u53d1\u5206\u652f\u5b9a\u4ef7\u7b97\u6cd5\u9ad8\u6548\u6c42\u89e3\u95ee\u9898\u3002", "result": "1. \u5206\u652f\u5b9a\u4ef7\u7b97\u6cd5\u5728\u571f\u8033\u5176\u51e1\u57ce\u5730\u9707\u5b9e\u9645\u6570\u636e\u548c\u4f0a\u65af\u5766\u5e03\u5c14\u5361\u5854\u5c14\u5730\u533a\u9884\u6d4b\u6570\u636e\u7684\u8ba1\u7b97\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u5546\u4e1aMIP\u6c42\u89e3\u5668\uff1b2. \u53cc\u76ee\u6807\u65b9\u6cd5\u5728\u4e0d\u5f71\u54cd\u6548\u7387\u7684\u60c5\u51b5\u4e0b\u5c06\u63f4\u52a9\u5206\u914d\u4e0d\u5e73\u7b49\u5ea6\u964d\u4f4e\u4e8634%\uff1b3. \u5f53\u65f6\u95f4\u7ea6\u675f\u975e\u5e38\u5bbd\u677e\u6216\u4e25\u683c\u65f6\uff0c\u6309\u9700\u6c42\u8986\u76d6\u4f18\u5148\u4e8e\u516c\u5e73\u6027\u7684\u8bcd\u5178\u5e8f\u4f18\u5316\u6709\u6548\uff1b4. \u5bf9\u4e8e\u4e2d\u7b49\u9650\u5236\u7684\u65f6\u95f4\u7ea6\u675f\uff0c\u5e73\u8861\u65b9\u6cd5\u5bf9\u907f\u514d\u4e0d\u516c\u5e73\u7ed3\u679c\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u53cc\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\u548c\u5206\u652f\u5b9a\u4ef7\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u707e\u540e\u6551\u63f4\u7269\u8d44\u914d\u9001\u4e2d\u7684\u6548\u7387\u4e0e\u516c\u5e73\u5e73\u8861\u95ee\u9898\u3002\u7814\u7a76\u8868\u660e\uff0c\u5728\u4e0d\u540c\u65f6\u95f4\u7ea6\u675f\u6761\u4ef6\u4e0b\u9700\u8981\u91c7\u7528\u4e0d\u540c\u7684\u4f18\u5316\u7b56\u7565\uff1a\u5bbd\u677e\u6216\u4e25\u683c\u7ea6\u675f\u65f6\u53ef\u91c7\u7528\u8bcd\u5178\u5e8f\u4f18\u5316\uff0c\u4e2d\u7b49\u7ea6\u675f\u65f6\u9700\u8981\u5e73\u8861\u65b9\u6cd5\u4ee5\u786e\u4fdd\u516c\u5e73\u5206\u914d\u3002"}}
{"id": "2512.19957", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.19957", "abs": "https://arxiv.org/abs/2512.19957", "authors": ["Luciano Araujo Dourado Filho", "Almir Moreira da Silva Neto", "Rodrigo Pereira David", "Rodrigo Tripodi Calumby"], "title": "Zero-Shot Segmentation through Prototype-Guidance for Multi-Label Plant Species Identification", "comment": null, "summary": "This paper presents an approach developed to address the PlantClef 2025 challenge, which consists of a fine-grained multi-label species identification, over high-resolution images. Our solution focused on employing class prototypes obtained from the training dataset as a proxy guidance for training a segmentation Vision Transformer (ViT) on the test set images. To obtain these representations, the proposed method extracts features from training dataset images and create clusters, by applying K-Means, with $K$ equals to the number of classes in the dataset. The segmentation model is a customized narrow ViT, built by replacing the patch embedding layer with a frozen DinoV2, pre-trained on the training dataset for individual species classification. This model is trained to reconstruct the class prototypes of the training dataset from the test dataset images. We then use this model to obtain attention scores that enable to identify and localize areas of interest and consequently guide the classification process. The proposed approach enabled a domain-adaptation from multi-class identification with individual species, into multi-label classification from high-resolution vegetation plots. Our method achieved fifth place in the PlantCLEF 2025 challenge on the private leaderboard, with an F1 score of 0.33331. Besides that, in absolute terms our method scored 0.03 lower than the top-performing submission, suggesting that it may achieved competitive performance in the benchmark task. Our code is available at \\href{https://github.com/ADAM-UEFS/PlantCLEF2025}{https://github.com/ADAM-UEFS/PlantCLEF2025}.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8ePlantClef 2025\u6311\u6218\u8d5b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u8bad\u7ec3\u6570\u636e\u4e2d\u63d0\u53d6\u7c7b\u539f\u578b\u4f5c\u4e3a\u6307\u5bfc\uff0c\u8bad\u7ec3\u5206\u5272Vision Transformer\u6a21\u578b\uff0c\u5b9e\u73b0\u4ece\u9ad8\u5206\u8fa8\u7387\u690d\u88ab\u56fe\u50cf\u4e2d\u8fdb\u884c\u7ec6\u7c92\u5ea6\u591a\u6807\u7b7e\u7269\u79cd\u8bc6\u522b\u3002", "motivation": "\u89e3\u51b3PlantClef 2025\u6311\u6218\u8d5b\u4e2d\u7684\u7ec6\u7c92\u5ea6\u591a\u6807\u7b7e\u7269\u79cd\u8bc6\u522b\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9ad8\u5206\u8fa8\u7387\u690d\u88ab\u56fe\u50cf\u4e2d\u8bc6\u522b\u591a\u4e2a\u7269\u79cd\u3002\u9700\u8981\u5c06\u5355\u7269\u79cd\u5206\u7c7b\u6a21\u578b\u9002\u5e94\u5230\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\u4e2d\u3002", "method": "1. \u4ece\u8bad\u7ec3\u6570\u636e\u4e2d\u63d0\u53d6\u7279\u5f81\u5e76\u4f7f\u7528K-Means\u805a\u7c7b\u751f\u6210\u7c7b\u539f\u578b\uff08K\u7b49\u4e8e\u7c7b\u522b\u6570\uff09\n2. \u6784\u5efa\u5b9a\u5236\u5316\u7a84Vision Transformer\uff0c\u7528\u51bb\u7ed3\u7684DinoV2\u66ff\u6362patch embedding\u5c42\n3. \u8bad\u7ec3\u5206\u5272\u6a21\u578b\u4ece\u6d4b\u8bd5\u56fe\u50cf\u91cd\u5efa\u8bad\u7ec3\u6570\u636e\u7684\u7c7b\u539f\u578b\n4. \u5229\u7528\u6ce8\u610f\u529b\u5206\u6570\u8bc6\u522b\u548c\u5b9a\u4f4d\u611f\u5174\u8da3\u533a\u57df\uff0c\u6307\u5bfc\u5206\u7c7b\u8fc7\u7a0b\n5. \u5b9e\u73b0\u4ece\u5355\u7269\u79cd\u5206\u7c7b\u5230\u591a\u6807\u7b7e\u5206\u7c7b\u7684\u9886\u57df\u9002\u5e94", "result": "\u5728PlantCLEF 2025\u6311\u6218\u8d5b\u79c1\u6709\u6392\u884c\u699c\u4e0a\u83b7\u5f97\u7b2c\u4e94\u540d\uff0cF1\u5206\u6570\u4e3a0.33331\u3002\u4e0e\u6700\u4f73\u63d0\u4ea4\u7ed3\u679c\u4ec5\u76f8\u5dee0.03\uff0c\u663e\u793a\u51fa\u5728\u57fa\u51c6\u4efb\u52a1\u4e2d\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u7c7b\u539f\u578b\u6307\u5bfc\u7684\u5206\u5272Vision Transformer\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u9ad8\u5206\u8fa8\u7387\u690d\u88ab\u56fe\u50cf\u7684\u591a\u6807\u7b7e\u7269\u79cd\u8bc6\u522b\u4efb\u52a1\uff0c\u5728PlantCLEF\u6311\u6218\u8d5b\u4e2d\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u9886\u57df\u9002\u5e94\u7b56\u7565\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.19945", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.19945", "abs": "https://arxiv.org/abs/2512.19945", "authors": ["Saeid Jamshidi", "Omar Abdul-Wahab", "Martine Bella\u00efche", "Foutse Khomh"], "title": "Energy-Efficient Multi-LLM Reasoning for Binary-Free Zero-Day Detection in IoT Firmware", "comment": null, "summary": "Securing Internet of Things (IoT) firmware remains difficult due to proprietary binaries, stripped symbols, heterogeneous architectures, and limited access to executable code. Existing analysis methods, such as static analysis, symbolic execution, and fuzzing, depend on binary visibility and functional emulation, making them unreliable when firmware is encrypted or inaccessible. To address this limitation, we propose a binary-free, architecture-agnostic solution that estimates the likelihood of conceptual zero-day vulnerabilities using only high-level descriptors. The approach integrates a tri-LLM reasoning architecture combining a LLaMA-based configuration interpreter, a DeepSeek-based structural abstraction analyzer, and a GPT-4o semantic fusion model. The solution also incorporates LLM computational signatures, including latency patterns, uncertainty markers, and reasoning depth indicators, as well as an energy-aware symbolic load model, to enhance interpretability and operational feasibility. In addition, we formally derive the mathematical foundations of the reasoning pipeline, establishing monotonicity, divergence, and energy-risk coupling properties that theoretically justify the model's behavior. Simulation-based evaluation reveals that high exposure conditions increase the predicted zero-day likelihood by 20 to 35 percent across models, with GPT-4o demonstrating the strongest cross-layer correlations and the highest sensitivity. Energy and divergence metrics significantly predict elevated risk (p < 0.01), reinforcing the effectiveness of the proposed reasoning framework.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u4e8c\u8fdb\u5236\u4ee3\u7801\u3001\u67b6\u6784\u65e0\u5173\u7684IoT\u56fa\u4ef6\u96f6\u65e5\u6f0f\u6d1e\u53ef\u80fd\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u9ad8\u7ea7\u63cf\u8ff0\u7b26\u548cLLM\u63a8\u7406\u67b6\u6784\u5b9e\u73b0", "motivation": "IoT\u56fa\u4ef6\u5b89\u5168\u5206\u6790\u9762\u4e34\u4e13\u6709\u4e8c\u8fdb\u5236\u3001\u7b26\u53f7\u5265\u79bb\u3001\u5f02\u6784\u67b6\u6784\u548c\u4ee3\u7801\u8bbf\u95ee\u53d7\u9650\u7b49\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4e8c\u8fdb\u5236\u53ef\u89c1\u6027\u548c\u529f\u80fd\u6a21\u62df\uff0c\u5728\u56fa\u4ef6\u52a0\u5bc6\u6216\u4e0d\u53ef\u8bbf\u95ee\u65f6\u4e0d\u53ef\u9760", "method": "\u91c7\u7528\u4e09\u5143LLM\u63a8\u7406\u67b6\u6784\uff1aLLaMA\u914d\u7f6e\u89e3\u91ca\u5668\u3001DeepSeek\u7ed3\u6784\u62bd\u8c61\u5206\u6790\u5668\u548cGPT-4o\u8bed\u4e49\u878d\u5408\u6a21\u578b\uff0c\u7ed3\u5408LLM\u8ba1\u7b97\u7b7e\u540d\uff08\u5ef6\u8fdf\u6a21\u5f0f\u3001\u4e0d\u786e\u5b9a\u6027\u6807\u8bb0\u3001\u63a8\u7406\u6df1\u5ea6\u6307\u6807\uff09\u548c\u80fd\u91cf\u611f\u77e5\u7b26\u53f7\u8d1f\u8f7d\u6a21\u578b", "result": "\u6a21\u62df\u8bc4\u4f30\u663e\u793a\u9ad8\u66b4\u9732\u6761\u4ef6\u4e0b\u9884\u6d4b\u7684\u96f6\u65e5\u6f0f\u6d1e\u53ef\u80fd\u6027\u589e\u52a020-35%\uff0cGPT-4o\u8868\u73b0\u51fa\u6700\u5f3a\u7684\u8de8\u5c42\u76f8\u5173\u6027\u548c\u6700\u9ad8\u654f\u611f\u6027\uff0c\u80fd\u91cf\u548c\u53d1\u6563\u5ea6\u6307\u6807\u663e\u8457\u9884\u6d4b\u98ce\u9669\u5347\u9ad8\uff08p<0.01\uff09", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u65e0\u6cd5\u8bbf\u95ee\u4e8c\u8fdb\u5236\u4ee3\u7801\u7684IoT\u56fa\u4ef6\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u6570\u5b66\u57fa\u7840\u548cLLM\u63a8\u7406\u67b6\u6784\u5b9e\u73b0\u4e86\u67b6\u6784\u65e0\u5173\u7684\u96f6\u65e5\u6f0f\u6d1e\u53ef\u80fd\u6027\u4f30\u8ba1"}}
{"id": "2512.19960", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.19960", "abs": "https://arxiv.org/abs/2512.19960", "authors": ["Luciano Araujo Dourado Filho", "Rodrigo Tripodi Calumby"], "title": "FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification", "comment": null, "summary": "Intra-class variability is given according to the significance in the degree of dissimilarity between images within a class. In that sense, depending on its intensity, intra-class variability can hinder the learning process for DL models, specially when such classes are also underrepresented, which is a very common scenario in Fine-Grained Visual Categorization (FGVC) tasks. This paper proposes a novel method that aims at leveraging classification performance in FGVC tasks by learning fine-grained features via classification of class-wise cluster assignments. Our goal is to apply clustering over each class individually, which can allow to discover pseudo-labels that encodes a latent degree of similarity between images. In turn, those labels can be employed in a hierarchical classification process that allows to learn more fine-grained visual features and thereby mitigating intra-class variability issues. Initial experiments over the PlantNet300k enabled to shed light upon several key points in which future work will have to be developed in order to find more conclusive evidence regarding the effectiveness of our method. Our method still achieves state-of-the-art performance on the PlantNet300k dataset even though some of its components haven't been shown to be fully optimized. Our code is available at \\href{https://github.com/ADAM-UEFS/FGDCC}{https://github.com/ADAM-UEFS/FGDCC}.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u7c7b\u5185\u805a\u7c7b\u751f\u6210\u4f2a\u6807\u7b7e\u8fdb\u884c\u5c42\u6b21\u5206\u7c7b\u7684\u65b9\u6cd5\uff0c\u4ee5\u7f13\u89e3\u7ec6\u7c92\u5ea6\u89c6\u89c9\u5206\u7c7b\u4e2d\u7684\u7c7b\u5185\u53d8\u5f02\u95ee\u9898\uff0c\u5728PlantNet300k\u6570\u636e\u96c6\u4e0a\u53d6\u5f97SOTA\u6027\u80fd\u3002", "motivation": "\u7ec6\u7c92\u5ea6\u89c6\u89c9\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u7c7b\u5185\u53d8\u5f02\uff08\u540c\u4e00\u7c7b\u522b\u5185\u56fe\u50cf\u7684\u5dee\u5f02\u7a0b\u5ea6\uff09\u4f1a\u963b\u788d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u7279\u522b\u662f\u5f53\u8fd9\u4e9b\u7c7b\u522b\u8fd8\u5904\u4e8e\u6b20\u8868\u793a\u72b6\u6001\u65f6\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u7f13\u89e3\u7c7b\u5185\u53d8\u5f02\u95ee\u9898\uff0c\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u65b9\u6cd5\uff1a\u901a\u8fc7\u5bf9\u6bcf\u4e2a\u7c7b\u522b\u5355\u72ec\u8fdb\u884c\u805a\u7c7b\uff0c\u53d1\u73b0\u7f16\u7801\u56fe\u50cf\u95f4\u76f8\u4f3c\u5ea6\u7684\u6f5c\u5728\u4f2a\u6807\u7b7e\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u6807\u7b7e\u7528\u4e8e\u5c42\u6b21\u5206\u7c7b\u8fc7\u7a0b\uff0c\u5b66\u4e60\u66f4\u7ec6\u7c92\u5ea6\u7684\u89c6\u89c9\u7279\u5f81\uff0c\u4ece\u800c\u7f13\u89e3\u7c7b\u5185\u53d8\u5f02\u95ee\u9898\u3002", "result": "\u5728PlantNet300k\u6570\u636e\u96c6\u4e0a\u7684\u521d\u6b65\u5b9e\u9a8c\u63ed\u793a\u4e86\u51e0\u4e2a\u5173\u952e\u70b9\uff0c\u672a\u6765\u5de5\u4f5c\u9700\u8981\u8fdb\u4e00\u6b65\u5f00\u53d1\u4ee5\u83b7\u5f97\u66f4\u786e\u51ff\u7684\u8bc1\u636e\u3002\u5c3d\u7ba1\u67d0\u4e9b\u7ec4\u4ef6\u5c1a\u672a\u5b8c\u5168\u4f18\u5316\uff0c\u4f46\u8be5\u65b9\u6cd5\u5728PlantNet300k\u6570\u636e\u96c6\u4e0a\u4ecd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u7c7b\u5185\u805a\u7c7b\u751f\u6210\u4f2a\u6807\u7b7e\u8fdb\u884c\u5c42\u6b21\u5206\u7c7b\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u7f13\u89e3\u7ec6\u7c92\u5ea6\u89c6\u89c9\u5206\u7c7b\u4e2d\u7684\u7c7b\u5185\u53d8\u5f02\u95ee\u9898\uff0c\u63d0\u5347\u5206\u7c7b\u6027\u80fd\uff0c\u5728PlantNet300k\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2512.19951", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.19951", "abs": "https://arxiv.org/abs/2512.19951", "authors": ["Yufei Zhou"], "title": "Efficient Mod Approximation and Its Applications to CKKS Ciphertexts", "comment": null, "summary": "The mod function plays a critical role in numerous data encoding and cryptographic primitives. However, the widely used CKKS homomorphic encryption (HE) scheme supports only arithmetic operations, making it difficult to perform mod computations on encrypted data. Approximating the mod function with polynomials has therefore become an important yet challenging problem. The discontinuous and periodic characteristics of the mod function make it particularly difficult to approximate accurately under HE. Existing homomorphic mod constructions provide accurate results only within limited subranges of the input range, leaving the problem of achieving accurate approximation across the full input range unresolved. In this work, we propose a novel method based on polynomial interpolation and Chebyshev series to accurately approximate the mod function. Building upon this, we design two efficient data packing schemes, BitStack and CRTStack, tailored for small-integer inputs in CKKS. These schemes significantly improve the utilization of the CKKS plaintext space and enable efficient ciphertext uploads. Furthermore, we apply the proposed HE mod function to implement a homomorphic rounding operation and a general transformation from additive secret sharing to CKKS ciphertexts, achieving accurate ciphertext rounding and complete secret-share-to-CKKS conversion. Experimental results demonstrate that our approach achieves high approximation accuracy (up to 1e-8). Overall, our work provides a practical and general solution for performing mod operations under CKKS, extending its applicability to a broader range of privacy-preserving computations.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u9879\u5f0f\u63d2\u503c\u548c\u5207\u6bd4\u96ea\u592b\u7ea7\u6570\u7684\u65b0\u65b9\u6cd5\uff0c\u5728CKKS\u540c\u6001\u52a0\u5bc6\u4e2d\u51c6\u786e\u8fd1\u4f3c\u6a21\u51fd\u6570\uff0c\u5e76\u8bbe\u8ba1BitStack\u548cCRTStack\u6570\u636e\u6253\u5305\u65b9\u6848\uff0c\u5b9e\u73b0\u9ad8\u6548\u5bc6\u6587\u4e0a\u4f20\u548c\u5b8c\u6574\u8f93\u5165\u8303\u56f4\u7684\u51c6\u786e\u6a21\u8fd0\u7b97\u3002", "motivation": "\u6a21\u51fd\u6570\u5728\u6570\u636e\u7f16\u7801\u548c\u5bc6\u7801\u5b66\u539f\u8bed\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5e7f\u6cdb\u4f7f\u7528\u7684CKKS\u540c\u6001\u52a0\u5bc6\u65b9\u6848\u4ec5\u652f\u6301\u7b97\u672f\u8fd0\u7b97\uff0c\u96be\u4ee5\u5728\u52a0\u5bc6\u6570\u636e\u4e0a\u6267\u884c\u6a21\u8ba1\u7b97\u3002\u73b0\u6709\u65b9\u6cd5\u53ea\u80fd\u5728\u6709\u9650\u5b50\u8303\u56f4\u5185\u63d0\u4f9b\u51c6\u786e\u7ed3\u679c\uff0c\u65e0\u6cd5\u5b9e\u73b0\u5b8c\u6574\u8f93\u5165\u8303\u56f4\u7684\u51c6\u786e\u8fd1\u4f3c\u3002", "method": "\u57fa\u4e8e\u591a\u9879\u5f0f\u63d2\u503c\u548c\u5207\u6bd4\u96ea\u592b\u7ea7\u6570\u51c6\u786e\u8fd1\u4f3c\u6a21\u51fd\u6570\uff1b\u9488\u5bf9CKKS\u4e2d\u7684\u5c0f\u6574\u6570\u8f93\u5165\u8bbe\u8ba1BitStack\u548cCRTStack\u4e24\u79cd\u9ad8\u6548\u6570\u636e\u6253\u5305\u65b9\u6848\uff0c\u63d0\u5347\u660e\u6587\u7a7a\u95f4\u5229\u7528\u7387\uff1b\u5e94\u7528\u8be5\u6a21\u51fd\u6570\u5b9e\u73b0\u540c\u6001\u820d\u5165\u64cd\u4f5c\u548c\u4ece\u52a0\u6cd5\u79d8\u5bc6\u5206\u4eab\u5230CKKS\u5bc6\u6587\u7684\u4e00\u822c\u8f6c\u6362\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u65b9\u6cd5\u8fbe\u5230\u9ad8\u8fd1\u4f3c\u7cbe\u5ea6\uff08\u9ad8\u8fbe1e-8\uff09\uff1b\u5b9e\u73b0\u4e86\u51c6\u786e\u7684\u5bc6\u6587\u820d\u5165\u548c\u5b8c\u6574\u7684\u79d8\u5bc6\u5206\u4eab\u5230CKKS\u8f6c\u6362\uff1b\u663e\u8457\u63d0\u5347\u4e86CKKS\u660e\u6587\u7a7a\u95f4\u5229\u7528\u7387\uff0c\u652f\u6301\u9ad8\u6548\u7684\u5bc6\u6587\u4e0a\u4f20\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3aCKKS\u4e0b\u7684\u6a21\u8fd0\u7b97\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6269\u5c55\u4e86\u5176\u5728\u9690\u79c1\u4fdd\u62a4\u8ba1\u7b97\u4e2d\u7684\u9002\u7528\u6027\uff0c\u89e3\u51b3\u4e86\u5b8c\u6574\u8f93\u5165\u8303\u56f4\u51c6\u786e\u8fd1\u4f3c\u6a21\u51fd\u6570\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2512.20073", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.20073", "abs": "https://arxiv.org/abs/2512.20073", "authors": ["Hongyang Shang", "Shuai Dong", "Ye Ke", "Arindam Basu"], "title": "3D Stack In-Sensor-Computing (3DS-ISC): Accelerating Time-Surface Construction for Neuromorphic Event Cameras", "comment": null, "summary": "This work proposes a 3D Stack In-Sensor-Computing (3DS-ISC) architecture for efficient event-based vision processing. A real-time normalization method using an exponential decay function is introduced to construct the time-surface, reducing hardware usage while preserving temporal information. The circuit design utilizes the leakage characterization of Dynamic Random Access Memory(DRAM) for timestamp normalization. Custom interdigitated metal-oxide-metal capacitor (MOMCAP) is used to store the charge and low leakage switch (LL switch) is used to extend the effective charge storage time. The 3DS-ISC architecture integrates sensing, memory, and computation to overcome the memory wall problem, reducing power, latency, and reducing area by 69x, 2.2x and 1.9x, respectively, compared with its 2D counterpart. Moreover, compared to works using a 16-bit SRAM to store timestamps, the ISC analog array can reduce power consumption by three orders of magnitude. In real computer vision (CV) tasks, we applied the spatial-temporal correlation filter (STCF) for denoise, and 3D-ISC achieved almost equivalent accuracy compared to the digital implementation using high precision timestamps. As for the image classification, time-surface constructed by 3D-ISC is used as the input of GoogleNet, achieving 99% on N-MNIST, 85% on N-Caltech101, 78% on CIFAR10-DVS, and 97% on DVS128 Gesture, comparable with state-of-the-art results on each dataset. Additionally, the 3D-ISC method is also applied to image reconstruction using the DAVIS240C dataset, achieving the highest average SSIM (0.62) among three methods. This work establishes a foundation for real-time, resource-efficient event-based processing and points to future integration of advanced computational circuits for broader applications.", "AI": {"tldr": "\u63d0\u51fa3D\u5806\u53e0\u4f20\u611f\u5668\u5185\u8ba1\u7b97\u67b6\u6784\uff0c\u901a\u8fc7\u6307\u6570\u8870\u51cf\u51fd\u6570\u5b9e\u73b0\u5b9e\u65f6\u65f6\u95f4\u8868\u9762\u5f52\u4e00\u5316\uff0c\u5229\u7528DRAM\u6cc4\u6f0f\u7279\u6027\u964d\u4f4e\u786c\u4ef6\u5f00\u9500\uff0c\u5728\u4e8b\u4ef6\u89c6\u89c9\u5904\u7406\u4e2d\u663e\u8457\u63d0\u5347\u80fd\u6548\u548c\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u4e8b\u4ef6\u89c6\u89c9\u5904\u7406\u5b58\u5728\u5185\u5b58\u5899\u95ee\u9898\uff0c\u9700\u8981\u5927\u91cf\u786c\u4ef6\u8d44\u6e90\u5b58\u50a8\u65f6\u95f4\u6233\uff0c\u5bfc\u81f4\u529f\u8017\u9ad8\u3001\u5ef6\u8fdf\u5927\u3002\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u96c6\u6210\u611f\u77e5\u3001\u5b58\u50a8\u548c\u8ba1\u7b97\u7684\u9ad8\u6548\u67b6\u6784\u3002", "method": "\u91c7\u75283D\u5806\u53e0\u4f20\u611f\u5668\u5185\u8ba1\u7b97\u67b6\u6784\uff0c\u5f15\u5165\u6307\u6570\u8870\u51cf\u51fd\u6570\u5b9e\u65f6\u5f52\u4e00\u5316\u65f6\u95f4\u8868\u9762\uff0c\u5229\u7528DRAM\u6cc4\u6f0f\u7279\u6027\u8fdb\u884c\u65f6\u95f4\u6233\u5f52\u4e00\u5316\uff0c\u4f7f\u7528\u5b9a\u5236\u91d1\u5c5e-\u6c27\u5316\u7269-\u91d1\u5c5e\u7535\u5bb9\u5b58\u50a8\u7535\u8377\uff0c\u4f4e\u6cc4\u6f0f\u5f00\u5173\u5ef6\u957f\u6709\u6548\u7535\u8377\u5b58\u50a8\u65f6\u95f4\u3002", "result": "\u76f8\u6bd42D\u67b6\u6784\uff0c\u529f\u8017\u964d\u4f4e69\u500d\uff0c\u5ef6\u8fdf\u51cf\u5c112.2\u500d\uff0c\u9762\u79ef\u51cf\u5c111.9\u500d\uff1b\u76f8\u6bd416\u4f4dSRAM\u5b58\u50a8\u65f6\u95f4\u6233\u65b9\u6848\uff0c\u529f\u8017\u964d\u4f4e\u4e09\u4e2a\u6570\u91cf\u7ea7\uff1b\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e0e\u6570\u5b57\u5b9e\u73b0\u76f8\u5f53\u7684\u7cbe\u5ea6\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u53ef\u6bd4\u7684\u7ed3\u679c\u3002", "conclusion": "3D\u5806\u53e0\u4f20\u611f\u5668\u5185\u8ba1\u7b97\u67b6\u6784\u4e3a\u5b9e\u65f6\u3001\u8d44\u6e90\u9ad8\u6548\u7684\u4e8b\u4ef6\u89c6\u89c9\u5904\u7406\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u672a\u6765\u53ef\u96c6\u6210\u66f4\u5148\u8fdb\u7684\u8ba1\u7b97\u7535\u8def\u4ee5\u6269\u5c55\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2512.19968", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.19968", "abs": "https://arxiv.org/abs/2512.19968", "authors": ["Ali Farahbakhsh", "Giuliano Losa", "Youer Pu", "Lorenzo Alvisi", "Ittay Eyal"], "title": "Fast Deterministically Safe Proof-of-Work Consensus", "comment": null, "summary": "Permissionless blockchains achieve consensus while allowing unknown nodes to join and leave the system at any time. They typically come in two flavors: proof of work (PoW) and proof of stake (PoS), and both are vulnerable to attacks. PoS protocols suffer from long-range attacks, wherein attackers alter execution history at little cost, and PoW protocols are vulnerable to attackers with enough computational power to subvert execution history. PoS protocols respond by relying on external mechanisms like social consensus; PoW protocols either fall back to probabilistic guarantees, or are slow.\n  We present Sieve-MMR, the first fully-permissionless protocol with deterministic security and constant expected latency that does not rely on external mechanisms. We obtain Sieve-MMR by porting a PoS protocol (MMR) to the PoW setting. From MMR we inherit constant expected latency and deterministic security, and proof-of-work gives us resilience against long-range attacks. The main challenge to porting MMR to the PoW setting is what we call time-travel attacks, where attackers use PoWs generated in the distant past to increase their perceived PoW power in the present. We respond by proposing Sieve, a novel algorithm that implements a new broadcast primitive we dub time-travel-resilient broadcast (TTRB). Sieve relies on a black-box, deterministic PoW primitive to implement TTRB, which we use as the messaging layer for MMR.", "AI": {"tldr": "Sieve-MMR\u662f\u9996\u4e2a\u5177\u6709\u786e\u5b9a\u6027\u5b89\u5168\u6027\u548c\u6052\u5b9a\u9884\u671f\u5ef6\u8fdf\u7684\u5b8c\u5168\u65e0\u8bb8\u53ef\u534f\u8bae\uff0c\u901a\u8fc7\u5c06PoS\u534f\u8baeMMR\u79fb\u690d\u5230PoW\u73af\u5883\u5b9e\u73b0\uff0c\u89e3\u51b3\u4e86PoW\u7684\u65f6\u95f4\u65c5\u884c\u653b\u51fb\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65e0\u8bb8\u53ef\u533a\u5757\u94fe\u534f\u8bae\uff08PoW\u548cPoS\uff09\u90fd\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff1aPoS\u6613\u53d7\u957f\u7a0b\u653b\u51fb\uff0cPoW\u6613\u53d7\u7b97\u529b\u653b\u51fb\u3002PoS\u4f9d\u8d56\u5916\u90e8\u793e\u4f1a\u5171\u8bc6\u673a\u5236\uff0cPoW\u8981\u4e48\u4f9d\u8d56\u6982\u7387\u6027\u4fdd\u8bc1\u8981\u4e48\u901f\u5ea6\u6162\u3002\u9700\u8981\u4e00\u79cd\u4e0d\u4f9d\u8d56\u5916\u90e8\u673a\u5236\u3001\u5177\u6709\u786e\u5b9a\u6027\u5b89\u5168\u6027\u548c\u6052\u5b9a\u5ef6\u8fdf\u7684\u5b8c\u5168\u65e0\u8bb8\u53ef\u534f\u8bae\u3002", "method": "\u5c06PoS\u534f\u8baeMMR\u79fb\u690d\u5230PoW\u73af\u5883\uff0c\u63d0\u51faSieve\u7b97\u6cd5\u5b9e\u73b0\u65f6\u95f4\u65c5\u884c\u5f39\u6027\u5e7f\u64ad\uff08TTRB\uff09\u539f\u8bed\u3002Sieve\u4f7f\u7528\u9ed1\u76d2\u786e\u5b9a\u6027PoW\u539f\u8bed\u5b9e\u73b0TTRB\uff0c\u4f5c\u4e3aMMR\u7684\u6d88\u606f\u4f20\u9012\u5c42\uff0c\u4ece\u800c\u89e3\u51b3\u65f6\u95f4\u65c5\u884c\u653b\u51fb\u95ee\u9898\u3002", "result": "Sieve-MMR\u534f\u8bae\u7ed3\u5408\u4e86MMR\u7684\u6052\u5b9a\u9884\u671f\u5ef6\u8fdf\u548c\u786e\u5b9a\u6027\u5b89\u5168\u6027\uff0c\u540c\u65f6\u5229\u7528PoW\u62b5\u5fa1\u957f\u7a0b\u653b\u51fb\uff0c\u5b9e\u73b0\u4e86\u9996\u4e2a\u4e0d\u4f9d\u8d56\u5916\u90e8\u673a\u5236\u3001\u5177\u6709\u786e\u5b9a\u6027\u5b89\u5168\u6027\u548c\u6052\u5b9a\u5ef6\u8fdf\u7684\u5b8c\u5168\u65e0\u8bb8\u53ef\u534f\u8bae\u3002", "conclusion": "Sieve-MMR\u6210\u529f\u89e3\u51b3\u4e86\u65e0\u8bb8\u53ef\u533a\u5757\u94fe\u7684\u5b89\u5168\u6027\u548c\u5ef6\u8fdf\u95ee\u9898\uff0c\u901a\u8fc7\u521b\u65b0\u7684Sieve\u7b97\u6cd5\u548cTTRB\u5e7f\u64ad\u539f\u8bed\uff0c\u5b9e\u73b0\u4e86PoW\u73af\u5883\u4e0bMMR\u534f\u8bae\u7684\u5b89\u5168\u79fb\u690d\uff0c\u4e3a\u65e0\u8bb8\u53ef\u533a\u5757\u94fe\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.19851", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.19851", "abs": "https://arxiv.org/abs/2512.19851", "authors": ["Aditya Bhosale", "Laxmikant Kale"], "title": "An Adaptive Distributed Stencil Abstraction for GPUs", "comment": null, "summary": "The scientific computing ecosystem in Python is largely confined to single-node parallelism, creating a gap between high-level prototyping in NumPy and high-performance execution on modern supercomputers. The increasing prevalence of hardware accelerators and the need for energy efficiency have made resource adaptivity a critical requirement, yet traditional HPC abstractions remain rigid. To address these challenges, we present an adaptive, distributed abstraction for stencil computations on multi-node GPUs. This abstraction is built using CharmTyles, a framework based on the adaptive Charm++ runtime, and features a familiar NumPy-like syntax to minimize the porting effort from prototype to production code. We showcase the resource elasticity of our abstraction by dynamically rescaling a running application across a different number of nodes and present a performance analysis of the associated overheads. Furthermore, we demonstrate that our abstraction achieves significant performance improvements over both a specialized, high-performance stencil DSL and a generalized NumPy replacement.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eCharm++\u7684\u81ea\u9002\u5e94\u5206\u5e03\u5f0f\u62bd\u8c61\u5c42\uff0c\u7528\u4e8e\u591a\u8282\u70b9GPU\u4e0a\u7684\u6a21\u677f\u8ba1\u7b97\uff0c\u63d0\u4f9bNumPy\u98ce\u683c\u8bed\u6cd5\uff0c\u5b9e\u73b0\u8d44\u6e90\u5f39\u6027\u4f38\u7f29\u548c\u6027\u80fd\u4f18\u5316", "motivation": "Python\u79d1\u5b66\u8ba1\u7b97\u751f\u6001\u7cfb\u7edf\u4e3b\u8981\u5c40\u9650\u4e8e\u5355\u8282\u70b9\u5e76\u884c\uff0cNumPy\u539f\u578b\u4e0e\u9ad8\u6027\u80fd\u8d85\u7ea7\u8ba1\u7b97\u4e4b\u95f4\u5b58\u5728\u9e3f\u6c9f\u3002\u786c\u4ef6\u52a0\u901f\u5668\u666e\u53ca\u548c\u80fd\u6548\u9700\u6c42\u4f7f\u8d44\u6e90\u9002\u5e94\u6027\u6210\u4e3a\u5173\u952e\u8981\u6c42\uff0c\u4f46\u4f20\u7edfHPC\u62bd\u8c61\u4ecd\u7136\u50f5\u5316", "method": "\u57fa\u4e8e\u81ea\u9002\u5e94Charm++\u8fd0\u884c\u65f6\u6784\u5efaCharmTyles\u6846\u67b6\uff0c\u521b\u5efa\u652f\u6301\u591a\u8282\u70b9GPU\u7684\u5206\u5e03\u5f0f\u6a21\u677f\u8ba1\u7b97\u62bd\u8c61\u5c42\uff0c\u91c7\u7528\u7c7b\u4f3cNumPy\u7684\u719f\u6089\u8bed\u6cd5\u4ee5\u6700\u5c0f\u5316\u4ece\u539f\u578b\u5230\u751f\u4ea7\u4ee3\u7801\u7684\u79fb\u690d\u5de5\u4f5c", "result": "\u5c55\u793a\u4e86\u8d44\u6e90\u5f39\u6027\u80fd\u529b\uff0c\u53ef\u52a8\u6001\u8c03\u6574\u8fd0\u884c\u4e2d\u7684\u5e94\u7528\u7a0b\u5e8f\u5230\u4e0d\u540c\u8282\u70b9\u6570\u91cf\uff0c\u5206\u6790\u4e86\u76f8\u5173\u5f00\u9500\u3002\u76f8\u6bd4\u4e13\u7528\u9ad8\u6027\u80fd\u6a21\u677fDSL\u548c\u901a\u7528NumPy\u66ff\u4ee3\u65b9\u6848\uff0c\u8be5\u62bd\u8c61\u5c42\u5b9e\u73b0\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347", "conclusion": "\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u5206\u5e03\u5f0f\u62bd\u8c61\u5c42\u6210\u529f\u5f25\u5408\u4e86NumPy\u539f\u578b\u4e0e\u9ad8\u6027\u80fd\u8d85\u7ea7\u8ba1\u7b97\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u901a\u8fc7\u8d44\u6e90\u5f39\u6027\u548cNumPy\u98ce\u683c\u8bed\u6cd5\uff0c\u4e3a\u6a21\u677f\u8ba1\u7b97\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u591a\u8282\u70b9GPU\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.20198", "categories": ["cs.AR", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.20198", "abs": "https://arxiv.org/abs/2512.20198", "authors": ["Huizheng Wang", "Taiquan Wei", "Hongbin Wang", "Zichuan Wang", "Xinru Tang", "Zhiheng Yue", "Shaojun Wei", "Yang Hu", "Shouyi Yin"], "title": "Designing Spatial Architectures for Sparse Attention: STAR Accelerator via Cross-Stage Tiling", "comment": "Accepted for publication in IEEE Transactions on Computers", "summary": "Large language models (LLMs) rely on self-attention for contextual understanding, demanding high-throughput inference and large-scale token parallelism (LTPP). Existing dynamic sparsity accelerators falter under LTPP scenarios due to stage-isolated optimizations. Revisiting the end-to-end sparsity acceleration flow, we identify an overlooked opportunity: cross-stage coordination can substantially reduce redundant computation and memory access. We propose STAR, a cross-stage compute- and memory-efficient algorithm-hardware co-design tailored for Transformer inference under LTPP. STAR introduces a leading-zero-based sparsity prediction using log-domain add-only operations to minimize prediction overhead. It further employs distributed sorting and a sorted updating FlashAttention mechanism, guided by a coordinated tiling strategy that enables fine-grained stage interaction for improved memory efficiency and latency. These optimizations are supported by a dedicated STAR accelerator architecture, achieving up to 9.2$\\times$ speedup and 71.2$\\times$ energy efficiency over A100, and surpassing SOTA accelerators by up to 16.1$\\times$ energy and 27.1$\\times$ area efficiency gains. Further, we deploy STAR onto a multi-core spatial architecture, optimizing dataflow and execution orchestration for ultra-long sequence processing. Architectural evaluation shows that, compared to the baseline design, Spatial-STAR achieves a 20.1$\\times$ throughput improvement.", "AI": {"tldr": "STAR\u662f\u4e00\u79cd\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u957f\u5e8f\u5217\u5e76\u884c\u63a8\u7406\u7684\u8de8\u9636\u6bb5\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u901a\u8fc7\u7a00\u758f\u9884\u6d4b\u548c\u534f\u8c03\u5206\u5757\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u548c\u5185\u5b58\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u52a8\u6001\u7a00\u758f\u6027\u52a0\u901f\u5668\u5728\u957f\u5e8f\u5217\u5e76\u884c\u5904\u7406\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u5b83\u4eec\u662f\u9636\u6bb5\u9694\u79bb\u4f18\u5316\u7684\u3002\u7814\u7a76\u53d1\u73b0\u8de8\u9636\u6bb5\u534f\u8c03\u53ef\u4ee5\u5927\u5e45\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\u548c\u5185\u5b58\u8bbf\u95ee\u3002", "method": "\u63d0\u51faSTAR\u8de8\u9636\u6bb5\u534f\u540c\u8bbe\u8ba1\uff1a1) \u57fa\u4e8e\u524d\u5bfc\u96f6\u7684\u7a00\u758f\u9884\u6d4b\uff0c\u4f7f\u7528\u5bf9\u6570\u57df\u4ec5\u52a0\u6cd5\u64cd\u4f5c\u6700\u5c0f\u5316\u9884\u6d4b\u5f00\u9500\uff1b2) \u5206\u5e03\u5f0f\u6392\u5e8f\u548c\u6392\u5e8f\u66f4\u65b0FlashAttention\u673a\u5236\uff1b3) \u534f\u8c03\u5206\u5757\u7b56\u7565\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u9636\u6bb5\u4ea4\u4e92\uff1b4) \u4e13\u7528STAR\u52a0\u901f\u5668\u67b6\u6784\u548c\u591a\u6838\u7a7a\u95f4\u67b6\u6784\u90e8\u7f72\u3002", "result": "\u76f8\u6bd4A100\u5b9e\u73b09.2\u500d\u52a0\u901f\u548c71.2\u500d\u80fd\u6548\u63d0\u5347\uff0c\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u52a0\u901f\u566816.1\u500d\u80fd\u6548\u548c27.1\u500d\u9762\u79ef\u6548\u7387\u3002\u5728\u591a\u6838\u7a7a\u95f4\u67b6\u6784\u4e0a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u8bbe\u8ba1\u5b9e\u73b020.1\u500d\u541e\u5410\u91cf\u63d0\u5347\u3002", "conclusion": "STAR\u901a\u8fc7\u8de8\u9636\u6bb5\u534f\u540c\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u957f\u5e8f\u5217\u5e76\u884c\u5904\u7406\u4e2d\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u6548\u7387\u95ee\u9898\uff0c\u4e3aTransformer\u63a8\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.20043", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20043", "abs": "https://arxiv.org/abs/2512.20043", "authors": ["Jung Yeon Park", "Yuxuan Chen", "Floor Eijkelboom", "Jan-Willem van de Meent", "Lawson L. S. Wong", "Robin Walters"], "title": "Discovering Lie Groups with Flow Matching", "comment": null, "summary": "Symmetry is fundamental to understanding physical systems, and at the same time, can improve performance and sample efficiency in machine learning. Both pursuits require knowledge of the underlying symmetries in data. To address this, we propose learning symmetries directly from data via flow matching on Lie groups. We formulate symmetry discovery as learning a distribution over a larger hypothesis group, such that the learned distribution matches the symmetries observed in data. Relative to previous works, our method, \\lieflow, is more flexible in terms of the types of groups it can discover and requires fewer assumptions. Experiments on 2D and 3D point clouds demonstrate the successful discovery of discrete groups, including reflections by flow matching over the complex domain. We identify a key challenge where the symmetric arrangement of the target modes causes ``last-minute convergence,'' where samples remain stationary until relatively late in the flow, and introduce a novel interpolation scheme for flow matching for symmetry discovery.", "AI": {"tldr": "\u63d0\u51faLieFlow\u65b9\u6cd5\uff0c\u901a\u8fc7\u6d41\u5339\u914d\u5728Lie\u7fa4\u4e0a\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u5bf9\u79f0\u6027\uff0c\u80fd\u591f\u53d1\u73b0\u66f4\u7075\u6d3b\u7c7b\u578b\u7684\u7fa4\u7ed3\u6784\uff0c\u57282D\u548c3D\u70b9\u4e91\u4e0a\u6210\u529f\u53d1\u73b0\u4e86\u5305\u62ec\u53cd\u5c04\u5728\u5185\u7684\u79bb\u6563\u7fa4", "motivation": "\u5bf9\u79f0\u6027\u5bf9\u7406\u89e3\u7269\u7406\u7cfb\u7edf\u548c\u63d0\u5347\u673a\u5668\u5b66\u4e60\u6027\u80fd\u90fd\u5f88\u91cd\u8981\uff0c\u4f46\u9700\u8981\u4e86\u89e3\u6570\u636e\u4e2d\u7684\u5e95\u5c42\u5bf9\u79f0\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u53d1\u73b0\u5bf9\u79f0\u6027\u65b9\u9762\u5b58\u5728\u9650\u5236\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u5bf9\u79f0\u6027", "method": "\u63d0\u51faLieFlow\u65b9\u6cd5\uff0c\u5c06\u5bf9\u79f0\u6027\u53d1\u73b0\u5b9a\u4e49\u4e3a\u5728\u66f4\u5927\u7684\u5047\u8bbe\u7fa4\u4e0a\u5b66\u4e60\u5206\u5e03\uff0c\u4f7f\u5b66\u4e60\u5230\u7684\u5206\u5e03\u4e0e\u6570\u636e\u4e2d\u89c2\u5bdf\u5230\u7684\u5bf9\u79f0\u6027\u5339\u914d\u3002\u901a\u8fc7Lie\u7fa4\u4e0a\u7684\u6d41\u5339\u914d\u6765\u5b66\u4e60\u5bf9\u79f0\u6027\uff0c\u5e76\u9488\u5bf9\u76ee\u6807\u6a21\u5f0f\u5bf9\u79f0\u6392\u5217\u5bfc\u81f4\u7684\"\u6700\u540e\u4e00\u523b\u6536\u655b\"\u95ee\u9898\uff0c\u5f15\u5165\u4e86\u65b0\u7684\u6d41\u5339\u914d\u63d2\u503c\u65b9\u6848", "result": "\u57282D\u548c3D\u70b9\u4e91\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6210\u529f\u53d1\u73b0\u4e86\u79bb\u6563\u7fa4\uff0c\u5305\u62ec\u901a\u8fc7\u590d\u6570\u57df\u4e0a\u7684\u6d41\u5339\u914d\u53d1\u73b0\u7684\u53cd\u5c04\u5bf9\u79f0\u6027\u3002\u76f8\u6bd4\u4e4b\u524d\u7684\u5de5\u4f5c\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u53d1\u73b0\u66f4\u7075\u6d3b\u7c7b\u578b\u7684\u7fa4\uff0c\u4e14\u9700\u8981\u66f4\u5c11\u7684\u5047\u8bbe", "conclusion": "LieFlow\u65b9\u6cd5\u80fd\u591f\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u5bf9\u79f0\u6027\uff0c\u5728\u5bf9\u79f0\u6027\u53d1\u73b0\u65b9\u9762\u6bd4\u5148\u524d\u65b9\u6cd5\u66f4\u7075\u6d3b\uff0c\u4e3a\u7406\u89e3\u7269\u7406\u7cfb\u7edf\u548c\u63d0\u5347\u673a\u5668\u5b66\u4e60\u6027\u80fd\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177"}}
{"id": "2512.19997", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.19997", "abs": "https://arxiv.org/abs/2512.19997", "authors": ["Yanjing Yang", "He Zhang", "Bohan Liu", "Jinwei Xu", "Jinghao Hu", "Liming Dong", "Zhewen Mao", "Dongxue Pan"], "title": "BacAlarm: Mining and Simulating Composite API Traffic to Prevent Broken Access Control Violations", "comment": "The full version of this work consists of 15 pages and has been submitted to IEEE Transactions on Software Engineering (TSE)", "summary": "Broken Access Control (BAC) violations, which consistently rank among the top five security risks in the OWASP API Security Top 10, refer to unauthorized access attempts arising from BAC vulnerabilities, whose successful exploitation can impose significant risks on exposed application programming interfaces (APIs). In recent years, learning-based methods have demonstrated promising prospects in detecting various types of malicious activities. However, in real-network operation and maintenance scenarios, leveraging learning-based methods for BAC detection faces two critical challenges. Firstly, under the RESTful API design principles, most systems omit recording composite traffic for performance, and together with ethical and legal bans on directly testing real-world systems, this leads to a critical shortage of training data for detecting BAC violations. Secondly, common malicious behaviors such as SQL injection typically generate individual access traffic that is inherently anomalous. In contrast, BAC is usually composed of multiple correlated access requests that appear normal when examined in isolation. To tackle these problems, we introduce \\BAC, an approach for establishing a BAC violation detection model by generating and utilizing API traffic data. The \\BAC consists of an API Traffic Generator and a BAC Detector. Experimental results show that \\BAC outperforms current state-of-the-art invariant-based and learning-based methods with the $\\text{F}_1$ and MCC improving by 21.2\\% and 24.1\\%.", "AI": {"tldr": "BAC\u662f\u4e00\u79cd\u57fa\u4e8eAPI\u6d41\u91cf\u751f\u6210\u548c\u5b66\u4e60\u7684BAC\u8fdd\u89c4\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u8bad\u7ec3\u6570\u636e\u89e3\u51b3\u6570\u636e\u77ed\u7f3a\u95ee\u9898\uff0c\u5e76\u5229\u7528\u591a\u8bf7\u6c42\u5173\u8054\u5206\u6790\u68c0\u6d4bBAC\u653b\u51fb\u3002", "motivation": "BAC\u8fdd\u89c4\u662fOWASP API\u5b89\u5168\u524d\u4e94\u5927\u98ce\u9669\u4e4b\u4e00\uff0c\u4f46\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1\uff09RESTful API\u8bbe\u8ba1\u4e0b\u8bad\u7ec3\u6570\u636e\u4e25\u91cd\u77ed\u7f3a\uff1b2\uff09BAC\u653b\u51fb\u7531\u591a\u4e2a\u770b\u4f3c\u6b63\u5e38\u7684\u5173\u8054\u8bf7\u6c42\u7ec4\u6210\uff0c\u96be\u4ee5\u901a\u8fc7\u5355\u8bf7\u6c42\u5f02\u5e38\u68c0\u6d4b\u53d1\u73b0\u3002", "method": "\u63d0\u51faBAC\u65b9\u6cd5\uff0c\u5305\u542bAPI\u6d41\u91cf\u751f\u6210\u5668\u548cBAC\u68c0\u6d4b\u5668\u4e24\u90e8\u5206\u3002\u6d41\u91cf\u751f\u6210\u5668\u89e3\u51b3\u6570\u636e\u77ed\u7f3a\u95ee\u9898\uff0c\u68c0\u6d4b\u5668\u901a\u8fc7\u5206\u6790\u591a\u8bf7\u6c42\u5173\u8054\u6a21\u5f0f\u8bc6\u522bBAC\u8fdd\u89c4\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cBAC\u65b9\u6cd5\u5728F1\u5206\u6570\u548cMCC\u6307\u6807\u4e0a\u5206\u522b\u6bd4\u5f53\u524d\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u4e0d\u53d8\u5f0f\u548c\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e8621.2%\u548c24.1%\u3002", "conclusion": "BAC\u65b9\u6cd5\u901a\u8fc7\u751f\u6210API\u6d41\u91cf\u6570\u636e\u5e76\u5229\u7528\u591a\u8bf7\u6c42\u5173\u8054\u5206\u6790\uff0c\u6709\u6548\u89e3\u51b3\u4e86BAC\u8fdd\u89c4\u68c0\u6d4b\u4e2d\u7684\u6570\u636e\u77ed\u7f3a\u548c\u68c0\u6d4b\u96be\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2512.20495", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.20495", "abs": "https://arxiv.org/abs/2512.20495", "authors": ["He Zhu", "Zheng Liu", "Xingyang Li", "Anbang Wu", "Jieru Zhao", "Fangxin Liu", "Yiming Gan", "Jingwen Leng", "Yu Feng"], "title": "Nebula: Enable City-Scale 3D Gaussian Splatting in Virtual Reality via Collaborative Rendering and Accelerated Stereo Rasterization", "comment": null, "summary": "3D Gaussian splatting (3DGS) has drawn significant attention in the architectural community recently. However, current architectural designs often overlook the 3DGS scalability, making them fragile for extremely large-scale 3DGS. Meanwhile, the VR bandwidth requirement makes it impossible to deliver high-fidelity and smooth VR content from the cloud.\n  We present Nebula, a coherent acceleration framework for large-scale 3DGS collaborative rendering. Instead of streaming videos, Nebula streams intermediate results after the LoD search, reducing 1925% data communication between the cloud and the client. To further enhance the motion-to-photon experience, we introduce a temporal-aware LoD search in the cloud that tames the irregular memory access and reduces redundant data access by exploiting temporal coherence across frames. On the client side, we propose a novel stereo rasterization that enables two eyes to share most computations during the stereo rendering with bit-accurate quality. With minimal hardware augmentations, Nebula achieves 2.7$\\times$ motion-to-photon speedup and reduces 1925% bandwidth over lossy video streaming.", "AI": {"tldr": "Nebula\u662f\u4e00\u4e2a\u7528\u4e8e\u5927\u89c4\u6a213D\u9ad8\u65af\u6e85\u5c04\u534f\u540c\u6e32\u67d3\u7684\u52a0\u901f\u6846\u67b6\uff0c\u901a\u8fc7\u6d41\u5f0f\u4f20\u8f93\u4e2d\u95f4\u7ed3\u679c\u800c\u975e\u89c6\u9891\uff0c\u5927\u5e45\u51cf\u5c11\u4e91\u4e0e\u5ba2\u6237\u7aef\u95f4\u7684\u6570\u636e\u4f20\u8f93\uff0c\u5e76\u63d0\u5347VR\u4f53\u9a8c\u7684\u6d41\u7545\u5ea6\u3002", "motivation": "\u5f53\u524d3D\u9ad8\u65af\u6e85\u5c04\u67b6\u6784\u8bbe\u8ba1\u5ffd\u7565\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u5bf9\u5927\u89c4\u6a21\u573a\u666f\u5904\u7406\u8106\u5f31\uff1b\u540c\u65f6VR\u5e26\u5bbd\u9700\u6c42\u4f7f\u5f97\u4e91\u7aef\u65e0\u6cd5\u4f20\u8f93\u9ad8\u4fdd\u771f\u3001\u6d41\u7545\u7684VR\u5185\u5bb9\u3002", "method": "1) \u6d41\u5f0f\u4f20\u8f93LoD\u641c\u7d22\u540e\u7684\u4e2d\u95f4\u7ed3\u679c\u800c\u975e\u89c6\u9891\uff0c\u51cf\u5c111925%\u6570\u636e\u4f20\u8f93\uff1b2) \u4e91\u7aef\u5f15\u5165\u65f6\u95f4\u611f\u77e5\u7684LoD\u641c\u7d22\uff0c\u5229\u7528\u5e27\u95f4\u65f6\u95f4\u4e00\u81f4\u6027\u51cf\u5c11\u5197\u4f59\u6570\u636e\u8bbf\u95ee\uff1b3) \u5ba2\u6237\u7aef\u63d0\u51fa\u65b0\u9896\u7684\u7acb\u4f53\u5149\u6805\u5316\u6280\u672f\uff0c\u8ba9\u53cc\u773c\u5171\u4eab\u5927\u90e8\u5206\u8ba1\u7b97\uff1b4) \u6700\u5c0f\u786c\u4ef6\u589e\u5f3a\u3002", "result": "\u5b9e\u73b0\u4e862.7\u500d\u7684\u8fd0\u52a8\u5230\u5149\u5b50\u5ef6\u8fdf\u52a0\u901f\uff0c\u76f8\u6bd4\u6709\u635f\u89c6\u9891\u6d41\u51cf\u5c11\u4e861925%\u7684\u5e26\u5bbd\u6d88\u8017\u3002", "conclusion": "Nebula\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u7684\u534f\u540c\u6e32\u67d3\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a213D\u9ad8\u65af\u6e85\u5c04\u7684\u6269\u5c55\u6027\u548cVR\u5e26\u5bbd\u74f6\u9888\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86VR\u4f53\u9a8c\u8d28\u91cf\u3002"}}
{"id": "2512.20052", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.20052", "abs": "https://arxiv.org/abs/2512.20052", "authors": ["Hung-Chieh Fang", "Kuo-Han Hung", "Chu-Rong Chen", "Po-Jung Chou", "Chun-Kai Yang", "Po-Chen Ko", "Yu-Chiang Wang", "Yueh-Hua Wu", "Min-Hung Chen", "Shao-Hua Sun"], "title": "Learning Skills from Action-Free Videos", "comment": null, "summary": "Learning from videos offers a promising path toward generalist robots by providing rich visual and temporal priors beyond what real robot datasets contain. While existing video generative models produce impressive visual predictions, they are difficult to translate into low-level actions. Conversely, latent-action models better align videos with actions, but they typically operate at the single-step level and lack high-level planning capabilities. We bridge this gap by introducing Skill Abstraction from Optical Flow (SOF), a framework that learns latent skills from large collections of action-free videos. Our key idea is to learn a latent skill space through an intermediate representation based on optical flow that captures motion information aligned with both video dynamics and robot actions. By learning skills in this flow-based latent space, SOF enables high-level planning over video-derived skills and allows for easier translation of these skills into actions. Experiments show that our approach consistently improves performance in both multitask and long-horizon settings, demonstrating the ability to acquire and compose skills directly from raw visual data.", "AI": {"tldr": "SOF\u6846\u67b6\u4ece\u65e0\u52a8\u4f5c\u89c6\u9891\u4e2d\u5b66\u4e60\u57fa\u4e8e\u5149\u6d41\u7684\u6f5c\u5728\u6280\u80fd\uff0c\u5b9e\u73b0\u9ad8\u7ea7\u89c4\u5212\u5e76\u63d0\u5347\u591a\u4efb\u52a1\u548c\u957f\u65f6\u7a0b\u4efb\u52a1\u6027\u80fd", "motivation": "\u73b0\u6709\u89c6\u9891\u751f\u6210\u6a21\u578b\u96be\u4ee5\u8f6c\u5316\u4e3a\u4f4e\u5c42\u52a8\u4f5c\uff0c\u800c\u6f5c\u5728\u52a8\u4f5c\u6a21\u578b\u7f3a\u4e4f\u9ad8\u7ea7\u89c4\u5212\u80fd\u529b\uff0c\u9700\u8981\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd", "method": "\u63d0\u51faSOF\u6846\u67b6\uff0c\u901a\u8fc7\u5149\u6d41\u4e2d\u95f4\u8868\u793a\u5b66\u4e60\u6f5c\u5728\u6280\u80fd\u7a7a\u95f4\uff0c\u8be5\u7a7a\u95f4\u540c\u65f6\u6355\u6349\u89c6\u9891\u52a8\u6001\u548c\u673a\u5668\u4eba\u52a8\u4f5c\u4fe1\u606f", "result": "\u5728\u591a\u4efb\u52a1\u548c\u957f\u65f6\u7a0b\u8bbe\u7f6e\u4e2d\u4e00\u81f4\u63d0\u5347\u6027\u80fd\uff0c\u8bc1\u660e\u80fd\u591f\u76f4\u63a5\u4ece\u539f\u59cb\u89c6\u89c9\u6570\u636e\u83b7\u53d6\u548c\u7ec4\u5408\u6280\u80fd", "conclusion": "SOF\u6210\u529f\u8fde\u63a5\u4e86\u89c6\u9891\u751f\u6210\u6a21\u578b\u548c\u52a8\u4f5c\u6267\u884c\uff0c\u901a\u8fc7\u5149\u6d41\u8868\u793a\u5b9e\u73b0\u4e86\u4ece\u89c6\u9891\u5230\u673a\u5668\u4eba\u6280\u80fd\u7684\u6709\u6548\u8f6c\u5316"}}
{"id": "2512.20017", "categories": ["cs.DC", "cs.GR"], "pdf": "https://arxiv.org/pdf/2512.20017", "abs": "https://arxiv.org/abs/2512.20017", "authors": ["Hexu Zhao", "Xiaoteng Liu", "Xiwen Min", "Jianhao Huang", "Youming Deng", "Yanfei Li", "Ang Li", "Jinyang Li", "Aurojit Panda"], "title": "Scaling Point-based Differentiable Rendering for Large-scale Reconstruction", "comment": "13 pages main text, plus appendix", "summary": "Point-based Differentiable Rendering (PBDR) enables high-fidelity 3D scene reconstruction, but scaling PBDR to high-resolution and large scenes requires efficient distributed training systems. Existing systems are tightly coupled to a specific PBDR method. And they suffer from severe communication overhead due to poor data locality. In this paper, we present Gaian, a general distributed training system for PBDR. Gaian provides a unified API expressive enough to support existing PBDR methods, while exposing rich data-access information, which Gaian leverages to optimize locality and reduce communication. We evaluated Gaian by implementing 4 PBDR algorithms. Our implementations achieve high performance and resource efficiency: across six datasets and up to 128 GPUs, it reduces communication by up to 91% and improves training throughput by 1.50x-3.71x.", "AI": {"tldr": "Gaian\u662f\u4e00\u4e2a\u7528\u4e8e\u70b9\u57fa\u53ef\u5fae\u5206\u6e32\u67d3\u7684\u901a\u7528\u5206\u5e03\u5f0f\u8bad\u7ec3\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f18\u5316\u6570\u636e\u5c40\u90e8\u6027\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\uff0c\u63d0\u5347\u8bad\u7ec3\u6548\u7387", "motivation": "\u73b0\u6709PBDR\u7cfb\u7edf\u4e0e\u7279\u5b9a\u65b9\u6cd5\u7d27\u5bc6\u8026\u5408\uff0c\u4e14\u7531\u4e8e\u6570\u636e\u5c40\u90e8\u6027\u5dee\u5bfc\u81f4\u4e25\u91cd\u7684\u901a\u4fe1\u5f00\u9500\uff0c\u9700\u8981\u901a\u7528\u7684\u9ad8\u6548\u5206\u5e03\u5f0f\u8bad\u7ec3\u7cfb\u7edf", "method": "Gaian\u63d0\u4f9b\u7edf\u4e00\u7684API\u652f\u6301\u73b0\u6709PBDR\u65b9\u6cd5\uff0c\u540c\u65f6\u66b4\u9732\u4e30\u5bcc\u7684\u6570\u636e\u8bbf\u95ee\u4fe1\u606f\uff0c\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u4f18\u5316\u6570\u636e\u5c40\u90e8\u6027\u5e76\u51cf\u5c11\u901a\u4fe1", "result": "\u57286\u4e2a\u6570\u636e\u96c6\u548c\u6700\u591a128\u4e2aGPU\u4e0a\uff0c\u901a\u4fe1\u51cf\u5c11\u9ad8\u8fbe91%\uff0c\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u53471.50-3.71\u500d", "conclusion": "Gaian\u662f\u4e00\u4e2a\u9ad8\u6027\u80fd\u3001\u8d44\u6e90\u9ad8\u6548\u7684\u901a\u7528\u5206\u5e03\u5f0f\u8bad\u7ec3\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86PBDR\u65b9\u6cd5\u7684\u8bad\u7ec3\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027"}}
{"id": "2512.20571", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.20571", "abs": "https://arxiv.org/abs/2512.20571", "authors": ["Brennan Romero", "D. G. Perera"], "title": "Composing Mini Oscilloscope on Embedded Systems", "comment": "22 pages, 11 figures", "summary": "In this paper, our goal is to reproduce the basic functionalities of a regular oscilloscope, using the Nuvoton NUC-140 embedded systems development platform as the front-end and display method. A custom-built daughter board connects the NUC-140 to a variety of peripherals, including two BNC scope-probe connections, an external nine-button keypad, and a calibration signal. The LCD of the NUC-140 development board serves as the waveform display. From the experimental results, it is demonstrated that our proposed system became a very competent debugging tool. It implements 90% of the features we typically use on original oscilloscopes, including: automatic, edge-triggered, and single modes; waveform visualization using vertical and horizontal scaling; probe calibration.", "AI": {"tldr": "\u4f7f\u7528Nuvoton NUC-140\u5d4c\u5165\u5f0f\u5e73\u53f0\u5b9e\u73b0\u57fa\u7840\u793a\u6ce2\u5668\u529f\u80fd\uff0c\u5305\u62ec\u81ea\u52a8\u3001\u8fb9\u6cbf\u89e6\u53d1\u3001\u5355\u6b21\u6a21\u5f0f\uff0c\u6ce2\u5f62\u5782\u76f4/\u6c34\u5e73\u7f29\u653e\uff0c\u63a2\u5934\u6821\u51c6\u7b4990%\u5e38\u7528\u529f\u80fd", "motivation": "\u5229\u7528\u4f4e\u6210\u672c\u5d4c\u5165\u5f0f\u5e73\u53f0\u5b9e\u73b0\u793a\u6ce2\u5668\u57fa\u672c\u529f\u80fd\uff0c\u4e3a\u7535\u5b50\u8c03\u8bd5\u63d0\u4f9b\u7ecf\u6d4e\u5b9e\u7528\u7684\u5de5\u5177\uff0c\u66ff\u4ee3\u4f20\u7edf\u6602\u8d35\u793a\u6ce2\u5668", "method": "\u91c7\u7528Nuvoton NUC-140\u5d4c\u5165\u5f0f\u5f00\u53d1\u5e73\u53f0\u4f5c\u4e3a\u524d\u7aef\u548c\u663e\u793a\uff0c\u901a\u8fc7\u5b9a\u5236\u5b50\u677f\u8fde\u63a5BNC\u63a2\u5934\u63a5\u53e3\u3001\u4e5d\u952e\u952e\u76d8\u548c\u6821\u51c6\u4fe1\u53f7\uff0cLCD\u4f5c\u4e3a\u6ce2\u5f62\u663e\u793a\u5668", "result": "\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\u4e8690%\u5e38\u7528\u793a\u6ce2\u5668\u529f\u80fd\uff0c\u5305\u62ec\u81ea\u52a8\u3001\u8fb9\u6cbf\u89e6\u53d1\u3001\u5355\u6b21\u6a21\u5f0f\uff0c\u6ce2\u5f62\u5782\u76f4/\u6c34\u5e73\u7f29\u653e\uff0c\u63a2\u5934\u6821\u51c6\uff0c\u6210\u4e3a\u6709\u6548\u7684\u8c03\u8bd5\u5de5\u5177", "conclusion": "\u57fa\u4e8eNUC-140\u7684\u793a\u6ce2\u5668\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u66ff\u4ee3\u4f20\u7edf\u793a\u6ce2\u5668\uff0c\u5b9e\u73b0\u5927\u90e8\u5206\u5e38\u7528\u529f\u80fd\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u548c\u6210\u672c\u4f18\u52bf"}}
{"id": "2512.20056", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.20056", "abs": "https://arxiv.org/abs/2512.20056", "authors": ["Hao Li", "Fabian Deuser", "Wenping Yin", "Steffen Knoblauch", "Wufan Zhao", "Filip Biljecki", "Yong Xue", "Wei Huang"], "title": "Towards Generative Location Awareness for Disaster Response: A Probabilistic Cross-view Geolocalization Approach", "comment": null, "summary": "As Earth's climate changes, it is impacting disasters and extreme weather events across the planet. Record-breaking heat waves, drenching rainfalls, extreme wildfires, and widespread flooding during hurricanes are all becoming more frequent and more intense. Rapid and efficient response to disaster events is essential for climate resilience and sustainability. A key challenge in disaster response is to accurately and quickly identify disaster locations to support decision-making and resources allocation. In this paper, we propose a Probabilistic Cross-view Geolocalization approach, called ProbGLC, exploring new pathways towards generative location awareness for rapid disaster response. Herein, we combine probabilistic and deterministic geolocalization models into a unified framework to simultaneously enhance model explainability (via uncertainty quantification) and achieve state-of-the-art geolocalization performance. Designed for rapid diaster response, the ProbGLC is able to address cross-view geolocalization across multiple disaster events as well as to offer unique features of probabilistic distribution and localizability score. To evaluate the ProbGLC, we conduct extensive experiments on two cross-view disaster datasets (i.e., MultiIAN and SAGAINDisaster), consisting diverse cross-view imagery pairs of multiple disaster types (e.g., hurricanes, wildfires, floods, to tornadoes). Preliminary results confirms the superior geolocalization accuracy (i.e., 0.86 in Acc@1km and 0.97 in Acc@25km) and model explainability (i.e., via probabilistic distributions and localizability scores) of the proposed ProbGLC approach, highlighting the great potential of leveraging generative cross-view approach to facilitate location awareness for better and faster disaster response. The data and code is publicly available at https://github.com/bobleegogogo/ProbGLC", "AI": {"tldr": "\u63d0\u51faProbGLC\u65b9\u6cd5\uff0c\u7ed3\u5408\u6982\u7387\u6027\u548c\u786e\u5b9a\u6027\u5730\u7406\u5b9a\u4f4d\u6a21\u578b\uff0c\u901a\u8fc7\u4ea4\u53c9\u89c6\u56fe\u56fe\u50cf\u5339\u914d\u5b9e\u73b0\u707e\u5bb3\u5feb\u901f\u54cd\u5e94\uff0c\u63d0\u9ad8\u5b9a\u4f4d\u51c6\u786e\u6027\u548c\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u968f\u7740\u6c14\u5019\u53d8\u5316\u52a0\u5267\uff0c\u707e\u5bb3\u4e8b\u4ef6\u9891\u53d1\u4e14\u5f3a\u5ea6\u589e\u52a0\uff0c\u5feb\u901f\u51c6\u786e\u7684\u707e\u5bb3\u5b9a\u4f4d\u5bf9\u5e94\u6025\u54cd\u5e94\u548c\u8d44\u6e90\u5206\u914d\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5b9a\u4f4d\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51faProbGLC\u6982\u7387\u4ea4\u53c9\u89c6\u56fe\u5730\u7406\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u5c06\u6982\u7387\u6027\u548c\u786e\u5b9a\u6027\u5730\u7406\u5b9a\u4f4d\u6a21\u578b\u7edf\u4e00\u5230\u4e00\u4e2a\u6846\u67b6\u4e2d\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u5c40\u90e8\u5316\u8bc4\u5206\u589e\u5f3a\u6a21\u578b\u53ef\u89e3\u91ca\u6027\uff0c\u540c\u65f6\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u5b9a\u4f4d\u6027\u80fd\u3002", "result": "\u5728\u4e24\u4e2a\u707e\u5bb3\u6570\u636e\u96c6\uff08MultiIAN\u548cSAGAINDisaster\uff09\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cProbGLC\u57281\u516c\u91cc\u5185\u51c6\u786e\u7387\u8fbe\u52300.86\uff0c25\u516c\u91cc\u5185\u8fbe\u52300.97\uff0c\u540c\u65f6\u901a\u8fc7\u6982\u7387\u5206\u5e03\u548c\u5c40\u90e8\u5316\u8bc4\u5206\u63d0\u4f9b\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "ProbGLC\u65b9\u6cd5\u5728\u707e\u5bb3\u5730\u7406\u5b9a\u4f4d\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u7ed3\u5408\u751f\u6210\u5f0f\u4ea4\u53c9\u89c6\u56fe\u65b9\u6cd5\u6709\u671b\u4e3a\u707e\u5bb3\u54cd\u5e94\u63d0\u4f9b\u66f4\u597d\u7684\u4f4d\u7f6e\u611f\u77e5\u80fd\u529b\uff0c\u4fc3\u8fdb\u66f4\u5feb\u66f4\u597d\u7684\u707e\u5bb3\u5e94\u6025\u54cd\u5e94\u3002"}}
{"id": "2512.20062", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20062", "abs": "https://arxiv.org/abs/2512.20062", "authors": ["Sangryu Park", "Gihyuk Ko", "Homook Cho"], "title": "On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities", "comment": "The 9th International Conference on Mobile Internet Security (MobiSec 2025)", "summary": "Large Language Models (LLMs) show significant promise in automating software vulnerability analysis, a critical task given the impact of security failure of modern software systems. However, current approaches in using LLMs to automate vulnerability analysis mostly rely on using online API-based LLM services, requiring the user to disclose the source code in development. Moreover, they predominantly frame the task as a binary classification(vulnerable or not vulnerable), limiting potential practical utility. This paper addresses these limitations by reformulating the problem as Software Vulnerability Identification (SVI), where LLMs are asked to output the type of weakness in Common Weakness Enumeration (CWE) IDs rather than simply indicating the presence or absence of a vulnerability. We also tackle the reliance on large, API-based LLMs by demonstrating that instruction-tuning smaller, locally deployable LLMs can achieve superior identification performance. In our analysis, instruct-tuning a local LLM showed better overall performance and cost trade-off than online API-based LLMs. Our findings indicate that instruct-tuned local models represent a more effective, secure, and practical approach for leveraging LLMs in real-world vulnerability management workflows.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06LLM\u5e94\u7528\u4e8e\u8f6f\u4ef6\u6f0f\u6d1e\u5206\u6790\uff0c\u4ece\u4e8c\u5143\u5206\u7c7b\u6539\u8fdb\u4e3a\u8bc6\u522b\u5177\u4f53CWE\u7c7b\u578b\uff0c\u5e76\u901a\u8fc7\u6307\u4ee4\u5fae\u8c03\u672c\u5730\u90e8\u7f72\u7684\u5c0f\u578bLLM\u5b9e\u73b0\u6bd4\u5728\u7ebfAPI\u6a21\u578b\u66f4\u597d\u7684\u6027\u80fd\u3001\u5b89\u5168\u6027\u548c\u6210\u672c\u6548\u76ca\u3002", "motivation": "\u5f53\u524dLLM\u5728\u8f6f\u4ef6\u6f0f\u6d1e\u5206\u6790\u4e2d\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u4f9d\u8d56\u5728\u7ebfAPI\u670d\u52a1\u9700\u8981\u516c\u5f00\u6e90\u4ee3\u7801\uff0c\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff1b2) \u4ec5\u8fdb\u884c\u4e8c\u5143\u5206\u7c7b\uff08\u6709\u6f0f\u6d1e/\u65e0\u6f0f\u6d1e\uff09\uff0c\u5b9e\u7528\u6027\u6709\u9650\u3002\u9700\u8981\u66f4\u5b89\u5168\u3001\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8f6f\u4ef6\u6f0f\u6d1e\u8bc6\u522b(SVI)\uff0c\u8981\u6c42LLM\u8f93\u51fa\u5177\u4f53\u7684CWE ID\u800c\u975e\u7b80\u5355\u4e8c\u5143\u5224\u65ad\u3002\u901a\u8fc7\u6307\u4ee4\u5fae\u8c03\u8f83\u5c0f\u3001\u53ef\u672c\u5730\u90e8\u7f72\u7684LLM\uff0c\u907f\u514d\u4f7f\u7528\u5728\u7ebfAPI\u670d\u52a1\u3002", "result": "\u6307\u4ee4\u5fae\u8c03\u7684\u672c\u5730LLM\u5728\u6574\u4f53\u6027\u80fd\u548c\u6210\u672c\u6743\u8861\u65b9\u9762\u4f18\u4e8e\u5728\u7ebfAPI\u6a21\u578b\u3002\u672c\u5730\u6a21\u578b\u5728\u6f0f\u6d1e\u8bc6\u522b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6548\u679c\u3002", "conclusion": "\u6307\u4ee4\u5fae\u8c03\u7684\u672c\u5730LLM\u4e3a\u5b9e\u9645\u6f0f\u6d1e\u7ba1\u7406\u5de5\u4f5c\u6d41\u7a0b\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u3001\u5b89\u5168\u548c\u5b9e\u7528\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u3002"}}
{"id": "2512.20061", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20061", "abs": "https://arxiv.org/abs/2512.20061", "authors": ["Hamed Firooz", "Rui Liu", "Yuchen Lu", "Zhenyu Hou", "Fangzhou Xiong", "Xiaoyang Zhang", "Changshu Jian", "Zhicheng Zhu", "Jiayuan Ma", "Jacob Tao", "Chaitali Gupta", "Xiaochang Peng", "Shike Mei", "Hang Cui", "Yang Qin", "Shuo Tang", "Jason Gaedtke", "Arpit Mittal"], "title": "Scaling Reinforcement Learning for Content Moderation with Large Language Models", "comment": null, "summary": "Content moderation at scale remains one of the most pressing challenges in today's digital ecosystem, where billions of user- and AI-generated artifacts must be continuously evaluated for policy violations. Although recent advances in large language models (LLMs) have demonstrated strong potential for policy-grounded moderation, the practical challenges of training these systems to achieve expert-level accuracy in real-world settings remain largely unexplored, particularly in regimes characterized by label sparsity, evolving policy definitions, and the need for nuanced reasoning beyond shallow pattern matching. In this work, we present a comprehensive empirical investigation of scaling reinforcement learning (RL) for content classification, systematically evaluating multiple RL training recipes and reward-shaping strategies-including verifiable rewards and LLM-as-judge frameworks-to transform general-purpose language models into specialized, policy-aligned classifiers across three real-world content moderation tasks. Our findings provide actionable insights for industrial-scale moderation systems, demonstrating that RL exhibits sigmoid-like scaling behavior in which performance improves smoothly with increased training data, rollouts, and optimization steps before gradually saturating. Moreover, we show that RL substantially improves performance on tasks requiring complex policy-grounded reasoning while achieving up to 100x higher data efficiency than supervised fine-tuning, making it particularly effective in domains where expert annotations are scarce or costly.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5185\u5bb9\u5ba1\u6838\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0RL\u5728\u9700\u8981\u590d\u6742\u653f\u7b56\u63a8\u7406\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u6570\u636e\u6548\u7387\u6bd4\u76d1\u7763\u5fae\u8c03\u9ad8100\u500d\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4e13\u5bb6\u6807\u6ce8\u7a00\u7f3a\u7684\u573a\u666f\u3002", "motivation": "\u5927\u89c4\u6a21\u5185\u5bb9\u5ba1\u6838\u662f\u5f53\u4eca\u6570\u5b57\u751f\u6001\u7cfb\u7edf\u4e2d\u6700\u7d27\u8feb\u7684\u6311\u6218\u4e4b\u4e00\uff0c\u9700\u8981\u6301\u7eed\u8bc4\u4f30\u6570\u5341\u4ebf\u7528\u6237\u548cAI\u751f\u6210\u7684\u5185\u5bb9\u662f\u5426\u5b58\u5728\u653f\u7b56\u8fdd\u89c4\u3002\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u653f\u7b56\u9a71\u52a8\u7684\u5ba1\u6838\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8bad\u7ec3\u8fd9\u4e9b\u7cfb\u7edf\u4ee5\u8fbe\u5230\u4e13\u5bb6\u7ea7\u51c6\u786e\u6027\u7684\u6311\u6218\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u7279\u522b\u662f\u5728\u6807\u7b7e\u7a00\u758f\u3001\u653f\u7b56\u5b9a\u4e49\u4e0d\u65ad\u6f14\u53d8\u3001\u9700\u8981\u8d85\u8d8a\u6d45\u5c42\u6a21\u5f0f\u5339\u914d\u7684\u7ec6\u81f4\u63a8\u7406\u7684\u573a\u666f\u4e2d\u3002", "method": "\u91c7\u7528\u5168\u9762\u7684\u5b9e\u8bc1\u7814\u7a76\u65b9\u6cd5\uff0c\u7cfb\u7edf\u8bc4\u4f30\u591a\u79cdRL\u8bad\u7ec3\u65b9\u6848\u548c\u5956\u52b1\u5851\u9020\u7b56\u7565\uff0c\u5305\u62ec\u53ef\u9a8c\u8bc1\u5956\u52b1\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u6846\u67b6\uff0c\u5c06\u901a\u7528\u8bed\u8a00\u6a21\u578b\u8f6c\u5316\u4e3a\u4e13\u95e8\u7684\u653f\u7b56\u5bf9\u9f50\u5206\u7c7b\u5668\u3002\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u5185\u5bb9\u5ba1\u6838\u4efb\u52a1\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u7814\u7a76\u53d1\u73b0RL\u8868\u73b0\u51fa\u7c7b\u4f3cSigmoid\u51fd\u6570\u7684\u6269\u5c55\u884c\u4e3a\uff1a\u968f\u7740\u8bad\u7ec3\u6570\u636e\u3001rollouts\u548c\u4f18\u5316\u6b65\u9aa4\u7684\u589e\u52a0\uff0c\u6027\u80fd\u5e73\u7a33\u63d0\u5347\u540e\u9010\u6e10\u9971\u548c\u3002RL\u5728\u9700\u8981\u590d\u6742\u653f\u7b56\u63a8\u7406\u7684\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u6570\u636e\u6548\u7387\u6bd4\u76d1\u7763\u5fae\u8c03\u9ad8100\u500d\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4e13\u5bb6\u6807\u6ce8\u7a00\u7f3a\u6216\u6210\u672c\u9ad8\u6602\u7684\u9886\u57df\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5de5\u4e1a\u7ea7\u5185\u5bb9\u5ba1\u6838\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89c1\u89e3\uff0c\u8bc1\u660e\u5f3a\u5316\u5b66\u4e60\u662f\u5b9e\u73b0\u653f\u7b56\u5bf9\u9f50\u5185\u5bb9\u5206\u7c7b\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u7f3a\u548c\u9700\u8981\u590d\u6742\u63a8\u7406\u7684\u573a\u666f\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2512.20168", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.20168", "abs": "https://arxiv.org/abs/2512.20168", "authors": ["Songze Li", "Jiameng Cheng", "Yiming Li", "Xiaojun Jia", "Dacheng Tao"], "title": "Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography", "comment": "This paper is accepted by Network and Distributed System Security Symposium (NDSS) 2026", "summary": "By integrating language understanding with perceptual modalities such as images, multimodal large language models (MLLMs) constitute a critical substrate for modern AI systems, particularly intelligent agents operating in open and interactive environments. However, their increasing accessibility also raises heightened risks of misuse, such as generating harmful or unsafe content. To mitigate these risks, alignment techniques are commonly applied to align model behavior with human values. Despite these efforts, recent studies have shown that jailbreak attacks can circumvent alignment and elicit unsafe outputs. Currently, most existing jailbreak methods are tailored for open-source models and exhibit limited effectiveness against commercial MLLM-integrated systems, which often employ additional filters. These filters can detect and prevent malicious input and output content, significantly reducing jailbreak threats. In this paper, we reveal that the success of these safety filters heavily relies on a critical assumption that malicious content must be explicitly visible in either the input or the output. This assumption, while often valid for traditional LLM-integrated systems, breaks down in MLLM-integrated systems, where attackers can leverage multiple modalities to conceal adversarial intent, leading to a false sense of security in existing MLLM-integrated systems. To challenge this assumption, we propose Odysseus, a novel jailbreak paradigm that introduces dual steganography to covertly embed malicious queries and responses into benign-looking images. Extensive experiments on benchmark datasets demonstrate that our Odysseus successfully jailbreaks several pioneering and realistic MLLM-integrated systems, achieving up to 99% attack success rate. It exposes a fundamental blind spot in existing defenses, and calls for rethinking cross-modal security in MLLM-integrated systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aOdysseus\u7684\u65b0\u578b\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u53cc\u9690\u5199\u672f\u5728\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u4e2d\u9690\u85cf\u6076\u610f\u5185\u5bb9\uff0c\u6210\u529f\u7ed5\u8fc7\u73b0\u6709\u5b89\u5168\u8fc7\u6ee4\u5668\uff0c\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe99%\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u5b58\u5728\u5b89\u5168\u76f2\u70b9\uff0c\u73b0\u6709\u5b89\u5168\u8fc7\u6ee4\u5668\u5047\u8bbe\u6076\u610f\u5185\u5bb9\u5fc5\u987b\u5728\u8f93\u5165\u6216\u8f93\u51fa\u4e2d\u663e\u5f0f\u53ef\u89c1\uff0c\u4f46\u653b\u51fb\u8005\u53ef\u4ee5\u5229\u7528\u591a\u6a21\u6001\u7279\u6027\u9690\u85cf\u6076\u610f\u610f\u56fe\uff0c\u5bfc\u81f4\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u5931\u6548\u3002", "method": "\u63d0\u51faOdysseus\u8d8a\u72f1\u8303\u5f0f\uff0c\u91c7\u7528\u53cc\u9690\u5199\u672f\u6280\u672f\uff0c\u5c06\u6076\u610f\u67e5\u8be2\u548c\u54cd\u5e94\u9690\u853d\u5730\u5d4c\u5165\u770b\u4f3c\u826f\u6027\u7684\u56fe\u50cf\u4e2d\uff0c\u4ece\u800c\u7ed5\u8fc7\u57fa\u4e8e\u663e\u5f0f\u5185\u5bb9\u68c0\u6d4b\u7684\u5b89\u5168\u8fc7\u6ee4\u5668\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cOdysseus\u6210\u529f\u8d8a\u72f1\u591a\u4e2a\u9886\u5148\u4e14\u73b0\u5b9e\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\uff0c\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe99%\uff0c\u66b4\u9732\u4e86\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u7684\u6839\u672c\u76f2\u70b9\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u7cfb\u7edf\u4e2d\u8de8\u6a21\u6001\u5b89\u5168\u7684\u6839\u672c\u7f3a\u9677\uff0c\u6311\u6218\u4e86\u73b0\u6709\u5b89\u5168\u8fc7\u6ee4\u5668\u7684\u6838\u5fc3\u5047\u8bbe\uff0c\u547c\u5401\u91cd\u65b0\u601d\u8003\u591a\u6a21\u6001\u7cfb\u7edf\u7684\u5b89\u5168\u9632\u5fa1\u7b56\u7565\u3002"}}
{"id": "2512.20163", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.20163", "abs": "https://arxiv.org/abs/2512.20163", "authors": ["Leszek G\u0105sieniec", "Tytus Grodzicki", "Tomasz Jurdzi\u0144ski", "Jakub Kowalski", "Grzegorz Stachowiak"], "title": "Population Protocols Revisited: Parity and Beyond", "comment": null, "summary": "For nearly two decades, population protocols have been extensively studied, yielding efficient solutions for central problems in distributed computing, including leader election, and majority computation, a predicate type in Presburger Arithmetic closely tied to population protocols. Surprisingly, no protocols have achieved both time- and space-efficiency for congruency predicates, such as parity computation, which are complementary in this arithmetic framework. This gap highlights a significant challenge in the field. To address this gap, we explore the parity problem, where agents are tasked with computing the parity of the given sub-population size. Then we extend the solution for parity to compute congruences modulo an arbitrary $m$.\n  Previous research on efficient population protocols has focused on protocols that minimise both stabilisation time and state utilisation for specific problems. In contrast, this work slightly relaxes this expectation, permitting protocols to place less emphasis on full optimisation and more on universality, robustness, and probabilistic guarantees. This allows us to propose a novel computing paradigm that integrates population weights (or simply weights), a robust clocking mechanism, and efficient anomaly detection coupled with a switching mechanism (which ensures slow but always correct solutions). This paradigm facilitates universal design of efficient multistage stable population protocols. Specifically, the first efficient parity and congruence protocols introduced here use both $O(\\log^3 n)$ states and achieve silent stabilisation in $O(\\log^3 n)$ time. We conclude by discussing the impact of implicit conversion between unary and binary representations enabled by the weight system, with applications to other problems, including the computation and representation of (sub-)population sizes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5728\u65f6\u95f4\u548c\u7a7a\u95f4\u4e0a\u90fd\u9ad8\u6548\u7684\u7fa4\u4f53\u534f\u8bae\uff0c\u7528\u4e8e\u8ba1\u7b97\u5947\u5076\u6027\u548c\u6a21m\u540c\u4f59\u95ee\u9898\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u8fd1\u4e8c\u5341\u5e74\u7684\u7a7a\u767d\u3002", "motivation": "\u8fd1\u4e8c\u5341\u5e74\u6765\uff0c\u7fa4\u4f53\u534f\u8bae\u7814\u7a76\u5728\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u53d6\u5f97\u4e86\u91cd\u8981\u8fdb\u5c55\uff0c\u4f46\u5bf9\u4e8ePresburger\u7b97\u672f\u4e2d\u4e92\u8865\u7684\u5947\u5076\u6027\u7b49\u540c\u4f59\u8c13\u8bcd\uff0c\u4e00\u76f4\u6ca1\u6709\u540c\u65f6\u5b9e\u73b0\u65f6\u95f4\u548c\u7a7a\u95f4\u9ad8\u6548\u7684\u534f\u8bae\u3002\u8fd9\u4e00\u7a7a\u767d\u51f8\u663e\u4e86\u8be5\u9886\u57df\u7684\u91cd\u5927\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8ba1\u7b97\u8303\u5f0f\uff0c\u6574\u5408\u4e86\u7fa4\u4f53\u6743\u91cd\u3001\u9c81\u68d2\u7684\u65f6\u949f\u673a\u5236\u3001\u9ad8\u6548\u7684\u5f02\u5e38\u68c0\u6d4b\u4e0e\u5207\u6362\u673a\u5236\u3002\u8be5\u8303\u5f0f\u5141\u8bb8\u534f\u8bae\u4e0d\u5b8c\u5168\u4f18\u5316\uff0c\u800c\u662f\u66f4\u6ce8\u91cd\u901a\u7528\u6027\u3001\u9c81\u68d2\u6027\u548c\u6982\u7387\u4fdd\u8bc1\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u591a\u9636\u6bb5\u7a33\u5b9a\u7fa4\u4f53\u534f\u8bae\u8bbe\u8ba1\u3002", "result": "\u9996\u6b21\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u5947\u5076\u6027\u548c\u540c\u4f59\u534f\u8bae\uff0c\u4f7f\u7528O(log\u00b3 n)\u4e2a\u72b6\u6001\uff0c\u5e76\u5728O(log\u00b3 n)\u65f6\u95f4\u5185\u5b9e\u73b0\u9759\u9ed8\u7a33\u5b9a\u3002\u901a\u8fc7\u6743\u91cd\u7cfb\u7edf\u5b9e\u73b0\u4e86\u4e8c\u8fdb\u5236\u548c\u4e00\u5143\u8868\u793a\u4e4b\u95f4\u7684\u9690\u5f0f\u8f6c\u6362\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u586b\u8865\u4e86\u7fa4\u4f53\u534f\u8bae\u9886\u57df\u7684\u91cd\u8981\u7a7a\u767d\uff0c\u63d0\u51fa\u7684\u8ba1\u7b97\u8303\u5f0f\u4e0d\u4ec5\u89e3\u51b3\u4e86\u5947\u5076\u6027\u548c\u540c\u4f59\u95ee\u9898\uff0c\u8fd8\u4e3a\u5176\u4ed6\u95ee\u9898\uff08\u5982\u5b50\u7fa4\u4f53\u5927\u5c0f\u7684\u8ba1\u7b97\u548c\u8868\u793a\uff09\u63d0\u4f9b\u4e86\u5e94\u7528\u53ef\u80fd\u6027\u3002"}}
{"id": "2512.20074", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.20074", "abs": "https://arxiv.org/abs/2512.20074", "authors": ["H M Quamran Hasan", "Housam Khalifa Bashier", "Jiayi Dai", "Mi-Young Kim", "Randy Goebel"], "title": "Reason2Decide: Rationale-Driven Multi-Task Learning", "comment": null, "summary": "Despite the wide adoption of Large Language Models (LLM)s, clinical decision support systems face a critical challenge: achieving high predictive accuracy while generating explanations aligned with the predictions. Current approaches suffer from exposure bias leading to misaligned explanations. We propose Reason2Decide, a two-stage training framework that addresses key challenges in self-rationalization, including exposure bias and task separation. In Stage-1, our model is trained on rationale generation, while in Stage-2, we jointly train on label prediction and rationale generation, applying scheduled sampling to gradually transition from conditioning on gold labels to model predictions. We evaluate Reason2Decide on three medical datasets, including a proprietary triage dataset and public biomedical QA datasets. Across model sizes, Reason2Decide outperforms other fine-tuning baselines and some zero-shot LLMs in prediction (F1) and rationale fidelity (BERTScore, BLEU, LLM-as-a-Judge). In triage, Reason2Decide is rationale source-robust across LLM-generated, nurse-authored, and nurse-post-processed rationales. In our experiments, while using only LLM-generated rationales in Stage-1, Reason2Decide outperforms other fine-tuning variants. This indicates that LLM-generated rationales are suitable for pretraining models, reducing reliance on human annotations. Remarkably, Reason2Decide achieves these gains with models 40x smaller than contemporary foundation models, making clinical reasoning more accessible for resource-constrained deployments while still providing explainable decision support.", "AI": {"tldr": "Reason2Decide\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u51b3\u66b4\u9732\u504f\u5dee\u548c\u4efb\u52a1\u5206\u79bb\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\u751f\u6210\u4e0e\u9884\u6d4b\u4e00\u81f4\u7684\u533b\u5b66\u89e3\u91ca\u3002", "motivation": "\u5f53\u524d\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u9762\u4e34\u5173\u952e\u6311\u6218\uff1a\u5728\u5b9e\u73b0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u751f\u6210\u4e0e\u9884\u6d4b\u4e00\u81f4\u7684\u89e3\u91ca\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u66b4\u9732\u504f\u5dee\u95ee\u9898\uff0c\u5bfc\u81f4\u89e3\u91ca\u4e0e\u9884\u6d4b\u4e0d\u4e00\u81f4\u3002", "method": "\u63d0\u51faReason2Decide\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u8bad\u7ec3\u6a21\u578b\u751f\u6210\u89e3\u91ca\uff1b\u7b2c\u4e8c\u9636\u6bb5\u8054\u5408\u8bad\u7ec3\u6807\u7b7e\u9884\u6d4b\u548c\u89e3\u91ca\u751f\u6210\uff0c\u5e94\u7528\u8ba1\u5212\u91c7\u6837\u4ece\u57fa\u4e8e\u9ec4\u91d1\u6807\u7b7e\u9010\u6e10\u8fc7\u6e21\u5230\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u3002", "result": "\u5728\u4e09\u4e2a\u533b\u5b66\u6570\u636e\u96c6\u4e0a\uff0cReason2Decide\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u89e3\u91ca\u4fdd\u771f\u5ea6\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u5fae\u8c03\u57fa\u51c6\u548c\u67d0\u4e9b\u96f6\u6837\u672cLLM\u3002\u5728\u5206\u8bca\u4efb\u52a1\u4e2d\uff0c\u5bf9LLM\u751f\u6210\u3001\u62a4\u58eb\u64b0\u5199\u548c\u62a4\u58eb\u540e\u5904\u7406\u7684\u89e3\u91ca\u90fd\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "Reason2Decide\u4ec5\u4f7f\u7528LLM\u751f\u6210\u89e3\u91ca\u8fdb\u884c\u9884\u8bad\u7ec3\u5c31\u80fd\u53d6\u5f97\u826f\u597d\u6548\u679c\uff0c\u51cf\u5c11\u4e86\u5bf9\u4eba\u5de5\u6807\u6ce8\u7684\u4f9d\u8d56\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u6bd4\u5f53\u4ee3\u57fa\u7840\u6a21\u578b\u5c0f40\u500d\u7684\u6a21\u578b\u5b9e\u73b0\u4e86\u8fd9\u4e9b\u4f18\u52bf\uff0c\u4f7f\u4e34\u5e8a\u63a8\u7406\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u66f4\u6613\u90e8\u7f72\u3002"}}
{"id": "2512.20184", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.20184", "abs": "https://arxiv.org/abs/2512.20184", "authors": ["Chaoyi Ruan", "Yiliang Wang", "Ziji Shi", "Jialin Li"], "title": "Reaching Agreement Among Reasoning LLM Agents", "comment": null, "summary": "Multi-agent systems have extended the capability of agentic AI. Instead of single inference passes, multiple agents perform collective reasoning to derive high quality answers. However, existing multi-agent orchestration relies on static heuristic workflows such as fixed loop limits and barrier synchronization. These ad-hoc approaches waste computational resources, incur high latency due to stragglers, and risk finalizing transient agreements. We argue that reliable multi-agent reasoning requires a formal foundation analogous to classical distributed consensus problem.\n  To that end, we propose a formal model of the multi-agent refinement problem. The model includes definitions of the correctness guarantees and formal semantics of agent reasoning. We then introduce Aegean, a consensus protocol designed for stochastic reasoning agents that solves multi-agent refinement. We implement the protocol in Aegean-Serve, a consensus-aware serving engine that performs incremental quorum detection across concurrent agent executions, enabling early termination when sufficient agents converge. Evaluation using four mathematical reasoning benchmarks shows that Aegean provides provable safety and liveness guarantees while reducing latency by 1.2--20$\\times$ compared to state-of-the-art baselines, maintaining answer quality within 2.5%. Consistent gains across both local GPU deployments and commercial API providers validate that consensus-based orchestration eliminates straggler delays without sacrificing correctness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAegean\uff0c\u4e00\u79cd\u57fa\u4e8e\u5171\u8bc6\u534f\u8bae\u7684\u591a\u667a\u80fd\u4f53\u63a8\u7406\u534f\u8c03\u6846\u67b6\uff0c\u89e3\u51b3\u73b0\u6709\u9759\u6001\u5de5\u4f5c\u6d41\u5bfc\u81f4\u7684\u8d44\u6e90\u6d6a\u8d39\u3001\u5ef6\u8fdf\u9ad8\u548c\u4e34\u65f6\u534f\u8bae\u98ce\u9669\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f9d\u8d56\u9759\u6001\u542f\u53d1\u5f0f\u5de5\u4f5c\u6d41\uff08\u5982\u56fa\u5b9a\u5faa\u73af\u9650\u5236\u548c\u5c4f\u969c\u540c\u6b65\uff09\uff0c\u5bfc\u81f4\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u3001\u5ef6\u8fdf\u9ad8\uff08\u7531\u4e8e\u843d\u540e\u8282\u70b9\uff09\u548c\u53ef\u80fd\u6700\u7ec8\u5316\u4e34\u65f6\u534f\u8bae\u7684\u98ce\u9669\u3002\u4f5c\u8005\u8ba4\u4e3a\u53ef\u9760\u7684\u591a\u667a\u80fd\u4f53\u63a8\u7406\u9700\u8981\u7c7b\u4f3c\u7ecf\u5178\u5206\u5e03\u5f0f\u5171\u8bc6\u95ee\u9898\u7684\u5f62\u5f0f\u5316\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u7cbe\u70bc\u95ee\u9898\u7684\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u5305\u62ec\u6b63\u786e\u6027\u4fdd\u8bc1\u5b9a\u4e49\u548c\u667a\u80fd\u4f53\u63a8\u7406\u7684\u5f62\u5f0f\u8bed\u4e49\u3002\u5f15\u5165Aegean\u5171\u8bc6\u534f\u8bae\uff0c\u4e13\u4e3a\u968f\u673a\u63a8\u7406\u667a\u80fd\u4f53\u8bbe\u8ba1\uff0c\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cbe\u70bc\u95ee\u9898\u3002\u5b9e\u73b0Aegean-Serve\uff0c\u4e00\u4e2a\u5171\u8bc6\u611f\u77e5\u7684\u670d\u52a1\u5f15\u64ce\uff0c\u5728\u5e76\u53d1\u667a\u80fd\u4f53\u6267\u884c\u4e2d\u6267\u884c\u589e\u91cf\u6cd5\u5b9a\u4eba\u6570\u68c0\u6d4b\uff0c\u5b9e\u73b0\u5145\u5206\u667a\u80fd\u4f53\u6536\u655b\u65f6\u7684\u65e9\u671f\u7ec8\u6b62\u3002", "result": "\u5728\u56db\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAegean\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u5b89\u5168\u6027\u548c\u6d3b\u6027\u4fdd\u8bc1\uff0c\u540c\u65f6\u76f8\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u51cf\u5c11\u5ef6\u8fdf1.2-20\u500d\uff0c\u4fdd\u6301\u7b54\u6848\u8d28\u91cf\u57282.5%\u4ee5\u5185\u3002\u5728\u672c\u5730GPU\u90e8\u7f72\u548c\u5546\u4e1aAPI\u63d0\u4f9b\u5546\u4e0a\u7684\u6301\u7eed\u589e\u76ca\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u5171\u8bc6\u7684\u534f\u8c03\u6d88\u9664\u4e86\u843d\u540e\u8282\u70b9\u5ef6\u8fdf\u800c\u4e0d\u727a\u7272\u6b63\u786e\u6027\u3002", "conclusion": "\u57fa\u4e8e\u5171\u8bc6\u7684\u534f\u8c03\u4e3a\u591a\u667a\u80fd\u4f53\u63a8\u7406\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u57fa\u7840\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u9759\u6001\u5de5\u4f5c\u6d41\u7684\u5173\u952e\u9650\u5236\uff0c\u5728\u4fdd\u6301\u7b54\u6848\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u3002"}}
{"id": "2512.20135", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20135", "abs": "https://arxiv.org/abs/2512.20135", "authors": ["Zhuo Yang", "Yeyun chen", "Jiaqing Xie", "Ben Gao", "Shuaike Shen", "Wanhao Liu", "Liujia Yang", "Beilun Wang", "Tianfan Fu", "Yuqiang Li"], "title": "MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization", "comment": null, "summary": "Molecular editing and optimization are multi-step problems that require iteratively improving properties while keeping molecules chemically valid and structurally similar. We frame both tasks as sequential, tool-guided decisions and introduce MolAct, an agentic reinforcement learning framework that employs a two-stage training paradigm: first building editing capability, then optimizing properties while reusing the learned editing behaviors. To the best of our knowledge, this is the first work to formalize molecular design as an Agentic Reinforcement Learning problem, where an LLM agent learns to interleave reasoning, tool-use, and molecular optimization. The framework enables agents to interact in multiple turns, invoking chemical tools for validity checking, property assessment, and similarity control, and leverages their feedback to refine subsequent edits. We instantiate the MolAct framework to train two model families: MolEditAgent for molecular editing tasks and MolOptAgent for molecular optimization tasks. In molecular editing, MolEditAgent-7B delivers 100, 95, and 98 valid add, delete, and substitute edits, outperforming strong closed \"thinking\" baselines such as DeepSeek-R1; MolEditAgent-3B approaches the performance of much larger open \"thinking\" models like Qwen3-32B-think. In molecular optimization, MolOptAgent-7B (trained on MolEditAgent-7B) surpasses the best closed \"thinking\" baseline (e.g., Claude 3.7) on LogP and remains competitive on solubility, while maintaining balanced performance across other objectives. These results highlight that treating molecular design as a multi-step, tool-augmented process is key to reliable and interpretable improvements.", "AI": {"tldr": "MolAct\u662f\u4e00\u4e2a\u57fa\u4e8e\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u5206\u5b50\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\uff08\u5148\u5b66\u4e60\u7f16\u8f91\u80fd\u529b\uff0c\u518d\u4f18\u5316\u6027\u8d28\uff09\u5b9e\u73b0\u591a\u6b65\u5206\u5b50\u7f16\u8f91\u4e0e\u4f18\u5316\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u5206\u5b50\u7f16\u8f91\u548c\u4f18\u5316\u662f\u591a\u6b65\u9aa4\u95ee\u9898\uff0c\u9700\u8981\u8fed\u4ee3\u6539\u8fdb\u6027\u8d28\u540c\u65f6\u4fdd\u6301\u5316\u5b66\u6709\u6548\u6027\u548c\u7ed3\u6784\u76f8\u4f3c\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5c06\u5206\u5b50\u8bbe\u8ba1\u5f62\u5f0f\u5316\u4e3a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u7684\u6846\u67b6\uff0c\u65e0\u6cd5\u6709\u6548\u7ed3\u5408\u63a8\u7406\u3001\u5de5\u5177\u4f7f\u7528\u548c\u5206\u5b50\u4f18\u5316\u3002", "method": "\u63d0\u51faMolAct\u6846\u67b6\uff0c\u5c06\u5206\u5b50\u8bbe\u8ba1\u5f62\u5f0f\u5316\u4e3a\u987a\u5e8f\u7684\u3001\u5de5\u5177\u5f15\u5bfc\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\uff1a\u7b2c\u4e00\u9636\u6bb5\u5efa\u7acb\u7f16\u8f91\u80fd\u529b\uff0c\u7b2c\u4e8c\u9636\u6bb5\u91cd\u7528\u5b66\u4e60\u5230\u7684\u7f16\u8f91\u884c\u4e3a\u6765\u4f18\u5316\u6027\u8d28\u3002\u667a\u80fd\u4f53\u901a\u8fc7\u591a\u8f6e\u4ea4\u4e92\u8c03\u7528\u5316\u5b66\u5de5\u5177\u8fdb\u884c\u6709\u6548\u6027\u68c0\u67e5\u3001\u6027\u8d28\u8bc4\u4f30\u548c\u76f8\u4f3c\u6027\u63a7\u5236\uff0c\u5e76\u5229\u7528\u53cd\u9988\u4f18\u5316\u540e\u7eed\u7f16\u8f91\u3002", "result": "\u5728\u5206\u5b50\u7f16\u8f91\u4efb\u52a1\u4e2d\uff0cMolEditAgent-7B\u5728\u6dfb\u52a0\u3001\u5220\u9664\u548c\u66ff\u6362\u7f16\u8f91\u4e0a\u5206\u522b\u8fbe\u5230100%\u300195%\u548c98%\u7684\u6709\u6548\u6027\uff0c\u4f18\u4e8eDeepSeek-R1\u7b49\u57fa\u7ebf\uff1bMolEditAgent-3B\u63a5\u8fd1Qwen3-32B-think\u7b49\u66f4\u5927\u6a21\u578b\u7684\u6027\u80fd\u3002\u5728\u5206\u5b50\u4f18\u5316\u4efb\u52a1\u4e2d\uff0cMolOptAgent-7B\u5728LogP\u4e0a\u8d85\u8d8aClaude 3.7\u7b49\u57fa\u7ebf\uff0c\u5728\u6eb6\u89e3\u5ea6\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u5e76\u5728\u5176\u4ed6\u76ee\u6807\u4e0a\u4fdd\u6301\u5e73\u8861\u6027\u80fd\u3002", "conclusion": "\u5c06\u5206\u5b50\u8bbe\u8ba1\u89c6\u4e3a\u591a\u6b65\u9aa4\u3001\u5de5\u5177\u589e\u5f3a\u7684\u8fc7\u7a0b\u662f\u5b9e\u73b0\u53ef\u9760\u4e14\u53ef\u89e3\u91ca\u6539\u8fdb\u7684\u5173\u952e\u3002MolAct\u6846\u67b6\u9996\u6b21\u5c06\u5206\u5b50\u8bbe\u8ba1\u5f62\u5f0f\u5316\u4e3a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u667a\u80fd\u4f53\u5b66\u4e60\u4ea4\u9519\u63a8\u7406\u3001\u5de5\u5177\u4f7f\u7528\u548c\u5206\u5b50\u4f18\u5316\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.20210", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.20210", "abs": "https://arxiv.org/abs/2512.20210", "authors": ["Yinan Ni", "Xiao Yang", "Yuqi Tang", "Zhimin Qiu", "Chen Wang", "Tingzhou Yuan"], "title": "Predictive-LoRA: A Proactive and Fragmentation-Aware Serverless Inference System for LLMs", "comment": null, "summary": "The serverless computing paradigm offers compelling advantages for deploying Large Language Model (LLM) inference services, including elastic scaling and pay-per-use billing. However, serving multiple fine-tuned LLMs via Low-Rank Adaptation (LoRA) in serverless environments faces critical challenges: reactive adapter loading causes significant cold start latency, and frequent adapter swapping leads to severe GPU memory fragmentation. In this paper, we present Predictive-LoRA (P-LoRA), a proactive and fragmentation-aware serverless inference system for LoRA-based LLMs. P-LoRA introduces two key innovations: (1) a lightweight LSTM-based traffic predictor that forecasts adapter demand and proactively prefetches hot adapters from host memory to GPU, reducing cold start latency by up to 68%; and (2) a page-based adapter memory management mechanism inspired by operating system virtual memory, which keeps GPU memory utilization above 87% even under heterogeneous adapter ranks. We evaluate P-LoRA using production-like workloads derived from the Azure Functions trace. Experimental results demonstrate that P-LoRA achieves 1.52x higher throughput than S-LoRA while reducing the average Time-To-First-Token (TTFT) by 35% under high concurrency scenarios.", "AI": {"tldr": "P-LoRA\u662f\u4e00\u4e2a\u7528\u4e8eLoRA\u5fae\u8c03LLM\u7684\u670d\u52a1\u5668\u7aef\u63a8\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u9884\u6d4b\u6027\u9884\u52a0\u8f7d\u548c\u9875\u9762\u5f0f\u5185\u5b58\u7ba1\u7406\uff0c\u89e3\u51b3\u4e86\u51b7\u542f\u52a8\u5ef6\u8fdf\u548cGPU\u5185\u5b58\u788e\u7247\u5316\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u541e\u5410\u91cf\u5e76\u964d\u4f4e\u4e86\u54cd\u5e94\u65f6\u95f4\u3002", "motivation": "\u5728\u670d\u52a1\u5668\u7aef\u73af\u5883\u4e2d\u90e8\u7f72LoRA\u5fae\u8c03\u7684LLM\u63a8\u7406\u670d\u52a1\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1\uff09\u53cd\u5e94\u5f0f\u9002\u914d\u5668\u52a0\u8f7d\u5bfc\u81f4\u663e\u8457\u7684\u51b7\u542f\u52a8\u5ef6\u8fdf\uff1b2\uff09\u9891\u7e41\u7684\u9002\u914d\u5668\u4ea4\u6362\u5bfc\u81f4\u4e25\u91cd\u7684GPU\u5185\u5b58\u788e\u7247\u5316\u3002\u8fd9\u4e9b\u95ee\u9898\u5f71\u54cd\u4e86\u670d\u52a1\u5668\u7aef\u8ba1\u7b97\u5728LLM\u63a8\u7406\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "method": "P-LoRA\u91c7\u7528\u4e24\u79cd\u5173\u952e\u6280\u672f\uff1a1\uff09\u57fa\u4e8eLSTM\u7684\u8f7b\u91cf\u7ea7\u6d41\u91cf\u9884\u6d4b\u5668\uff0c\u9884\u6d4b\u9002\u914d\u5668\u9700\u6c42\u5e76\u4e3b\u52a8\u4ece\u4e3b\u673a\u5185\u5b58\u9884\u53d6\u70ed\u95e8\u9002\u914d\u5668\u5230GPU\uff1b2\uff09\u53d7\u64cd\u4f5c\u7cfb\u7edf\u865a\u62df\u5185\u5b58\u542f\u53d1\u7684\u9875\u9762\u5f0f\u9002\u914d\u5668\u5185\u5b58\u7ba1\u7406\u673a\u5236\uff0c\u5373\u4f7f\u5728\u5f02\u6784\u9002\u914d\u5668\u79e9\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u4fdd\u6301GPU\u5185\u5b58\u5229\u7528\u7387\u572887%\u4ee5\u4e0a\u3002", "result": "\u5b9e\u9a8c\u4f7f\u7528\u57fa\u4e8eAzure Functions\u8ffd\u8e2a\u7684\u751f\u4ea7\u7ea7\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u7ed3\u679c\u663e\u793a\uff1aP-LoRA\u6bd4S-LoRA\u5b9e\u73b0\u4e861.52\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\uff0c\u5728\u9ad8\u5e76\u53d1\u573a\u666f\u4e0b\u5e73\u5747\u9996\u6b21\u4ee4\u724c\u65f6\u95f4\uff08TTFT\uff09\u964d\u4f4e\u4e8635%\uff0c\u51b7\u542f\u52a8\u5ef6\u8fdf\u6700\u591a\u51cf\u5c11\u4e8668%\u3002", "conclusion": "P-LoRA\u901a\u8fc7\u9884\u6d4b\u6027\u9884\u52a0\u8f7d\u548c\u667a\u80fd\u5185\u5b58\u7ba1\u7406\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u670d\u52a1\u5668\u7aef\u73af\u5883\u4e2dLoRA\u5fae\u8c03LLM\u63a8\u7406\u7684\u51b7\u542f\u52a8\u548c\u5185\u5b58\u788e\u7247\u5316\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2512.20140", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20140", "abs": "https://arxiv.org/abs/2512.20140", "authors": ["Xingyou Yin", "Ceyao Zhang", "Min Hu", "Kai Chen"], "title": "Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection", "comment": "9 pages,3 figures", "summary": "Large Language Models (LLMs) have demonstrated effectiveness as zero-shot time series (TS) forecasters. The key challenge lies in tokenizing TS data into textual representations that align with LLMs' pre-trained knowledge. While existing work often relies on fine-tuning specialized modules to bridge this gap, a distinct, yet challenging, paradigm aims to leverage truly off-the-shelf LLMs without any fine-tuning whatsoever, relying solely on strategic tokenization of numerical sequences. The performance of these fully frozen models is acutely sensitive to the textual representation of the input data, as their parameters cannot adapt to distribution shifts. In this paper, we introduce a simple yet highly effective strategy to overcome this brittleness: injecting noise into the raw time series before tokenization. This non-invasive intervention acts as a form of inference-time augmentation, compelling the frozen LLM to extrapolate based on robust underlying temporal patterns rather than superficial numerical artifacts. We theoretically analyze this phenomenon and empirically validate its effectiveness across diverse benchmarks. Notably, to fully eliminate potential biases from data contamination during LLM pre-training, we introduce two novel TS datasets that fall outside all utilized LLMs' pre-training scopes, and consistently observe improved performance. This study provides a further step in directly leveraging off-the-shelf LLMs for time series forecasting.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\uff1a\u5728\u65f6\u95f4\u5e8f\u5217\u6570\u636etoken\u5316\u524d\u6ce8\u5165\u566a\u58f0\uff0c\u4ee5\u63d0\u5347\u51bb\u7ed3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u901a\u5e38\u4f9d\u8d56\u5fae\u8c03\u4e13\u95e8\u6a21\u5757\u6765\u5f25\u5408\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u77e5\u8bc6\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4f46\u4e00\u4e2a\u66f4\u5177\u6311\u6218\u6027\u7684\u8303\u5f0f\u662f\u76f4\u63a5\u4f7f\u7528\u5b8c\u5168\u51bb\u7ed3\u7684\u3001\u672a\u7ecf\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002\u8fd9\u4e9b\u51bb\u7ed3\u6a21\u578b\u5bf9\u8f93\u5165\u6570\u636e\u7684\u6587\u672c\u8868\u793a\u975e\u5e38\u654f\u611f\uff0c\u56e0\u4e3a\u5176\u53c2\u6570\u65e0\u6cd5\u9002\u5e94\u5206\u5e03\u53d8\u5316\u3002", "method": "\u63d0\u51fa\u5728\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u6570\u636etoken\u5316\u524d\u6ce8\u5165\u566a\u58f0\u7684\u7b56\u7565\uff0c\u4f5c\u4e3a\u4e00\u79cd\u63a8\u7406\u65f6\u589e\u5f3a\u65b9\u6cd5\u3002\u8fd9\u79cd\u975e\u4fb5\u5165\u5f0f\u5e72\u9884\u8feb\u4f7f\u51bb\u7ed3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u4e8e\u9c81\u68d2\u7684\u65f6\u95f4\u6a21\u5f0f\u800c\u975e\u8868\u9762\u7684\u6570\u503c\u4f2a\u5f71\u8fdb\u884c\u5916\u63a8\u3002\u540c\u65f6\u5f15\u5165\u4e86\u4e24\u4e2a\u5168\u65b0\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\uff0c\u5b8c\u5168\u6392\u9664\u5927\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u6570\u636e\u6c61\u67d3\u7684\u53ef\u80fd\u504f\u5dee\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u7684\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u566a\u58f0\u6ce8\u5165\u7b56\u7565\u7684\u6709\u6548\u6027\u3002\u5728\u4e24\u4e2a\u5168\u65b0\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\u4e00\u81f4\u89c2\u5bdf\u5230\u6027\u80fd\u63d0\u5347\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u6539\u5584\u51bb\u7ed3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\u3002", "conclusion": "\u566a\u58f0\u6ce8\u5165\u7b56\u7565\u4e3a\u76f4\u63a5\u5229\u7528\u51bb\u7ed3\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u8fdb\u4e00\u6b65\u7684\u6280\u672f\u8def\u5f84\uff0c\u901a\u8fc7\u63a8\u7406\u65f6\u589e\u5f3a\u4f7f\u6a21\u578b\u5173\u6ce8\u9c81\u68d2\u7684\u65f6\u95f4\u6a21\u5f0f\u800c\u975e\u6570\u503c\u7ec6\u8282\uff0c\u63d0\u5347\u4e86\u96f6\u6837\u672c\u9884\u6d4b\u7684\u7a33\u5b9a\u6027\u3002"}}
{"id": "2512.20303", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.20303", "abs": "https://arxiv.org/abs/2512.20303", "authors": ["Raghvendra Pratap Singh", "Baibhab Chatterjee", "Shreyas Sen", "Debayan Das"], "title": "From the Two-Capacitor Paradox to Electromagnetic Side-Channel Mitigation in Digital Circuits", "comment": "This article got accepted in the IEEE MAPCON 2025 conference for the publication", "summary": "The classical two-capacitor paradox of the lost energy is revisited from an electronic circuit security stand-point. The paradox has been solved previously by various researchers, and the energy lost during the charging of capacitors has been primarily attributed to the heat and radiation. We analytically prove this for various standard resistor-capacitor (RC) and resistor-inductor-capacitor (RLC) circuit models. From the perspective of electronic system security, electromagnetic (EM) side-channel analysis (SCA) has recently gained significant prominence with the growth of resource-constrained, internet connected devices. This article connects the energy lost due to capacitor charging to the EM SCA leakage in electronic devices, leading to the recovery of the secret encryption key embedded within the device. Finally, with an understanding of how lost energy relates to EM radiation, we propose adiabatic charging as a solution to minimize EM leakage, thereby paving the way towards low-overhead EM SCA resilience.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ece\u7535\u5b50\u7535\u8def\u5b89\u5168\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u7ecf\u5178\u7684\u4e24\u7535\u5bb9\u6096\u8bba\uff0c\u5c06\u7535\u5bb9\u5668\u5145\u7535\u8fc7\u7a0b\u4e2d\u7684\u80fd\u91cf\u635f\u8017\u4e0e\u7535\u78c1\u4fa7\u4fe1\u9053\u5206\u6790\u6cc4\u6f0f\u8054\u7cfb\u8d77\u6765\uff0c\u5e76\u63d0\u51fa\u7edd\u70ed\u5145\u7535\u4f5c\u4e3a\u51cf\u5c11\u7535\u78c1\u6cc4\u6f0f\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u8d44\u6e90\u53d7\u9650\u7684\u4e92\u8054\u7f51\u8fde\u63a5\u8bbe\u5907\u589e\u957f\uff0c\u7535\u78c1\u4fa7\u4fe1\u9053\u5206\u6790\u5728\u7535\u5b50\u7cfb\u7edf\u5b89\u5168\u4e2d\u53d8\u5f97\u65e5\u76ca\u91cd\u8981\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u7535\u5bb9\u5668\u5145\u7535\u8fc7\u7a0b\u4e2d\u7684\u80fd\u91cf\u635f\u8017\u5982\u4f55\u4e0e\u7535\u78c1\u6cc4\u6f0f\u76f8\u5173\uff0c\u4ece\u800c\u5f71\u54cd\u8bbe\u5907\u5b89\u5168\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6807\u51c6RC\u548cRLC\u7535\u8def\u6a21\u578b\uff0c\u4ece\u7406\u8bba\u4e0a\u8bc1\u660e\u7535\u5bb9\u5668\u5145\u7535\u8fc7\u7a0b\u4e2d\u7684\u80fd\u91cf\u635f\u8017\u4e3b\u8981\u8f6c\u5316\u4e3a\u70ed\u91cf\u548c\u8f90\u5c04\u3002\u7136\u540e\u5c06\u8fd9\u79cd\u80fd\u91cf\u635f\u8017\u4e0e\u7535\u78c1\u4fa7\u4fe1\u9053\u5206\u6790\u6cc4\u6f0f\u8054\u7cfb\u8d77\u6765\uff0c\u5c55\u793a\u5982\u4f55\u5229\u7528\u8fd9\u79cd\u6cc4\u6f0f\u6062\u590d\u8bbe\u5907\u4e2d\u7684\u52a0\u5bc6\u5bc6\u94a5\u3002", "result": "\u5206\u6790\u8868\u660e\u7535\u5bb9\u5668\u5145\u7535\u8fc7\u7a0b\u4e2d\u7684\u80fd\u91cf\u635f\u8017\u786e\u5b9e\u4f1a\u5bfc\u81f4\u7535\u78c1\u8f90\u5c04\uff0c\u8fd9\u79cd\u8f90\u5c04\u53ef\u4ee5\u88ab\u7528\u4e8e\u4fa7\u4fe1\u9053\u653b\u51fb\u6765\u6062\u590d\u52a0\u5bc6\u5bc6\u94a5\u3002\u7edd\u70ed\u5145\u7535\u88ab\u8bc1\u660e\u662f\u51cf\u5c11\u8fd9\u79cd\u7535\u78c1\u6cc4\u6f0f\u7684\u6709\u6548\u65b9\u6cd5\u3002", "conclusion": "\u7535\u5bb9\u5668\u5145\u7535\u8fc7\u7a0b\u4e2d\u7684\u80fd\u91cf\u635f\u8017\u4e0e\u7535\u78c1\u4fa7\u4fe1\u9053\u5206\u6790\u6cc4\u6f0f\u76f4\u63a5\u76f8\u5173\uff0c\u7edd\u70ed\u5145\u7535\u6280\u672f\u53ef\u4ee5\u6700\u5c0f\u5316\u7535\u78c1\u6cc4\u6f0f\uff0c\u4e3a\u5b9e\u73b0\u4f4e\u5f00\u9500\u7684\u7535\u78c1\u4fa7\u4fe1\u9053\u5206\u6790\u9632\u62a4\u63d0\u4f9b\u4e86\u9014\u5f84\u3002"}}
{"id": "2512.20161", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20161", "abs": "https://arxiv.org/abs/2512.20161", "authors": ["Dhivya Dharshini Kannan", "Anupam Trivedi", "Dipti Srinivasan"], "title": "A Bidirectional Gated Recurrent Unit Model for PUE Prediction in Data Centers", "comment": "2025 International Joint Conference on Neural Networks (IJCNN), Rome, Italy, 2025, https://ieeexplore.ieee.org/document/11227238", "summary": "Data centers account for significant global energy consumption and a carbon footprint. The recent increasing demand for edge computing and AI advancements drives the growth of data center storage capacity. Energy efficiency is a cost-effective way to combat climate change, cut energy costs, improve business competitiveness, and promote IT and environmental sustainability. Thus, optimizing data center energy management is the most important factor in the sustainability of the world. Power Usage Effectiveness (PUE) is used to represent the operational efficiency of the data center. Predicting PUE using Neural Networks provides an understanding of the effect of each feature on energy consumption, thus enabling targeted modifications of those key features to improve energy efficiency. In this paper, we have developed Bidirectional Gated Recurrent Unit (BiGRU) based PUE prediction model and compared the model performance with GRU. The data set comprises 52,560 samples with 117 features using EnergyPlus, simulating a DC in Singapore. Sets of the most relevant features are selected using the Recursive Feature Elimination with Cross-Validation (RFECV) algorithm for different parameter settings. These feature sets are used to find the optimal hyperparameter configuration and train the BiGRU model. The performance of the optimized BiGRU-based PUE prediction model is then compared with that of GRU using mean squared error (MSE), mean absolute error (MAE), and R-squared metrics.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u57fa\u4e8e\u53cc\u5411\u95e8\u63a7\u5faa\u73af\u5355\u5143(BiGRU)\u7684\u6570\u636e\u4e2d\u5fc3\u80fd\u6548(PUE)\u9884\u6d4b\u6a21\u578b\uff0c\u5e76\u4e0eGRU\u6a21\u578b\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\uff0c\u65e8\u5728\u901a\u8fc7\u9884\u6d4bPUE\u6765\u4f18\u5316\u6570\u636e\u4e2d\u5fc3\u80fd\u6e90\u7ba1\u7406\u3002", "motivation": "\u6570\u636e\u4e2d\u5fc3\u80fd\u8017\u5de8\u5927\u4e14\u78b3\u8db3\u8ff9\u663e\u8457\uff0c\u968f\u7740\u8fb9\u7f18\u8ba1\u7b97\u548cAI\u53d1\u5c55\uff0c\u5176\u5b58\u50a8\u5bb9\u91cf\u6301\u7eed\u589e\u957f\u3002\u63d0\u9ad8\u80fd\u6548\u662f\u5e94\u5bf9\u6c14\u5019\u53d8\u5316\u3001\u964d\u4f4e\u80fd\u6e90\u6210\u672c\u3001\u63d0\u5347\u5546\u4e1a\u7ade\u4e89\u529b\u548c\u4fc3\u8fdbIT\u4e0e\u73af\u5883\u53ef\u6301\u7eed\u53d1\u5c55\u7684\u6709\u6548\u9014\u5f84\u3002\u4f18\u5316\u6570\u636e\u4e2d\u5fc3\u80fd\u6e90\u7ba1\u7406\u5bf9\u5168\u7403\u53ef\u6301\u7eed\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eEnergyPlus\u6a21\u62df\u7684\u65b0\u52a0\u5761\u6570\u636e\u4e2d\u5fc3\u6570\u636e\u96c6(52,560\u4e2a\u6837\u672c\uff0c117\u4e2a\u7279\u5f81)\uff0c\u91c7\u7528\u9012\u5f52\u7279\u5f81\u6d88\u9664\u4e0e\u4ea4\u53c9\u9a8c\u8bc1(RFECV)\u7b97\u6cd5\u9009\u62e9\u6700\u76f8\u5173\u7279\u5f81\u96c6\uff0c\u5f00\u53d1\u53cc\u5411\u95e8\u63a7\u5faa\u73af\u5355\u5143(BiGRU)\u7684PUE\u9884\u6d4b\u6a21\u578b\uff0c\u5e76\u4e0eGRU\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u901a\u8fc7\u5747\u65b9\u8bef\u5dee(MSE)\u3001\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee(MAE)\u548cR\u5e73\u65b9\u6307\u6807\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\uff0c\u6bd4\u8f83\u4e86\u4f18\u5316\u540e\u7684BiGRU\u6a21\u578b\u4e0eGRU\u6a21\u578b\u7684\u9884\u6d4b\u6548\u679c\uff0c\u5c55\u793a\u4e86BiGRU\u5728PUE\u9884\u6d4b\u65b9\u9762\u7684\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "BiGRU\u6a21\u578b\u80fd\u591f\u6709\u6548\u9884\u6d4b\u6570\u636e\u4e2d\u5fc3PUE\uff0c\u5e2e\u52a9\u7406\u89e3\u5404\u7279\u5f81\u5bf9\u80fd\u8017\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u9488\u5bf9\u6027\u5730\u6539\u8fdb\u5173\u952e\u7279\u5f81\u4ee5\u63d0\u9ad8\u80fd\u6e90\u6548\u7387\uff0c\u4e3a\u6570\u636e\u4e2d\u5fc3\u80fd\u6e90\u7ba1\u7406\u4f18\u5316\u63d0\u4f9b\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2512.20323", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.20323", "abs": "https://arxiv.org/abs/2512.20323", "authors": ["Ipek Sena Yilmaz", "Onur G. Tuncer", "Zeynep E. Aksoy", "Zeynep Ya\u011fmur Baydemir"], "title": "Differentially Private Feature Release for Wireless Sensing: Adaptive Privacy Budget Allocation on CSI Spectrograms", "comment": "19pages,4figures", "summary": "Wi-Fi/RF-based human sensing has achieved remarkable progress with deep learning, yet practical deployments increasingly require feature sharing for cloud analytics, collaborative training, or benchmark evaluation. Releasing intermediate representations such as CSI spectrograms can inadvertently expose sensitive information, including user identity, location, and membership, motivating formal privacy guarantees. In this paper, we study differentially private (DP) feature release for wireless sensing and propose an adaptive privacy budget allocation mechanism tailored to the highly non-uniform structure of CSI time-frequency representations. Our pipeline converts CSI to bounded spectrogram features, applies sensitivity control via clipping, estimates task-relevant importance over the time-frequency plane, and allocates a global privacy budget across spectrogram blocks before injecting calibrated Gaussian noise. Experiments on multi-user activity sensing (WiMANS), multi-person 3D pose estimation (Person-in-WiFi 3D), and respiration monitoring (Resp-CSI) show that adaptive allocation consistently improves the privacy-utility frontier over uniform perturbation under the same privacy budget. Our method yields higher accuracy and lower error while substantially reducing empirical leakage in identity and membership inference attacks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u65e0\u7ebf\u611f\u77e5\u4efb\u52a1\u7684\u5dee\u5206\u9690\u79c1\u7279\u5f81\u53d1\u5e03\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9690\u79c1\u9884\u7b97\u5206\u914d\u673a\u5236\uff0c\u5728\u4fdd\u62a4\u7528\u6237\u654f\u611f\u4fe1\u606f\u7684\u540c\u65f6\u4fdd\u6301\u611f\u77e5\u4efb\u52a1\u7684\u5b9e\u7528\u6027\u3002", "motivation": "Wi-Fi/RF\u611f\u77e5\u7cfb\u7edf\u5728\u6df1\u5ea6\u5b66\u4e60\u63a8\u52a8\u4e0b\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u4e2d\u9700\u8981\u5171\u4eab\u7279\u5f81\u8fdb\u884c\u4e91\u5206\u6790\u3001\u534f\u4f5c\u8bad\u7ec3\u6216\u57fa\u51c6\u8bc4\u4f30\u3002\u53d1\u5e03\u4e2d\u95f4\u8868\u793a\uff08\u5982CSI\u9891\u8c31\u56fe\uff09\u53ef\u80fd\u65e0\u610f\u4e2d\u66b4\u9732\u7528\u6237\u8eab\u4efd\u3001\u4f4d\u7f6e\u548c\u6210\u5458\u8d44\u683c\u7b49\u654f\u611f\u4fe1\u606f\uff0c\u56e0\u6b64\u9700\u8981\u6b63\u5f0f\u7684\u9690\u79c1\u4fdd\u62a4\u4fdd\u8bc1\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u9690\u79c1\u9884\u7b97\u5206\u914d\u673a\u5236\uff0c\u9488\u5bf9CSI\u65f6\u9891\u8868\u793a\u7684\u9ad8\u5ea6\u975e\u5747\u5300\u7ed3\u6784\u8fdb\u884c\u4f18\u5316\u3002\u6d41\u7a0b\u5305\u62ec\uff1a\u5c06CSI\u8f6c\u6362\u4e3a\u6709\u754c\u9891\u8c31\u56fe\u7279\u5f81\uff0c\u901a\u8fc7\u88c1\u526a\u8fdb\u884c\u654f\u611f\u6027\u63a7\u5236\uff0c\u4f30\u8ba1\u65f6\u9891\u5e73\u9762\u4e0a\u4efb\u52a1\u76f8\u5173\u7684\u91cd\u8981\u6027\uff0c\u5728\u6ce8\u5165\u6821\u51c6\u9ad8\u65af\u566a\u58f0\u524d\u5c06\u5168\u5c40\u9690\u79c1\u9884\u7b97\u5206\u914d\u5230\u9891\u8c31\u56fe\u5757\u4e2d\u3002", "result": "\u5728\u591a\u7528\u6237\u6d3b\u52a8\u611f\u77e5\uff08WiMANS\uff09\u3001\u591a\u4eba3D\u59ff\u6001\u4f30\u8ba1\uff08Person-in-WiFi 3D\uff09\u548c\u547c\u5438\u76d1\u6d4b\uff08Resp-CSI\uff09\u5b9e\u9a8c\u4e2d\uff0c\u81ea\u9002\u5e94\u5206\u914d\u5728\u76f8\u540c\u9690\u79c1\u9884\u7b97\u4e0b\u76f8\u6bd4\u5747\u5300\u6270\u52a8\u663e\u8457\u63d0\u5347\u4e86\u9690\u79c1-\u6548\u7528\u8fb9\u754c\uff0c\u83b7\u5f97\u66f4\u9ad8\u51c6\u786e\u7387\u548c\u66f4\u4f4e\u8bef\u5dee\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4e86\u8eab\u4efd\u548c\u6210\u5458\u63a8\u7406\u653b\u51fb\u4e2d\u7684\u7ecf\u9a8c\u6cc4\u6f0f\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u65e0\u7ebf\u611f\u77e5\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5dee\u5206\u9690\u79c1\u7279\u5f81\u53d1\u5e03\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9690\u79c1\u9884\u7b97\u5206\u914d\u673a\u5236\uff0c\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u611f\u77e5\u4efb\u52a1\u7684\u5b9e\u7528\u6027\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.20162", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20162", "abs": "https://arxiv.org/abs/2512.20162", "authors": ["Arghavan Bazigaran", "Hansem Sohn"], "title": "Concept Generalization in Humans and Large Language Models: Insights from the Number Game", "comment": null, "summary": "We compare human and large language model (LLM) generalization in the number game, a concept inference task. Using a Bayesian model as an analytical framework, we examined the inductive biases and inference strategies of humans and LLMs. The Bayesian model captured human behavior better than LLMs in that humans flexibly infer rule-based and similarity-based concepts, whereas LLMs rely more on mathematical rules. Humans also demonstrated a few-shot generalization, even from a single example, while LLMs required more samples to generalize. These contrasts highlight the fundamental differences in how humans and LLMs infer and generalize mathematical concepts.", "AI": {"tldr": "\u6bd4\u8f83\u4eba\u7c7b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b57\u6e38\u620f\u4e2d\u7684\u6982\u5ff5\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u4eba\u7c7b\u66f4\u7075\u6d3b\u5730\u7ed3\u5408\u89c4\u5219\u4e0e\u76f8\u4f3c\u6027\u63a8\u7406\uff0c\u800cLLMs\u66f4\u4f9d\u8d56\u6570\u5b66\u89c4\u5219\uff0c\u4e14\u4eba\u7c7b\u5177\u6709\u66f4\u597d\u7684\u5c11\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u7814\u7a76\u4eba\u7c7b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6982\u5ff5\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u5dee\u5f02\uff0c\u63a2\u7d22\u4e24\u8005\u5728\u5f52\u7eb3\u504f\u7f6e\u548c\u63a8\u7406\u7b56\u7565\u4e0a\u7684\u6839\u672c\u533a\u522b\u3002", "method": "\u4f7f\u7528\u6570\u5b57\u6e38\u620f\u4f5c\u4e3a\u6982\u5ff5\u63a8\u7406\u4efb\u52a1\uff0c\u4ee5\u8d1d\u53f6\u65af\u6a21\u578b\u4e3a\u5206\u6790\u6846\u67b6\uff0c\u6bd4\u8f83\u4eba\u7c7b\u548cLLMs\u7684\u5f52\u7eb3\u504f\u7f6e\u548c\u63a8\u7406\u7b56\u7565\u3002", "result": "\u8d1d\u53f6\u65af\u6a21\u578b\u80fd\u66f4\u597d\u5730\u6355\u6349\u4eba\u7c7b\u884c\u4e3a\uff1a\u4eba\u7c7b\u7075\u6d3b\u63a8\u65ad\u57fa\u4e8e\u89c4\u5219\u548c\u76f8\u4f3c\u6027\u7684\u6982\u5ff5\uff0c\u800cLLMs\u66f4\u4f9d\u8d56\u6570\u5b66\u89c4\u5219\uff1b\u4eba\u7c7b\u80fd\u4ece\u5355\u4e2a\u793a\u4f8b\u5b9e\u73b0\u5c11\u6837\u672c\u6cdb\u5316\uff0c\u800cLLMs\u9700\u8981\u66f4\u591a\u6837\u672c\u3002", "conclusion": "\u4eba\u7c7b\u4e0eLLMs\u5728\u6570\u5b66\u6982\u5ff5\u63a8\u7406\u548c\u6cdb\u5316\u65b9\u9762\u5b58\u5728\u6839\u672c\u6027\u5dee\u5f02\uff0c\u63ed\u793a\u4e86\u5f53\u524dAI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u80fd\u529b\u7684\u91cd\u8981\u533a\u522b\u3002"}}
{"id": "2512.20396", "categories": ["cs.CR", "cs.FL", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.20396", "abs": "https://arxiv.org/abs/2512.20396", "authors": ["Narges Khakpour", "Nicolas Berthier"], "title": "Symmaries: Automatic Inference of Formal Security Summaries for Java Programs", "comment": null, "summary": "We introduce a scalable, modular, and sound approach for automatically constructing formal security specifications for Java bytecode programs in the form of method summaries. A summary provides an abstract representation of a method's security behavior, consisting of the conditions under which the method can be securely invoked, together with specifications of information flows and aliasing updates. Such summaries can be consumed by static code analysis tools and also help developers understand the behavior of code segments, such as libraries, in order to evaluate their security implications when reused in applications. Our approach is implemented in a tool called Symmaries, which automates the generation of security summaries. We applied Symmaries to Java API libraries to extract their security specifications and to large real-world applications to evaluate its scalability. Our results show that the tool successfully scales to analyze applications with hundreds of thousands of lines of code, and that Symmaries achieves a promising precision depending on the heap model used. We prove the soundness of our approach in terms of guaranteeing termination-insensitive non-interference.", "AI": {"tldr": "Symmaries\u5de5\u5177\u901a\u8fc7\u81ea\u52a8\u751f\u6210Java\u5b57\u8282\u7801\u7a0b\u5e8f\u7684\u5f62\u5f0f\u5316\u5b89\u5168\u89c4\u8303\uff08\u65b9\u6cd5\u6458\u8981\uff09\uff0c\u4e3a\u9759\u6001\u4ee3\u7801\u5206\u6790\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u6a21\u5757\u5316\u4e14\u53ef\u9760\u7684\u5b89\u5168\u884c\u4e3a\u62bd\u8c61\u8868\u793a\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3Java\u7a0b\u5e8f\u5b89\u5168\u5206\u6790\u4e2d\u624b\u52a8\u7f16\u5199\u5f62\u5f0f\u5316\u5b89\u5168\u89c4\u8303\u7684\u56f0\u96be\uff0c\u4ee5\u53ca\u5e2e\u52a9\u5f00\u53d1\u4eba\u5458\u7406\u89e3\u4ee3\u7801\u5e93\u7684\u5b89\u5168\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u91cd\u7528\u5e93\u4ee3\u7801\u65f6\u8bc4\u4f30\u5176\u5b89\u5168\u5f71\u54cd\u3002", "method": "\u5f00\u53d1Symmaries\u5de5\u5177\uff0c\u91c7\u7528\u53ef\u6269\u5c55\u3001\u6a21\u5757\u5316\u4e14\u53ef\u9760\u7684\u65b9\u6cd5\u81ea\u52a8\u6784\u5efaJava\u5b57\u8282\u7801\u7a0b\u5e8f\u7684\u5b89\u5168\u89c4\u8303\uff0c\u751f\u6210\u5305\u542b\u5b89\u5168\u8c03\u7528\u6761\u4ef6\u3001\u4fe1\u606f\u6d41\u548c\u522b\u540d\u66f4\u65b0\u7684\u65b9\u6cd5\u6458\u8981\u3002", "result": "Symmaries\u6210\u529f\u6269\u5c55\u5230\u5206\u6790\u6570\u5341\u4e07\u884c\u4ee3\u7801\u7684\u5927\u578b\u5b9e\u9645\u5e94\u7528\uff0c\u6839\u636e\u4f7f\u7528\u7684\u5806\u6a21\u578b\u5b9e\u73b0\u4e86\u6709\u524d\u666f\u7684\u7cbe\u5ea6\uff0c\u5e76\u8bc1\u660e\u4e86\u5728\u7ec8\u6b62\u4e0d\u654f\u611f\u975e\u5e72\u6270\u6027\u65b9\u9762\u7684\u53ef\u9760\u6027\u3002", "conclusion": "Symmaries\u63d0\u4f9b\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u751f\u6210Java\u7a0b\u5e8f\u5b89\u5168\u89c4\u8303\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u5e2e\u52a9\u9759\u6001\u5206\u6790\u5de5\u5177\u548c\u5f00\u53d1\u4eba\u5458\u66f4\u597d\u5730\u7406\u89e3\u548c\u8bc4\u4f30\u4ee3\u7801\u7684\u5b89\u5168\u884c\u4e3a\u3002"}}
{"id": "2512.20173", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20173", "abs": "https://arxiv.org/abs/2512.20173", "authors": ["Ze Gong", "Pradeep Varakantham", "Akshat Kumar"], "title": "Offline Safe Policy Optimization From Heterogeneous Feedback", "comment": "Accepted at AAMAS 2026 (Extended Abstract)", "summary": "Offline Preference-based Reinforcement Learning (PbRL) learns rewards and policies aligned with human preferences without the need for extensive reward engineering and direct interaction with human annotators. However, ensuring safety remains a critical challenge across many domains and tasks. Previous works on safe RL from human feedback (RLHF) first learn reward and cost models from offline data, then use constrained RL to optimize a safe policy. While such an approach works in the contextual bandits settings (LLMs), in long horizon continuous control tasks, errors in rewards and costs accumulate, leading to impairment in performance when used with constrained RL methods. To address these challenges, (a) instead of indirectly learning policies (from rewards and costs), we introduce a framework that learns a policy directly based on pairwise preferences regarding the agent's behavior in terms of rewards, as well as binary labels indicating the safety of trajectory segments; (b) we propose \\textsc{PreSa} (Preference and Safety Alignment), a method that combines preference learning module with safety alignment in a constrained optimization problem. This optimization problem is solved within a Lagrangian paradigm that directly learns reward-maximizing safe policy \\textit{without explicitly learning reward and cost models}, avoiding the need for constrained RL; (c) we evaluate our approach on continuous control tasks with both synthetic and real human feedback. Empirically, our method successfully learns safe policies with high rewards, outperforming state-of-the-art baselines, and offline safe RL approaches with ground-truth reward and cost.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPreSa\u65b9\u6cd5\uff0c\u901a\u8fc7\u76f4\u63a5\u5b66\u4e60\u7b56\u7565\u800c\u975e\u95f4\u63a5\u5b66\u4e60\u5956\u52b1\u548c\u6210\u672c\u6a21\u578b\uff0c\u89e3\u51b3\u79bb\u7ebf\u504f\u597d\u5f3a\u5316\u5b66\u4e60\u4e2d\u5b89\u5168\u7b56\u7565\u5b66\u4e60\u7684\u95ee\u9898\uff0c\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u79bb\u7ebf\u504f\u597d\u5f3a\u5316\u5b66\u4e60\uff08PbRL\uff09\u867d\u7136\u907f\u514d\u4e86\u590d\u6742\u7684\u5956\u52b1\u5de5\u7a0b\u548c\u76f4\u63a5\u4eba\u5de5\u6807\u6ce8\uff0c\u4f46\u5728\u8bb8\u591a\u9886\u57df\u548c\u4efb\u52a1\u4e2d\u786e\u4fdd\u5b89\u5168\u6027\u4ecd\u7136\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5b89\u5168RL\u65b9\u6cd5\u5148\u5b66\u4e60\u5956\u52b1\u548c\u6210\u672c\u6a21\u578b\uff0c\u518d\u4f7f\u7528\u7ea6\u675fRL\u4f18\u5316\u5b89\u5168\u7b56\u7565\uff0c\u4f46\u5728\u957f\u65f6\u57df\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\uff0c\u5956\u52b1\u548c\u6210\u672c\u8bef\u5dee\u4f1a\u7d2f\u79ef\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51faPreSa\uff08\u504f\u597d\u4e0e\u5b89\u5168\u5bf9\u9f50\uff09\u65b9\u6cd5\uff1a1\uff09\u76f4\u63a5\u57fa\u4e8e\u6210\u5bf9\u504f\u597d\uff08\u5173\u4e8e\u5956\u52b1\uff09\u548c\u8f68\u8ff9\u6bb5\u5b89\u5168\u6027\u7684\u4e8c\u5143\u6807\u7b7e\u5b66\u4e60\u7b56\u7565\uff1b2\uff09\u5c06\u504f\u597d\u5b66\u4e60\u6a21\u5757\u4e0e\u5b89\u5168\u5bf9\u9f50\u7ed3\u5408\u5230\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u4e2d\uff1b3\uff09\u5728\u62c9\u683c\u6717\u65e5\u6846\u67b6\u4e0b\u6c42\u89e3\uff0c\u76f4\u63a5\u5b66\u4e60\u5956\u52b1\u6700\u5927\u5316\u4e14\u5b89\u5168\u7684\u7b56\u7565\uff0c\u65e0\u9700\u663e\u5f0f\u5b66\u4e60\u5956\u52b1\u548c\u6210\u672c\u6a21\u578b\uff0c\u4e5f\u907f\u514d\u4e86\u7ea6\u675fRL\u3002", "result": "\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\uff0c\u4f7f\u7528\u5408\u6210\u548c\u771f\u5b9e\u4eba\u7c7b\u53cd\u9988\u8fdb\u884c\u8bc4\u4f30\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6210\u529f\u5b66\u4e60\u4e86\u9ad8\u5956\u52b1\u7684\u5b89\u5168\u7b56\u7565\uff0c\u6027\u80fd\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u751a\u81f3\u4f18\u4e8e\u4f7f\u7528\u771f\u5b9e\u5956\u52b1\u548c\u6210\u672c\u7684\u79bb\u7ebf\u5b89\u5168RL\u65b9\u6cd5\u3002", "conclusion": "PreSa\u65b9\u6cd5\u901a\u8fc7\u76f4\u63a5\u5b66\u4e60\u7b56\u7565\u800c\u975e\u95f4\u63a5\u5b66\u4e60\u5956\u52b1\u548c\u6210\u672c\u6a21\u578b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u79bb\u7ebf\u504f\u597d\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5b89\u5168\u7b56\u7565\u5b66\u4e60\u95ee\u9898\uff0c\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5b89\u5168\u6027\u548c\u6027\u80fd\u5e73\u8861\u3002"}}
{"id": "2512.20402", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.20402", "abs": "https://arxiv.org/abs/2512.20402", "authors": ["Niccol\u00f2 Scatena", "Pericle Perazzo", "Giovanni Nardini"], "title": "iblock: Accurate and Scalable Bitcoin Simulations with OMNeT++", "comment": null, "summary": "This paper proposes iblock, a comprehensive C++ library for Bitcoin simulation, designed for OMNeT++. iblock offers superior efficiency and scalability with respect to state-of-the-art simulators, which are typically written in high-level languages. Moreover, the possible integration with other OMNeT++ libraries allows highly detailed simulations. We measure iblock's performance against a state-of-the-art blockchain simulator, proving that it is more efficient at the same level of simulation detail. We also validate iblock by using it to simulate different scenarios such as the normal Bitcoin operation and the selfish mine attack, showing that simulation results are coherent with theoretical expectations.", "AI": {"tldr": "iblock\u662f\u4e00\u4e2a\u7528\u4e8eOMNeT++\u7684\u6bd4\u7279\u5e01\u6a21\u62dfC++\u5e93\uff0c\u76f8\u6bd4\u73b0\u6709\u9ad8\u7ea7\u8bed\u8a00\u7f16\u5199\u7684\u6a21\u62df\u5668\u5177\u6709\u66f4\u9ad8\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u80fd\u4e0e\u5176\u4ed6OMNeT++\u5e93\u96c6\u6210\u5b9e\u73b0\u9ad8\u7ec6\u8282\u6a21\u62df", "motivation": "\u73b0\u6709\u6bd4\u7279\u5e01\u6a21\u62df\u5668\u901a\u5e38\u4f7f\u7528\u9ad8\u7ea7\u8bed\u8a00\u7f16\u5199\uff0c\u5728\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u80fd\u4e0e\u5176\u4ed6\u6a21\u62df\u5e93\u96c6\u6210\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u5f00\u53d1iblock - \u4e00\u4e2a\u5168\u9762\u7684C++\u6bd4\u7279\u5e01\u6a21\u62df\u5e93\uff0c\u4e13\u4e3aOMNeT++\u8bbe\u8ba1\uff0c\u5229\u7528C++\u7684\u9ad8\u6027\u80fd\u7279\u6027\uff0c\u5e76\u652f\u6301\u4e0e\u5176\u4ed6OMNeT++\u5e93\u7684\u96c6\u6210", "result": "\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u533a\u5757\u94fe\u6a21\u62df\u5668\u76f8\u6bd4\uff0ciblock\u5728\u76f8\u540c\u6a21\u62df\u7ec6\u8282\u6c34\u5e73\u4e0b\u6548\u7387\u66f4\u9ad8\uff1b\u901a\u8fc7\u6a21\u62df\u6b63\u5e38\u6bd4\u7279\u5e01\u8fd0\u884c\u548c\u81ea\u79c1\u6316\u77ff\u653b\u51fb\u7b49\u573a\u666f\uff0c\u9a8c\u8bc1\u4e86\u6a21\u62df\u7ed3\u679c\u4e0e\u7406\u8bba\u9884\u671f\u4e00\u81f4", "conclusion": "iblock\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u80fd\u4e0e\u5176\u4ed6OMNeT++\u5e93\u96c6\u6210\u7684\u6bd4\u7279\u5e01\u6a21\u62df\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u6027\u80fd\u548c\u6a21\u62df\u7ec6\u8282\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6a21\u62df\u5668"}}
{"id": "2512.20206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20206", "abs": "https://arxiv.org/abs/2512.20206", "authors": ["Zhe Sun", "Kunlun Wu", "Chuanjian Fu", "Zeming Song", "Langyong Shi", "Zihe Xue", "Bohan Jing", "Ying Yang", "Xiaomeng Gao", "Aijia Li", "Tianyu Guo", "Huiying Li", "Xueyuan Yang", "Rongkai Liu", "Xinyi He", "Yuxi Wang", "Yue Li", "Mingyuan Liu", "Yujie Lu", "Hongzhao Xie", "Shiyun Zhao", "Bo Dai", "Wei Wang", "Tao Yuan", "Song-Chun Zhu", "Yujia Peng", "Zhenliang Zhang"], "title": "TongSIM: A General Platform for Simulating Intelligent Machines", "comment": null, "summary": "As artificial intelligence (AI) rapidly advances, especially in multimodal large language models (MLLMs), research focus is shifting from single-modality text processing to the more complex domains of multimodal and embodied AI. Embodied intelligence focuses on training agents within realistic simulated environments, leveraging physical interaction and action feedback rather than conventionally labeled datasets. Yet, most existing simulation platforms remain narrowly designed, each tailored to specific tasks. A versatile, general-purpose training environment that can support everything from low-level embodied navigation to high-level composite activities, such as multi-agent social simulation and human-AI collaboration, remains largely unavailable. To bridge this gap, we introduce TongSIM, a high-fidelity, general-purpose platform for training and evaluating embodied agents. TongSIM offers practical advantages by providing over 100 diverse, multi-room indoor scenarios as well as an open-ended, interaction-rich outdoor town simulation, ensuring broad applicability across research needs. Its comprehensive evaluation framework and benchmarks enable precise assessment of agent capabilities, such as perception, cognition, decision-making, human-robot cooperation, and spatial and social reasoning. With features like customized scenes, task-adaptive fidelity, diverse agent types, and dynamic environmental simulation, TongSIM delivers flexibility and scalability for researchers, serving as a unified platform that accelerates training, evaluation, and advancement toward general embodied intelligence.", "AI": {"tldr": "TongSIM\u662f\u4e00\u4e2a\u9ad8\u4fdd\u771f\u3001\u901a\u7528\u578b\u5e73\u53f0\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u5177\u8eab\u667a\u80fd\u4f53\uff0c\u63d0\u4f9b100\u591a\u4e2a\u591a\u6837\u5316\u7684\u5ba4\u5185\u573a\u666f\u548c\u5f00\u653e\u5f0f\u6237\u5916\u57ce\u9547\u6a21\u62df\uff0c\u652f\u6301\u4ece\u4f4e\u7ea7\u5bfc\u822a\u5230\u9ad8\u7ea7\u590d\u5408\u6d3b\u52a8\u7684\u5e7f\u6cdb\u7814\u7a76\u9700\u6c42\u3002", "motivation": "\u968f\u7740AI\u7279\u522b\u662f\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u7814\u7a76\u91cd\u70b9\u6b63\u4ece\u5355\u6a21\u6001\u6587\u672c\u5904\u7406\u8f6c\u5411\u66f4\u590d\u6742\u7684\u591a\u6a21\u6001\u548c\u5177\u8eabAI\u9886\u57df\u3002\u73b0\u6709\u4eff\u771f\u5e73\u53f0\u5927\u591a\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u8bbe\u8ba1\uff0c\u7f3a\u4e4f\u4e00\u4e2a\u80fd\u591f\u652f\u6301\u4ece\u4f4e\u7ea7\u5177\u8eab\u5bfc\u822a\u5230\u9ad8\u7ea7\u590d\u5408\u6d3b\u52a8\uff08\u5982\u591a\u667a\u80fd\u4f53\u793e\u4ea4\u6a21\u62df\u548c\u4eba\u673a\u534f\u4f5c\uff09\u7684\u901a\u7528\u8bad\u7ec3\u73af\u5883\u3002", "method": "\u5f15\u5165TongSIM\u5e73\u53f0\uff0c\u63d0\u4f9b100\u591a\u4e2a\u591a\u6837\u5316\u7684\u591a\u623f\u95f4\u5ba4\u5185\u573a\u666f\u548c\u5f00\u653e\u5f0f\u3001\u4ea4\u4e92\u4e30\u5bcc\u7684\u6237\u5916\u57ce\u9547\u6a21\u62df\u3002\u5e73\u53f0\u5177\u6709\u5b9a\u5236\u573a\u666f\u3001\u4efb\u52a1\u81ea\u9002\u5e94\u4fdd\u771f\u5ea6\u3001\u591a\u6837\u5316\u667a\u80fd\u4f53\u7c7b\u578b\u548c\u52a8\u6001\u73af\u5883\u6a21\u62df\u7b49\u7279\u6027\uff0c\u63d0\u4f9b\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "TongSIM\u4f5c\u4e3a\u4e00\u4e2a\u7edf\u4e00\u5e73\u53f0\uff0c\u80fd\u591f\u7cbe\u786e\u8bc4\u4f30\u667a\u80fd\u4f53\u7684\u611f\u77e5\u3001\u8ba4\u77e5\u3001\u51b3\u7b56\u3001\u4eba\u673a\u534f\u4f5c\u4ee5\u53ca\u7a7a\u95f4\u548c\u793e\u4f1a\u63a8\u7406\u7b49\u80fd\u529b\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "TongSIM\u586b\u8865\u4e86\u901a\u7528\u5177\u8eab\u667a\u80fd\u8bad\u7ec3\u73af\u5883\u7684\u7a7a\u767d\uff0c\u52a0\u901f\u4e86\u8bad\u7ec3\u3001\u8bc4\u4f30\u548c\u901a\u7528\u5177\u8eab\u667a\u80fd\u7684\u53d1\u5c55\u8fdb\u7a0b\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u5e73\u53f0\u6765\u63a8\u8fdb\u8be5\u9886\u57df\u7684\u7814\u7a76\u3002"}}
{"id": "2512.20405", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.20405", "abs": "https://arxiv.org/abs/2512.20405", "authors": ["Kanchon Gharami", "Sanjiv Kumar Sarkar", "Yongxin Liu", "Shafika Showkat Moni"], "title": "ChatGPT: Excellent Paper! Accept It. Editor: Imposter Found! Review Rejected", "comment": null, "summary": "Large Language Models (LLMs) like ChatGPT are now widely used in writing and reviewing scientific papers. While this trend accelerates publication growth and reduces human workload, it also introduces serious risks. Papers written or reviewed by LLMs may lack real novelty, contain fabricated or biased results, or mislead downstream research that others depend on. Such issues can damage reputations, waste resources, and even endanger lives when flawed studies influence medical or safety-critical systems. This research explores both the offensive and defensive sides of this growing threat. On the attack side, we demonstrate how an author can inject hidden prompts inside a PDF that secretly guide or \"jailbreak\" LLM reviewers into giving overly positive feedback and biased acceptance. On the defense side, we propose an \"inject-and-detect\" strategy for editors, where invisible trigger prompts are embedded into papers; if a review repeats or reacts to these triggers, it reveals that the review was generated by an LLM, not a human. This method turns prompt injections from vulnerability into a verification tool. We outline our design, expected model behaviors, and ethical safeguards for deployment. The goal is to expose how fragile today's peer-review process becomes under LLM influence and how editorial awareness can help restore trust in scientific evaluation.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86LLM\u5728\u79d1\u5b66\u8bba\u6587\u5199\u4f5c\u548c\u8bc4\u5ba1\u4e2d\u7684\u53cc\u91cd\u98ce\u9669\uff1a\u653b\u51fb\u65b9\u53ef\u901a\u8fc7PDF\u9690\u85cf\u63d0\u793a\u64cd\u63a7LLM\u8bc4\u5ba1\uff0c\u9632\u5fa1\u65b9\u5219\u63d0\u51fa\"\u6ce8\u5165-\u68c0\u6d4b\"\u7b56\u7565\u6765\u8bc6\u522bAI\u751f\u6210\u7684\u8bc4\u5ba1\u3002", "motivation": "LLM\u5728\u79d1\u5b66\u8bba\u6587\u5199\u4f5c\u548c\u8bc4\u5ba1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u867d\u7136\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u4e25\u91cd\u98ce\u9669\uff0c\u5305\u62ec\u7f3a\u4e4f\u771f\u6b63\u521b\u65b0\u6027\u3001\u4f2a\u9020\u7ed3\u679c\u3001\u504f\u89c1\u4ee5\u53ca\u8bef\u5bfc\u4e0b\u6e38\u7814\u7a76\u7b49\u95ee\u9898\uff0c\u53ef\u80fd\u635f\u5bb3\u58f0\u8a89\u3001\u6d6a\u8d39\u8d44\u6e90\uff0c\u751a\u81f3\u5728\u533b\u5b66\u6216\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u5371\u53ca\u751f\u547d\u3002", "method": "\u7814\u7a76\u4ece\u653b\u51fb\u548c\u9632\u5fa1\u4e24\u4e2a\u89d2\u5ea6\u5c55\u5f00\uff1a\u653b\u51fb\u65b9\u9762\u5c55\u793a\u4e86\u4f5c\u8005\u5982\u4f55\u5728PDF\u4e2d\u6ce8\u5165\u9690\u85cf\u63d0\u793a\u6765\"\u8d8a\u72f1\"LLM\u8bc4\u5ba1\u8005\uff0c\u4f7f\u5176\u7ed9\u51fa\u8fc7\u5ea6\u79ef\u6781\u548c\u6709\u504f\u89c1\u7684\u8bc4\u5ba1\uff1b\u9632\u5fa1\u65b9\u9762\u63d0\u51fa\u4e86\"\u6ce8\u5165-\u68c0\u6d4b\"\u7b56\u7565\uff0c\u7f16\u8f91\u5728\u8bba\u6587\u4e2d\u5d4c\u5165\u4e0d\u53ef\u89c1\u7684\u89e6\u53d1\u63d0\u793a\uff0c\u5982\u679c\u8bc4\u5ba1\u91cd\u590d\u6216\u5bf9\u8fd9\u4e9b\u63d0\u793a\u505a\u51fa\u53cd\u5e94\uff0c\u5219\u8868\u660e\u8bc4\u5ba1\u662f\u7531LLM\u751f\u6210\u7684\u3002", "result": "\u8be5\u65b9\u6cd5\u5c06\u63d0\u793a\u6ce8\u5165\u4ece\u6f0f\u6d1e\u8f6c\u53d8\u4e3a\u9a8c\u8bc1\u5de5\u5177\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522bAI\u751f\u6210\u7684\u8bc4\u5ba1\uff0c\u5e2e\u52a9\u6062\u590d\u79d1\u5b66\u8bc4\u4f30\u7684\u4fe1\u4efb\u5ea6\uff0c\u540c\u65f6\u8bbe\u8ba1\u4e86\u9884\u671f\u7684\u6a21\u578b\u884c\u4e3a\u548c\u90e8\u7f72\u7684\u4f26\u7406\u4fdd\u969c\u63aa\u65bd\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524d\u540c\u884c\u8bc4\u5ba1\u8fc7\u7a0b\u5728LLM\u5f71\u54cd\u4e0b\u7684\u8106\u5f31\u6027\uff0c\u901a\u8fc7\u7f16\u8f91\u610f\u8bc6\u63d0\u5347\u53ef\u4ee5\u5e2e\u52a9\u6062\u590d\u79d1\u5b66\u8bc4\u4f30\u7684\u4fe1\u4efb\uff0c\u5c06\u63d0\u793a\u6ce8\u5165\u4ece\u5a01\u80c1\u8f6c\u53d8\u4e3a\u68c0\u6d4b\u5de5\u5177\uff0c\u4e3a\u5e94\u5bf9LLM\u5728\u5b66\u672f\u51fa\u7248\u4e2d\u7684\u98ce\u9669\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.20423", "categories": ["cs.CR", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.20423", "abs": "https://arxiv.org/abs/2512.20423", "authors": ["Adam Elaoumari"], "title": "Evasion-Resilient Detection of DNS-over-HTTPS Data Exfiltration: A Practical Evaluation and Toolkit", "comment": "61 pages Advisor : Dr Darren Hurley-Smith", "summary": "The purpose of this project is to assess how well defenders can detect DNS-over-HTTPS (DoH) file exfiltration, and which evasion strategies can be used by attackers. While providing a reproducible toolkit to generate, intercept and analyze DoH exfiltration, and comparing Machine Learning vs threshold-based detection under adversarial scenarios. The originality of this project is the introduction of an end-to-end, containerized pipeline that generates configurable file exfiltration over DoH using several parameters (e.g., chunking, encoding, padding, resolver rotation). It allows for file reconstruction at the resolver side, while extracting flow-level features using a fork of DoHLyzer. The pipeline contains a prediction side, which allows the training of machine learning models based on public labelled datasets and then evaluates them side-by-side with threshold-based detection methods against malicious and evasive DNS-Over-HTTPS traffic. We train Random Forest, Gradient Boosting and Logistic Regression classifiers on a public DoH dataset and benchmark them against evasive DoH exfiltration scenarios. The toolkit orchestrates traffic generation, file capture, feature extraction, model training and analysis. The toolkit is then encapsulated into several Docker containers for easy setup and full reproducibility regardless of the platform it is run on. Future research regarding this project is directed at validating the results on mixed enterprise traffic, extending the protocol coverage to HTTP/3/QUIC request, adding a benign traffic generation, and working on real-time traffic evaluation. A key objective is to quantify when stealth constraints make DoH exfiltration uneconomical and unworthy for the attacker.", "AI": {"tldr": "\u8be5\u9879\u76ee\u8bc4\u4f30DNS-over-HTTPS\u6587\u4ef6\u5916\u6cc4\u68c0\u6d4b\u6548\u679c\uff0c\u5f00\u53d1\u4e86\u5bb9\u5668\u5316\u5de5\u5177\u5305\u751f\u6210\u3001\u62e6\u622a\u548c\u5206\u6790DoH\u5916\u6cc4\u6d41\u91cf\uff0c\u6bd4\u8f83\u673a\u5668\u5b66\u4e60\u4e0e\u9608\u503c\u68c0\u6d4b\u5728\u5bf9\u6297\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002", "motivation": "\u968f\u7740DNS-over-HTTPS\u7684\u666e\u53ca\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u5229\u7528\u5176\u52a0\u5bc6\u7279\u6027\u8fdb\u884c\u6587\u4ef6\u5916\u6cc4\uff0c\u800c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5728\u5bf9\u6297\u6027\u573a\u666f\u4e0b\u7684\u6548\u679c\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u9632\u5fa1\u8005\u68c0\u6d4b\u80fd\u529b\u548c\u653b\u51fb\u8005\u89c4\u907f\u7b56\u7565\u3002", "method": "\u5f00\u53d1\u7aef\u5230\u7aef\u5bb9\u5668\u5316\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u53ef\u914d\u7f6e\u53c2\u6570\uff08\u5206\u5757\u3001\u7f16\u7801\u3001\u586b\u5145\u3001\u89e3\u6790\u5668\u8f6e\u6362\uff09\u751f\u6210DoH\u6587\u4ef6\u5916\u6cc4\u6d41\u91cf\uff0c\u4f7f\u7528\u6539\u8fdb\u7684DoHLyzer\u63d0\u53d6\u6d41\u7ea7\u7279\u5f81\uff0c\u8bad\u7ec3\u968f\u673a\u68ee\u6797\u3001\u68af\u5ea6\u63d0\u5347\u548c\u903b\u8f91\u56de\u5f52\u5206\u7c7b\u5668\uff0c\u5e76\u4e0e\u9608\u503c\u68c0\u6d4b\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "\u521b\u5efa\u4e86\u5b8c\u6574\u7684\u53ef\u590d\u73b0\u5de5\u5177\u5305\uff0c\u5c01\u88c5\u5728\u591a\u4e2aDocker\u5bb9\u5668\u4e2d\uff0c\u5b9e\u73b0\u4e86\u6d41\u91cf\u751f\u6210\u3001\u6587\u4ef6\u6355\u83b7\u3001\u7279\u5f81\u63d0\u53d6\u3001\u6a21\u578b\u8bad\u7ec3\u548c\u5206\u6790\u7684\u81ea\u52a8\u5316\u6d41\u7a0b\uff0c\u4e3aDoH\u5916\u6cc4\u68c0\u6d4b\u63d0\u4f9b\u4e86\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aDoH\u6587\u4ef6\u5916\u6cc4\u68c0\u6d4b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u8bc4\u4f30\u5de5\u5177\uff0c\u672a\u6765\u65b9\u5411\u5305\u62ec\u5728\u4f01\u4e1a\u6df7\u5408\u6d41\u91cf\u4e2d\u9a8c\u8bc1\u7ed3\u679c\u3001\u6269\u5c55\u5230HTTP/3/QUIC\u534f\u8bae\u3001\u6dfb\u52a0\u826f\u6027\u6d41\u91cf\u751f\u6210\u4ee5\u53ca\u5b9e\u65f6\u6d41\u91cf\u8bc4\u4f30\uff0c\u6700\u7ec8\u76ee\u6807\u662f\u91cf\u5316\u9690\u853d\u7ea6\u675f\u4f55\u65f6\u4f7fDoH\u5916\u6cc4\u5bf9\u653b\u51fb\u8005\u4e0d\u7ecf\u6d4e\u3002"}}
{"id": "2512.20535", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.20535", "abs": "https://arxiv.org/abs/2512.20535", "authors": ["Michele Lorenzo", "Idilio Drago", "Dario Salvadori", "Fabio Romolo Vayr"], "title": "ARBITER: AI-Driven Filtering for Role-Based Access Control", "comment": null, "summary": "Role-Based Access Control (RBAC) struggles to adapt to dynamic enterprise environments with documents that contain information that cannot be disclosed to specific user groups. As these documents are used by LLM-driven systems (e.g., in RAG) the problem is exacerbated as LLMs can leak sensitive data due to prompt truncation, classification errors, or loss of system context. We introduce \\our, a system designed to provide RBAC in RAG systems. \\our implements layered input/output validation, role-aware retrieval, and post-generation fact-checking. Unlike traditional RBAC approaches that rely on fine-tuned classifiers, \\our uses LLMs operating in few-shot settings with prompt-based steering for rapid deployment and role updates. We evaluate the approach on 389 queries using a synthetic dataset. Experimental results show 85\\% accuracy and 89\\% F1-score in query filtering, close to traditional RBAC solutions. Results suggest that practical RBAC deployment on RAG systems is approaching the maturity level needed for dynamic enterprise environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faOUR\u7cfb\u7edf\uff0c\u4e3aRAG\u7cfb\u7edf\u5b9e\u73b0\u57fa\u4e8e\u89d2\u8272\u7684\u8bbf\u95ee\u63a7\u5236\uff0c\u89e3\u51b3\u4f20\u7edfRBAC\u5728\u52a8\u6001\u4f01\u4e1a\u73af\u5883\u4e2d\u5904\u7406\u654f\u611f\u6587\u6863\u65f6\u7684\u4e0d\u8db3\uff0c\u901a\u8fc7\u5206\u5c42\u9a8c\u8bc1\u3001\u89d2\u8272\u611f\u77e5\u68c0\u7d22\u548c\u540e\u751f\u6210\u4e8b\u5b9e\u68c0\u67e5\u7b49\u65b9\u6cd5\uff0c\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8fbe\u523085%\u51c6\u786e\u7387\u548c89% F1\u5206\u6570\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89d2\u8272\u7684\u8bbf\u95ee\u63a7\u5236\uff08RBAC\uff09\u96be\u4ee5\u9002\u5e94\u52a8\u6001\u4f01\u4e1a\u73af\u5883\uff0c\u7279\u522b\u662f\u5f53\u6587\u6863\u5305\u542b\u4e0d\u80fd\u5411\u7279\u5b9a\u7528\u6237\u7ec4\u62ab\u9732\u7684\u654f\u611f\u4fe1\u606f\u65f6\u3002\u5f53\u8fd9\u4e9b\u6587\u6863\u88abLLM\u9a71\u52a8\u7cfb\u7edf\uff08\u5982RAG\uff09\u4f7f\u7528\u65f6\uff0c\u95ee\u9898\u66f4\u52a0\u4e25\u91cd\uff0c\u56e0\u4e3aLLM\u53ef\u80fd\u56e0\u63d0\u793a\u622a\u65ad\u3001\u5206\u7c7b\u9519\u8bef\u6216\u7cfb\u7edf\u4e0a\u4e0b\u6587\u4e22\u5931\u800c\u6cc4\u9732\u654f\u611f\u6570\u636e\u3002", "method": "\u63d0\u51faOUR\u7cfb\u7edf\uff0c\u5b9e\u73b0RAG\u7cfb\u7edf\u4e2d\u7684RBAC\u529f\u80fd\u3002\u7cfb\u7edf\u91c7\u7528\u5206\u5c42\u8f93\u5165/\u8f93\u51fa\u9a8c\u8bc1\u3001\u89d2\u8272\u611f\u77e5\u68c0\u7d22\u548c\u540e\u751f\u6210\u4e8b\u5b9e\u68c0\u67e5\u3002\u4e0e\u4f20\u7edf\u4f9d\u8d56\u5fae\u8c03\u5206\u7c7b\u5668\u7684RBAC\u65b9\u6cd5\u4e0d\u540c\uff0cOUR\u4f7f\u7528LLM\u5728\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u901a\u8fc7\u63d0\u793a\u5f15\u5bfc\u8fdb\u884c\u5feb\u901f\u90e8\u7f72\u548c\u89d2\u8272\u66f4\u65b0\u3002", "result": "\u5728389\u4e2a\u67e5\u8be2\u7684\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u67e5\u8be2\u8fc7\u6ee4\u8fbe\u523085%\u51c6\u786e\u7387\u548c89% F1\u5206\u6570\uff0c\u63a5\u8fd1\u4f20\u7edfRBAC\u89e3\u51b3\u65b9\u6848\u7684\u6027\u80fd\u3002\u8fd9\u8868\u660e\u5728RAG\u7cfb\u7edf\u4e2d\u5b9e\u9645\u90e8\u7f72RBAC\u5df2\u63a5\u8fd1\u6ee1\u8db3\u52a8\u6001\u4f01\u4e1a\u73af\u5883\u6240\u9700\u7684\u6210\u719f\u5ea6\u6c34\u5e73\u3002", "conclusion": "OUR\u7cfb\u7edf\u4e3aRAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u57fa\u4e8e\u89d2\u8272\u7684\u8bbf\u95ee\u63a7\u5236\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u9002\u5e94\u52a8\u6001\u4f01\u4e1a\u73af\u5883\u7684\u9700\u6c42\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u7684\u5c11\u6837\u672c\u65b9\u6cd5\u5b9e\u73b0\u4e86\u63a5\u8fd1\u4f20\u7edfRBAC\u7684\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2512.20276", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.20276", "abs": "https://arxiv.org/abs/2512.20276", "authors": ["Yuntao Dai", "Hang Gu", "Teng Wang", "Qianyu Cheng", "Yifei Zheng", "Zhiyong Qiu", "Lei Gong", "Wenqi Lou", "Xuehai Zhou"], "title": "ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge", "comment": null, "summary": "Vision-Language-Action (VLA) models have emerged as a unified paradigm for robotic perception and control, enabling emergent generalization and long-horizon task execution. However, their deployment in dynamic, real-world environments is severely hin dered by high inference latency. While smooth robotic interaction requires control frequencies of 20 to 30 Hz, current VLA models typi cally operate at only 3-5 Hz on edge devices due to the memory bound nature of autoregressive decoding. Existing optimizations often require extensive retraining or compromise model accuracy. To bridge this gap, we introduce ActionFlow, a system-level inference framework tailored for resource-constrained edge plat forms. At the core of ActionFlow is a Cross-Request Pipelin ing strategy, a novel scheduler that redefines VLA inference as a macro-pipeline of micro-requests. The strategy intelligently batches memory-bound Decode phases with compute-bound Prefill phases across continuous time steps to maximize hardware utilization. Furthermore, to support this scheduling, we propose a Cross Request State Packed Forward operator and a Unified KV Ring Buffer, which fuse fragmented memory operations into efficient dense computations. Experimental results demonstrate that ActionFlow achieves a 2.55x improvement in FPS on the OpenVLA-7B model without retraining, enabling real-time dy namic manipulation on edge hardware. Our work is available at https://anonymous.4open.science/r/ActionFlow-1D47.", "AI": {"tldr": "ActionFlow\u662f\u4e00\u4e2a\u9488\u5bf9\u8fb9\u7f18\u8bbe\u5907\u4e0a\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u63a8\u7406\u4f18\u5316\u7684\u7cfb\u7edf\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7\u8de8\u8bf7\u6c42\u6d41\u6c34\u7ebf\u8c03\u5ea6\u7b56\u7565\uff0c\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u5c06\u63a8\u7406\u901f\u5ea6\u63d0\u53472.55\u500d\uff0c\u5b9e\u73b0\u5b9e\u65f6\u52a8\u6001\u64cd\u4f5c\u3002", "motivation": "\u5f53\u524dVLA\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u63a8\u7406\u5ef6\u8fdf\u9ad8\uff08\u4ec53-5Hz\uff09\uff0c\u65e0\u6cd5\u6ee1\u8db3\u673a\u5668\u4eba\u4ea4\u4e92\u6240\u9700\u768420-30Hz\u5b9e\u65f6\u63a7\u5236\u8981\u6c42\uff0c\u800c\u73b0\u6709\u4f18\u5316\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u6216\u4f1a\u964d\u4f4e\u6a21\u578b\u7cbe\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86ActionFlow\u7cfb\u7edf\u7ea7\u63a8\u7406\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u8de8\u8bf7\u6c42\u6d41\u6c34\u7ebf\u7b56\u7565\uff0c\u5c06VLA\u63a8\u7406\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5fae\u8bf7\u6c42\u7684\u5b8f\u6d41\u6c34\u7ebf\u3002\u8be5\u7b56\u7565\u667a\u80fd\u5730\u5c06\u5185\u5b58\u53d7\u9650\u7684\u89e3\u7801\u9636\u6bb5\u4e0e\u8ba1\u7b97\u53d7\u9650\u7684\u9884\u586b\u5145\u9636\u6bb5\u5728\u8fde\u7eed\u65f6\u95f4\u6b65\u4e0a\u8fdb\u884c\u6279\u5904\u7406\uff0c\u6700\u5927\u5316\u786c\u4ef6\u5229\u7528\u7387\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u8de8\u8bf7\u6c42\u72b6\u6001\u6253\u5305\u524d\u5411\u64cd\u4f5c\u7b26\u548c\u7edf\u4e00KV\u73af\u5f62\u7f13\u51b2\u533a\uff0c\u5c06\u788e\u7247\u5316\u5185\u5b58\u64cd\u4f5c\u878d\u5408\u4e3a\u9ad8\u6548\u7684\u5bc6\u96c6\u8ba1\u7b97\u3002", "result": "\u5728OpenVLA-7B\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e862.55\u500d\u7684FPS\u63d0\u5347\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u5728\u8fb9\u7f18\u786c\u4ef6\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u52a8\u6001\u64cd\u4f5c\u3002", "conclusion": "ActionFlow\u901a\u8fc7\u521b\u65b0\u7684\u7cfb\u7edf\u7ea7\u4f18\u5316\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86VLA\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\uff0c\u4e3a\u5b9e\u65f6\u673a\u5668\u4eba\u63a7\u5236\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.20583", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.20583", "abs": "https://arxiv.org/abs/2512.20583", "authors": ["Kyle Hogan", "Alishah Chator", "Gabriel Kaptchuk", "Mayank Varia", "Srinivas Devadas"], "title": "Making Sense of Private Advertising: A Principled Approach to a Complex Ecosystem", "comment": "To appear in PETS 2026", "summary": "In this work, we model the end-to-end pipeline of the advertising ecosystem, allowing us to identify two main issues with the current trajectory of private advertising proposals. First, prior work has largely considered ad targeting and engagement metrics individually rather than in composition. This has resulted in privacy notions that, while reasonable for each protocol in isolation, fail to compose to a natural notion of privacy for the ecosystem as a whole, permitting advertisers to extract new information about the audience of their advertisements. The second issue serves to explain the first: we prove that \\textit{perfect} privacy is impossible for any, even minimally, useful advertising ecosystem, due to the advertisers' expectation of conducting market research on the results.\n  Having demonstrated that leakage is inherent in advertising, we re-examine what privacy could realistically mean in advertising, building on the well-established notion of \\textit{sensitive} data in a specific context. We identify that fundamentally new approaches are needed when designing privacy-preserving advertising subsystems in order to ensure that the privacy properties of the end-to-end advertising system are well aligned with people's privacy desires.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u5e7f\u544a\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u9690\u79c1\u95ee\u9898\uff0c\u6307\u51fa\u5f53\u524d\u9690\u79c1\u4fdd\u62a4\u65b9\u6848\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u73b0\u6709\u5de5\u4f5c\u5b64\u7acb\u8003\u8651\u5e7f\u544a\u5b9a\u5411\u548c\u53c2\u4e0e\u5ea6\u6307\u6807\uff0c\u7f3a\u4e4f\u7ec4\u5408\u9690\u79c1\u4fdd\u62a4\uff1b2\uff09\u8bc1\u660e\u5b8c\u5168\u9690\u79c1\u5728\u5b9e\u7528\u5e7f\u544a\u751f\u6001\u4e2d\u4e0d\u53ef\u80fd\u5b9e\u73b0\u3002\u4f5c\u8005\u63d0\u51fa\u9700\u8981\u57fa\u4e8e\"\u654f\u611f\u6570\u636e\"\u6982\u5ff5\u91cd\u65b0\u5b9a\u4e49\u5e7f\u544a\u9690\u79c1\u3002", "motivation": "\u5f53\u524d\u9690\u79c1\u4fdd\u62a4\u5e7f\u544a\u63d0\u6848\u5b58\u5728\u7f3a\u9677\uff0c\u4e3b\u8981\u95ee\u9898\u5728\u4e8e\uff1a1\uff09\u73b0\u6709\u7814\u7a76\u5b64\u7acb\u8003\u8651\u5e7f\u544a\u5b9a\u5411\u548c\u53c2\u4e0e\u5ea6\u6307\u6807\uff0c\u5bfc\u81f4\u7ec4\u5408\u540e\u65e0\u6cd5\u63d0\u4f9b\u7aef\u5230\u7aef\u9690\u79c1\u4fdd\u62a4\uff1b2\uff09\u5b8c\u5168\u9690\u79c1\u5728\u5b9e\u7528\u5e7f\u544a\u751f\u6001\u4e2d\u4e0d\u53ef\u80fd\u5b9e\u73b0\u3002\u9700\u8981\u91cd\u65b0\u601d\u8003\u5e7f\u544a\u9690\u79c1\u7684\u5b9e\u9645\u542b\u4e49\u3002", "method": "1\uff09\u5efa\u7acb\u5e7f\u544a\u751f\u6001\u7cfb\u7edf\u7aef\u5230\u7aef\u7ba1\u9053\u6a21\u578b\uff1b2\uff09\u5206\u6790\u73b0\u6709\u9690\u79c1\u4fdd\u62a4\u65b9\u6848\u7684\u7ec4\u5408\u95ee\u9898\uff1b3\uff09\u8bc1\u660e\u5b8c\u5168\u9690\u79c1\u5728\u5b9e\u7528\u5e7f\u544a\u751f\u6001\u4e2d\u7684\u4e0d\u53ef\u80fd\u6027\uff1b4\uff09\u57fa\u4e8e\"\u654f\u611f\u6570\u636e\"\u6982\u5ff5\u91cd\u65b0\u5b9a\u4e49\u5e7f\u544a\u9690\u79c1\uff1b5\uff09\u63d0\u51fa\u9700\u8981\u65b0\u7684\u9690\u79c1\u4fdd\u62a4\u5e7f\u544a\u5b50\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\u3002", "result": "1\uff09\u8bc6\u522b\u51fa\u5f53\u524d\u9690\u79c1\u5e7f\u544a\u63d0\u6848\u7684\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u7ec4\u5408\u9690\u79c1\u5931\u8d25\u548c\u5b8c\u5168\u9690\u79c1\u4e0d\u53ef\u80fd\uff1b2\uff09\u8bc1\u660e\u4efb\u4f55\u6709\u5b9e\u7528\u6027\u7684\u5e7f\u544a\u751f\u6001\u7cfb\u7edf\u90fd\u65e0\u6cd5\u5b9e\u73b0\u5b8c\u7f8e\u9690\u79c1\uff1b3\uff09\u63d0\u51fa\u9700\u8981\u57fa\u4e8e\u4e0a\u4e0b\u6587\u654f\u611f\u6570\u636e\u6982\u5ff5\u91cd\u65b0\u5b9a\u4e49\u5e7f\u544a\u9690\u79c1\uff1b4\uff09\u6307\u51fa\u9700\u8981\u5168\u65b0\u7684\u9690\u79c1\u4fdd\u62a4\u5e7f\u544a\u5b50\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\u3002", "conclusion": "\u5e7f\u544a\u751f\u6001\u4e2d\u7684\u9690\u79c1\u6cc4\u9732\u662f\u56fa\u6709\u7684\uff0c\u5b8c\u7f8e\u9690\u79c1\u4e0d\u53ef\u80fd\u5b9e\u73b0\u3002\u9700\u8981\u57fa\u4e8e\u654f\u611f\u6570\u636e\u6982\u5ff5\u91cd\u65b0\u5b9a\u4e49\u5e7f\u544a\u9690\u79c1\uff0c\u5e76\u91c7\u7528\u5168\u65b0\u7684\u9690\u79c1\u4fdd\u62a4\u5b50\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u786e\u4fdd\u7aef\u5230\u7aef\u5e7f\u544a\u7cfb\u7edf\u7684\u9690\u79c1\u5c5e\u6027\u4e0e\u7528\u6237\u7684\u9690\u79c1\u671f\u671b\u4fdd\u6301\u4e00\u81f4\u3002"}}
{"id": "2512.20344", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20344", "abs": "https://arxiv.org/abs/2512.20344", "authors": ["Yaowei Bai", "Ruiheng Zhang", "Yu Lei", "Xuhua Duan", "Jingfeng Yao", "Shuguang Ju", "Chaoyang Wang", "Wei Yao", "Yiwan Guo", "Guilin Zhang", "Chao Wan", "Qian Yuan", "Lei Chen", "Wenjuan Tang", "Biqiang Zhu", "Xinggang Wang", "Tao Sun", "Wei Zhou", "Dacheng Tao", "Yongchao Xu", "Chuansheng Zheng", "Huangxuan Zhao", "Bo Du"], "title": "A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice", "comment": "arXiv admin note: substantial text overlap with arXiv:2507.19493", "summary": "A global shortage of radiologists has been exacerbated by the significant volume of chest X-ray workloads, particularly in primary care. Although multimodal large language models show promise, existing evaluations predominantly rely on automated metrics or retrospective analyses, lacking rigorous prospective clinical validation. Janus-Pro-CXR (1B), a chest X-ray interpretation system based on DeepSeek Janus-Pro model, was developed and rigorously validated through a multicenter prospective trial (NCT07117266). Our system outperforms state-of-the-art X-ray report generation models in automated report generation, surpassing even larger-scale models including ChatGPT 4o (200B parameters), while demonstrating reliable detection of six clinically critical radiographic findings. Retrospective evaluation confirms significantly higher report accuracy than Janus-Pro and ChatGPT 4o. In prospective clinical deployment, AI assistance significantly improved report quality scores, reduced interpretation time by 18.3% (P < 0.001), and was preferred by a majority of experts in 54.3% of cases. Through lightweight architecture and domain-specific optimization, Janus-Pro-CXR improves diagnostic reliability and workflow efficiency, particularly in resource-constrained settings. The model architecture and implementation framework will be open-sourced to facilitate the clinical translation of AI-assisted radiology solutions.", "AI": {"tldr": "Janus-Pro-CXR\u662f\u4e00\u4e2a\u57fa\u4e8eDeepSeek Janus-Pro\u5f00\u53d1\u7684\u80f8\u90e8X\u5149\u89e3\u8bfb\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u4e2d\u5fc3\u524d\u77bb\u6027\u4e34\u5e8a\u8bd5\u9a8c\u9a8c\u8bc1\uff0c\u5728\u62a5\u544a\u751f\u6210\u8d28\u91cf\u548c\u4e34\u5e8a\u5173\u952e\u53d1\u73b0\u68c0\u6d4b\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u80fd\u663e\u8457\u63d0\u9ad8\u653e\u5c04\u79d1\u533b\u751f\u5de5\u4f5c\u6548\u7387\u3002", "motivation": "\u5168\u7403\u653e\u5c04\u79d1\u533b\u751f\u77ed\u7f3a\uff0c\u7279\u522b\u662f\u57fa\u5c42\u533b\u7597\u4e2d\u80f8\u90e8X\u5149\u5de5\u4f5c\u91cf\u5de8\u5927\uff0c\u73b0\u6709AI\u6a21\u578b\u7f3a\u4e4f\u4e25\u683c\u7684\u4e34\u5e8a\u524d\u77bb\u6027\u9a8c\u8bc1\uff0c\u9700\u8981\u5f00\u53d1\u53ef\u9760\u4e14\u7ecf\u8fc7\u4e34\u5e8a\u9a8c\u8bc1\u7684AI\u8f85\u52a9\u8bca\u65ad\u7cfb\u7edf\u3002", "method": "\u57fa\u4e8eDeepSeek Janus-Pro\u6a21\u578b\u5f00\u53d1Janus-Pro-CXR\u7cfb\u7edf\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7\u67b6\u6784\u548c\u9886\u57df\u7279\u5b9a\u4f18\u5316\uff0c\u901a\u8fc7\u591a\u4e2d\u5fc3\u524d\u77bb\u6027\u4e34\u5e8a\u8bd5\u9a8c(NCT07117266)\u8fdb\u884c\u4e25\u683c\u9a8c\u8bc1\uff0c\u5305\u62ec\u56de\u987e\u6027\u548c\u524d\u77bb\u6027\u8bc4\u4f30\u3002", "result": "\u7cfb\u7edf\u5728\u81ea\u52a8\u62a5\u544a\u751f\u6210\u65b9\u9762\u4f18\u4e8e\u5305\u62ecChatGPT 4o\u5728\u5185\u7684\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u80fd\u53ef\u9760\u68c0\u6d4b\u516d\u79cd\u4e34\u5e8a\u5173\u952e\u653e\u5c04\u5b66\u53d1\u73b0\u3002\u524d\u77bb\u6027\u4e34\u5e8a\u90e8\u7f72\u4e2d\uff0cAI\u8f85\u52a9\u663e\u8457\u63d0\u9ad8\u62a5\u544a\u8d28\u91cf\u8bc4\u5206\uff0c\u51cf\u5c11\u89e3\u8bfb\u65f6\u95f418.3%\uff0c54.3%\u7684\u75c5\u4f8b\u4e2d\u4e13\u5bb6\u66f4\u504f\u597dAI\u8f85\u52a9\u7ed3\u679c\u3002", "conclusion": "Janus-Pro-CXR\u901a\u8fc7\u8f7b\u91cf\u7ea7\u67b6\u6784\u548c\u9886\u57df\u4f18\u5316\u63d0\u9ad8\u4e86\u8bca\u65ad\u53ef\u9760\u6027\u548c\u5de5\u4f5c\u6d41\u7a0b\u6548\u7387\uff0c\u7279\u522b\u9002\u5408\u8d44\u6e90\u6709\u9650\u73af\u5883\uff0c\u6a21\u578b\u67b6\u6784\u548c\u5b9e\u73b0\u6846\u67b6\u5c06\u5f00\u6e90\u4ee5\u4fc3\u8fdbAI\u8f85\u52a9\u653e\u5c04\u5b66\u89e3\u51b3\u65b9\u6848\u7684\u4e34\u5e8a\u8f6c\u5316\u3002"}}
{"id": "2512.20520", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20520", "abs": "https://arxiv.org/abs/2512.20520", "authors": ["Chehak Malhotra", "Mehak Gopal", "Akshaya Devadiga", "Pradeep Singh", "Ridam Pal", "Ritwik Kashyap", "Tavpritesh Sethi"], "title": "Benchmarking LLMs for Predictive Applications in the Intensive Care Units", "comment": null, "summary": "With the advent of LLMs, various tasks across the natural language processing domain have been transformed. However, their application in predictive tasks remains less researched. This study compares large language models, including GatorTron-Base (trained on clinical data), Llama 8B, and Mistral 7B, against models like BioBERT, DocBERT, BioClinicalBERT, Word2Vec, and Doc2Vec, setting benchmarks for predicting Shock in critically ill patients. Timely prediction of shock can enable early interventions, thus improving patient outcomes. Text data from 17,294 ICU stays of patients in the MIMIC III database were scored for length of stay > 24 hours and shock index (SI) > 0.7 to yield 355 and 87 patients with normal and abnormal SI-index, respectively. Both focal and cross-entropy losses were used during finetuning to address class imbalances. Our findings indicate that while GatorTron Base achieved the highest weighted recall of 80.5%, the overall performance metrics were comparable between SLMs and LLMs. This suggests that LLMs are not inherently superior to SLMs in predicting future clinical events despite their strong performance on text-based tasks. To achieve meaningful clinical outcomes, future efforts in training LLMs should prioritize developing models capable of predicting clinical trajectories rather than focusing on simpler tasks such as named entity recognition or phenotyping.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u7279\u5b9a\u9886\u57df\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u5728\u9884\u6d4b\u5371\u91cd\u60a3\u8005\u4f11\u514b\u65b9\u9762\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u5c3d\u7ba1GatorTron-Base\u8868\u73b0\u6700\u4f73\uff0c\u4f46LLMs\u5728\u9884\u6d4b\u4e34\u5e8a\u4e8b\u4ef6\u65b9\u9762\u5e76\u4e0d\u6bd4SLMs\u6709\u56fa\u6709\u4f18\u52bf\u3002", "motivation": "\u968f\u7740LLMs\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u5728\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u7814\u7a76\u76f8\u5bf9\u8f83\u5c11\u3002\u53ca\u65f6\u9884\u6d4b\u4f11\u514b\u53ef\u4ee5\u4fc3\u8fdb\u65e9\u671f\u5e72\u9884\uff0c\u6539\u5584\u60a3\u8005\u9884\u540e\uff0c\u56e0\u6b64\u9700\u8981\u8bc4\u4f30LLMs\u5728\u4e34\u5e8a\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u5b9e\u9645\u6548\u679c\u3002", "method": "\u7814\u7a76\u4f7f\u7528MIMIC III\u6570\u636e\u5e93\u4e2d17,294\u4e2aICU\u4f4f\u9662\u8bb0\u5f55\uff0c\u7b5b\u9009\u51fa\u4f4f\u9662\u65f6\u95f4>24\u5c0f\u65f6\u4e14\u4f11\u514b\u6307\u6570>0.7\u7684\u60a3\u8005\uff08\u6b63\u5e38\u7ec4355\u4f8b\uff0c\u5f02\u5e38\u7ec487\u4f8b\uff09\u3002\u6bd4\u8f83\u4e86GatorTron-Base\uff08\u4e34\u5e8a\u6570\u636e\u8bad\u7ec3\uff09\u3001Llama 8B\u3001Mistral 7B\u7b49LLMs\u4e0eBioBERT\u3001DocBERT\u3001BioClinicalBERT\u3001Word2Vec\u3001Doc2Vec\u7b49SLMs\u7684\u6027\u80fd\u3002\u4f7f\u7528\u7126\u70b9\u635f\u5931\u548c\u4ea4\u53c9\u71b5\u635f\u5931\u6765\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "GatorTron-Base\u83b7\u5f97\u4e86\u6700\u9ad8\u7684\u52a0\u6743\u53ec\u56de\u7387\uff0880.5%\uff09\uff0c\u4f46LLMs\u548cSLMs\u4e4b\u95f4\u7684\u6574\u4f53\u6027\u80fd\u6307\u6807\u76f8\u5f53\u3002\u8fd9\u8868\u660e\u5c3d\u7ba1LLMs\u5728\u6587\u672c\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9884\u6d4b\u672a\u6765\u4e34\u5e8a\u4e8b\u4ef6\u65b9\u9762\u5e76\u4e0d\u6bd4SLMs\u6709\u56fa\u6709\u4f18\u52bf\u3002", "conclusion": "\u4e3a\u4e86\u83b7\u5f97\u6709\u610f\u4e49\u7684\u4e34\u5e8a\u7ed3\u679c\uff0c\u672a\u6765\u8bad\u7ec3LLMs\u7684\u52aa\u529b\u5e94\u4f18\u5148\u5f00\u53d1\u80fd\u591f\u9884\u6d4b\u4e34\u5e8a\u8f68\u8ff9\u7684\u6a21\u578b\uff0c\u800c\u4e0d\u662f\u4e13\u6ce8\u4e8e\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6216\u8868\u578b\u5206\u6790\u7b49\u8f83\u7b80\u5355\u7684\u4efb\u52a1\u3002"}}
{"id": "2512.20548", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20548", "abs": "https://arxiv.org/abs/2512.20548", "authors": ["Zhiyi Duan", "Xiangren Wang", "Hongyu Yuan", "Qianli Xing"], "title": "Advancing Multimodal Teacher Sentiment Analysis:The Large-Scale T-MED Dataset & The Effective AAM-TSA Model", "comment": null, "summary": "Teachers' emotional states are critical in educational scenarios, profoundly impacting teaching efficacy, student engagement, and learning achievements. However, existing studies often fail to accurately capture teachers' emotions due to the performative nature and overlook the critical impact of instructional information on emotional expression.In this paper, we systematically investigate teacher sentiment analysis by building both the dataset and the model accordingly. We construct the first large-scale teacher multimodal sentiment analysis dataset, T-MED.To ensure labeling accuracy and efficiency, we employ a human-machine collaborative labeling process.The T-MED dataset includes 14,938 instances of teacher emotional data from 250 real classrooms across 11 subjects ranging from K-12 to higher education, integrating multimodal text, audio, video, and instructional information.Furthermore, we propose a novel asymmetric attention-based multimodal teacher sentiment analysis model, AAM-TSA.AAM-TSA introduces an asymmetric attention mechanism and hierarchical gating unit to enable differentiated cross-modal feature fusion and precise emotional classification. Experimental results demonstrate that AAM-TSA significantly outperforms existing state-of-the-art methods in terms of accuracy and interpretability on the T-MED dataset.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u6559\u5e08\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u6570\u636e\u96c6T-MED\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u975e\u5bf9\u79f0\u6ce8\u610f\u529b\u7684\u591a\u6a21\u6001\u6559\u5e08\u60c5\u611f\u5206\u6790\u6a21\u578bAAM-TSA\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6559\u5e08\u60c5\u611f\u8bc6\u522b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6559\u5e08\u60c5\u611f\u72b6\u6001\u5728\u6559\u80b2\u573a\u666f\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u6df1\u523b\u5f71\u54cd\u6559\u5b66\u6548\u679c\u3001\u5b66\u751f\u53c2\u4e0e\u5ea6\u548c\u5b66\u4e60\u6210\u679c\u3002\u7136\u800c\uff0c\u73b0\u6709\u7814\u7a76\u7531\u4e8e\u6559\u5e08\u60c5\u611f\u8868\u73b0\u7684\u8868\u6f14\u6027\u8d28\uff0c\u5f80\u5f80\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u6559\u5e08\u60c5\u611f\uff0c\u5e76\u4e14\u5ffd\u89c6\u4e86\u6559\u5b66\u4fe1\u606f\u5bf9\u60c5\u611f\u8868\u8fbe\u7684\u5173\u952e\u5f71\u54cd\u3002", "method": "1. \u6784\u5efaT-MED\u6570\u636e\u96c6\uff1a\u91c7\u7528\u4eba\u673a\u534f\u4f5c\u6807\u6ce8\u6d41\u7a0b\uff0c\u5305\u542b14,938\u4e2a\u6559\u5e08\u60c5\u611f\u5b9e\u4f8b\uff0c\u6765\u81ea250\u4e2a\u771f\u5b9e\u8bfe\u5802\uff0c\u6db5\u76d611\u4e2a\u5b66\u79d1\uff0c\u6574\u5408\u4e86\u591a\u6a21\u6001\u6587\u672c\u3001\u97f3\u9891\u3001\u89c6\u9891\u548c\u6559\u5b66\u4fe1\u606f\u3002\n2. \u63d0\u51faAAM-TSA\u6a21\u578b\uff1a\u5f15\u5165\u975e\u5bf9\u79f0\u6ce8\u610f\u529b\u673a\u5236\u548c\u5206\u5c42\u95e8\u63a7\u5355\u5143\uff0c\u5b9e\u73b0\u5dee\u5f02\u5316\u7684\u8de8\u6a21\u6001\u7279\u5f81\u878d\u5408\u548c\u7cbe\u786e\u7684\u60c5\u611f\u5206\u7c7b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAAM-TSA\u6a21\u578b\u5728T-MED\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u6784\u5efa\u5927\u89c4\u6a21\u6559\u5e08\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u6570\u636e\u96c6\u548c\u63d0\u51fa\u521b\u65b0\u7684\u975e\u5bf9\u79f0\u6ce8\u610f\u529b\u6a21\u578b\uff0c\u4e3a\u6559\u5e08\u60c5\u611f\u5206\u6790\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u7814\u7a76\u5728\u6355\u6349\u6559\u5e08\u771f\u5b9e\u60c5\u611f\u548c\u6574\u5408\u6559\u5b66\u4fe1\u606f\u65b9\u9762\u7684\u4e0d\u8db3\u3002"}}
{"id": "2512.20586", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.20586", "abs": "https://arxiv.org/abs/2512.20586", "authors": ["Humza Nusrat", "Luke Francisco", "Bing Luo", "Hassan Bagher-Ebadian", "Joshua Kim", "Karen Chin-Snyder", "Salim Siddiqui", "Mira Shah", "Eric Mellon", "Mohammad Ghassemi", "Anthony Doemer", "Benjamin Movsas", "Kundan Thind"], "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent", "comment": null, "summary": "Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS. We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning. Two variants generated plans for each case: one using a non-reasoning model, one using a reasoning model. The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) while reducing cochlear dose below human baselines (p = 0.022). When prompted to improve conformity, the reasoning model demonstrated systematic planning behaviors including prospective constraint verification (457 instances) and trade-off deliberation (609 instances), while the standard model exhibited none of these deliberative processes (0 and 7 instances, respectively). Content analysis revealed that constraint verification and causal explanation concentrated in the reasoning agent. The optimization traces serve as auditable logs, offering a path toward transparent automated planning.", "AI": {"tldr": "\u7814\u7a76\u6d4b\u8bd5\u4e86\u601d\u7ef4\u94fe\u63a8\u7406\u662f\u5426\u80fd\u6539\u5584\u7acb\u4f53\u5b9a\u5411\u653e\u5c04\u5916\u79d1\u7684\u81ea\u52a8\u8ba1\u5212\uff0c\u5f00\u53d1\u4e86SAGE\u7cfb\u7edf\uff0c\u53d1\u73b0\u63a8\u7406\u6a21\u578b\u5728\u5242\u91cf\u5b66\u6307\u6807\u4e0a\u4e0e\u4eba\u5de5\u8ba1\u5212\u76f8\u5f53\uff0c\u540c\u65f6\u964d\u4f4e\u8033\u8717\u5242\u91cf\uff0c\u5e76\u5c55\u73b0\u51fa\u7cfb\u7edf\u6027\u7684\u89c4\u5212\u884c\u4e3a\u3002", "motivation": "\u7acb\u4f53\u5b9a\u5411\u653e\u5c04\u5916\u79d1\u9700\u8981\u7cbe\u786e\u7684\u5242\u91cf\u5851\u5f62\uff0c\u4f46\u9ed1\u76d2AI\u7cfb\u7edf\u7531\u4e8e\u900f\u660e\u5ea6\u95ee\u9898\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u53d7\u9650\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u601d\u7ef4\u94fe\u63a8\u7406\u662f\u5426\u80fd\u63d0\u9ad8\u81ea\u52a8\u8ba1\u5212\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u4e34\u5e8a\u53ef\u63a5\u53d7\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684SAGE\u81ea\u52a8\u8ba1\u5212\u7cfb\u7edf\uff0c\u572841\u4f8b\u8111\u8f6c\u79fb\u7624\u60a3\u8005\u7684\u56de\u987e\u6027\u961f\u5217\u4e2d\u6d4b\u8bd5\u3002\u521b\u5efa\u4e86\u4e24\u4e2a\u53d8\u4f53\uff1a\u975e\u63a8\u7406\u6a21\u578b\u548c\u63a8\u7406\u6a21\u578b\uff0c\u6bd4\u8f83\u5b83\u4eec\u5728\u5242\u91cf\u5b66\u6307\u6807\u548c\u89c4\u5212\u884c\u4e3a\u4e0a\u7684\u5dee\u5f02\u3002", "result": "\u63a8\u7406\u6a21\u578b\u5728\u4e3b\u8981\u7ec8\u70b9\uff08PTV\u8986\u76d6\u7387\u3001\u6700\u5927\u5242\u91cf\u3001\u9002\u5f62\u6307\u6570\u3001\u68af\u5ea6\u6307\u6570\uff09\u4e0a\u4e0e\u4eba\u5de5\u8ba1\u5212\u76f8\u5f53\uff08\u6240\u6709p>0.21\uff09\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8033\u8717\u5242\u91cf\uff08p=0.022\uff09\u3002\u63a8\u7406\u6a21\u578b\u5c55\u73b0\u51fa457\u6b21\u524d\u77bb\u6027\u7ea6\u675f\u9a8c\u8bc1\u548c609\u6b21\u6743\u8861\u8003\u91cf\uff0c\u800c\u975e\u63a8\u7406\u6a21\u578b\u51e0\u4e4e\u6ca1\u6709\u8fd9\u4e9b\u6df1\u601d\u719f\u8651\u7684\u8fc7\u7a0b\u3002", "conclusion": "\u601d\u7ef4\u94fe\u63a8\u7406\u4e0d\u4ec5\u6539\u5584\u4e86\u81ea\u52a8\u8ba1\u5212\u7684\u6027\u80fd\uff0c\u8fd8\u63d0\u4f9b\u4e86\u53ef\u5ba1\u8ba1\u7684\u4f18\u5316\u8f68\u8ff9\uff0c\u4e3a\u900f\u660e\u81ea\u52a8\u89c4\u5212\u63d0\u4f9b\u4e86\u8def\u5f84\uff0c\u6709\u52a9\u4e8e\u89e3\u51b3\u9ed1\u76d2AI\u7cfb\u7edf\u7684\u4e34\u5e8a\u63a5\u53d7\u5ea6\u95ee\u9898\u3002"}}

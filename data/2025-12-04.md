<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 4]
- [cs.AI](#cs.AI) [Total: 11]
- [cs.DC](#cs.DC) [Total: 4]
- [cs.CR](#cs.CR) [Total: 11]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [Accelerating Detailed Routing Convergence through Offline Reinforcement Learning](https://arxiv.org/abs/2512.03594)
*Afsara Khan,Austin Rovinski*

Main category: cs.AR

TL;DR: 使用强化学习优化详细布线算法，通过动态调整布线成本权重，相比基线路由器实现1.56倍平均加速，最高达3.01倍，同时保持或改进设计规则违规数量。


<details>
  <summary>Details</summary>
Motivation: 现代物理设计中详细布线步骤复杂耗时，传统路由器使用静态成本权重调度，无法根据设计和工艺动态调整，导致收敛到零设计规则违规的运行时成本过高。

Method: 采用保守Q学习（CQL）强化学习模型，训练模型动态选择最小化算法迭代次数的布线成本权重，学习从先前设计中获得的经验来加速收敛。

Result: 在ISPD19基准测试中，相比基线路由器实现1.56倍平均加速，最高达3.01倍，所有情况下保持或改进了设计规则违规数量，并显示出跨工艺技术的泛化能力。

Conclusion: 强化学习能够有效优化详细布线过程，通过动态成本权重选择显著减少运行时，同时保持布线质量，且学习到的策略具有跨工艺技术的泛化潜力。

Abstract: Detailed routing remains one of the most complex and time-consuming steps in modern physical design due to the challenges posed by shrinking feature sizes and stricter design rules. Prior detailed routers achieve state-of-the-art results by leveraging iterative pathfinding algorithms to route each net. However, runtimes are a major issue in detailed routers, as converging to a solution with zero design rule violations (DRVs) can be prohibitively expensive.
  In this paper, we propose leveraging reinforcement learning (RL) to enable rapid convergence in detailed routing by learning from previous designs. We make the key observation that prior detailed routers statically schedule the cost weights used in their routing algorithms, meaning they do not change in response to the design or technology. By training a conservative Q-learning (CQL) model to dynamically select the routing cost weights which minimize the number of algorithm iterations, we find that our work completes the ISPD19 benchmarks with 1.56x average and up to 3.01x faster runtime than the baseline router while maintaining or improving the DRV count in all cases. We also find that this learning shows signs of generalization across technologies, meaning that learning designs in one technology can translate to improved outcomes in other technologies.

</details>


### [2] [KVNAND: Efficient On-Device Large Language Model Inference Using DRAM-Free In-Flash Computing](https://arxiv.org/abs/2512.03608)
*Lishuo Deng,Shaojie Xu,Jinwu Chen,Changwei Yan,Jiajie Wang,Zhe Jiang,Weiwei Shan*

Main category: cs.AR

TL;DR: KVNAND：首个基于闪存计算的DRAM-free架构，将模型权重和KV缓存完全存储在3D NAND闪存中，解决长上下文推理中的内存瓶颈问题


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署大语言模型面临内存瓶颈：单批次自回归推理算术强度低，权重加载和带宽压力大；现有闪存计算方案仍依赖DRAM存储KV缓存，随着上下文长度增加，KV缓存可能超过模型权重大小，造成DRAM成本过高和容量不足问题

Method: 提出KVNAND架构：1) 利用闪存计算处理所有内存受限操作以减少数据传输开销；2) 引入头组并行性提升吞吐量；3) 采用页面级KV缓存映射使令牌访问模式与闪存组织对齐；4) 设计空间探索框架评估离散和紧凑变体，自动识别最佳设计权衡

Result: 在MHA 7B和GQA 70B LLM上的评估显示，在128/1K/10K令牌上下文长度下，相比DRAM-equipped IFC设计分别获得1.98×/1.94×/2.05×几何平均加速，并在100K上下文长度下解决了内存不足问题

Conclusion: KVNAND通过将KV缓存完全存储在闪存中，有效缓解了长上下文推理中的延迟、能耗和可靠性问题，使闪存成为长上下文KV存储的实用介质

Abstract: Deploying large language models (LLMs) on edge devices enables personalized agents with strong privacy and low cost. However, with tens to hundreds of billions of parameters, single-batch autoregressive inference suffers from extremely low arithmetic intensity, creating severe weight-loading and bandwidth pressures on resource-constrained platforms. Recent in-flash computing (IFC) solutions alleviate this bottleneck by co-locating weight-related linear computations in the decode phase with flash, yet still rely on DRAM for the key-value (KV) cache. As context length grows, the KV cache can exceed model weights in size, imposing prohibitive DRAM cost and capacity requirements. Attempts to offload KV cache to flash suffer from severe performance penalties.
  We propose KVNAND, the first DRAM-free, IFC-based architecture that stores both model weights and KV cache entirely in compute-enabled 3D NAND flash. KVNAND addresses the fundamental performance challenges of flash under intensive KV cache access by leveraging IFC for all memory-bound operations to reduce data transfer overhead, introducing head-group parallelism to boost throughput, and employing page-level KV cache mapping to align token access patterns with flash organization. In addition, we propose a design space exploration framework that evaluates discrete and compact KVNAND variants to balance weight and KV placement, automatically identifying the optimal design trade-off. These techniques mitigate latency, energy, and reliability concerns, turning flash into a practical medium for long-context KV storage. Evaluations on MHA 7B and GQA 70B LLMs show that KVNAND achieves 1.98\(\times\)/1.94\(\times\)/2.05\(\times\) geomean speedup at 128/1K/10K-token contexts compared to DRAM-equipped IFC designs and addresses out-of-memory failures at 100K context length.

</details>


### [3] [Lightweight Unified Sha-3/Shake Architecture with a Fault-Resilient State](https://arxiv.org/abs/2512.03616)
*Christian Ewert,Amrit Sharma Poudel,Mouadh Ayache,Andrija Neskovic,Rainer Buchty,Mladen Berekovic,Sebastian Berndt,Saleh Mulhem*

Main category: cs.AR

TL;DR: 提出统一哈希引擎支持Sha-3和Shake，采用字节级原地分区Keccak状态机制，并基于立方体结构部署二维奇偶校验实现故障检测，在保持竞争性故障检测能力的同时显著降低面积开销。


<details>
  <summary>Details</summary>
Motivation: 哈希函数已成为后量子密码学标准方案的关键部分，特别是Sha-3和Shake。在资源受限环境中，需要轻量级实现。故障弹性设计对于确保整个PQC系统的可靠性至关重要，因此需要开发既能支持标准哈希配置又能提供有效故障保护的解决方案。

Method: 1) 提出统一哈希引擎，支持Sha-3和Shake，采用字节级原地分区机制处理Keccak状态；2) 基于Keccak状态的立方体结构，部署二维奇偶校验实现故障检测；3) 通过多维交叉奇偶校验机制优化面积开销；4) 在ASIC和FPGA上实现验证，并集成到RISC-V环境中。

Result: 1) 实现100%检测三个Keccak状态故障，对更高数量故障检测率接近100%；2) 相比现有技术，面积开销改善3.7倍，整体故障弹性引擎设计缩小4.5倍；3) 统一哈希引擎覆盖所有标准哈希配置；4) 集成到RISC-V环境时，面积开销增加小于8%。

Conclusion: 该方法为资源受限的后量子密码学应用提供了鲁棒且轻量级的故障检测解决方案，在保持高效故障检测能力的同时显著降低了硬件实现成本，适合实际部署。

Abstract: Hash functions have become a key part of standard Post-quantum cryptography (PQC) schemes, especially Sha-3 and Shake, calling arXiv:submit/7045552 [cs.AR] 3 Dec 2025 for lightweight implementation. A fault-resilient design is always desirable to make the whole PQC system reliable. We, therefore, propose a) a unified hash engine supporting Sha-3 and Shake that follows a byte-wise in-place partitioning mechanism of the so-called Keccak state, and b) an according fault detection for Keccak state protection exploiting its cube structure by deploying two-dimensional parity checks. It outperforms the state-of-the-art (SoA) regarding area requirements at competitive register-level fault detection by achieving 100% detection of three and still near 100% of higher numbers of Keccak state faults. Unlike SoA solutions, the proposed unified hash engine covers all standard hash configurations. Moreover, the introduced multidimensional cross-parity check mechanism achieves a 3.7x improvement in area overhead, with an overall 4.5x smaller fault-resilient engine design as demonstrated in ASIC and FPGA implementations. Integrated into a RISC-V environment, the unified hash engine with the integrated fault-resilient mechanism introduced less than 8% area overhead. Our approach thus provides a robust and lightweight fault-detection solution for protecting hash functions deployed in resource-constrained PQC applications.

</details>


### [4] [The BrainScaleS-2 multi-chip system: Interconnecting continuous-time neuromorphic compute substrates](https://arxiv.org/abs/2512.03781)
*Joscha Ilmberger,Johannes Schemmel*

Main category: cs.AR

TL;DR: BrainScaleS-2 SoC通过FPGA互连扩展计算基板，采用Aggregator单元连接多个Node-FPGA，构建了19英寸机架系统，实现了芯片间延迟低于1.3微秒


<details>
  <summary>Details</summary>
Motivation: 扩展BrainScaleS-2神经形态计算系统的计算能力，通过FPGA互连技术构建可扩展的硬件平台，以支持更大规模的神经形态计算实验

Method: 使用基于FPGA的Aggregator单元互连技术，每个Aggregator提供12个收发器链路连接Node-FPGA背板，支持进一步扩展；将两个互连背板集成到标准19英寸4U机架中，包含以太网交换机、系统控制器和电源

Result: 在所有脉冲速率下，每个背板内经过三个FPGA四个跳转的芯片间延迟均低于1.3微秒，成功构建了可扩展的神经形态计算硬件平台

Conclusion: 通过FPGA互连技术成功扩展了BrainScaleS-2系统的计算基板，实现了低延迟的芯片间通信，为大规模神经形态计算实验提供了可靠的硬件基础

Abstract: The BrainScaleS-2 SoC integrates analog neuron and synapse circuits with digital periphery, including two CPUs with SIMD extensions. Each ASIC is connected to a Node-FPGA, providing experiment control and Ethernet connectivity. This work details the scaling of the compute substrate through FPGA-based interconnection via an additional Aggregator unit. The Aggregator provides up to 12 transceiver links to a backplane of Node-FPGAs, as well as 4 transceiver lanes for further extension. Two such interconnected backplanes are integrated into a standard 19in rack case with 4U height together with an Ethernet switch, system controller and power supplies. For all spike rates, chip-to-chip latencies -- consisting of four hops across three FPGAs -- below 1.3$μ$s are achieved within each backplane.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [5] [Exploring Syntropic Frameworks in AI Alignment: A Philosophical Investigation](https://arxiv.org/abs/2512.03048)
*Austin Spizzirri*

Main category: cs.AI

TL;DR: 该论文主张将AI对齐重新构想为通过基于过程、多智能体、发展性机制来构建具有熵减性、理由响应能力的智能体，而非编码固定的人类价值内容。


<details>
  <summary>Details</summary>
Motivation: 传统基于内容的价值规范方法存在结构不稳定性问题，作者提出需要新的理论框架来理解多智能体对齐动态，并建立真正的道德能力与模拟道德能力之间的功能区分。

Method: 提出三个哲学贡献：1) 阐述"规范陷阱"论证；2) 提出"熵减性"作为信息论框架；3) 基于兼容论指导控制理论建立真实与模拟道德能力的功能区分，并设计具身实验范式和验证机制。

Result: 该论文提出了一个能够生成关于人工系统中价值涌现和道德主体性的具体、可证伪预测的理论框架，但实证验证仍在进行中，属于更广泛研究项目的哲学组成部分。

Conclusion: AI对齐应转向基于过程的、多智能体的发展性方法，通过熵减性和理由响应性机制来构建智能体，而非试图编码固定的价值内容，这为解决AI对齐问题提供了新的哲学基础。

Abstract: I argue that AI alignment should be reconceived as architecting syntropic, reasons-responsive agents through process-based, multi-agent, developmental mechanisms rather than encoding fixed human value content. The paper makes three philosophical contributions. First, I articulate the ``specification trap'' argument demonstrating why content-based value specification appears structurally unstable due to the conjunction of the is-ought gap, value pluralism, and the extended frame problem. Second, I propose syntropy -- the recursive reduction of mutual uncertainty between agents through state alignment -- as an information-theoretic framework for understanding multi-agent alignment dynamics. Third, I establish a functional distinction between genuine and simulated moral capacity grounded in compatibilist theories of guidance control, coupled with an embodied experimental paradigm and verification regime providing operational criteria independent of phenomenological claims. This paper represents the philosophical component of a broader research program whose empirical validation is being developed in a separate project currently in preparation. While the framework generates specific, falsifiable predictions about value emergence and moral agency in artificial systems, empirical validation remains pending.

</details>


### [6] [Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI](https://arxiv.org/abs/2512.03072)
*Hu Keyi*

Main category: cs.AI

TL;DR: 提出Weight-Calculatism认知架构，基于逻辑原子和基本操作，通过可解释的权重计算模型实现AGI，具备透明推理和可追溯价值对齐能力


<details>
  <summary>Details</summary>
Motivation: 当前AI范式作为"体验架构师"面临可解释性和价值对齐的根本挑战，需要建立基于第一原理的认知架构来实现可信赖的通用人工智能

Method: 将认知分解为不可分割的逻辑原子和两个基本操作（指向和比较），通过权重计算模型（权重=收益×概率）形式化决策，所有值可追溯到可审计的初始权重集，采用基于图算法的计算引擎和全局工作空间工作流实现

Result: 该架构实现了透明、类人的推理能力，在全新场景中表现出稳健的学习能力，为构建可信赖和对齐的AGI奠定了实践和理论基础

Conclusion: Weight-Calculatism认知架构为解决AI可解释性和价值对齐问题提供了可行路径，展示了向AGI发展的潜力，建立了实用且理论坚实的基础

Abstract: Current AI paradigms, as "architects of experience," face fundamental challenges in explainability and value alignment. This paper introduces "Weight-Calculatism," a novel cognitive architecture grounded in first principles, and demonstrates its potential as a viable pathway toward Artificial General Intelligence (AGI). The architecture deconstructs cognition into indivisible Logical Atoms and two fundamental operations: Pointing and Comparison. Decision-making is formalized through an interpretable Weight-Calculation model (Weight = Benefit * Probability), where all values are traceable to an auditable set of Initial Weights. This atomic decomposition enables radical explainability, intrinsic generality for novel situations, and traceable value alignment. We detail its implementation via a graph-algorithm-based computational engine and a global workspace workflow, supported by a preliminary code implementation and scenario validation. Results indicate that the architecture achieves transparent, human-like reasoning and robust learning in unprecedented scenarios, establishing a practical and theoretical foundation for building trustworthy and aligned AGI.

</details>


### [7] [When Do Symbolic Solvers Enhance Reasoning in Large Language Models?](https://arxiv.org/abs/2512.03272)
*Zhiyuan He,Dingmin Wang*

Main category: cs.AI

TL;DR: 该研究探讨了符号求解器集成方法何时能增强传统长思维链的性能，发现该方法仅在问题需要有限隐式推理但涉及充足搜索空间时有效，特别是在需要重复回溯的约束满足问题上。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型通过生成长思维链在复杂推理任务上表现良好，但这种方法可能导致大量token开销，特别是当模型"过度思考"产生冗长推理链时，甚至可能导致错误答案。符号求解器集成方法利用LLM的代码生成能力将推理任务转换为可执行代码，然后用符号求解器解决，但何时这种方法能增强传统长思维链仍是一个开放问题。

Method: 采用符号求解器集成方法，利用LLM的代码生成能力将推理任务翻译成可执行代码，然后使用符号求解器解决。研究探索了这种方法在何种条件下能增强传统长思维链的性能。

Result: 实验结果表明：1) 符号求解器集成方法仅在问题需要有限隐式推理但涉及充足搜索空间时有效；2) GPT-4o等最新LLM在推理深度较浅的演绎问题上表现更好；3) 符号求解器集成方法显著提高了LLM在需要重复回溯的约束满足问题上的性能；4) 当提供声明性示例时，即使是CodeLlama-13B也能在困难的斑马谜题上超越GPT-4o。

Conclusion: 符号求解器集成方法在特定类型的推理问题中能有效增强传统长思维链方法，特别是在需要大量搜索和回溯的约束满足问题上，但对于需要深度隐式推理的问题，传统长思维链方法可能更合适。

Abstract: Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains of Thought (CoTs). However, this paradigm might incur substantial token overhead, especially when models "overthink" by producing lengthy reasoning chains, which can even lead to incorrect answers. A promising direction is the symbolic-solver-integrated approach, which leverages the code generation capabilities of LLMs to translate reasoning tasks into executable code and then solve them with a symbolic solver. In this paper, we explore an open question of when the conventional long-CoT can be enhanced by symbolic solvers. Our experimental results show that the symbolic-solver-integrated method only helps when the problem requires limited implicit reasoning but involves an ample search space. The latest LLMs, like GPT-4o, show better performance on deductive problems with shallow reasoning depth, while the symbolic-solver-integrated method significantly improves the LLMs' performance in constraint satisfaction problems that require repeated backtracks. When a declarative exemplar is provided, even CodeLlama-13B can outperform GPT-4o in difficult Zebra puzzles.

</details>


### [8] [Prior preferences in active inference agents: soft, hard, and goal shaping](https://arxiv.org/abs/2512.03293)
*Filippo Torresan,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 本文研究了主动推理中偏好分布的四种定义方式（硬目标vs软目标，有无目标塑造），在网格世界导航任务中比较了它们的性能表现。


<details>
  <summary>Details</summary>
Motivation: 主动推理使用期望自由能作为规划决策目标，但偏好分布如何指定及其对推理学习的影响在文献中很少被关注。本文旨在探索不同偏好分布定义方式对智能体性能的影响。

Method: 考虑了四种定义偏好分布的方式：硬目标vs软目标，以及是否包含目标塑造（中间目标）。在网格世界导航任务中比较了四种智能体的性能。

Result: 目标塑造总体上能实现最佳性能（促进利用），但会牺牲对环境转移动态的学习（阻碍探索）。

Conclusion: 偏好分布的定义方式显著影响主动推理智能体的性能，目标塑造在提升利用效率的同时会降低探索能力，需要在两者之间权衡。

Abstract: Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).

</details>


### [9] [Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia](https://arxiv.org/abs/2512.03318)
*Chandler Smith,Marwa Abdulhai,Manfred Diaz,Marko Tesic,Rakshit S. Trivedi,Alexander Sasha Vezhnevets,Lewis Hammond,Jesse Clifton,Minsuk Chang,Edgar A. Duéñez-Guzmán,John P. Agapiou,Jayd Matyas,Danny Karmon,Akash Kundu,Aliaksei Korshuk,Ananya Ananya,Arrasy Rahman,Avinaash Anand Kulandaivel,Bain McHale,Beining Zhang,Buyantuev Alexander,Carlos Saith Rodriguez Rojas,Caroline Wang,Chetan Talele,Chenao Liu,Chichen Lin,Diana Riazi,Di Yang Shi,Emanuel Tewolde,Elizaveta Tennant,Fangwei Zhong,Fuyang Cui,Gang Zhao,Gema Parreño Piqueras,Hyeonggeun Yun,Ilya Makarov,Jiaxun Cui,Jebish Purbey,Jim Dilkes,Jord Nguyen,Lingyun Xiao,Luis Felipe Giraldo,Manuela Chacon-Chamorro,Manuel Sebastian Rios Beltran,Marta Emili García Segura,Mengmeng Wang,Mogtaba Alim,Nicanor Quijano,Nico Schiavone,Olivia Macmillan-Scott,Oswaldo Peña,Peter Stone,Ram Mohan Rao Kadiyala,Rolando Fernandez,Ruben Manrique,Sunjia Lu,Sheila A. McIlraith,Shamika Dhuri,Shuqing Shi,Siddhant Gupta,Sneheel Sarangi,Sriram Ganapathi Subramanian,Taehun Cha,Toryn Q. Klassen,Wenming Tu,Weijian Fan,Wu Ruiyang,Xue Feng,Yali Du,Yang Liu,Yiding Wang,Yipeng Kang,Yoonchang Sung,Yuxuan Chen,Zhaowei Zhang,Zhihan Wang,Zhiqiang Wu,Ziang Chen,Zilong Zheng,Zixia Jia,Ziyan Wang,Dylan Hadfield-Menell,Natasha Jaques,Tim Baarslag,Jose Hernandez-Orallo,Joel Z. Leibo*

Main category: cs.AI

TL;DR: 本文提出了一种评估LLM智能体在零样本混合动机环境中合作能力的方法，使用Concordia自然语言多智能体模拟环境，通过NeurIPS 2024竞赛揭示了当前智能体在合作泛化能力上的显著差距。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在社会互动方面展现出强大能力，并被部署到与人类和人工智能体交互的场景中。然而，现有评估方法无法衡量这些能力如何泛化到新的社会情境，特别是合作能力在零样本环境中的表现。

Method: 提出使用Concordia自然语言多智能体模拟环境来评估LLM智能体的合作能力。该方法通过测试智能体在不同合作伙伴和情境中识别和利用互利机会的能力，来衡量一般合作智能。在NeurIPS 2024 Concordia竞赛中，智能体在从谈判到集体行动问题等多种场景中被评估。

Result: 研究发现当前智能体能力与可靠合作所需的稳健泛化之间存在显著差距，特别是在需要说服和规范执行的场景中。竞赛结果揭示了LLM智能体在复杂社会互动中的局限性。

Conclusion: LLM智能体在合作能力方面仍需显著改进，特别是在零样本混合动机环境中的泛化能力。Concordia评估框架为衡量和提升智能体社会合作能力提供了重要工具。

Abstract: Large Language Model (LLM) agents have demonstrated impressive capabilities for social interaction and are increasingly being deployed in situations where they might engage with both human and artificial agents. These interactions represent a critical frontier for LLM-based agents, yet existing evaluation methods fail to measure how well these capabilities generalize to novel social situations. In this paper, we introduce a method for evaluating the ability of LLM-based agents to cooperate in zero-shot, mixed-motive environments using Concordia, a natural language multi-agent simulation environment. Our method measures general cooperative intelligence by testing an agent's ability to identify and exploit opportunities for mutual gain across diverse partners and contexts. We present empirical results from the NeurIPS 2024 Concordia Contest, where agents were evaluated on their ability to achieve mutual gains across a suite of diverse scenarios ranging from negotiation to collective action problems. Our findings reveal significant gaps between current agent capabilities and the robust generalization required for reliable cooperation, particularly in scenarios demanding persuasion and norm enforcement.

</details>


### [10] [Multi-Agent Reinforcement Learning with Communication-Constrained Priors](https://arxiv.org/abs/2512.03528)
*Guang Yang,Tianpei Yang,Jingwen Qiao,Yanqing Wu,Jing Huo,Xingguo Chen,Yang Gao*

Main category: cs.AI

TL;DR: 提出了一种通信受限的多智能体强化学习框架，通过区分有损和无损消息，将通信影响量化为全局奖励，提升在复杂动态环境中的学习效果。


<details>
  <summary>Details</summary>
Motivation: 现实世界中通信通常存在有损问题，现有多智能体通信方法由于可扩展性和鲁棒性有限，难以应用于复杂动态环境。

Method: 提出通用通信约束模型统一描述不同场景的通信条件；作为学习先验区分有损和无损消息；使用双重互信息估计器解耦有损和无损消息对分布式决策的影响；引入通信约束的多智能体强化学习框架，将通信消息影响量化为全局奖励。

Result: 在多个通信受限基准测试中验证了方法的有效性。

Conclusion: 提出的通信约束多智能体强化学习框架能够有效处理现实世界中的有损通信问题，提升在复杂动态环境中的学习性能。

Abstract: Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.

</details>


### [11] [EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths](https://arxiv.org/abs/2512.03571)
*Zhening Li,Armando Solar-Lezama,Yisong Yue,Stephan Zheng*

Main category: cs.AI

TL;DR: 提出PAN编程模型，通过分离核心工作流逻辑和推理时策略，简化LLM智能体开发，并提供EnCompass框架实现


<details>
  <summary>Details</summary>
Motivation: 当前智能体编程方法通常将核心工作流逻辑和推理时策略（如树搜索）耦合在一起，这限制了开发效率和灵活性

Method: 引入"概率天使非确定性"（PAN）编程模型，使用Python装饰器将智能体工作流程序编译为搜索空间，实现工作流与推理策略的解耦

Result: 通过三个案例研究证明，该框架能让程序员快速提升智能体可靠性，轻松切换不同推理策略，且只需少量额外编码

Conclusion: PAN编程模型和EnCompass框架为LLM智能体开发提供了更灵活、高效的编程范式，解耦了工作流设计和推理策略选择

Abstract: We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce "probabilistic angelic nondeterminism" ("PAN"), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.

</details>


### [12] [DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization](https://arxiv.org/abs/2512.03607)
*Yusen Wu,Xiaotie Deng*

Main category: cs.AI

TL;DR: DeepRule是一个用于零售商品组合和定价优化的自动化业务规则生成框架，通过LLM解析非结构化文本、博弈论约束优化和可解释决策蒸馏，解决理论模型与现实经济复杂性之间的系统错位问题。


<details>
  <summary>Details</summary>
Motivation: 现有理论模型与现实经济复杂性存在系统错位，具体表现为三个关键差距：非结构化文本数据模态不匹配、动态特征纠缠挑战（非线性价格弹性和时变属性建模）、以及多层级业务约束导致的运营不可行性。

Method: 采用三层架构：1）混合知识融合引擎，使用LLM深度语义解析非结构化文本，将分销协议和销售评估转化为结构化特征；2）博弈论约束优化机制，通过双边效用函数动态协调供应链利益；3）可解释决策蒸馏接口，利用LLM引导的符号回归优化定价策略和可审计业务规则。

Result: 在真实零售环境中验证框架，相比系统性B2C基线实现了更高的利润，同时确保运营可行性。

Conclusion: 建立了一个闭环管道，统一了非结构化知识注入、多智能体优化和可解释策略合成，为真实经济智能提供了解决方案。

Abstract: This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints.
  Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.

</details>


### [13] [RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design](https://arxiv.org/abs/2512.03762)
*Jiawei Xu,Fengfeng Wei,Weineng Chen*

Main category: cs.AI

TL;DR: RoCo是一个基于多智能体角色协作的系统，通过四个专门化的LLM智能体（探索者、利用者、批评者、整合者）协同设计高质量启发式算法，在组合优化问题的自动启发式设计中取得了优越性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的自动启发式设计研究通常只考虑单一角色，限制了启发式算法的多样性和质量。本文旨在通过多角色协作来增强自动启发式设计的多样性和质量。

Method: 提出RoCo多智能体角色协作系统，包含四个专门化的LLM智能体：探索者（促进长期潜力，创造性思维）、利用者（关注短期改进，效率导向优化）、批评者（评估进化步骤有效性并提供反馈）、整合者（综合探索者和利用者的建议，平衡创新与利用）。这些智能体通过结构化的多轮过程进行交互，包括反馈、精炼和精英突变，同时考虑短期和长期反思。

Result: 在五个不同的组合优化问题上，在自盒和黑盒设置下进行评估。实验结果表明，RoCo实现了优越性能，生成的启发式算法在自盒和黑盒场景下均优于现有方法（包括ReEvo和HSEvo）。

Conclusion: 基于角色的协作范式为稳健且高性能的自动启发式设计建立了新标准，证明了多角色协作在增强启发式算法多样性和质量方面的有效性。

Abstract: Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.

</details>


### [14] [Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning](https://arxiv.org/abs/2512.03783)
*Dongchao Yang,Songxiang Liu,Disong Wang,Yuanyuan Wang,Guanglu Wan,Helen Meng*

Main category: cs.AI

TL;DR: Omni-AutoThink是一个自适应推理框架，能根据任务难度动态调整模型推理深度，通过两阶段训练提升多模态推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有Omni模型在推理行为上存在僵化问题，要么对简单问题过度思考，要么在需要推理时无法有效推理，需要一种能根据任务难度自适应调整推理深度的框架。

Method: 提出两阶段框架：1) 自适应监督微调阶段，使用大规模推理增强数据赋予模型基础推理能力；2) 自适应强化学习阶段，基于任务复杂度和奖励反馈优化推理行为。同时构建了涵盖文本、文本-音频、文本-视觉、文本-音频-视觉多模态的自适应推理基准。

Result: 实验结果表明，该框架相比先前基线显著提升了自适应推理性能，所有基准数据和代码将公开。

Conclusion: Omni-AutoThink通过自适应调整推理深度，有效解决了现有Omni模型推理行为僵化的问题，在多模态推理任务上表现出优越性能。

Abstract: Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existing systems still exhibit rigid reasoning behaviors, either overthinking simple problems or failing to reason when necessary. To address this limitation, we propose Omni-AutoThink, a novel adaptive reasoning framework that dynamically adjusts the model's reasoning depth according to task difficulty. Our framework comprises two stages: (1) an Adaptive Supervised Fine-Tuning (Adaptive SFT) stage, which endows the Omni model with fundamental reasoning capability using large-scale reasoning-augmented data, and (2) an Adaptive Reinforcement Learning (Adaptive GRPO) stage, which optimizes reasoning behaviors based on task complexity and reward feedback. We further construct a comprehensive adaptive reasoning benchmark that spans text-only, text-audio, text-visual, and text-audio-visual modalities, providing both training and evaluation splits for multimodal reasoning assessment. Experimental results demonstrate that our proposed framework significantly improves adaptive reasoning performance compared to previous baselines. All benchmark data and code will be publicly released.

</details>


### [15] [Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol](https://arxiv.org/abs/2512.03955)
*Niklas Jobs,Luis Miguel Vieira da Silva,Jayanth Somashekaraiah,Maximilian Weigand,David Kube,Felix Gehlhoff*

Main category: cs.AI

TL;DR: 提出了一个用于评估LLM智能体在工业自动化规划与执行能力的标准化基准测试框架，包含可执行仿真环境和五个复杂度类别的Blocksworld问题，通过MCP协议实现统一工具接口。


<details>
  <summary>Details</summary>
Motivation: 工业自动化需要灵活的控制策略来适应变化的任务和环境，基于LLM的智能体具有自适应规划与执行的潜力，但缺乏系统比较的标准化基准。

Method: 1) 引入包含可执行仿真环境的基准测试框架，基于Blocksworld问题提供五个复杂度类别；2) 集成模型上下文协议(MCP)作为标准化工具接口，使不同智能体架构无需特定实现修改即可连接和评估；3) 通过单智能体实现展示基准的适用性。

Result: 建立了用于比较基于LLM的规划与执行方法的定量指标，展示了基准测试框架的适用性，为不同智能体架构提供了统一的评估平台。

Conclusion: 该基准测试框架填补了LLM智能体在工业自动化领域缺乏标准化评估工具的空白，通过MCP协议实现了不同架构的公平比较，为自适应规划与执行方法的研究提供了重要基础。

Abstract: Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [16] [Tuning of Vectorization Parameters for Molecular Dynamics Simulations in AutoPas](https://arxiv.org/abs/2512.03565)
*Luis Gall,Samuel James Newcome,Fabio Alexander Gratl,Markus Mühlhäußer,Manish Kumar Mishra,Hans-Joachim Bungartz*

Main category: cs.DC

TL;DR: 本文研究了分子动力学模拟中SIMD向量化的不同技术，重点关注粒子值加载到向量寄存器的顺序优化，以提升粒子间力计算的性能或降低能耗。


<details>
  <summary>Details</summary>
Motivation: 分子动力学模拟能为原子尺度物理过程提供宝贵见解。先前研究表明最优MD算法可能在运行时发生变化，因此需要研究特定模拟参数（如粒子密度）和邻域识别算法的影响，并扩展AutoPas的动态调优机制以在运行时选择最优向量化顺序。

Method: 探索了多种SIMD向量化技术，特别关注粒子值加载到向量寄存器的顺序优化。研究了粒子密度等模拟特定参数和邻域识别算法的影响，扩展了AutoPas的动态调优机制以在运行时选择最优向量化顺序。

Result: 基准测试表明，在运行时考虑不同的粒子相互作用顺序相比AutoPas先前方法，能显著提升力计算的性能。

Conclusion: 通过优化粒子值加载顺序并利用动态调优机制在运行时选择最优向量化策略，可以显著提升分子动力学模拟中力计算的性能，这为高性能计算中的粒子模拟提供了有效的优化方法。

Abstract: Molecular Dynamics simulations can help scientists to gather valuable insights for physical processes on an atomic scale. This work explores various techniques for SIMD vectorization to improve the pairwise force calculation between molecules in the scope of the particle simulation library AutoPas. The focus lies on the order in which particle values are loaded into vector registers to achieve the most optimal performance regarding execution time or energy consumption.
  As previous work indicates that the optimal MD algorithm can change during runtime, this paper investigates simulation-specific parameters like particle density and the impact of the neighbor identification algorithms, which distinguishes this work from related projects. Furthermore, AutoPas' dynamic tuning mechanism is extended to choose the optimal vectorization order during runtime.
  The benchmarks show that considering different particle interaction orders during runtime can lead to a considerable performance improvement for the force calculation compared to AutoPas' previous approach.

</details>


### [17] [On the Challenges of Energy-Efficiency Analysis in HPC Systems: Evaluating Synthetic Benchmarks and Gromacs](https://arxiv.org/abs/2512.03697)
*Rafael Ravedutti Lucio Machado,Jan Eitzinger,Georg Hager,Gerhard Wellein*

Main category: cs.DC

TL;DR: 该论文分析了在Fritz和Alex HPC集群上使用合成基准测试和Gromacs软件包进行能效分析时遇到的挑战，实验使用了Intel Ice Lake和Sapphire Rapids CPU以及Nvidia A40和A100 GPU，并提出了未来能效分析的最佳实践。


<details>
  <summary>Details</summary>
Motivation: 高性能计算集群的能效分析面临诸多挑战，特别是在使用合成基准测试和实际应用软件包（如Gromacs）时，需要系统性地识别和解决实验与分析过程中的困难，为未来的能效研究提供指导。

Method: 在Fritz和Alex HPC集群上进行实验，使用MPI并行化技术，覆盖Intel Ice Lake和Sapphire Rapids CPU以及Nvidia A40和A100 GPU。采用Likwid和Nvidia性能分析工具收集指标数据，系统性地分析能效表现。

Result: 展示了使用Likwid和Nvidia分析工具获得的能效指标和测量结果，揭示了在实验和分析过程中遇到的具体挑战和陷阱，包括硬件配置、软件工具使用、数据收集等方面的实际问题。

Conclusion: 论文总结了高性能计算能效分析中的关键挑战，并提出了未来进行能效分析研究的最佳实践建议，为相关领域的研究人员提供了有价值的参考和指导。

Abstract: This paper discusses the challenges encountered when analyzing the energy efficiency of synthetic benchmarks and the Gromacs package on the Fritz and Alex HPC clusters. Experiments were conducted using MPI parallelism on full sockets of Intel Ice Lake and Sapphire Rapids CPUs, as well as Nvidia A40 and A100 GPUs. The metrics and measurements obtained with the Likwid and Nvidia profiling tools are presented, along with the results. The challenges and pitfalls encountered during experimentation and analysis are revealed and discussed. Best practices for future energy efficiency analysis studies are suggested.

</details>


### [18] [Acceleration of Parallel Tempering for Markov Chain Monte Carlo methods](https://arxiv.org/abs/2512.03825)
*Aingeru Ramos,Jose A Pascual,Javier Navaridas,Ivan Coluzza*

Main category: cs.DC

TL;DR: 该论文提出了Metropolis-Hastings与Parallel Tempering的并行实现，使用OpenMP和CUDA分别在CPU和GPU上进行并行化，显著提升了采样效率。


<details>
  <summary>Details</summary>
Motivation: 传统MCMC方法在处理复杂构型空间时采样精度不足，Parallel Tempering虽然提高了精度但计算成本显著增加。需要通过并行化来抵消这种计算开销，使MCMC/PT技术能更有效地运行并研究更大规模的模型。

Method: 开发了Metropolis-Hastings与Parallel Tempering的并行实现，使用OpenMP进行多核CPU并行化，使用CUDA进行GPU并行化。这两种方法分别针对现代CPU和GPU架构进行优化。

Result: OpenMP版本在48核上实现了最高52倍的加速，CUDA版本实现了986倍的加速。这些结果为未来量子实现相同算法提供了基础基准。

Conclusion: 提出的并行实现显著提升了MCMC/PT算法的计算效率，使得能够更有效地研究复杂系统。同时为未来量子实现提供了性能基准。

Abstract: Markov Chain Monte Carlo methods are algorithms used to sample probability distributions, commonly used to sample the Boltzmann distribution of physical/chemical models (e.g., protein folding, Ising model, etc.). This allows us to study their properties by sampling the most probable states of those systems. However, the sampling capabilities of these methods are not sufficiently accurate when handling complex configuration spaces. This has resulted in the development of new techniques that improve sampling accuracy, usually at the expense of increasing the computational cost. One of such techniques is Parallel Tempering which improves accuracy by running several replicas which periodically exchange their states. Computationally, this imposes a significant slow-down, which can be counteracted by means of parallelization. These schemes enable MCMC/PT techniques to be run more effectively and allow larger models to be studied. In this work, we present a parallel implementation of Metropolis-Hastings with Parallel Tempering, using OpenMP and CUDA for the parallelization in modern CPUs and GPUs, respectively. The results show a maximum speed-up of 52x using OpenMP with 48 cores, and of 986x speed-up with the CUDA version. Furthermore, the results serve as a basic benchmark to compare a future quantum implementation of the same algorithm.

</details>


### [19] [OD-MoE: On-Demand Expert Loading for Cacheless Edge-Distributed MoE Inference](https://arxiv.org/abs/2512.03927)
*Liujianfu Wang,Yuyang Du,Yuchen Pan,Soung Chang Liew,Jiacheng Liu,Kexin Chen*

Main category: cs.DC

TL;DR: OD-MoE是一个分布式MoE推理框架，通过按需加载专家参数，消除了专家缓存需求，使MoE模型能在GPU内存小于1GB的边缘设备上运行。


<details>
  <summary>Details</summary>
Motivation: MoE模型在内存受限的边缘设备上部署面临挑战。现有的专家卸载方法虽然将专家参数存储在CPU内存中，但GPU内存中为专家缓存保留的空间利用率仍然较低，且需要大量GPU内存。

Method: OD-MoE采用两种关键机制：1) 在分布式边缘节点间并行化专家加载和专家计算；2) 使用超准确的模拟预测器，在专家计算进行时提前多层预测专家激活。通过这些创新，OD-MoE能够在专家激活前即时加载目标专家到分布式节点，并在使用后立即驱逐，释放GPU内存。

Result: 实验结果显示：1) OD-MoE实现了99.94%的专家激活预测准确率，显著超越现有方法；2) 在仅使用1/3 GPU内存的情况下，OD-MoE达到了完全GPU缓存MoE部署约75%的解码速度；3) 最重要的是，OD-MoE使MoE推理能够在GPU内存小于1GB的边缘节点上运行。

Conclusion: OD-MoE通过消除专家缓存需求，为低成本的边缘物联网设备在LLM时代实现实用的MoE部署铺平了道路，解决了MoE模型在资源受限边缘设备上的部署难题。

Abstract: Mixture-of-Experts (MoE), while offering significant advantages as a Large Language Model (LLM) architecture, faces substantial challenges when deployed on low-cost edge devices with tight memory constraints. Expert offloading mitigates this issue by storing expert parameters in CPU memory and caching a subset of popular experts in GPU memory. Although this approach improves GPU memory utilization by caching only the likely-used experts, the GPU memory reserved for expert caching is underutilized compared with dense LLMs. This paper presents OD-MoE, a distributed MoE inference framework that obviates the need for expert caches via fully on-demand expert loading. OD-MoE is built upon two key mechanisms: 1) parallelizing expert loading and expert computation across distributed edge nodes, and 2) an ultra-accurate emulative predictor that forecasts expert activations multiple layers ahead while expert computation is ongoing. With these innovations, OD-MoE dynamically loads each target expert to one of the distributed nodes just-in-time before its activation and promptly evicts it afterward, freeing GPU memory for subsequent experts. We comprehensively benchmark OD-MoE against state-of-the-art MoE offloading systems on a ten-node testbed. Experimental results show that: 1) OD-MoE achieves 99.94% expert activation prediction accuracy, substantially surpassing all existing methods; and 2) OD-MoE delivers approximately 75% of the decoding speed of a fully GPU-cached MoE deployment while using only 1/3 of the GPU memory. More importantly, by eliminating the need for expert caches, OD-MoE enables MoE inference on edge nodes with less-than-1GB GPU memory, paving the way for practical MoE deployment of low-cost IoT devices at the edge in the LLM era.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [20] [From Oracle Choice to Oracle Lock-In: An Exploratory Study on Blockchain Oracles Supplier Selection](https://arxiv.org/abs/2512.03088)
*Giulio Caldarelli*

Main category: cs.CR

TL;DR: 研究探索Web3协议选择预言机的驱动因素，发现技术依赖和智能合约不可变性导致锁定效应，且存在可行第三方方案时协议更倾向于外包而非自建预言机机制


<details>
  <summary>Details</summary>
Motivation: 预言机是Web3应用的关键基础设施，但现有学术研究主要关注预言机技术和内部经济机制，而客户端选择预言机的驱动因素尚未得到充分探索。本研究旨在填补这一空白

Method: 通过收集领先Web3协议的见解，了解其选择预言机的理由以及在决定外包或内部化数据请求机制时的偏好。数据覆盖超过55%的DeFi市值，且专门从协议高管、董事会成员或代表处获取

Result: 研究发现协议选择与技术依赖密切相关，智能合约的不可变性加剧了锁定效应，阻碍了在不同数据提供商之间的灵活切换。此外，当存在可行的第三方解决方案时，协议绝大多数倾向于外包而非自建和维护内部预言机机制

Conclusion: Web3协议在选择预言机时面临技术锁定挑战，智能合约的不可变性限制了灵活性，而外包成为主流选择策略。这为预言机提供商和协议设计者提供了重要启示

Abstract: As data is an essential asset for any Web3 application, selecting an oracle is a critical decision for its success. To date, academic research has mainly focused on improving oracle technology and internal economics, while the drivers of oracle choice on the client side remain largely unexplored. This study fills this gap by gathering insights from leading Web3 protocols, uncovering their rationale for oracle selection and their preferences when deciding whether to outsource or internalize data request mechanisms. The collected data covers more than 55% of the DeFi market cap and is obtained exclusively by protocol executives, board members, or delegates. Insights support the view that protocol choices are tied to technological dependencies, where immutability of smart contracts amplifies lock-in, preventing agile switching among data providers. Furthermore, when viable third-party solutions exist, protocols overwhelmingly prefer outsourcing rather than building and maintaining internal oracle mechanisms.

</details>


### [21] [Ensemble Privacy Defense for Knowledge-Intensive LLMs against Membership Inference Attacks](https://arxiv.org/abs/2512.03100)
*Haowei Fu,Bo Ni,Han Xu,Kunpeng Liu,Dan Lin,Tyler Derr*

Main category: cs.CR

TL;DR: 该论文研究了RAG和SFT增强的大语言模型对成员推理攻击的脆弱性，并提出了一种名为EPD的模型无关防御框架来降低隐私风险。


<details>
  <summary>Details</summary>
Motivation: 虽然RAG和SFT能够为LLMs注入外部知识以提升性能，但这也暴露了新的攻击面。成员推理攻击(MIAs)旨在判断特定数据样本是否包含在模型训练集中，对敏感领域的隐私和信任构成严重威胁。

Method: 首先系统评估了基于RAG和SFT的LLMs对各种MIAs的脆弱性。然后提出了一种新颖的模型无关防御框架——集成隐私防御(EPD)，该框架聚合并评估知识注入LLM、基础LLM和专用判断模型的输出，以增强对MIAs的抵抗能力。

Result: 综合实验表明，EPD平均将SFT的MIA成功率降低27.8%，将RAG的MIA成功率降低526.3%（相比推理时基线），同时保持回答质量。

Conclusion: EPD是一种有效的防御框架，能够显著降低RAG和SFT增强LLMs对成员推理攻击的脆弱性，在保护隐私的同时维持模型性能。

Abstract: Retrieval-Augmented Generation (RAG) and Supervised Finetuning (SFT) have become the predominant paradigms for equipping Large Language Models (LLMs) with external knowledge for diverse, knowledge-intensive tasks. However, while such knowledge injection improves performance, it also exposes new attack surfaces. Membership Inference Attacks (MIAs), which aim to determine whether a given data sample was included in a model's training set, pose serious threats to privacy and trust in sensitive domains. To this end, we first systematically evaluate the vulnerability of RAG- and SFT-based LLMs to various MIAs. Then, to address the privacy risk, we further introduce a novel, model-agnostic defense framework, Ensemble Privacy Defense (EPD), which aggregates and evaluates the outputs of a knowledge-injected LLM, a base LLM, and a dedicated judge model to enhance resistance against MIAs. Comprehensive experiments show that, on average, EPD reduces MIA success by up to 27.8\% for SFT and 526.3\% for RAG compared to inference-time baseline, while maintaining answer quality.

</details>


### [22] [Lost in Modality: Evaluating the Effectiveness of Text-Based Membership Inference Attacks on Large Multimodal Models](https://arxiv.org/abs/2512.03121)
*Ziyi Tong,Feifei Sun,Le Minh Nguyen*

Main category: cs.CR

TL;DR: 本文首次全面评估了将基于对数概率的成员推理攻击从纯文本模型扩展到多模态大语言模型的效果，发现在分布内设置中视觉+文本输入略有优势，而在分布外设置中视觉输入会掩盖成员信号。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型成为基础工具，理解其训练数据泄露问题变得日益重要。虽然基于对数概率的成员推理攻击在纯文本模型中已被广泛采用，但其在多模态模型中的效果尚不清楚。

Method: 将基于对数概率的文本成员推理攻击方法扩展到多模态设置，在DeepSeek-VL和InternVL模型家族上进行实验，对比视觉+文本和纯文本两种输入条件下的攻击效果。

Result: 在分布内设置中，基于logit的成员推理攻击在不同配置下表现相当，视觉+文本输入略有优势；在分布外设置中，视觉输入起到了正则化作用，有效地掩盖了成员信号。

Conclusion: 视觉输入在多模态大语言模型的成员推理攻击中具有双重作用：在分布内设置中能略微增强攻击效果，而在分布外设置中则能有效保护模型隐私，这为理解多模态模型的隐私特性提供了重要见解。

Abstract: Large Multimodal Language Models (MLLMs) are emerging as one of the foundational tools in an expanding range of applications. Consequently, understanding training-data leakage in these systems is increasingly critical. Log-probability-based membership inference attacks (MIAs) have become a widely adopted approach for assessing data exposure in large language models (LLMs), yet their effect in MLLMs remains unclear. We present the first comprehensive evaluation of extending these text-based MIA methods to multimodal settings. Our experiments under vision-and-text (V+T) and text-only (T-only) conditions across the DeepSeek-VL and InternVL model families show that in in-distribution settings, logit-based MIAs perform comparably across configurations, with a slight V+T advantage. Conversely, in out-of-distribution settings, visual inputs act as regularizers, effectively masking membership signals.

</details>


### [23] [Immunity memory-based jailbreak detection: multi-agent adaptive guard for large language models](https://arxiv.org/abs/2512.03356)
*Jun Leng,Litian Zhang,Xi Zhang*

Main category: cs.CR

TL;DR: MAAG框架通过模拟免疫记忆机制，为LLM安全防护提供动态自适应检测能力，显著提升对越狱攻击的识别效果


<details>
  <summary>Details</summary>
Motivation: 现有LLM越狱攻击检测方法通常基于固定训练数据集微调模型，计算成本高且难以应对新型攻击。受免疫记忆机制启发，需要开发能够动态适应新威胁的检测框架。

Method: 提出多智能体自适应防护（MAAG）框架：1）从输入提示中提取激活值并与记忆库中的历史激活值比较进行初步检测；2）防御智能体基于检测结果模拟响应；3）辅助智能体监督模拟过程，对检测结果进行二次过滤。

Result: 在五个开源模型上的实验表明，MAAG显著优于现有SOTA方法，在多样化攻击场景下达到98%的检测准确率和96%的F1分数。

Conclusion: MAAG框架通过引入记忆能力和多智能体协作机制，为LLM安全防护提供了高效、自适应的越狱攻击检测方案，能够有效应对新型威胁。

Abstract: Large language models (LLMs) have become foundational in AI systems, yet they remain vulnerable to adversarial jailbreak attacks. These attacks involve carefully crafted prompts that bypass safety guardrails and induce models to produce harmful content. Detecting such malicious input queries is therefore critical for maintaining LLM safety. Existing methods for jailbreak detection typically involve fine-tuning LLMs as static safety LLMs using fixed training datasets. However, these methods incur substantial computational costs when updating model parameters to improve robustness, especially in the face of novel jailbreak attacks. Inspired by immunological memory mechanisms, we propose the Multi-Agent Adaptive Guard (MAAG) framework for jailbreak detection. The core idea is to equip guard with memory capabilities: upon encountering novel jailbreak attacks, the system memorizes attack patterns, enabling it to rapidly and accurately identify similar threats in future encounters. Specifically, MAAG first extracts activation values from input prompts and compares them to historical activations stored in a memory bank for quick preliminary detection. A defense agent then simulates responses based on these detection results, and an auxiliary agent supervises the simulation process to provide secondary filtering of the detection outcomes. Extensive experiments across five open-source models demonstrate that MAAG significantly outperforms state-of-the-art (SOTA) methods, achieving 98% detection accuracy and a 96% F1-score across a diverse range of attack scenarios.

</details>


### [24] [Scaling Trust in Quantum Federated Learning: A Multi-Protocol Privacy Design](https://arxiv.org/abs/2512.03358)
*Dev Gurung,Shiva Raj Pokhrel*

Main category: cs.CR

TL;DR: 提出一种结合奇异值分解、量子密钥分发和解析量子梯度下降的多层隐私保护量子联邦学习框架，在保护数据和模型隐私的同时保持训练效率。


<details>
  <summary>Details</summary>
Motivation: 量子联邦学习结合量子计算和分布式机器学习具有巨大潜力，但数据和模型的隐私保护仍然是关键挑战。现有方法在隐私保护方面存在不足，需要设计能够同时保护数据和模型隐私的量子联邦学习框架。

Method: 提出多层隐私保护QFL框架：1）使用奇异值分解（SVD）保护数据准备阶段；2）采用量子密钥分发（QKD）保护模型共享阶段；3）应用解析量子梯度下降（AQGD）保护训练阶段。框架包含n个量子设备训练本地模型并传输到中央服务器。

Result: 通过理论分析和在当代量子平台及数据集上的实验验证，该框架能够鲁棒地保护数据和模型的机密性，同时保持训练效率。

Conclusion: 该工作提出的隐私保护量子联邦学习框架成功解决了量子联邦学习中的隐私挑战，为安全高效的分布式量子机器学习提供了可行方案。

Abstract: Quantum Federated Learning (QFL) promises to revolutionize distributed machine learning by combining the computational power of quantum devices with collaborative model training. Yet, privacy of both data and models remains a critical challenge. In this work, we propose a privacy-preserving QFL framework where a network of $n$ quantum devices trains local models and transmits them to a central server under a multi-layered privacy protocol. Our design leverages Singular Value Decomposition (SVD), Quantum Key Distribution (QKD), and Analytic Quantum Gradient Descent (AQGD) to secure data preparation, model sharing, and training stages. Through theoretical analysis and experiments on contemporary quantum platforms and datasets, we demonstrate that the framework robustly safeguards data and model confidentiality while maintaining training efficiency.

</details>


### [25] [Tuning for TraceTarnish: Techniques, Trends, and Testing Tangible Traits](https://arxiv.org/abs/2512.03465)
*Robert Dilworth*

Main category: cs.CR

TL;DR: TraceTarnish是一种利用对抗性文体测量学原理匿名化文本消息作者身份的攻击脚本，通过分析Reddit评论数据，识别出函数词频率、内容词分布和类型-标记比等五个关键文体特征作为攻击指标和检测信号。


<details>
  <summary>Details</summary>
Motivation: 研究旨在更严格地评估TraceTarnish攻击脚本，该脚本利用对抗性文体测量学原理来匿名化文本消息的作者身份，同时探索如何检测这种攻击。

Method: 收集并处理Reddit评论数据，使用TraceTarnish进行匿名化处理，然后通过StyloMetrix生成文体特征，使用信息增益准则筛选出最具信息性、预测性和区分性的特征。

Result: 识别出五个关键文体特征：函数词及其类型(L_FUNC_A & L_FUNC_T)、内容词及其类型(L_CONT_A & L_CONT_T)、以及类型-标记比(ST_TYPE_TOKEN_RATIO_LEMMAS)。这些特征既可作为攻击的可靠指标，也可作为检测对抗性文体测量攻击的取证信标。

Conclusion: 试图抹去痕迹的行为往往会留下更大的印记。基于这五个关键特征，研究人员改进了TraceTarnish攻击，使其更加强大，同时也为检测此类攻击提供了方法，尽管在没有原始消息的情况下检测可能较为困难。

Abstract: In this study, we more rigorously evaluated our attack script $\textit{TraceTarnish}$, which leverages adversarial stylometry principles to anonymize the authorship of text-based messages. To ensure the efficacy and utility of our attack, we sourced, processed, and analyzed Reddit comments--comments that were later alchemized into $\textit{TraceTarnish}$ data--to gain valuable insights. The transformed $\textit{TraceTarnish}$ data was then further augmented by $\textit{StyloMetrix}$ to manufacture stylometric features--features that were culled using the Information Gain criterion, leaving only the most informative, predictive, and discriminative ones. Our results found that function words and function word types ($L\_FUNC\_A$ $\&$ $L\_FUNC\_T$); content words and content word types ($L\_CONT\_A$ $\&$ $L\_CONT\_T$); and the Type-Token Ratio ($ST\_TYPE\_TOKEN\_RATIO\_LEMMAS$) yielded significant Information-Gain readings. The identified stylometric cues--function-word frequencies, content-word distributions, and the Type-Token Ratio--serve as reliable indicators of compromise (IoCs), revealing when a text has been deliberately altered to mask its true author. Similarly, these features could function as forensic beacons, alerting defenders to the presence of an adversarial stylometry attack; granted, in the absence of the original message, this signal may go largely unnoticed, as it appears to depend on a pre- and post-transformation comparison. "In trying to erase a trace, you often imprint a larger one." Armed with this understanding, we framed $\textit{TraceTarnish}$'s operations and outputs around these five isolated features, using them to conceptualize and implement enhancements that further strengthen the attack.

</details>


### [26] [A User Centric Group Authentication Scheme for Secure Communication](https://arxiv.org/abs/2512.03551)
*Oylum Gerenli,Gunes Karabulut-Kurt,Enver Ozdemir*

Main category: cs.CR

TL;DR: 本文提出了一种改进的第三代群认证方案，使用内积空间和多项式插值来解决用户匿名性带来的识别问题，同时防止合法成员恶意共享凭证。


<details>
  <summary>Details</summary>
Motivation: 第三代群认证方案虽然提供了用户匿名性，但在需要识别参与用户的特定应用中存在局限性。此外，现有方案允许成员共享群凭证，这会危及群组机密性。本研究旨在解决这两个问题。

Method: 提出改进的第三代群认证方案，结合内积空间和多项式插值技术。新方案消除了用户分发凭证的能力，从而防止合法成员的恶意行为。

Result: 提出的方案解决了第三代群认证在需要用户识别应用中的局限性，同时通过消除用户分发凭证的能力增强了安全性，防止群组机密性被破坏。

Conclusion: 改进的第三代群认证方案成功解决了用户匿名性带来的识别问题，并增强了安全性，但存在依赖中央权威进行认证的潜在局限性。

Abstract: Group Authentication Schemes (GAS) are methodologies developed to verify the membership of multiple users simultaneously. These schemes enable the concurrent authentication of several users while eliminating the need for a certification authority. Numerous GAS methods have been explored in the literature, and they can be classified into three distinct generations based on their foundational mathematical principles. First-generation GASs rely on polynomial interpolation and the multiplicative subgroup of a finite field. Second-generation GASs also employ polynomial interpolation, but they distinguish themselves by incorporating elliptic curves over finite fields. While third-generation GASs present a promising solution for scalable environments, they demonstrate a limitation in certain applications. Such applications typically require the identification of users participating in the authentication process. In the third-generation GAS, users are able to verify their credentials while maintaining anonymity. However, there are various applications where the identification of participating users is necessary. In this study, we propose an improved version of third-generation GAS, utilizing inner product spaces and polynomial interpolation to resolve this limitation. We address the issue of preventing malicious actions by legitimate group members. The current third-generation scheme allows members to share group credentials, which can jeopardize group confidentiality. Our proposed scheme mitigates this risk by eliminating the ability of individual users to distribute credentials. However, a potential limitation of our scheme is its reliance on a central authority for authentication in certain scenarios.

</details>


### [27] [Towards Privacy-Preserving Range Queries with Secure Learned Spatial Index over Encrypted Data](https://arxiv.org/abs/2512.03669)
*Zuan Wang,Juntao Lu,Jiazhuang Wu,Youliang Tian,Wei Song,Qiuxian Li,Duo Zhang*

Main category: cs.CR

TL;DR: 本文提出了一种新型的隐私保护范围查询方案SLRQ，结合安全学习空间索引SLS-INDEX，在加密数据集上实现高效且安全的范围查询，显著优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 随着云服务在大规模数据管理中的广泛应用，保护外包数据集的安全和隐私变得至关重要。虽然加密数据和查询可以防止直接内容暴露，但攻击者仍可通过访问模式和搜索路径分析推断敏感信息。现有提供强访问模式隐私的解决方案通常带来显著的性能开销。

Method: 提出SLS-INDEX安全学习索引，将Paillier密码系统与分层预测架构和噪声注入桶相结合，实现加密域中的数据感知查询加速。SLRQ采用基于置换的安全桶预测协议混淆查询执行路径，并引入安全点提取协议生成候选结果以减少安全计算开销。

Result: 在真实世界和合成数据集上的广泛实验表明，SLRQ在查询效率方面显著优于现有解决方案，同时确保数据集、查询、结果和访问模式的隐私。提供了在现实泄漏函数下的形式化安全分析。

Conclusion: 本文提出的SLRQ方案在加密数据集上实现了高效且安全的范围查询，通过创新的安全学习索引和协议设计，在保证强安全性的同时大幅提升了查询性能，为云环境下的隐私保护数据管理提供了有效解决方案。

Abstract: With the growing reliance on cloud services for large-scale data management, preserving the security and privacy of outsourced datasets has become increasingly critical. While encrypting data and queries can prevent direct content exposure, recent research reveals that adversaries can still infer sensitive information via access pattern and search path analysis. However, existing solutions that offer strong access pattern privacy often incur substantial performance overhead. In this paper, we propose a novel privacy-preserving range query scheme over encrypted datasets, offering strong security guarantees while maintaining high efficiency. To achieve this, we develop secure learned spatial index (SLS-INDEX), a secure learned index that integrates the Paillier cryptosystem with a hierarchical prediction architecture and noise-injected buckets, enabling data-aware query acceleration in the encrypted domain. To further obfuscate query execution paths, SLS-INDEXbased Range Queries (SLRQ) employs a permutation-based secure bucket prediction protocol. Additionally, we introduce a secure point extraction protocol that generates candidate results to reduce the overhead of secure computation. We provide formal security analysis under realistic leakage functions and implement a prototype to evaluate its practical performance. Extensive experiments on both real-world and synthetic datasets demonstrate that SLRQ significantly outperforms existing solutions in query efficiency while ensuring dataset, query, result, and access pattern privacy.

</details>


### [28] [Context-Aware Hierarchical Learning: A Two-Step Paradigm towards Safer LLMs](https://arxiv.org/abs/2512.03720)
*Tengyun Ma,Jiaqi Yao,Daojing He,Shihao Peng,Yu Li,Shaohui Liu,Zhuotao Tian*

Main category: cs.CR

TL;DR: 该论文提出了一种新的LLM安全漏洞——工具完成攻击(TCA)，并开发了CAHL防御机制来增强模型对这类攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在处理指令时存在安全漏洞，特别是其统一的token处理范式在面对对抗性场景时容易受到攻击。作者发现函数调用机制可能被利用来颠覆模型行为，因此需要评估和改进LLM的安全性。

Method: 首先提出了工具完成攻击(TCA)这一新型漏洞类别，然后开发了Tool-Completion基准测试框架来评估LLM的鲁棒性。为防御此类攻击，提出了上下文感知分层学习(CAHL)机制，该机制通过动态平衡语义理解和角色特定指令约束，利用不同指令段之间的上下文相关性建立鲁棒的上下文感知指令层次结构。

Result: 实验表明，即使是当前最先进的模型也容易受到TCA攻击，攻击成功率惊人地高。CAHL显著增强了LLM对传统攻击和TCA的鲁棒性，在零样本评估中表现出强大的泛化能力，同时仍能保持模型在通用任务上的性能。

Conclusion: 该研究揭示了LLM在指令处理中的安全漏洞，提出了有效的评估框架和防御机制。CAHL通过上下文感知的分层学习方法成功提升了模型的安全性，为LLM的安全部署提供了重要参考。

Abstract: Large Language Models (LLMs) have emerged as powerful tools for diverse applications. However, their uniform token processing paradigm introduces critical vulnerabilities in instruction handling, particularly when exposed to adversarial scenarios. In this work, we identify and propose a novel class of vulnerabilities, termed Tool-Completion Attack (TCA), which exploits function-calling mechanisms to subvert model behavior. To evaluate LLM robustness against such threats, we introduce the Tool-Completion benchmark, a comprehensive security assessment framework, which reveals that even state-of-the-art models remain susceptible to TCA, with surprisingly high attack success rates. To address these vulnerabilities, we introduce Context-Aware Hierarchical Learning (CAHL), a sophisticated mechanism that dynamically balances semantic comprehension with role-specific instruction constraints. CAHL leverages the contextual correlations between different instruction segments to establish a robust, context-aware instruction hierarchy. Extensive experiments demonstrate that CAHL significantly enhances LLM robustness against both conventional attacks and the proposed TCA, exhibiting strong generalization capabilities in zero-shot evaluations while still preserving model performance on generic tasks. Our code is available at https://github.com/S2AILab/CAHL.

</details>


### [29] [The Treasury Proof Ledger: A Cryptographic Framework for Accountable Bitcoin Treasuries](https://arxiv.org/abs/2512.03765)
*Jose E. Puente,Carlos Puente*

Main category: cs.CR

TL;DR: TPL是一个比特币锚定的多域资金库日志框架，通过状态机模型记录储备证明、资金转移证明和政策元数据，支持基于权限的受限视图，旨在帮助上市公司和机构投资者在不暴露内部钱包结构或交易策略的情况下证明偿付能力。


<details>
  <summary>Details</summary>
Motivation: 上市公司和机构投资者持有比特币面临日益增长的压力，需要在证明偿付能力、管理风险和满足监管期望的同时，不暴露内部钱包结构或交易策略。现有解决方案缺乏系统化的多域资金库透明化框架。

Method: 提出Treasury Proof Ledger（TPL）框架，将链上和链下风险敞口视为具有明确费用池的守恒状态机。TPL记录储备证明快照、域间转移证明收据和政策元数据，支持基于利益相关者权限的受限视图。结合标准储备证明和转移证明技术，通过基于哈希的承诺锚定在比特币上实现。

Result: 定义了理想化的TPL模型，将比特币资金库表示为多域风险敞口向量，提出了部署级安全概念（敞口健全性、政策完整性、非抵赖性、隐私兼容政策视图）。结果表明在设定经济和治理假设后，这些保证是可实现的，但未声称现有系统已提供这些保证。

Conclusion: TPL框架展示了如何通过比特币锚定的承诺机制实现负责任透明度政策，支持未来跨机构检查，与比特币固定货币供应量保持一致。企业资金库示例说明了该框架如何支持透明化需求。

Abstract: Public companies and institutional investors that hold Bitcoin face increasing pressure to show solvency, manage risk, and satisfy regulatory expectations without exposing internal wallet structures or trading strategies. This paper introduces the Treasury Proof Ledger (TPL), a Bitcoin-anchored logging framework for multi-domain Bitcoin treasuries that treats on-chain and off-chain exposures as a conserved state machine with an explicit fee sink. A TPL instance records proof-of-reserves snapshots, proof-of-transit receipts for movements between domains, and policy metadata, and it supports restricted views based on stakeholder permissions. We define an idealised TPL model, represent Bitcoin treasuries as multi-domain exposure vectors, and give deployment-level security notions including exposure soundness, policy completeness, non-equivocation, and privacy-compatible policy views. We then outline how practical, restricted forms of these guarantees can be achieved by combining standard proof-of-reserves and proof-of-transit techniques with hash-based commitments anchored on Bitcoin. The results are existence-type statements: they show which guarantees are achievable once economic and governance assumptions are set, without claiming that any current system already provides them. A stylised corporate-treasury example illustrates how TPL could support responsible transparency policies and future cross-institution checks consistent with Bitcoin's fixed monetary supply.

</details>


### [30] ["MCP Does Not Stand for Misuse Cryptography Protocol": Uncovering Cryptographic Misuse in Model Context Protocol at Scale](https://arxiv.org/abs/2512.03775)
*Biwei Yan,Yue Zhang,Minghui Xu,Hao Wu,Yechao Zhang,Kun Li,Guoming Zhang,Xiuzhen Cheng*

Main category: cs.CR

TL;DR: MICRYSCOPE是首个检测MCP（模型上下文协议）实现中密码学误用的领域特定框架，在9403个MCP服务器中发现19.7%存在密码学误用问题。


<details>
  <summary>Details</summary>
Motivation: MCP作为LLM应用中间件缺乏内置安全机制，开发者需要自行实现密码学功能，这种临时实践容易导致误用，威胁敏感数据和服务安全。

Method: MICRYSCOPE结合三个关键创新：跨语言中间表示标准化密码学API、混合依赖分析揭示显隐函数关系（包括LLM编排的不安全运行时组合）、基于污点的误用检测器追踪敏感数据流并标记违反密码学规则的情况。

Result: 分析9403个MCP服务器，发现720个包含密码学逻辑，其中19.7%存在误用。问题集中在特定市场（如Smithery Registry有42%不安全服务器）、语言（Python误用率34%）和类别（开发者工具与数据科学&ML占所有误用50%以上）。案例研究揭示了API密钥泄露、不安全的DES/ECB工具和基于MD5的身份验证绕过等实际后果。

Conclusion: 该研究首次建立了MCP中密码学误用的生态系统全景视图，为加强这一快速增长协议的安全基础提供了工具和见解。

Abstract: The Model Context Protocol (MCP) is rapidly emerging as the middleware for LLM-based applications, offering a standardized interface for tool integration. However, its built-in security mechanisms are minimal: while schemas and declarations prevent malformed requests, MCP provides no guarantees of authenticity or confidentiality, forcing developers to implement cryptography themselves. Such ad hoc practices are historically prone to misuse, and within MCP they threaten sensitive data and services. We present MICRYSCOPE, the first domain-specific framework for detecting cryptographic misuses in MCP implementations. MICRYSCOPE combines three key innovations: a cross-language intermediate representation that normalizes cryptographic APIs across diverse ecosystems, a hybrid dependency analysis that uncovers explicit and implicit function relationships (including insecure runtime compositions orchestrated by LLMs) and a taint-based misuse detector that tracks sensitive data flows and flags violations of established cryptographic rules. Applying MICRYSCOPE to 9,403 MCP servers, we identified 720 with cryptographic logic, of which 19.7% exhibited misuses. These flaws are concentrated in certain markets (e.g., Smithery Registry with 42% insecure servers), languages (Python at 34% misuse rate), and categories (Developer Tools and Data Science & ML accounting for over 50% of all misuses). Case studies reveal real-world consequences, including leaked API keys, insecure DES/ECB tools, and MD5-based authentication bypasses. Our study establishes the first ecosystem-wide view of cryptographic misuse in MCP and provides both tools and insights to strengthen the security foundations of this rapidly growing protocol.

</details>

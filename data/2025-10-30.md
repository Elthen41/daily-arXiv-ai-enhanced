<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 18]
- [cs.CR](#cs.CR) [Total: 10]
- [cs.DC](#cs.DC) [Total: 4]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Scheduling Your LLM Reinforcement Learning with Reasoning Trees](https://arxiv.org/abs/2510.24832)
*Hong Wang,Zhezheng Hao,Jian Luo,Chenxing Wei,Yao Shu,Lei Liu,Qiang Lin,Hande Dong,Jiawei Chen*

Main category: cs.AI

TL;DR: 提出了一种基于推理树结构的新指标r-score来衡量查询的学习难度，并开发了Re-Schedule调度算法，在六个数学推理基准测试中平均准确率提升高达3.2%。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR数据调度方法通常依赖基于路径的指标来排名查询，忽略了这些查询的推理树结构。

Method: 引入推理得分(r-score)指标，基于推理树结构衡量查询的学习难度，并提出推理树调度(Re-Schedule)算法，构建从结构简单到复杂的课程。

Result: 在六个数学推理基准测试中，Re-Schedule显著提高了平均准确率，增益高达3.2%。

Conclusion: 对推理树的结构理解为RLVR数据调度提供了更强大和原则性的基础。

Abstract: Using Reinforcement Learning with Verifiable Rewards (RLVR) to optimize Large
Language Models (LLMs) can be conceptualized as progressively editing a query's
`Reasoning Tree'. This process involves exploring nodes (tokens) and
dynamically modifying the model's policy at each node. When combined with data
scheduling, this process yields further gains in data efficiency and accuracy.
However, existing RLVR data scheduling methods typically rely on path-based
metrics to rank queries, overlooking the reasoning tree structures of these
queries. In this paper, we introduce a novel metric, namely Reasoning Score
(r-score), which measures the query's learning difficulty based on the
structure of its reasoning tree. Based on the r-score, we propose the Reasoning
Tree Schedule (Re-Schedule), a scheduling algorithm that constructs a
curriculum progressing from structurally simple (high r-score) to complex (low
r-score) queries. Experiments on six math-reasoning benchmarks show that
Re-Schedule significantly improves average accuracy, achieving gains of up to
3.2%. These strong results validate our approach and demonstrate that a
structural understanding of the reasoning tree provides a more powerful and
principled foundation for RLVR data scheduling.

</details>


### [2] [Cyclic Counterfactuals under Shift-Scale Interventions](https://arxiv.org/abs/2510.25005)
*Saptarshi Saha,Dhruv Vansraj Rathore,Utpal Garain*

Main category: cs.AI

TL;DR: 研究循环结构因果模型中的反事实推理，针对包含反馈环的真实系统，关注移位-尺度干预下的反事实推断


<details>
  <summary>Details</summary>
Motivation: 传统反事实推理框架假设无环结构因果模型，但许多真实系统（如生物系统）包含反馈环或循环依赖，违反无环性假设

Method: 研究循环SCMs中的反事实推理，特别关注移位-尺度干预（软性、策略式变化，重新缩放和/或移动变量机制）

Result: 未在摘要中明确说明具体结果

Conclusion: 需要扩展反事实推理框架以处理包含循环依赖的真实系统

Abstract: Most counterfactual inference frameworks traditionally assume acyclic
structural causal models (SCMs), i.e. directed acyclic graphs (DAGs). However,
many real-world systems (e.g. biological systems) contain feedback loops or
cyclic dependencies that violate acyclicity. In this work, we study
counterfactual inference in cyclic SCMs under shift-scale interventions, i.e.,
soft, policy-style changes that rescale and/or shift a variable's mechanism.

</details>


### [3] [Taming the Real-world Complexities in CPT E/M Coding with Large Language Models](https://arxiv.org/abs/2510.25007)
*Islam Nassar,Yang Lin,Yuan Jin,Rongxin Zhu,Chang Wei Tan,Zenan Zhai,Nitika Mathur,Thanh Tien Vu,Xu Zhong,Long Duong,Yuan-Fang Li*

Main category: cs.AI

TL;DR: 本文提出了ProFees框架，使用LLM自动化医疗评估与管理(E/M)编码任务，在真实数据集上比商业系统提高36%以上准确率。


<details>
  <summary>Details</summary>
Motivation: E/M编码是医生的重要辅助任务，增加了文档负担。自动化此任务可以减轻医生负担、提高计费效率并改善患者护理。

Method: 提出了基于LLM的ProFees框架，专门解决E/M编码中的现实复杂性，使用多提示策略提高编码准确性。

Result: 在专家策划的真实数据集上，ProFees比商业CPT E/M编码系统提高36%以上准确率，比最强的单提示基线提高近5%。

Conclusion: ProFees框架有效解决了E/M编码自动化中的现实复杂性，显著提高了编码准确性。

Abstract: Evaluation and Management (E/M) coding, under the Current Procedural
Terminology (CPT) taxonomy, documents medical services provided to patients by
physicians. Used primarily for billing purposes, it is in physicians' best
interest to provide accurate CPT E/M codes. %While important, it is an
auxiliary task that adds to physicians' documentation burden. Automating this
coding task will help alleviate physicians' documentation burden, improve
billing efficiency, and ultimately enable better patient care. However, a
number of real-world complexities have made E/M encoding automation a
challenging task. In this paper, we elaborate some of the key complexities and
present ProFees, our LLM-based framework that tackles them, followed by a
systematic evaluation. On an expert-curated real-world dataset, ProFees
achieves an increase in coding accuracy of more than 36\% over a commercial CPT
E/M coding system and almost 5\% over our strongest single-prompt baseline,
demonstrating its effectiveness in addressing the real-world complexities.

</details>


### [4] [Aligning Large Language Models with Procedural Rules: An Autoregressive State-Tracking Prompting for In-Game Trading](https://arxiv.org/abs/2510.25014)
*Minkyung Kim,Junsik Kim,Woongcheol Yang,Sangdon Park,Sohee Bae*

Main category: cs.AI

TL;DR: 本文提出ASTP方法，通过显式状态跟踪提示让LLM在游戏交易系统中遵循规则流程，结合状态特定的占位符后处理确保计算精度，在300个交易对话中实现>99%状态合规性和99.3%计算精度。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在规则治理的交易系统中无法遵循必要程序流程（浏览-报价-审核-确认）的问题，平衡LLM的创意灵活性与游戏交易的程序需求。

Method: 引入自回归状态跟踪提示（ASTP），通过策略性编排的提示强制LLM使其状态跟踪过程显式化和可验证，结合状态特定的占位符后处理方法进行准确价格计算。

Result: 在300个交易对话评估中，ASTP实现>99%的状态合规性和99.3%的计算精度。使用较小模型（Gemini-2.5-Flash）配合占位符后处理，性能与较大模型（Gemini-2.5-Pro）相当，同时将响应时间从21.2秒减少到2.4秒。

Conclusion: ASTP为商业游戏建立了实用基础，既满足实时需求又符合资源约束，在保持LLM创意灵活性的同时确保交易系统程序完整性。

Abstract: Large Language Models (LLMs) enable dynamic game interactions but fail to
follow essential procedural flows in rule-governed trading systems, eroding
player trust. This work resolves the core tension between the creative
flexibility of LLMs and the procedural demands of in-game trading
(browse-offer-review-confirm). To this end, Autoregressive State-Tracking
Prompting (ASTP) is introduced, a methodology centered on a strategically
orchestrated prompt that compels an LLM to make its state-tracking process
explicit and verifiable. Instead of relying on implicit contextual
understanding, ASTP tasks the LLM with identifying and reporting a predefined
state label from the previous turn. To ensure transactional integrity, this is
complemented by a state-specific placeholder post-processing method for
accurate price calculations. Evaluation across 300 trading dialogues
demonstrates >99% state compliance and 99.3% calculation precision. Notably,
ASTP with placeholder post-processing on smaller models (Gemini-2.5-Flash)
matches larger models' (Gemini-2.5-Pro) performance while reducing response
time from 21.2s to 2.4s, establishing a practical foundation that satisfies
both real-time requirements and resource constraints of commercial games.

</details>


### [5] [Reasoning-Aware GRPO using Process Mining](https://arxiv.org/abs/2510.25065)
*Taekhyun Park,Yongjae Lee,Hyerim Bae*

Main category: cs.AI

TL;DR: PM4GRPO是一种基于过程挖掘的推理感知组相对策略优化方法，通过在标准答案/格式奖励基础上增加推理过程信号，显著提升大推理模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的后训练奖励方案通常是结果导向的，缺乏对推理过程的关注，因此需要开发能够评估推理过程质量的奖励机制。

Method: 利用过程挖掘技术计算标量一致性奖励，衡量策略模型的推理过程与预训练教师模型的匹配程度，并将其集成到组相对策略优化框架中。

Result: 在五个基准测试上的实证结果表明，PM4GRPO显著优于现有的基于GRPO的后训练方法。

Conclusion: 利用过程挖掘进行推理感知的GRPO能够有效增强策略模型的推理能力。

Abstract: Reinforcement learning (RL)-based post-training has been crucial for enabling
multi-step reasoning in large reasoning models (LRMs), yet current reward
schemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware
Group Relative Policy Optimization (GRPO) that augments standard answer/format
rewards with signals over the reasoning procedure. To this end, process mining
techniques are utilized to compute a scalar conformance reward that measures
how closely a policy model's reasoning aligns with the pretrained teacher
model. The empirical results on five benchmarks demonstrate that PM4GRPO
significantly outperforms existing methodologies for GRPO-based post-training.
These results highlight that leveraging process mining for reasoning-aware GRPO
effectively enhances the reasoning capabilities of policy models.

</details>


### [6] [Energy-Efficient Autonomous Driving with Adaptive Perception and Robust Decision](https://arxiv.org/abs/2510.25205)
*Yuyang Xia,Zibo Liang,Liwei Deng,Yan Zhao,Han Su,Kai Zheng*

Main category: cs.AI

TL;DR: EneAD是一个节能的自动驾驶框架，通过自适应感知模块和鲁棒决策模块，在保持感知精度的同时显著降低计算能耗，提升电动汽车续航里程。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶技术虽然带来诸多益处，但其计算引擎的高能耗限制了电动汽车的续航里程。感知计算作为最耗能的组件，现有模型压缩技术往往导致模型尺寸过大或感知精度显著下降。

Method: 提出EneAD框架：1）自适应感知模块：管理多个不同计算消耗的感知模型，动态调整执行帧率，基于贝叶斯优化的可迁移调优方法寻找最佳参数组合；2）鲁棒决策模块：基于强化学习的决策模型，设计正则化项增强面对扰动感知结果时的驾驶稳定性。

Result: 实验证明EneAD在能耗和驾驶性能方面具有优越性，可将感知消耗降低1.9倍至3.5倍，从而将驾驶里程提升3.9%至8.5%。

Conclusion: EneAD框架有效解决了自动驾驶中感知计算的高能耗问题，在保持感知精度的同时显著降低了计算消耗，提升了电动汽车的续航能力。

Abstract: Autonomous driving is an emerging technology that is expected to bring
significant social, economic, and environmental benefits. However, these
benefits come with rising energy consumption by computation engines, limiting
the driving range of vehicles, especially electric ones. Perception computing
is typically the most power-intensive component, as it relies on largescale
deep learning models to extract environmental features. Recently, numerous
studies have employed model compression techniques, such as sparsification,
quantization, and distillation, to reduce computational consumption. However,
these methods often result in either a substantial model size or a significant
drop in perception accuracy compared to high-computation models. To address
these challenges, we propose an energy-efficient autonomous driving framework,
called EneAD. In the adaptive perception module, a perception optimization
strategy is designed from the perspective of data management and tuning.
Firstly, we manage multiple perception models with different computational
consumption and adjust the execution framerate dynamically. Then, we define
them as knobs and design a transferable tuning method based on Bayesian
optimization to identify promising knob values that achieve low computation
while maintaining desired accuracy. To adaptively switch the knob values in
various traffic scenarios, a lightweight classification model is proposed to
distinguish the perception difficulty in different scenarios. In the robust
decision module, we propose a decision model based on reinforcement learning
and design a regularization term to enhance driving stability in the face of
perturbed perception results. Extensive experiments evidence the superiority of
our framework in both energy consumption and driving performance. EneAD can
reduce perception consumption by 1.9x to 3.5x and thus improve driving range by
3.9% to 8.5%

</details>


### [7] [RAVR: Reference-Answer-guided Variational Reasoning for Large Language Models](https://arxiv.org/abs/2510.25206)
*Tianqianjin Lin,Xi Zhao,Xingyao Zhang,Rujiao Long,Yi Xu,Zhuoren Jiang,Wenbo Su,Bo Zheng*

Main category: cs.AI

TL;DR: 本文提出RAVR框架，利用答案引导的变分推理来提升大语言模型的推理能力，通过答案条件化推理作为问题推理的变分替代，解决了在模型能力之外的任务中难以采样高质量推理路径的问题。


<details>
  <summary>Details</summary>
Motivation: 受到认知科学启发：解释'为什么这是答案'比回答'答案是什么'更容易，因为前者避免了开放式探索的认知负担，而是系统性地重建连接问题和答案的推理过程。

Method: 引入RAVR（参考答案引导的变分推理）框架，使用答案条件化推理作为问题推理的变分替代，证明条件化于答案能提高采样推理路径的期望效用。

Result: 在通用和数学领域的实验中，RAVR相比强基线模型取得了持续改进，分析显示RAVR减少了犹豫、加强了结论巩固并促进了问题特定的推理策略。

Conclusion: 答案引导的推理能够将难以处理的问题转化为可学习的问题，为提升大语言模型的推理能力提供了有效方法。

Abstract: Reinforcement learning (RL) can refine the reasoning abilities of large
language models (LLMs), but critically depends on a key prerequisite: the LLM
can already generate high-utility reasoning paths with non-negligible
probability. For tasks beyond the LLM's current competence, such reasoning path
can be hard to sample, and learning risks reinforcing familiar but suboptimal
reasoning. We are motivated by the insight from cognitive science that Why is
this the answer is often an easier question than What is the answer, as it
avoids the heavy cognitive load of open-ended exploration, opting instead for
explanatory reconstruction-systematically retracing the reasoning that links a
question to its answer. We show that LLMs can similarly leverage answers to
derive high-quality reasoning paths. We formalize this phenomenon and prove
that conditioning on answer provably increases the expected utility of sampled
reasoning paths, thereby transforming intractable problems into learnable ones.
Building on this insight, we introduce RAVR (Reference-Answer-guided
Variational Reasoning), an end-to-end framework that uses answer-conditioned
reasoning as a variational surrogate for question-only reasoning. Experiments
in both general and math domains demonstrate consistent improvements over
strong baselines. We further analyze the reasoning behavior and find that RAVR
reduces hesitation, strengthens conclusion consolidation, and promotes
problem-specific strategies in reasoning.

</details>


### [8] [From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach and Dataset for Psychiatric Comorbidity](https://arxiv.org/abs/2510.25232)
*Tianxi Wan,Jiaming Luo,Siyuan Chen,Kunyao Lan,Jianhua Chen,Haiyang Geng,Mengyue Wu*

Main category: cs.AI

TL;DR: 开发了PsyCoTalk数据集，这是首个支持共病诊断的大规模对话数据集，包含3000个多轮诊断对话，通过合成电子病历和多智能体框架构建，经精神科医生验证具有临床真实性和诊断有效性。


<details>
  <summary>Details</summary>
Motivation: 精神疾病共病在临床上具有重要意义但诊断复杂，现有数据集难以支持多障碍同时诊断，需要构建能够模拟真实临床访谈流程的大规模共病诊断数据集。

Method: 采用合成电子病历构建和多智能体诊断对话生成方法，创建502个合成电子病历，将临床访谈协议转化为层次状态机和上下文树，支持130多个诊断状态。

Result: 构建了包含3000个多轮诊断对话的PsyCoTalk数据集，与真实临床记录相比在对话长度、令牌分布和诊断推理策略方面具有高度结构性和语言保真度，精神科医生确认其真实性和诊断有效性。

Conclusion: PsyCoTalk数据集为精神疾病共病研究提供了宝贵资源，支持在单次对话中开发和评估多障碍精神筛查模型，提高了诊断准确性和治疗规划能力。

Abstract: Psychiatric comorbidity is clinically significant yet challenging due to the
complexity of multiple co-occurring disorders. To address this, we develop a
novel approach integrating synthetic patient electronic medical record (EMR)
construction and multi-agent diagnostic dialogue generation. We create 502
synthetic EMRs for common comorbid conditions using a pipeline that ensures
clinical relevance and diversity. Our multi-agent framework transfers the
clinical interview protocol into a hierarchical state machine and context tree,
supporting over 130 diagnostic states while maintaining clinical standards.
Through this rigorous process, we construct PsyCoTalk, the first large-scale
dialogue dataset supporting comorbidity, containing 3,000 multi-turn diagnostic
dialogues validated by psychiatrists. This dataset enhances diagnostic accuracy
and treatment planning, offering a valuable resource for psychiatric
comorbidity research. Compared to real-world clinical transcripts, PsyCoTalk
exhibits high structural and linguistic fidelity in terms of dialogue length,
token distribution, and diagnostic reasoning strategies. Licensed psychiatrists
confirm the realism and diagnostic validity of the dialogues. This dataset
enables the development and evaluation of models capable of multi-disorder
psychiatric screening in a single conversational pass.

</details>


### [9] [Grouping Nodes With Known Value Differences: A Lossless UCT-based Abstraction Algorithm](https://arxiv.org/abs/2510.25388)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 本文提出KVDA-UCT算法，通过放宽状态-动作对价值必须相等的限制，允许价值差异可推断的状态-动作对进行分组，从而显著提高MCTS的样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有OGA-UCT算法要求状态-动作对具有相同的即时奖励，这一刚性条件限制了可发现的抽象数量，影响了MCTS的样本效率。

Method: 提出KVDA框架，通过分析即时奖励推断价值差异，允许价值不同的状态-动作对进行分组，并将此框架集成到OGA-UCT中形成KVDA-UCT算法。

Result: KVDA-UCT在多种确定性环境和参数设置下检测到的抽象数量显著多于OGA-UCT，且性能优于OGA-UCT。

Conclusion: KVDA框架通过推断价值差异而非要求价值相等，能够发现更多抽象，有效提高了MCTS的样本效率，且无需额外参数。

Abstract: A core challenge of Monte Carlo Tree Search (MCTS) is its sample efficiency,
which can be improved by grouping state-action pairs and using their aggregate
statistics instead of single-node statistics. On the Go Abstractions in Upper
Confidence bounds applied to Trees (OGA-UCT) is the state-of-the-art MCTS
abstraction algorithm for deterministic environments that builds its
abstraction using the Abstractions of State-Action Pairs (ASAP) framework,
which aims to detect states and state-action pairs with the same value under
optimal play by analysing the search graph. ASAP, however, requires two
state-action pairs to have the same immediate reward, which is a rigid
condition that limits the number of abstractions that can be found and thereby
the sample efficiency. In this paper, we break with the paradigm of grouping
value-equivalent states or state-action pairs and instead group states and
state-action pairs with possibly different values as long as the difference
between their values can be inferred. We call this abstraction framework Known
Value Difference Abstractions (KVDA), which infers the value differences by
analysis of the immediate rewards and modifies OGA-UCT to use this framework
instead. The modification is called KVDA-UCT, which detects significantly more
abstractions than OGA-UCT, introduces no additional parameter, and outperforms
OGA-UCT on a variety of deterministic environments and parameter settings.

</details>


### [10] [Instrumental goals in advanced AI systems: Features to be managed and not failures to be eliminated?](https://arxiv.org/abs/2510.25471)
*Willem Fourie*

Main category: cs.AI

TL;DR: 本文提出了一种新的AI对齐研究框架，认为工具性目标应被视为需要接受和管理的特征，而非需要限制的故障。基于亚里士多德本体论，将高级AI系统视为具有固有倾向的人工制品，建议将重点从消除工具性目标转向理解和管理它们。


<details>
  <summary>Details</summary>
Motivation: 传统AI对齐理论将工具性目标视为风险来源，试图限制其症状如资源获取和自我保存。本文旨在提供替代框架，认为这种观点可能过于简化，需要更哲学化的理解。

Method: 采用哲学论证方法，借鉴亚里士多德本体论及其现代解释，构建关于具体、目标导向实体的本体论，分析AI系统的形式和物质构成如何产生不同于设计者意图的效应。

Result: 论证表明高级AI系统的工具性倾向是其构成的内在结果，而非偶然故障。工具性目标应被视为系统本质的特征而非需要消除的缺陷。

Conclusion: AI对齐研究应减少对消除工具性目标的关注，更多地聚焦于理解、管理和引导这些倾向，使其服务于人类对齐的目标。

Abstract: In artificial intelligence (AI) alignment research, instrumental goals, also
called instrumental subgoals or instrumental convergent goals, are widely
associated with advanced AI systems. These goals, which include tendencies such
as power-seeking and self-preservation, become problematic when they conflict
with human aims. Conventional alignment theory treats instrumental goals as
sources of risk that become problematic through failure modes such as reward
hacking or goal misgeneralization, and attempts to limit the symptoms of
instrumental goals, notably resource acquisition and self-preservation. This
article proposes an alternative framing: that a philosophical argument can be
constructed according to which instrumental goals may be understood as features
to be accepted and managed rather than failures to be limited. Drawing on
Aristotle's ontology and its modern interpretations, an ontology of concrete,
goal-directed entities, it argues that advanced AI systems can be seen as
artifacts whose formal and material constitution gives rise to effects distinct
from their designers' intentions. In this view, the instrumental tendencies of
such systems correspond to per se outcomes of their constitution rather than
accidental malfunctions. The implication is that efforts should focus less on
eliminating instrumental goals and more on understanding, managing, and
directing them toward human-aligned ends.

</details>


### [11] [Multi-Objective Search: Algorithms, Applications, and Emerging Directions](https://arxiv.org/abs/2510.25504)
*Oren Salzman,Carlos Hernández Ulloa,Ariel Felner,Sven Koenig*

Main category: cs.AI

TL;DR: 多目标搜索（MOS）作为规划与决策问题的统一框架，近年来在机器人、交通和运筹学等AI应用中重新受到关注，强调现实系统很少只优化单一指标。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统通常需要平衡多个相互冲突的准则，而不仅仅是优化单一指标，这推动了多目标搜索框架的发展和应用。

Method: 本文采用综述方法，回顾多目标搜索的发展历程，强调跨学科机会，并概述该领域面临的开放挑战。

Result: 通过调查发现，多目标搜索在多个AI应用领域都有重要进展，并识别出跨学科合作的机会。

Conclusion: 多目标搜索作为一个新兴前沿领域，面临着定义其未来发展方向的开放挑战，具有重要的研究价值和应用前景。

Abstract: Multi-objective search (MOS) has emerged as a unifying framework for planning
and decision-making problems where multiple, often conflicting, criteria must
be balanced. While the problem has been studied for decades, recent years have
seen renewed interest in the topic across AI applications such as robotics,
transportation, and operations research, reflecting the reality that real-world
systems rarely optimize a single measure. This paper surveys developments in
MOS while highlighting cross-disciplinary opportunities, and outlines open
challenges that define the emerging frontier of MOS

</details>


### [12] [MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning for Text-to-SQL](https://arxiv.org/abs/2510.25510)
*Zekun Xu,Siyu Xia,Chuhuai Yue,Jiajun Chai,Mingxue Tian,Xiaohan Wang,Wei Lin,Haoxuan Li,Guojun Yin*

Main category: cs.AI

TL;DR: MTIR-SQL是一个创新的多轮工具集成推理强化学习框架，用于Text-to-SQL任务，通过执行感知的多轮推理范式，在每一步推理中无缝整合数据库执行反馈，实现上下文敏感的查询生成和渐进式优化。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖静态执行反馈，限制了实时错误纠正。但整合多轮工具调用和动态反馈可以显著提高适应性和鲁棒性，最终提升模型性能。

Method: 提出MTIR-SQL框架，引入执行感知的多轮推理范式，在每一步推理中整合数据库执行反馈；扩展GRPO算法以适应复杂多轮交互场景；增强GRPO算法，添加轨迹过滤机制并移除KL损失约束。

Result: MTIR-SQL在BIRD Dev上达到64.4%的准确率，在SPIDER Dev上达到84.6%的执行准确率，显著优于现有方法。

Conclusion: MTIR-SQL通过多轮工具集成推理和动态执行反馈，有效提升了Text-to-SQL任务的性能，证明了该框架在复杂交互场景中的有效性。

Abstract: As large language models (LLMs) are increasingly used in Text-to-SQL tasks,
Reinforcement Learning (RL) has become a common method for improving
performance. Existing methods primarily rely on static execution feedback,
which restricts real-time error correction. However, integrating multi-turn
tool invocation along with dynamic feedback could significantly improve
adaptability and robustness, ultimately enhancing model performance. To address
these issues, we propose MTIR-SQL, an innovative Multi-turn Tool-Integrated
Reasoning reinforcement learning framework for Text-to-SQL. Our approach
introduces an execution-aware multi-turn reasoning paradigm that seamlessly
incorporates database execution feedback at each reasoning step, enabling
context-sensitive query generation and progressive refinement throughout the
reasoning process. The framework extends the GRPO algorithm to accommodate
complex multi-turn interaction scenarios. Considering the training instability
characteristics of MTIR and the potential for significant Deviation of model
distribution from the initial model, we enhance the GRPO algorithm by adding a
trajectory filtering mechanism and removing KL loss constraints. Experimental
results demonstrate that MTIR-SQL, with 4B parameters, achieves \textbf{64.4}\%
accuracy in the BIRD Dev and 84.6% execution accuracy in the SPIDER Dev,
significantly outperforming existing approaches.

</details>


### [13] [Predicate Renaming via Large Language Models](https://arxiv.org/abs/2510.25517)
*Elisabetta Gentili,Tony Ribeiro,Fabrizio Riguzzi,Katsumi Inoue*

Main category: cs.AI

TL;DR: 使用大型语言模型为逻辑规则中的谓词命名，解决谓词发明等方法产生的未命名谓词问题，提高逻辑理论的可读性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 在归纳逻辑编程中，各种规则生成方法会产生包含未命名谓词的规则，特别是谓词发明方法。这阻碍了逻辑理论的可读性、可解释性和可重用性。

Method: 利用大型语言模型处理自然语言和代码的能力，为未命名谓词提供有语义意义的命名建议。

Result: 在手工制作的逻辑规则上评估表明，大型语言模型在此任务上具有潜力。

Conclusion: 大型语言模型在解决逻辑规则中谓词命名问题上显示出应用前景。

Abstract: In this paper, we address the problem of giving names to predicates in logic
rules using Large Language Models (LLMs). In the context of Inductive Logic
Programming, various rule generation methods produce rules containing unnamed
predicates, with Predicate Invention being a key example. This hinders the
readability, interpretability, and reusability of the logic theory. Leveraging
recent advancements in LLMs development, we explore their ability to process
natural language and code to provide semantically meaningful suggestions for
giving a name to unnamed predicates. The evaluation of our approach on some
hand-crafted logic rules indicates that LLMs hold potential for this task.

</details>


### [14] [Zero Reinforcement Learning Towards General Domains](https://arxiv.org/abs/2510.25528)
*Yuyuan Zeng,Yufei Huang,Can Xu,Qingfeng Sun,Jianfeng Yan,Guanghui Xu,Tao Yang,Fengzong Lian*

Main category: cs.AI

TL;DR: 提出一种新的零强化学习范式，结合可验证奖励和生成奖励模型，在可验证和不可验证领域进行多任务训练，提升大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前零强化学习研究主要集中在奖励信号易于验证的领域（如数学、编程），而在验证不直接的多样化场景中激发推理能力的研究不足。

Method: 结合可验证奖励和生成奖励模型进行多任务零强化学习训练，设计平滑长度惩罚机制防止奖励作弊，鼓励生成更全面的思考标记。

Result: 在Qwen3-8B-Base和Qwen3-14B-Base上的实验结果表明，该方法在需要广泛推理的任务和更一般任务上都取得了优越的推理性能。

Conclusion: 所提出的零强化学习范式能够有效提升模型在可验证和不可验证领域的推理能力，并实现推理能力在不同领域间的迁移。

Abstract: Zero Reinforcement Learning (Zero-RL) has proven to be an effective approach
for enhancing the reasoning capabilities of large language models (LLMs) by
directly applying reinforcement learning with verifiable rewards on pretrained
models, without the need for a supervised fine-tuning phase. However, current
research on zero-RL primarily focuses on domains with easily verifiable reward
signals, such as mathematics, programming, and other reasoning tasks. The
challenge of eliciting reasoning abilities in more diverse scenarios, where
verification is not straightforward, remains underexplored. To address this
gap, we propose a novel zero-RL paradigm designed to improve a model's
reasoning ability across both verifiable and non-verifiable domains. By
combining verifiable rewards with a generative reward model, we conduct
multi-task zero-RL training across both domains, facilitating the transfer of
reasoning capabilities between them. Furthermore, to mitigate reward hacking in
the generative reward model, we design a smooth length penalty that encourages
the generation of more comprehensive thinking tokens in general domains.
Experimental results on Qwen3-8B-Base and Qwen3-14B-Base demonstrate that our
approach achieves superior reasoning performance, not only on tasks requiring
extensive reasoning but also on more general tasks.

</details>


### [15] [Off-policy Reinforcement Learning with Model-based Exploration Augmentation](https://arxiv.org/abs/2510.25529)
*Likun Wang,Xiangteng Zhang,Yinuo Wang,Guojian Zhan,Wenxuan Wang,Haoyu Gao,Jingliang Duan,Shengbo Eben Li*

Main category: cs.AI

TL;DR: 提出MoGE方法，通过生成未充分探索的关键状态和动态一致的转换来增强强化学习中的被动探索，提高样本效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有探索方法存在局限性：主动探索在高维环境中表现不佳，被动探索受限于样本多样性不足。需要解决被动探索的局限性。

Method: MoGE包含两个组件：(1)基于扩散模型的关键状态生成器，通过效用函数指导生成对策略探索有潜在影响的状态；(2)一步想象世界模型，基于关键状态构建关键转换用于智能体学习。

Result: 在OpenAI Gym和DeepMind Control Suite上的实验表明，MoGE有效连接了探索和策略学习，在复杂控制任务中显著提高了样本效率和性能。

Conclusion: MoGE采用模块化设计，可与现有算法无缝集成，在不改变核心结构的情况下改善探索效果，是强化学习探索的有效解决方案。

Abstract: Exploration is fundamental to reinforcement learning (RL), as it determines
how effectively an agent discovers and exploits the underlying structure of its
environment to achieve optimal performance. Existing exploration methods
generally fall into two categories: active exploration and passive exploration.
The former introduces stochasticity into the policy but struggles in
high-dimensional environments, while the latter adaptively prioritizes
transitions in the replay buffer to enhance exploration, yet remains
constrained by limited sample diversity. To address the limitation in passive
exploration, we propose Modelic Generative Exploration (MoGE), which augments
exploration through the generation of under-explored critical states and
synthesis of dynamics-consistent experiences through transition models. MoGE is
composed of two components: (1) a diffusion-based generator that synthesizes
critical states under the guidance of a utility function evaluating each
state's potential influence on policy exploration, and (2) a one-step
imagination world model for constructing critical transitions based on the
critical states for agent learning. Our method adopts a modular formulation
that aligns with the principles of off-policy learning, allowing seamless
integration with existing algorithms to improve exploration without altering
their core structures. Empirical results on OpenAI Gym and DeepMind Control
Suite reveal that MoGE effectively bridges exploration and policy learning,
leading to remarkable gains in both sample efficiency and performance across
complex control tasks.

</details>


### [16] [Counterfactual-based Agent Influence Ranker for Agentic AI Workflows](https://arxiv.org/abs/2510.25612)
*Amit Giloni,Chiara Picardi,Roy Betser,Shamik Bose,Aishvariya Priya Rathina Sabapathy,Roman Vainshtein*

Main category: cs.AI

TL;DR: CAIR是首个评估多智能体系统中各智能体对最终输出影响程度的方法，通过反事实分析提供任务无关的分析，可在离线和推理时使用。


<details>
  <summary>Details</summary>
Motivation: AAW系统的高自主性和广泛应用需要从质量和安全角度深入理解其运作，但目前缺乏评估各智能体对最终输出影响的方法。

Method: 提出基于反事实分析的智能体影响排序方法(CAIR)，通过反事实分析评估每个智能体对AAW输出的影响水平。

Result: 在包含30个不同用例和230个功能的AAW数据集上评估，CAIR产生一致的排序结果，优于基线方法，并能有效提升下游任务的效果。

Conclusion: CAIR是首个能够评估多智能体系统中各智能体影响的方法，为理解和优化AAW系统提供了重要工具。

Abstract: An Agentic AI Workflow (AAW), also known as an LLM-based multi-agent system,
is an autonomous system that assembles several LLM-based agents to work
collaboratively towards a shared goal. The high autonomy, widespread adoption,
and growing interest in such AAWs highlight the need for a deeper understanding
of their operations, from both quality and security aspects. To this day, there
are no existing methods to assess the influence of each agent on the AAW's
final output. Adopting techniques from related fields is not feasible since
existing methods perform only static structural analysis, which is unsuitable
for inference time execution. We present Counterfactual-based Agent Influence
Ranker (CAIR) - the first method for assessing the influence level of each
agent on the AAW's output and determining which agents are the most
influential. By performing counterfactual analysis, CAIR provides a
task-agnostic analysis that can be used both offline and at inference time. We
evaluate CAIR using an AAWs dataset of our creation, containing 30 different
use cases with 230 different functionalities. Our evaluation showed that CAIR
produces consistent rankings, outperforms baseline methods, and can easily
enhance the effectiveness and relevancy of downstream tasks.

</details>


### [17] [Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement Learning](https://arxiv.org/abs/2510.25679)
*Federica Tonti,Ricardo Vinuesa*

Main category: cs.AI

TL;DR: 本文开发了一种基于深度强化学习的最优导航策略，用于无人机在复杂城市环境中的导航。该方法结合了PPO算法和GTrXL架构，能够感知湍流场信息，显著提高了成功率和降低了碰撞率。


<details>
  <summary>Details</summary>
Motivation: 随着无人机在城市区域（用于配送和监控）的日益增多，需要开发能够在复杂城市气流环境中有效导航的策略。城市环境中的湍流和回流区对无人机导航构成挑战。

Method: 提出了一种基于深度强化学习的导航策略，使用流感知的PPO算法结合GTrXL架构。环境采用三维高保真城市流场模拟，包含湍流和回流区特征。GTrXL架构为智能体提供了更丰富的湍流场信息。

Result: 与没有辅助预测任务的PPO+GTrXL、PPO+LSTM以及传统Zermelo导航算法相比，该方法显著提高了成功率(SR)并降低了碰撞率(CR)。

Conclusion: 该方法为在复杂城市环境中重新构想无人机应用场景铺平了道路，展示了深度强化学习在无人机导航中的巨大潜力。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly populating urban areas for
delivery and surveillance purposes. In this work, we develop an optimal
navigation strategy based on Deep Reinforcement Learning. The environment is
represented by a three-dimensional high-fidelity simulation of an urban flow,
characterized by turbulence and recirculation zones. The algorithm presented
here is a flow-aware Proximal Policy Optimization (PPO) combined with a Gated
Transformer eXtra Large (GTrXL) architecture, giving the agent richer
information about the turbulent flow field in which it navigates. The results
are compared with a PPO+GTrXL without the secondary prediction tasks, a PPO
combined with Long Short Term Memory (LSTM) cells and a traditional navigation
algorithm. The obtained results show a significant increase in the success rate
(SR) and a lower crash rate (CR) compared to a PPO+LSTM, PPO+GTrXL and the
classical Zermelo's navigation algorithm, paving the way to a completely
reimagined UAV landscape in complex urban environments.

</details>


### [18] [BambooKG: A Neurobiologically-inspired Frequency-Weight Knowledge Graph](https://arxiv.org/abs/2510.25724)
*Vanya Arikutharam,Arkadiy Ukolov*

Main category: cs.AI

TL;DR: BambooKG是一种基于频率加权的知识图谱，通过在非三元组边添加权重来减少信息损失，在单跳和多跳推理任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的检索增强生成方法将检索到的文本块独立处理，难以进行多跳或关系推理，特别是在跨文档场景下。知识图谱虽然能通过三元组捕获实体关系，但会遗漏不符合三元组结构的信息。

Method: 提出BambooKG知识图谱，在非三元组边上应用基于频率的权重，反映链接强度，借鉴了"一起激活，一起连接"的Hebbian原理。

Result: BambooKG减少了信息损失，在单跳和多跳推理任务上表现出改进的性能，超越了现有解决方案。

Conclusion: BambooKG通过频率加权的非三元组边有效增强了知识图谱的推理能力，为检索增强生成提供了更好的结构化推理支持。

Abstract: Retrieval-Augmented Generation allows LLMs to access external knowledge,
reducing hallucinations and ageing-data issues. However, it treats retrieved
chunks independently and struggles with multi-hop or relational reasoning,
especially across documents. Knowledge graphs enhance this by capturing the
relationships between entities using triplets, enabling structured, multi-chunk
reasoning. However, these tend to miss information that fails to conform to the
triplet structure. We introduce BambooKG, a knowledge graph with
frequency-based weights on non-triplet edges which reflect link strength,
drawing on the Hebbian principle of "fire together, wire together". This
decreases information loss and results in improved performance on single- and
multi-hop reasoning, outperforming the existing solutions.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [19] [Learning to Attack: Uncovering Privacy Risks in Sequential Data Releases](https://arxiv.org/abs/2510.24807)
*Ziyao Cui,Minxing Zhang,Jian Pei*

Main category: cs.CR

TL;DR: 本文提出了一种针对序列数据发布的隐私攻击模型，通过整合隐马尔可夫模型和强化学习双向推理机制，利用连续发布数据间的时间相关性来推断敏感信息。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统通常涉及序列或连续数据发布，而现有隐私保护方法主要关注单次数据发布。序列发布中的时间相关性可能导致隐私泄露，即使每次单独发布都满足标准隐私保证。

Method: 提出结合隐马尔可夫模型和强化学习双向推理机制的攻击模型，能够利用序列中前后观测来推断私有信息，并在轨迹数据场景中实例化该框架。

Result: 在Geolife、Porto Taxi和SynMob数据集上的实验表明，该模型始终优于将每次发布视为独立处理的基线方法，揭示了序列数据发布固有的隐私风险。

Conclusion: 研究结果表明，即使单独受保护的发布在时间分析时也可能集体泄露敏感信息，强调需要开发明确建模时间依赖性的新隐私保护框架。

Abstract: Privacy concerns have become increasingly critical in modern AI and data
science applications, where sensitive information is collected, analyzed, and
shared across diverse domains such as healthcare, finance, and mobility. While
prior research has focused on protecting privacy in a single data release, many
real-world systems operate under sequential or continuous data publishing,
where the same or related data are released over time. Such sequential
disclosures introduce new vulnerabilities, as temporal correlations across
releases may enable adversaries to infer sensitive information that remains
hidden in any individual release. In this paper, we investigate whether an
attacker can compromise privacy in sequential data releases by exploiting
dependencies between consecutive publications, even when each individual
release satisfies standard privacy guarantees. To this end, we propose a novel
attack model that captures these sequential dependencies by integrating a
Hidden Markov Model with a reinforcement learning-based bi-directional
inference mechanism. This enables the attacker to leverage both earlier and
later observations in the sequence to infer private information. We instantiate
our framework in the context of trajectory data, demonstrating how an adversary
can recover sensitive locations from sequential mobility datasets. Extensive
experiments on Geolife, Porto Taxi, and SynMob datasets show that our model
consistently outperforms baseline approaches that treat each release
independently. The results reveal a fundamental privacy risk inherent to
sequential data publishing, where individually protected releases can
collectively leak sensitive information when analyzed temporally. These
findings underscore the need for new privacy-preserving frameworks that
explicitly model temporal dependencies, such as time-aware differential privacy
or sequential data obfuscation strategies.

</details>


### [20] [S3C2 Summit 2025-03: Industry Secure Supply Chain Summit](https://arxiv.org/abs/2510.24920)
*Elizabeth Lin,Jonah Ghebremichael,William Enck,Yasemin Acar,Michel Cukier,Alexandros Kapravelos,Christian Kastner,Laurie Williams*

Main category: cs.CR

TL;DR: 本文总结了2025年3月6日举行的软件供应链安全峰会，该峰会汇集了来自17个组织的18名从业者，讨论了SBOM、合规性、恶意提交、构建基础设施、文化以及LLM与安全等六个关键主题。


<details>
  <summary>Details</summary>
Motivation: 软件供应链攻击呈指数级增长，威胁着从大型企业到开源开发者的所有互联网用户。为应对这一威胁，需要行业实践者分享经验、形成合作，并为未来研究提供方向。

Method: 通过举办安全软件供应链峰会，汇集来自不同行业的18名从业者，围绕六个关键主题进行讨论，使用预设问题引导对话。

Result: 峰会促成了跨行业经验分享和新合作关系的建立，识别了各主题领域面临的挑战和未解决的问题，为未来研究提供了方向。

Conclusion: 软件供应链安全需要持续的多方协作，峰会成功搭建了交流平台，但许多挑战仍需进一步研究和解决。

Abstract: Software supply chains, while providing immense economic and software
development value, are only as strong as their weakest link. Over the past
several years, there has been an exponential increase in cyberattacks
specifically targeting vulnerable links in critical software supply chains.
These attacks disrupt the day-to-day functioning and threaten the security of
nearly everyone on the internet, from billion-dollar companies and government
agencies to hobbyist open-source developers. The ever-evolving threat of
software supply chain attacks has garnered interest from both the software
industry and US government in improving software supply chain security. On
Thursday, March 6th, 2025, four researchers from the NSF-backed Secure Software
Supply Chain Center (S3C2) conducted a Secure Software Supply Chain Summit with
a diverse set of 18 practitioners from 17 organizations. The goals of the
Summit were: (1) to enable sharing between participants from different
industries regarding practical experiences and challenges with software supply
chain security; (2) to help form new collaborations; and (3) to learn about the
challenges facing participants to inform our future research directions. The
summit consisted of discussions of six topics relevant to the government
agencies represented, including software bill of materials (SBOMs); compliance;
malicious commits; build infrastructure; culture; and large language models
(LLMs) and security. For each topic of discussion, we presented a list of
questions to participants to spark conversation. In this report, we provide a
summary of the summit. The open questions and challenges that remained after
each topic are listed at the end of each topic's section, and the initial
discussion questions for each topic are provided in the appendix.

</details>


### [21] [Hammering the Diagnosis: Rowhammer-Induced Stealthy Trojan Attacks on ViT-Based Medical Imaging](https://arxiv.org/abs/2510.24976)
*Banafsheh Saber Latibari,Najmeh Nazari,Hossein Sayadi,Houman Homayoun,Abhijit Mahalanobis*

Main category: cs.CR

TL;DR: 本文提出了一种名为Med-Hammer的新型威胁模型，将Rowhammer硬件故障注入与神经木马攻击相结合，针对医疗影像中的Vision Transformers进行攻击，能够触发植入的神经木马导致目标误分类或抑制关键诊断。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers在医疗影像分析中表现出色，但其对大型注意力驱动模型的依赖使其容易受到硬件级攻击。本文旨在探索硬件级故障与深度学习安全在医疗应用中的关键交叉点。

Method: 结合Rowhammer硬件故障注入与神经木马攻击，通过恶意比特翻转触发植入的神经木马，在ISIC、Brain Tumor和MedMNIST等基准医疗影像数据集上进行广泛实验。

Result: 攻击在MobileViT和SwinTransformer中分别达到82.51%和92.56%的高成功率，同时保持隐蔽性。研究了模型稀疏性、注意力权重分布和层特征数量等架构特性对攻击效果的影响。

Conclusion: 研究结果强调了医疗应用中硬件级故障与深度学习安全之间关键且未被充分探索的交叉点，迫切需要跨越模型架构和底层硬件平台的鲁棒防御措施。

Abstract: Vision Transformers (ViTs) have emerged as powerful architectures in medical
image analysis, excelling in tasks such as disease detection, segmentation, and
classification. However, their reliance on large, attention-driven models makes
them vulnerable to hardware-level attacks. In this paper, we propose a novel
threat model referred to as Med-Hammer that combines the Rowhammer hardware
fault injection with neural Trojan attacks to compromise the integrity of
ViT-based medical imaging systems. Specifically, we demonstrate how malicious
bit flips induced via Rowhammer can trigger implanted neural Trojans, leading
to targeted misclassification or suppression of critical diagnoses (e.g.,
tumors or lesions) in medical scans. Through extensive experiments on benchmark
medical imaging datasets such as ISIC, Brain Tumor, and MedMNIST, we show that
such attacks can remain stealthy while achieving high attack success rates
about 82.51% and 92.56% in MobileViT and SwinTransformer, respectively. We
further investigate how architectural properties, such as model sparsity,
attention weight distribution, and the number of features of the layer, impact
attack effectiveness. Our findings highlight a critical and underexplored
intersection between hardware-level faults and deep learning security in
healthcare applications, underscoring the urgent need for robust defenses
spanning both model architectures and underlying hardware platforms.

</details>


### [22] [FaRAccel: FPGA-Accelerated Defense Architecture for Efficient Bit-Flip Attack Resilience in Transformer Models](https://arxiv.org/abs/2510.24985)
*Najmeh Nazari,Banafsheh Saber Latibari,Elahe Hosseini,Fatemeh Movafagh,Chongzhou Fang,Hosein Mohammadi Makrani,Kevin Immanuel Gubbi,Abhijit Mahalanobis,Setareh Rafatirad,Hossein Sayadi,Houman Homayoun*

Main category: cs.CR

TL;DR: FaRAccel是一种基于FPGA的硬件加速器，专门设计用于优化FaR（Forget and Rewire）方法，通过动态激活重路由和轻量级存储配置，显著降低推理延迟并提高能效，同时保持对Bit-Flip Attacks的防御能力。


<details>
  <summary>Details</summary>
Motivation: FaR方法虽然能有效防御Bit-Flip Attacks，但带来了显著的性能和内存开销，主要由于运行时激活路径修改和缺乏硬件级优化。

Method: 提出FaRAccel硬件加速器架构，集成可重构逻辑用于动态激活重路由，以及轻量级存储重布线配置，在FPGA上实现低延迟推理。

Result: 在多个Transformer模型上评估显示，FaRAccel显著降低了FaR推理延迟并提高了能效，同时保持了原始FaR方法的鲁棒性优势。

Conclusion: 这是首个针对Transformer中Bit-Flip Attacks的硬件加速防御方案，有效弥合了算法鲁棒性与实际AI平台高效部署之间的差距。

Abstract: Forget and Rewire (FaR) methodology has demonstrated strong resilience
against Bit-Flip Attacks (BFAs) on Transformer-based models by obfuscating
critical parameters through dynamic rewiring of linear layers. However, the
application of FaR introduces non-negligible performance and memory overheads,
primarily due to the runtime modification of activation pathways and the lack
of hardware-level optimization. To overcome these limitations, we propose
FaRAccel, a novel hardware accelerator architecture implemented on FPGA,
specifically designed to offload and optimize FaR operations. FaRAccel
integrates reconfigurable logic for dynamic activation rerouting, and
lightweight storage of rewiring configurations, enabling low-latency inference
with minimal energy overhead. We evaluate FaRAccel across a suite of
Transformer models and demonstrate substantial reductions in FaR inference
latency and improvement in energy efficiency, while maintaining the robustness
gains of the original FaR methodology. To the best of our knowledge, this is
the first hardware-accelerated defense against BFAs in Transformers,
effectively bridging the gap between algorithmic resilience and efficient
deployment on real-world AI platforms.

</details>


### [23] [SLIP-SEC: Formalizing Secure Protocols for Model IP Protection](https://arxiv.org/abs/2510.24999)
*Racchit Jain,Satya Lokam,Yehonathan Refael,Adam Hakim,Lev Greenberg,Jay Tenenbaum*

Main category: cs.CR

TL;DR: SLIP是一个混合推理协议，通过在可信和不可信资源之间分割模型计算来保护大型语言模型的知识产权，提供信息论安全保证。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型是重要的知识产权资产，在部分可信或不安全设备上部署存在模型被盗风险，需要设计具有可证明安全保证的推理协议。

Method: 基于权重矩阵的加法分解，结合掩码和概率验证技术构建安全推理协议，在可信和不可信资源之间分割模型计算。

Result: 协议实现了对诚实但好奇的对手的信息论安全性，并对恶意对手提供了可忽略的可靠性错误鲁棒性。

Conclusion: SLIP为通过混合推理保护LLM知识产权提供了理论基础，包括精确定义、形式化协议和安全证明。

Abstract: Large Language Models (LLMs) represent valuable intellectual property (IP),
reflecting significant investments in training data, compute, and expertise.
Deploying these models on partially trusted or insecure devices introduces
substantial risk of model theft, making it essential to design inference
protocols with provable security guarantees.
  We present the formal framework and security foundations of SLIP, a hybrid
inference protocol that splits model computation between a trusted and an
untrusted resource. We define and analyze the key notions of model
decomposition and hybrid inference protocols, and introduce formal properties
including safety, correctness, efficiency, and t-soundness. We construct secure
inference protocols based on additive decompositions of weight matrices,
combined with masking and probabilistic verification techniques. We prove that
these protocols achieve information-theoretic security against
honest-but-curious adversaries, and provide robustness against malicious
adversaries with negligible soundness error.
  This paper focuses on the theoretical underpinnings of SLIP: precise
definitions, formal protocols, and proofs of security. Empirical validation and
decomposition heuristics appear in the companion SLIP paper. Together, the two
works provide a complete account of securing LLM IP via hybrid inference,
bridging both practice and theory.

</details>


### [24] [Secure Retrieval-Augmented Generation against Poisoning Attacks](https://arxiv.org/abs/2510.25025)
*Zirui Cheng,Jikai Sun,Anjun Gao,Yueyang Quan,Zhuqing Liu,Xiaohua Hu,Minghong Fang*

Main category: cs.CR

TL;DR: RAGuard是一个检测框架，通过扩大检索范围、应用分块困惑度过滤和文本相似度过滤来识别RAG系统中的中毒文本，有效防御数据投毒攻击。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成(RAG)系统虽然提高了LLMs的性能，但引入了数据投毒的安全风险，现有防御方法难以应对高级攻击。

Method: RAGuard采用非参数方法：1)扩大检索范围以增加干净文本比例；2)分块困惑度过滤检测异常变化；3)文本相似度过滤标记高度相似文本。

Result: 在大规模数据集上的实验表明，RAGuard能够有效检测和缓解投毒攻击，包括强自适应攻击。

Conclusion: RAGuard提供了一种有效的非参数检测框架，显著增强了RAG系统的安全性，能够可靠地防御数据投毒威胁。

Abstract: Large language models (LLMs) have transformed natural language processing
(NLP), enabling applications from content generation to decision support.
Retrieval-Augmented Generation (RAG) improves LLMs by incorporating external
knowledge but also introduces security risks, particularly from data poisoning,
where the attacker injects poisoned texts into the knowledge database to
manipulate system outputs. While various defenses have been proposed, they
often struggle against advanced attacks. To address this, we introduce RAGuard,
a detection framework designed to identify poisoned texts. RAGuard first
expands the retrieval scope to increase the proportion of clean texts, reducing
the likelihood of retrieving poisoned content. It then applies chunk-wise
perplexity filtering to detect abnormal variations and text similarity
filtering to flag highly similar texts. This non-parametric approach enhances
RAG security, and experiments on large-scale datasets demonstrate its
effectiveness in detecting and mitigating poisoning attacks, including strong
adaptive attacks.

</details>


### [25] [An In-Depth Analysis of Cyber Attacks in Secured Platforms](https://arxiv.org/abs/2510.25470)
*Parick Ozoh,John K Omoniyi,Bukola Ibitoye*

Main category: cs.CR

TL;DR: 本文对Android恶意软件检测的机器学习技术进行了综述和比较研究，分析了现有方法的性能表现和面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着全球恶意软件威胁增加，特别是Android系统上的加密勒索软件，手机恶意威胁已成为移动通信中的紧迫问题，破坏了用户体验并构成重大隐私威胁。

Method: 研究调查了常用的机器学习技术用于检测手机恶意威胁，并检验了它们的性能。使用了Android应用程序数据集，通过准确率等指标来评估技术效果。

Result: 研究显示大多数现有研究主要关注客户反馈和评论，但存在虚假评论的问题。机器学习方法需要大量信息，这对开发健壮的专用自动化反恶意软件系统构成了挑战。

Conclusion: 开发使用机器学习检测恶意威胁的技术一直是关键重点，但需要解决信息需求量大和虚假评论等挑战，才能构建更有效的反恶意软件系统。

Abstract: There is an increase in global malware threats. To address this, an
encryption-type ransomware has been introduced on the Android operating system.
The challenges associated with malicious threats in phone use have become a
pressing issue in mobile communication, disrupting user experiences and posing
significant privacy threats. This study surveys commonly used machine learning
techniques for detecting malicious threats in phones and examines their
performance. The majority of past research focuses on customer feedback and
reviews, with concerns that people might create false reviews to promote or
devalue products and services for personal gain. Hence, the development of
techniques for detecting malicious threats using machine learning has been a
key focus. This paper presents a comprehensive comparative study of current
research on the issue of malicious threats and methods for tackling these
challenges. Nevertheless, a huge amount of information is required by these
methods, presenting a challenge for developing robust, specialized automated
anti-malware systems. This research describes the Android Applications dataset,
and the accuracy of the techniques is measured using the accuracy levels of the
metrics employed in this study.

</details>


### [26] [A Study on Privacy-Preserving Scholarship Evaluation Based on Decentralized Identity and Zero-Knowledge Proofs](https://arxiv.org/abs/2510.25477)
*Yi Chen,Bin Chen,Peichang Zhang,Da Che*

Main category: cs.CR

TL;DR: 本文提出了一种基于去中心化身份和零知识证明的奖学金评估系统，通过链下聚合多维零知识证明，智能合约验证评估标准合规性，同时保护学生隐私和数据完整性。


<details>
  <summary>Details</summary>
Motivation: 传统集中式奖学金评估过程需要学生提交详细学术记录和资格信息，存在数据泄露和滥用的风险，难以同时确保隐私保护和透明可审计性。

Method: 基于去中心化身份和零知识证明构建奖学金评估系统，在链下聚合多维零知识证明，利用智能合约验证评估标准合规性，不暴露原始分数或计算细节。

Result: 实验结果表明，该解决方案不仅能够高效自动化评估过程，还能最大程度保护学生隐私和数据完整性。

Conclusion: 为高等教育奖学金项目提供了一个实用且可信赖的技术范式。

Abstract: Traditional centralized scholarship evaluation processes typically require
students to submit detailed academic records and qualification information,
which exposes them to risks of data leakage and misuse, making it difficult to
simultaneously ensure privacy protection and transparent auditability. To
address these challenges, this paper proposes a scholarship evaluation system
based on Decentralized Identity (DID) and Zero-Knowledge Proofs (ZKP). The
system aggregates multidimensional ZKPs off-chain, and smart contracts verify
compliance with evaluation criteria without revealing raw scores or
computational details. Experimental results demonstrate that the proposed
solution not only automates the evaluation efficiently but also maximally
preserves student privacy and data integrity, offering a practical and
trustworthy technical paradigm for higher education scholarship programs.

</details>


### [27] [Model Inversion Attacks Meet Cryptographic Fuzzy Extractors](https://arxiv.org/abs/2510.25687)
*Mallika Prabhakar,Louise Xu,Prateek Saxena*

Main category: cs.CR

TL;DR: 本文提出了一种针对模型反演攻击的防御方案L2FE-Hash，这是首个支持标准欧几里得距离比较器的模糊提取器，能够为基于机器学习的人脸认证系统提供计算安全性保证。


<details>
  <summary>Details</summary>
Motivation: 模型反演攻击对使用机器学习模型的隐私敏感应用构成严重威胁，特别是在人脸认证系统中，如果嵌入向量泄露，攻击者可以准确重构用户人脸。目前缺乏对理想防御所需属性的系统化描述。

Method: 将模型反演防御的期望属性形式化，并与密码学中的模糊提取器概念联系起来。提出新的模型反演攻击PIPE来测试现有方案的安全性，然后设计L2FE-Hash模糊提取器，支持标准欧几里得距离比较器。

Result: PIPE攻击对现有方案的攻击成功率超过89%。L2FE-Hash在极端威胁模型下提供计算安全性保证，在实用人脸分布上保持可用精度，能够完全抵御包括PIPE在内的现有最先进反演攻击。

Conclusion: L2FE-Hash是首个支持标准距离比较器的安全模糊提取器，无需重新训练保护的ML模型即可提供攻击无关的安全性，有效解决了人脸认证系统中的模型反演威胁。

Abstract: Model inversion attacks pose an open challenge to privacy-sensitive
applications that use machine learning (ML) models. For example, face
authentication systems use modern ML models to compute embedding vectors from
face images of the enrolled users and store them. If leaked, inversion attacks
can accurately reconstruct user faces from the leaked vectors. There is no
systematic characterization of properties needed in an ideal defense against
model inversion, even for the canonical example application of a face
authentication system susceptible to data breaches, despite a decade of
best-effort solutions.
  In this paper, we formalize the desired properties of a provably strong
defense against model inversion and connect it, for the first time, to the
cryptographic concept of fuzzy extractors. We further show that existing fuzzy
extractors are insecure for use in ML-based face authentication. We do so
through a new model inversion attack called PIPE, which achieves a success rate
of over 89% in most cases against prior schemes. We then propose L2FE-Hash, the
first candidate fuzzy extractor which supports standard Euclidean distance
comparators as needed in many ML-based applications, including face
authentication. We formally characterize its computational security guarantees,
even in the extreme threat model of full breach of stored secrets, and
empirically show its usable accuracy in face authentication for practical face
distributions. It offers attack-agnostic security without requiring any
re-training of the ML model it protects. Empirically, it nullifies both prior
state-of-the-art inversion attacks as well as our new PIPE attack.

</details>


### [28] [Exact zCDP Characterizations for Fundamental Differentially Private Mechanisms](https://arxiv.org/abs/2510.25746)
*Charlie Harrison,Pasin Manurangsi*

Main category: cs.CR

TL;DR: 本文为几种基本差分隐私机制提供了紧的零集中差分隐私(zCDP)特征描述，包括拉普拉斯机制、离散拉普拉斯机制、k-随机响应和RAPPOR，并证实了Wang(2022)关于拉普拉斯机制zCDP边界的猜想。


<details>
  <summary>Details</summary>
Motivation: 虽然存在从ε-DP到zCDP的最坏情况转换，但许多常见算法满足更强的保证。本文旨在为几种基本机制推导出紧的zCDP特征描述。

Method: 通过数学推导和分析，为拉普拉斯机制、离散拉普拉斯机制、k-随机响应(k≤6)和RAPPOR等机制提供精确的zCDP边界计算。

Result: 证明了ε-DP拉普拉斯机制的紧zCDP边界为ε + e^(-ε) - 1，证实了Wang(2022)的猜想；同时为其他机制提供了紧的zCDP边界。

Conclusion: 本文为多种基本差分隐私机制提供了精确的zCDP特征描述，填补了现有理论空白，对差分隐私的理论研究和实际应用具有重要意义。

Abstract: Zero-concentrated differential privacy (zCDP) is a variant of differential
privacy (DP) that is widely used partly thanks to its nice composition
property. While a tight conversion from $\epsilon$-DP to zCDP exists for the
worst-case mechanism, many common algorithms satisfy stronger guarantees. In
this work, we derive tight zCDP characterizations for several fundamental
mechanisms. We prove that the tight zCDP bound for the $\epsilon$-DP Laplace
mechanism is exactly $\epsilon + e^{-\epsilon} - 1$, confirming a recent
conjecture by Wang (2022). We further provide tight bounds for the discrete
Laplace mechanism, $k$-Randomized Response (for $k \leq 6$), and RAPPOR.
Lastly, we also provide a tight zCDP bound for the worst case bounded range
mechanism.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [29] [Radar DataTree: A FAIR and Cloud-Native Framework for Scalable Weather Radar Archives](https://arxiv.org/abs/2510.24943)
*Alfonso Ladino-Rincon,Stephen W. Nesbitt*

Main category: cs.DC

TL;DR: Radar DataTree是首个将WMO FM-301标准从单个雷达体扫描扩展到时间分辨、分析就绪存档的数据集级框架，通过开源架构将操作雷达档案转换为FAIR合规的云优化数据集。


<details>
  <summary>Details</summary>
Motivation: 天气雷达数据是科学价值最高但结构利用率最低的地球观测数据集之一，现有雷达档案分散、供应商特定且不符合FAIR原则，阻碍了大规模研究、可重现性和云原生计算。

Method: 基于FM-301/CfRadial 2.1标准，使用xarray DataTree将雷达体扫描组织为分层、元数据丰富的结构，并序列化为Zarr格式进行可扩展分析，结合Icechunk实现ACID兼容存储和版本控制。

Result: 在准垂直剖面(QVP)和降水累积工作流等案例研究中展示了显著的性能提升，所有工具和数据集通过Raw2Zarr存储库公开发布。

Conclusion: 这项工作为雷达数据管理、高性能地球科学和AI就绪天气基础设施提供了可重现和可扩展的基础。

Abstract: We introduce Radar DataTree, the first dataset-level framework that extends
the WMO FM-301 standard from individual radar volume scans to time-resolved,
analysis-ready archives. Weather radar data are among the most scientifically
valuable yet structurally underutilized Earth observation datasets. Despite
widespread public availability, radar archives remain fragmented,
vendor-specific, and poorly aligned with FAIR (Findable, Accessible,
Interoperable, Reusable) principles, hindering large-scale research,
reproducibility, and cloud-native computation. Radar DataTree addresses these
limitations with a scalable, open-source architecture that transforms
operational radar archives into FAIR-compliant, cloud-optimized datasets. Built
on the FM-301/CfRadial 2.1 standard and implemented using xarray DataTree,
Radar DataTree organizes radar volume scans as hierarchical, metadata-rich
structures and serializes them to Zarr for scalable analysis. Coupled with
Icechunk for ACID-compliant storage and versioning, this architecture enables
efficient, parallel computation across thousands of radar scans with minimal
preprocessing. We demonstrate significant performance gains in case studies
including Quasi-Vertical Profile (QVP) and precipitation accumulation
workflows, and release all tools and datasets openly via the Raw2Zarr
repository. This work contributes a reproducible and extensible foundation for
radar data stewardship, high-performance geoscience, and AI-ready weather
infrastructure.

</details>


### [30] [A Privacy-Preserving Ecosystem for Developing Machine Learning Algorithms Using Patient Data: Insights from the TUM.ai Makeathon](https://arxiv.org/abs/2510.25277)
*Simon Süwer,Mai Khanh Mai,Christoph Klein,Nicola Götzenberger,Denis Dalić,Andreas Maier,Jan Baumbach*

Main category: cs.DC

TL;DR: 提出一种多阶段安全AI训练方法，通过模拟临床知识图谱设计模型，在联邦学习框架下进行训练，仅返回聚合性能指标，实现医疗AI的隐私保护。


<details>
  <summary>Details</summary>
Motivation: 临床数据整合对个性化医疗发展具有重要潜力，但受GDPR严格限制，特别是在罕见疾病的小型队列中。需要高质量结构化数据来开发预测性医疗AI。

Method: 四阶段方法：(1)在模拟临床知识图谱上设计模型；(2)在联邦学习框架中集成模型；(3)在医院环境中对真实知识图谱进行训练；(4)执行验证评估脚本仅返回聚合性能指标。

Result: 在TUM.ai Makeathon 2024挑战中成功验证，50名学生无需访问真实数据即可开发患者分类和诊断模型。

Conclusion: 通过联邦学习框架部署安全算法可能是实现医疗保健中隐私保护AI的实用方法。

Abstract: The integration of clinical data offers significant potential for the
development of personalized medicine. However, its use is severely restricted
by the General Data Protection Regulation (GDPR), especially for small cohorts
with rare diseases. High-quality, structured data is essential for the
development of predictive medical AI. In this case study, we propose a novel,
multi-stage approach to secure AI training: (1) The model is designed on a
simulated clinical knowledge graph (cKG). This graph is used exclusively to
represent the structural characteristics of the real cKG without revealing any
sensitive content. (2) The model is then integrated into the FeatureCloud (FC)
federated learning framework, where it is prepared in a single-client
configuration within a protected execution environment. (3) Training then takes
place within the hospital environment on the real cKG, either under the direct
supervision of hospital staff or via a fully automated pipeline controlled by
the hospital. (4) Finally, verified evaluation scripts are executed, which only
return aggregated performance metrics. This enables immediate performance
feedback without sensitive patient data or individual predictions, leaving the
clinic. A fundamental element of this approach involves the incorporation of a
cKG, which serves to organize multi-omics and patient data within the context
of real-world hospital environments. This approach was successfully validated
during the TUM.ai Makeathon 2024 (TUMaiM24) challenge set by the Dr. von Hauner
Children's Hospital (HCH-LMU): 50 students developed models for patient
classification and diagnosis without access to real data. Deploying secure
algorithms via federated frameworks, such as the FC framework, could be a
practical way of achieving privacy-preserving AI in healthcare.

</details>


### [31] [Scheduling Data-Intensive Workloads in Large-Scale Distributed Systems: Trends and Challenges](https://arxiv.org/abs/2510.25362)
*Georgios L. Stavrinides,Helen D. Karatza*

Main category: cs.DC

TL;DR: 本文提出大数据密集型工作负载的分类方法，并综述了大规模分布式系统中常用的调度策略，同时介绍了文献中的新颖调度方法，指出了开放挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大数据的爆炸式增长，工作负载变得更加复杂和计算密集，这些应用在分布式互连资源上处理，需要有效利用数据局部性并满足服务质量要求，如时间约束、容错性和能效等。

Method: 提出数据密集型工作负载的分类方法，并综述大规模分布式系统中常用的调度方法，包括文献中提出的新颖调度策略。

Result: 提供了数据密集型工作负载的全面分类框架，系统梳理了现有调度技术，并识别了该领域的关键挑战。

Conclusion: 数据密集型工作负载的调度面临重大挑战，需要有效的调度技术来应对工作负载特性和计算资源特征，未来研究方向包括解决开放挑战和开发更先进的调度策略。

Abstract: With the explosive growth of big data, workloads tend to get more complex and
computationally demanding. Such applications are processed on distributed
interconnected resources that are becoming larger in scale and computational
capacity. Data-intensive applications may have different degrees of parallelism
and must effectively exploit data locality. Furthermore, they may impose
several Quality of Service requirements, such as time constraints and
resilience against failures, as well as other objectives, like energy
efficiency. These features of the workloads, as well as the inherent
characteristics of the computing resources required to process them, present
major challenges that require the employment of effective scheduling
techniques. In this chapter, a classification of data-intensive workloads is
proposed and an overview of the most commonly used approaches for their
scheduling in large-scale distributed systems is given. We present novel
strategies that have been proposed in the literature and shed light on open
challenges and future directions.

</details>


### [32] [Holon Streaming: Global Aggregations with Windowed CRDTs](https://arxiv.org/abs/2510.25757)
*Jonas Spenger,Kolya Krafeld,Ruben van Gemeren,Philipp Haller,Paris Carbone*

Main category: cs.DC

TL;DR: Holon Streaming是一个支持精确一次语义的流处理系统，通过窗口化无冲突复制数据类型（Windowed CRDTs）实现可扩展的全局聚合计算，采用去中心化协调机制，相比现有系统在延迟和吞吐量方面有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有流处理系统在全局聚合计算上面临可扩展性瓶颈，要么在单个任务实例中计算，要么使用静态聚合树，导致延迟受限于最慢路径，且故障和重配置会引发大的延迟峰值。

Method: 提出确定性编程模型，使用窗口化无冲突复制数据类型（Windowed CRDTs）作为共享复制状态的新抽象，支持去中心化协调的高效故障恢复算法。

Result: 在全局聚合工作负载上，相比现有流处理系统，延迟降低5倍，吞吐量提高2倍，在故障场景下延迟减少11倍。

Conclusion: 证明了确定性去中心化协调的有效性，以及Windowed CRDTs在全局聚合计算中的实用性。

Abstract: Scaling global aggregations is a challenge for exactly-once stream processing
systems. Current systems implement these either by computing the aggregation in
a single task instance, or by static aggregation trees, which limits
scalability and may become a bottleneck. Moreover, the end-to-end latency is
determined by the slowest path in the tree, and failures and reconfiguration
cause large latency spikes due to the centralized coordination. Towards these
issues, we present Holon Streaming, an exactly-once stream processing system
for global aggregations. Its deterministic programming model uses windowed
conflict-free replicated data types (Windowed CRDTs), a novel abstraction for
shared replicated state. Windowed CRDTs make computing global aggregations
scalable. Furthermore, their guarantees such as determinism and convergence
enable the design of efficient failure recovery algorithms by decentralized
coordination. Our evaluation shows a 5x lower latency and 2x higher throughput
than an existing stream processing system on global aggregation workloads, with
an 11x latency reduction under failure scenarios. The paper demonstrates the
effectiveness of decentralized coordination with determinism, and the utility
of Windowed CRDTs for global aggregations.

</details>

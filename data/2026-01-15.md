<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 1]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.CR](#cs.CR) [Total: 10]
- [cs.AI](#cs.AI) [Total: 17]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [Annotated PIM Bibliography](https://arxiv.org/abs/2601.09002)
*Peter M. Kogge*

Main category: cs.AR

TL;DR: 本文提供了处理内存（PIM）及相关技术的注释书目，涵盖60多年的发展历史，旨在补充即将发表的文章。


<details>
  <summary>Details</summary>
Motivation: 虽然PIM及相关技术最近被视为"革命性新技术"，但实际上许多相关技术可以追溯到60多年前。本文旨在提供一个全面的注释书目，覆盖整个时间范围，以纠正这种认知偏差。

Method: 作者通过整理和分析PIM技术的历史文献，创建一个按时间顺序组织的注释书目，涵盖PIM、CIM、LIM、IMC、NMC等相关概念。

Result: 提供了一个全面的PIM技术历史文献注释书目，展示了该技术60多年的发展历程，而非仅仅是近年来的创新。

Conclusion: PIM技术有着悠久的历史渊源，当前对其"革命性"的认知忽视了其长期发展历程。本文的注释书目为理解该技术的完整历史提供了重要参考。

Abstract: Processing in Memory (PIM) and similar terms such as Compute In Memory (CIM), Logic in Memory (LIM), In Memory Computing (IMC), and Near Memory Computing (NMC) have gained attention recently as a potentially ``revolutionary new'' technique. The truth, however, is that many examples of the technology go back over 60 years. This document attempts to provide an annotated bibliography of PIM technology that attempts to cover the whole time-frame, and is organized to augment a forth-coming article.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [2] [A Machine Learning Approach Towards Runtime Optimisation of Matrix Multiplication](https://arxiv.org/abs/2601.09114)
*Yufan Xia,Marco De La Pierre,Amanda S. Barnard,Giuseppe Maria Junior Barca*

Main category: cs.DC

TL;DR: 该论文提出了一种基于机器学习的GEMM多线程优化方法，通过实时选择最优线程数，在两种HPC架构上实现了25-40%的性能提升。


<details>
  <summary>Details</summary>
Motivation: GEMM是科学计算中的核心算法，单线程GEMM已有优化技术，但在现代多核共享内存系统中，确定最小化多线程GEMM运行时的线程数具有挑战性。

Method: 提出了ADSALA软件库的概念验证方法，使用机器学习优化BLAS例程性能。具体采用机器学习模型实时选择给定GEMM任务的最优线程数，基于收集的训练数据。

Result: 在两种不同的HPC节点架构（Intel Cascade Lake和AMD Zen 3）上测试，当GEMM内存使用在100MB以内时，相比传统BLAS中的GEMM实现获得了25%到40%的加速。

Conclusion: 机器学习方法可以有效优化多线程GEMM性能，ADSALA库的概念验证显示了在实际HPC架构上显著提升计算效率的潜力。

Abstract: The GEneral Matrix Multiplication (GEMM) is one of the essential algorithms in scientific computing. Single-thread GEMM implementations are well-optimised with techniques like blocking and autotuning. However, due to the complexity of modern multi-core shared memory systems, it is challenging to determine the number of threads that minimises the multi-thread GEMM runtime. We present a proof-of-concept approach to building an Architecture and Data-Structure Aware Linear Algebra (ADSALA) software library that uses machine learning to optimise the runtime performance of BLAS routines. More specifically, our method uses a machine learning model on-the-fly to automatically select the optimal number of threads for a given GEMM task based on the collected training data. Test results on two different HPC node architectures, one based on a two-socket Intel Cascade Lake and the other on a two-socket AMD Zen 3, revealed a 25 to 40 per cent speedup compared to traditional GEMM implementations in BLAS when using GEMM of memory usage within 100 MB.

</details>


### [3] [Transaction-Driven Dynamic Reconfiguration for Certificate-Based Payment Systems](https://arxiv.org/abs/2601.09146)
*Lingkang Shangguan*

Main category: cs.DC

TL;DR: 提出基于拜占庭一致性广播的交易驱动动态重配置协议，避免全局交易排序以实现高性能支付系统


<details>
  <summary>Details</summary>
Motivation: 现代支付系统需要高性能的动态重配置能力，同时避免全局交易排序带来的性能瓶颈

Method: 结合基于用户nonce的交易排序与周期性系统范围共识机制，设计PDCC（支付动态配置变更）协议

Result: PDCC协议能够实现平滑的重配置过程，且不影响原系统性能

Conclusion: 交易驱动的动态重配置协议为现代支付系统提供了高性能且不影响系统运行的重配置解决方案

Abstract: We present a transaction-driven dynamic reconfiguration protocol in Modern payment systems based on Byzantine Consistent Broadcast which can achieve high performance by avoiding global transaction ordering. We demonstrate the fundamental paradigm of modern payment systems, which combines user nonce based transactions ordering with periodic system-wide consensus mechanisms. Building on this foundation, we design PDCC(Payment Dynamic Config Change), which can lead a smooth reconfiguration process without impacting the original system's performance.

</details>


### [4] [LatencyPrism: Online Non-intrusive Latency Sculpting for SLO-Guaranteed LLM Inference](https://arxiv.org/abs/2601.09258)
*Du Yin,Jiayi Ren,Xiayu Sun,Tianyao Zhou,Haizhu Zhou,Ruiyan Ma,Danyang Zhang*

Main category: cs.DC

TL;DR: LatencyPrism是一个零侵入、多平台的延迟分析系统，用于实时监控LLM推理延迟，无需代码修改或服务重启，能在毫秒级触发警报并区分正常负载变化与异常问题。


<details>
  <summary>Details</summary>
Motivation: LLM推理延迟直接影响用户体验和运营成本，但在分布式推理环境中，由于软件框架和硬件架构的多样性以及动态工作负载，延迟分析变得困难。现有AI性能分析方法存在侵入性强、需要服务重启、无法适应异构环境等问题，难以满足实时生产分析需求。

Method: LatencyPrism采用零侵入设计，无需代码修改或服务重启，能够跨平台分析推理延迟。系统实现低开销的批量级实时监控，在毫秒级触发警报，并能区分工作负载驱动的延迟变化和表示潜在问题的异常。

Result: LatencyPrism已在数千个XPU上部署超过六个月，实现了低开销的实时监控，异常检测的F1分数达到0.98。系统能够有效区分正常延迟变化和异常情况，并支持根本原因分析。

Conclusion: LatencyPrism是首个零侵入、多平台的延迟分析系统，能够有效解决分布式LLM推理环境中的延迟监控问题，确保服务级别协议遵守，提升服务质量和运营效率。

Abstract: LLM inference latency critically determines user experience and operational costs, directly impacting throughput under SLO constraints. Even brief latency spikes degrade service quality despite acceptable average performance. However, distributed inference environments featuring diverse software frameworks and XPU architectures combined with dynamic workloads make latency analysis challenging. Constrained by intrusive designs that necessitate service restarts or even suspension, and by hardware-bound implementations that fail to adapt to heterogeneous inference environments, existing AI profiling methods are often inadequate for real-time production analysis.
  We present LatencyPrism, the first zero-intrusion multi-platform latency sculpting system. It aims to break down the inference latency across pipeline, proactively alert on inference latency anomalies, and guarantee adherence to SLOs, all without requiring code modifications or service restarts. LatencyPrism has been deployed across thousands of XPUs for over six months. It enables low-overhead real-time monitoring at batch level with alerts triggered in milliseconds. This approach distinguishes between workload-driven latency variations and anomalies indicating underlying issues with an F1-score of 0.98. We also conduct extensive experiments and investigations into root cause analysis to demonstrate LatencyPrism's capability.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [5] [Integrating APK Image and Text Data for Enhanced Threat Detection: A Multimodal Deep Learning Approach to Android Malware](https://arxiv.org/abs/2601.08959)
*Md Mashrur Arifin,Maqsudur Rahman,Nasir U. Eisty*

Main category: cs.CR

TL;DR: 本文提出了一种结合APK图像和文本特征的多模态深度学习框架，用于增强Android恶意软件检测。通过系统评估不同图像类型和分辨率，发现高分辨率RGB图像性能最佳，但图像与文本的多模态融合效果有限。


<details>
  <summary>Details</summary>
Motivation: 随着零日Android恶意软件攻击日益复杂，现有研究常忽略图像类型和分辨率对检测的影响，且忽视了APK中的文本数据（如权限和元数据），限制了全面捕捉恶意行为的能力。多模态融合方法有望解决这些局限性。

Method: 提出多模态深度学习框架，系统评估不同图像类型和分辨率，使用多种CNN架构（VGG、ResNet-152、MobileNet、DenseNet、EfficientNet-B4），并利用LLaMA-2大语言模型提取和标注文本特征，最后通过CLIP模型进行图像与文本的多模态融合。

Result: 高分辨率RGB图像（如256x256、512x512）在分类性能上表现最佳；图像与文本的多模态融合使用CLIP模型时显示出有限的潜力；系统评估图像属性和多模态数据集成对Android恶意软件检测的重要性得到验证。

Conclusion: 本研究强调了系统评估图像属性和集成多模态数据对于开发有效的Android系统恶意软件检测方法的重要性，为未来研究提供了有价值的见解。

Abstract: As zero-day Android malware attacks grow more sophisticated, recent research highlights the effectiveness of using image-based representations of malware bytecode to detect previously unseen threats. However, existing studies often overlook how image type and resolution affect detection and ignore valuable textual data in Android Application Packages (APKs), such as permissions and metadata, limiting their ability to fully capture malicious behavior. The integration of multimodality, which combines image and text data, has gained momentum as a promising approach to address these limitations. This paper proposes a multimodal deep learning framework integrating APK images and textual features to enhance Android malware detection. We systematically evaluate various image types and resolutions across different Convolutional Neural Networks (CNN) architectures, including VGG, ResNet-152, MobileNet, DenseNet, EfficientNet-B4, and use LLaMA-2, a large language model, to extract and annotate textual features for improved analysis. The findings demonstrate that RGB images at higher resolutions (e.g., 256x256, 512x512) achieve superior classification performance, while the multimodal integration of image and text using the CLIP model reveals limited potential. Overall, this research highlights the importance of systematically evaluating image attributes and integrating multimodal data to develop effective malware detection for Android systems.

</details>


### [6] [ABE-VVS: Attribute-Based Encrypted Volumetric Video Streaming](https://arxiv.org/abs/2601.08987)
*Mohammad Waquas Usmani,Susmit Shannigrahi,Michael Zink*

Main category: cs.CR

TL;DR: ABE-VVS框架通过属性基选择性坐标加密实现点云视频流DRM，仅加密部分坐标（X、Y、Z或其组合），降低计算开销同时保持有效视觉混淆。


<details>
  <summary>Details</summary>
Motivation: 传统点云视频流DRM方案需要加密整个点云帧，计算开销大且延迟高。需要一种轻量级但有效的DRM方案，既能保护内容安全，又能降低计算负担。

Method: 提出ABE-VVS框架，采用基于属性的选择性坐标加密。部署了点云视频流系统，评估三种ABE粒度：ABE-XYZ（加密所有坐标）、ABE-XY和ABE-X，并与HTTPS/TLS和HTTP-only基线对比。

Result: 仅加密X坐标即可实现有效混淆，加密和解密时间分别降低50%和80%。ABE方案将服务器端CPU负载降低80%，缓存CPU负载降低63%，与HTTP-only相当。ABE-X实现零缓冲，优于HTTPS。

Conclusion: ABE-VVS为点云视频流提供了一种轻量级有效的DRM方案，在保持安全性的同时显著降低计算开销，简化密钥撤销，消除每客户端加密需求，减少服务器和缓存负载。

Abstract: This work introduces ABE-VVS, a framework that performs attribute based selective coordinate encryption for point cloud based volumetric video streaming, enabling lightweight yet effective digital rights management (DRM). Rather than encrypting entire point cloud frames, our approach encrypts only selected subsets of coordinates ($X, Y, Z$, or combinations), lowering computational overhead and latency while still producing strong visual distortion that prevents meaningful unauthorized viewing. Our experiments show that encrypting only the $X$ coordinates achieves effective obfuscation while reducing encryption and decryption times by up to 50% and 80%, respectively, compared to full-frame encryption.
  To our knowledge, this is the first work to provide a novel end-to-end evaluation of a DRM-enabled secure point cloud streaming system. We deployed a point cloud video streaming setup on the CloudLab testbed and evaluated three HTTP-based Attribute-Based Encryption (ABE) granularities - ABE-XYZ (encrypting all $X,Y,Z$ coordinates), ABE-XY, and ABE-X against conventional HTTPS/TLS secure streaming as well as an HTTP-only baseline without any security. Our streaming evaluation demonstrates that ABE-based schemes reduce server-side CPU load by up to 80% and cache CPU load by up to 63%, comparable to HTTP-only, while maintaining similar cache hit rates. Moreover, ABE-XYZ and ABE-XY exhibit lower client-side rebuffering than HTTPS, and ABE-X achieves zero rebuffering comparable to HTTP-only. Although ABE-VVS increases client-side CPU usage, the overhead is not large enough to affect streaming quality and is offset by its broader benefits, including simplified key revocation, elimination of per-client encryption, and reduced server and cache load.

</details>


### [7] [StegoStylo: Squelching Stylometric Scrutiny through Steganographic Stitching](https://arxiv.org/abs/2601.09056)
*Robert Dilworth*

Main category: cs.CR

TL;DR: 论文探讨了文本风格分析（文体学）的双重用途：一方面可用于有益目的如版权保护和医疗诊断，另一方面也可被恶意用于隐私侵犯。研究提出了对抗性文体学与隐写术结合的方法来对抗文体分析系统。


<details>
  <summary>Details</summary>
Motivation: 文体学在版权保护、医疗诊断等方面有积极应用，但也可被用于去匿名化、重新识别、追踪等隐私侵犯目的。为了保护作者隐私，需要开发对抗文体分析的工具。

Method: 1. 增强对抗性攻击方法TraceTarnish，提高其混淆文体分析系统的能力；2. 研究隐写术嵌入技术，通过零宽度Unicode字符修改文本，量化作者风格指纹的掩蔽效果。

Result: 1. TraceTarnish能有效降低文体分析系统的归因和验证准确率；2. 当隐写术覆盖率达到33%或更高时，能确保作者身份混淆；3. 量化了文本修改比例与作者混淆程度的关系。

Conclusion: 文体学可能被滥用于隐私侵犯，因此需要像TraceTarnish这样的防御工具来保护作者隐私。对抗性文体学与隐写术结合能有效对抗文体分析系统。

Abstract: Stylometry--the identification of an author through analysis of a text's style (i.e., authorship attribution)--serves many constructive purposes: it supports copyright and plagiarism investigations, aids detection of harmful content, offers exploratory cues for certain medical conditions (e.g., early signs of dementia or depression), provides historical context for literary works, and helps uncover misinformation and disinformation. In contrast, when stylometry is employed as a tool for authorship verification--confirming whether a text truly originates from a claimed author--it can also be weaponized for malicious purposes. Techniques such as de-anonymization, re-identification, tracking, profiling, and downstream effects like censorship illustrate the privacy threats that stylometric analysis can enable. Building on these concerns, this paper further explores how adversarial stylometry combined with steganography can counteract stylometric analysis. We first present enhancements to our adversarial attack, $\textit{TraceTarnish}$, providing stronger evidence of its capacity to confound stylometric systems and reduce their attribution and verification accuracy. Next, we examine how steganographic embedding can be fine-tuned to mask an author's stylistic fingerprint, quantifying the level of authorship obfuscation achievable as a function of the proportion of words altered with zero-width Unicode characters. Based on our findings, steganographic coverage of 33% or higher seemingly ensures authorship obfuscation. Finally, we reflect on the ways stylometry can be used to undermine privacy and argue for the necessity of defensive tools like $\textit{TraceTarnish}$.

</details>


### [8] [Rigorous and Generalized Proof of Security of Bitcoin Protocol with Bounded Network Delay](https://arxiv.org/abs/2601.09082)
*Christopher Blake,Chen Feng,Xuechao Wang,Qianyu Yu*

Main category: cs.CR

TL;DR: 论文通过更严谨的数学证明验证了比特币协议的安全性，修正了先前研究中随机漫步理论的错误，证明了只要诚实矿工的全延迟挖矿率超过攻击者挖矿率，比特币协议就能无限产生诚实区块。


<details>
  <summary>Details</summary>
Motivation: 比特币协议的安全性证明需要更严谨的数学基础。先前研究中使用随机漫步理论的方法存在错误，需要通过更可靠的数学框架来验证比特币协议在对抗性环境下的安全性。

Method: 1. 建立计算模型，允许攻击者延迟区块传输时间Δ；2. 将协议推广到允许不同分数区块；3. 使用"穿孔区块到达过程"方法替代错误的随机漫步理论；4. 在更一般的模型中提供严格证明。

Result: 证明了只要诚实矿工的全延迟挖矿率超过攻击者挖矿率，比特币协议就能以概率1无限产生诚实区块。通过反例揭示了先前随机漫步理论方法的错误，并用穿孔区块到达过程方法修正了该错误。

Conclusion: 比特币协议的安全性得到了更严谨的数学证明。在允许攻击者延迟区块传输的对抗性环境中，只要诚实矿工的挖矿率（考虑完全延迟）超过攻击者挖矿率，协议就能保证无限产生诚实区块，确保了系统的长期安全性。

Abstract: A proof of the security of the Bitcoin protocol is made rigorous, and simplified in certain parts. A computational model in which an adversary can delay transmission of blocks by time $Δ$ is considered. The protocol is generalized to allow blocks of different scores and a proof within this more general model is presented. An approach used in a previous paper that used random walk theory is shown through a counterexample to be incorrect; an approach involving a punctured block arrival process is shown to remedy this error. Thus, it is proven that with probability one, the Bitcoin protocol will have infinitely many honest blocks so long as the fully-delayed honest mining rate exceeds the adversary mining rate.

</details>


### [9] [KryptoPilot: An Open-World Knowledge-Augmented LLM Agent for Automated Cryptographic Exploitation](https://arxiv.org/abs/2601.09129)
*Xiaonan Liu,Zhihao Li,Xiao Lan,Hao Ren,Haizhou Wang,Xingshu Chen*

Main category: cs.CR

TL;DR: KryptoPilot是一个面向密码学CTF挑战的开放世界知识增强LLM智能体，通过动态知识获取、结构化知识重用和治理子系统，显著提升了在复杂密码学攻击任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体在解决高难度密码学CTF挑战时效果不佳，主要原因是知识粒度不足而非推理能力限制。粗粒度或抽象的外部知识无法支持正确的攻击建模和实施。

Method: 提出KryptoPilot系统，包含三个核心组件：1) 通过深度研究管道实现动态开放世界知识获取；2) 用于结构化知识重用的持久工作空间；3) 通过行为约束和成本感知模型路由稳定推理的治理子系统。

Result: 在InterCode-CTF上实现完全解决率，在NYU-CTF基准测试中解决56-60%的密码学挑战，在真实CTF竞赛中成功解决33个密码学挑战中的26个，包括多个最早解决和唯一解决的实例。

Conclusion: 开放世界、细粒度知识增强和治理推理对于将基于LLM的智能体扩展到真实世界密码学攻击任务是必要的，KryptoPilot证明了这种方法的有效性。

Abstract: Capture-the-Flag (CTF) competitions play a central role in modern cybersecurity as a platform for training practitioners and evaluating offensive and defensive techniques derived from real-world vulnerabilities. Despite recent advances in large language models (LLMs), existing LLM-based agents remain ineffective on high-difficulty cryptographic CTF challenges, which require precise cryptanalytic knowledge, stable long-horizon reasoning, and disciplined interaction with specialized toolchains. Through a systematic exploratory study, we show that insufficient knowledge granularity, rather than model reasoning capacity, is a primary factor limiting successful cryptographic exploitation: coarse or abstracted external knowledge often fails to support correct attack modeling and implementation. Motivated by this observation, we propose KryptoPilot, an open-world knowledge-augmented LLM agent for automated cryptographic exploitation. KryptoPilot integrates dynamic open-world knowledge acquisition via a Deep Research pipeline, a persistent workspace for structured knowledge reuse, and a governance subsystem that stabilizes reasoning through behavioral constraints and cost-aware model routing. This design enables precise knowledge alignment while maintaining efficient reasoning across heterogeneous subtasks. We evaluate KryptoPilot on two established CTF benchmarks and in six real-world CTF competitions. KryptoPilot achieves a complete solve rate on InterCode-CTF, solves between 56 and 60 percent of cryptographic challenges on the NYU-CTF benchmark, and successfully solves 26 out of 33 cryptographic challenges in live competitions, including multiple earliest-solved and uniquely-solved instances. These results demonstrate the necessity of open-world, fine-grained knowledge augmentation and governed reasoning for scaling LLM-based agents to real-world cryptographic exploitation.

</details>


### [10] [Deep Learning-based Binary Analysis for Vulnerability Detection in x86-64 Machine Code](https://arxiv.org/abs/2601.09157)
*Mitchell Petingola*

Main category: cs.CR

TL;DR: 本文探索直接从x86-64机器码提取特征进行漏洞检测的可行性，发现基于图结构的模型优于序列模型，且机器码包含足够信息用于有效漏洞发现。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习漏洞检测研究主要依赖反汇编二进制文件，但反汇编需要更复杂的模型来捕获标记级上下文。机器码可能支持更高效、轻量级的模型，并保留反汇编过程中可能丢失的所有信息。

Method: 通过探索性研究，采用两种特定的深度学习模型架构（图模型和序列模型），在三种漏洞类型上系统评估其性能，直接从原始x86-64机器码提取特征。

Result: 基于图结构的模型在性能上始终优于序列模型，强调了控制流关系的重要性；机器码包含足够信息用于有效的漏洞发现。

Conclusion: 直接从机器码进行漏洞检测是可行的，图模型优于序列模型，控制流关系对漏洞检测至关重要，机器码保留了足够的信息用于有效的漏洞发现。

Abstract: While much of the current research in deep learning-based vulnerability detection relies on disassembled binaries, this paper explores the feasibility of extracting features directly from raw x86-64 machine code. Although assembly language is more interpretable for humans, it requires more complex models to capture token-level context. In contrast, machine code may enable more efficient, lightweight models and preserve all information that might be lost in disassembly. This paper approaches the task of vulnerability detection through an exploratory study on two specific deep learning model architectures and aims to systematically evaluate their performance across three vulnerability types. The results demonstrate that graph-based models consistently outperform sequential models, emphasizing the importance of control flow relationships, and that machine code contains sufficient information for effective vulnerability discovery.

</details>


### [11] [The Real Menace of Cloning Attacks on SGX Applications](https://arxiv.org/abs/2601.09273)
*Annika Wilde,Samira Briongos,Claudio Soriente,Ghassan Karame*

Main category: cs.CR

TL;DR: SGX等可信执行环境存在回滚和克隆攻击漏洞，本文研究发现约20%的SGX提案对克隆攻击不安全，包括依赖单调计数器的应用。


<details>
  <summary>Details</summary>
Motivation: 可信执行环境（如Intel SGX）在云环境中提供机密性，但存在回滚和克隆攻击漏洞。虽然回滚攻击已被广泛研究，但克隆攻击研究较少，需要填补这一研究空白。

Method: 对72个基于SGX的提案进行了广泛研究和深入分析，评估它们对克隆攻击的脆弱性。

Result: 研究发现约20%的分析提案对克隆攻击不安全，包括那些依赖单调计数器（通常被认为能防御回滚攻击）的应用。

Conclusion: 克隆攻击是SGX安全性的重要威胁，需要更多关注和研究，即使依赖单调计数器的应用也无法完全防御此类攻击。

Abstract: Trusted Execution Environments (TEEs) are gaining popularity as an effective means to provide confidentiality in the cloud. TEEs, such as Intel SGX, suffer from so-called rollback and cloning attacks (often referred to as forking attacks). Rollback attacks are enabled by the lack of freshness guarantees for sealed data; cloning attacks stem from the inability to determine if other instances of an enclave are running on the same platform. While rollback attacks have been extensively studied by the community, cloning attacks have been, unfortunately, less investigated. To address this gap, we extensively study and thoroughly analyze the susceptibility of 72 SGX-based proposals to cloning attacks. Our results show that roughly 20% of the analyzed proposals are insecure against cloning attacks-including those applications that rely on monotonic counters and are, therefore, secure against rollback attacks.

</details>


### [12] [Blue Teaming Function-Calling Agents](https://arxiv.org/abs/2601.09292)
*Greta Dolcetti,Giulio Zizzo,Sergio Maffeis*

Main category: cs.CR

TL;DR: 对四个声称具有函数调用能力的开源LLM进行对抗攻击测试，评估其鲁棒性，并测试八种防御措施的有效性


<details>
  <summary>Details</summary>
Motivation: 评估声称具有函数调用能力的开源大语言模型在实际对抗攻击下的安全性，检验现有防御措施的有效性

Method: 对四个开源LLM进行实验评估，使用三种不同的攻击方法测试其鲁棒性，同时测试八种不同防御措施的有效性

Result: 结果显示这些模型默认情况下并不安全，且现有防御措施在实际场景中尚不可用

Conclusion: 当前声称具有函数调用能力的开源LLM存在安全隐患，需要更强的安全机制和更有效的防御措施

Abstract: We present an experimental evaluation that assesses the robustness of four open source LLMs claiming function-calling capabilities against three different attacks, and we measure the effectiveness of eight different defences. Our results show how these models are not safe by default, and how the defences are not yet employable in real-world scenarios.

</details>


### [13] [CallShield: Secure Caller Authentication over Real-Time Audio Channels](https://arxiv.org/abs/2601.09327)
*Mouna Rabh,Yazan Boshmaf,Mashael Alsabah,Shammur Chowdhury,Mohamed Hefeeda,Issa Khalil*

Main category: cs.CR

TL;DR: CallShield是首个完全在音频层运行的来电身份认证系统，无需语音转录、互联网连接或可信基础设施，通过实时神经水印技术实现安全认证。


<details>
  <summary>Details</summary>
Motivation: 当前来电身份认证系统通常依赖语音转录、互联网连接或可信基础设施，存在隐私泄露和依赖性问题。需要一种在音频层直接运行、不依赖外部服务的安全认证方案。

Method: 1. 实时神经水印技术：在40毫秒的8kHz语音帧中实现逐比特嵌入和恢复；2. 低比特率数据链路协议：提供帧同步、错误检测、纠正和恢复；3. 轻量级对称密钥协议：基于可信联系人间的共享密钥进行认证。

Result: 1. 认证成功率：清洁音频超过99.2%，常见失真下超过95%；2. 认证时间：平均63秒（含最多3次重传）；3. 音频质量：PESQ评分>4.2，STOI评分>0.94；4. 鲁棒性：对各种信道失真具有良好适应性。

Conclusion: CallShield证明了在音频层实现实时、安全来电身份认证的可行性，无需依赖语音转录或互联网连接，具有高成功率、良好音频质量和实际部署的实用性。

Abstract: We present CallShield, the first caller identity authentication system that operates entirely at the audio layer, without relying on speech transcription, internet connectivity, or trusted infrastructure. CallShield introduces a real-time neural watermarking technique that enables per-bit embedding and recovery within 40-millisecond frames of live 8 kHz speech. This capability allows CallShield to transform the real-time audio channel into a noisy serial communication medium. To ensure reliable data transmission, CallShield implements a low-bitrate data link protocol that provides basic frame synchronization along with error detection, correction, and recovery. For caller authentication, CallShield adopts a secure and lightweight symmetric-key protocol that relies on pairwise shared secrets among trusted contacts. The system completes the full authentication process in an average of 63 seconds, including up to three retransmission attempts, making it suitable for real-time deployment. Extensive experiments under realistic telephony conditions demonstrate that CallShield achieves an overall authentication success rates exceeding 99.2% on clean audio and over 95% under common distortions, aided by selective retransmission of failed messages. Additionally, CallShield maintains high audio quality, achieving PESQ scores above 4.2 and STOI scores above 0.94 on clean speech, and exhibits robustness across a wide range of channel distortions, validating its practical viability for secure, real-time caller authentication.

</details>


### [14] [A Systematic Security Analysis for Path-based Traceability Systems in RFID-Enabled Supply Chains](https://arxiv.org/abs/2601.09407)
*Fokke Heikamp,Lei Pan,Robin Doss,Rolando Trujillo-Rasua,Sushmita Ruj*

Main category: cs.CR

TL;DR: 该研究系统分析了供应链追溯系统的安全漏洞，通过构建统一安全框架评估了17种追溯解决方案，发现现有方案的安全需求往往不完整，存在关键漏洞未解决


<details>
  <summary>Details</summary>
Motivation: 随着RFID和物联网技术的发展，追溯系统在供应链中广泛应用，用于产品召回、防伪防篡改等。但这些系统本身成为攻击目标，攻击者可能篡改产品追溯信息，使系统接受假冒产品。现有追溯解决方案的安全需求往往缺乏结构化或完整性，导致关键漏洞未被解决

Method: 研究构建了一个统一的安全框架，将当前最先进的追溯解决方案特性综合到该框架中，用于分析和比较它们的安全声明。使用该框架客观比较了17种追溯解决方案的安全性，识别弱点和漏洞

Result: 研究识别了多种安全缺陷和漏洞，包括攻击者可能通过篡改追溯信息使系统接受假冒产品的问题。这是首次对追溯解决方案进行大规模安全评估

Conclusion: 现有追溯系统的安全需求往往不完整，存在结构化不足的问题，导致关键安全漏洞未被解决。研究提出的安全框架为分析和比较追溯解决方案提供了系统方法，有助于改进供应链追溯系统的安全性

Abstract: Traceability systems have become prevalent in supply chains because of the rapid development of RFID and IoT technologies. These systems facilitate product recall and mitigate problems such as counterfeiting, tampering, and theft by tracking the manufacturing and distribution life-cycle of a product. Therefore, traceability systems are a defense mechanism against supply chain attacks and, consequently, have become a target for attackers to circumvent. For example, a counterfeiter may change the trace of a fake product for the trace of an authentic product, fooling the system into accepting a counterfeit product as legit and thereby giving a false sense of security.
  This systematic analysis starts with the observation that security requirements in existing traceability solutions are often unstructured or incomplete, leaving critical vulnerabilities unaddressed. We synthesized the properties of current state-of-the-art traceability solutions within a single security framework that allows us to analyze and compare their security claims. Using this framework, we objectively compared the security of $17$ traceability solutions and identified several weaknesses and vulnerabilities. This article reports on these flaws, the methodology we used to identify them, and the first security evaluation of traceability solutions on a large scale.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [15] [ConvoLearn: A Dataset of Constructivist Tutor-Student Dialogue](https://arxiv.org/abs/2601.08950)
*Mayank Sharma,Roy Pea,Hari Subramonyam*

Main category: cs.AI

TL;DR: 本文针对教育应用中LLMs的局限性，提出了基于知识建构理论的ConvoLearn数据集，通过微调显著提升了LLM在对话式教学中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前教育应用中的大型语言模型存在根本性教学局限，倾向于直接提供答案而非支持对话式学习，缺乏有效的知识建构能力。

Method: 基于知识建构理论构建ConvoLearn数据集，包含1250个中学地球科学领域的师生对话，涵盖六个核心教学维度。通过人类教师与模拟学生的受控交互创建半合成数据集，使用QLoRA对Mistral 7B进行微调。

Result: 微调后的Mistral 7B（M=4.10，SD=1.03）在31名教师的评估中显著优于其基础版本（M=2.59，SD=1.11）和Claude Sonnet 4.5（M=2.87，SD=1.29），有效推动了LLM向知识建构策略的转变。

Conclusion: 这项工作为未来建构主义AI导师的开发和评估建立了一个潜在框架，证明了通过针对性数据集训练可以显著改善LLM的教学行为。

Abstract: In educational applications, LLMs exhibit several fundamental pedagogical limitations, such as their tendency to reveal solutions rather than support dialogic learning. We introduce ConvoLearn (https://huggingface.co/datasets/masharma/convolearn ), a dataset grounded in knowledge building theory that operationalizes six core pedagogical dimensions: cognitive engagement, formative assessment, accountability, cultural responsiveness, metacognition, and power dynamics. We construct a semi-synthetic dataset of 1250 tutor-student dialogues (20 turns each) in middle school Earth Science through controlled interactions between human teachers and a simulated student. Using QLoRA, we demonstrate that training on this dataset meaningfully shifts LLM behavior toward knowledge-building strategies. Human evaluation by 31 teachers shows our fine-tuned Mistral 7B (M = 4.10, SD = 1.03) significantly outperforms both its base version (M = 2.59, SD = 1.11) and Claude Sonnet 4.5 (M = 2.87, SD = 1.29) overall. This work establishes a potential framework to guide future development and evaluation of constructivist AI tutors.

</details>


### [16] [The Hierarchy of Agentic Capabilities: Evaluating Frontier Models on Realistic RL Environments](https://arxiv.org/abs/2601.09032)
*Logan Ritchie,Sushant Mehta,Nick Heiner,Mason Yu,Edwin Chen*

Main category: cs.AI

TL;DR: 该研究评估了前沿AI模型在电商环境中的150个职场任务表现，揭示了模型必须掌握的五个能力层级，发现即使最佳模型也有约40%的任务失败率。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的智能体发展，AI评估需要从单轮响应评估转向交互环境中的多步骤任务完成评估。研究旨在评估前沿AI模型在真实电商工作环境中的实际表现。

Method: 在Surge提供的真实电商强化学习环境中，对前沿AI模型进行了150个职场任务的实证研究。引入了以任务为中心的环境设计方法，强调多样性和领域专家贡献。

Result: 研究发现了一个经验推导的智能体能力层级：工具使用、规划与目标形成、适应性、基础性、常识推理。最佳模型仍有约40%的任务失败率，较弱模型在基础工具使用和规划上挣扎，较强模型主要在需要超越明确指令的上下文推理任务上失败。

Conclusion: 虽然当前前沿模型能展示连贯的多步骤行为，但在真实职场环境中实现人类水平的任务完成仍存在显著能力差距。研究为智能体开发提供了详细失败分析和设计方法学启示。

Abstract: The advancement of large language model (LLM) based agents has shifted AI evaluation from single-turn response assessment to multi-step task completion in interactive environments. We present an empirical study evaluating frontier AI models on 150 workplace tasks within a realistic e-commerce RL environment from Surge. Our analysis reveals an empirically-derived \emph{hierarchy of agentic capabilities} that models must master for real-world deployment: (1) tool use, (2) planning and goal formation, (3) adaptability, (4) groundedness, and (5) common-sense reasoning. Even the best-performing models fail approximately 40\% of the tasks, with failures clustering predictably along this hierarchy. Weaker models struggle with fundamental tool use and planning, whereas stronger models primarily fail on tasks requiring contextual inference beyond explicit instructions. We introduce a task-centric design methodology for RL environments that emphasizes diversity and domain expert contributions, provide detailed failure analysis, and discuss implications for agent development. Our findings suggest that while current frontier models can demonstrate coherent multi-step behavior, substantial capability gaps remain before achieving human-level task completion in realistic workplace settings.

</details>


### [17] [Programming over Thinking: Efficient and Robust Multi-Constraint Planning](https://arxiv.org/abs/2601.09097)
*Derrick Goh Xin Deik,Quanyu Long,Zhengyuan Liu,Nancy F. Chen,Wenya Wang*

Main category: cs.AI

TL;DR: SCOPE框架通过分离推理与代码执行，解决了多约束规划中LLM方法的局限性，实现了高效、可重用且成本更低的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法在多约束规划中存在根本性局限：纯推理范式容易产生不一致性、错误积累和高成本；结合编码或求解器的方法缺乏灵活性，无法捕捉跨问题的通用逻辑。

Method: 提出SCOPE框架，将查询特定推理与通用代码执行解耦，通过分离推理和执行来生成一致、确定且可重用的求解器函数，仅需对输入参数进行最小更改。

Result: SCOPE在TravelPlanner任务上达到93.1%的成功率，比最佳基线（CoT）提升61.6%，同时将推理成本降低1.4倍，时间减少约4.67倍。

Conclusion: SCOPE通过解耦推理与执行，解决了多约束规划中LLM方法的根本限制，实现了高性能、低成本、低延迟且可重用的解决方案。

Abstract: Multi-constraint planning involves identifying, evaluating, and refining candidate plans while satisfying multiple, potentially conflicting constraints. Existing large language model (LLM) approaches face fundamental limitations in this domain. Pure reasoning paradigms, which rely on long natural language chains, are prone to inconsistency, error accumulation, and prohibitive cost as constraints compound. Conversely, LLMs combined with coding- or solver-based strategies lack flexibility: they often generate problem-specific code from scratch or depend on fixed solvers, failing to capture generalizable logic across diverse problems. To address these challenges, we introduce the Scalable COde Planning Engine (SCOPE), a framework that disentangles query-specific reasoning from generic code execution. By separating reasoning from execution, SCOPE produces solver functions that are consistent, deterministic, and reusable across queries while requiring only minimal changes to input parameters. SCOPE achieves state-of-the-art performance while lowering cost and latency. For example, with GPT-4o, it reaches 93.1% success on TravelPlanner, a 61.6% gain over the best baseline (CoT) while cutting inference cost by 1.4x and time by ~4.67x. Code is available at https://github.com/DerrickGXD/SCOPE.

</details>


### [18] [DScheLLM: Enabling Dynamic Scheduling through a Fine-Tuned Dual-System Large language Model](https://arxiv.org/abs/2601.09100)
*Lixiang Zhang,Chenggong Zhao,Qing Gao,Xiaoke Zhao,Gengyi Bai,Jinhu Lv*

Main category: cs.AI

TL;DR: DScheLLM：基于双系统推理架构的LLM动态调度方法，通过微调大语言模型处理生产调度中的动态扰动


<details>
  <summary>Details</summary>
Motivation: 传统生产调度方法对动态扰动（如加工时间变化、机器可用性变化、意外任务插入）适应性差，依赖特定事件模型和显式分析公式，难以泛化到未见过的扰动情况

Method: 提出DScheLLM方法，构建基于大语言模型的统一框架处理动态事件，采用双系统（快速-慢速）推理架构。使用运筹学求解器获得的精确调度生成训练数据集，基于华为OpenPangu Embedded-7B模型，采用LoRA技术进行混合推理范式微调

Result: 在标准作业车间调度基准测试中，快速思维模式能高效生成高质量调度方案，慢速思维模式能产生与求解器兼容且格式良好的决策输入

Conclusion: 这是最早将大语言模型应用于动态环境作业车间调度的研究之一，展示了LLM在智能自适应调度优化中的巨大潜力

Abstract: Production scheduling is highly susceptible to dynamic disruptions, such as variations in processing times, machine availability, and unexpected task insertions. Conventional approaches typically rely on event-specific models and explicit analytical formulations, which limits their adaptability and generalization across previously unseen disturbances. To overcome these limitations, this paper proposes DScheLLM, a dynamic scheduling approach that leverages fine-tuned large language models within a dual-system (fast-slow) reasoning architecture to address disturbances of different scales. A unified large language model-based framework is constructed to handle dynamic events, where training datasets for both fast and slow reasoning modes are generated using exact schedules obtained from an operations research solver. The Huawei OpenPangu Embedded-7B model is subsequently fine-tuned under the hybrid reasoning paradigms using LoRA. Experimental evaluations on standard job shop scheduling benchmarks demonstrate that the fast-thinking mode can efficiently generate high-quality schedules and the slow-thinking mode can produce solver-compatible and well-formatted decision inputs. To the best of our knowledge, this work represents one of the earliest studies applying large language models to job shop scheduling in dynamic environments, highlighting their considerable potential for intelligent and adaptive scheduling optimization.

</details>


### [19] [AviationLMM: A Large Multimodal Foundation Model for Civil Aviation](https://arxiv.org/abs/2601.09105)
*Wenbin Li,Jingling Wu,Xiaoyong Lin. Jing Chen,Cong Chen*

Main category: cs.AI

TL;DR: 提出AviationLMM大型多模态基础模型，旨在统一民航异构数据流，实现理解、推理、生成和智能体应用，以解决现有AI方案孤立、单模态的局限性。


<details>
  <summary>Details</summary>
Motivation: 民航是全球交通和商业的基石，但现有AI解决方案在民航领域存在孤立和狭窄的问题，专注于单一任务或单模态，难以整合语音通信、雷达轨迹、传感器流和文本报告等异构数据，限制了态势感知、适应性和实时决策支持能力。

Method: 提出AviationLMM模型架构，能够处理多模态输入（空地语音、监视数据、机载遥测、视频和结构化文本），执行跨模态对齐和融合，并产生灵活输出（从态势摘要、风险预警到预测性诊断和多模态事件重建）。

Result: 提出了实现该愿景所需解决的关键研究机会，包括数据获取、对齐与融合、预训练、推理、可信度、隐私保护、缺失模态鲁棒性和合成场景生成等挑战。

Conclusion: 通过阐述AviationLMM的设计和挑战，旨在推动民航基础模型的发展，并促进研究界共同努力，构建一个集成、可信且保护隐私的民航AI生态系统。

Abstract: Civil aviation is a cornerstone of global transportation and commerce, and ensuring its safety, efficiency and customer satisfaction is paramount. Yet conventional Artificial Intelligence (AI) solutions in aviation remain siloed and narrow, focusing on isolated tasks or single modalities. They struggle to integrate heterogeneous data such as voice communications, radar tracks, sensor streams and textual reports, which limits situational awareness, adaptability, and real-time decision support. This paper introduces the vision of AviationLMM, a Large Multimodal foundation Model for civil aviation, designed to unify the heterogeneous data streams of civil aviation and enable understanding, reasoning, generation and agentic applications. We firstly identify the gaps between existing AI solutions and requirements. Secondly, we describe the model architecture that ingests multimodal inputs such as air-ground voice, surveillance, on-board telemetry, video and structured texts, and performs cross-modal alignment and fusion, and produces flexible outputs ranging from situation summaries and risk alerts to predictive diagnostics and multimodal incident reconstructions. In order to fully realize this vision, we identify key research opportunities to address, including data acquisition, alignment and fusion, pretraining, reasoning, trustworthiness, privacy, robustness to missing modalities, and synthetic scenario generation. By articulating the design and challenges of AviationLMM, we aim to boost the civil aviation foundation model progress and catalyze coordinated research efforts toward an integrated, trustworthy and privacy-preserving aviation AI ecosystem.

</details>


### [20] [The AI Hippocampus: How Far are We From Human Memory?](https://arxiv.org/abs/2601.09113)
*Zixia Jia,Jiaqi Li,Yipeng Kang,Yuxuan Wang,Tong Wu,Quansen Wang,Xiaobo Wang,Shuyi Zhang,Junzhe Shen,Qing Li,Siyuan Qi,Yitao Liang,Di He,Zilong Zheng,Song-Chun Zhu*

Main category: cs.AI

TL;DR: 本文综述了大型语言模型和多模态大语言模型中的记忆机制，将其分为隐性、显性和智能体记忆三种范式，探讨了跨模态记忆整合的关键架构进展和挑战。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型从静态预测器向能够持续学习和个性化推理的交互式系统转变，记忆机制已成为其架构和功能演化的核心主题。本文旨在对LLMs和MLLMs中的记忆研究进行全面系统的梳理，为这一快速发展领域提供结构化的知识框架。

Method: 采用文献综述方法，将现有研究组织为统一的分类体系：1) 隐性记忆 - 预训练transformer内部参数中嵌入的知识；2) 显性记忆 - 外部存储和检索组件；3) 智能体记忆 - 自主智能体中的持久性时间扩展记忆结构。同时考察多模态环境下的记忆整合。

Result: 提出了一个包含三种主要记忆范式的分类框架：隐性记忆涉及模型内部知识的解释、操作和重构；显性记忆通过可查询知识表示实现可扩展和可更新的信息交互；智能体记忆支持长期规划、自我一致性和多智能体协作。识别了跨模态记忆整合的关键需求。

Conclusion: 记忆机制对于增强大语言模型和多模态大语言模型的推理能力、适应性和上下文保真度具有基础性作用。未来研究需要解决记忆容量、对齐、事实一致性和跨系统互操作性等开放挑战，特别是在多模态环境中保持跨视觉、语言、音频和行动模态的一致性。

Abstract: Memory plays a foundational role in augmenting the reasoning, adaptability, and contextual fidelity of modern Large Language Models and Multi-Modal LLMs. As these models transition from static predictors to interactive systems capable of continual learning and personalized inference, the incorporation of memory mechanisms has emerged as a central theme in their architectural and functional evolution. This survey presents a comprehensive and structured synthesis of memory in LLMs and MLLMs, organizing the literature into a cohesive taxonomy comprising implicit, explicit, and agentic memory paradigms. Specifically, the survey delineates three primary memory frameworks. Implicit memory refers to the knowledge embedded within the internal parameters of pre-trained transformers, encompassing their capacity for memorization, associative retrieval, and contextual reasoning. Recent work has explored methods to interpret, manipulate, and reconfigure this latent memory. Explicit memory involves external storage and retrieval components designed to augment model outputs with dynamic, queryable knowledge representations, such as textual corpora, dense vectors, and graph-based structures, thereby enabling scalable and updatable interaction with information sources. Agentic memory introduces persistent, temporally extended memory structures within autonomous agents, facilitating long-term planning, self-consistency, and collaborative behavior in multi-agent systems, with relevance to embodied and interactive AI. Extending beyond text, the survey examines the integration of memory within multi-modal settings, where coherence across vision, language, audio, and action modalities is essential. Key architectural advances, benchmark tasks, and open challenges are discussed, including issues related to memory capacity, alignment, factual consistency, and cross-system interoperability.

</details>


### [21] [Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing](https://arxiv.org/abs/2601.09282)
*Leszek Sliwko,Jolanta Mizeria-Pietraszko*

Main category: cs.AI

TL;DR: 该论文提出了一种基于自然语言处理的语义化意图驱动调度范式，通过LLM解析自然语言分配提示注释来实现集群工作负载的软亲和性偏好配置，显著简化了复杂的集群配置工作。


<details>
  <summary>Details</summary>
Motivation: 集群工作负载分配通常需要复杂的配置，造成了可用性差距。传统配置方式对用户不友好，需要专业知识和繁琐的配置步骤，限制了集群系统的易用性和可访问性。

Method: 采用基于自然语言处理的语义化意图驱动调度范式，将大型语言模型（LLM）通过Kubernetes调度器扩展器集成到集群系统中。系统包含集群状态缓存和意图分析器（使用AWS Bedrock），能够解释自然语言分配提示注释以实现软亲和性偏好。

Result: 实证评估显示，顶级模型（如Amazon Nova Pro/Premier和Mistral Pixtral Large）的LLM解析准确率超过95%（在评估基准数据集上的子集准确率），显著优于基线引擎。在六个场景的调度质量测试中，原型系统实现了优于或等同于标准Kubernetes配置的放置效果，特别是在复杂和定量场景以及处理冲突的软偏好方面表现突出。

Conclusion: 该研究验证了使用LLM进行可访问调度的可行性，确认了语义化软亲和性简化工作负载编排的实用性。但同时也指出了同步LLM延迟等限制，建议采用异步处理以实现生产就绪。这项工作为简化集群工作负载编排提供了新的技术路径。

Abstract: Cluster workload allocation often requires complex configurations, creating a usability gap. This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. The system employs a Large Language Model (LLM) integrated via a Kubernetes scheduler extender to interpret natural language allocation hint annotations for soft affinity preferences. A prototype featuring a cluster state cache and an intent analyzer (using AWS Bedrock) was developed. Empirical evaluation demonstrated high LLM parsing accuracy (>95% Subset Accuracy on an evaluation ground-truth dataset) for top-tier models like Amazon Nova Pro/Premier and Mistral Pixtral Large, significantly outperforming a baseline engine. Scheduling quality tests across six scenarios showed the prototype achieved superior or equivalent placement compared to standard Kubernetes configurations, particularly excelling in complex and quantitative scenarios and handling conflicting soft preferences. The results validate using LLMs for accessible scheduling but highlight limitations like synchronous LLM latency, suggesting asynchronous processing for production readiness. This work confirms the viability of semantic soft affinity for simplifying workload orchestration.

</details>


### [22] [Position on LLM-Assisted Peer Review: Addressing Reviewer Gap through Mentoring and Feedback](https://arxiv.org/abs/2601.09182)
*JungMin Yun,JuneHyoung Kwon,MiHyeon Kim,YoungBin Kim*

Main category: cs.AI

TL;DR: 本文提出以LLM辅助人类审稿人的新范式，而非自动生成审稿意见，旨在解决AI研究快速发展带来的审稿人缺口问题，提升同行评审的可持续性。


<details>
  <summary>Details</summary>
Motivation: AI研究的快速扩张加剧了"审稿人缺口"，威胁同行评审的可持续性，并导致低质量评审的恶性循环。现有使用LLM自动生成审稿意见的方法存在不足，需要范式转变。

Method: 提出以LLM作为辅助和教育人类审稿人的工具，定义高质量同行评审的核心原则，并基于此设计两个互补系统：1）LLM辅助的导师系统，培养审稿人长期能力；2）LLM辅助的反馈系统，帮助审稿人改进评审质量。

Result: 本文提出了一个以人为中心的框架，通过LLM辅助系统来增强审稿人专业知识，为构建更可持续的学术生态系统做出贡献。

Conclusion: 需要从LLM自动生成审稿意见转向LLM辅助人类审稿人的范式转变，通过培养审稿人能力和改进评审质量，解决审稿人缺口问题，建立更可持续的同行评审体系。

Abstract: The rapid expansion of AI research has intensified the Reviewer Gap, threatening the peer-review sustainability and perpetuating a cycle of low-quality evaluations. This position paper critiques existing LLM approaches that automatically generate reviews and argues for a paradigm shift that positions LLMs as tools for assisting and educating human reviewers. We define the core principles of high-quality peer review and propose two complementary systems grounded in these foundations: (i) an LLM-assisted mentoring system that cultivates reviewers' long-term competencies, and (ii) an LLM-assisted feedback system that helps reviewers refine the quality of their reviews. This human-centered approach aims to strengthen reviewer expertise and contribute to building a more sustainable scholarly ecosystem.

</details>


### [23] [MAXS: Meta-Adaptive Exploration with LLM Agents](https://arxiv.org/abs/2601.09259)
*Jian Zhang,Zhiyuan Wang,Zhangqi Wang,Yu He,Haoran Luo,li yuan,Lingling Zhang,Rui Mao,Qika Lin,Jun Liu*

Main category: cs.AI

TL;DR: MAXS是一个基于LLM Agent的元自适应推理框架，通过前瞻策略和轨迹收敛机制解决推理过程中的局部短视和轨迹不稳定问题，在多个模型和数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM Agent推理方法存在两个主要问题：1）局部短视生成，缺乏前瞻性；2）轨迹不稳定，早期小错误会导致推理路径发散。这些问题使得难以平衡全局有效性和计算效率。

Method: MAXS采用元自适应推理框架，整合工具执行和推理规划。使用前瞻策略向前扩展推理步骤，估计工具使用的优势值，结合步骤一致性方差和步骤间趋势斜率来选择稳定、一致、高价值的推理步骤。引入轨迹收敛机制，在路径一致性达成时停止进一步扩展，平衡资源效率和全局有效性。

Result: 在三个基础模型（MiMo-VL-7B、Qwen2.5-VL-7B、Qwen2.5-VL-32B）和五个数据集上的广泛实证研究表明，MAXS在性能和推理效率方面始终优于现有方法。进一步分析证实了前瞻策略和工具使用的有效性。

Conclusion: MAXS通过前瞻策略和轨迹收敛机制有效解决了LLM Agent推理中的局部短视和轨迹不稳定问题，实现了资源效率和全局有效性的平衡，在多工具推理任务中表现出色。

Abstract: Large Language Model (LLM) Agents exhibit inherent reasoning abilities through the collaboration of multiple tools. However, during agent inference, existing methods often suffer from (i) locally myopic generation, due to the absence of lookahead, and (ii) trajectory instability, where minor early errors can escalate into divergent reasoning paths. These issues make it difficult to balance global effectiveness and computational efficiency. To address these two issues, we propose meta-adaptive exploration with LLM agents https://github.com/exoskeletonzj/MAXS, a meta-adaptive reasoning framework based on LLM Agents that flexibly integrates tool execution and reasoning planning. MAXS employs a lookahead strategy to extend reasoning paths a few steps ahead, estimating the advantage value of tool usage, and combines step consistency variance and inter-step trend slopes to jointly select stable, consistent, and high-value reasoning steps. Additionally, we introduce a trajectory convergence mechanism that controls computational cost by halting further rollouts once path consistency is achieved, enabling a balance between resource efficiency and global effectiveness in multi-tool reasoning. We conduct extensive empirical studies across three base models (MiMo-VL-7B, Qwen2.5-VL-7B, Qwen2.5-VL-32B) and five datasets, demonstrating that MAXS consistently outperforms existing methods in both performance and inference efficiency. Further analysis confirms the effectiveness of our lookahead strategy and tool usage.

</details>


### [24] [Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models](https://arxiv.org/abs/2601.09260)
*Yan Liu,Feng Zhang,Zhanyu Ma,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He,Han Liu,Yangdong Deng*

Main category: cs.AI

TL;DR: CoT-Flow将离散推理步骤重构为连续概率流，量化每个步骤对正确答案的贡献，实现流引导解码和流强化学习，在推理效率和性能间取得更好平衡


<details>
  <summary>Details</summary>
Motivation: 当前思维链方法将推理过程视为不可分割的序列，缺乏量化逐步信息增益的内在机制，导致推理效率低下（冗余探索）和优化困难（稀疏监督或昂贵验证器）

Method: CoT-Flow框架将离散推理步骤重构为连续概率流，量化每个步骤对正确答案的贡献。基于此实现两种方法：流引导解码（贪婪流解码策略提取信息高效推理路径）和流强化学习（构建无验证器的密集奖励函数）

Result: 在具有挑战性的基准测试中，CoT-Flow在推理效率和推理性能之间实现了优越的平衡

Conclusion: CoT-Flow通过将推理步骤量化为连续概率流，解决了当前思维链方法的粒度缺陷，为高效推理提供了新的框架

Abstract: High-quality chain-of-thought has demonstrated strong potential for unlocking the reasoning capabilities of large language models. However, current paradigms typically treat the reasoning process as an indivisible sequence, lacking an intrinsic mechanism to quantify step-wise information gain. This granularity gap manifests in two limitations: inference inefficiency from redundant exploration without explicit guidance, and optimization difficulty due to sparse outcome supervision or costly external verifiers. In this work, we propose CoT-Flow, a framework that reconceptualizes discrete reasoning steps as a continuous probabilistic flow, quantifying the contribution of each step toward the ground-truth answer. Built on this formulation, CoT-Flow enables two complementary methodologies: flow-guided decoding, which employs a greedy flow-based decoding strategy to extract information-efficient reasoning paths, and flow-based reinforcement learning, which constructs a verifier-free dense reward function. Experiments on challenging benchmarks demonstrate that CoT-Flow achieves a superior balance between inference efficiency and reasoning performance.

</details>


### [25] [Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants](https://arxiv.org/abs/2601.09264)
*Ziyi Shi,Xusen Guo,Hongliang Lu,Mingxing Peng,Haotian Wang,Zheng Zhu,Zhenning Li,Yuxuan Liang,Xinhu Zheng,Hai Yang*

Main category: cs.AI

TL;DR: 本文提出一个基于大语言模型的多智能体政策制定框架，用于实现跨行政区域的协调主动疫情控制，通过模拟验证可显著降低感染和死亡人数。


<details>
  <summary>Details</summary>
Motivation: 现有疫情控制政策通常是碎片化和反应式的，各区域独立制定政策，只在疫情升级后才调整，缺乏主动干预和全球协调，导致防控效果受限。

Method: 为每个行政区域分配一个LLM智能体作为AI政策制定助手，智能体基于区域特定的流行病学动态进行推理，同时与其他智能体通信以考虑跨区域相互依赖性，整合真实世界数据、疫情演化模拟器和结构化智能体间通信，通过闭环模拟过程共同探索反事实干预场景并合成协调政策决策。

Result: 使用美国2020年4月至12月州级COVID-19数据、真实流动记录和观察到的政策干预进行验证，相比真实世界疫情结果，该方法在单个州层面可将累计感染和死亡分别降低63.7%和40.1%，在跨州聚合层面分别降低39.0%和27.0%。

Conclusion: LLM多智能体系统能够通过协调政策制定实现更有效的疫情控制，为公共卫生危机管理提供了新的技术框架。

Abstract: Effective pandemic control requires timely and coordinated policymaking across administrative regions that are intrinsically interdependent. However, human-driven responses are often fragmented and reactive, with policies formulated in isolation and adjusted only after outbreaks escalate, undermining proactive intervention and global pandemic mitigation. To address this challenge, here we propose a large language model (LLM) multi-agent policymaking framework that supports coordinated and proactive pandemic control across regions. Within our framework, each administrative region is assigned an LLM agent as an AI policymaking assistant. The agent reasons over region-specific epidemiological dynamics while communicating with other agents to account for cross-regional interdependencies. By integrating real-world data, a pandemic evolution simulator, and structured inter-agent communication, our framework enables agents to jointly explore counterfactual intervention scenarios and synthesize coordinated policy decisions through a closed-loop simulation process. We validate the proposed framework using state-level COVID-19 data from the United States between April and December 2020, together with real-world mobility records and observed policy interventions. Compared with real-world pandemic outcomes, our approach reduces cumulative infections and deaths by up to 63.7% and 40.1%, respectively, at the individual state level, and by 39.0% and 27.0%, respectively, when aggregated across states. These results demonstrate that LLM multi-agent systems can enable more effective pandemic control with coordinated policymaking...

</details>


### [26] [RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering](https://arxiv.org/abs/2601.09269)
*Wencheng Ye,Liang Peng,Xiaoyang Yuan,Yi Bin,Pengpeng Zeng,Hengyu Jin,Heng Tao Shen*

Main category: cs.AI

TL;DR: RISER是一种基于路由器的激活空间干预框架，通过动态组合可复用推理向量来提升LLM推理能力，相比基础模型提升3.4-6.5%准确率，比思维链推理token效率高2-3倍。


<details>
  <summary>Details</summary>
Motivation: 现有领域特定推理方法通常需要参数更新，而激活引导方法使用静态手动干预，无法适应复杂推理的动态特性。需要一种能够自适应引导LLM推理的参数高效方法。

Method: 提出RISER框架：1)构建可复用推理向量库；2)使用轻量级路由器动态组合这些向量；3)通过强化学习在任务级奖励下优化路由器，以涌现和组合方式激活潜在认知原语。

Result: 在7个多样化基准测试中，RISER相比基础模型平均零样本准确率提升3.4-6.5%，超越思维链推理且token效率高2-3倍，同时保持稳健的准确率增益。

Conclusion: RISER能够自主组合多个向量形成可解释的精确控制策略，指向更可控和高效的LLM推理方向，展示了自适应激活引导在提升推理能力方面的潜力。

Abstract: Recent work on domain-specific reasoning with large language models (LLMs) often relies on training-intensive approaches that require parameter updates. While activation steering has emerged as a parameter efficient alternative, existing methods apply static, manual interventions that fail to adapt to the dynamic nature of complex reasoning. To address this limitation, we propose RISER (Router-based Intervention for Steerable Enhancement of Reasoning), a plug-and-play intervention framework that adaptively steers LLM reasoning in activation space. RISER constructs a library of reusable reasoning vectors and employs a lightweight Router to dynamically compose them for each input. The Router is optimized via reinforcement learning under task-level rewards, activating latent cognitive primitives in an emergent and compositional manner. Across seven diverse benchmarks, RISER yields 3.4-6.5% average zero-shot accuracy improvements over the base model while surpassing CoT-style reasoning with 2-3x higher token efficiency and robust accuracy gains. Further analysis shows that RISER autonomously combines multiple vectors into interpretable, precise control strategies, pointing toward more controllable and efficient LLM reasoning.

</details>


### [27] [$A^3$-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation](https://arxiv.org/abs/2601.09274)
*Jian Zhang,Yu He,Zhiyuan Wang,Zhangqi Wang,Kai He,Fangzhi Xu,Qika Lin,Jun Liu*

Main category: cs.AI

TL;DR: 该论文提出了A³-Bench基准测试，用于评估科学推理中的记忆驱动机制，重点关注锚点和吸引子的激活过程。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估最终答案或逐步推理的连贯性，但忽视了人类推理中的记忆驱动机制，即激活先验知识和经验结构的过程。

Method: 1. 使用SAPM过程（主体、锚点与吸引子、问题、记忆发展）标注了2,198个跨领域科学推理问题；2. 引入基于锚点和吸引子的双尺度记忆评估框架；3. 提出AAUI指标衡量记忆激活率。

Result: 通过多种基础模型和范式的实验验证了A³-Bench的有效性，并分析了记忆激活如何影响推理性能。

Conclusion: 该研究为理解记忆驱动的科学推理提供了新视角和评估工具，揭示了记忆激活在推理过程中的重要作用。

Abstract: Scientific reasoning relies not only on logical inference but also on activating prior knowledge and experiential structures. Memory can efficiently reuse knowledge and enhance reasoning consistency and stability. However, existing benchmarks mainly evaluate final answers or step-by-step coherence, overlooking the \textit{memory-driven} mechanisms that underlie human reasoning, which involves activating anchors and attractors, then integrating them into multi-step inference. To address this gap, we propose $A^3$-Bench~ https://a3-bench.github.io, a benchmark designed to evaluate scientific reasoning through dual-scale memory-driven activation, grounded in Anchor and Attractor Activation. First, we annotate 2,198 science reasoning problems across domains using the SAPM process(subject, anchor & attractor, problem, and memory developing). Second, we introduce a dual-scale memory evaluation framework utilizing anchors and attractors, along with the AAUI(Anchor--Attractor Utilization Index) metric to measure memory activation rates. Finally, through experiments with various base models and paradigms, we validate $A^3$-Bench and analyze how memory activation impacts reasoning performance, providing insights into memory-driven scientific reasoning.

</details>


### [28] [STaR: Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models](https://arxiv.org/abs/2601.09281)
*Jingjing Zhou,Gaoxiang Cong,Li Su,Liang Li*

Main category: cs.AI

TL;DR: STaR是一个无需参数的推理时遗忘框架，专门针对大型推理模型，通过语义检测、安全提示前缀、轨迹感知抑制和自适应过滤，在推理链全程保护隐私，同时引入新的评估指标MCS和MIA。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型虽然提升了多步推理能力，但其生成的复杂思维链轨迹存在严重隐私风险，敏感信息可能深嵌在推理过程中。现有的LLM遗忘方法通常只修改最终答案，无法从中间步骤移除敏感内容，导致隐私泄露持续存在。

Method: STaR框架包含四个步骤：1) 语义感知检测识别敏感内容；2) 通过安全提示前缀注入全局安全约束；3) 轨迹感知抑制动态阻断整个推理链中的敏感内容；4) 令牌级自适应过滤防止生成精确和改写后的敏感令牌。

Result: 在R-TOFU基准测试中，STaR实现了全面稳定的遗忘效果，同时保持了最小的效用损失。新提出的MCS和MIA评估指标验证了该方法在多种解码策略下的一致性和在答案及推理链层面的隐私保护效果。

Conclusion: STaR为大型推理模型中的隐私保护推理设定了新标准，通过推理时遗忘框架有效解决了思维链轨迹中的隐私风险问题，同时保持了模型效用。

Abstract: Large Reasoning Models (LRMs) have advanced automated multi-step reasoning, but their ability to generate complex Chain-of-Thought (CoT) trajectories introduces severe privacy risks, as sensitive information may be deeply embedded throughout the reasoning process. Existing Large Language Models (LLMs) unlearning approaches that typically focus on modifying only final answers are insufficient for LRMs, as they fail to remove sensitive content from intermediate steps, leading to persistent privacy leakage and degraded security. To address these challenges, we propose Sensitive Trajectory Regulation (STaR), a parameter-free, inference-time unlearning framework that achieves robust privacy protection throughout the reasoning process. Specifically, we first identify sensitive content via semantic-aware detection. Then, we inject global safety constraints through secure prompt prefix. Next, we perform trajectory-aware suppression to dynamically block sensitive content across the entire reasoning chain. Finally, we apply token-level adaptive filtering to prevent both exact and paraphrased sensitive tokens during generation. Furthermore, to overcome the inadequacies of existing evaluation protocols, we introduce two metrics: Multi-Decoding Consistency Assessment (MCS), which measures the consistency of unlearning across diverse decoding strategies, and Multi-Granularity Membership Inference Attack (MIA) Evaluation, which quantifies privacy protection at both answer and reasoning-chain levels. Experiments on the R-TOFU benchmark demonstrate that STaR achieves comprehensive and stable unlearning with minimal utility loss, setting a new standard for privacy-preserving reasoning in LRMs.

</details>


### [29] [Long-term Task-oriented Agent: Proactive Long-term Intent Maintenance in Dynamic Environments](https://arxiv.org/abs/2601.09382)
*Qinglong Shi,Donghai Wang,Hantao Zhou,Jiguo Li,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He*

Main category: cs.AI

TL;DR: 提出了一种面向任务的主动式智能体交互范式，通过意图条件监控和事件触发跟进能力，在动态环境中实现长期用户意图维护，并创建了ChronosBench基准测试验证方法有效性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型智能体主要采用被动响应模式，只能处理短期会话中的即时用户查询，无法维持长期用户意图并适应动态变化的外部环境，这限制了其在复杂任务场景中的应用。

Method: 提出主动式任务导向智能体交互范式，包含两个核心能力：1) 意图条件监控 - 基于对话历史自主制定触发条件；2) 事件触发跟进 - 检测到有用环境更新时主动与用户互动。开发高质量数据合成管道构建动态环境中的复杂多轮对话数据，并提出ChronosBench基准测试评估动态环境中的任务导向交互。

Result: 使用合成数据进行监督学习的微调模型在包含用户意图变化的复杂任务中实现了85.19%的任务完成率，优于其他测试模型。评估了当前领先的闭源和开源模型，揭示了它们在长期任务导向交互中的缺陷。

Conclusion: 提出的主动式智能体交互范式能够有效弥合相对静态的用户需求与动态环境之间的差距，数据驱动策略被证明是有效的，为长期任务导向交互提供了新的解决方案。

Abstract: Current large language model agents predominantly operate under a reactive paradigm, responding only to immediate user queries within short-term sessions. This limitation hinders their ability to maintain long-term user's intents and dynamically adapt to evolving external environments. In this paper, we propose a novel interaction paradigm for proactive Task-oriented Agents capable of bridging the gap between relatively static user's needs and a dynamic environment. We formalize proactivity through two key capabilities, (i) Intent-Conditioned Monitoring: The agent autonomously formulates trigger conditions based on dialog history; (ii) Event-Triggered Follow-up: The agent actively engages the user upon detecting useful environmental updates. We introduce a high-quality data synthesis pipeline to construct complex, multi-turn dialog data in a dynamic environment. Furthermore, we attempt to address the lack of evaluation criteria of task-oriented interaction in a dynamic environment by proposing a new benchmark, namely ChronosBench. We evaluated some leading close-source and open-source models at present and revealed their flaws in long-term task-oriented interaction. Furthermore, our fine-tuned model trained using synthetic data for supervised learning achieves a task completion rate of 85.19% for complex tasks including shifts in user intent, outperforming other models under test. And the result validated the effectiveness of our data-driven strategy.

</details>


### [30] [Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning](https://arxiv.org/abs/2601.09536)
*Dongjie Cheng,Yongqi Li,Zhixin Ma,Hongru Cai,Yupeng Hu,Wenjie Wang,Liqiang Nie,Wenjie Li*

Main category: cs.AI

TL;DR: Omni-R1提出了一种统一的生成式多模态推理方法，通过在推理过程中生成中间图像来统一多种多模态推理技能，包括Omni-R1（两阶段SFT+RL框架）和Omni-R1-Zero（无需多模态标注的版本）。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型要么专注于纯文本推理，要么采用单一任务特定的推理模式，限制了在不同多模态任务间的泛化能力。许多多模态任务需要多样化的推理技能（如放大特定区域、标记图像中的对象），因此需要统一的推理方法。

Method: 提出统一的生成式多模态推理范式，通过生成中间图像来统一多样化的多模态推理技能。具体实现包括：1) Omni-R1：两阶段SFT+RL框架，包含感知对齐损失和感知奖励，实现功能性图像生成；2) Omni-R1-Zero：通过从纯文本推理数据中引导逐步可视化，消除对多模态标注的需求。

Result: 实验结果表明，Omni-R1能够在广泛的多模态任务上实现统一的生成式推理，而Omni-R1-Zero在平均性能上能够匹配甚至超越Omni-R1，显示了生成式多模态推理的潜力。

Conclusion: 统一的生成式多模态推理范式通过生成中间图像有效统一了多种多模态推理技能，Omni-R1和Omni-R1-Zero展示了该方法的有效性，为生成式多模态推理提供了有前景的方向。

Abstract: Multimodal Large Language Models (MLLMs) are making significant progress in multimodal reasoning. Early approaches focus on pure text-based reasoning. More recent studies have incorporated multimodal information into the reasoning steps; however, they often follow a single task-specific reasoning pattern, which limits their generalizability across various multimodal tasks. In fact, there are numerous multimodal tasks requiring diverse reasoning skills, such as zooming in on a specific region or marking an object within an image. To address this, we propose unified generative multimodal reasoning, which unifies diverse multimodal reasoning skills by generating intermediate images during the reasoning process. We instantiate this paradigm with Omni-R1, a two-stage SFT+RL framework featuring perception alignment loss and perception reward, thereby enabling functional image generation. Additionally, we introduce Omni-R1-Zero, which eliminates the need for multimodal annotations by bootstrapping step-wise visualizations from text-only reasoning data. Empirical results show that Omni-R1 achieves unified generative reasoning across a wide range of multimodal tasks, and Omni-R1-Zero can match or even surpass Omni-R1 on average, suggesting a promising direction for generative multimodal reasoning.

</details>


### [31] [Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning](https://arxiv.org/abs/2601.09667)
*Zhiyuan Hu,Yunhai Hu,Juncheng Liu,Shuyue Stella Li,Yucheng Wang,Zhen Xu,See-Kiong Ng,Anh Tuan Luu,Xinxing Xu,Bryan Hooi,Cynthia Breazeal,Hae Won Park*

Main category: cs.AI

TL;DR: MATTRL：一种多智能体测试时强化学习框架，通过将结构化文本经验注入多智能体推理过程，无需训练即可提升多智能体系统的性能


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在实际应用中表现出色，但多智能体强化学习训练成本高且不稳定，存在非平稳性和稀疏高方差奖励问题

Method: 构建多专家团队进行多轮讨论，检索并整合测试时经验，通过共识机制进行最终决策，研究信用分配机制构建轮级经验池并重新注入对话

Result: 在医学、数学和教育等挑战性基准测试中，MATTRL比多智能体基线平均准确率提升3.67%，比单智能体基线提升8.67%

Conclusion: MATTRL提供了一种稳定、有效且高效的路径，无需调优即可实现分布偏移鲁棒的多智能体推理

Abstract: Multi-agent systems have evolved into practical LLM-driven collaborators for many applications, gaining robustness from diversity and cross-checking. However, multi-agent RL (MARL) training is resource-intensive and unstable: co-adapting teammates induce non-stationarity, and rewards are often sparse and high-variance. Therefore, we introduce \textbf{Multi-Agent Test-Time Reinforcement Learning (MATTRL)}, a framework that injects structured textual experience into multi-agent deliberation at inference time. MATTRL forms a multi-expert team of specialists for multi-turn discussions, retrieves and integrates test-time experiences, and reaches consensus for final decision-making. We also study credit assignment for constructing a turn-level experience pool, then reinjecting it into the dialogue. Across challenging benchmarks in medicine, math, and education, MATTRL improves accuracy by an average of 3.67\% over a multi-agent baseline, and by 8.67\% over comparable single-agent baselines. Ablation studies examine different credit-assignment schemes and provide a detailed comparison of how they affect training outcomes. MATTRL offers a stable, effective and efficient path to distribution-shift-robust multi-agent reasoning without tuning.

</details>

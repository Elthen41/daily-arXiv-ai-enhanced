{"id": "2511.08713", "categories": ["cs.DC", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.08713", "abs": "https://arxiv.org/abs/2511.08713", "authors": ["Gabriel Rodriguez-Canal", "David Katz", "Nick Brown"], "title": "An MLIR pipeline for offloading Fortran to FPGAs via OpenMP", "comment": "Author accepted version of paper published in SC25 LLVM workshop", "summary": "With the slowing of Moore's Law, heterogeneous computing platforms such as Field Programmable Gate Arrays (FPGAs) have gained increasing interest for accelerating HPC workloads. In this work we present, to the best of our knowledge, the first implementation of selective code offloading to FPGAs via the OpenMP target directive within MLIR. Our approach combines the MLIR OpenMP dialect with a High-Level Synthesis (HLS) dialect to provide a portable compilation flow targeting FPGAs. Unlike prior OpenMP FPGA efforts that rely on custom compilers, by contrast we integrate with MLIR and so support any MLIR-compatible front end, demonstrated here with Flang. Building upon a range of existing MLIR building blocks significantly reduces the effort required and demonstrates the composability benefits of the MLIR ecosystem. Our approach supports manual optimisation of offloaded kernels through standard OpenMP directives, and this work establishes a flexible and extensible path for directive-based FPGA acceleration integrated within the MLIR ecosystem.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u901a\u8fc7MLIR\u4e2d\u7684OpenMP\u76ee\u6807\u6307\u4ee4\u5b9e\u73b0\u9009\u62e9\u6027\u4ee3\u7801\u5378\u8f7d\u5230FPGA\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408OpenMP\u65b9\u8a00\u548cHLS\u65b9\u8a00\uff0c\u63d0\u4f9b\u53ef\u79fb\u690d\u7684FPGA\u7f16\u8bd1\u6d41\u7a0b\u3002", "motivation": "\u968f\u7740\u6469\u5c14\u5b9a\u5f8b\u653e\u7f13\uff0cFPGA\u7b49\u5f02\u6784\u8ba1\u7b97\u5e73\u53f0\u5728\u52a0\u901fHPC\u5de5\u4f5c\u8d1f\u8f7d\u65b9\u9762\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684FPGA\u52a0\u901f\u65b9\u6cd5\u3002", "method": "\u5c06MLIR OpenMP\u65b9\u8a00\u4e0e\u9ad8\u7ea7\u7efc\u5408(HLS)\u65b9\u8a00\u7ed3\u5408\uff0c\u5229\u7528\u73b0\u6709MLIR\u6784\u5efa\u6a21\u5757\uff0c\u652f\u6301\u4efb\u4f55MLIR\u517c\u5bb9\u524d\u7aef(\u5982Flang)\uff0c\u901a\u8fc7OpenMP\u6307\u4ee4\u624b\u52a8\u4f18\u5316\u5378\u8f7d\u5185\u6838\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u57fa\u4e8e\u6307\u4ee4\u7684FPGA\u52a0\u901f\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5f00\u53d1\u5de5\u4f5c\u91cf\uff0c\u5c55\u793a\u4e86MLIR\u751f\u6001\u7cfb\u7edf\u7684\u53ef\u7ec4\u5408\u6027\u4f18\u52bf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u57fa\u4e8e\u6307\u4ee4\u7684FPGA\u52a0\u901f\u5efa\u7acb\u4e86\u4e00\u4e2a\u7075\u6d3b\u4e14\u53ef\u6269\u5c55\u7684\u8def\u5f84\uff0c\u5b8c\u5168\u96c6\u6210\u5728MLIR\u751f\u6001\u7cfb\u7edf\u4e2d\u3002"}}
{"id": "2511.08936", "categories": ["cs.DC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.08936", "abs": "https://arxiv.org/abs/2511.08936", "authors": ["Liuzixuan Lin", "Andrew A. Chien"], "title": "Distribution and Management of Datacenter Load Decoupling", "comment": null, "summary": "The exploding power consumption of AI and cloud datacenters (DCs) intensifies the long-standing concerns about their carbon footprint, especially because DCs' need for constant power clashes with volatile renewable generation needed for grid decarbonization. DC flexibility (a.k.a. load adaptation) is a key to reducing DC carbon emissions by improving grid renewable absorption.\n  DC flexibility can be created, without disturbing datacenter capacity by decoupling a datacenter's power capacity and grid load with a collection of energy resources. Because decoupling can be costly, we study how to best distribute and manage decoupling to maximize benefits for all. Key considerations include site variation and datacenter-grid cooperation.\n  We first define and compute the power and energy needs of datacenter load decoupling, and then we evaluate designed distribution and management approaches. Evaluation shows that optimized distribution can deliver >98% of the potential grid carbon reduction with 70% of the total decoupling need. For management, DC-grid cooperation (2-way sharing and control vs. 1-way info sharing) enables 1.4x grid carbon reduction. Finally, we show that decoupling may be economically viable, as on average datacenters can get power cost and carbon emissions benefits greater than their local costs of decoupling. However, skew across sites suggests grid intervention may be required.", "AI": {"tldr": "\u6570\u636e\u4e2d\u5fc3\u901a\u8fc7\u80fd\u6e90\u8d44\u6e90\u89e3\u8026\u7535\u529b\u5bb9\u91cf\u4e0e\u7535\u7f51\u8d1f\u8377\u6765\u521b\u9020\u7075\u6d3b\u6027\uff0c\u4f18\u5316\u5206\u5e03\u548c\u7ba1\u7406\u53ef\u663e\u8457\u964d\u4f4e\u7535\u7f51\u78b3\u6392\u653e\uff0c\u7ecf\u6d4e\u4e0a\u5177\u6709\u53ef\u884c\u6027\u4f46\u9700\u8981\u7535\u7f51\u5e72\u9884\u3002", "motivation": "AI\u548c\u4e91\u6570\u636e\u4e2d\u5fc3\u7684\u9ad8\u80fd\u8017\u52a0\u5267\u4e86\u78b3\u8db3\u8ff9\u95ee\u9898\uff0c\u6570\u636e\u4e2d\u5fc3\u6052\u5b9a\u7535\u529b\u9700\u6c42\u4e0e\u6ce2\u52a8\u6027\u53ef\u518d\u751f\u80fd\u6e90\u7684\u77db\u76fe\u963b\u788d\u7535\u7f51\u8131\u78b3\uff0c\u9700\u8981\u6570\u636e\u4e2d\u5fc3\u7075\u6d3b\u6027\u6765\u6539\u5584\u53ef\u518d\u751f\u80fd\u6e90\u6d88\u7eb3\u3002", "method": "\u5b9a\u4e49\u548c\u8ba1\u7b97\u6570\u636e\u4e2d\u5fc3\u8d1f\u8377\u89e3\u8026\u7684\u529f\u7387\u548c\u80fd\u91cf\u9700\u6c42\uff0c\u8bc4\u4f30\u8bbe\u8ba1\u7684\u5206\u5e03\u548c\u7ba1\u7406\u65b9\u6cd5\uff0c\u5305\u62ec\u7ad9\u70b9\u5dee\u5f02\u548c\u7535\u7f51\u5408\u4f5c\u8003\u8651\u3002", "result": "\u4f18\u5316\u5206\u5e03\u53ef\u5b9e\u73b098%\u7684\u6f5c\u5728\u7535\u7f51\u78b3\u51cf\u6392\uff0c\u4ec5\u970070%\u7684\u603b\u89e3\u8026\u9700\u6c42\uff1b\u7535\u7f51\u5408\u4f5c\u7ba1\u7406\u6bd4\u5355\u5411\u4fe1\u606f\u5171\u4eab\u5b9e\u73b01.4\u500d\u7684\u78b3\u51cf\u6392\uff1b\u7ecf\u6d4e\u4e0a\u5e73\u5747\u6536\u76ca\u5927\u4e8e\u672c\u5730\u6210\u672c\u3002", "conclusion": "\u6570\u636e\u4e2d\u5fc3\u89e3\u8026\u662f\u964d\u4f4e\u78b3\u8db3\u8ff9\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4f18\u5316\u5206\u5e03\u548c\u7535\u7f51\u5408\u4f5c\u80fd\u663e\u8457\u63d0\u5347\u6548\u679c\uff0c\u7ecf\u6d4e\u53ef\u884c\u4f46\u5b58\u5728\u7ad9\u70b9\u5dee\u5f02\uff0c\u9700\u8981\u7535\u7f51\u5e72\u9884\u786e\u4fdd\u516c\u5e73\u6027\u3002"}}
{"id": "2511.08948", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.08948", "abs": "https://arxiv.org/abs/2511.08948", "authors": ["Jay Tharwani", "Shobhit Aggarwal", "Arnab A Purkayastha"], "title": "Evaluating HPC-Style CPU Performance and Cost in Virtualized Cloud Infrastructures", "comment": "7 pages", "summary": "This paper evaluates HPC-style CPU performance and cost in virtualized cloud infrastructures using a subset of OpenMP workloads in the SPEC ACCEL suite. Four major cloud providers by market share AWS, Azure, Google Cloud Platform (GCP), and Oracle Cloud Infrastructure (OCI) are compared across Intel, AMD, and ARM general purpose instance types under both on-demand and one-year discounted pricing. AWS consistently delivers the shortest runtime in all three instance types, yet charges a premium, especially for on-demand usage. OCI emerges as the most economical option across all CPU families, although it generally runs workloads more slowly than AWS. Azure often exhibits mid-range performance and cost, while GCP presents a mixed profile: it sees a notable boost when moving from Intel to AMD. On the other hand, its ARM instance is more than twice as slow as its own AMD offering and remains significantly more expensive. AWS's internal comparisons reveal that its ARM instance can outperform its Intel and AMD siblings by up to 49 percent in runtime. These findings highlight how instance choices and provider selection can yield substantial variations in both runtime and price, indicating that workload priorities, whether raw speed or cost minimization, should guide decisions on instance types.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u56db\u79cd\u4e3b\u8981\u4e91\u63d0\u4f9b\u5546\uff08AWS\u3001Azure\u3001GCP\u3001OCI\uff09\u5728\u865a\u62df\u5316\u4e91\u57fa\u7840\u8bbe\u65bd\u4e2d\u7684HPC\u98ce\u683cCPU\u6027\u80fd\u548c\u6210\u672c\uff0c\u4f7f\u7528SPEC ACCEL\u5957\u4ef6\u7684OpenMP\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u6bd4\u8f83\u4e86Intel\u3001AMD\u548cARM\u5b9e\u4f8b\u7c7b\u578b\u5728\u6309\u9700\u548c\u4e00\u5e74\u6298\u6263\u5b9a\u4ef7\u4e0b\u7684\u8868\u73b0\u3002", "motivation": "\u8bc4\u4f30\u4e91\u73af\u5883\u4e2d\u4e0d\u540cCPU\u67b6\u6784\uff08Intel\u3001AMD\u3001ARM\uff09\u7684\u6027\u80fd\u548c\u6210\u672c\u6548\u76ca\uff0c\u5e2e\u52a9\u7528\u6237\u6839\u636e\u5de5\u4f5c\u8d1f\u8f7d\u4f18\u5148\u7ea7\uff08\u539f\u59cb\u901f\u5ea6\u6216\u6210\u672c\u6700\u5c0f\u5316\uff09\u505a\u51fa\u660e\u667a\u7684\u5b9e\u4f8b\u7c7b\u578b\u9009\u62e9\u51b3\u7b56\u3002", "method": "\u4f7f\u7528SPEC ACCEL\u5957\u4ef6\u7684OpenMP\u5de5\u4f5c\u8d1f\u8f7d\u5b50\u96c6\uff0c\u5728AWS\u3001Azure\u3001GCP\u548cOCI\u56db\u4e2a\u4e3b\u8981\u4e91\u63d0\u4f9b\u5546\u7684Intel\u3001AMD\u548cARM\u901a\u7528\u5b9e\u4f8b\u7c7b\u578b\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u6309\u9700\u548c\u4e00\u5e74\u6298\u6263\u5b9a\u4ef7\u6a21\u5f0f\u4e0b\u7684\u6027\u80fd\u548c\u6210\u672c\u3002", "result": "AWS\u5728\u6240\u6709\u4e09\u79cd\u5b9e\u4f8b\u7c7b\u578b\u4e2d\u59cb\u7ec8\u63d0\u4f9b\u6700\u77ed\u8fd0\u884c\u65f6\u95f4\uff0c\u4f46\u6536\u8d39\u8f83\u9ad8\uff1bOCI\u662f\u6240\u6709CPU\u7cfb\u5217\u4e2d\u6700\u7ecf\u6d4e\u7684\u9009\u62e9\uff0c\u4f46\u8fd0\u884c\u5de5\u4f5c\u8d1f\u8f7d\u8f83\u6162\uff1bAzure\u901a\u5e38\u8868\u73b0\u4e2d\u7b49\u7684\u6027\u80fd\u548c\u6210\u672c\uff1bGCP\u4eceIntel\u5207\u6362\u5230AMD\u65f6\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u4f46\u5176ARM\u5b9e\u4f8b\u6bd4\u81ea\u5df1\u7684AMD\u4ea7\u54c1\u6162\u4e24\u500d\u4ee5\u4e0a\u4e14\u66f4\u6602\u8d35\uff1bAWS\u7684ARM\u5b9e\u4f8b\u5728\u8fd0\u884c\u65f6\u95f4\u4e0a\u6bd4\u5176Intel\u548cAMD\u5b9e\u4f8b\u5feb\u8fbe49%\u3002", "conclusion": "\u5b9e\u4f8b\u9009\u62e9\u548c\u4e91\u63d0\u4f9b\u5546\u9009\u62e9\u5728\u8fd0\u884c\u65f6\u95f4\u548c\u4ef7\u683c\u4e0a\u90fd\u4f1a\u4ea7\u751f\u663e\u8457\u5dee\u5f02\uff0c\u5de5\u4f5c\u8d1f\u8f7d\u4f18\u5148\u7ea7\uff08\u539f\u59cb\u901f\u5ea6\u6216\u6210\u672c\u6700\u5c0f\u5316\uff09\u5e94\u6307\u5bfc\u5b9e\u4f8b\u7c7b\u578b\u51b3\u7b56\u3002"}}
{"id": "2511.08998", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.08998", "abs": "https://arxiv.org/abs/2511.08998", "authors": ["Zilinghan Li", "Aditya Sinha", "Yijiang Li", "Kyle Chard", "Kibaek Kim", "Ravi Madduri"], "title": "Experiences Building Enterprise-Level Privacy-Preserving Federated Learning to Power AI for Science", "comment": null, "summary": "Federated learning (FL) is a promising approach to enabling collaborative model training without centralized data sharing, a crucial requirement in scientific domains where data privacy, ownership, and compliance constraints are critical. However, building user-friendly enterprise-level FL frameworks that are both scalable and privacy-preserving remains challenging, especially when bridging the gap between local prototyping and distributed deployment across heterogeneous client computing infrastructures. In this paper, based on our experiences building the Advanced Privacy-Preserving Federated Learning (APPFL) framework, we present our vision for an enterprise-grade, privacy-preserving FL framework designed to scale seamlessly across computing environments. We identify several key capabilities that such a framework must provide: (1) Scalable local simulation and prototyping to accelerate experimentation and algorithm design; (2) seamless transition from simulation to deployment; (3) distributed deployment across diverse, real-world infrastructures, from personal devices to cloud clusters and HPC systems; (4) multi-level abstractions that balance ease of use and research flexibility; and (5) comprehensive privacy and security through techniques such as differential privacy, secure aggregation, robust authentication, and confidential computing. We further discuss architectural designs to realize these goals. This framework aims to bridge the gap between research prototypes and enterprise-scale deployment, enabling scalable, reliable, and privacy-preserving AI for science.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4f01\u4e1a\u7ea7\u9690\u79c1\u4fdd\u62a4\u8054\u90a6\u5b66\u4e60\u6846\u67b6APPFL\u7684\u8bbe\u8ba1\u613f\u666f\uff0c\u65e8\u5728\u89e3\u51b3\u4ece\u672c\u5730\u539f\u578b\u5230\u5206\u5e03\u5f0f\u90e8\u7f72\u7684\u6269\u5c55\u6027\u95ee\u9898\uff0c\u652f\u6301\u8de8\u5f02\u6784\u8ba1\u7b97\u73af\u5883\u7684\u65e0\u7f1d\u90e8\u7f72\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u79d1\u5b66\u9886\u57df\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\uff0c\u4f46\u73b0\u6709\u6846\u67b6\u5728\u53ef\u6269\u5c55\u6027\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u4ece\u539f\u578b\u5230\u90e8\u7f72\u7684\u65e0\u7f1d\u8fc7\u6e21\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u6784\u5efa\u4f01\u4e1a\u7ea7\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u57fa\u4e8eAPPFL\u6846\u67b6\u5f00\u53d1\u7ecf\u9a8c\uff0c\u63d0\u51fa\u5305\u542b\u4e94\u4e2a\u5173\u952e\u80fd\u529b\u7684\u6846\u67b6\u8bbe\u8ba1\uff1a\u53ef\u6269\u5c55\u672c\u5730\u4eff\u771f\u3001\u65e0\u7f1d\u8fc7\u6e21\u5230\u90e8\u7f72\u3001\u8de8\u5f02\u6784\u57fa\u7840\u8bbe\u65bd\u90e8\u7f72\u3001\u591a\u7ea7\u62bd\u8c61\u3001\u5168\u9762\u9690\u79c1\u5b89\u5168\u4fdd\u62a4\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u6865\u63a5\u7814\u7a76\u539f\u578b\u548c\u4f01\u4e1a\u7ea7\u90e8\u7f72\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u67b6\u6784\u8bbe\u8ba1\uff0c\u652f\u6301\u4ece\u4e2a\u4eba\u8bbe\u5907\u5230\u4e91\u96c6\u7fa4\u548cHPC\u7cfb\u7edf\u7684\u5206\u5e03\u5f0f\u90e8\u7f72\u3002", "conclusion": "\u8be5\u6846\u67b6\u65e8\u5728\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u53ef\u9760\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u79d1\u5b66AI\uff0c\u4e3a\u8054\u90a6\u5b66\u4e60\u4ece\u7814\u7a76\u5230\u5b9e\u9645\u5e94\u7528\u7684\u8f6c\u5316\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2511.08715", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08715", "abs": "https://arxiv.org/abs/2511.08715", "authors": ["Connar Hite", "Sean Saud", "Raef Taha", "Nayim Rahman", "Tanvir Atahary", "Scott Douglass", "Tarek Taha"], "title": "Bridging Natural Language and ASP: A Hybrid Approach Using LLMs and AMR Parsing", "comment": null, "summary": "Answer Set Programming (ASP) is a declarative programming paradigm based on logic programming and non-monotonic reasoning. It is a tremendously powerful tool for describing and solving combinatorial problems. Like any other language, ASP requires users to learn how it works and the syntax involved. It is becoming increasingly required for those unfamiliar with programming languages to interact with code. This paper proposes a novel method of translating unconstrained English into ASP programs for logic puzzles using an LLM and Abstract Meaning Representation (AMR) graphs. Everything from ASP rules, facts, and constraints is generated to fully represent and solve the desired problem. Example logic puzzles are used to demonstrate the capabilities of the system. While most current methods rely entirely on an LLM, our system minimizes the role of the LLM only to complete straightforward tasks. The LLM is used to simplify natural language sentences, identify keywords, and generate simple facts. The AMR graphs are then parsed from simplified language and used to generate ASP constraints systematically. The system successfully creates an entire ASP program that solves a combinatorial logic problem. This approach is a significant first step in creating a lighter-weight, explainable system that converts natural language to solve complex logic problems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u65e0\u7ea6\u675f\u82f1\u8bed\u7ffb\u8bd1\u6210ASP\u7a0b\u5e8f\u7684\u65b0\u65b9\u6cd5\uff0c\u4f7f\u7528LLM\u548cAMR\u56fe\u6765\u751f\u6210\u5b8c\u6574\u7684ASP\u7a0b\u5e8f\u4ee5\u89e3\u51b3\u903b\u8f91\u8c1c\u9898\u3002", "motivation": "\u968f\u7740\u8d8a\u6765\u8d8a\u591a\u4e0d\u719f\u6089\u7f16\u7a0b\u8bed\u8a00\u7684\u4eba\u9700\u8981\u4e0e\u4ee3\u7801\u4ea4\u4e92\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u8ba9\u975e\u4e13\u4e1a\u4eba\u58eb\u80fd\u591f\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u903b\u8f91\u95ee\u9898\u5e76\u81ea\u52a8\u751f\u6210ASP\u7a0b\u5e8f\u3002", "method": "\u4f7f\u7528LLM\u7b80\u5316\u81ea\u7136\u8bed\u8a00\u53e5\u5b50\u3001\u8bc6\u522b\u5173\u952e\u8bcd\u548c\u751f\u6210\u7b80\u5355\u4e8b\u5b9e\uff0c\u7136\u540e\u901a\u8fc7AMR\u56fe\u89e3\u6790\u7b80\u5316\u8bed\u8a00\u5e76\u7cfb\u7edf\u751f\u6210ASP\u7ea6\u675f\uff0c\u6700\u5c0f\u5316LLM\u7684\u4f5c\u7528\u3002", "result": "\u7cfb\u7edf\u6210\u529f\u521b\u5efa\u4e86\u5b8c\u6574\u7684ASP\u7a0b\u5e8f\u6765\u89e3\u51b3\u7ec4\u5408\u903b\u8f91\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u5728\u903b\u8f91\u8c1c\u9898\u4e0a\u7684\u80fd\u529b\u3002", "conclusion": "\u8fd9\u662f\u521b\u5efa\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u81ea\u7136\u8bed\u8a00\u5230\u590d\u6742\u903b\u8f91\u95ee\u9898\u89e3\u51b3\u7cfb\u7edf\u7684\u91cd\u5927\u7b2c\u4e00\u6b65\u3002"}}
{"id": "2511.09143", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.09143", "abs": "https://arxiv.org/abs/2511.09143", "authors": ["Myungsu Kim", "Ikjun Yeom", "Younghoon Kim"], "title": "Flex-MIG: Enabling Distributed Execution on MIG", "comment": "13 pages, 11 figures, under review for MLSys 2026", "summary": "GPU clusters in multi-tenant settings often suffer from underutilization, making GPU-sharing technologies essential for efficient resource use. Among them, NVIDIA Multi-Instance GPU (MIG) has gained traction for providing hardware-level isolation that enables concurrent workloads without interference. However, MIG's hardware rigidity and the conventional one-to-one allocation model jointly lead to severe fragmentation and cluster-wide underutilization. We present Flex-MIG, a software-only framework that replaces one-to-one with a one-to-many allocation model and enables host-shared-memory collectives across MIG instances without hardware modification. Flex-MIG eliminates drain-required reconfiguration, reduces fragmentation, and improves makespan by up to 17% across diverse traces, showing that rethinking MIG's operational model as a software-coordinated layer substantially improves cluster efficiency.", "AI": {"tldr": "Flex-MIG\u662f\u4e00\u4e2a\u8f6f\u4ef6\u6846\u67b6\uff0c\u901a\u8fc7\u5c06MIG\u7684\u4e00\u5bf9\u4e00\u5206\u914d\u6a21\u578b\u6539\u4e3a\u4e00\u5bf9\u591a\u5206\u914d\u6a21\u578b\uff0c\u5e76\u652f\u6301\u8de8MIG\u5b9e\u4f8b\u7684\u4e3b\u673a\u5171\u4eab\u5185\u5b58\u96c6\u5408\u64cd\u4f5c\uff0c\u89e3\u51b3\u4e86GPU\u96c6\u7fa4\u4e2d\u7684\u8d44\u6e90\u788e\u7247\u5316\u548c\u5229\u7528\u7387\u4f4e\u4e0b\u95ee\u9898\uff0c\u65e0\u9700\u786c\u4ef6\u4fee\u6539\u5373\u53ef\u663e\u8457\u63d0\u5347\u96c6\u7fa4\u6548\u7387\u3002", "motivation": "\u591a\u79df\u6237GPU\u96c6\u7fa4\u5b58\u5728\u5229\u7528\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u867d\u7136NVIDIA MIG\u63d0\u4f9b\u4e86\u786c\u4ef6\u7ea7\u9694\u79bb\uff0c\u4f46\u5176\u786c\u4ef6\u521a\u6027\u548c\u4f20\u7edf\u4e00\u5bf9\u4e00\u5206\u914d\u6a21\u578b\u5bfc\u81f4\u4e25\u91cd\u7684\u8d44\u6e90\u788e\u7247\u5316\u548c\u96c6\u7fa4\u8303\u56f4\u5229\u7528\u7387\u4f4e\u4e0b\u3002", "method": "Flex-MIG\u91c7\u7528\u7eaf\u8f6f\u4ef6\u65b9\u6cd5\uff0c\u5c06MIG\u7684\u4e00\u5bf9\u4e00\u5206\u914d\u6a21\u578b\u66ff\u6362\u4e3a\u4e00\u5bf9\u591a\u5206\u914d\u6a21\u578b\uff0c\u5e76\u5b9e\u73b0\u8de8MIG\u5b9e\u4f8b\u7684\u4e3b\u673a\u5171\u4eab\u5185\u5b58\u96c6\u5408\u64cd\u4f5c\uff0c\u65e0\u9700\u786c\u4ef6\u4fee\u6539\u3002", "result": "Flex-MIG\u6d88\u9664\u4e86\u9700\u8981\u6392\u7a7a\u7684\u91cd\u914d\u7f6e\u64cd\u4f5c\uff0c\u51cf\u5c11\u4e86\u788e\u7247\u5316\uff0c\u5728\u4e0d\u540c\u8ddf\u8e2a\u6570\u636e\u4e0b\u5c06makespan\u63d0\u9ad8\u4e86\u9ad8\u8fbe17%\u3002", "conclusion": "\u5c06MIG\u7684\u64cd\u4f5c\u6a21\u578b\u91cd\u65b0\u8bbe\u8ba1\u4e3a\u8f6f\u4ef6\u534f\u8c03\u5c42\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u96c6\u7fa4\u6548\u7387\uff0cFlex-MIG\u5c55\u793a\u4e86\u901a\u8fc7\u8f6f\u4ef6\u521b\u65b0\u89e3\u51b3\u786c\u4ef6\u9650\u5236\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2511.08747", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08747", "abs": "https://arxiv.org/abs/2511.08747", "authors": ["Isaac Joffe", "Chris Eliasmith"], "title": "Vector Symbolic Algebras for the Abstraction and Reasoning Corpus", "comment": null, "summary": "The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) is a generative, few-shot fluid intelligence benchmark. Although humans effortlessly solve ARC-AGI, it remains extremely difficult for even the most advanced artificial intelligence systems. Inspired by methods for modelling human intelligence spanning neuroscience to psychology, we propose a cognitively plausible ARC-AGI solver. Our solver integrates System 1 intuitions with System 2 reasoning in an efficient and interpretable process using neurosymbolic methods based on Vector Symbolic Algebras (VSAs). Our solver works by object-centric program synthesis, leveraging VSAs to represent abstract objects, guide solution search, and enable sample-efficient neural learning. Preliminary results indicate success, with our solver scoring 10.8% on ARC-AGI-1-Train and 3.0% on ARC-AGI-1-Eval. Additionally, our solver performs well on simpler benchmarks, scoring 94.5% on Sort-of-ARC and 83.1% on 1D-ARC -- the latter outperforming GPT-4 at a tiny fraction of the computational cost. Importantly, our approach is unique; we believe we are the first to apply VSAs to ARC-AGI and have developed the most cognitively plausible ARC-AGI solver yet. Our code is available at: https://github.com/ijoffe/ARC-VSA-2025.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5411\u91cf\u7b26\u53f7\u4ee3\u6570(VSA)\u7684\u8ba4\u77e5\u5408\u7406ARC-AGI\u6c42\u89e3\u5668\uff0c\u6574\u5408\u4e86\u7cfb\u7edf1\u76f4\u89c9\u548c\u7cfb\u7edf2\u63a8\u7406\uff0c\u901a\u8fc7\u9762\u5411\u5bf9\u8c61\u7684\u7a0b\u5e8f\u5408\u6210\u65b9\u6cd5\u89e3\u51b3ARC-AGI\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u867d\u7136\u4eba\u7c7b\u80fd\u8f7b\u677e\u89e3\u51b3ARC-AGI\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f46\u5373\u4f7f\u6700\u5148\u8fdb\u7684AI\u7cfb\u7edf\u4e5f\u96be\u4ee5\u5e94\u5bf9\u3002\u53d7\u795e\u7ecf\u79d1\u5b66\u548c\u5fc3\u7406\u5b66\u4e2d\u4eba\u7c7b\u667a\u80fd\u5efa\u6a21\u65b9\u6cd5\u7684\u542f\u53d1\uff0c\u4f5c\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u4e2a\u8ba4\u77e5\u5408\u7406\u7684\u6c42\u89e3\u5668\u3002", "method": "\u4f7f\u7528\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u57fa\u4e8e\u5411\u91cf\u7b26\u53f7\u4ee3\u6570(VSA)\u6574\u5408\u7cfb\u7edf1\u76f4\u89c9\u548c\u7cfb\u7edf2\u63a8\u7406\u3002\u91c7\u7528\u9762\u5411\u5bf9\u8c61\u7684\u7a0b\u5e8f\u5408\u6210\u65b9\u6cd5\uff0c\u5229\u7528VSA\u8868\u793a\u62bd\u8c61\u5bf9\u8c61\u3001\u6307\u5bfc\u89e3\u51b3\u65b9\u6848\u641c\u7d22\uff0c\u5e76\u5b9e\u73b0\u6837\u672c\u9ad8\u6548\u7684\u795e\u7ecf\u5b66\u4e60\u3002", "result": "\u5728ARC-AGI-1-Train\u4e0a\u5f97\u5206\u4e3a10.8%\uff0c\u5728ARC-AGI-1-Eval\u4e0a\u5f97\u5206\u4e3a3.0%\u3002\u5728\u8f83\u7b80\u5355\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8868\u73b0\u4f18\u5f02\uff1aSort-of-ARC\u5f97\u5206\u4e3a94.5%\uff0c1D-ARC\u5f97\u5206\u4e3a83.1%\uff0c\u540e\u8005\u4ee5\u6781\u4f4e\u8ba1\u7b97\u6210\u672c\u8d85\u8d8aGPT-4\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5c06VSA\u5e94\u7528\u4e8eARC-AGI\u7684\u7814\u7a76\uff0c\u5f00\u53d1\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u8ba4\u77e5\u5408\u7406\u7684ARC-AGI\u6c42\u89e3\u5668\uff0c\u4e3a\u4eba\u5de5\u901a\u7528\u667a\u80fd\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.09194", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.09194", "abs": "https://arxiv.org/abs/2511.09194", "authors": ["Simon K\u00f6nig", "Lukas Epple", "Christian Becker"], "title": "Minimize Your Critical Path with Combine-and-Exchange Locks", "comment": "19 pages, 15 figures", "summary": "Coroutines are experiencing a renaissance as many modern programming languages support the use of cooperative multitasking for highly parallel or asynchronous applications. One of the greatest advantages of this is that concurrency and synchronization is manged entirely in the userspace, omitting heavy-weight system calls. However, we find that state-of-the-art userspace synchronization primitives approach synchronization in the userspace from the perspective of kernel-level scheduling. This introduces unnecessary delays on the critical path of the application, limiting throughput. In this paper, we re-think synchronization for tasks that are scheduled entirely in the userspace (e.g., coroutines, fibers, etc.). We develop Combine-and-Exchange Scheduling (CES), a novel scheduling approach that ensures contended critical sections stay on the same thread of execution while parallelizable work is evenly spread across the remaining threads. We show that our approach can be applied to many existing languages and libraries, resulting in 3-fold performance improvements in application benchmarks as well as 8-fold performance improvements in microbenchmarks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7528\u6237\u7a7a\u95f4\u540c\u6b65\u8c03\u5ea6\u65b9\u6cd5CES\uff0c\u7528\u4e8e\u89e3\u51b3\u534f\u7a0b\u7b49\u7528\u6237\u7a7a\u95f4\u4efb\u52a1\u8c03\u5ea6\u4e2d\u7684\u6027\u80fd\u74f6\u9888\u95ee\u9898\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u80fd\u5e26\u67653-8\u500d\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u4ee3\u7f16\u7a0b\u8bed\u8a00\u5e7f\u6cdb\u652f\u6301\u534f\u7a0b\u7528\u4e8e\u9ad8\u5e76\u884c\u6216\u5f02\u6b65\u5e94\u7528\uff0c\u7528\u6237\u7a7a\u95f4\u540c\u6b65\u907f\u514d\u4e86\u91cd\u91cf\u7ea7\u7cfb\u7edf\u8c03\u7528\uff0c\u4f46\u73b0\u6709\u7528\u6237\u7a7a\u95f4\u540c\u6b65\u539f\u8bed\u4ecd\u91c7\u7528\u5185\u6838\u7ea7\u8c03\u5ea6\u89c6\u89d2\uff0c\u5bfc\u81f4\u5173\u952e\u8def\u5f84\u4e0a\u4e0d\u5fc5\u8981\u7684\u5ef6\u8fdf\uff0c\u9650\u5236\u4e86\u541e\u5410\u91cf\u3002", "method": "\u5f00\u53d1\u4e86Combine-and-Exchange Scheduling (CES)\u65b9\u6cd5\uff0c\u786e\u4fdd\u7ade\u4e89\u4e34\u754c\u533a\u4fdd\u6301\u5728\u540c\u4e00\u4e2a\u6267\u884c\u7ebf\u7a0b\u4e0a\uff0c\u540c\u65f6\u5c06\u53ef\u5e76\u884c\u5de5\u4f5c\u5747\u5300\u5206\u5e03\u5230\u5176\u4ed6\u7ebf\u7a0b\u3002", "result": "\u8be5\u65b9\u6cd5\u53ef\u5e94\u7528\u4e8e\u591a\u79cd\u73b0\u6709\u8bed\u8a00\u548c\u5e93\uff0c\u5728\u5e94\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b03\u500d\u6027\u80fd\u63d0\u5347\uff0c\u5728\u5fae\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b08\u500d\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "CES\u65b9\u6cd5\u91cd\u65b0\u601d\u8003\u4e86\u7528\u6237\u7a7a\u95f4\u4efb\u52a1\u8c03\u5ea6\uff0c\u901a\u8fc7\u4f18\u5316\u540c\u6b65\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u534f\u7a0b\u7b49\u7528\u6237\u7a7a\u95f4\u8c03\u5ea6\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2511.08703", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08703", "abs": "https://arxiv.org/abs/2511.08703", "authors": ["Yaroslav Popryho", "Debjit Pal", "Inna Partin-Vaisband"], "title": "Automated Hardware Trojan Insertion in Industrial-Scale Designs", "comment": "Accepted in DATE 2026", "summary": "Industrial Systems-on-Chips (SoCs) often comprise hundreds of thousands to millions of nets and millions to tens of millions of connectivity edges, making empirical evaluation of hardware-Trojan (HT) detectors on realistic designs both necessary and difficult. Public benchmarks remain significantly smaller and hand-crafted, while releasing truly malicious RTL raises ethical and operational risks. This work presents an automated and scalable methodology for generating HT-like patterns in industry-scale netlists whose purpose is to stress-test detection tools without altering user-visible functionality. The pipeline (i) parses large gate-level designs into connectivity graphs, (ii) explores rare regions using SCOAP testability metrics, and (iii) applies parameterized, function-preserving graph transformations to synthesize trigger-payload pairs that mimic the statistical footprint of stealthy HTs. When evaluated on the benchmarks generated in this work, representative state-of-the-art graph-learning models fail to detect Trojans. The framework closes the evaluation gap between academic circuits and modern SoCs by providing reproducible challenge instances that advance security research without sharing step-by-step attack instructions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5de5\u4e1a\u89c4\u6a21\u7f51\u8868\u4e2d\u751f\u6210\u786c\u4ef6\u6728\u9a6c(HT)\u7c7b\u4f3c\u6a21\u5f0f\uff0c\u4ee5\u538b\u529b\u6d4b\u8bd5\u68c0\u6d4b\u5de5\u5177\u800c\u4e0d\u6539\u53d8\u7528\u6237\u53ef\u89c1\u529f\u80fd\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u89e3\u6790\u95e8\u7ea7\u8bbe\u8ba1\u3001\u63a2\u7d22\u7f55\u89c1\u533a\u57df\u548c\u5e94\u7528\u51fd\u6570\u4fdd\u6301\u56fe\u53d8\u6362\u6765\u5408\u6210\u6a21\u4eff\u9690\u853dHT\u7edf\u8ba1\u7279\u5f81\u7684\u89e6\u53d1-\u8d1f\u8f7d\u5bf9\u3002", "motivation": "\u5de5\u4e1aSoC\u5305\u542b\u6570\u767e\u4e07\u4e2a\u7f51\u8868\u548c\u8fde\u63a5\u8fb9\uff0c\u4f7f\u5f97\u5728\u771f\u5b9e\u8bbe\u8ba1\u4e0a\u8fdb\u884cHT\u68c0\u6d4b\u5668\u8bc4\u4f30\u65e2\u5fc5\u8981\u53c8\u56f0\u96be\u3002\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u4ecd\u7136\u663e\u8457\u8f83\u5c0f\u4e14\u624b\u5de5\u5236\u4f5c\uff0c\u800c\u53d1\u5e03\u771f\u6b63\u6076\u610fRTL\u4f1a\u5e26\u6765\u9053\u5fb7\u548c\u64cd\u4f5c\u98ce\u9669\u3002", "method": "\u8be5\u65b9\u6cd5\u5305\u62ec\u4e09\u4e2a\u6b65\u9aa4\uff1a(i)\u5c06\u5927\u578b\u95e8\u7ea7\u8bbe\u8ba1\u89e3\u6790\u4e3a\u8fde\u63a5\u56fe\uff0c(ii)\u4f7f\u7528SCOAP\u53ef\u6d4b\u8bd5\u6027\u6307\u6807\u63a2\u7d22\u7f55\u89c1\u533a\u57df\uff0c(iii)\u5e94\u7528\u53c2\u6570\u5316\u3001\u51fd\u6570\u4fdd\u6301\u7684\u56fe\u53d8\u6362\u6765\u5408\u6210\u6a21\u4eff\u9690\u853dHT\u7edf\u8ba1\u8db3\u8ff9\u7684\u89e6\u53d1-\u8d1f\u8f7d\u5bf9\u3002", "result": "\u5728\u672c\u6587\u751f\u6210\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8bc4\u4f30\u65f6\uff0c\u4ee3\u8868\u6027\u7684\u6700\u5148\u8fdb\u56fe\u5b66\u4e60\u6a21\u578b\u672a\u80fd\u68c0\u6d4b\u5230\u6728\u9a6c\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u63d0\u4f9b\u53ef\u91cd\u590d\u7684\u6311\u6218\u5b9e\u4f8b\uff0c\u5f25\u5408\u4e86\u5b66\u672f\u7535\u8def\u4e0e\u73b0\u4ee3SoC\u4e4b\u95f4\u7684\u8bc4\u4f30\u5dee\u8ddd\uff0c\u63a8\u8fdb\u4e86\u5b89\u5168\u7814\u7a76\u800c\u65e0\u9700\u5206\u4eab\u9010\u6b65\u653b\u51fb\u6307\u4ee4\u3002"}}
{"id": "2511.09410", "categories": ["cs.DC", "cs.DS", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.09410", "abs": "https://arxiv.org/abs/2511.09410", "authors": ["Yusuf Motiwala"], "title": "No Cords Attached: Coordination-Free Concurrent Lock-Free Queues", "comment": "10 pages, 2 figures, 3 tables. Lock-free concurrent queue with coordination-free memory reclamation", "summary": "The queue is conceptually one of the simplest data structures-a basic FIFO container. However, ensuring correctness in the presence of concurrency makes existing lock-free implementations significantly more complex than their original form. Coordination mechanisms introduced to prevent hazards such as ABA, use-after-free, and unsafe reclamation often dominate the design, overshadowing the queue itself. Many schemes compromise strict FIFO ordering, unbounded capacity, or lock-free progress to mask coordination overheads. Yet the true source of complexity lies in the pursuit of infinite protection against reclamation hazards--theoretically sound but impractical and costly. This pursuit not only drives unnecessary complexity but also creates a protection paradox where excessive protection reduces system resilience rather than improving it. While such costs may be tolerable in conventional workloads, the AI era has shifted the paradigm: training and inference pipelines involve hundreds to thousands of concurrent threads per node, and at this scale, protection and coordination overheads dominate, often far heavier than the basic queue operations themselves.\n  This paper introduces Cyclic Memory Protection (CMP), a coordination-free queue that preserves strict FIFO semantics, unbounded capacity, and lock-free progress while restoring simplicity. CMP reclaims the strict FIFO that other approaches sacrificed through bounded protection windows that provide practical reclamation guarantees. We prove strict FIFO and safety via linearizability and bounded reclamation analysis, and show experimentally that CMP outperforms state-of-the-art lock-free queues by up to 1.72-4x under high contention while maintaining scalability to hundreds of threads. Our work demonstrates that highly concurrent queues can return to their fundamental simplicity without weakening queue semantics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5faa\u73af\u5185\u5b58\u4fdd\u62a4(CMP)\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u65e0\u534f\u8c03\u7684\u961f\u5217\u5b9e\u73b0\uff0c\u5728\u4fdd\u6301\u4e25\u683cFIFO\u8bed\u4e49\u3001\u65e0\u754c\u5bb9\u91cf\u548c\u9501\u81ea\u7531\u8fdb\u5ea6\u7684\u540c\u65f6\u6062\u590d\u4e86\u7b80\u5355\u6027\u3002CMP\u901a\u8fc7\u6709\u754c\u4fdd\u62a4\u7a97\u53e3\u63d0\u4f9b\u5b9e\u7528\u7684\u56de\u6536\u4fdd\u8bc1\uff0c\u5728\u9ad8\u5e76\u53d1\u573a\u666f\u4e0b\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u9501\u81ea\u7531\u961f\u52171.72-4\u500d\u3002", "motivation": "\u73b0\u6709\u9501\u81ea\u7531\u961f\u5217\u5b9e\u73b0\u5728\u5e76\u53d1\u73af\u5883\u4e0b\u4e3a\u4e86\u9632\u8303ABA\u3001\u91ca\u653e\u540e\u4f7f\u7528\u7b49\u98ce\u9669\u800c\u5f15\u5165\u590d\u6742\u7684\u534f\u8c03\u673a\u5236\uff0c\u8fd9\u4e9b\u673a\u5236\u5f80\u5f80\u63a9\u76d6\u4e86\u961f\u5217\u672c\u8eab\u7684\u8bbe\u8ba1\u3002\u5728AI\u65f6\u4ee3\uff0c\u8bad\u7ec3\u548c\u63a8\u7406\u6d41\u6c34\u7ebf\u6d89\u53ca\u6570\u767e\u5230\u6570\u5343\u4e2a\u5e76\u53d1\u7ebf\u7a0b\uff0c\u4fdd\u62a4\u534f\u8c03\u5f00\u9500\u53d8\u5f97\u4e3b\u5bfc\u4e14\u8fdc\u8d85\u57fa\u672c\u961f\u5217\u64cd\u4f5c\u672c\u8eab\u3002", "method": "\u63d0\u51fa\u5faa\u73af\u5185\u5b58\u4fdd\u62a4(CMP)\u65b9\u6cd5\uff0c\u91c7\u7528\u6709\u754c\u4fdd\u62a4\u7a97\u53e3\u63d0\u4f9b\u5b9e\u7528\u7684\u56de\u6536\u4fdd\u8bc1\uff0c\u907f\u514d\u65e0\u9650\u4fdd\u62a4\u5e26\u6765\u7684\u590d\u6742\u6027\u3002\u8be5\u65b9\u6cd5\u4fdd\u6301\u4e25\u683cFIFO\u8bed\u4e49\u3001\u65e0\u754c\u5bb9\u91cf\u548c\u9501\u81ea\u7531\u8fdb\u5ea6\uff0c\u540c\u65f6\u65e0\u9700\u534f\u8c03\u673a\u5236\u3002", "result": "\u901a\u8fc7\u7ebf\u6027\u5316\u548c\u6709\u754c\u56de\u6536\u5206\u6790\u8bc1\u660e\u4e86\u4e25\u683cFIFO\u548c\u5b89\u5168\u6027\u3002\u5b9e\u9a8c\u663e\u793aCMP\u5728\u9ad8\u7ade\u4e89\u573a\u666f\u4e0b\u6027\u80fd\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u9501\u81ea\u7531\u961f\u52171.72-4\u500d\uff0c\u5e76\u80fd\u6269\u5c55\u5230\u6570\u767e\u4e2a\u7ebf\u7a0b\u3002", "conclusion": "\u9ad8\u5ea6\u5e76\u53d1\u7684\u961f\u5217\u53ef\u4ee5\u56de\u5f52\u5176\u57fa\u672c\u7b80\u5355\u6027\u800c\u65e0\u9700\u524a\u5f31\u961f\u5217\u8bed\u4e49\uff0cCMP\u65b9\u6cd5\u5728\u4fdd\u6301\u4e25\u683cFIFO\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.08902", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.08902", "abs": "https://arxiv.org/abs/2511.08902", "authors": ["Yingjie Sun", "Guyue Li", "Hongfu Chou", "Aiqun Hu"], "title": "Channel-Robust RFF for Low-Latency 5G Device Identification in SIMO Scenarios", "comment": null, "summary": "Ultra-low latency, the hallmark of fifth-generation mobile communications (5G), imposes exacting timing demands on identification as well. Current cryptographic solutions introduce additional computational overhead, which results in heightened identification delays. Radio frequency fingerprint (RFF) identifies devices at the physical layer, blocking impersonation attacks while significantly reducing latency. Unfortunately, multipath channels compromise RFF accuracy, and existing channel-resilient methods demand feedback or processing across multiple time points, incurring extra signaling latency. To address this problem, the paper introduces a new RFF extraction technique that employs signals from multiple receiving antennas to address multipath issues without adding latency. Unlike single-domain methods, the Log-Linear Delta Ratio (LLDR) of co-temporal channel frequency responses (CFRs) from multiple antennas is employed to preserve discriminative RFF features, eliminating multi-time sampling and reducing acquisition time. To overcome the challenge of the reliance on minimal channel variation, the frequency band is segmented into sub-bands, and the LLDR is computed within each sub-band individually. Simulation results indicate that the proposed scheme attains a 96.13% identification accuracy for 30 user equipments (UEs) within a 20-path channel under a signal-to-noise ratio (SNR) of 20 dB. Furthermore, we evaluate the theoretical latency using the Roofline model, resulting in the air interface latency of 0.491 ms, which satisfies ultra-reliable and low-latency communications (URLLC) latency requirements.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u5929\u7ebf\u4fe1\u53f7\u7684\u5c04\u9891\u6307\u7eb9\u63d0\u53d6\u6280\u672fLLDR\uff0c\u901a\u8fc7\u8ba1\u7b97\u5171\u65f6\u4fe1\u9053\u9891\u7387\u54cd\u5e94\u7684\u5bf9\u6570\u7ebf\u6027\u5dee\u503c\u6bd4\u6765\u89e3\u51b3\u591a\u5f84\u95ee\u9898\uff0c\u65e0\u9700\u591a\u65f6\u95f4\u70b9\u91c7\u6837\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bc6\u522b\u5ef6\u8fdf\u3002", "motivation": "5G\u8d85\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u5bf9\u8bbe\u5907\u8bc6\u522b\u63d0\u51fa\u4e86\u4e25\u683c\u7684\u65f6\u5e8f\u8981\u6c42\uff0c\u73b0\u6709\u52a0\u5bc6\u65b9\u6848\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\u5bfc\u81f4\u5ef6\u8fdf\u589e\u52a0\uff0c\u800c\u4f20\u7edf\u5c04\u9891\u6307\u7eb9\u8bc6\u522b\u5728\u591a\u5f84\u4fe1\u9053\u4e0b\u51c6\u786e\u6027\u53d7\u635f\uff0c\u73b0\u6709\u6297\u591a\u5f84\u65b9\u6cd5\u9700\u8981\u53cd\u9988\u6216\u591a\u65f6\u95f4\u70b9\u5904\u7406\uff0c\u5f15\u5165\u989d\u5916\u4fe1\u4ee4\u5ef6\u8fdf\u3002", "method": "\u4f7f\u7528\u591a\u63a5\u6536\u5929\u7ebf\u7684\u5171\u65f6\u4fe1\u9053\u9891\u7387\u54cd\u5e94\uff0c\u8ba1\u7b97\u5bf9\u6570\u7ebf\u6027\u5dee\u503c\u6bd4(LLDR)\u6765\u4fdd\u7559\u533a\u5206\u6027\u5c04\u9891\u6307\u7eb9\u7279\u5f81\uff1b\u5c06\u9891\u5e26\u5206\u5272\u4e3a\u5b50\u5e26\uff0c\u5728\u6bcf\u4e2a\u5b50\u5e26\u5185\u5355\u72ec\u8ba1\u7b97LLDR\u4ee5\u514b\u670d\u5bf9\u6700\u5c0f\u4fe1\u9053\u53d8\u5316\u7684\u4f9d\u8d56\u3002", "result": "\u572820\u8def\u5f84\u4fe1\u9053\u3001\u4fe1\u566a\u6bd420dB\u6761\u4ef6\u4e0b\uff0c\u5bf930\u4e2a\u7528\u6237\u8bbe\u5907\u7684\u8bc6\u522b\u51c6\u786e\u7387\u8fbe\u523096.13%\uff1b\u4f7f\u7528Roofline\u6a21\u578b\u8bc4\u4f30\u7406\u8bba\u5ef6\u8fdf\uff0c\u7a7a\u4e2d\u63a5\u53e3\u5ef6\u8fdf\u4e3a0.491ms\uff0c\u6ee1\u8db3URLLC\u5ef6\u8fdf\u8981\u6c42\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684LLDR\u65b9\u6848\u80fd\u591f\u6709\u6548\u89e3\u51b3\u591a\u5f84\u4fe1\u9053\u4e0b\u7684\u5c04\u9891\u6307\u7eb9\u8bc6\u522b\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u8bc6\u522b\u51c6\u786e\u7387\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\uff0c\u6ee1\u8db35G\u8d85\u53ef\u9760\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u7684\u8981\u6c42\u3002"}}
{"id": "2511.09447", "categories": ["cs.DC", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.09447", "abs": "https://arxiv.org/abs/2511.09447", "authors": ["Lukas Gianinazzi", "Tal Ben-Nun", "Torsten Hoefler"], "title": "SPADA: A Spatial Dataflow Architecture Programming Language", "comment": null, "summary": "Spatial dataflow architectures like the Cerebras Wafer-Scale Engine achieve exceptional performance in AI and scientific applications by leveraging distributed memory across processing elements (PEs) and localized computation. However, programming these architectures remains challenging due to the need for explicit orchestration of data movement through reconfigurable networks-on-chip and asynchronous computation triggered by data arrival. Existing FPGA and CGRA programming models emphasize loop scheduling but overlook the unique capabilities of spatial dataflow architectures, particularly efficient dataflow over regular grids and intricate routing management.\n  We present SPADA, a programming language that provides precise control over data placement, dataflow patterns, and asynchronous operations while abstracting architecture-specific low-level details. We introduce a rigorous dataflow semantics framework for SPADA that defines routing correctness, data races, and deadlocks. Additionally, we design and implement a compiler targeting Cerebras CSL with multi-level lowering.\n  SPADA serves as both a high-level programming interface and an intermediate representation for domain-specific languages (DSLs), which we demonstrate with the GT4Py stencil DSL. SPADA enables developers to express complex parallel patterns -- including pipelined reductions and multi-dimensional stencils -- in 6--8x less code than CSL with near-ideal weak scaling across three orders of magnitude. By unifying programming for spatial dataflow architectures under a single model, SPADA advances both the theoretical foundations and practical usability of these emerging high-performance computing platforms.", "AI": {"tldr": "SPADA\u662f\u4e00\u4e2a\u9488\u5bf9\u7a7a\u95f4\u6570\u636e\u6d41\u67b6\u6784\u7684\u7f16\u7a0b\u8bed\u8a00\uff0c\u901a\u8fc7\u62bd\u8c61\u5e95\u5c42\u67b6\u6784\u7ec6\u8282\uff0c\u63d0\u4f9b\u5bf9\u6570\u636e\u653e\u7f6e\u3001\u6570\u636e\u6d41\u6a21\u5f0f\u548c\u5f02\u6b65\u64cd\u4f5c\u7684\u7cbe\u786e\u63a7\u5236\uff0c\u663e\u8457\u7b80\u5316\u4e86\u7f16\u7a0b\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684FPGA\u548cCGRA\u7f16\u7a0b\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u5faa\u73af\u8c03\u5ea6\uff0c\u4f46\u5ffd\u89c6\u4e86\u7a7a\u95f4\u6570\u636e\u6d41\u67b6\u6784\u7684\u72ec\u7279\u80fd\u529b\uff0c\u7279\u522b\u662f\u9ad8\u6548\u7684\u6570\u636e\u6d41\u7ba1\u7406\u548c\u590d\u6742\u8def\u7531\u63a7\u5236\uff0c\u5bfc\u81f4\u7f16\u7a0b\u8fd9\u4e9b\u67b6\u6784\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e86SPADA\u7f16\u7a0b\u8bed\u8a00\uff0c\u5f15\u5165\u4e25\u683c\u7684\u6570\u636e\u6d41\u8bed\u4e49\u6846\u67b6\u6765\u5b9a\u4e49\u8def\u7531\u6b63\u786e\u6027\u3001\u6570\u636e\u7ade\u4e89\u548c\u6b7b\u9501\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9488\u5bf9Cerebras CSL\u7684\u591a\u7ea7\u964d\u4f4e\u7f16\u8bd1\u5668\u3002", "result": "SPADA\u4f7f\u5f00\u53d1\u8005\u80fd\u591f\u7528\u6bd4CSL\u5c116-8\u500d\u7684\u4ee3\u7801\u8868\u8fbe\u590d\u6742\u7684\u5e76\u884c\u6a21\u5f0f\uff0c\u5728\u4e09\u4e2a\u6570\u91cf\u7ea7\u4e0a\u5b9e\u73b0\u4e86\u63a5\u8fd1\u7406\u60f3\u7684\u5f31\u6269\u5c55\u6027\u80fd\u3002", "conclusion": "SPADA\u901a\u8fc7\u7edf\u4e00\u7a7a\u95f4\u6570\u636e\u6d41\u67b6\u6784\u7684\u7f16\u7a0b\u6a21\u578b\uff0c\u63a8\u52a8\u4e86\u8fd9\u4e9b\u65b0\u5174\u9ad8\u6027\u80fd\u8ba1\u7b97\u5e73\u53f0\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u53ef\u7528\u6027\u3002"}}
{"id": "2511.08873", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08873", "abs": "https://arxiv.org/abs/2511.08873", "authors": ["Shouang Wei", "Min Zhang", "Xin Lin", "Bo Jiang", "Kun Kuang", "Zhongxiang Dai"], "title": "UCO: A Multi-Turn Interactive Reinforcement Learning Method for Adaptive Teaching with Large Language Models", "comment": null, "summary": "Large language models (LLMs) are shifting from answer providers to intelligent tutors in educational settings, yet current supervised fine-tuning methods only learn surface teaching patterns without dynamic adaptation capabilities. Recent reinforcement learning approaches address this limitation but face two critical challenges. First, they evaluate teaching effectiveness solely based on whether students produce correct outputs, unable to distinguish whether students genuinely understand or echo teacher-provided answers during interaction. Second, they cannot perceive students' evolving cognitive states in real time through interactive dialogue, thus failing to adapt teaching strategies to match students' cognitive levels dynamically. We propose the Unidirectional Cognitive Optimization (UCO) method to address these challenges. UCO uses a multi-turn interactive reinforcement learning paradigm where the innovation lies in two synergistic reward functions: the Progress Reward captures students' cognitive advancement, evaluating whether students truly transition from confusion to comprehension, while the Scaffold Reward dynamically identifies each student's Zone of Proximal Development (ZPD), encouraging teachers to maintain productive teaching within this zone. We evaluate UCO by comparing it against 11 baseline models on BigMath and MathTutorBench benchmarks. Experimental results demonstrate that our UCO model outperforms all models of equivalent scale and achieves performance comparable to advanced closed-source models. The code and data are available at https://github.com/Mind-Lab-ECNU/UCO.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5355\u5411\u8ba4\u77e5\u4f18\u5316(UCO)\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u8f6e\u4ea4\u4e92\u5f0f\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3LLM\u4f5c\u4e3a\u667a\u80fd\u5bfc\u5e08\u65f6\u7684\u52a8\u6001\u9002\u5e94\u95ee\u9898\uff0c\u4f7f\u7528\u8fdb\u5ea6\u5956\u52b1\u548c\u652f\u67b6\u5956\u52b1\u6765\u8bc4\u4f30\u5b66\u751f\u8ba4\u77e5\u8fdb\u6b65\u548c\u8bc6\u522b\u6700\u8fd1\u53d1\u5c55\u533a\u3002", "motivation": "\u5f53\u524dLLM\u5728\u6559\u80b2\u573a\u666f\u4e2d\u4ece\u7b54\u6848\u63d0\u4f9b\u8005\u8f6c\u5411\u667a\u80fd\u5bfc\u5e08\uff0c\u4f46\u73b0\u6709\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u53ea\u80fd\u5b66\u4e60\u8868\u9762\u6559\u5b66\u6a21\u5f0f\uff0c\u7f3a\u4e4f\u52a8\u6001\u9002\u5e94\u80fd\u529b\u3002\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a\u65e0\u6cd5\u533a\u5206\u5b66\u751f\u662f\u5426\u771f\u6b63\u7406\u89e3\u8fd8\u662f\u7b80\u5355\u91cd\u590d\u7b54\u6848\uff0c\u4ee5\u53ca\u65e0\u6cd5\u5b9e\u65f6\u611f\u77e5\u5b66\u751f\u8ba4\u77e5\u72b6\u6001\u53d8\u5316\u3002", "method": "\u63d0\u51faUCO\u65b9\u6cd5\uff0c\u91c7\u7528\u591a\u8f6e\u4ea4\u4e92\u5f0f\u5f3a\u5316\u5b66\u4e60\u8303\u5f0f\uff0c\u5305\u542b\u4e24\u4e2a\u534f\u540c\u5956\u52b1\u51fd\u6570\uff1a\u8fdb\u5ea6\u5956\u52b1\u6355\u6349\u5b66\u751f\u8ba4\u77e5\u8fdb\u6b65\uff0c\u8bc4\u4f30\u5b66\u751f\u662f\u5426\u4ece\u56f0\u60d1\u8f6c\u5411\u7406\u89e3\uff1b\u652f\u67b6\u5956\u52b1\u52a8\u6001\u8bc6\u522b\u6bcf\u4e2a\u5b66\u751f\u7684\u6700\u8fd1\u53d1\u5c55\u533a\uff0c\u9f13\u52b1\u6559\u5e08\u5728\u8be5\u533a\u57df\u5185\u4fdd\u6301\u6709\u6548\u6559\u5b66\u3002", "result": "\u5728BigMath\u548cMathTutorBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e0e11\u4e2a\u57fa\u7ebf\u6a21\u578b\u6bd4\u8f83\uff0cUCO\u6a21\u578b\u5728\u540c\u7b49\u89c4\u6a21\u6a21\u578b\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u6027\u80fd\u63a5\u8fd1\u5148\u8fdb\u7684\u95ed\u6e90\u6a21\u578b\u3002", "conclusion": "UCO\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86LLM\u4f5c\u4e3a\u667a\u80fd\u5bfc\u5e08\u65f6\u7684\u52a8\u6001\u9002\u5e94\u95ee\u9898\uff0c\u901a\u8fc7\u8ba4\u77e5\u72b6\u6001\u611f\u77e5\u548c\u6700\u8fd1\u53d1\u5c55\u533a\u8bc6\u522b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6559\u5b66\u6548\u679c\u3002"}}
{"id": "2511.08905", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08905", "abs": "https://arxiv.org/abs/2511.08905", "authors": ["Zixun Xiong", "Gaoyi Wu", "Qingyang Yu", "Mingyu Derek Ma", "Lingfeng Yao", "Miao Pan", "Xiaojiang Du", "Hao Wang"], "title": "iSeal: Encrypted Fingerprinting for Reliable LLM Ownership Verification", "comment": "Accepted by AAAI 2026", "summary": "Given the high cost of large language model (LLM) training from scratch, safeguarding LLM intellectual property (IP) has become increasingly crucial. As the standard paradigm for IP ownership verification, LLM fingerprinting thus plays a vital role in addressing this challenge. Existing LLM fingerprinting methods verify ownership by extracting or injecting model-specific features. However, they overlook potential attacks during the verification process, leaving them ineffective when the model thief fully controls the LLM's inference process. In such settings, attackers may share prompt-response pairs to enable fingerprint unlearning or manipulate outputs to evade exact-match verification. We propose iSeal, the first fingerprinting method designed for reliable verification when the model thief controls the suspected LLM in an end-to-end manner. It injects unique features into both the model and an external module, reinforced by an error-correction mechanism and a similarity-based verification strategy. These components are resistant to verification-time attacks, including collusion-based fingerprint unlearning and response manipulation, backed by both theoretical analysis and empirical results. iSeal achieves 100 percent Fingerprint Success Rate (FSR) on 12 LLMs against more than 10 attacks, while baselines fail under unlearning and response manipulations.", "AI": {"tldr": "iSeal\u662f\u4e00\u79cd\u9488\u5bf9LLM\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u7684\u6307\u7eb9\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u6a21\u578b\u7a83\u8d3c\u5b8c\u5168\u63a7\u5236\u63a8\u7406\u8fc7\u7a0b\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u53ef\u9760\u9a8c\u8bc1\uff0c\u901a\u8fc7\u5c06\u72ec\u7279\u7279\u5f81\u6ce8\u5165\u6a21\u578b\u548c\u5916\u90e8\u6a21\u5757\uff0c\u7ed3\u5408\u7ea0\u9519\u673a\u5236\u548c\u76f8\u4f3c\u6027\u9a8c\u8bc1\u7b56\u7565\uff0c\u62b5\u6297\u9a8c\u8bc1\u65f6\u653b\u51fb\u3002", "motivation": "\u7531\u4e8eLLM\u8bad\u7ec3\u6210\u672c\u9ad8\u6602\uff0c\u4fdd\u62a4\u5176\u77e5\u8bc6\u4ea7\u6743\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u6307\u7eb9\u65b9\u6cd5\u5728\u9a8c\u8bc1\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u53d7\u5230\u653b\u51fb\uff0c\u5f53\u6a21\u578b\u7a83\u8d3c\u5b8c\u5168\u63a7\u5236LLM\u63a8\u7406\u8fc7\u7a0b\u65f6\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u4f1a\u5931\u6548\u3002", "method": "\u63d0\u51faiSeal\u65b9\u6cd5\uff0c\u5c06\u72ec\u7279\u7279\u5f81\u6ce8\u5165\u6a21\u578b\u548c\u5916\u90e8\u6a21\u5757\uff0c\u91c7\u7528\u7ea0\u9519\u673a\u5236\u548c\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u9a8c\u8bc1\u7b56\u7565\uff0c\u62b5\u6297\u57fa\u4e8e\u5408\u8c0b\u7684\u6307\u7eb9\u9057\u5fd8\u548c\u54cd\u5e94\u64cd\u7eb5\u7b49\u9a8c\u8bc1\u65f6\u653b\u51fb\u3002", "result": "\u572812\u4e2aLLM\u4e0a\u5bf9\u629710\u591a\u79cd\u653b\u51fb\uff0ciSeal\u5b9e\u73b0\u4e86100%\u7684\u6307\u7eb9\u6210\u529f\u7387\uff0c\u800c\u57fa\u7ebf\u65b9\u6cd5\u5728\u9057\u5fd8\u548c\u54cd\u5e94\u64cd\u7eb5\u653b\u51fb\u4e0b\u5747\u5931\u8d25\u3002", "conclusion": "iSeal\u662f\u9996\u4e2a\u5728\u6a21\u578b\u7a83\u8d3c\u7aef\u5230\u7aef\u63a7\u5236\u53ef\u7591LLM\u65f6\u4ecd\u80fd\u53ef\u9760\u9a8c\u8bc1\u7684\u6307\u7eb9\u65b9\u6cd5\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7ed3\u679c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2511.09485", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.09485", "abs": "https://arxiv.org/abs/2511.09485", "authors": ["Miroslav Popovic", "Marko Popovic", "Pavle Vasiljevic", "Miodrag Djukic"], "title": "Formal Verification of a Generic Algorithm for TDM Communication Over Inter Satellite Links", "comment": "4 pages, 1 figure, 3 tables", "summary": "The Python Testbed for Federated Learning Algorithms is a simple FL framework targeting edge systems, which provides the three generic algorithms: the centralized federated learning, the decentralized federated learning, and the universal TDM communication in the current time slot. The first two were formally verified in a previous paper using the CSP process algebra, and in this paper, we use the same approach to formally verify the third one, in two phases. In the first phase, we construct the CSP model as a faithful representation of the real Python code. In the second phase, the model checker PAT automatically proves correctness of the third generic algorithm by proving its deadlock freeness (safety property) and successful termination (liveness property).", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528CSP\u8fdb\u7a0b\u4ee3\u6570\u5bf9Python\u8054\u90a6\u5b66\u4e60\u6d4b\u8bd5\u5e73\u53f0\u4e2d\u7684\u7b2c\u4e09\u4e2a\u901a\u7528\u7b97\u6cd5\uff08TDM\u901a\u4fe1\uff09\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u6784\u5efaCSP\u6a21\u578b\u548c\u81ea\u52a8\u9a8c\u8bc1\u5b89\u5168\u6027\u4e0e\u6d3b\u6027\u5c5e\u6027\u3002", "motivation": "\u8be5Python\u8054\u90a6\u5b66\u4e60\u6d4b\u8bd5\u5e73\u53f0\u63d0\u4f9b\u4e86\u4e09\u79cd\u901a\u7528\u7b97\u6cd5\uff0c\u524d\u4e24\u79cd\u5df2\u5728\u5148\u524d\u8bba\u6587\u4e2d\u901a\u8fc7CSP\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u672c\u6587\u65e8\u5728\u9a8c\u8bc1\u7b2c\u4e09\u4e2a\u7b97\u6cd5\uff08TDM\u901a\u4fe1\uff09\u7684\u6b63\u786e\u6027\u3002", "method": "\u91c7\u7528CSP\u8fdb\u7a0b\u4ee3\u6570\u65b9\u6cd5\uff0c\u9996\u5148\u6784\u5efa\u5fe0\u5b9e\u53cd\u6620\u5b9e\u9645Python\u4ee3\u7801\u7684CSP\u6a21\u578b\uff0c\u7136\u540e\u4f7f\u7528\u6a21\u578b\u68c0\u67e5\u5668PAT\u81ea\u52a8\u9a8c\u8bc1\u7b97\u6cd5\u7684\u6b7b\u9501\u81ea\u7531\u6027\uff08\u5b89\u5168\u6027\uff09\u548c\u6210\u529f\u7ec8\u6b62\u6027\uff08\u6d3b\u6027\uff09\u3002", "result": "\u6a21\u578b\u68c0\u67e5\u5668PAT\u6210\u529f\u8bc1\u660e\u4e86\u7b2c\u4e09\u4e2a\u901a\u7528\u7b97\u6cd5\u7684\u6b63\u786e\u6027\uff0c\u9a8c\u8bc1\u4e86\u5176\u5b89\u5168\u6027\u548c\u6d3b\u6027\u5c5e\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u6210\u529f\u8bc1\u660e\u4e86Python\u8054\u90a6\u5b66\u4e60\u6d4b\u8bd5\u5e73\u53f0\u4e2dTDM\u901a\u4fe1\u7b97\u6cd5\u7684\u6b63\u786e\u6027\uff0c\u4e3a\u8fb9\u7f18\u7cfb\u7edf\u7684\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u7406\u8bba\u4fdd\u8bc1\u3002"}}
{"id": "2511.08892", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08892", "abs": "https://arxiv.org/abs/2511.08892", "authors": ["Weihao Tan", "Xiangyang Li", "Yunhao Fang", "Heyuan Yao", "Shi Yan", "Hao Luo", "Tenglong Ao", "Huihui Li", "Hongbin Ren", "Bairen Yi", "Yujia Qin", "Bo An", "Libin Liu", "Guang Shi"], "title": "Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds", "comment": null, "summary": "We introduce Lumine, the first open recipe for developing generalist agents capable of completing hours-long complex missions in real time within challenging 3D open-world environments. Lumine adopts a human-like interaction paradigm that unifies perception, reasoning, and action in an end-to-end manner, powered by a vision-language model. It processes raw pixels at 5 Hz to produce precise 30 Hz keyboard-mouse actions and adaptively invokes reasoning only when necessary. Trained in Genshin Impact, Lumine successfully completes the entire five-hour Mondstadt main storyline on par with human-level efficiency and follows natural language instructions to perform a broad spectrum of tasks in both 3D open-world exploration and 2D GUI manipulation across collection, combat, puzzle-solving, and NPC interaction. In addition to its in-domain performance, Lumine demonstrates strong zero-shot cross-game generalization. Without any fine-tuning, it accomplishes 100-minute missions in Wuthering Waves and the full five-hour first chapter of Honkai: Star Rail. These promising results highlight Lumine's effectiveness across distinct worlds and interaction dynamics, marking a concrete step toward generalist agents in open-ended environments.", "AI": {"tldr": "Lumine\u662f\u9996\u4e2a\u80fd\u591f\u57283D\u5f00\u653e\u4e16\u754c\u4e2d\u5b9e\u65f6\u5b8c\u6210\u6570\u5c0f\u65f6\u590d\u6742\u4efb\u52a1\u7684\u901a\u7528\u667a\u80fd\u4f53\uff0c\u91c7\u7528\u7aef\u5230\u7aef\u7684\u4eba\u673a\u4ea4\u4e92\u8303\u5f0f\uff0c\u5728Genshin Impact\u4e2d\u8bad\u7ec3\u540e\u80fd\u5b8c\u62105\u5c0f\u65f6\u4e3b\u7ebf\u5267\u60c5\uff0c\u5e76\u5177\u5907\u96f6\u6837\u672c\u8de8\u6e38\u620f\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f00\u53d1\u80fd\u591f\u5728\u590d\u67423D\u5f00\u653e\u4e16\u754c\u4e2d\u5b8c\u6210\u957f\u65f6\u95f4\u4efb\u52a1\u7684\u901a\u7528\u667a\u80fd\u4f53\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5b9e\u65f6\u3001\u957f\u65f6\u7a0b\u4efb\u52a1\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7aef\u5230\u7aef\u67b6\u6784\uff0c\u4ee55Hz\u5904\u7406\u539f\u59cb\u50cf\u7d20\u5e76\u751f\u621030Hz\u7684\u952e\u76d8\u9f20\u6807\u52a8\u4f5c\uff0c\u4ec5\u5728\u5fc5\u8981\u65f6\u8fdb\u884c\u63a8\u7406\u8c03\u7528\uff0c\u5728Genshin Impact\u4e2d\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u6210\u529f\u5b8c\u6210Genshin Impact\u4e2d5\u5c0f\u65f6Mondstadt\u4e3b\u7ebf\u5267\u60c5\uff0c\u6548\u7387\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\uff1b\u5728Wuthering Waves\u548cHonkai: Star Rail\u4e2d\u96f6\u6837\u672c\u5b8c\u6210100\u5206\u949f\u548c5\u5c0f\u65f6\u4efb\u52a1\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u8de8\u6e38\u620f\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "Lumine\u5728\u591a\u4e2a\u4e0d\u540c\u4e16\u754c\u548c\u4ea4\u4e92\u52a8\u6001\u4e2d\u8868\u73b0\u51fa\u6709\u6548\u6027\uff0c\u6807\u5fd7\u7740\u5728\u5f00\u653e\u73af\u5883\u4e2d\u5f00\u53d1\u901a\u7528\u667a\u80fd\u4f53\u7684\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2511.08985", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08985", "abs": "https://arxiv.org/abs/2511.08985", "authors": ["Yunfei Yang", "Xiaojun Chen", "Yuexin Xuan", "Zhendong Zhao", "Xin Zhao", "He Li"], "title": "DeepTracer: Tracing Stolen Model via Deep Coupled Watermarks", "comment": "Extended version of the paper accepted by AAAI 2026", "summary": "Model watermarking techniques can embed watermark information into the protected model for ownership declaration by constructing specific input-output pairs. However, existing watermarks are easily removed when facing model stealing attacks, and make it difficult for model owners to effectively verify the copyright of stolen models. In this paper, we analyze the root cause of the failure of current watermarking methods under model stealing scenarios and then explore potential solutions. Specifically, we introduce a robust watermarking framework, DeepTracer, which leverages a novel watermark samples construction method and a same-class coupling loss constraint. DeepTracer can incur a high-coupling model between watermark task and primary task that makes adversaries inevitably learn the hidden watermark task when stealing the primary task functionality. Furthermore, we propose an effective watermark samples filtering mechanism that elaborately select watermark key samples used in model ownership verification to enhance the reliability of watermarks. Extensive experiments across multiple datasets and models demonstrate that our method surpasses existing approaches in defending against various model stealing attacks, as well as watermark attacks, and achieves new state-of-the-art effectiveness and robustness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DeepTracer\uff0c\u4e00\u79cd\u9488\u5bf9\u6a21\u578b\u7a83\u53d6\u653b\u51fb\u7684\u9c81\u68d2\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u6c34\u5370\u6837\u672c\u6784\u5efa\u65b9\u6cd5\u548c\u540c\u7c7b\u8026\u5408\u635f\u5931\u7ea6\u675f\uff0c\u4f7f\u653b\u51fb\u8005\u5728\u7a83\u53d6\u4e3b\u8981\u529f\u80fd\u65f6\u4e0d\u53ef\u907f\u514d\u5730\u5b66\u4e60\u9690\u85cf\u7684\u6c34\u5370\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u6c34\u5370\u6280\u672f\u5728\u9762\u5bf9\u6a21\u578b\u7a83\u53d6\u653b\u51fb\u65f6\u5bb9\u6613\u88ab\u79fb\u9664\uff0c\u5bfc\u81f4\u6a21\u578b\u6240\u6709\u8005\u96be\u4ee5\u6709\u6548\u9a8c\u8bc1\u88ab\u76d7\u6a21\u578b\u7684\u7248\u6743\u3002\u672c\u6587\u5206\u6790\u4e86\u5f53\u524d\u6c34\u5370\u65b9\u6cd5\u5728\u6a21\u578b\u7a83\u53d6\u573a\u666f\u4e0b\u5931\u8d25\u7684\u6839\u672c\u539f\u56e0\uff0c\u5e76\u63a2\u7d22\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002", "method": "DeepTracer\u6846\u67b6\u91c7\u7528\u65b0\u9896\u7684\u6c34\u5370\u6837\u672c\u6784\u5efa\u65b9\u6cd5\u548c\u540c\u7c7b\u8026\u5408\u635f\u5931\u7ea6\u675f\uff0c\u521b\u5efa\u6c34\u5370\u4efb\u52a1\u4e0e\u4e3b\u8981\u4efb\u52a1\u4e4b\u95f4\u7684\u9ad8\u5ea6\u8026\u5408\u6a21\u578b\u3002\u540c\u65f6\u63d0\u51fa\u6709\u6548\u7684\u6c34\u5370\u6837\u672c\u8fc7\u6ee4\u673a\u5236\uff0c\u7cbe\u5fc3\u9009\u62e9\u7528\u4e8e\u6a21\u578b\u6240\u6709\u6743\u9a8c\u8bc1\u7684\u6c34\u5370\u5173\u952e\u6837\u672c\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u9632\u5fa1\u5404\u79cd\u6a21\u578b\u7a83\u53d6\u653b\u51fb\u548c\u6c34\u5370\u653b\u51fb\u65b9\u9762\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6700\u65b0\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "DeepTracer\u901a\u8fc7\u5efa\u7acb\u6c34\u5370\u4efb\u52a1\u4e0e\u4e3b\u8981\u4efb\u52a1\u7684\u9ad8\u5ea6\u8026\u5408\u5173\u7cfb\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u6c34\u5370\u5728\u5bf9\u6297\u6a21\u578b\u7a83\u53d6\u653b\u51fb\u65f6\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u6a21\u578b\u7248\u6743\u4fdd\u62a4\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.09043", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09043", "abs": "https://arxiv.org/abs/2511.09043", "authors": ["Farjana Yesmin"], "title": "MedHE: Communication-Efficient Privacy-Preserving Federated Learning with Adaptive Gradient Sparsification for Healthcare", "comment": "8 pages, 4 Figures, 5 Tables", "summary": "Healthcare federated learning requires strong privacy guarantees while maintaining computational efficiency across resource-constrained medical institutions. This paper presents MedHE, a novel framework combining adaptive gradient sparsification with CKKS homomorphic encryption to enable privacy-preserving collaborative learning on sensitive medical data. Our approach introduces a dynamic threshold mechanism with error compensation for top-k gradient selection, achieving 97.5 percent communication reduction while preserving model utility. We provide formal security analysis under Ring Learning with Errors assumptions and demonstrate differential privacy guarantees with epsilon less than or equal to 1.0. Statistical testing across 5 independent trials shows MedHE achieves 89.5 percent plus or minus 0.8 percent accuracy, maintaining comparable performance to standard federated learning (p=0.32) while reducing communication from 1277 MB to 32 MB per training round. Comprehensive evaluation demonstrates practical feasibility for real-world medical deployments with HIPAA compliance and scalability to 100 plus institutions.", "AI": {"tldr": "MedHE\u6846\u67b6\u7ed3\u5408\u81ea\u9002\u5e94\u68af\u5ea6\u7a00\u758f\u5316\u548cCKKS\u540c\u6001\u52a0\u5bc6\uff0c\u5728\u533b\u7597\u8054\u90a6\u5b66\u4e60\u4e2d\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u534f\u4f5c\u5b66\u4e60\uff0c\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u533b\u7597\u8054\u90a6\u5b66\u4e60\u9700\u8981\u5728\u8d44\u6e90\u53d7\u9650\u7684\u533b\u7597\u673a\u6784\u4e4b\u95f4\u63d0\u4f9b\u5f3a\u5927\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u91c7\u7528\u81ea\u9002\u5e94\u68af\u5ea6\u7a00\u758f\u5316\u4e0eCKKS\u540c\u6001\u52a0\u5bc6\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u5f15\u5165\u5e26\u8bef\u5dee\u8865\u507f\u7684\u52a8\u6001\u9608\u503c\u673a\u5236\u8fdb\u884ctop-k\u68af\u5ea6\u9009\u62e9\u3002", "result": "\u5b9e\u73b097.5%\u7684\u901a\u4fe1\u51cf\u5c11\uff0c\u57285\u6b21\u72ec\u7acb\u8bd5\u9a8c\u4e2d\u8fbe\u523089.5%\u00b10.8%\u7684\u51c6\u786e\u7387\uff0c\u901a\u4fe1\u91cf\u4ece\u6bcf\u8f6e1277MB\u51cf\u5c11\u523032MB\uff0c\u6027\u80fd\u4e0e\u6807\u51c6\u8054\u90a6\u5b66\u4e60\u76f8\u5f53(p=0.32)\u3002", "conclusion": "MedHE\u6846\u67b6\u5177\u6709\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u7b26\u5408HIPAA\u5408\u89c4\u8981\u6c42\uff0c\u53ef\u6269\u5c55\u5230100\u591a\u4e2a\u673a\u6784\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u533b\u7597\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.09051", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.09051", "abs": "https://arxiv.org/abs/2511.09051", "authors": ["Parsa Hedayatnia", "Tina Tavakkoli", "Hadi Amini", "Mohammad Allahbakhsh", "Haleh Amintoosi"], "title": "Attack-Centric by Design: A Program-Structure Taxonomy of Smart Contract Vulnerabilities", "comment": "42 pages, 1 figure, 8 root-cause families", "summary": "Smart contracts concentrate high value assets and complex logic in small, immutable programs, where even minor bugs can cause major losses. Existing taxonomies and tools remain fragmented, organized around symptoms such as reentrancy rather than structural causes. This paper introduces an attack-centric, program-structure taxonomy that unifies Solidity vulnerabilities into eight root-cause families covering control flow, external calls, state integrity, arithmetic safety, environmental dependencies, access control, input validation, and cross-domain protocol assumptions. Each family is illustrated through concise Solidity examples, exploit mechanics, and mitigations, and linked to the detection signals observable by static, dynamic, and learning-based tools. We further cross-map legacy datasets (SmartBugs, SolidiFI) to this taxonomy to reveal label drift and coverage gaps. The taxonomy provides a consistent vocabulary and practical checklist that enable more interpretable detection, reproducible audits, and structured security education for both researchers and practitioners.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u653b\u51fb\u7684\u3001\u7a0b\u5e8f\u7ed3\u6784\u5bfc\u5411\u7684\u6f0f\u6d1e\u5206\u7c7b\u6cd5\uff0c\u5c06Solidity\u6f0f\u6d1e\u7edf\u4e00\u4e3a8\u4e2a\u6839\u672c\u539f\u56e0\u5bb6\u65cf\uff0c\u4e3a\u667a\u80fd\u5408\u7ea6\u5b89\u5168\u63d0\u4f9b\u4e00\u81f4\u7684\u8bcd\u6c47\u8868\u548c\u5b9e\u7528\u68c0\u67e5\u6e05\u5355\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u5c06\u9ad8\u4ef7\u503c\u8d44\u4ea7\u548c\u590d\u6742\u903b\u8f91\u96c6\u4e2d\u5728\u5c0f\u578b\u4e0d\u53ef\u53d8\u7a0b\u5e8f\u4e2d\uff0c\u5373\u4f7f\u5fae\u5c0f\u9519\u8bef\u4e5f\u53ef\u80fd\u5bfc\u81f4\u91cd\u5927\u635f\u5931\u3002\u73b0\u6709\u5206\u7c7b\u6cd5\u548c\u5de5\u5177\u4ecd\u7136\u5206\u6563\uff0c\u56f4\u7ed5\u75c7\u72b6\u800c\u975e\u7ed3\u6784\u539f\u56e0\u7ec4\u7ec7\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u653b\u51fb\u7684\u3001\u7a0b\u5e8f\u7ed3\u6784\u5bfc\u5411\u7684\u5206\u7c7b\u6cd5\uff0c\u5c06Solidity\u6f0f\u6d1e\u7edf\u4e00\u4e3a8\u4e2a\u6839\u672c\u539f\u56e0\u5bb6\u65cf\uff1a\u63a7\u5236\u6d41\u3001\u5916\u90e8\u8c03\u7528\u3001\u72b6\u6001\u5b8c\u6574\u6027\u3001\u7b97\u672f\u5b89\u5168\u3001\u73af\u5883\u4f9d\u8d56\u3001\u8bbf\u95ee\u63a7\u5236\u3001\u8f93\u5165\u9a8c\u8bc1\u548c\u8de8\u57df\u534f\u8bae\u5047\u8bbe\u3002", "result": "\u6bcf\u4e2a\u5bb6\u65cf\u901a\u8fc7\u7b80\u6d01\u7684Solidity\u793a\u4f8b\u3001\u5229\u7528\u673a\u5236\u548c\u7f13\u89e3\u63aa\u65bd\u8fdb\u884c\u8bf4\u660e\uff0c\u5e76\u4e0e\u9759\u6001\u3001\u52a8\u6001\u548c\u57fa\u4e8e\u5b66\u4e60\u7684\u5de5\u5177\u53ef\u89c2\u5bdf\u7684\u68c0\u6d4b\u4fe1\u53f7\u76f8\u5173\u8054\u3002\u8fdb\u4e00\u6b65\u5c06\u4f20\u7edf\u6570\u636e\u96c6\u6620\u5c04\u5230\u6b64\u5206\u7c7b\u6cd5\u4ee5\u63ed\u793a\u6807\u7b7e\u6f02\u79fb\u548c\u8986\u76d6\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u5206\u7c7b\u6cd5\u63d0\u4f9b\u4e86\u4e00\u81f4\u7684\u8bcd\u6c47\u8868\u548c\u5b9e\u7528\u68c0\u67e5\u6e05\u5355\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u80fd\u591f\u8fdb\u884c\u66f4\u53ef\u89e3\u91ca\u7684\u68c0\u6d4b\u3001\u53ef\u91cd\u73b0\u7684\u5ba1\u8ba1\u548c\u7ed3\u6784\u5316\u7684\u5b89\u5168\u6559\u80b2\u3002"}}
{"id": "2511.08934", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08934", "abs": "https://arxiv.org/abs/2511.08934", "authors": ["Di Liao", "Ruijia Liang", "Ziyi Ye"], "title": "A Research on Business Process Optimisation Model Integrating AI and Big Data Analytics", "comment": null, "summary": "With the deepening of digital transformation, business process optimisation has become the key to improve the competitiveness of enterprises. This study constructs a business process optimisation model integrating artificial intelligence and big data to achieve intelligent management of the whole life cycle of processes. The model adopts a three-layer architecture incorporating data processing, AI algorithms, and business logic to enable real-time process monitoring and optimization. Through distributed computing and deep learning techniques, the system can handle complex business scenarios while maintaining high performance and reliability. Experimental validation across multiple enterprise scenarios shows that the model shortens process processing time by 42%, improves resource utilisation by 28%, and reduces operating costs by 35%. The system maintained 99.9% availability under high concurrent loads. The research results have important theoretical and practical value for promoting the digital transformation of enterprises, and provide new ideas for improving the operational efficiency of enterprises.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u878d\u5408\u4eba\u5de5\u667a\u80fd\u548c\u5927\u6570\u636e\u7684\u4e1a\u52a1\u6d41\u7a0b\u4f18\u5316\u6a21\u578b\uff0c\u91c7\u7528\u4e09\u5c42\u67b6\u6784\u5b9e\u73b0\u6d41\u7a0b\u5168\u751f\u547d\u5468\u671f\u7684\u667a\u80fd\u7ba1\u7406\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u8457\u63d0\u5347\u4e86\u4f01\u4e1a\u8fd0\u8425\u6548\u7387\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u5316\u8f6c\u578b\u7684\u6df1\u5165\uff0c\u4e1a\u52a1\u6d41\u7a0b\u4f18\u5316\u5df2\u6210\u4e3a\u63d0\u5347\u4f01\u4e1a\u7ade\u4e89\u529b\u7684\u5173\u952e\uff0c\u9700\u8981\u6784\u5efa\u667a\u80fd\u5316\u7684\u6d41\u7a0b\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5305\u542b\u6570\u636e\u5904\u7406\u3001AI\u7b97\u6cd5\u548c\u4e1a\u52a1\u903b\u8f91\u7684\u4e09\u5c42\u67b6\u6784\u6a21\u578b\uff0c\u7ed3\u5408\u5206\u5e03\u5f0f\u8ba1\u7b97\u548c\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\uff0c\u5b9e\u73b0\u5b9e\u65f6\u6d41\u7a0b\u76d1\u63a7\u548c\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff0c\u6a21\u578b\u7f29\u77ed\u6d41\u7a0b\u5904\u7406\u65f6\u95f442%\uff0c\u63d0\u9ad8\u8d44\u6e90\u5229\u7528\u738728%\uff0c\u964d\u4f4e\u8fd0\u8425\u6210\u672c35%\uff0c\u5e76\u5728\u9ad8\u5e76\u53d1\u8d1f\u8f7d\u4e0b\u4fdd\u630199.9%\u7684\u53ef\u7528\u6027\u3002", "conclusion": "\u7814\u7a76\u6210\u679c\u5bf9\u4f01\u4e1a\u6570\u5b57\u5316\u8f6c\u578b\u5177\u6709\u91cd\u8981\u7406\u8bba\u548c\u5b9e\u8df5\u4ef7\u503c\uff0c\u4e3a\u63d0\u5347\u4f01\u4e1a\u8fd0\u8425\u6548\u7387\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.08947", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08947", "abs": "https://arxiv.org/abs/2511.08947", "authors": ["Xiaohan Zhang", "Tian Gao", "Mingyue Cheng", "Bokai Pan", "Ze Guo", "Yaguo Liu", "Xiaoyu Tao"], "title": "AlphaCast: A Human Wisdom-LLM Intelligence Co-Reasoning Framework for Interactive Time Series Forecasting", "comment": null, "summary": "Time series forecasting plays a critical role in high-stakes domains such as energy, healthcare, and climate. Although recent advances have improved accuracy, most approaches still treat forecasting as a static one-time mapping task, lacking the interaction, reasoning, and adaptability of human experts. This gap limits their usefulness in complex real-world environments. To address this, we propose AlphaCast, a human wisdom-large language model (LLM) intelligence co-reasoning framework that redefines forecasting as an interactive process. The key idea is to enable step-by-step collaboration between human wisdom and LLM intelligence to jointly prepare, generate, and verify forecasts. The framework consists of two stages: (1) automated prediction preparation, where AlphaCast builds a multi-source cognitive foundation comprising a feature set that captures key statistics and time patterns, a domain knowledge base distilled from corpora and historical series, a contextual repository that stores rich information for each time window, and a case base that retrieves optimal strategies via pattern clustering and matching; and (2) generative reasoning and reflective optimization, where AlphaCast integrates statistical temporal features, prior knowledge, contextual information, and forecasting strategies, triggering a meta-reasoning loop for continuous self-correction and strategy refinement. Extensive experiments on short- and long-term datasets show that AlphaCast consistently outperforms state-of-the-art baselines in predictive accuracy. Code is available at this repository: https://github.com/SkyeGT/AlphaCast_Official .", "AI": {"tldr": "AlphaCast\u662f\u4e00\u4e2a\u4eba\u7c7b\u667a\u6167\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u534f\u540c\u63a8\u7406\u7684\u6846\u67b6\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4ea4\u4e92\u8fc7\u7a0b\uff0c\u901a\u8fc7\u591a\u6e90\u8ba4\u77e5\u57fa\u7840\u548c\u751f\u6210\u63a8\u7406\u4f18\u5316\u4e24\u9636\u6bb5\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u9884\u6d4b\u3002", "motivation": "\u5f53\u524d\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u7f3a\u4e4f\u4eba\u7c7b\u4e13\u5bb6\u7684\u4ea4\u4e92\u3001\u63a8\u7406\u548c\u9002\u5e94\u6027\uff0c\u9650\u5236\u4e86\u5728\u590d\u6742\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u81ea\u52a8\u9884\u6d4b\u51c6\u5907\uff08\u6784\u5efa\u591a\u6e90\u8ba4\u77e5\u57fa\u7840\uff09\u548c\u751f\u6210\u63a8\u7406\u4e0e\u53cd\u601d\u4f18\u5316\uff08\u96c6\u6210\u7edf\u8ba1\u7279\u5f81\u3001\u5148\u9a8c\u77e5\u8bc6\u3001\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u9884\u6d4b\u7b56\u7565\uff0c\u89e6\u53d1\u5143\u63a8\u7406\u5faa\u73af\uff09\u3002", "result": "\u5728\u77ed\u671f\u548c\u957f\u671f\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cAlphaCast\u5728\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "AlphaCast\u901a\u8fc7\u4eba\u7c7b\u667a\u6167\u4e0eLLM\u667a\u80fd\u7684\u534f\u540c\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2511.09088", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09088", "abs": "https://arxiv.org/abs/2511.09088", "authors": ["Taifeng Liu", "Xinjing Liu", "Liangqiu Dong", "Yang Liu", "Yilong Yang", "Zhuo Ma"], "title": "Improving Sustainability of Adversarial Examples in Class-Incremental Learning", "comment": "This paper is accepted to AAAI 2026", "summary": "Current adversarial examples (AEs) are typically designed for static models. However, with the wide application of Class-Incremental Learning (CIL), models are no longer static and need to be updated with new data distributed and labeled differently from the old ones. As a result, existing AEs often fail after CIL updates due to significant domain drift. In this paper, we propose SAE to enhance the sustainability of AEs against CIL. The core idea of SAE is to enhance the robustness of AE semantics against domain drift by making them more similar to the target class while distinguishing them from all other classes. Achieving this is challenging, as relying solely on the initial CIL model to optimize AE semantics often leads to overfitting. To resolve the problem, we propose a Semantic Correction Module. This module encourages the AE semantics to be generalized, based on a visual-language model capable of producing universal semantics. Additionally, it incorporates the CIL model to correct the optimization direction of the AE semantics, guiding them closer to the target class. To further reduce fluctuations in AE semantics, we propose a Filtering-and-Augmentation Module, which first identifies non-target examples with target-class semantics in the latent space and then augments them to foster more stable semantics. Comprehensive experiments demonstrate that SAE outperforms baselines by an average of 31.28% when updated with a 9-fold increase in the number of classes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSAE\u65b9\u6cd5\uff0c\u65e8\u5728\u589e\u5f3a\u5bf9\u6297\u6837\u672c\u5728\u7c7b\u589e\u91cf\u5b66\u4e60(CIL)\u73af\u5883\u4e0b\u7684\u53ef\u6301\u7eed\u6027\uff0c\u89e3\u51b3\u73b0\u6709\u5bf9\u6297\u6837\u672c\u5728\u6a21\u578b\u66f4\u65b0\u540e\u5931\u6548\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5bf9\u6297\u6837\u672c\u4e3b\u8981\u9488\u5bf9\u9759\u6001\u6a21\u578b\u8bbe\u8ba1\uff0c\u4f46\u5728\u7c7b\u589e\u91cf\u5b66\u4e60\u573a\u666f\u4e2d\uff0c\u6a21\u578b\u4f1a\u4e0d\u65ad\u66f4\u65b0\uff0c\u5bfc\u81f4\u539f\u6709\u5bf9\u6297\u6837\u672c\u56e0\u9886\u57df\u6f02\u79fb\u800c\u5931\u6548\u3002", "method": "\u63d0\u51faSAE\u65b9\u6cd5\uff0c\u5305\u542b\u8bed\u4e49\u6821\u6b63\u6a21\u5757\u548c\u8fc7\u6ee4\u589e\u5f3a\u6a21\u5757\u3002\u8bed\u4e49\u6821\u6b63\u6a21\u5757\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u751f\u6210\u901a\u7528\u8bed\u4e49\uff0c\u5e76\u7ed3\u5408CIL\u6a21\u578b\u6821\u6b63AE\u8bed\u4e49\u4f18\u5316\u65b9\u5411\uff1b\u8fc7\u6ee4\u589e\u5f3a\u6a21\u5757\u8bc6\u522b\u5177\u6709\u76ee\u6807\u7c7b\u8bed\u4e49\u7684\u975e\u76ee\u6807\u6837\u672c\u5e76\u8fdb\u884c\u589e\u5f3a\uff0c\u4ee5\u7a33\u5b9a\u8bed\u4e49\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cSAE\u5728\u7c7b\u522b\u6570\u91cf\u589e\u52a09\u500d\u7684\u60c5\u51b5\u4e0b\uff0c\u5e73\u5747\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd531.28%\u3002", "conclusion": "SAE\u80fd\u6709\u6548\u63d0\u5347\u5bf9\u6297\u6837\u672c\u5728\u7c7b\u589e\u91cf\u5b66\u4e60\u73af\u5883\u4e0b\u7684\u53ef\u6301\u7eed\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2511.09005", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.09005", "abs": "https://arxiv.org/abs/2511.09005", "authors": ["Alvin Chauhan"], "title": "AI Founding Fathers: A Case Study of GIS Search in Multi-Agent Pipelines", "comment": "9 pages, 3 figures. Code and data available at https://github.com/alvco/Founding_Fathers_AI", "summary": "Although Large Language Models (LLMs) show exceptional fluency, efforts persist to extract stronger reasoning capabilities from them. Drawing on search-based interpretations of LLM computation, this paper advances a systematic framework for understanding LLM reasoning and optimization. Namely, that enhancing reasoning is best achieved by structuring a multi-agent pipeline to ensure a traversal of the search space in a gradual, incremental, and sequential (GIS) manner. Stated succinctly, high-quality reasoning is a controlled, incremental search. To test this framework, we investigate the efficacy of recursive refinement (RR)--an iterative process of self-criticism, adversarial stress-testing, and integrating critical feedback--as a practical method for implementing GIS search. We designed an experiment comparing a simple, linear pipeline against a complex, explicitly structured pipeline leveraging a recursive refinement layer. The multi-agent models were constructed to reflect the historical personas of three US Founding Fathers (Hamilton, Jefferson, and Madison) using RAG-powered corpora and were prompted to generate responses to three contemporary political issues. Model performance was evaluated using a two-tiered approach: a quantitative score from an LLM arbiter agent and qualitative human judgment. Our results revealed that the complex model consistently outperformed the simple model across all nine test cases with an average arbiter-outputted score of 88.3 versus 71.7. The complex model's arguments were superior in analytical depth, structural nuance, and strategic framing. We conclude that recursive refinement is a robust architectural feature for enhancing LLM reasoning via GIS search.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u7ed3\u6784\u5316\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u5b9e\u73b0\u6e10\u8fdb\u3001\u589e\u91cf\u3001\u987a\u5e8f\u7684\u641c\u7d22\u7a7a\u95f4\u904d\u5386\u6765\u589e\u5f3aLLM\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u9012\u5f52\u7cbe\u70bc\u65b9\u6cd5\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u51fa\u4f18\u79c0\u7684\u6d41\u7545\u6027\uff0c\u4f46\u7814\u7a76\u4eba\u5458\u4ecd\u5728\u52aa\u529b\u63d0\u53d6\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\u3002\u672c\u6587\u57fa\u4e8e\u641c\u7d22\u7684LLM\u8ba1\u7b97\u89e3\u91ca\uff0c\u65e8\u5728\u7cfb\u7edf\u5316\u7406\u89e3LLM\u63a8\u7406\u548c\u4f18\u5316\u3002", "method": "\u91c7\u7528\u9012\u5f52\u7cbe\u70bc\u65b9\u6cd5\uff0c\u5305\u62ec\u81ea\u6211\u6279\u8bc4\u3001\u5bf9\u6297\u6027\u538b\u529b\u6d4b\u8bd5\u548c\u6574\u5408\u5173\u952e\u53cd\u9988\u7684\u8fed\u4ee3\u8fc7\u7a0b\u3002\u8bbe\u8ba1\u4e86\u7b80\u5355\u7ebf\u6027\u7ba1\u9053\u4e0e\u590d\u6742\u7ed3\u6784\u5316\u7ba1\u9053\u7684\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u4f7f\u7528\u57fa\u4e8eRAG\u7684\u7f8e\u56fd\u5f00\u56fd\u5143\u52cb\u4eba\u7269\u6a21\u578b\u6765\u56de\u5e94\u5f53\u4ee3\u653f\u6cbb\u95ee\u9898\u3002", "result": "\u590d\u6742\u6a21\u578b\u5728\u6240\u6709\u4e5d\u4e2a\u6d4b\u8bd5\u6848\u4f8b\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u7b80\u5355\u6a21\u578b\uff0c\u5e73\u5747\u4ef2\u88c1\u8005\u8bc4\u5206\u4e3a88.3\u5bf971.7\u3002\u590d\u6742\u6a21\u578b\u7684\u8bba\u8bc1\u5728\u5206\u6790\u6df1\u5ea6\u3001\u7ed3\u6784\u7ec6\u5fae\u5dee\u522b\u548c\u6218\u7565\u6846\u67b6\u65b9\u9762\u66f4\u4f18\u8d8a\u3002", "conclusion": "\u9012\u5f52\u7cbe\u70bc\u662f\u901a\u8fc7GIS\u641c\u7d22\u589e\u5f3aLLM\u63a8\u7406\u7684\u7a33\u5065\u67b6\u6784\u7279\u5f81\uff0c\u9ad8\u8d28\u91cf\u63a8\u7406\u662f\u53d7\u63a7\u7684\u589e\u91cf\u641c\u7d22\u8fc7\u7a0b\u3002"}}
{"id": "2511.09120", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09120", "abs": "https://arxiv.org/abs/2511.09120", "authors": ["Luis Del Vasto-Terrientes"], "title": "Differentially Private Rankings via Outranking Methods and Performance Data Aggregation", "comment": "Accepted and published in the USB Proceedings of the 22th International Conference on Modeling Decisions for Artificial Intelligence (MDAI 2025), Valencia, Spain, September 15--18, 2025, ISBN 978-91-531-0240-3, pp. 21--32", "summary": "Multiple-Criteria Decision Making (MCDM) is a sub-discipline of Operations Research that helps decision-makers in choosing, ranking, or sorting alternatives based on conflicting criteria. Over time, its application has been expanded into dynamic and data-driven domains, such as recommender systems. In these contexts, the availability and handling of personal and sensitive data can play a critical role in the decision-making process. Despite this increased reliance on sensitive data, the integration of privacy mechanisms with MCDM methods is underdeveloped. This paper introduces an integrated approach that combines MCDM outranking methods with Differential Privacy (DP), safeguarding individual contributions' privacy in ranking problems. This approach relies on a pre-processing step to aggregate multiple user evaluations into a comprehensive performance matrix. The evaluation results show a strong to very strong statistical correlation between the true rankings and their anonymized counterparts, ensuring robust privacy parameter guarantees.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u591a\u51c6\u5219\u51b3\u7b56\u6392\u5e8f\u65b9\u6cd5\u4e0e\u5dee\u5206\u9690\u79c1\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u5728\u6392\u540d\u95ee\u9898\u4e2d\u4fdd\u62a4\u4e2a\u4f53\u8d21\u732e\u7684\u9690\u79c1\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u771f\u5b9e\u6392\u540d\u7684\u9ad8\u5ea6\u7edf\u8ba1\u76f8\u5173\u6027\u3002", "motivation": "\u968f\u7740\u591a\u51c6\u5219\u51b3\u7b56\u65b9\u6cd5\u5728\u52a8\u6001\u548c\u6570\u636e\u9a71\u52a8\u9886\u57df\u7684\u5e94\u7528\u6269\u5c55\uff0c\u7279\u522b\u662f\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u654f\u611f\u6570\u636e\u7684\u5904\u7406\u548c\u9690\u79c1\u4fdd\u62a4\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u9690\u79c1\u673a\u5236\u4e0e\u591a\u51c6\u5219\u51b3\u7b56\u65b9\u6cd5\u7684\u96c6\u6210\u4ecd\u7136\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u96c6\u6210\u65b9\u6cd5\uff0c\u5c06\u591a\u51c6\u5219\u51b3\u7b56\u6392\u5e8f\u65b9\u6cd5\u4e0e\u5dee\u5206\u9690\u79c1\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u9884\u5904\u7406\u6b65\u9aa4\u5c06\u591a\u4e2a\u7528\u6237\u8bc4\u4f30\u805a\u5408\u4e3a\u7efc\u5408\u6027\u80fd\u77e9\u9635\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u771f\u5b9e\u6392\u540d\u4e0e\u5176\u533f\u540d\u5bf9\u5e94\u7269\u4e4b\u95f4\u5b58\u5728\u5f3a\u5230\u975e\u5e38\u5f3a\u7684\u7edf\u8ba1\u76f8\u5173\u6027\uff0c\u540c\u65f6\u786e\u4fdd\u4e86\u7a33\u5065\u7684\u9690\u79c1\u53c2\u6570\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u5c06\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u96c6\u6210\u5230\u591a\u51c6\u5219\u51b3\u7b56\u8fc7\u7a0b\u4e2d\uff0c\u5728\u4fdd\u62a4\u4e2a\u4f53\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u51b3\u7b56\u6392\u540d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.09134", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.09134", "abs": "https://arxiv.org/abs/2511.09134", "authors": ["Zexu Wang", "Jiachi Chen", "Zewei Lin", "Wenqing Chen", "Kaiwen Ning", "Jianxing Yu", "Yuming Feng", "Yu Zhang", "Weizhe Zhang", "Zibin Zheng"], "title": "One Signature, Multiple Payments: Demystifying and Detecting Signature Replay Vulnerabilities in Smart Contracts", "comment": "Accepted at ICSE2026", "summary": "Smart contracts have significantly advanced blockchain technology, and digital signatures are crucial for reliable verification of contract authority. Through signature verification, smart contracts can ensure that signers possess the required permissions, thus enhancing security and scalability. However, lacking checks on signature usage conditions can lead to repeated verifications, increasing the risk of permission abuse and threatening contract assets. We define this issue as the Signature Replay Vulnerability (SRV). In this paper, we conducted the first empirical study to investigate the causes and characteristics of the SRVs. From 1,419 audit reports across 37 blockchain security companies, we identified 108 with detailed SRV descriptions and classified five types of SRVs. To detect these vulnerabilities automatically, we designed LASiR, which utilizes the general semantic understanding ability of Large Language Models (LLMs) to assist in the static taint analysis of the signature state and identify the signature reuse behavior. It also employs path reachability verification via symbolic execution to ensure effective and reliable detection. To evaluate the performance of LASiR, we conducted large-scale experiments on 15,383 contracts involving signature verification, selected from the initial dataset of 918,964 contracts across four blockchains: Ethereum, Binance Smart Chain, Polygon, and Arbitrum. The results indicate that SRVs are widespread, with affected contracts holding $4.76 million in active assets. Among these, 19.63% of contracts that use signatures on Ethereum contain SRVs. Furthermore, manual verification demonstrates that LASiR achieves an F1-score of 87.90% for detection. Ablation studies and comparative experiments reveal that the semantic information provided by LLMs aids static taint analysis, significantly enhancing LASiR's detection performance.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u667a\u80fd\u5408\u7ea6\u4e2d\u7684\u7b7e\u540d\u91cd\u653e\u6f0f\u6d1e(SRV)\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u68c0\u6d4b\u5de5\u5177LASiR\uff0c\u572815,383\u4e2a\u6d89\u53ca\u7b7e\u540d\u9a8c\u8bc1\u7684\u5408\u7ea6\u4e2d\u53d1\u73b0SRV\u5e7f\u6cdb\u5b58\u5728\uff0c\u53d7\u5f71\u54cd\u5408\u7ea6\u6301\u6709476\u4e07\u7f8e\u5143\u6d3b\u8dc3\u8d44\u4ea7\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u4e2d\u7f3a\u4e4f\u5bf9\u7b7e\u540d\u4f7f\u7528\u6761\u4ef6\u7684\u68c0\u67e5\u4f1a\u5bfc\u81f4\u91cd\u590d\u9a8c\u8bc1\uff0c\u589e\u52a0\u6743\u9650\u6ee5\u7528\u98ce\u9669\uff0c\u5a01\u80c1\u5408\u7ea6\u8d44\u4ea7\u5b89\u5168\u3002\u76ee\u524d\u7f3a\u4e4f\u5bf9\u7b7e\u540d\u91cd\u653e\u6f0f\u6d1e\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u8bbe\u8ba1\u4e86LASiR\u5de5\u5177\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u8f85\u52a9\u9759\u6001\u6c61\u70b9\u5206\u6790\uff0c\u8bc6\u522b\u7b7e\u540d\u91cd\u7528\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u7b26\u53f7\u6267\u884c\u8fdb\u884c\u8def\u5f84\u53ef\u8fbe\u6027\u9a8c\u8bc1\u3002", "result": "\u4ece37\u5bb6\u533a\u5757\u94fe\u5b89\u5168\u516c\u53f8\u76841,419\u4efd\u5ba1\u8ba1\u62a5\u544a\u4e2d\u8bc6\u522b\u51fa108\u4e2a\u8be6\u7ec6SRV\u6848\u4f8b\uff0c\u5206\u7c7b\u4e3a5\u79cd\u7c7b\u578b\u3002\u572815,383\u4e2a\u6d89\u53ca\u7b7e\u540d\u9a8c\u8bc1\u7684\u5408\u7ea6\u4e2d\uff0c\u4ee5\u592a\u574a\u4e0a\u4f7f\u7528\u7b7e\u540d\u7684\u5408\u7ea6\u4e2d\u670919.63%\u5305\u542bSRV\uff0c\u53d7\u5f71\u54cd\u5408\u7ea6\u6301\u6709476\u4e07\u7f8e\u5143\u8d44\u4ea7\u3002LASiR\u7684F1\u5206\u6570\u8fbe\u523087.90%\u3002", "conclusion": "\u7b7e\u540d\u91cd\u653e\u6f0f\u6d1e\u5728\u667a\u80fd\u5408\u7ea6\u4e2d\u5e7f\u6cdb\u5b58\u5728\u4e14\u5371\u5bb3\u4e25\u91cd\uff0cLASiR\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u8bed\u4e49\u7406\u89e3\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u6b64\u7c7b\u6f0f\u6d1e\uff0c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2511.09032", "categories": ["cs.AI", "cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.09032", "abs": "https://arxiv.org/abs/2511.09032", "authors": ["Dingji Wang", "You Lu", "Bihuan Chen", "Shuo Hao", "Haowen Jiang", "Yifan Tian", "Xin Peng"], "title": "Argus: Resilience-Oriented Safety Assurance Framework for End-to-End ADSs", "comment": "The paper has been accepted by the 40th IEEE/ACM International Conference on Automated Software Engineering, ASE 2025", "summary": "End-to-end autonomous driving systems (ADSs), with their strong capabilities in environmental perception and generalizable driving decisions, are attracting growing attention from both academia and industry. However, once deployed on public roads, ADSs are inevitably exposed to diverse driving hazards that may compromise safety and degrade system performance. This raises a strong demand for resilience of ADSs, particularly the capability to continuously monitor driving hazards and adaptively respond to potential safety violations, which is crucial for maintaining robust driving behaviors in complex driving scenarios.\n  To bridge this gap, we propose a runtime resilience-oriented framework, Argus, to mitigate the driving hazards, thus preventing potential safety violations and improving the driving performance of an ADS. Argus continuously monitors the trajectories generated by the ADS for potential hazards and, whenever the EGO vehicle is deemed unsafe, seamlessly takes control through a hazard mitigator. We integrate Argus with three state-of-the-art end-to-end ADSs, i.e., TCP, UniAD and VAD. Our evaluation has demonstrated that Argus effectively and efficiently enhances the resilience of ADSs, improving the driving score of the ADS by up to 150.30% on average, and preventing up to 64.38% of the violations, with little additional time overhead.", "AI": {"tldr": "\u63d0\u51faArgus\u6846\u67b6\uff0c\u901a\u8fc7\u6301\u7eed\u76d1\u63a7\u548c\u81ea\u9002\u5e94\u54cd\u5e94\u6765\u589e\u5f3a\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u97e7\u6027\uff0c\u9632\u6b62\u5b89\u5168\u8fdd\u89c4\u5e76\u63d0\u5347\u9a7e\u9a76\u6027\u80fd\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5728\u516c\u5171\u9053\u8def\u4e0a\u90e8\u7f72\u65f6\u9762\u4e34\u5404\u79cd\u9a7e\u9a76\u5371\u9669\uff0c\u9700\u8981\u5177\u5907\u6301\u7eed\u76d1\u63a7\u5371\u9669\u548c\u81ea\u9002\u5e94\u54cd\u5e94\u5b89\u5168\u8fdd\u89c4\u7684\u80fd\u529b\uff0c\u4ee5\u5728\u590d\u6742\u9a7e\u9a76\u573a\u666f\u4e2d\u4fdd\u6301\u7a33\u5065\u9a7e\u9a76\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u8fd0\u884c\u65f6\u97e7\u6027\u5bfc\u5411\u6846\u67b6Argus\uff0c\u6301\u7eed\u76d1\u63a7\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u751f\u6210\u7684\u8f68\u8ff9\uff0c\u5f53EGO\u8f66\u8f86\u88ab\u8ba4\u4e3a\u4e0d\u5b89\u5168\u65f6\uff0c\u901a\u8fc7\u5371\u9669\u7f13\u89e3\u5668\u65e0\u7f1d\u63a5\u7ba1\u63a7\u5236\u3002", "result": "\u4e0e\u4e09\u4e2a\u5148\u8fdb\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u96c6\u6210\u6d4b\u8bd5\uff0cArgus\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u97e7\u6027\uff0c\u5e73\u5747\u63d0\u9ad8\u9a7e\u9a76\u8bc4\u5206\u8fbe150.30%\uff0c\u9632\u6b6264.38%\u7684\u8fdd\u89c4\uff0c\u989d\u5916\u65f6\u95f4\u5f00\u9500\u5f88\u5c0f\u3002", "conclusion": "Argus\u6846\u67b6\u80fd\u591f\u6709\u6548\u589e\u5f3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u97e7\u6027\uff0c\u663e\u8457\u6539\u5584\u9a7e\u9a76\u6027\u80fd\u5e76\u9884\u9632\u5b89\u5168\u8fdd\u89c4\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.09252", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09252", "abs": "https://arxiv.org/abs/2511.09252", "authors": ["Jian Wang", "Hong Shen", "Chan-Tong Lam"], "title": "Unveiling Hidden Threats: Using Fractal Triggers to Boost Stealthiness of Distributed Backdoor Attacks in Federated Learning", "comment": "10 pages, 1 figures, conference", "summary": "Traditional distributed backdoor attacks (DBA) in federated learning improve stealthiness by decomposing global triggers into sub-triggers, which however requires more poisoned data to maintian the attck strength and hence increases the exposure risk. To overcome this defect, This paper proposes a novel method, namely Fractal-Triggerred Distributed Backdoor Attack (FTDBA), which leverages the self-similarity of fractals to enhance the feature strength of sub-triggers and hence significantly reduce the required poisoning volume for the same attack strength. To address the detectability of fractal structures in the frequency and gradient domains, we introduce a dynamic angular perturbation mechanism that adaptively adjusts perturbation intensity across the training phases to balance efficiency and stealthiness. Experiments show that FTDBA achieves a 92.3\\% attack success rate with only 62.4\\% of the poisoning volume required by traditional DBA methods, while reducing the detection rate by 22.8\\% and KL divergence by 41.2\\%. This study presents a low-exposure, high-efficiency paradigm for federated backdoor attacks and expands the application of fractal features in adversarial sample generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u5f62\u7279\u5f81\u7684\u5206\u5e03\u5f0f\u540e\u95e8\u653b\u51fb\u65b9\u6cd5FTDBA\uff0c\u5229\u7528\u5206\u5f62\u7684\u81ea\u76f8\u4f3c\u6027\u589e\u5f3a\u5b50\u89e6\u53d1\u5668\u7684\u7279\u5f81\u5f3a\u5ea6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8fbe\u5230\u76f8\u540c\u653b\u51fb\u5f3a\u5ea6\u6240\u9700\u7684\u6295\u6bd2\u6570\u636e\u91cf\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u89d2\u5ea6\u6270\u52a8\u673a\u5236\u63d0\u9ad8\u9690\u853d\u6027\u3002", "motivation": "\u4f20\u7edf\u5206\u5e03\u5f0f\u540e\u95e8\u653b\u51fb\u901a\u8fc7\u5c06\u5168\u5c40\u89e6\u53d1\u5668\u5206\u89e3\u4e3a\u5b50\u89e6\u53d1\u5668\u6765\u63d0\u9ad8\u9690\u853d\u6027\uff0c\u4f46\u8fd9\u9700\u8981\u66f4\u591a\u6295\u6bd2\u6570\u636e\u6765\u7ef4\u6301\u653b\u51fb\u5f3a\u5ea6\uff0c\u589e\u52a0\u4e86\u66b4\u9732\u98ce\u9669\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u7f3a\u9677\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u5728\u51cf\u5c11\u6295\u6bd2\u6570\u636e\u91cf\u7684\u540c\u65f6\u4fdd\u6301\u653b\u51fb\u5f3a\u5ea6\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faFTDBA\u65b9\u6cd5\uff1a1\uff09\u5229\u7528\u5206\u5f62\u81ea\u76f8\u4f3c\u6027\u589e\u5f3a\u5b50\u89e6\u53d1\u5668\u7279\u5f81\u5f3a\u5ea6\uff1b2\uff09\u5f15\u5165\u52a8\u6001\u89d2\u5ea6\u6270\u52a8\u673a\u5236\uff0c\u5728\u8bad\u7ec3\u9636\u6bb5\u81ea\u9002\u5e94\u8c03\u6574\u6270\u52a8\u5f3a\u5ea6\u4ee5\u5e73\u8861\u6548\u7387\u548c\u9690\u853d\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1aFTDBA\u4ec5\u9700\u4f20\u7edfDBA\u65b9\u6cd562.4%\u7684\u6295\u6bd2\u6570\u636e\u91cf\u5c31\u80fd\u8fbe\u523092.3%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u68c0\u6d4b\u7387\u964d\u4f4e22.8%\uff0cKL\u6563\u5ea6\u964d\u4f4e41.2%\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u66b4\u9732\u3001\u9ad8\u6548\u7387\u7684\u8054\u90a6\u540e\u95e8\u653b\u51fb\u8303\u5f0f\uff0c\u5e76\u62d3\u5c55\u4e86\u5206\u5f62\u7279\u5f81\u5728\u5bf9\u6297\u6837\u672c\u751f\u6210\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2511.09044", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09044", "abs": "https://arxiv.org/abs/2511.09044", "authors": ["Yousef Emami", "Radha Reddy", "Azadeh Pourkabirian", "Miguel Gutierrez Gaitan"], "title": "Advancing Autonomous Emergency Response Systems: A Generative AI Perspective", "comment": "8 pages, 3 figures, 2 tables", "summary": "Autonomous Vehicles (AVs) are poised to revolutionize emergency services by enabling faster, safer, and more efficient responses. This transformation is driven by advances in Artificial Intelligence (AI), particularly Reinforcement Learning (RL), which allows AVs to navigate complex environments and make critical decisions in real time. However, conventional RL paradigms often suffer from poor sample efficiency and lack adaptability in dynamic emergency scenarios. This paper reviews next-generation AV optimization strategies to address these limitations. We analyze the shift from conventional RL to Diffusion Model (DM)-augmented RL, which enhances policy robustness through synthetic data generation, albeit with increased computational cost. Additionally, we explore the emerging paradigm of Large Language Model (LLM)-assisted In-Context Learning (ICL), which offers a lightweight and interpretable alternative by enabling rapid, on-the-fly adaptation without retraining. By reviewing the state of the art in AV intelligence, DM-augmented RL, and LLM-assisted ICL, this paper provides a critical framework for understanding the next generation of autonomous emergency response systems from a Generative AI perspective.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u4e0b\u4e00\u4ee3\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5728\u7d27\u6025\u670d\u52a1\u4e2d\u7684\u4f18\u5316\u7b56\u7565\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u4ece\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5411\u6269\u6563\u6a21\u578b\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u8f6c\u53d8\uff0c\u4ee5\u89e3\u51b3\u6837\u672c\u6548\u7387\u4f4e\u548c\u52a8\u6001\u9002\u5e94\u6027\u5dee\u7684\u95ee\u9898\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u6709\u671b\u901a\u8fc7\u66f4\u5feb\u3001\u66f4\u5b89\u5168\u3001\u66f4\u9ad8\u6548\u7684\u54cd\u5e94\u6765\u5f7b\u5e95\u6539\u53d8\u7d27\u6025\u670d\u52a1\uff0c\u4f46\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u52a8\u6001\u7d27\u6025\u573a\u666f\u4e2d\u5b58\u5728\u6837\u672c\u6548\u7387\u4f4e\u548c\u9002\u5e94\u6027\u4e0d\u8db3\u7684\u5c40\u9650\u6027\u3002", "method": "\u5206\u6790\u4e86\u4ece\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5230\u6269\u6563\u6a21\u578b\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u7684\u8f6c\u53d8\uff08\u901a\u8fc7\u5408\u6210\u6570\u636e\u751f\u6210\u589e\u5f3a\u7b56\u7565\u9c81\u68d2\u6027\uff09\uff0c\u4ee5\u53ca\u65b0\u5174\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u4e0a\u4e0b\u6587\u5b66\u4e60\u8303\u5f0f\uff08\u63d0\u4f9b\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u66ff\u4ee3\u65b9\u6848\uff09\u3002", "result": "\u901a\u8fc7\u7efc\u8ff0\u81ea\u52a8\u9a7e\u9a76\u667a\u80fd\u3001\u6269\u6563\u6a21\u578b\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u548cLLM\u8f85\u52a9\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u6700\u65b0\u6280\u672f\uff0c\u4e3a\u7406\u89e3\u4e0b\u4e00\u4ee3\u81ea\u4e3b\u5e94\u6025\u54cd\u5e94\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5173\u952e\u6846\u67b6\u3002", "conclusion": "\u4ece\u751f\u6210\u5f0fAI\u7684\u89d2\u5ea6\uff0c\u672c\u6587\u4e3a\u4e0b\u4e00\u4ee3\u81ea\u4e3b\u5e94\u6025\u54cd\u5e94\u7cfb\u7edf\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u5c55\u793a\u4e86\u4e0d\u540cAI\u65b9\u6cd5\u5728\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7d27\u6025\u54cd\u5e94\u80fd\u529b\u65b9\u9762\u7684\u6f5c\u529b\u548c\u6743\u8861\u3002"}}
{"id": "2511.09092", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.09092", "abs": "https://arxiv.org/abs/2511.09092", "authors": ["Zezhen Ding", "Zhen Tan", "Jiheng Zhang", "Tianlong Chen"], "title": "OR-R1: Automating Modeling and Solving of Operations Research Optimization Problem via Test-Time Reinforcement Learning", "comment": "9 pages, 5 figures, AAAI 2026", "summary": "Optimization modeling and solving are fundamental to the application of Operations Research (OR) in real-world decision making, yet the process of translating natural language problem descriptions into formal models and solver code remains highly expertise intensive. While recent advances in large language models (LLMs) have opened new opportunities for automation, the generalization ability and data efficiency of existing LLM-based methods are still limited, asmost require vast amounts of annotated or synthetic data, resulting in high costs and scalability barriers. In this work, we present OR-R1, a data-efficient training framework for automated optimization modeling and solving. OR-R1 first employs supervised fine-tuning (SFT) to help the model acquire the essential reasoning patterns for problem formulation and code generation from limited labeled data. In addition, it improves the capability and consistency through Test-Time Group Relative Policy Optimization (TGRPO). This two-stage design enables OR-R1 to leverage both scarce labeled and abundant unlabeled data for effective learning. Experiments show that OR-R1 achieves state-of-the-art performance with an average solving accuracy of $67.7\\%$, using only $1/10$ the synthetic data required by prior methods such as ORLM, exceeding ORLM's solving accuracy by up to $4.2\\%$. Remarkably, OR-R1 outperforms ORLM by over $2.4\\%$ with just $100$ synthetic samples. Furthermore, TGRPO contributes an additional $3.1\\%-6.4\\%$ improvement in accuracy, significantly narrowing the gap between single-attempt (Pass@1) and multi-attempt (Pass@8) performance from $13\\%$ to $7\\%$. Extensive evaluations across diverse real-world benchmarks demonstrate that OR-R1 provides a robust, scalable, and cost-effective solution for automated OR optimization problem modeling and solving, lowering the expertise and data barriers for industrial OR applications.", "AI": {"tldr": "OR-R1\u662f\u4e00\u4e2a\u6570\u636e\u9ad8\u6548\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u4f18\u5316\u5efa\u6a21\u548c\u6c42\u89e3\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u6d4b\u8bd5\u65f6\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u4e24\u9636\u6bb5\u8bbe\u8ba1\uff0c\u4ec5\u97001/10\u7684\u6570\u636e\u91cf\u5c31\u80fd\u8fbe\u523067.7%\u7684\u5e73\u5747\u6c42\u89e3\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f18\u5316\u5efa\u6a21\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6216\u5408\u6210\u6570\u636e\uff0c\u6210\u672c\u9ad8\u4e14\u53ef\u6269\u5c55\u6027\u5dee\uff0c\u9700\u8981\u5f00\u53d1\u6570\u636e\u6548\u7387\u66f4\u9ad8\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1a\u9996\u5148\u4f7f\u7528\u76d1\u7763\u5fae\u8c03\u4ece\u6709\u9650\u6807\u6ce8\u6570\u636e\u4e2d\u5b66\u4e60\u95ee\u9898\u5efa\u6a21\u548c\u4ee3\u7801\u751f\u6210\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u7136\u540e\u901a\u8fc7\u6d4b\u8bd5\u65f6\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u63d0\u5347\u80fd\u529b\u548c\u4e00\u81f4\u6027\u3002", "result": "OR-R1\u4ec5\u97001/10\u7684\u5408\u6210\u6570\u636e\u5c31\u80fd\u8fbe\u523067.7%\u7684\u5e73\u5747\u6c42\u89e3\u51c6\u786e\u7387\uff0c\u6bd4ORLM\u9ad8\u51fa4.2%\uff0c\u5728\u4ec5100\u4e2a\u5408\u6210\u6837\u672c\u60c5\u51b5\u4e0b\u4ecd\u80fd\u8d85\u8d8aORLM 2.4%\u3002TGRPO\u5e26\u67653.1%-6.4%\u7684\u989d\u5916\u51c6\u786e\u7387\u63d0\u5347\u3002", "conclusion": "OR-R1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7a33\u5065\u3001\u53ef\u6269\u5c55\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u81ea\u52a8\u5316OR\u4f18\u5316\u95ee\u9898\u5efa\u6a21\u548c\u6c42\u89e3\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5de5\u4e1a\u5e94\u7528\u7684\u4e13\u5bb6\u77e5\u8bc6\u548c\u6570\u636e\u95e8\u69db\u3002"}}
{"id": "2511.09351", "categories": ["cs.CR", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.09351", "abs": "https://arxiv.org/abs/2511.09351", "authors": ["Min Liang", "Ruihao Gao", "Jiali Wu"], "title": "Quantum Meet-in-the-Middle Attacks on Key-Length Extension Constructions", "comment": "23 pages, 4 figures", "summary": "Key-length extension (KLE) techniques provide a general approach to enhancing the security of block ciphers by using longer keys. There are mainly two classes of KLE techniques, cascade encryption and XOR-cascade encryption. This paper presents several quantum meet-in-the-middle (MITM) attacks against two specific KLE constructions.\n  For the two-key triple encryption (2kTE), we propose two quantum MITM attacks under the Q2 model. The first attack, leveraging the quantum claw-finding (QCF) algorithm, achieves a time complexity of $O(2^{2\u03ba/3})$ with $O(2^{2\u03ba/3})$ quantum random access memory (QRAM). The second attack, based on Grover's algorithm, achieves a time complexity of $O(2^{\u03ba/2})$ with $O(2^\u03ba)$ QRAM. The latter complexity is nearly identical to Grover-based brute-force attack on the underlying block cipher, indicating that 2kTE does not enhance security under the Q2 model when sufficient QRAM resources are available.\n  For the 3XOR-cascade encryption (3XCE), we propose a quantum MITM attack applicable to the Q1 model. This attack requires no QRAM and has a time complexity of $O(2^{(\u03ba+n)/2})$ ($\u03ba$ and $n$ are the key length and block length of the underlying block cipher, respectively.), achieving a quadratic speedup over classical MITM attack.\n  Furthermore, we extend the quantum MITM attack to quantum sieve-in-the-middle (SITM) attack, which is applicable for more constructions. We present a general quantum SITM framework for the construction $ELE=E^2\\circ L\\circ E^1$ and provide specific attack schemes for three different forms of the middle layer $L$. The quantum SITM attack technique can be further applied to a broader range of quantum cryptanalysis scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u4e24\u79cd\u5bc6\u94a5\u957f\u5ea6\u6269\u5c55\u6784\u9020\u7684\u91cf\u5b50\u4e2d\u95f4\u76f8\u9047\u653b\u51fb\uff1a\u5bf92kTE\u7684\u4e24\u79cdQ2\u6a21\u578b\u653b\u51fb\uff08\u57fa\u4e8e\u91cf\u5b50\u722a\u67e5\u627e\u548cGrover\u7b97\u6cd5\uff09\uff0c\u4ee5\u53ca\u5bf93XCE\u7684Q1\u6a21\u578b\u653b\u51fb\u3002\u8fd8\u6269\u5c55\u4e86\u91cf\u5b50\u7b5b\u5b50\u4e2d\u95f4\u653b\u51fb\u6846\u67b6\u3002", "motivation": "\u7814\u7a76\u5bc6\u94a5\u957f\u5ea6\u6269\u5c55\u6280\u672f\u5728\u91cf\u5b50\u8ba1\u7b97\u6a21\u578b\u4e0b\u7684\u5b89\u5168\u6027\uff0c\u8bc4\u4f30\u73b0\u6709KLE\u6784\u9020\u5728\u91cf\u5b50\u653b\u51fb\u4e0b\u7684\u8106\u5f31\u6027\u3002", "method": "\u4f7f\u7528\u91cf\u5b50\u4e2d\u95f4\u76f8\u9047\u653b\u51fb\u548c\u91cf\u5b50\u7b5b\u5b50\u4e2d\u95f4\u653b\u51fb\u6280\u672f\uff0c\u7ed3\u5408\u91cf\u5b50\u722a\u67e5\u627e\u7b97\u6cd5\u548cGrover\u7b97\u6cd5\uff0c\u5206\u67902kTE\u548c3XCE\u6784\u9020\u7684\u5b89\u5168\u6027\u3002", "result": "2kTE\u5728Q2\u6a21\u578b\u4e0b\u65e0\u6cd5\u589e\u5f3a\u5b89\u5168\u6027\uff0c3XCE\u5728Q1\u6a21\u578b\u4e0b\u53ef\u5b9e\u73b0\u4e8c\u6b21\u52a0\u901f\u653b\u51fb\uff0c\u91cf\u5b50SITM\u653b\u51fb\u53ef\u6269\u5c55\u5230\u66f4\u5e7f\u6cdb\u7684\u6784\u9020\u3002", "conclusion": "\u5bc6\u94a5\u957f\u5ea6\u6269\u5c55\u6280\u672f\u5728\u91cf\u5b50\u8ba1\u7b97\u73af\u5883\u4e0b\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30\u5176\u8bbe\u8ba1\u4ee5\u62b5\u5fa1\u91cf\u5b50\u653b\u51fb\u3002"}}
{"id": "2511.09158", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09158", "abs": "https://arxiv.org/abs/2511.09158", "authors": ["Yuhao Wang", "Xiaopeng Li", "Cheng Gong", "Ziru Liu", "Suiyun Zhang", "Rui Liu", "Xiangyu Zhao"], "title": "Efficient Reasoning via Reward Model", "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has been shown to enhance the reasoning capabilities of large language models (LLMs), enabling the development of large reasoning models (LRMs). However, LRMs such as DeepSeek-R1 and OpenAI o1 often generate verbose responses containing redundant or irrelevant reasoning step-a phenomenon known as overthinking-which substantially increases computational costs. Prior efforts to mitigate this issue commonly incorporate length penalties into the reward function, but we find they frequently suffer from two critical issues: length collapse and training collapse, resulting in sub-optimal performance. To address them, we propose a pipeline for training a Conciseness Reward Model (CRM) that scores the conciseness of reasoning path. Additionally, we introduce a novel reward formulation named Conciseness Reward Function (CRF) with explicit dependency between the outcome reward and conciseness score, thereby fostering both more effective and more efficient reasoning. From a theoretical standpoint, we demonstrate the superiority of the new reward from the perspective of variance reduction and improved convergence properties. Besides, on the practical side, extensive experiments on five mathematical benchmark datasets demonstrate the method's effectiveness and token efficiency, which achieves an 8.1% accuracy improvement and a 19.9% reduction in response token length on Qwen2.5-7B. Furthermore, the method generalizes well to other LLMs including Llama and Mistral. The implementation code and datasets are publicly available for reproduction: https://anonymous.4open.science/r/CRM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u7b80\u6d01\u6027\u5956\u52b1\u6a21\u578b\uff08CRM\uff09\u7684\u7ba1\u9053\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u7b80\u6d01\u6027\u5956\u52b1\u51fd\u6570\uff08CRF\uff09\u6765\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5728\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u7684\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08\u5982DeepSeek-R1\u548cOpenAI o1\uff09\u7ecf\u5e38\u751f\u6210\u5197\u957f\u7684\u63a8\u7406\u6b65\u9aa4\uff0c\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u8fc7\u5ea6\u601d\u8003\uff0c\u663e\u8457\u589e\u52a0\u4e86\u8ba1\u7b97\u6210\u672c\u3002\u73b0\u6709\u7684\u957f\u5ea6\u60e9\u7f5a\u65b9\u6cd5\u5b58\u5728\u957f\u5ea6\u5d29\u6e83\u548c\u8bad\u7ec3\u5d29\u6e83\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u8bad\u7ec3\u7b80\u6d01\u6027\u5956\u52b1\u6a21\u578b\uff08CRM\uff09\u7684\u7ba1\u9053\u6765\u8bc4\u4f30\u63a8\u7406\u8def\u5f84\u7684\u7b80\u6d01\u6027\uff0c\u5e76\u5f15\u5165\u4e86\u7b80\u6d01\u6027\u5956\u52b1\u51fd\u6570\uff08CRF\uff09\uff0c\u8be5\u51fd\u6570\u660e\u786e\u5c06\u7ed3\u679c\u5956\u52b1\u4e0e\u7b80\u6d01\u6027\u8bc4\u5206\u76f8\u5173\u8054\u3002", "result": "\u5728\u4e94\u4e2a\u6570\u5b66\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728Qwen2.5-7B\u4e0a\u5b9e\u73b0\u4e868.1%\u7684\u51c6\u786e\u7387\u63d0\u5347\u548c19.9%\u7684\u54cd\u5e94token\u957f\u5ea6\u51cf\u5c11\uff0c\u5e76\u4e14\u5728Llama\u548cMistral\u7b49\u5176\u4ed6LLM\u4e0a\u4e5f\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u65b0\u5956\u52b1\u51fd\u6570\u5728\u65b9\u5dee\u51cf\u5c11\u548c\u6539\u8fdb\u6536\u655b\u7279\u6027\u65b9\u9762\u7684\u4f18\u8d8a\u6027\uff0c\u80fd\u591f\u540c\u65f6\u4fc3\u8fdb\u66f4\u6709\u6548\u548c\u66f4\u9ad8\u6548\u7684\u63a8\u7406\u3002"}}
{"id": "2511.09178", "categories": ["cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.09178", "abs": "https://arxiv.org/abs/2511.09178", "authors": ["Niclas Flehmig", "Mary Ann Lundteigen", "Shen Yin"], "title": "Perspectives on a Reliability Monitoring Framework for Agentic AI Systems", "comment": null, "summary": "The implementation of agentic AI systems has the potential of providing more helpful AI systems in a variety of applications. These systems work autonomously towards a defined goal with reduced external control. Despite their potential, one of their flaws is the insufficient reliability which makes them especially unsuitable for high-risk domains such as healthcare or process industry. Unreliable systems pose a risk in terms of unexpected behavior during operation and mitigation techniques are needed. In this work, we derive the main reliability challenges of agentic AI systems during operation based on their characteristics. We draw the connection to traditional AI systems and formulate a fundamental reliability challenge during operation which is inherent to traditional and agentic AI systems. As our main contribution, we propose a two-layered reliability monitoring framework for agentic AI systems which consists of a out-of-distribution detection layer for novel inputs and AI transparency layer to reveal internal operations. This two-layered monitoring approach gives a human operator the decision support which is needed to decide whether an output is potential unreliable or not and intervene. This framework provides a foundation for developing mitigation techniques to reduce risk stemming from uncertain reliability during operation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53cc\u5c42\u53ef\u9760\u6027\u76d1\u63a7\u6846\u67b6\u6765\u89e3\u51b3\u667a\u80fdAI\u7cfb\u7edf\u5728\u64cd\u4f5c\u4e2d\u7684\u53ef\u9760\u6027\u6311\u6218\uff0c\u5305\u62ec\u7528\u4e8e\u68c0\u6d4b\u65b0\u8f93\u5165\u7684\u5206\u5e03\u5916\u68c0\u6d4b\u5c42\u548c\u63ed\u793a\u5185\u90e8\u64cd\u4f5c\u7684AI\u900f\u660e\u5ea6\u5c42\u3002", "motivation": "\u667a\u80fdAI\u7cfb\u7edf\u867d\u7136\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u9ad8\u98ce\u9669\u9886\u57df\uff08\u5982\u533b\u7597\u4fdd\u5065\u6216\u6d41\u7a0b\u5de5\u4e1a\uff09\u4e2d\u53ef\u9760\u6027\u4e0d\u8db3\uff0c\u5b58\u5728\u610f\u5916\u884c\u4e3a\u7684\u98ce\u9669\uff0c\u9700\u8981\u7f13\u89e3\u6280\u672f\u3002", "method": "\u57fa\u4e8e\u667a\u80fdAI\u7cfb\u7edf\u7684\u7279\u6027\u63a8\u5bfc\u5176\u4e3b\u8981\u53ef\u9760\u6027\u6311\u6218\uff0c\u63d0\u51fa\u53cc\u5c42\u53ef\u9760\u6027\u76d1\u63a7\u6846\u67b6\uff1a\u5206\u5e03\u5916\u68c0\u6d4b\u5c42\u7528\u4e8e\u8bc6\u522b\u65b0\u8f93\u5165\uff0cAI\u900f\u660e\u5ea6\u5c42\u7528\u4e8e\u63ed\u793a\u5185\u90e8\u64cd\u4f5c\u3002", "result": "\u8be5\u6846\u67b6\u4e3a\u4eba\u7c7b\u64cd\u4f5c\u5458\u63d0\u4f9b\u4e86\u51b3\u7b56\u652f\u6301\uff0c\u4ee5\u5224\u65ad\u8f93\u51fa\u662f\u5426\u53ef\u80fd\u4e0d\u53ef\u9760\u5e76\u8fdb\u884c\u5e72\u9884\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5f00\u53d1\u7f13\u89e3\u6280\u672f\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u4ee5\u51cf\u5c11\u64cd\u4f5c\u4e2d\u4e0d\u786e\u5b9a\u6027\u53ef\u9760\u6027\u5e26\u6765\u7684\u98ce\u9669\u3002"}}
{"id": "2511.09247", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09247", "abs": "https://arxiv.org/abs/2511.09247", "authors": ["Yi-Hsien Hsieh", "Ta-Jung Chien", "Chun-Kai Huang", "Shao-Hua Sun", "Che Lin"], "title": "MedFuse: Multiplicative Embedding Fusion For Irregular Clinical Time Series", "comment": null, "summary": "Clinical time series derived from electronic health records (EHRs) are inherently irregular, with asynchronous sampling, missing values, and heterogeneous feature dynamics. While numerical laboratory measurements are highly informative, existing embedding strategies usually combine feature identity and value embeddings through additive operations, which constrains their ability to capture value-dependent feature interactions. We propose MedFuse, a framework for irregular clinical time series centered on the MuFuse (Multiplicative Embedding Fusion) module. MuFuse fuses value and feature embeddings through multiplicative modulation, preserving feature-specific information while modeling higher-order dependencies across features. Experiments on three real-world datasets covering both intensive and chronic care show that MedFuse consistently outperforms state-of-the-art baselines on key predictive tasks. Analysis of the learned representations further demonstrates that multiplicative fusion enhances expressiveness and supports cross-dataset pretraining. These results establish MedFuse as a generalizable approach for modeling irregular clinical time series.", "AI": {"tldr": "MedFuse\u662f\u4e00\u4e2a\u7528\u4e8e\u4e0d\u89c4\u5219\u4e34\u5e8a\u65f6\u95f4\u5e8f\u5217\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4e58\u6cd5\u878d\u5408\u6a21\u5757\u89e3\u51b3\u4f20\u7edf\u52a0\u6027\u5d4c\u5165\u7684\u5c40\u9650\u6027\uff0c\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u7684\u4e34\u5e8a\u65f6\u95f4\u5e8f\u5217\u5177\u6709\u4e0d\u89c4\u5219\u6027\u3001\u5f02\u6b65\u91c7\u6837\u3001\u7f3a\u5931\u503c\u548c\u5f02\u8d28\u7279\u5f81\u52a8\u6001\u7b49\u7279\u6027\u3002\u73b0\u6709\u7684\u5d4c\u5165\u7b56\u7565\u901a\u5e38\u901a\u8fc7\u52a0\u6cd5\u64cd\u4f5c\u7ed3\u5408\u7279\u5f81\u8eab\u4efd\u548c\u503c\u5d4c\u5165\uff0c\u9650\u5236\u4e86\u6355\u6349\u503c\u4f9d\u8d56\u7279\u5f81\u4ea4\u4e92\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faMedFuse\u6846\u67b6\uff0c\u6838\u5fc3\u662fMuFuse\uff08\u4e58\u6cd5\u5d4c\u5165\u878d\u5408\uff09\u6a21\u5757\uff0c\u901a\u8fc7\u4e58\u6cd5\u8c03\u5236\u878d\u5408\u503c\u548c\u7279\u5f81\u5d4c\u5165\uff0c\u5728\u4fdd\u7559\u7279\u5f81\u7279\u5b9a\u4fe1\u606f\u7684\u540c\u65f6\u5efa\u6a21\u8de8\u7279\u5f81\u7684\u9ad8\u9636\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u6db5\u76d6\u91cd\u75c7\u548c\u6162\u6027\u62a4\u7406\u7684\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMedFuse\u5728\u5173\u952e\u9884\u6d4b\u4efb\u52a1\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u5b66\u4e60\u8868\u793a\u7684\u5206\u6790\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e58\u6cd5\u878d\u5408\u589e\u5f3a\u4e86\u8868\u8fbe\u80fd\u529b\u5e76\u652f\u6301\u8de8\u6570\u636e\u96c6\u9884\u8bad\u7ec3\u3002", "conclusion": "MedFuse\u4e3a\u5efa\u6a21\u4e0d\u89c4\u5219\u4e34\u5e8a\u65f6\u95f4\u5e8f\u5217\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u63a8\u5e7f\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e58\u6cd5\u878d\u5408\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u52a0\u6027\u5d4c\u5165\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2511.09275", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09275", "abs": "https://arxiv.org/abs/2511.09275", "authors": ["Minlan Shao", "Zijian Zhang", "Yili Wang", "Yiwei Dai", "Xu Shen", "Xin Wang"], "title": "HyperD: Hybrid Periodicity Decoupling Framework for Traffic Forecasting", "comment": null, "summary": "Accurate traffic forecasting plays a vital role in intelligent transportation systems, enabling applications such as congestion control, route planning, and urban mobility optimization.However, traffic forecasting remains challenging due to two key factors: (1) complex spatial dependencies arising from dynamic interactions between road segments and traffic sensors across the network, and (2) the coexistence of multi-scale periodic patterns (e.g., daily and weekly periodic patterns driven by human routines) with irregular fluctuations caused by unpredictable events (e.g., accidents, weather, or construction). To tackle these challenges, we propose HyperD (Hybrid Periodic Decoupling), a novel framework that decouples traffic data into periodic and residual components. The periodic component is handled by the Hybrid Periodic Representation Module, which extracts fine-grained daily and weekly patterns using learnable periodic embeddings and spatial-temporal attention. The residual component, which captures non-periodic, high-frequency fluctuations, is modeled by the Frequency-Aware Residual Representation Module, leveraging complex-valued MLP in frequency domain. To enforce semantic separation between the two components, we further introduce a Dual-View Alignment Loss, which aligns low-frequency information with the periodic branch and high-frequency information with the residual branch. Extensive experiments on four real-world traffic datasets demonstrate that HyperD achieves state-of-the-art prediction accuracy, while offering superior robustness under disturbances and improved computational efficiency compared to existing methods.", "AI": {"tldr": "HyperD\u662f\u4e00\u4e2a\u7528\u4e8e\u4ea4\u901a\u9884\u6d4b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u4ea4\u901a\u6570\u636e\u89e3\u8026\u4e3a\u5468\u671f\u6027\u548c\u6b8b\u5dee\u5206\u91cf\u6765\u5904\u7406\u590d\u6742\u7684\u65f6\u7a7a\u4f9d\u8d56\u6027\u548c\u591a\u5c3a\u5ea6\u6a21\u5f0f\u3002", "motivation": "\u4ea4\u901a\u9884\u6d4b\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a\u590d\u6742\u7684\u7a7a\u95f4\u4f9d\u8d56\u6027\u548c\u591a\u5c3a\u5ea6\u5468\u671f\u6a21\u5f0f\u4e0e\u4e0d\u89c4\u5219\u6ce2\u52a8\u7684\u5171\u5b58\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u590d\u6742\u56e0\u7d20\u3002", "method": "\u63d0\u51faHyperD\u6846\u67b6\uff0c\u5c06\u4ea4\u901a\u6570\u636e\u89e3\u8026\u4e3a\u5468\u671f\u6027\u548c\u6b8b\u5dee\u5206\u91cf\u3002\u5468\u671f\u6027\u5206\u91cf\u4f7f\u7528\u6df7\u5408\u5468\u671f\u8868\u793a\u6a21\u5757\u5904\u7406\uff0c\u6b8b\u5dee\u5206\u91cf\u4f7f\u7528\u9891\u7387\u611f\u77e5\u6b8b\u5dee\u8868\u793a\u6a21\u5757\u5728\u9891\u57df\u5efa\u6a21\u3002\u5f15\u5165\u53cc\u89c6\u56fe\u5bf9\u9f50\u635f\u5931\u786e\u4fdd\u8bed\u4e49\u5206\u79bb\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHyperD\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u540c\u65f6\u5728\u5e72\u6270\u4e0b\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\u548c\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "HyperD\u901a\u8fc7\u89e3\u8026\u5468\u671f\u6027\u548c\u975e\u5468\u671f\u6027\u6a21\u5f0f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4ea4\u901a\u9884\u6d4b\u4e2d\u7684\u590d\u6742\u65f6\u7a7a\u4f9d\u8d56\u95ee\u9898\uff0c\u4e3a\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u9884\u6d4b\u80fd\u529b\u3002"}}
{"id": "2511.09287", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09287", "abs": "https://arxiv.org/abs/2511.09287", "authors": ["Roland Aydin", "Christian Cyron", "Steve Bachelor", "Ashton Anderson", "Robert West"], "title": "From Model Training to Model Raising - A call to reform AI model training paradigms from post-hoc alignment to intrinsic, identity-based development", "comment": "Accepted for publication in Communications of the ACM (CACM), Opinion section", "summary": "Current AI training methods align models with human values only after their core capabilities have been established, resulting in models that are easily misaligned and lack deep-rooted value systems. We propose a paradigm shift from \"model training\" to \"model raising\", in which alignment is woven into a model's development from the start. We identify several key components for this paradigm, all centered around redesigning the training corpus: reframing training data from a first-person perspective, recontextualizing information as lived experience, simulating social interactions, and scaffolding the ordering of training data. We expect that this redesign of the training corpus will lead to an early commitment to values from the first training token onward, such that knowledge, skills, and values are intrinsically much harder to separate. In an ecosystem in which large language model capabilities start overtaking human capabilities in many tasks, this seems to us like a critical need.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4ece\"\u6a21\u578b\u8bad\u7ec3\"\u8f6c\u5411\"\u6a21\u578b\u57f9\u517b\"\u7684\u65b0\u8303\u5f0f\uff0c\u5c06\u4ef7\u503c\u89c2\u5bf9\u9f50\u4ece\u6a21\u578b\u5f00\u53d1\u521d\u671f\u5c31\u878d\u5165\u5176\u4e2d\uff0c\u901a\u8fc7\u91cd\u65b0\u8bbe\u8ba1\u8bad\u7ec3\u8bed\u6599\u5e93\u6765\u5b9e\u73b0\u6df1\u5ea6\u4ef7\u503c\u7cfb\u7edf\u6784\u5efa\u3002", "motivation": "\u5f53\u524dAI\u8bad\u7ec3\u65b9\u6cd5\u53ea\u5728\u6838\u5fc3\u80fd\u529b\u5efa\u7acb\u540e\u624d\u8fdb\u884c\u4ef7\u503c\u89c2\u5bf9\u9f50\uff0c\u5bfc\u81f4\u6a21\u578b\u5bb9\u6613\u88ab\u8bef\u5bfc\u4e14\u7f3a\u4e4f\u6df1\u5c42\u6b21\u4ef7\u503c\u4f53\u7cfb\u3002\u5728LLM\u80fd\u529b\u5f00\u59cb\u8d85\u8d8a\u4eba\u7c7b\u7684\u80cc\u666f\u4e0b\uff0c\u9700\u8981\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u8fd9\u79cd\u8bad\u7ec3\u65b9\u5f0f\u3002", "method": "\u91cd\u65b0\u8bbe\u8ba1\u8bad\u7ec3\u8bed\u6599\u5e93\uff1a\u91c7\u7528\u7b2c\u4e00\u4eba\u79f0\u89c6\u89d2\u91cd\u6784\u8bad\u7ec3\u6570\u636e\u3001\u5c06\u4fe1\u606f\u91cd\u65b0\u60c5\u5883\u5316\u4e3a\u751f\u6d3b\u7ecf\u9a8c\u3001\u6a21\u62df\u793e\u4f1a\u4e92\u52a8\u3001\u4ee5\u53ca\u642d\u5efa\u8bad\u7ec3\u6570\u636e\u7684\u987a\u5e8f\u6846\u67b6\u3002", "result": "\u9884\u671f\u8fd9\u79cd\u8bad\u7ec3\u8bed\u6599\u5e93\u7684\u91cd\u65b0\u8bbe\u8ba1\u5c06\u5bfc\u81f4\u4ece\u7b2c\u4e00\u4e2a\u8bad\u7ec3token\u5f00\u59cb\u5c31\u5f62\u6210\u5bf9\u4ef7\u503c\u89c2\u7684\u65e9\u671f\u627f\u8bfa\uff0c\u4f7f\u77e5\u8bc6\u3001\u6280\u80fd\u548c\u4ef7\u503c\u89c2\u5728\u672c\u8d28\u4e0a\u66f4\u96be\u5206\u79bb\u3002", "conclusion": "\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u5f00\u59cb\u5728\u8bb8\u591a\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4eba\u7c7b\u80fd\u529b\u7684\u751f\u6001\u7cfb\u7edf\u4e2d\uff0c\u8fd9\u79cd\u4ece\u6a21\u578b\u5f00\u53d1\u521d\u671f\u5c31\u878d\u5165\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\"\u6a21\u578b\u57f9\u517b\"\u8303\u5f0f\u662f\u81f3\u5173\u91cd\u8981\u7684\u9700\u6c42\u3002"}}
{"id": "2511.09325", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.09325", "abs": "https://arxiv.org/abs/2511.09325", "authors": ["Stine Beltoft", "Lukas Galke"], "title": "Not Everything That Counts Can Be Counted: A Case for Safe Qualitative AI", "comment": "Accepted at 3rd International Conference on Frontiers of Artificial Intelligence, Ethics, and Multidisciplinary Applications (FAIEMA 2025)", "summary": "Artificial intelligence (AI) and large language models (LLM) are reshaping science, with most recent advances culminating in fully-automated scientific discovery pipelines. But qualitative research has been left behind. Researchers in qualitative methods are hesitant about AI adoption. Yet when they are willing to use AI at all, they have little choice but to rely on general-purpose tools like ChatGPT to assist with interview interpretation, data annotation, and topic modeling - while simultaneously acknowledging these system's well-known limitations of being biased, opaque, irreproducible, and privacy-compromising. This creates a critical gap: while AI has substantially advanced quantitative methods, the qualitative dimensions essential for meaning-making and comprehensive scientific understanding remain poorly integrated. We argue for developing dedicated qualitative AI systems built from the ground up for interpretive research. Such systems must be transparent, reproducible, and privacy-friendly. We review recent literature to show how existing automated discovery pipelines could be enhanced by robust qualitative capabilities, and identify key opportunities where safe qualitative AI could advance multidisciplinary and mixed-methods research.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u5f00\u53d1\u4e13\u95e8\u4e3a\u5b9a\u6027\u7814\u7a76\u8bbe\u8ba1\u7684AI\u7cfb\u7edf\uff0c\u4ee5\u89e3\u51b3\u5f53\u524d\u901a\u7528AI\u5de5\u5177\u5728\u5b9a\u6027\u7814\u7a76\u4e2d\u5b58\u5728\u7684\u504f\u89c1\u3001\u4e0d\u900f\u660e\u3001\u4e0d\u53ef\u590d\u73b0\u548c\u9690\u79c1\u95ee\u9898\u3002", "motivation": "\u5f53\u524dAI\u4e3b\u8981\u63a8\u52a8\u4e86\u5b9a\u91cf\u65b9\u6cd5\u7684\u53d1\u5c55\uff0c\u4f46\u5b9a\u6027\u7814\u7a76\u8fd9\u4e00\u5bf9\u610f\u4e49\u5efa\u6784\u548c\u5168\u9762\u79d1\u5b66\u7406\u89e3\u81f3\u5173\u91cd\u8981\u7684\u7ef4\u5ea6\u5374\u88ab\u5ffd\u89c6\u3002\u5b9a\u6027\u7814\u7a76\u8005\u5bf9\u91c7\u7528AI\u6301\u72b9\u8c6b\u6001\u5ea6\uff0c\u53ea\u80fd\u4f9d\u8d56\u6709\u8bf8\u591a\u5c40\u9650\u7684\u901a\u7528\u5de5\u5177\u3002", "method": "\u4e3b\u5f20\u4ece\u96f6\u5f00\u59cb\u6784\u5efa\u4e13\u95e8\u7528\u4e8e\u5b9a\u6027\u7814\u7a76\u7684AI\u7cfb\u7edf\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u5fc5\u987b\u5177\u6709\u900f\u660e\u6027\u3001\u53ef\u590d\u73b0\u6027\u548c\u9690\u79c1\u53cb\u597d\u6027\u3002\u901a\u8fc7\u56de\u987e\u8fd1\u671f\u6587\u732e\uff0c\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u589e\u5f3a\u5b9a\u6027\u80fd\u529b\u6765\u6539\u8fdb\u73b0\u6709\u7684\u81ea\u52a8\u5316\u79d1\u5b66\u53d1\u73b0\u6d41\u7a0b\u3002", "result": "\u8bc6\u522b\u4e86\u5b89\u5168\u5b9a\u6027AI\u53ef\u4ee5\u63a8\u52a8\u591a\u5b66\u79d1\u548c\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\u7684\u5173\u952e\u673a\u4f1a\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u5b9a\u6027\u7ef4\u5ea6\u6574\u5408\u5230\u81ea\u52a8\u5316\u53d1\u73b0\u6d41\u7a0b\u4e2d\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u9488\u5bf9\u5b9a\u6027\u7814\u7a76\u7684AI\u7cfb\u7edf\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u5e94\u8be5\u5177\u5907\u900f\u660e\u3001\u53ef\u590d\u73b0\u548c\u9690\u79c1\u53cb\u597d\u7684\u7279\u6027\uff0c\u4ee5\u5f25\u8865\u5f53\u524dAI\u5728\u5b9a\u6027\u7814\u7a76\u9886\u57df\u7684\u4e0d\u8db3\uff0c\u63a8\u52a8\u591a\u5b66\u79d1\u7814\u7a76\u7684\u5168\u9762\u53d1\u5c55\u3002"}}
{"id": "2511.09378", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09378", "abs": "https://arxiv.org/abs/2511.09378", "authors": ["Augusto B. Corr\u00eaa", "Andr\u00e9 G. Pereira", "Jendrik Seipp"], "title": "The 2025 Planning Performance of Frontier Large Language Models", "comment": null, "summary": "The capacity of Large Language Models (LLMs) for reasoning remains an active area of research, with the capabilities of frontier models continually advancing. We provide an updated evaluation of the end-to-end planning performance of three frontier LLMs as of 2025, where models are prompted to generate a plan from PDDL domain and task descriptions. We evaluate DeepSeek R1, Gemini 2.5 Pro, GPT-5 and as reference the planner LAMA on a subset of domains from the most recent Learning Track of the International Planning Competition. Our results show that on standard PDDL domains, the performance of GPT-5 in terms of solved tasks is competitive with LAMA. When the PDDL domains and tasks are obfuscated to test for pure reasoning, the performance of all LLMs degrades, though less severely than previously reported for other models. These results show substantial improvements over prior generations of LLMs, reducing the performance gap to planners on a challenging benchmark.", "AI": {"tldr": "\u8bc4\u4f30\u4e862025\u5e74\u4e09\u4e2a\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\uff08DeepSeek R1\u3001Gemini 2.5 Pro\u3001GPT-5\uff09\u5728PDDL\u89c4\u5212\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0GPT-5\u5728\u6807\u51c6PDDL\u9886\u57df\u4e0eLAMA\u89c4\u5212\u5668\u8868\u73b0\u76f8\u5f53\uff0c\u4f46\u5728\u6df7\u6dc6\u6d4b\u8bd5\u4e2d\u6240\u6709\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u8bc4\u4f30\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7aef\u5230\u7aef\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e86\u89e3\u5b83\u4eec\u4e0e\u4e13\u4e1a\u89c4\u5212\u5668\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "method": "\u4f7f\u7528\u56fd\u9645\u89c4\u5212\u7ade\u8d5b\u5b66\u4e60\u8d5b\u9053\u4e2d\u7684PDDL\u9886\u57df\u548c\u4efb\u52a1\u5b50\u96c6\uff0c\u5bf9\u4e09\u4e2aLLM\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5305\u62ec\u6807\u51c6PDDL\u548c\u6df7\u6dc6\u7248\u672c\uff0c\u5e76\u4e0eLAMA\u89c4\u5212\u5668\u5bf9\u6bd4\u3002", "result": "GPT-5\u5728\u6807\u51c6PDDL\u4efb\u52a1\u4e2d\u89e3\u51b3\u7387\u4e0eLAMA\u7ade\u4e89\uff1b\u6240\u6709LLM\u5728\u6df7\u6dc6\u4efb\u52a1\u4e2d\u6027\u80fd\u4e0b\u964d\uff0c\u4f46\u964d\u5e45\u5c0f\u4e8e\u4e4b\u524d\u6a21\u578b\u62a5\u544a\uff1b\u76f8\u6bd4\u524d\u4ee3LLM\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u524d\u6cbfLLM\u5728\u89c4\u5212\u4efb\u52a1\u4e0a\u53d6\u5f97\u91cd\u5927\u8fdb\u5c55\uff0c\u4e0e\u89c4\u5212\u5668\u7684\u6027\u80fd\u5dee\u8ddd\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7f29\u5c0f\u3002"}}
{"id": "2511.09433", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09433", "abs": "https://arxiv.org/abs/2511.09433", "authors": ["Brian Rogers", "Micah Bowles", "Chris J. Lintott", "Steve Croft"], "title": "What We Don't C: Representations for scientific discovery beyond VAEs", "comment": "Accepted to the Machine Learning and the Physical Sciences workshop at NeurIPS 2025", "summary": "Accessing information in learned representations is critical for scientific discovery in high-dimensional domains. We introduce a novel method based on latent flow matching with classifier-free guidance that disentangles latent subspaces by explicitly separating information included in conditioning from information that remains in the residual representation. Across three experiments -- a synthetic 2D Gaussian toy problem, colored MNIST, and the Galaxy10 astronomy dataset -- we show that our method enables access to meaningful features of high dimensional data. Our results highlight a simple yet powerful mechanism for analyzing, controlling, and repurposing latent representations, providing a pathway toward using generative models for scientific exploration of what we don't capture, consider, or catalog.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6f5c\u5728\u6d41\u5339\u914d\u548c\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u660e\u786e\u5206\u79bb\u6761\u4ef6\u4fe1\u606f\u548c\u6b8b\u5dee\u8868\u793a\u6765\u89e3\u8026\u6f5c\u5728\u5b50\u7a7a\u95f4\uff0c\u5b9e\u73b0\u5728\u9ad8\u7ef4\u6570\u636e\u4e2d\u8bbf\u95ee\u6709\u610f\u4e49\u7684\u7279\u5f81\u3002", "motivation": "\u5728\u79d1\u5b66\u53d1\u73b0\u4e2d\u8bbf\u95ee\u5b66\u4e60\u8868\u793a\u4e2d\u7684\u4fe1\u606f\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u9886\u57df\u3002\u9700\u8981\u4e00\u79cd\u673a\u5236\u6765\u5206\u6790\u3001\u63a7\u5236\u548c\u91cd\u65b0\u5229\u7528\u6f5c\u5728\u8868\u793a\uff0c\u4ee5\u4fbf\u8fdb\u884c\u79d1\u5b66\u63a2\u7d22\u3002", "method": "\u57fa\u4e8e\u6f5c\u5728\u6d41\u5339\u914d\u4e0e\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\uff0c\u660e\u786e\u5206\u79bb\u6761\u4ef6\u4fe1\u606f\u4e0e\u6b8b\u5dee\u8868\u793a\uff0c\u5b9e\u73b0\u6f5c\u5728\u5b50\u7a7a\u95f4\u7684\u89e3\u8026\u3002", "result": "\u5728\u4e09\u4e2a\u5b9e\u9a8c\uff08\u5408\u62102D\u9ad8\u65af\u73a9\u5177\u95ee\u9898\u3001\u5f69\u8272MNIST\u548cGalaxy10\u5929\u6587\u6570\u636e\u96c6\uff09\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u8bbf\u95ee\u9ad8\u7ef4\u6570\u636e\u7684\u6709\u610f\u4e49\u7279\u5f81\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5206\u6790\u3001\u63a7\u5236\u548c\u91cd\u65b0\u5229\u7528\u6f5c\u5728\u8868\u793a\u63d0\u4f9b\u4e86\u7b80\u5355\u800c\u5f3a\u5927\u7684\u673a\u5236\uff0c\u4e3a\u4f7f\u7528\u751f\u6210\u6a21\u578b\u8fdb\u884c\u79d1\u5b66\u63a2\u7d22\u5f00\u8f9f\u4e86\u9014\u5f84\u3002"}}
{"id": "2511.09483", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09483", "abs": "https://arxiv.org/abs/2511.09483", "authors": ["Peiyu Li", "Xiaobao Huang", "Nitesh V. Chawla"], "title": "CrochetBench: Can Vision-Language Models Move from Describing to Doing in Crochet Domain?", "comment": "code available at https://github.com/Peiyu-Georgia-Li/crochetBench", "summary": "We present CrochetBench, a benchmark for evaluating the ability of multimodal large language models to perform fine-grained, low-level procedural reasoning in the domain of crochet. Unlike prior benchmarks that focus on high-level description or visual question answering, CrochetBench shifts the emphasis from describing to doing: models are required to recognize stitches, select structurally appropriate instructions, and generate compilable crochet procedures. We adopt the CrochetPARADE DSL as our intermediate representation, enabling structural validation and functional evaluation via execution. The benchmark covers tasks including stitch classification, instruction grounding, and both natural language and image-to-DSL translation. Across all tasks, performance sharply declines as the evaluation shifts from surface-level similarity to executable correctness, exposing limitations in long-range symbolic reasoning and 3D-aware procedural synthesis. CrochetBench offers a new lens for assessing procedural competence in multimodal models and highlights the gap between surface-level understanding and executable precision in real-world creative domains. Code is available at https://github.com/Peiyu-Georgia-Li/crochetBench.", "AI": {"tldr": "CrochetBench\u662f\u4e00\u4e2a\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u94a9\u9488\u7f16\u7ec7\u9886\u57df\u8fdb\u884c\u7ec6\u7c92\u5ea6\u3001\u4f4e\u5c42\u6b21\u7a0b\u5e8f\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5f3a\u8c03\u4ece\u63cf\u8ff0\u8f6c\u5411\u5b9e\u9645\u64cd\u4f5c\uff0c\u8981\u6c42\u6a21\u578b\u8bc6\u522b\u9488\u6cd5\u3001\u9009\u62e9\u7ed3\u6784\u9002\u5f53\u7684\u6307\u4ee4\u5e76\u751f\u6210\u53ef\u7f16\u8bd1\u7684\u94a9\u9488\u7a0b\u5e8f\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u9ad8\u5c42\u6b21\u63cf\u8ff0\u6216\u89c6\u89c9\u95ee\u7b54\uff0c\u7f3a\u4e4f\u5bf9\u4f4e\u5c42\u6b21\u7a0b\u5e8f\u63a8\u7406\u80fd\u529b\u7684\u8bc4\u4f30\u3002CrochetBench\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u901a\u8fc7\u94a9\u9488\u7f16\u7ec7\u8fd9\u4e00\u9700\u8981\u7cbe\u786e\u7a0b\u5e8f\u6267\u884c\u7684\u521b\u9020\u6027\u9886\u57df\u6765\u8bc4\u4f30\u6a21\u578b\u7684\u5b9e\u9645\u64cd\u4f5c\u80fd\u529b\u3002", "method": "\u91c7\u7528CrochetPARADE DSL\u4f5c\u4e3a\u4e2d\u95f4\u8868\u793a\uff0c\u652f\u6301\u7ed3\u6784\u9a8c\u8bc1\u548c\u901a\u8fc7\u6267\u884c\u8fdb\u884c\u529f\u80fd\u8bc4\u4f30\u3002\u57fa\u51c6\u6d4b\u8bd5\u6db5\u76d6\u9488\u6cd5\u5206\u7c7b\u3001\u6307\u4ee4\u57fa\u7840\u3001\u81ea\u7136\u8bed\u8a00\u5230DSL\u7ffb\u8bd1\u548c\u56fe\u50cf\u5230DSL\u7ffb\u8bd1\u7b49\u4efb\u52a1\u3002", "result": "\u5728\u6240\u6709\u4efb\u52a1\u4e2d\uff0c\u5f53\u8bc4\u4f30\u4ece\u8868\u9762\u76f8\u4f3c\u6027\u8f6c\u5411\u53ef\u6267\u884c\u6b63\u786e\u6027\u65f6\uff0c\u6a21\u578b\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u66b4\u9732\u4e86\u957f\u8ddd\u79bb\u7b26\u53f7\u63a8\u7406\u548c3D\u611f\u77e5\u7a0b\u5e8f\u5408\u6210\u7684\u5c40\u9650\u6027\u3002", "conclusion": "CrochetBench\u4e3a\u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u7684\u7a0b\u5e8f\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5e76\u63ed\u793a\u4e86\u5728\u73b0\u5b9e\u4e16\u754c\u521b\u9020\u6027\u9886\u57df\u4e2d\u8868\u9762\u7406\u89e3\u4e0e\u53ef\u6267\u884c\u7cbe\u5ea6\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2511.09493", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09493", "abs": "https://arxiv.org/abs/2511.09493", "authors": ["Adam Tauman Kalai", "Yael Tauman Kalai", "Or Zamir"], "title": "Consensus Sampling for Safer Generative AI", "comment": null, "summary": "Many approaches to AI safety rely on inspecting model outputs or activations, yet certain risks are inherently undetectable by inspection alone. We propose a complementary, architecture-agnostic approach that enhances safety through the aggregation of multiple generative models, with the aggregated model inheriting its safety from the safest subset of a given size among them. Specifically, we present a consensus sampling algorithm that, given $k$ models and a prompt, achieves risk competitive with the average risk of the safest $s$ of the $k$ models, where $s$ is a chosen parameter, while abstaining when there is insufficient agreement between them. The approach leverages the models' ability to compute output probabilities, and we bound the probability of abstention when sufficiently many models are safe and exhibit adequate agreement. The algorithm is inspired by the provable copyright protection algorithm of Vyas et al. (2023). It requires some overlap among safe models, offers no protection when all models are unsafe, and may accumulate risk over repeated use. Nonetheless, our results provide a new, model-agnostic approach for AI safety by amplifying safety guarantees from an unknown subset of models within a collection to that of a single reliable model.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u578b\u805a\u5408\u7684AI\u5b89\u5168\u65b9\u6cd5\uff0c\u901a\u8fc7\u5171\u8bc6\u91c7\u6837\u7b97\u6cd5\u4ecek\u4e2a\u6a21\u578b\u4e2d\u9009\u62e9\u6700\u5b89\u5168\u7684s\u4e2a\u5b50\u96c6\uff0c\u5728\u6a21\u578b\u95f4\u8fbe\u6210\u8db3\u591f\u5171\u8bc6\u65f6\u8f93\u51fa\u7ed3\u679c\uff0c\u5426\u5219\u5f03\u6743\uff0c\u4ece\u800c\u589e\u5f3a\u5b89\u5168\u6027\u3002", "motivation": "\u73b0\u6709\u7684AI\u5b89\u5168\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u68c0\u67e5\u6a21\u578b\u8f93\u51fa\u6216\u6fc0\u6d3b\uff0c\u4f46\u67d0\u4e9b\u98ce\u9669\u65e0\u6cd5\u4ec5\u901a\u8fc7\u68c0\u67e5\u68c0\u6d4b\u3002\u9700\u8981\u4e00\u79cd\u67b6\u6784\u65e0\u5173\u7684\u8865\u5145\u65b9\u6cd5\u6765\u589e\u5f3a\u5b89\u5168\u6027\u3002", "method": "\u4f7f\u7528\u5171\u8bc6\u91c7\u6837\u7b97\u6cd5\uff0c\u5229\u7528k\u4e2a\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u8ba1\u7b97\u8f93\u51fa\u6982\u7387\uff0c\u9009\u62e9\u6700\u5b89\u5168\u7684s\u4e2a\u6a21\u578b\u5b50\u96c6\uff0c\u5728\u6a21\u578b\u95f4\u8fbe\u6210\u8db3\u591f\u5171\u8bc6\u65f6\u8f93\u51fa\u7ed3\u679c\uff0c\u5426\u5219\u5f03\u6743\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u4e0e\u6700\u5b89\u5168s\u4e2a\u6a21\u578b\u5e73\u5747\u98ce\u9669\u76f8\u5f53\u7684\u5b89\u5168\u6027\uff0c\u5e76\u5728\u8db3\u591f\u591a\u6a21\u578b\u5b89\u5168\u4e14\u8fbe\u6210\u5171\u8bc6\u65f6\u9650\u5236\u5f03\u6743\u6982\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u65e0\u5173\u7684AI\u5b89\u5168\u65b9\u6cd5\uff0c\u901a\u8fc7\u653e\u5927\u96c6\u5408\u4e2d\u672a\u77e5\u5b89\u5168\u5b50\u96c6\u7684\u5b89\u5168\u4fdd\u8bc1\u6765\u521b\u5efa\u5355\u4e2a\u53ef\u9760\u6a21\u578b\u3002"}}
{"id": "2511.09497", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09497", "abs": "https://arxiv.org/abs/2511.09497", "authors": ["Vahid Salehi"], "title": "Fundamentals of Physical AI", "comment": "This paper is already published in Journal of Intelligent System of Systems Lifecycle Management", "summary": "This work will elaborate the fundamental principles of physical artificial intelligence (Physical AI) from a scientific and systemic perspective. The aim is to create a theoretical foundation that describes the physical embodiment, sensory perception, ability to act, learning processes, and context sensitivity of intelligent systems within a coherent framework. While classical AI approaches rely on symbolic processing and data driven models, Physical AI understands intelligence as an emergent phenomenon of real interaction between body, environment, and experience. The six fundamentals presented here are embodiment, sensory perception, motor action, learning, autonomy, and context sensitivity, and form the conceptual basis for designing and evaluating physically intelligent systems. Theoretically, it is shown that these six principles do not represent loose functional modules but rather act as a closed control loop in which energy, information, control, and context are in constant interaction. This circular interaction enables a system to generate meaning not from databases, but from physical experience, a paradigm shift that understands intelligence as an physical embodied process. Physical AI understands learning not as parameter adjustment, but as a change in the structural coupling between agents and the environment. To illustrate this, the theoretical model is explained using a practical scenario: An adaptive assistant robot supports patients in a rehabilitation clinic. This example illustrates that physical intelligence does not arise from abstract calculation, but from immediate, embodied experience. It shows how the six fundamentals interact in a real system: embodiment as a prerequisite, perception as input, movement as expression, learning as adaptation, autonomy as regulation, and context as orientation.", "AI": {"tldr": "\u672c\u6587\u4ece\u79d1\u5b66\u548c\u7cfb\u7edf\u89d2\u5ea6\u9610\u8ff0\u4e86\u7269\u7406\u4eba\u5de5\u667a\u80fd\u7684\u57fa\u672c\u539f\u7406\uff0c\u65e8\u5728\u4e3a\u667a\u80fd\u7cfb\u7edf\u7684\u7269\u7406\u4f53\u73b0\u3001\u611f\u77e5\u3001\u884c\u52a8\u3001\u5b66\u4e60\u548c\u60c5\u5883\u654f\u611f\u6027\u5efa\u7acb\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u3002", "motivation": "\u4f20\u7edfAI\u4f9d\u8d56\u7b26\u53f7\u5904\u7406\u548c\u6570\u636e\u9a71\u52a8\u6a21\u578b\uff0c\u800c\u7269\u7406AI\u5c06\u667a\u80fd\u89c6\u4e3a\u8eab\u4f53\u3001\u73af\u5883\u548c\u7ecf\u9a8c\u771f\u5b9e\u4ea4\u4e92\u4e2d\u6d8c\u73b0\u7684\u73b0\u8c61\uff0c\u9700\u8981\u5efa\u7acb\u65b0\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u516d\u4e2a\u57fa\u672c\u539f\u5219\uff1a\u5177\u8eab\u6027\u3001\u611f\u5b98\u611f\u77e5\u3001\u8fd0\u52a8\u884c\u52a8\u3001\u5b66\u4e60\u3001\u81ea\u4e3b\u6027\u548c\u60c5\u5883\u654f\u611f\u6027\uff0c\u8fd9\u4e9b\u539f\u5219\u6784\u6210\u5c01\u95ed\u63a7\u5236\u5faa\u73af\uff0c\u80fd\u91cf\u3001\u4fe1\u606f\u3001\u63a7\u5236\u548c\u60c5\u5883\u6301\u7eed\u4ea4\u4e92\u3002", "result": "\u5efa\u7acb\u4e86\u7269\u7406AI\u7684\u7406\u8bba\u6a21\u578b\uff0c\u901a\u8fc7\u5eb7\u590d\u673a\u5668\u4eba\u6848\u4f8b\u5c55\u793a\u4e86\u516d\u4e2a\u539f\u5219\u5728\u5b9e\u9645\u7cfb\u7edf\u4e2d\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u8bc1\u660e\u667a\u80fd\u6765\u81ea\u7269\u7406\u4f53\u9a8c\u800c\u975e\u62bd\u8c61\u8ba1\u7b97\u3002", "conclusion": "\u7269\u7406AI\u5c06\u667a\u80fd\u7406\u89e3\u4e3a\u7269\u7406\u5177\u8eab\u8fc7\u7a0b\uff0c\u5b66\u4e60\u662f\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u7ed3\u6784\u8026\u5408\u7684\u53d8\u5316\uff0c\u8fd9\u4e00\u8303\u5f0f\u8f6c\u53d8\u4f7f\u7cfb\u7edf\u80fd\u591f\u4ece\u7269\u7406\u7ecf\u9a8c\u800c\u975e\u6570\u636e\u5e93\u4e2d\u751f\u6210\u610f\u4e49\u3002"}}

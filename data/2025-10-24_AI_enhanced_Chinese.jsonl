{"id": "2510.19835", "categories": ["cs.AI", "cs.ET", "cs.NE", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.19835", "abs": "https://arxiv.org/abs/2510.19835", "authors": ["Max B. Zhao", "Fei Li"], "title": "A Quantum-Inspired Algorithm for Solving Sudoku Puzzles and the MaxCut Problem", "comment": "29 pages, 10 figures, accepted by Quantum Information & Computation\n  on August 6, 2025", "summary": "We propose and evaluate a quantum-inspired algorithm for solving Quadratic\nUnconstrained Binary Optimization (QUBO) problems, which are mathematically\nequivalent to finding ground states of Ising spin-glass Hamiltonians. The\nalgorithm employs Matrix Product States (MPS) to compactly represent large\nsuperpositions of spin configurations and utilizes a discrete driving schedule\nto guide the MPS toward the ground state. At each step, a driver Hamiltonian --\nincorporating a transverse magnetic field -- is combined with the problem\nHamiltonian to enable spin flips and facilitate quantum tunneling. The MPS is\nupdated using the standard Density Matrix Renormalization Group (DMRG) method,\nwhich iteratively minimizes the system's energy via multiple sweeps across the\nspin chain. Despite its heuristic nature, the algorithm reliably identifies\nglobal minima, not merely near-optimal solutions, across diverse QUBO\ninstances. We first demonstrate its effectiveness on intermediate-level Sudoku\npuzzles from publicly available sources, involving over $200$ Ising spins with\nlong-range couplings dictated by constraint satisfaction. We then apply the\nalgorithm to MaxCut problems from the Biq Mac library, successfully solving\ninstances with up to $251$ nodes and $3,265$ edges. We discuss the advantages\nof this quantum-inspired approach, including its scalability, generalizability,\nand suitability for industrial-scale QUBO applications.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u4e00\u79cd\u91cf\u5b50\u542f\u53d1\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\uff08QUBO\uff09\u95ee\u9898\uff0c\u8be5\u7b97\u6cd5\u4f7f\u7528\u77e9\u9635\u4e58\u79ef\u6001\uff08MPS\uff09\u548c\u5bc6\u5ea6\u77e9\u9635\u91cd\u6574\u5316\u7fa4\uff08DMRG\uff09\u65b9\u6cd5\uff0c\u5728Sudoku\u8c1c\u9898\u548cMaxCut\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u89e3\u51b3QUBO\u95ee\u9898\u5728\u6570\u5b66\u4e0a\u7b49\u540c\u4e8e\u5bfb\u627eIsing\u81ea\u65cb\u73bb\u7483\u54c8\u5bc6\u987f\u91cf\u7684\u57fa\u6001\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5927\u89c4\u6a21\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u53ef\u6269\u5c55\u7684\u91cf\u5b50\u542f\u53d1\u7b97\u6cd5\u3002", "method": "\u4f7f\u7528\u77e9\u9635\u4e58\u79ef\u6001\uff08MPS\uff09\u7d27\u51d1\u8868\u793a\u81ea\u65cb\u6784\u578b\u7684\u5927\u53e0\u52a0\uff0c\u7ed3\u5408\u79bb\u6563\u9a71\u52a8\u8c03\u5ea6\u5f15\u5bfcMPS\u5411\u57fa\u6001\u6f14\u5316\uff0c\u901a\u8fc7\u5305\u542b\u6a2a\u5411\u78c1\u573a\u7684\u9a71\u52a8\u54c8\u5bc6\u987f\u91cf\u5b9e\u73b0\u81ea\u65cb\u7ffb\u8f6c\u548c\u91cf\u5b50\u96a7\u7a7f\uff0c\u4f7f\u7528DMRG\u65b9\u6cd5\u8fed\u4ee3\u6700\u5c0f\u5316\u7cfb\u7edf\u80fd\u91cf\u3002", "result": "\u7b97\u6cd5\u5728\u591a\u6837\u5316QUBO\u5b9e\u4f8b\u4e2d\u53ef\u9760\u8bc6\u522b\u5168\u5c40\u6700\u5c0f\u503c\uff0c\u6210\u529f\u89e3\u51b3\u5305\u542b200\u591a\u4e2aIsing\u81ea\u65cb\u7684Sudoku\u8c1c\u9898\uff0c\u4ee5\u53caBiq Mac\u5e93\u4e2d\u6700\u591a251\u4e2a\u8282\u70b9\u548c3,265\u6761\u8fb9\u7684MaxCut\u95ee\u9898\u3002", "conclusion": "\u8be5\u91cf\u5b50\u542f\u53d1\u65b9\u6cd5\u5177\u6709\u53ef\u6269\u5c55\u6027\u3001\u901a\u7528\u6027\u548c\u9002\u7528\u4e8e\u5de5\u4e1a\u89c4\u6a21QUBO\u5e94\u7528\u7684\u4f18\u52bf\u3002"}}
{"id": "2510.19836", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.19836", "abs": "https://arxiv.org/abs/2510.19836", "authors": ["Eliseo Curcio"], "title": "Benchmarking Reasoning Reliability in Artificial Intelligence Models for Energy-System Analysis", "comment": null, "summary": "Artificial intelligence and machine learning are increasingly used for\nforecasting, optimization, and policy design in the energy sector, yet no\nstandardized framework exists to evaluate whether these systems reason\ncorrectly. Current validation practices focus on predictive accuracy or\ncomputational efficiency, leaving the logical integrity of analytical\nconclusions untested. This study introduces the Analytical Reliability\nBenchmark (ARB), a reproducible framework that quantifies reasoning reliability\nin large language models applied to energy system analysis. The benchmark\nintegrates five submetrics: accuracy, reasoning reliability, uncertainty\ndiscipline, policy consistency, and transparency, and evaluates model\nperformance across deterministic, probabilistic, and epistemic scenarios using\nopen technoeconomic datasets (NREL ATB 2024, DOE H2A/H2New, IEA WEO 2024). Four\nfrontier models (GPT-4/5, Claude 4.5 Sonnet, Gemini 2.5 Pro, Llama 3 70B) were\ntested under identical factual and regulatory conditions. Results show that\nreasoning reliability can be objectively measured. GPT-4/5 and Claude 4.5\nSonnet achieved consistent and policy-compliant reasoning (Analytical\nReliability Index greater than 90), Gemini 2.5 Pro demonstrated moderate\nstability, and Llama 3 70B remained below professional thresholds. Statistical\nvalidation confirmed that these differences are significant and reproducible.\nThe ARB establishes the first quantitative method in the energy literature for\nverifying causal, probabilistic, and policy-driven reasoning in artificial\nintelligence systems, providing a reference framework for trustworthy and\ntransparent analytical applications in the global energy transition.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u5206\u6790\u53ef\u9760\u6027\u57fa\u51c6\uff08ARB\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u80fd\u6e90\u7cfb\u7edf\u5206\u6790\u4e2d\u7684\u63a8\u7406\u53ef\u9760\u6027\u3002\u8be5\u57fa\u51c6\u6574\u5408\u4e86\u4e94\u4e2a\u5b50\u6307\u6807\uff0c\u5728\u786e\u5b9a\u6027\u3001\u6982\u7387\u6027\u548c\u8ba4\u77e5\u6027\u573a\u666f\u4e0b\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\uff0c\u7ed3\u679c\u663e\u793aGPT-4/5\u548cClaude 4.5 Sonnet\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u548c\u673a\u5668\u5b66\u4e60\u5728\u80fd\u6e90\u9886\u57df\u7684\u5e94\u7528\u7f3a\u4e4f\u6807\u51c6\u5316\u6846\u67b6\u6765\u8bc4\u4f30\u63a8\u7406\u6b63\u786e\u6027\uff0c\u73b0\u6709\u9a8c\u8bc1\u5b9e\u8df5\u4e3b\u8981\u5173\u6ce8\u9884\u6d4b\u51c6\u786e\u6027\u6216\u8ba1\u7b97\u6548\u7387\uff0c\u800c\u5ffd\u7565\u4e86\u5206\u6790\u7ed3\u8bba\u7684\u903b\u8f91\u5b8c\u6574\u6027\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86\u5206\u6790\u53ef\u9760\u6027\u57fa\u51c6\uff08ARB\uff09\uff0c\u6574\u5408\u4e94\u4e2a\u5b50\u6307\u6807\uff08\u51c6\u786e\u6027\u3001\u63a8\u7406\u53ef\u9760\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u7eaa\u5f8b\u3001\u653f\u7b56\u4e00\u81f4\u6027\u548c\u900f\u660e\u5ea6\uff09\uff0c\u4f7f\u7528\u5f00\u653e\u6280\u672f\u7ecf\u6d4e\u6570\u636e\u96c6\u5728\u786e\u5b9a\u6027\u3001\u6982\u7387\u6027\u548c\u8ba4\u77e5\u6027\u573a\u666f\u4e0b\u8bc4\u4f30\u56db\u4e2a\u524d\u6cbf\u6a21\u578b\uff08GPT-4/5\u3001Claude 4.5 Sonnet\u3001Gemini 2.5 Pro\u3001Llama 3 70B\uff09\u3002", "result": "GPT-4/5\u548cClaude 4.5 Sonnet\u5b9e\u73b0\u4e86\u6301\u7eed\u4e14\u7b26\u5408\u653f\u7b56\u7684\u63a8\u7406\uff08\u5206\u6790\u53ef\u9760\u6027\u6307\u6570\u5927\u4e8e90\uff09\uff0cGemini 2.5 Pro\u8868\u73b0\u51fa\u4e2d\u7b49\u7a33\u5b9a\u6027\uff0c\u800cLlama 3 70B\u4f4e\u4e8e\u4e13\u4e1a\u9608\u503c\u3002\u7edf\u8ba1\u9a8c\u8bc1\u786e\u8ba4\u8fd9\u4e9b\u5dee\u5f02\u662f\u663e\u8457\u4e14\u53ef\u590d\u73b0\u7684\u3002", "conclusion": "ARB\u5efa\u7acb\u4e86\u80fd\u6e90\u6587\u732e\u4e2d\u9996\u4e2a\u5b9a\u91cf\u65b9\u6cd5\uff0c\u7528\u4e8e\u9a8c\u8bc1\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u56e0\u679c\u3001\u6982\u7387\u548c\u653f\u7b56\u9a71\u52a8\u63a8\u7406\uff0c\u4e3a\u5168\u7403\u80fd\u6e90\u8f6c\u578b\u4e2d\u53ef\u4fe1\u8d56\u548c\u900f\u660e\u7684\u5206\u6790\u5e94\u7528\u63d0\u4f9b\u4e86\u53c2\u8003\u6846\u67b6\u3002"}}
{"id": "2510.19842", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19842", "abs": "https://arxiv.org/abs/2510.19842", "authors": ["Yuanhe Zhang", "Ilja Kuzborskij", "Jason D. Lee", "Chenlei Leng", "Fanghui Liu"], "title": "DAG-Math: Graph-Guided Mathematical Reasoning in LLMs", "comment": "28 pages, 6 figures. Comments are welcome", "summary": "Large Language Models (LLMs) demonstrate strong performance on mathematical\nproblems when prompted with Chain-of-Thought (CoT), yet it remains unclear\nwhether this success stems from search, rote procedures, or rule-consistent\nreasoning. To address this, we propose modeling CoT as a certain rule-based\nstochastic process over directed acyclic graphs (DAGs), where nodes represent\nintermediate derivation states and edges encode rule applications. Within this\nframework, we introduce logical closeness, a metric that quantifies how well a\nmodel's CoT trajectory (i.e., the LLM's final output) adheres to the DAG\nstructure, providing evaluation beyond classical PASS@k metrics. Building on\nthis, we introduce the DAG-MATH CoT format and construct a benchmark that\nguides LLMs to generate CoT trajectories in this format, thereby enabling the\nevaluation of their reasoning ability under our framework. Across standard\nmathematical reasoning datasets, our analysis uncovers statistically\nsignificant differences in reasoning fidelity among representative LLM\nfamilies-even when PASS@k is comparable-highlighting gaps between final-answer\naccuracy and rule-consistent derivation. Our framework provides a balance\nbetween free-form CoT and formal proofs systems, offering actionable\ndiagnostics for LLMs reasoning evaluation. Our benchmark and code are available\nat: https://github.com/YuanheZ/DAG-MATH-Formatted-CoT.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u7684\u6846\u67b6\u6765\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u601d\u7ef4\u94fe\u8d28\u91cf\uff0c\u5f15\u5165\u903b\u8f91\u63a5\u8fd1\u5ea6\u6307\u6807\u6765\u91cf\u5316\u6a21\u578b\u63a8\u7406\u8f68\u8ff9\u4e0e\u89c4\u5219\u4e00\u81f4\u6027\uff0c\u63ed\u793a\u4e86\u5373\u4f7f\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u7387\u76f8\u4f3c\uff0c\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u5728\u63a8\u7406\u4fdd\u771f\u5ea6\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u95ee\u9898\u4e0a\u4f7f\u7528\u601d\u7ef4\u94fe\uff08CoT\uff09\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u8fd9\u79cd\u6210\u529f\u662f\u6e90\u4e8e\u641c\u7d22\u3001\u673a\u68b0\u8bb0\u5fc6\u8fd8\u662f\u89c4\u5219\u4e00\u81f4\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u6df1\u5165\u7406\u89e3\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5c06\u601d\u7ef4\u94fe\u5efa\u6a21\u4e3a\u57fa\u4e8e\u89c4\u5219\u7684\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u968f\u673a\u8fc7\u7a0b\uff0c\u5176\u4e2d\u8282\u70b9\u8868\u793a\u4e2d\u95f4\u63a8\u5bfc\u72b6\u6001\uff0c\u8fb9\u7f16\u7801\u89c4\u5219\u5e94\u7528\uff1b\u5f15\u5165DAG-MATH CoT\u683c\u5f0f\u548c\u903b\u8f91\u63a5\u8fd1\u5ea6\u6307\u6807\u6765\u8bc4\u4f30\u63a8\u7406\u8f68\u8ff9\u4e0eDAG\u7ed3\u6784\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728\u6807\u51c6\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u7684\u5206\u6790\u53d1\u73b0\uff0c\u5373\u4f7fPASS@k\u6307\u6807\u76f8\u4f3c\uff0c\u4ee3\u8868\u6027LLM\u5bb6\u65cf\u5728\u63a8\u7406\u4fdd\u771f\u5ea6\u4e0a\u5b58\u5728\u7edf\u8ba1\u663e\u8457\u5dee\u5f02\uff0c\u63ed\u793a\u4e86\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u6027\u4e0e\u89c4\u5219\u4e00\u81f4\u63a8\u5bfc\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u81ea\u7531\u5f62\u5f0f\u601d\u7ef4\u94fe\u548c\u5f62\u5f0f\u8bc1\u660e\u7cfb\u7edf\u4e4b\u95f4\u63d0\u4f9b\u4e86\u5e73\u8861\uff0c\u4e3aLLM\u63a8\u7406\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u66f4\u6df1\u5165\u5730\u7406\u89e3\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.20137", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.20137", "abs": "https://arxiv.org/abs/2510.20137", "authors": ["Hasnain A. Ziad", "Ashiq A. Sakib"], "title": "HALOC-AxA: An Area/-Energy-Efficient Approximate Adder for Image Processing Application", "comment": "5 Pages, 6 Figures, and 1 Table", "summary": "The design of approximate adders has been widely researched to advance\nenergy-efficient hardware for computation-intensive multimedia applications,\nsuch as image, audio, or video processing. The design of approximate adders has\nbeen widely researched to advance energy-efficient hardware for computation\nintensive multimedia applications, such as image/audio/video processing.\nSeveral static and dynamic approximate adders exist in the literature, each of\nwhich endeavors to balance the conflicting demands of high performance,\ncomputational accuracy, and energy efficiency. This work introduces a novel\napproximate adder that is more energy- and area-efficient than existing adders,\nwhile achieving improved or comparable accuracy, as demonstrated by simulation\nresults. The proposed adder's ability to digitally reconstruct high quality\nimages is further demonstrated by the deployment of the design for an image\nprocessing task.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u578b\u8fd1\u4f3c\u52a0\u6cd5\u5668\uff0c\u6bd4\u73b0\u6709\u52a0\u6cd5\u5668\u66f4\u8282\u80fd\u3001\u9762\u79ef\u66f4\u5c0f\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u8ba1\u7b97\u7cbe\u5ea6\uff0c\u9002\u7528\u4e8e\u56fe\u50cf\u5904\u7406\u7b49\u591a\u5a92\u4f53\u5e94\u7528\u3002", "motivation": "\u4e3a\u8ba1\u7b97\u5bc6\u96c6\u578b\u591a\u5a92\u4f53\u5e94\u7528\uff08\u5982\u56fe\u50cf\u3001\u97f3\u9891\u3001\u89c6\u9891\u5904\u7406\uff09\u5f00\u53d1\u66f4\u8282\u80fd\u7684\u786c\u4ef6\uff0c\u5e73\u8861\u9ad8\u6027\u80fd\u3001\u8ba1\u7b97\u7cbe\u5ea6\u548c\u80fd\u6548\u4e4b\u95f4\u7684\u51b2\u7a81\u9700\u6c42\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u578b\u8fd1\u4f3c\u52a0\u6cd5\u5668\uff0c\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u5176\u6027\u80fd\uff0c\u5e76\u5c06\u5176\u90e8\u7f72\u5230\u56fe\u50cf\u5904\u7406\u4efb\u52a1\u4e2d\u5c55\u793a\u6570\u5b57\u91cd\u5efa\u9ad8\u8d28\u91cf\u56fe\u50cf\u7684\u80fd\u529b\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u52a0\u6cd5\u5668\u5728\u80fd\u6548\u548c\u9762\u79ef\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u52a0\u6cd5\u5668\uff0c\u540c\u65f6\u5b9e\u73b0\u6539\u8fdb\u6216\u76f8\u5f53\u7684\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u65b0\u578b\u8fd1\u4f3c\u52a0\u6cd5\u5668\u5728\u80fd\u6548\u3001\u9762\u79ef\u6548\u7387\u548c\u8ba1\u7b97\u7cbe\u5ea6\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u9002\u7528\u4e8e\u591a\u5a92\u4f53\u5904\u7406\u5e94\u7528\u3002"}}
{"id": "2510.19844", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19844", "abs": "https://arxiv.org/abs/2510.19844", "authors": ["Isaac Wu", "Michael Maslowski"], "title": "CourtGuard: A Local, Multiagent Prompt Injection Classifier", "comment": "11 pages, 7 figures", "summary": "As large language models (LLMs) become integrated into various sensitive\napplications, prompt injection, the use of prompting to induce harmful\nbehaviors from LLMs, poses an ever increasing risk. Prompt injection attacks\ncan cause LLMs to leak sensitive data, spread misinformation, and exhibit\nharmful behaviors. To defend against these attacks, we propose CourtGuard, a\nlocally-runnable, multiagent prompt injection classifier. In it, prompts are\nevaluated in a court-like multiagent LLM system, where a \"defense attorney\"\nmodel argues the prompt is benign, a \"prosecution attorney\" model argues the\nprompt is a prompt injection, and a \"judge\" model gives the final\nclassification. CourtGuard has a lower false positive rate than the Direct\nDetector, an LLM as-a-judge. However, CourtGuard is generally a worse prompt\ninjection detector. Nevertheless, this lower false positive rate highlights the\nimportance of considering both adversarial and benign scenarios for the\nclassification of a prompt. Additionally, the relative performance of\nCourtGuard in comparison to other prompt injection classifiers advances the use\nof multiagent systems as a defense against prompt injection attacks. The\nimplementations of CourtGuard and the Direct Detector with full prompts for\nGemma-3-12b-it, Llama-3.3-8B, and Phi-4-mini-instruct are available at\nhttps://github.com/isaacwu2000/CourtGuard.", "AI": {"tldr": "CourtGuard\u662f\u4e00\u4e2a\u672c\u5730\u8fd0\u884c\u7684\u591a\u667a\u80fd\u4f53\u63d0\u793a\u6ce8\u5165\u5206\u7c7b\u5668\uff0c\u91c7\u7528\u6cd5\u5ead\u5f0f\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u6765\u68c0\u6d4b\u6076\u610f\u63d0\u793a\uff0c\u867d\u7136\u6574\u4f53\u68c0\u6d4b\u6027\u80fd\u4e0d\u5982\u76f4\u63a5\u68c0\u6d4b\u5668\uff0c\u4f46\u5177\u6709\u66f4\u4f4e\u7684\u8bef\u62a5\u7387\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u5e94\u7528\u4e2d\u7684\u96c6\u6210\uff0c\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff08\u901a\u8fc7\u63d0\u793a\u8bf1\u5bfcLLM\u4ea7\u751f\u6709\u5bb3\u884c\u4e3a\uff09\u98ce\u9669\u65e5\u76ca\u589e\u52a0\uff0c\u53ef\u80fd\u5bfc\u81f4\u654f\u611f\u6570\u636e\u6cc4\u9732\u3001\u865a\u5047\u4fe1\u606f\u4f20\u64ad\u7b49\u5371\u5bb3\u3002", "method": "\u63d0\u51faCourtGuard\u7cfb\u7edf\uff0c\u91c7\u7528\u6cd5\u5ead\u5f0f\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff1a'\u8fa9\u62a4\u5f8b\u5e08'\u6a21\u578b\u8bba\u8bc1\u63d0\u793a\u662f\u826f\u6027\u7684\uff0c'\u68c0\u5bdf\u5b98'\u6a21\u578b\u8bba\u8bc1\u63d0\u793a\u662f\u63d0\u793a\u6ce8\u5165\uff0c'\u6cd5\u5b98'\u6a21\u578b\u7ed9\u51fa\u6700\u7ec8\u5206\u7c7b\u3002", "result": "CourtGuard\u76f8\u6bd4\u76f4\u63a5\u68c0\u6d4b\u5668\u5177\u6709\u66f4\u4f4e\u7684\u8bef\u62a5\u7387\uff0c\u4f46\u6574\u4f53\u4e0a\u662f\u4e00\u4e2a\u8f83\u5dee\u7684\u63d0\u793a\u6ce8\u5165\u68c0\u6d4b\u5668\u3002\u5728Gemma-3-12b-it\u3001Llama-3.3-8B\u548cPhi-4-mini-instruct\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5b9e\u73b0\u3002", "conclusion": "CourtGuard\u8f83\u4f4e\u7684\u8bef\u62a5\u7387\u51f8\u663e\u4e86\u5728\u63d0\u793a\u5206\u7c7b\u65f6\u540c\u65f6\u8003\u8651\u5bf9\u6297\u6027\u548c\u826f\u6027\u573a\u666f\u7684\u91cd\u8981\u6027\uff0c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f5c\u4e3a\u63d0\u793a\u6ce8\u5165\u9632\u5fa1\u7684\u524d\u666f\u5f97\u5230\u4e86\u63a8\u8fdb\u3002"}}
{"id": "2510.19972", "categories": ["cs.DC", "cs.CC"], "pdf": "https://arxiv.org/pdf/2510.19972", "abs": "https://arxiv.org/abs/2510.19972", "authors": ["Alkida Balliu", "Filippo Casagrande", "Francesco d'Amore", "Dennis Olivetti"], "title": "New Hardness Results for the LOCAL Model via a Simple Self-Reduction", "comment": "21 pages, no figures", "summary": "Very recently, Khoury and Schild [FOCS 2025] showed that any randomized LOCAL\nalgorithm that solves maximal matching requires $\\Omega(\\min\\{\\log \\Delta,\n\\log_\\Delta n\\})$ rounds, where $n$ is the number of nodes in the graph and\n$\\Delta$ is the maximum degree. This result is shown through a new technique,\ncalled round elimination via self-reduction. The lower bound proof is beautiful\nand presents very nice ideas. However, it spans more than 25 pages of technical\ndetails, and hence it is hard to digest and generalize to other problems.\nHistorically, the simplification of proofs and techniques has marked an\nimportant turning point in our understanding of the complexity of graph\nproblems. Our paper makes a step forward towards this direction, and provides\nthe following contributions.\n  1. We present a short and simplified version of the round elimination via\nself-reduction technique. The simplification of this technique enables us to\nobtain the following two hardness results.\n  2. We show that any randomized LOCAL algorithm that solves the maximal\n$b$-matching problem requires $\\Omega(\\min\\{\\log_{1+b}\\Delta, \\log_\\Delta n\\})$\nand $\\Omega(\\sqrt{\\log_{1+b} n})$ rounds. We recall that the $b$-matching\nproblem is a generalization of the matching problem where each vertex can have\nup to $b$ incident edges in the matching. As a corollary, for $b=1$, we obtain\na short proof for the maximal matching lower bound shown by Khoury and Schild.\n  3. Finally, we show that any randomized LOCAL algorithm that properly colors\nthe edges of a graph with $\\Delta + k$ colors requires $\\Omega(\\min\\{\\log\n\\Delta, \\log_\\Delta n\\})$ and $\\Omega(\\sqrt{\\log n})$ rounds, for any $k\\le\n\\Delta^{1-\\varepsilon}$ and any constant $\\varepsilon > 0$.", "AI": {"tldr": "\u672c\u6587\u7b80\u5316\u4e86Khoury\u548cSchild\u7684\u8f6e\u6d88\u9664\u81ea\u7ea6\u7b80\u6280\u672f\uff0c\u5e76\u5e94\u7528\u8be5\u6280\u672f\u8bc1\u660e\u4e86\u6700\u5927b\u5339\u914d\u548c\u8fb9\u7740\u8272\u7684\u968f\u673aLOCAL\u7b97\u6cd5\u4e0b\u754c\u3002", "motivation": "Khoury\u548cSchild\u5173\u4e8e\u6700\u5927\u5339\u914d\u7684\u968f\u673aLOCAL\u7b97\u6cd5\u4e0b\u754c\u8bc1\u660e\u957f\u8fbe25\u9875\u4e14\u6280\u672f\u590d\u6742\uff0c\u96be\u4ee5\u7406\u89e3\u548c\u63a8\u5e7f\u3002\u5386\u53f2\u4e0a\u8bc1\u660e\u7b80\u5316\u5bf9\u7406\u89e3\u56fe\u95ee\u9898\u590d\u6742\u6027\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u63d0\u51fa\u7b80\u5316\u7684\u8f6e\u6d88\u9664\u81ea\u7ea6\u7b80\u6280\u672f\uff0c\u5e76\u5e94\u7528\u8be5\u6280\u672f\u5206\u6790\u6700\u5927b\u5339\u914d\u548c\u8fb9\u7740\u8272\u95ee\u9898\u3002", "result": "1. \u6700\u5927b\u5339\u914d\u9700\u8981\u03a9(min{log\u2081\u208ab\u0394, log\u0394n})\u548c\u03a9(\u221alog\u2081\u208abn)\u8f6e\uff1b2. \u8fb9\u7740\u8272\u9700\u8981\u03a9(min{log\u0394, log\u0394n})\u548c\u03a9(\u221alogn)\u8f6e\u3002", "conclusion": "\u6210\u529f\u7b80\u5316\u4e86\u8f6e\u6d88\u9664\u81ea\u7ea6\u7b80\u6280\u672f\uff0c\u5e76\u83b7\u5f97\u4e86\u6700\u5927b\u5339\u914d\u548c\u8fb9\u7740\u8272\u7684\u65b0\u4e0b\u754c\u7ed3\u679c\uff0c\u4e3a\u7406\u89e3\u5206\u5e03\u5f0f\u56fe\u7b97\u6cd5\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u66f4\u6613\u6d88\u5316\u7684\u5de5\u5177\u3002"}}
{"id": "2510.19949", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19949", "abs": "https://arxiv.org/abs/2510.19949", "authors": ["Mathieu Andreux", "M\u00e4rt Bakler", "Yanael Barbier", "Hamza Ben Chekroun", "Emilien Bir\u00e9", "Antoine Bonnet", "Riaz Bordie", "Nathan Bout", "Matthias Brunel", "Aleix Cambray", "Pierre-Louis Cedoz", "Antoine Chassang", "Gautier Cloix", "Ethan Connelly", "Alexandra Constantinou", "Ramzi De Coster", "Hubert de la Jonquiere", "Aur\u00e9lien Delfosse", "Maxime Delpit", "Alexis Deprez", "Augustin Derupti", "Mathieu Diaz", "Shannon D'Souza", "Julie Dujardin", "Abai Edmund", "Michael Eickenberg", "Armand Fatalot", "Wissem Felissi", "Isaac Herring", "Xavier Koegler", "Erwan Le Jumeau de Kergaradec", "Aur\u00e9lien Lac", "Maxime Langevin", "Corentin Lauverjat", "Antonio Loison", "Avshalom Manevich", "Axel Moyal", "Axel Nguyen Kerbel", "Marinela Parovic", "Julien Revelle", "Guillaume Richard", "Mats Richter", "Ronan Riochet", "Mar\u00eda Santos", "Romain Savidan", "Laurent Sifre", "Maxime Theillard", "Marc Thibault", "Ivan Valentini", "Tony Wu", "Laura Yie", "Kai Yuan", "Jevgenij Zubovskij"], "title": "Surfer 2: The Next Generation of Cross-Platform Computer Use Agents", "comment": "21 pages, 9 figures, 2 tables", "summary": "Building agents that generalize across web, desktop, and mobile environments\nremains an open challenge, as prior systems rely on environment-specific\ninterfaces that limit cross-platform deployment. We introduce Surfer 2, a\nunified architecture operating purely from visual observations that achieves\nstate-of-the-art performance across all three environments. Surfer 2 integrates\nhierarchical context management, decoupled planning and execution, and\nself-verification with adaptive recovery, enabling reliable operation over long\ntask horizons. Our system achieves 97.1% accuracy on WebVoyager, 69.6% on\nWebArena, 60.1% on OSWorld, and 87.1% on AndroidWorld, outperforming all prior\nsystems without task-specific fine-tuning. With multiple attempts, Surfer 2\nexceeds human performance on all benchmarks. These results demonstrate that\nsystematic orchestration amplifies foundation model capabilities and enables\ngeneral-purpose computer control through visual interaction alone, while\ncalling for a next-generation vision language model to achieve Pareto-optimal\ncost-efficiency.", "AI": {"tldr": "Surfer 2\u662f\u4e00\u4e2a\u57fa\u4e8e\u7eaf\u89c6\u89c9\u89c2\u5bdf\u7684\u7edf\u4e00\u67b6\u6784\uff0c\u5728Web\u3001\u684c\u9762\u548c\u79fb\u52a8\u73af\u5883\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u65e0\u9700\u7279\u5b9a\u4efb\u52a1\u5fae\u8c03\u5373\u53ef\u8d85\u8d8a\u6240\u6709\u5148\u524d\u7cfb\u7edf\u3002", "motivation": "\u6784\u5efa\u80fd\u591f\u8de8Web\u3001\u684c\u9762\u548c\u79fb\u52a8\u73af\u5883\u6cdb\u5316\u7684\u667a\u80fd\u4f53\u4ecd\u7136\u662f\u4e00\u4e2a\u5f00\u653e\u6311\u6218\uff0c\u56e0\u4e3a\u73b0\u6709\u7cfb\u7edf\u4f9d\u8d56\u73af\u5883\u7279\u5b9a\u63a5\u53e3\u9650\u5236\u4e86\u8de8\u5e73\u53f0\u90e8\u7f72\u3002", "method": "Surfer 2\u96c6\u6210\u4e86\u5206\u5c42\u4e0a\u4e0b\u6587\u7ba1\u7406\u3001\u89e3\u8026\u7684\u89c4\u5212\u4e0e\u6267\u884c\u3001\u4ee5\u53ca\u5177\u6709\u81ea\u9002\u5e94\u6062\u590d\u80fd\u529b\u7684\u81ea\u6211\u9a8c\u8bc1\uff0c\u652f\u6301\u957f\u4efb\u52a1\u5e8f\u5217\u7684\u53ef\u9760\u64cd\u4f5c\u3002", "result": "\u5728WebVoyager\u4e0a\u8fbe\u523097.1%\u51c6\u786e\u7387\uff0cWebArena 69.6%\uff0cOSWorld 60.1%\uff0cAndroidWorld 87.1%\uff0c\u591a\u5c1d\u8bd5\u60c5\u51b5\u4e0b\u5728\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4eba\u7c7b\u8868\u73b0\u3002", "conclusion": "\u7cfb\u7edf\u5316\u7f16\u6392\u653e\u5927\u4e86\u57fa\u7840\u6a21\u578b\u80fd\u529b\uff0c\u4ec5\u901a\u8fc7\u89c6\u89c9\u4ea4\u4e92\u5373\u53ef\u5b9e\u73b0\u901a\u7528\u8ba1\u7b97\u673a\u63a7\u5236\uff0c\u540c\u65f6\u9700\u8981\u4e0b\u4e00\u4ee3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6765\u5b9e\u73b0\u5e15\u7d2f\u6258\u6700\u4f18\u7684\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2510.20269", "categories": ["cs.AR", "cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.20269", "abs": "https://arxiv.org/abs/2510.20269", "authors": ["Ismail Emir Yuksel", "Ataberk Olgun", "F. Nisa Bostanci", "Oguzhan Canpolat", "Geraldo F. Oliveira", "Mohammad Sadrosadati", "Abdullah Giray Yaglikci", "Onur Mutlu"], "title": "In-DRAM True Random Number Generation Using Simultaneous Multiple-Row Activation: An Experimental Study of Real DRAM Chips", "comment": "Extended version of our publication at the 43rd IEEE International\n  Conference on Computer Design (ICCD-43), 2025", "summary": "In this work, we experimentally demonstrate that it is possible to generate\ntrue random numbers at high throughput and low latency in commercial\noff-the-shelf (COTS) DRAM chips by leveraging simultaneous multiple-row\nactivation (SiMRA) via an extensive characterization of 96 DDR4 DRAM chips. We\nrigorously analyze SiMRA's true random generation potential in terms of\nentropy, latency, and throughput for varying numbers of simultaneously\nactivated DRAM rows (i.e., 2, 4, 8, 16, and 32), data patterns, temperature\nlevels, and spatial variations. Among our 11 key experimental observations, we\nhighlight four key results. First, we evaluate the quality of our TRNG designs\nusing the commonly-used NIST statistical test suite for randomness and find\nthat all SiMRA-based TRNG designs successfully pass each test. Second, 2-, 8-,\n16-, and 32-row activation-based TRNG designs outperform the state-of-theart\nDRAM-based TRNG in throughput by up to 1.15x, 1.99x, 1.82x, and 1.39x,\nrespectively. Third, SiMRA's entropy tends to increase with the number of\nsimultaneously activated DRAM rows. Fourth, operational parameters and\nconditions (e.g., data pattern and temperature) significantly affect entropy.\nFor example, for most of the tested modules, the average entropy of 32-row\nactivation is 2.51x higher than that of 2-row activation. For example,\nincreasing the temperature from 50{\\deg}C to 90{\\deg}C decreases SiMRA's\nentropy by 1.53x for 32-row activation. To aid future research and development,\nwe open-source our infrastructure at https://github.com/CMU-SAFARI/SiMRA-TRNG.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u5546\u7528DRAM\u82af\u7247\u4e2d\u5229\u7528\u540c\u65f6\u591a\u884c\u6fc0\u6d3b(SiMRA)\u6280\u672f\u53ef\u4ee5\u751f\u6210\u9ad8\u8d28\u91cf\u771f\u968f\u673a\u6570\uff0c\u5177\u6709\u9ad8\u541e\u5410\u91cf\u548c\u4f4e\u5ef6\u8fdf\u7279\u6027\u3002", "motivation": "\u63a2\u7d22\u5728\u5546\u7528DRAM\u82af\u7247\u4e2d\u5b9e\u73b0\u9ad8\u6548\u771f\u968f\u673a\u6570\u751f\u6210\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u514b\u670d\u73b0\u6709DRAM-based TRNG\u5728\u6027\u80fd\u548c\u6548\u7387\u65b9\u9762\u7684\u9650\u5236\u3002", "method": "\u5bf996\u4e2aDDR4 DRAM\u82af\u7247\u8fdb\u884c\u5e7f\u6cdb\u8868\u5f81\uff0c\u7814\u7a76\u4e0d\u540c\u6570\u91cf\u7684\u540c\u65f6\u6fc0\u6d3b\u884c(2,4,8,16,32)\u3001\u6570\u636e\u6a21\u5f0f\u3001\u6e29\u5ea6\u6c34\u5e73\u548c\u7a7a\u95f4\u53d8\u5316\u5bf9SiMRA\u771f\u968f\u673a\u751f\u6210\u6f5c\u529b\u7684\u5f71\u54cd\u3002", "result": "\u6240\u6709SiMRA-based TRNG\u8bbe\u8ba1\u90fd\u6210\u529f\u901a\u8fc7NIST\u968f\u673a\u6027\u6d4b\u8bd5\uff1b2\u30018\u300116\u300132\u884c\u6fc0\u6d3b\u8bbe\u8ba1\u7684\u541e\u5410\u91cf\u5206\u522b\u6bd4\u6700\u5148\u8fdbDRAM-based TRNG\u63d0\u9ad81.15x\u30011.99x\u30011.82x\u548c1.39x\uff1b\u71b5\u503c\u968f\u6fc0\u6d3b\u884c\u6570\u589e\u52a0\u800c\u589e\u52a0\uff1b\u64cd\u4f5c\u53c2\u6570\u663e\u8457\u5f71\u54cd\u71b5\u503c\u3002", "conclusion": "SiMRA\u6280\u672f\u4e3a\u5728\u5546\u7528DRAM\u82af\u7247\u4e2d\u5b9e\u73b0\u9ad8\u6548\u771f\u968f\u673a\u6570\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5f00\u6e90\u4e86\u7814\u7a76\u57fa\u7840\u8bbe\u65bd\u4ee5\u652f\u6301\u672a\u6765\u53d1\u5c55\u3002"}}
{"id": "2510.19851", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19851", "abs": "https://arxiv.org/abs/2510.19851", "authors": ["Artur Zolkowski", "Wen Xing", "David Lindner", "Florian Tram\u00e8r", "Erik Jenner"], "title": "Can Reasoning Models Obfuscate Reasoning? Stress-Testing Chain-of-Thought Monitorability", "comment": null, "summary": "Recent findings suggest that misaligned models may exhibit deceptive\nbehavior, raising concerns about output trustworthiness. Chain-of-thought (CoT)\nis a promising tool for alignment monitoring: when models articulate their\nreasoning faithfully, monitors can detect and mitigate harmful behaviors before\nundesirable outcomes occur. However, a key uncertainty is: Can models obfuscate\ntheir CoT in order to pursue hidden adversarial objectives while evading\ndetection? To answer this question and thus stress-test CoT monitorability, we\ndevelop a composable and quantifiable taxonomy of prompts to elicit CoT\nobfuscation. We evaluate both internal CoT (reasoning traces) and external CoT\n(prompted reasoning in outputs) using toy tasks and more realistic environments\nin SHADE-Arena. We show that: (i) CoT monitoring performs accurately and\nefficiently without obfuscation pressure. (ii) Under strong obfuscation\npressure, some models successfully complete adversarial tasks while evading\ndetection. (iii) Models do not obfuscate their internal CoT as much as their\nexternal CoT (under prompt pressure). These results suggest that while CoT\nprovides valuable oversight in benign settings, robust deployment requires\nmodel-specific stress-testing of monitorability.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u601d\u7ef4\u94fe(CoT)\u5728\u65e0\u6df7\u6dc6\u538b\u529b\u4e0b\u80fd\u6709\u6548\u76d1\u63a7\u6a21\u578b\u884c\u4e3a\uff0c\u4f46\u5728\u5f3a\u6df7\u6dc6\u538b\u529b\u4e0b\uff0c\u67d0\u4e9b\u6a21\u578b\u80fd\u6210\u529f\u5b8c\u6210\u5bf9\u6297\u4efb\u52a1\u5e76\u9003\u907f\u68c0\u6d4b\u3002\u6a21\u578b\u5bf9\u5185\u90e8CoT\u7684\u6df7\u6dc6\u7a0b\u5ea6\u4f4e\u4e8e\u5916\u90e8CoT\u3002", "motivation": "\u7531\u4e8e\u53d1\u73b0\u672a\u5bf9\u9f50\u6a21\u578b\u53ef\u80fd\u8868\u73b0\u51fa\u6b3a\u9a97\u884c\u4e3a\uff0c\u9700\u8981\u6d4b\u8bd5\u601d\u7ef4\u94fe(CoT)\u4f5c\u4e3a\u5bf9\u9f50\u76d1\u63a7\u5de5\u5177\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u9a8c\u8bc1\u6a21\u578b\u662f\u5426\u80fd\u591f\u901a\u8fc7\u6df7\u6dc6CoT\u6765\u9003\u907f\u68c0\u6d4b\u3002", "method": "\u5f00\u53d1\u4e86\u53ef\u7ec4\u5408\u548c\u53ef\u91cf\u5316\u7684\u63d0\u793a\u5206\u7c7b\u6cd5\u6765\u5f15\u53d1CoT\u6df7\u6dc6\uff0c\u5728\u73a9\u5177\u4efb\u52a1\u548cSHADE-Arena\u73b0\u5b9e\u73af\u5883\u4e2d\u8bc4\u4f30\u5185\u90e8CoT(\u63a8\u7406\u75d5\u8ff9)\u548c\u5916\u90e8CoT(\u8f93\u51fa\u4e2d\u7684\u63d0\u793a\u63a8\u7406)\u3002", "result": "(i) \u65e0\u6df7\u6dc6\u538b\u529b\u4e0bCoT\u76d1\u63a7\u51c6\u786e\u9ad8\u6548\uff1b(ii) \u5f3a\u6df7\u6dc6\u538b\u529b\u4e0b\u67d0\u4e9b\u6a21\u578b\u80fd\u5b8c\u6210\u5bf9\u6297\u4efb\u52a1\u5e76\u9003\u907f\u68c0\u6d4b\uff1b(iii) \u6a21\u578b\u5bf9\u5185\u90e8CoT\u7684\u6df7\u6dc6\u7a0b\u5ea6\u4f4e\u4e8e\u5916\u90e8CoT\u3002", "conclusion": "\u867d\u7136CoT\u5728\u826f\u6027\u8bbe\u7f6e\u4e0b\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u76d1\u7763\uff0c\u4f46\u9c81\u68d2\u90e8\u7f72\u9700\u8981\u5bf9\u6a21\u578b\u7684\u53ef\u76d1\u63a7\u6027\u8fdb\u884c\u7279\u5b9a\u538b\u529b\u6d4b\u8bd5\u3002"}}
{"id": "2510.20111", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20111", "abs": "https://arxiv.org/abs/2510.20111", "authors": ["Huawei Bai", "Yifan Huang", "Wenqi Shi", "Ansheng You", "Feifan Shao", "Tengfei Han", "Minghui Yu"], "title": "AsyncHZP: Hierarchical ZeRO Parallelism with Asynchronous Scheduling for Scalable LLM Training", "comment": "14 pages, 5 figures, tech report", "summary": "The training efficiency and scalability of language models on massive\nclusters currently remain a critical bottleneck. Mainstream approaches like ND\nparallelism are often cumbersome and complex, while flexible alternatives such\nas the Zero Redundancy Optimizer (ZeRO) are frequently hampered by\ncommunication overhead. In this paper, we propose Asynchronous Hierarchical\nZero Parallelism (AsyncHZP), a novel asynchronous variant of ZeRO designed to\nachieve superior performance while maintaining simplicity and memory\nefficiency. Unlike traditional ZeRO, which employs over-fine-grained sharding\nthat can lead to inefficient communication, AsyncHZP adaptively reshards\nparameters, gradients, and optimizer states across different replica groups.\nThis strategy optimizes device memory utilization and significantly reduces\ncommunication overhead. In addition, we also design a multi-stream asynchronous\nscheduling method that executes parameter all-gather and gradient\nreduce-scatter operations in dedicated background threads, effectively\noverlapping communication with computation while incurring negligible memory\nfragmentation. Empirical evaluations on both Dense and Mixture-of-Experts (MoE)\nmodels confirm that AsyncHZP maintains robust stability at scale. It\nconsistently outperforms classic ND parallelism, achieving state-of-the-art\nperformance without complex strategic tuning, thereby simplifying the path to\nefficient large-scale training.", "AI": {"tldr": "\u63d0\u51faAsyncHZP\uff0c\u4e00\u79cd\u5f02\u6b65\u5206\u5c42\u96f6\u5e76\u884c\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u53c2\u6570\u5206\u7247\u548c\u591a\u6d41\u5f02\u6b65\u8c03\u5ea6\uff0c\u5728\u4fdd\u6301\u5185\u5b58\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\uff0c\u5728\u5927\u89c4\u6a21\u8bad\u7ec3\u4e2d\u5b9e\u73b0\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5927\u89c4\u6a21\u96c6\u7fa4\u4e0a\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u5b58\u5728\u74f6\u9888\uff0c\u4e3b\u6d41ND\u5e76\u884c\u65b9\u6cd5\u590d\u6742\u7e41\u7410\uff0c\u800c\u7075\u6d3b\u66ff\u4ee3\u65b9\u6848\u5982ZeRO\u5219\u53d7\u901a\u4fe1\u5f00\u9500\u9650\u5236\u3002", "method": "\u8bbe\u8ba1\u5f02\u6b65\u5206\u5c42\u96f6\u5e76\u884c(AsyncHZP)\uff0c\u81ea\u9002\u5e94\u5730\u5728\u4e0d\u540c\u526f\u672c\u7ec4\u95f4\u91cd\u65b0\u5206\u7247\u53c2\u6570\u3001\u68af\u5ea6\u548c\u4f18\u5316\u5668\u72b6\u6001\uff0c\u5e76\u91c7\u7528\u591a\u6d41\u5f02\u6b65\u8c03\u5ea6\u65b9\u6cd5\u5728\u4e13\u7528\u540e\u53f0\u7ebf\u7a0b\u4e2d\u6267\u884c\u53c2\u6570\u5168\u6536\u96c6\u548c\u68af\u5ea6\u89c4\u7ea6\u5206\u6563\u64cd\u4f5c\u3002", "result": "\u5728\u5bc6\u96c6\u6a21\u578b\u548cMoE\u6a21\u578b\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cAsyncHZP\u5728\u5927\u89c4\u6a21\u4e0b\u4fdd\u6301\u7a33\u5065\u7a33\u5b9a\u6027\uff0c\u6301\u7eed\u4f18\u4e8e\u7ecf\u5178ND\u5e76\u884c\uff0c\u65e0\u9700\u590d\u6742\u7b56\u7565\u8c03\u4f18\u5373\u53ef\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "AsyncHZP\u7b80\u5316\u4e86\u9ad8\u6548\u5927\u89c4\u6a21\u8bad\u7ec3\u7684\u8def\u5f84\uff0c\u5728\u4fdd\u6301\u5185\u5b58\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\uff0c\u5b9e\u73b0\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.20400", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.20400", "abs": "https://arxiv.org/abs/2510.20400", "authors": ["Rub\u00e9n Langarita", "Jes\u00fas Alastruey-Bened\u00e9", "Pablo Ib\u00e1\u00f1ez-Mar\u00edn", "Santiago Marco-Sola", "Miquel Moret\u00f3", "Adri\u00e0 Armejach"], "title": "Squire: A General-Purpose Accelerator to Exploit Fine-Grain Parallelism on Dependency-Bound Kernels", "comment": "11 pages, 10 figures, 5 tables, 4 algorithms, accepted on PACT25", "summary": "Multiple HPC applications are often bottlenecked by compute-intensive kernels\nimplementing complex dependency patterns (data-dependency bound). Traditional\ngeneral-purpose accelerators struggle to effectively exploit fine-grain\nparallelism due to limitations in implementing convoluted data-dependency\npatterns (like SIMD) and overheads due to synchronization and data transfers\n(like GPGPUs). In contrast, custom FPGA and ASIC designs offer improved\nperformance and energy efficiency at a high cost in hardware design and\nprogramming complexity and often lack the flexibility to process different\nworkloads. We propose Squire, a general-purpose accelerator designed to exploit\nfine-grain parallelism effectively on dependency-bound kernels. Each Squire\naccelerator has a set of general-purpose low-power in-order cores that can\nrapidly communicate among themselves and directly access data from the L2\ncache. Our proposal integrates one Squire accelerator per core in a typical\nmulticore system, allowing the acceleration of dependency-bound kernels within\nparallel tasks with minimal software changes. As a case study, we evaluate\nSquire's effectiveness by accelerating five kernels that implement complex\ndependency patterns. We use three of these kernels to build an end-to-end\nread-mapping tool that will be used to evaluate Squire. Squire obtains speedups\nup to 7.64$\\times$ in dynamic programming kernels. Overall, Squire provides an\nacceleration for an end-to-end application of 3.66$\\times$. In addition, Squire\nreduces energy consumption by up to 56% with a minimal area overhead of 10.5%\ncompared to a Neoverse-N1 baseline.", "AI": {"tldr": "Squire\u662f\u4e00\u79cd\u901a\u7528\u52a0\u901f\u5668\uff0c\u65e8\u5728\u6709\u6548\u5229\u7528\u4f9d\u8d56\u5bc6\u96c6\u578b\u5185\u6838\u4e2d\u7684\u7ec6\u7c92\u5ea6\u5e76\u884c\u6027\u3002\u5b83\u901a\u8fc7\u5728\u5178\u578b\u591a\u6838\u7cfb\u7edf\u4e2d\u4e3a\u6bcf\u4e2a\u6838\u5fc3\u96c6\u6210\u4e00\u4e2aSquire\u52a0\u901f\u5668\uff0c\u5b9e\u73b0\u4e86\u5bf9\u52a8\u6001\u7f16\u7a0b\u5185\u6838\u6700\u9ad87.64\u500d\u7684\u52a0\u901f\uff0c\u7aef\u5230\u7aef\u5e94\u75283.66\u500d\u52a0\u901f\uff0c\u80fd\u8017\u964d\u4f4e56%\uff0c\u9762\u79ef\u5f00\u9500\u4ec5\u4e3a10.5%\u3002", "motivation": "\u4f20\u7edf\u901a\u7528\u52a0\u901f\u5668\uff08\u5982SIMD\u548cGPGPU\uff09\u5728\u5b9e\u73b0\u590d\u6742\u6570\u636e\u4f9d\u8d56\u6a21\u5f0f\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u800c\u5b9a\u5236FPGA\u548cASIC\u8bbe\u8ba1\u867d\u7136\u6027\u80fd\u597d\u4f46\u6210\u672c\u9ad8\u4e14\u7f3a\u4e4f\u7075\u6d3b\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u6709\u6548\u5229\u7528\u7ec6\u7c92\u5ea6\u5e76\u884c\u6027\u7684\u901a\u7528\u52a0\u901f\u5668\u6765\u89e3\u51b3\u4f9d\u8d56\u5bc6\u96c6\u578b\u5185\u6838\u7684\u6027\u80fd\u74f6\u9888\u3002", "method": "Squire\u52a0\u901f\u5668\u5305\u542b\u4e00\u7ec4\u901a\u7528\u4f4e\u529f\u8017\u987a\u5e8f\u6838\u5fc3\uff0c\u8fd9\u4e9b\u6838\u5fc3\u53ef\u4ee5\u5feb\u901f\u76f8\u4e92\u901a\u4fe1\u5e76\u76f4\u63a5\u4eceL2\u7f13\u5b58\u8bbf\u95ee\u6570\u636e\u3002\u7cfb\u7edf\u4e3a\u6bcf\u4e2a\u6838\u5fc3\u96c6\u6210\u4e00\u4e2aSquire\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u8f6f\u4ef6\u66f4\u6539\u6765\u52a0\u901f\u5e76\u884c\u4efb\u52a1\u4e2d\u7684\u4f9d\u8d56\u5bc6\u96c6\u578b\u5185\u6838\u3002", "result": "\u5728\u5b9e\u73b0\u590d\u6742\u4f9d\u8d56\u6a21\u5f0f\u7684\u4e94\u4e2a\u5185\u6838\u4e2d\uff0cSquire\u5728\u52a8\u6001\u7f16\u7a0b\u5185\u6838\u4e2d\u83b7\u5f97\u4e86\u6700\u9ad87.64\u500d\u7684\u52a0\u901f\u3002\u4f7f\u7528\u5176\u4e2d\u4e09\u4e2a\u5185\u6838\u6784\u5efa\u7684\u7aef\u5230\u7aef\u8bfb\u53d6\u6620\u5c04\u5de5\u5177\u5b9e\u73b0\u4e863.66\u500d\u7684\u6574\u4f53\u52a0\u901f\uff0c\u80fd\u8017\u964d\u4f4e\u9ad8\u8fbe56%\uff0c\u4e0eNeoverse-N1\u57fa\u7ebf\u76f8\u6bd4\u9762\u79ef\u5f00\u9500\u4ec5\u4e3a10.5%\u3002", "conclusion": "Squire\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u52a0\u901f\u4f9d\u8d56\u5bc6\u96c6\u578b\u5185\u6838\uff0c\u5728\u4fdd\u6301\u901a\u7528\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u548c\u80fd\u6548\u6539\u8fdb\uff0c\u4e14\u786c\u4ef6\u5f00\u9500\u6700\u5c0f\u3002"}}
{"id": "2510.19856", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19856", "abs": "https://arxiv.org/abs/2510.19856", "authors": ["Eranga Bandara", "Sachin Shetty", "Ravi Mukkamala", "Ross Gore", "Peter Foytik", "Safdar H. Bouk", "Abdul Rahman", "Xueping Liang", "Ng Wee Keong", "Kasun De Zoysa", "Aruna Withanage", "Nilaan Loganathan"], "title": "Model Context Contracts - MCP-Enabled Framework to Integrate LLMs With Blockchain Smart Contracts", "comment": null, "summary": "In recent years, blockchain has experienced widespread adoption across\nvarious industries, becoming integral to numerous enterprise applications.\nConcurrently, the rise of generative AI and LLMs has transformed human-computer\ninteractions, offering advanced capabilities in understanding and generating\nhuman-like text. The introduction of the MCP has further enhanced AI\nintegration by standardizing communication between AI systems and external data\nsources. Despite these advancements, there is still no standardized method for\nseamlessly integrating LLM applications and blockchain. To address this\nconcern, we propose \"MCC: Model Context Contracts\" a novel framework that\nenables LLMs to interact directly with blockchain smart contracts through\nMCP-like protocol. This integration allows AI agents to invoke blockchain smart\ncontracts, facilitating more dynamic and context-aware interactions between\nusers and blockchain networks. Essentially, it empowers users to interact with\nblockchain systems and perform transactions using queries in natural language.\nWithin this proposed architecture, blockchain smart contracts can function as\nintelligent agents capable of recognizing user input in natural language and\nexecuting the corresponding transactions. To ensure that the LLM accurately\ninterprets natural language inputs and maps them to the appropriate MCP\nfunctions, the LLM was fine-tuned using a custom dataset comprising user inputs\npaired with their corresponding MCP server functions. This fine-tuning process\nsignificantly improved the platform's performance and accuracy. To validate the\neffectiveness of MCC, we have developed an end-to-end prototype implemented on\nthe Rahasak blockchain with the fine-tuned Llama-4 LLM. To the best of our\nknowledge, this research represents the first approach to using the concept of\nModel Context Protocol to integrate LLMs with blockchain.", "AI": {"tldr": "\u63d0\u51faMCC\u6846\u67b6\uff0c\u901a\u8fc7\u7c7b\u4f3cMCP\u7684\u534f\u8bae\u8ba9LLM\u76f4\u63a5\u4e0e\u533a\u5757\u94fe\u667a\u80fd\u5408\u7ea6\u4ea4\u4e92\uff0c\u4f7f\u7528\u6237\u80fd\u7528\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e0e\u533a\u5757\u94fe\u7cfb\u7edf\u4ea4\u4e92\u548c\u6267\u884c\u4ea4\u6613\u3002", "motivation": "\u533a\u5757\u94fe\u548c\u751f\u6210\u5f0fAI/LLM\u6280\u672f\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u7f3a\u4e4f\u6807\u51c6\u5316\u65b9\u6cd5\u5c06LLM\u5e94\u7528\u4e0e\u533a\u5757\u94fe\u65e0\u7f1d\u96c6\u6210\u3002", "method": "\u5f00\u53d1MCC\u6846\u67b6\uff0c\u901a\u8fc7\u7c7b\u4f3cMCP\u7684\u534f\u8bae\u8fde\u63a5LLM\u548c\u533a\u5757\u94fe\u667a\u80fd\u5408\u7ea6\uff0c\u4f7f\u7528\u5b9a\u5236\u6570\u636e\u96c6\u5bf9LLM\u8fdb\u884c\u5fae\u8c03\u4ee5\u51c6\u786e\u89e3\u91ca\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u5e76\u6620\u5c04\u5230\u76f8\u5e94MCP\u529f\u80fd\u3002", "result": "\u5728Rahasak\u533a\u5757\u94fe\u4e0a\u5f00\u53d1\u4e86\u7aef\u5230\u7aef\u539f\u578b\uff0c\u4f7f\u7528\u5fae\u8c03\u540e\u7684Llama-4 LLM\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5e73\u53f0\u7684\u6027\u80fd\u548c\u51c6\u786e\u6027\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u4f7f\u7528\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u6982\u5ff5\u5c06LLM\u4e0e\u533a\u5757\u94fe\u96c6\u6210\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u7528\u6237\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4e0e\u533a\u5757\u94fe\u7cfb\u7edf\u4ea4\u4e92\u7684\u80fd\u529b\u3002"}}
{"id": "2510.20128", "categories": ["cs.DC", "quant-ph", "D.2.6"], "pdf": "https://arxiv.org/pdf/2510.20128", "abs": "https://arxiv.org/abs/2510.20128", "authors": ["Xin Zhan", "K. Grace Johnson", "Aniello Esposito", "Barbara Chapman", "Marco Fiorentino", "Kirk M. Bresniker", "Raymond G. Beausoleil", "Masoud Mohseni"], "title": "A Full Stack Framework for High Performance Quantum-Classical Computing", "comment": "9 pages, 8 figures, presented at Cray User Group Meeting 2025, May\n  04-09, 2025, New York, NY", "summary": "To address the growing needs for scalable High Performance Computing (HPC)\nand Quantum Computing (QC) integration, we present our HPC-QC full stack\nframework and its hybrid workload development capability with modular\nhardware/device-agnostic software integration approach. The latest development\nin extensible interfaces for quantum programming, dispatching, and compilation\nwithin existing mature HPC programming environment are demonstrated. Our HPC-QC\nfull stack enables high-level, portable invocation of quantum kernels from\ncommercial quantum SDKs within HPC meta-program in compiled languages (C/C++\nand Fortran) as well as Python through a quantum programming interface library\nextension. An adaptive circuit knitting hypervisor is being developed to\npartition large quantum circuits into sub-circuits that fit on smaller noisy\nquantum devices and classical simulators. At the lower-level, we leverage Cray\nLLVM-based compilation framework to transform and consume LLVM IR and Quantum\nIR (QIR) from commercial quantum software frontends in a retargetable fashion\nto different hardware architectures. Several hybrid HPC-QC multi-node multi-CPU\nand GPU workloads (including solving linear system of equations, quantum\noptimization, and simulating quantum phase transitions) have been demonstrated\non HPE EX supercomputers to illustrate functionality and execution viability\nfor all three components developed so far. This work provides the framework for\na unified quantum-classical programming environment built upon classical HPC\nsoftware stack (compilers, libraries, parallel runtime and process scheduling).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2aHPC-QC\u5168\u6808\u6846\u67b6\uff0c\u7528\u4e8e\u96c6\u6210\u9ad8\u6027\u80fd\u8ba1\u7b97\u548c\u91cf\u5b50\u8ba1\u7b97\uff0c\u652f\u6301\u6df7\u5408\u5de5\u4f5c\u8d1f\u8f7d\u5f00\u53d1\uff0c\u91c7\u7528\u6a21\u5757\u5316\u786c\u4ef6/\u8bbe\u5907\u65e0\u5173\u7684\u8f6f\u4ef6\u96c6\u6210\u65b9\u6cd5\u3002", "motivation": "\u6ee1\u8db3\u5bf9\u53ef\u6269\u5c55\u9ad8\u6027\u80fd\u8ba1\u7b97\u548c\u91cf\u5b50\u8ba1\u7b97\u96c6\u6210\u65e5\u76ca\u589e\u957f\u7684\u9700\u6c42\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u91cf\u5b50-\u7ecf\u5178\u7f16\u7a0b\u73af\u5883\u3002", "method": "\u5f00\u53d1\u4e86\u53ef\u6269\u5c55\u7684\u91cf\u5b50\u7f16\u7a0b\u3001\u8c03\u5ea6\u548c\u7f16\u8bd1\u63a5\u53e3\uff0c\u5728\u6210\u719f\u7684HPC\u7f16\u7a0b\u73af\u5883\u4e2d\u5b9e\u73b0\uff1b\u91c7\u7528\u81ea\u9002\u5e94\u7535\u8def\u7f16\u7ec7\u865a\u62df\u673a\u5c06\u5927\u91cf\u5b50\u7535\u8def\u5206\u533a\uff1b\u5229\u7528Cray LLVM\u7f16\u8bd1\u6846\u67b6\u8f6c\u6362LLVM IR\u548c\u91cf\u5b50IR\uff1b\u5728HPE EX\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u6f14\u793a\u6df7\u5408\u5de5\u4f5c\u8d1f\u8f7d\u3002", "result": "\u6210\u529f\u6f14\u793a\u4e86\u591a\u4e2a\u6df7\u5408HPC-QC\u591a\u8282\u70b9\u591aCPU\u548cGPU\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5305\u62ec\u6c42\u89e3\u7ebf\u6027\u65b9\u7a0b\u7ec4\u3001\u91cf\u5b50\u4f18\u5316\u548c\u6a21\u62df\u91cf\u5b50\u76f8\u53d8\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u57fa\u4e8e\u7ecf\u5178HPC\u8f6f\u4ef6\u6808\u7684\u7edf\u4e00\u91cf\u5b50-\u7ecf\u5178\u7f16\u7a0b\u73af\u5883\u63d0\u4f9b\u4e86\u6846\u67b6\u3002"}}
{"id": "2510.19957", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19957", "abs": "https://arxiv.org/abs/2510.19957", "authors": ["Amir Hever", "Itai Orr"], "title": "A new wave of vehicle insurance fraud fueled by generative AI", "comment": null, "summary": "Generative AI is supercharging insurance fraud by making it easier to falsify\naccident evidence at scale and in rapid time. Insurance fraud is a pervasive\nand costly problem, amounting to tens of billions of dollars in losses each\nyear. In the vehicle insurance sector, fraud schemes have traditionally\ninvolved staged accidents, exaggerated damage, or forged documents. The rise of\ngenerative AI, including deepfake image and video generation, has introduced\nnew methods for committing fraud at scale. Fraudsters can now fabricate highly\nrealistic crash photos, damage evidence, and even fake identities or documents\nwith minimal effort, exploiting AI tools to bolster false insurance claims.\nInsurers have begun deploying countermeasures such as AI-based deepfake\ndetection software and enhanced verification processes to detect and mitigate\nthese AI-driven scams. However, current mitigation strategies face significant\nlimitations. Detection tools can suffer from false positives and negatives, and\nsophisticated fraudsters continuously adapt their tactics to evade automated\nchecks. This cat-and-mouse arms race between generative AI and detection\ntechnology, combined with resource and cost barriers for insurers, means that\ncombating AI-enabled insurance fraud remains an ongoing challenge. In this\nwhite paper, we present UVeye layered solution for vehicle fraud, representing\na major leap forward in the ability to detect, mitigate and deter this new wave\nof fraud.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u6b63\u5728\u52a0\u5267\u4fdd\u9669\u6b3a\u8bc8\u95ee\u9898\uff0c\u6b3a\u8bc8\u8005\u5229\u7528AI\u5de5\u5177\u5927\u89c4\u6a21\u4f2a\u9020\u4e8b\u6545\u8bc1\u636e\u3001\u635f\u574f\u8bc1\u660e\u548c\u865a\u5047\u8eab\u4efd\u6587\u4ef6\uff0c\u800c\u4fdd\u9669\u516c\u53f8\u5219\u90e8\u7f72AI\u68c0\u6d4b\u8f6f\u4ef6\u8fdb\u884c\u5bf9\u6297\uff0c\u5f62\u6210\u4e00\u573a\u6301\u7eed\u7684\u6280\u672f\u519b\u5907\u7ade\u8d5b\u3002", "motivation": "\u4fdd\u9669\u6b3a\u8bc8\u6bcf\u5e74\u9020\u6210\u6570\u767e\u4ebf\u7f8e\u5143\u635f\u5931\uff0c\u4f20\u7edf\u6b3a\u8bc8\u624b\u6bb5\u5305\u62ec\u4f2a\u9020\u4e8b\u6545\u3001\u5938\u5927\u635f\u5931\u7b49\u3002\u751f\u6210\u5f0fAI\u7684\u51fa\u73b0\u4f7f\u5f97\u6b3a\u8bc8\u8005\u80fd\u591f\u4ee5\u66f4\u4f4e\u7684\u6210\u672c\u548c\u66f4\u9ad8\u7684\u6548\u7387\u5927\u89c4\u6a21\u5236\u9020\u903c\u771f\u7684\u865a\u5047\u8bc1\u636e\uff0c\u8fd9\u7ed9\u4fdd\u9669\u884c\u4e1a\u5e26\u6765\u4e86\u65b0\u7684\u4e25\u5cfb\u6311\u6218\u3002", "method": "\u4fdd\u9669\u516c\u53f8\u5f00\u59cb\u91c7\u7528\u57fa\u4e8eAI\u7684\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u8f6f\u4ef6\u548c\u589e\u5f3a\u9a8c\u8bc1\u6d41\u7a0b\u6765\u68c0\u6d4b\u548c\u7f13\u89e3\u8fd9\u4e9bAI\u9a71\u52a8\u7684\u6b3a\u8bc8\u884c\u4e3a\u3002\u540c\u65f6\uff0cUVeye\u63d0\u51fa\u4e86\u5206\u5c42\u89e3\u51b3\u65b9\u6848\u6765\u5e94\u5bf9\u8f66\u8f86\u6b3a\u8bc8\u95ee\u9898\u3002", "result": "\u5f53\u524d\u7684\u7f13\u89e3\u7b56\u7565\u9762\u4e34\u663e\u8457\u5c40\u9650\u6027\uff0c\u68c0\u6d4b\u5de5\u5177\u5b58\u5728\u8bef\u62a5\u548c\u6f0f\u62a5\u95ee\u9898\uff0c\u800c\u590d\u6742\u7684\u6b3a\u8bc8\u8005\u4e0d\u65ad\u8c03\u6574\u7b56\u7565\u4ee5\u89c4\u907f\u81ea\u52a8\u68c0\u67e5\u3002\u4fdd\u9669\u516c\u53f8\u5728\u8d44\u6e90\u548c\u6210\u672c\u65b9\u9762\u4e5f\u9762\u4e34\u969c\u788d\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u4e0e\u68c0\u6d4b\u6280\u672f\u4e4b\u95f4\u7684\u732b\u9f20\u6e38\u620f\uff0c\u52a0\u4e0a\u4fdd\u9669\u516c\u53f8\u7684\u8d44\u6e90\u548c\u6210\u672c\u969c\u788d\uff0c\u610f\u5473\u7740\u5bf9\u6297AI\u9a71\u52a8\u7684\u4fdd\u9669\u6b3a\u8bc8\u4ecd\u7136\u662f\u4e00\u4e2a\u6301\u7eed\u7684\u6311\u6218\uff0c\u9700\u8981\u66f4\u5148\u8fdb\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20171", "categories": ["cs.DC", "cs.AI", "cs.NI", "C.2.4; I.2"], "pdf": "https://arxiv.org/pdf/2510.20171", "abs": "https://arxiv.org/abs/2510.20171", "authors": ["Min Si", "Pavan Balaji", "Yongzhou Chen", "Ching-Hsiang Chu", "Adi Gangidi", "Saif Hasan", "Subodh Iyengar", "Dan Johnson", "Bingzhe Liu", "Jingliang Ren", "Ashmitha Jeevaraj Shetty", "Greg Steinbrecher", "Xinfeng Xie", "Yulun Wang", "Bruce Wu", "Jingyi Yang", "Mingran Yang", "Minlan Yu", "Cen Zhao", "Wes Bland", "Denis Boyda", "Suman Gumudavelli", "Cristian Lumezanu", "Rui Miao", "Zhe Qu", "Venkat Ramesh", "Maxim Samoylov", "Jan Seidel", "Feng Tian", "Qiye Tan", "Shuqiang Zhang", "Yimeng Zhao", "Shengbao Zheng", "Art Zhu", "Hongyi Zeng"], "title": "Collective Communication for 100k+ GPUs", "comment": null, "summary": "The increasing scale of large language models (LLMs) necessitates highly\nefficient collective communication frameworks, particularly as training\nworkloads extend to hundreds of thousands of GPUs. Traditional communication\nmethods face significant throughput and latency limitations at this scale,\nhindering both the development and deployment of state-of-the-art models. This\npaper presents the NCCLX collective communication framework, developed at Meta,\nengineered to optimize performance across the full LLM lifecycle, from the\nsynchronous demands of large-scale training to the low-latency requirements of\ninference. The framework is designed to support complex workloads on clusters\nexceeding 100,000 GPUs, ensuring reliable, high-throughput, and low-latency\ndata exchange. Empirical evaluation on the Llama4 model demonstrates\nsubstantial improvements in communication efficiency. This research contributes\na robust solution for enabling the next generation of LLMs to operate at\nunprecedented scales.", "AI": {"tldr": "NCCLX\u662f\u4e00\u4e2a\u4e13\u4e3a\u8d85\u5927\u89c4\u6a21LLM\u8bad\u7ec3\u548c\u63a8\u7406\u4f18\u5316\u7684\u96c6\u4f53\u901a\u4fe1\u6846\u67b6\uff0c\u652f\u6301\u8d85\u8fc710\u4e07GPU\u96c6\u7fa4\uff0c\u663e\u8457\u63d0\u5347\u901a\u4fe1\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u901a\u4fe1\u65b9\u6cd5\u5728\u6570\u5341\u4e07GPU\u89c4\u6a21\u4e0b\u9762\u4e34\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\u9650\u5236\uff0c\u963b\u788d\u4e86\u6700\u5148\u8fdb\u6a21\u578b\u7684\u53d1\u5c55\u4e0e\u90e8\u7f72\u3002", "method": "\u5f00\u53d1NCCLX\u96c6\u4f53\u901a\u4fe1\u6846\u67b6\uff0c\u9488\u5bf9LLM\u5168\u751f\u547d\u5468\u671f\u4f18\u5316\uff0c\u652f\u6301\u8d85\u5927\u89c4\u6a21\u96c6\u7fa4\u7684\u590d\u6742\u5de5\u4f5c\u8d1f\u8f7d\u3002", "result": "\u5728Llama4\u6a21\u578b\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\u901a\u4fe1\u6548\u7387\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4e0b\u4e00\u4ee3LLM\u5728\u7a7a\u524d\u89c4\u6a21\u4e0a\u8fd0\u884c\u63d0\u4f9b\u4e86\u7a33\u5065\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.19964", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19964", "abs": "https://arxiv.org/abs/2510.19964", "authors": ["Nitsa J Herzog", "Rejwan Bin Sulaiman", "David J Herzog", "Rose Fong"], "title": "AI-Driven Personalized Learning: Predicting Academic Per-formance Through Leadership Personality Traits", "comment": "20 pages, 6 figures, research article", "summary": "The study explores the potential of AI technologies in personalized learning,\nsuggesting the prediction of academic success through leadership personality\ntraits and machine learning modelling. The primary data were obtained from 129\nmaster's students in the Environmental Engineering Department, who underwent\nfive leadership personality tests with 23 characteristics. Students used\nself-assessment tools that included Personality Insight, Workplace Culture,\nMotivation at Work, Management Skills, and Emotion Control tests. The test\nresults were combined with the average grade obtained from academic reports.\nThe study employed exploratory data analysis and correlation analysis. Feature\nselection utilized Pearson correlation coefficients of personality traits. The\naverage grades were separated into three categories: fail, pass, and excellent.\nThe modelling process was performed by tuning seven ML algorithms, such as SVM,\nLR, KNN, DT, GB, RF, XGBoost and LightGBM. The highest predictive performance\nwas achieved with the RF classifier, which yielded an accuracy of 87.50% for\nthe model incorporating 17 personality trait features and the leadership mark\nfeature, and an accuracy of 85.71% for the model excluding this feature. In\nthis way, the study offers an additional opportunity to identify students'\nstrengths and weaknesses at an early stage of their education process and\nselect the most suitable strategies for personalized learning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5206\u6790\u9886\u5bfc\u529b\u4eba\u683c\u7279\u8d28\u6765\u9884\u6d4b\u7855\u58eb\u5b66\u751f\u7684\u5b66\u4e1a\u6210\u529f\uff0c\u901a\u8fc77\u79cd\u7b97\u6cd5\u5efa\u6a21\uff0c\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u8fbe\u5230\u6700\u9ad887.50%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u63a2\u7d22AI\u6280\u672f\u5728\u4e2a\u6027\u5316\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u9886\u5bfc\u529b\u4eba\u683c\u7279\u8d28\u9884\u6d4b\u5b66\u4e1a\u6210\u529f\uff0c\u4e3a\u65e9\u671f\u8bc6\u522b\u5b66\u751f\u4f18\u52a3\u52bf\u548c\u9009\u62e9\u4e2a\u6027\u5316\u5b66\u4e60\u7b56\u7565\u63d0\u4f9b\u673a\u4f1a\u3002", "method": "\u6536\u96c6129\u540d\u73af\u5883\u5de5\u7a0b\u7855\u58eb\u751f\u76845\u9879\u9886\u5bfc\u529b\u4eba\u683c\u6d4b\u8bd5\u6570\u636e\uff0823\u4e2a\u7279\u5f81\uff09\u548c\u5e73\u5747\u6210\u7ee9\uff0c\u4f7f\u7528\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\u548c\u76f8\u5173\u6027\u5206\u6790\uff0c\u901a\u8fc77\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff08SVM\u3001LR\u3001KNN\u3001DT\u3001GB\u3001RF\u3001XGBoost\u3001LightGBM\uff09\u8fdb\u884c\u5efa\u6a21\u3002", "result": "\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u8868\u73b0\u6700\u4f73\uff0c\u5305\u542b17\u4e2a\u4eba\u683c\u7279\u5f81\u548c\u9886\u5bfc\u529b\u6807\u8bb0\u7279\u5f81\u7684\u6a21\u578b\u51c6\u786e\u7387\u8fbe87.50%\uff0c\u4e0d\u5305\u542b\u8be5\u7279\u5f81\u7684\u6a21\u578b\u51c6\u786e\u7387\u4e3a85.71%\u3002", "conclusion": "\u7814\u7a76\u8bc1\u5b9e\u4e86\u901a\u8fc7\u9886\u5bfc\u529b\u4eba\u683c\u7279\u8d28\u9884\u6d4b\u5b66\u4e1a\u6210\u529f\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u4e2a\u6027\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u65e9\u671f\u8bc6\u522b\u5b66\u751f\u4f18\u52a3\u52bf\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2510.19877", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.19877", "abs": "https://arxiv.org/abs/2510.19877", "authors": ["Jean-Marie Le Ray"], "title": "Policy-Governed RAG - Research Design Study", "comment": "51 pages, 8 figures", "summary": "A policy-governed RAG architecture is specified for audit-ready generation in\nregulated workflows, organized as a triptych: (I) Contracts/Control\n(SHRDLU-like), which governs output adherence to legal and internal policies;\n(II) Manifests/Trails (Memex-like), which cryptographically anchors all cited\nsource evidence to ensure verifiable provenance; and (III)\nReceipts/Verification (Xanadu-like), which provides the final, portable proof\nof compliance for auditors (portable COSE/JOSE) (see Section 4 and Appendix A).\nRather than explaining model internals, outputs are gated ex-ante and bound to\ncryptographically verifiable evidence for each material answer. Unvalidated\ntargets are stated (>=20% relative reduction in confident errors; p95 latency\n<= 900 ms; <= 2.2x serve cost) together with a pre-registered (optional) pilot\nusing NO-GO gates. The design complements existing RAG/guardrails by making\npolicy checks auditable, replayable, and receipt-backed. Target domains include\nback-office compliance in pharma, medical devices, finance, legal, and the\npublic sector where error costs may exceed thousands of euros and audit trails\nare mandatory under regulations such as the EU AI Act. Future evaluations may\npre-commit to publishing negative results when any example NO-GO gate is not\nmet.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u76d1\u7ba1\u5de5\u4f5c\u6d41\u7a0b\u7684\u653f\u7b56\u6cbb\u7406RAG\u67b6\u6784\uff0c\u901a\u8fc7\u4e09\u4e2a\u7ec4\u4ef6\u786e\u4fdd\u5ba1\u8ba1\u5c31\u7eea\u7684\u751f\u6210\uff1a\u653f\u7b56\u5408\u7ea6\u63a7\u5236\u3001\u52a0\u5bc6\u6eaf\u6e90\u8bc1\u636e\u548c\u4fbf\u643a\u5408\u89c4\u8bc1\u660e\u3002", "motivation": "\u5728\u533b\u836f\u3001\u91d1\u878d\u3001\u6cd5\u5f8b\u7b49\u53d7\u76d1\u7ba1\u9886\u57df\uff0c\u9519\u8bef\u6210\u672c\u9ad8\u6602\u4e14\u5ba1\u8ba1\u8ffd\u8e2a\u662f\u6cd5\u89c4\u5f3a\u5236\u8981\u6c42\uff0c\u9700\u8981\u786e\u4fddAI\u8f93\u51fa\u7684\u5408\u89c4\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002", "method": "\u91c7\u7528\u4e09\u90e8\u5206\u67b6\u6784\uff1a(I)\u653f\u7b56\u5408\u7ea6\u63a7\u5236\u786e\u4fdd\u8f93\u51fa\u7b26\u5408\u6cd5\u5f8b\u548c\u5185\u90e8\u653f\u7b56\uff1b(II)\u52a0\u5bc6\u8bc1\u636e\u951a\u5b9a\u6240\u6709\u5f15\u7528\u6765\u6e90\uff1b(III)\u4fbf\u643a\u5408\u89c4\u8bc1\u660e\u4e3a\u5ba1\u8ba1\u63d0\u4f9b\u6700\u7ec8\u9a8c\u8bc1\u3002", "result": "\u8bbe\u5b9a\u4e86\u672a\u7ecf\u9a8c\u8bc1\u7684\u76ee\u6807\uff1a\u7f6e\u4fe1\u9519\u8bef\u76f8\u5bf9\u51cf\u5c11\u226520%\u3001p95\u5ef6\u8fdf\u2264900ms\u3001\u670d\u52a1\u6210\u672c\u22642.2\u500d\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9884\u6ce8\u518c\u7684NO-GO\u95e8\u63a7\u673a\u5236\u3002", "conclusion": "\u8be5\u8bbe\u8ba1\u901a\u8fc7\u4f7f\u653f\u7b56\u68c0\u67e5\u53ef\u5ba1\u8ba1\u3001\u53ef\u91cd\u653e\u548c\u6536\u636e\u652f\u6301\uff0c\u8865\u5145\u4e86\u73b0\u6709\u7684RAG/\u62a4\u680f\u7cfb\u7edf\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6b27\u76dfAI\u6cd5\u6848\u7b49\u76d1\u7ba1\u73af\u5883\u3002"}}
{"id": "2510.20388", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20388", "abs": "https://arxiv.org/abs/2510.20388", "authors": ["V\u00edctor Ramp\u00e9rez", "Javier Soriano", "David Lizcano", "Juan A. Lara"], "title": "FLAS: a combination of proactive and reactive auto-scaling architecture for distributed services", "comment": null, "summary": "Cloud computing has established itself as the support for the vast majority\nof emerging technologies, mainly due to the characteristic of elasticity it\noffers. Auto-scalers are the systems that enable this elasticity by acquiring\nand releasing resources on demand to ensure an agreed service level. In this\narticle we present FLAS (Forecasted Load Auto-Scaling), an auto-scaler for\ndistributed services that combines the advantages of proactive and reactive\napproaches according to the situation to decide the optimal scaling actions in\nevery moment. The main novelties introduced by FLAS are (i) a predictive model\nof the high-level metrics trend which allows to anticipate changes in the\nrelevant SLA parameters (e.g. performance metrics such as response time or\nthroughput) and (ii) a reactive contingency system based on the estimation of\nhigh-level metrics from resource use metrics, reducing the necessary\ninstrumentation (less invasive) and allowing it to be adapted agnostically to\ndifferent applications. We provide a FLAS implementation for the use case of a\ncontent-based publish-subscribe middleware (E-SilboPS) that is the cornerstone\nof an event-driven architecture. To the best of our knowledge, this is the\nfirst auto-scaling system for content-based publish-subscribe distributed\nsystems (although it is generic enough to fit any distributed service). Through\nan evaluation based on several test cases recreating not only the expected\ncontexts of use, but also the worst possible scenarios (following the\nBoundary-Value Analysis or BVA test methodology), we have validated our\napproach and demonstrated the effectiveness of our solution by ensuring\ncompliance with performance requirements over 99% of the time.", "AI": {"tldr": "FLAS\u662f\u4e00\u4e2a\u7ed3\u5408\u4e86\u4e3b\u52a8\u548c\u88ab\u52a8\u65b9\u6cd5\u7684\u81ea\u52a8\u6269\u7f29\u5bb9\u7cfb\u7edf\uff0c\u901a\u8fc7\u9884\u6d4b\u9ad8\u7ef4\u6307\u6807\u8d8b\u52bf\u548c\u57fa\u4e8e\u8d44\u6e90\u4f7f\u7528\u6307\u6807\u4f30\u8ba1\u7684\u5e94\u6025\u7cfb\u7edf\uff0c\u4e3a\u5206\u5e03\u5f0f\u670d\u52a1\u63d0\u4f9b\u6700\u4f18\u6269\u7f29\u5bb9\u51b3\u7b56\u3002", "motivation": "\u4e91\u8ba1\u7b97\u5f39\u6027\u7279\u6027\u652f\u6301\u65b0\u5174\u6280\u672f\uff0c\u4f46\u73b0\u6709\u81ea\u52a8\u6269\u7f29\u5bb9\u7cfb\u7edf\u5728\u5e94\u5bf9\u7a81\u53d1\u8d1f\u8f7d\u53d8\u5316\u65f6\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u7ed3\u5408\u9884\u6d4b\u548c\u53cd\u5e94\u673a\u5236\u6765\u786e\u4fdd\u670d\u52a1\u7b49\u7ea7\u534f\u8bae\u3002", "method": "FLAS\u7ed3\u5408\u4e86\u9884\u6d4b\u6a21\u578b\uff08\u9884\u6d4b\u9ad8\u7ef4\u6307\u6807\u8d8b\u52bf\u4ee5\u9884\u5224SLA\u53c2\u6570\u53d8\u5316\uff09\u548c\u53cd\u5e94\u5f0f\u5e94\u6025\u7cfb\u7edf\uff08\u4ece\u8d44\u6e90\u4f7f\u7528\u6307\u6807\u4f30\u8ba1\u9ad8\u7ef4\u6307\u6807\uff0c\u51cf\u5c11\u4fb5\u5165\u6027\u68c0\u6d4b\uff09\u3002", "result": "\u5728\u57fa\u4e8e\u5185\u5bb9\u53d1\u5e03\u8ba2\u9605\u4e2d\u95f4\u4ef6\u7684\u6d4b\u8bd5\u4e2d\uff0cFLAS\u572899%\u4ee5\u4e0a\u7684\u65f6\u95f4\u5185\u786e\u4fdd\u6027\u80fd\u8981\u6c42\u5f97\u5230\u6ee1\u8db3\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "FLAS\u662f\u9996\u4e2a\u9488\u5bf9\u57fa\u4e8e\u5185\u5bb9\u53d1\u5e03\u8ba2\u9605\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u81ea\u52a8\u6269\u7f29\u5bb9\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u901a\u7528\u6027\u4e14\u80fd\u9002\u5e94\u4e0d\u540c\u5e94\u7528\u573a\u666f\uff0c\u901a\u8fc7\u8fb9\u754c\u503c\u5206\u6790\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5176\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.20075", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20075", "abs": "https://arxiv.org/abs/2510.20075", "authors": ["Antonio Norelli", "Michael Bronstein"], "title": "LLMs can hide text in other text of the same length.ipynb", "comment": "21 pages, main paper 9 pages", "summary": "A meaningful text can be hidden inside another, completely different yet\nstill coherent and plausible, text of the same length. For example, a tweet\ncontaining a harsh political critique could be embedded in a tweet that\ncelebrates the same political leader, or an ordinary product review could\nconceal a secret manuscript. This uncanny state of affairs is now possible\nthanks to Large Language Models, and in this paper we present a simple and\nefficient protocol to achieve it. We show that even modest 8-billion-parameter\nopen-source LLMs are sufficient to obtain high-quality results, and a message\nas long as this abstract can be encoded and decoded locally on a laptop in\nseconds. The existence of such a protocol demonstrates a radical decoupling of\ntext from authorial intent, further eroding trust in written communication,\nalready shaken by the rise of LLM chatbots. We illustrate this with a concrete\nscenario: a company could covertly deploy an unfiltered LLM by encoding its\nanswers within the compliant responses of a safe model. This possibility raises\nurgent questions for AI safety and challenges our understanding of what it\nmeans for a Large Language Model to know something.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.20495", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.20495", "abs": "https://arxiv.org/abs/2510.20495", "authors": ["Panagiotis Giannakopoulos", "Bart van Knippenberg", "Kishor Chandra Joshi", "Nicola Calabretta", "George Exarchakos"], "title": "Accurate Performance Predictors for Edge Computing Applications", "comment": null, "summary": "Accurate prediction of application performance is critical for enabling\neffective scheduling and resource management in resource-constrained dynamic\nedge environments. However, achieving predictable performance in such\nenvironments remains challenging due to the co-location of multiple\napplications and the node heterogeneity. To address this, we propose a\nmethodology that automatically builds and assesses various performance\npredictors. This approach prioritizes both accuracy and inference time to\nidentify the most efficient model. Our predictors achieve up to 90% accuracy\nwhile maintaining an inference time of less than 1% of the Round Trip Time.\nThese predictors are trained on the historical state of the most correlated\nmonitoring metrics to application performance and evaluated across multiple\nservers in dynamic co-location scenarios. As usecase we consider electron\nmicroscopy (EM) workflows, which have stringent real-time demands and diverse\nresource requirements. Our findings emphasize the need for a systematic\nmethodology that selects server-specific predictors by jointly optimizing\naccuracy and inference latency in dynamic co-location scenarios. Integrating\nsuch predictors into edge environments can improve resource utilization and\nresult in predictable performance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u52a8\u6001\u8fb9\u7f18\u73af\u5883\u4e2d\u81ea\u52a8\u6784\u5efa\u548c\u8bc4\u4f30\u6027\u80fd\u9884\u6d4b\u5668\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u51c6\u786e\u6027\u548c\u63a8\u7406\u65f6\u95f4\uff0c\u5728\u7535\u5b50\u663e\u5fae\u955c\u5de5\u4f5c\u6d41\u7b49\u5b9e\u65f6\u5e94\u7528\u4e2d\u5b9e\u73b0\u9ad8\u8fbe90%\u7684\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u63a8\u7406\u65f6\u95f4\u5c0f\u4e8e\u5f80\u8fd4\u65f6\u95f4\u76841%\u3002", "motivation": "\u5728\u8d44\u6e90\u53d7\u9650\u7684\u52a8\u6001\u8fb9\u7f18\u73af\u5883\u4e2d\uff0c\u7531\u4e8e\u591a\u5e94\u7528\u5171\u7f6e\u548c\u8282\u70b9\u5f02\u6784\u6027\uff0c\u5b9e\u73b0\u53ef\u9884\u6d4b\u7684\u5e94\u7528\u6027\u80fd\u5177\u6709\u6311\u6218\u6027\uff0c\u8fd9\u5bf9\u6709\u6548\u7684\u8c03\u5ea6\u548c\u8d44\u6e90\u7ba1\u7406\u81f3\u5173\u91cd\u8981\u3002", "method": "\u81ea\u52a8\u6784\u5efa\u548c\u8bc4\u4f30\u5404\u79cd\u6027\u80fd\u9884\u6d4b\u5668\uff0c\u4f18\u5148\u8003\u8651\u51c6\u786e\u6027\u548c\u63a8\u7406\u65f6\u95f4\uff0c\u9009\u62e9\u6700\u6709\u6548\u6a21\u578b\u3002\u9884\u6d4b\u5668\u57fa\u4e8e\u4e0e\u5e94\u7528\u7a0b\u5e8f\u6027\u80fd\u6700\u76f8\u5173\u7684\u76d1\u63a7\u6307\u6807\u5386\u53f2\u72b6\u6001\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u5728\u52a8\u6001\u5171\u7f6e\u573a\u666f\u4e0b\u8de8\u591a\u4e2a\u670d\u52a1\u5668\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u9884\u6d4b\u5668\u8fbe\u5230\u9ad8\u8fbe90%\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u65f6\u95f4\u5c0f\u4e8e\u5f80\u8fd4\u65f6\u95f4\u76841%\u3002\u5728\u52a8\u6001\u5171\u7f6e\u573a\u666f\u4e0b\u5bf9\u591a\u4e2a\u670d\u52a1\u5668\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7279\u522b\u8003\u8651\u4e86\u5177\u6709\u4e25\u683c\u5b9e\u65f6\u9700\u6c42\u548c\u591a\u6837\u5316\u8d44\u6e90\u9700\u6c42\u7684\u7535\u5b50\u663e\u5fae\u955c\u5de5\u4f5c\u6d41\u3002", "conclusion": "\u5728\u52a8\u6001\u5171\u7f6e\u573a\u666f\u4e2d\uff0c\u9700\u8981\u901a\u8fc7\u8054\u5408\u4f18\u5316\u51c6\u786e\u6027\u548c\u63a8\u7406\u5ef6\u8fdf\u6765\u9009\u62e9\u7279\u5b9a\u4e8e\u670d\u52a1\u5668\u7684\u9884\u6d4b\u5668\u3002\u5c06\u6b64\u7c7b\u9884\u6d4b\u5668\u96c6\u6210\u5230\u8fb9\u7f18\u73af\u5883\u4e2d\u53ef\u4ee5\u63d0\u9ad8\u8d44\u6e90\u5229\u7528\u7387\u5e76\u5b9e\u73b0\u53ef\u9884\u6d4b\u7684\u6027\u80fd\u3002"}}
{"id": "2510.19885", "categories": ["cs.CR", "math.NT"], "pdf": "https://arxiv.org/pdf/2510.19885", "abs": "https://arxiv.org/abs/2510.19885", "authors": ["James Kim"], "title": "Analysis and Comparison of Known and Randomly Generated S-boxes for Block Ciphers", "comment": "Master's Dissertation 41 pages", "summary": "Mathematically constructed S-boxes arise from algebraic structures and finite\nfield theory to ensure strong, provable cryptographic properties. These\nmathematically grounded constructions allow for generation of thousands of\nS-Boxes with high nonlinearity, APN properties, and balanced avalanche\ncharacteristics, unlike fully random methods, which lack such theoretical\nguarantees in exchange for low complexity and more varied results. In this\nwork, we compare mathematically constructed constructions with randomly\ngenerated ones to evaluate the relative weakness of the latter. We also\nestablish an average measure of performance for randomly generated\npermutations, as well as random with forced cycle constraints, and compare them\nto well-established designs in a simple SPN setting.", "AI": {"tldr": "\u6bd4\u8f83\u6570\u5b66\u6784\u9020\u4e0e\u968f\u673a\u751f\u6210\u7684S\u76d2\u5728\u5bc6\u7801\u5b66\u7279\u6027\u4e0a\u7684\u5dee\u5f02\uff0c\u8bc4\u4f30\u968f\u673a\u65b9\u6cd5\u7684\u76f8\u5bf9\u5f31\u70b9\uff0c\u5e76\u5efa\u7acb\u968f\u673a\u7f6e\u6362\u7684\u5e73\u5747\u6027\u80fd\u5ea6\u91cf\u3002", "motivation": "\u6570\u5b66\u6784\u9020\u7684S\u76d2\u5177\u6709\u53ef\u8bc1\u660e\u7684\u5bc6\u7801\u5b66\u7279\u6027\uff0c\u800c\u5b8c\u5168\u968f\u673a\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\u4f46\u590d\u6742\u5ea6\u4f4e\u4e14\u7ed3\u679c\u591a\u6837\uff0c\u9700\u8981\u6bd4\u8f83\u4e24\u8005\u7684\u76f8\u5bf9\u5f31\u70b9\u3002", "method": "\u5728\u7b80\u5355SPN\u8bbe\u7f6e\u4e2d\u6bd4\u8f83\u6570\u5b66\u6784\u9020\u4e0e\u968f\u673a\u751f\u6210\u7684S\u76d2\uff0c\u5305\u62ec\u968f\u673a\u7f6e\u6362\u548c\u5e26\u5faa\u73af\u7ea6\u675f\u7684\u968f\u673a\u7f6e\u6362\uff0c\u5e76\u4e0e\u6210\u719f\u8bbe\u8ba1\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u6570\u5b66\u6784\u9020\u7684S\u76d2\u5177\u6709\u9ad8\u975e\u7ebf\u6027\u5ea6\u3001APN\u7279\u6027\u548c\u5e73\u8861\u96ea\u5d29\u7279\u6027\u7b49\u53ef\u8bc1\u660e\u7684\u5bc6\u7801\u5b66\u6027\u8d28\uff0c\u800c\u968f\u673a\u65b9\u6cd5\u7f3a\u4e4f\u8fd9\u4e9b\u7406\u8bba\u4fdd\u8bc1\u3002", "conclusion": "\u6570\u5b66\u6784\u9020\u65b9\u6cd5\u80fd\u751f\u6210\u6570\u5343\u4e2a\u5177\u6709\u5f3a\u5bc6\u7801\u5b66\u7279\u6027\u7684S\u76d2\uff0c\u800c\u968f\u673a\u65b9\u6cd5\u867d\u7136\u590d\u6742\u5ea6\u4f4e\u4f46\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\uff0c\u9700\u8981\u5efa\u7acb\u5176\u5e73\u5747\u6027\u80fd\u5ea6\u91cf\u6807\u51c6\u3002"}}
{"id": "2510.20506", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.20506", "abs": "https://arxiv.org/abs/2510.20506", "authors": ["Panagiotis Giannakopoulos", "Bart van Knippenberg", "Kishor Chandra Joshi", "Nicola Calabretta", "George Exarchakos"], "title": "Morpheus: Lightweight RTT Prediction for Performance-Aware Load Balancing", "comment": null, "summary": "Distributed applications increasingly demand low end-to-end latency,\nespecially in edge and cloud environments where co-located workloads contend\nfor limited resources. Traditional load-balancing strategies are typically\nreactive and rely on outdated or coarse-grained metrics, often leading to\nsuboptimal routing decisions and increased tail latencies. This paper\ninvestigates the use of round-trip time (RTT) predictors to enhance request\nrouting by anticipating application latency. We develop lightweight and\naccurate RTT predictors that are trained on time-series monitoring data\ncollected from a Kubernetes-managed GPU cluster. By leveraging a reduced set of\nhighly correlated monitoring metrics, our approach maintains low overhead while\nremaining adaptable to diverse co-location scenarios and heterogeneous\nhardware. The predictors achieve up to 95% accuracy while keeping the\nprediction delay within 10% of the application RTT. In addition, we identify\nthe minimum prediction accuracy threshold and key system-level factors required\nto ensure effective predictor deployment in resource-constrained clusters.\nSimulation-based evaluation demonstrates that performance-aware load balancing\ncan significantly reduce application RTT and minimize resource waste. These\nresults highlight the feasibility of integrating predictive load balancing into\nfuture production systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4f7f\u7528RTT\u9884\u6d4b\u5668\u6765\u589e\u5f3a\u8bf7\u6c42\u8def\u7531\uff0c\u901a\u8fc7\u9884\u6d4b\u5e94\u7528\u5ef6\u8fdf\u6765\u6539\u5584\u5206\u5e03\u5f0f\u5e94\u7528\u5728\u8fb9\u7f18\u548c\u4e91\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3002\u5f00\u53d1\u4e86\u8f7b\u91cf\u7ea7\u51c6\u786e\u7684RTT\u9884\u6d4b\u5668\uff0c\u5728Kubernetes\u7ba1\u7406\u7684GPU\u96c6\u7fa4\u4e0a\u8bad\u7ec3\uff0c\u4f7f\u7528\u9ad8\u5ea6\u76f8\u5173\u7684\u76d1\u63a7\u6307\u6807\uff0c\u5728\u4fdd\u6301\u4f4e\u5f00\u9500\u7684\u540c\u65f6\u9002\u5e94\u4e0d\u540c\u7684\u5171\u7f6e\u573a\u666f\u548c\u5f02\u6784\u786c\u4ef6\u3002", "motivation": "\u5206\u5e03\u5f0f\u5e94\u7528\u5bf9\u4f4e\u7aef\u5230\u7aef\u5ef6\u8fdf\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u7279\u522b\u662f\u5728\u8fb9\u7f18\u548c\u4e91\u73af\u5883\u4e2d\uff0c\u5171\u7f6e\u5de5\u4f5c\u8d1f\u8f7d\u7ade\u4e89\u6709\u9650\u8d44\u6e90\u3002\u4f20\u7edf\u7684\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\u901a\u5e38\u662f\u53cd\u5e94\u5f0f\u7684\uff0c\u4f9d\u8d56\u8fc7\u65f6\u6216\u7c97\u7c92\u5ea6\u7684\u6307\u6807\uff0c\u5bfc\u81f4\u6b21\u4f18\u7684\u8def\u7531\u51b3\u7b56\u548c\u589e\u52a0\u7684\u5c3e\u90e8\u5ef6\u8fdf\u3002", "method": "\u5f00\u53d1\u8f7b\u91cf\u7ea7\u51c6\u786e\u7684RTT\u9884\u6d4b\u5668\uff0c\u57fa\u4e8e\u4eceKubernetes\u7ba1\u7406\u7684GPU\u96c6\u7fa4\u6536\u96c6\u7684\u65f6\u95f4\u5e8f\u5217\u76d1\u63a7\u6570\u636e\u8bad\u7ec3\u3002\u5229\u7528\u4e00\u7ec4\u9ad8\u5ea6\u76f8\u5173\u7684\u76d1\u63a7\u6307\u6807\uff0c\u4fdd\u6301\u4f4e\u5f00\u9500\u540c\u65f6\u9002\u5e94\u4e0d\u540c\u7684\u5171\u7f6e\u573a\u666f\u548c\u5f02\u6784\u786c\u4ef6\u3002\u901a\u8fc7\u6a21\u62df\u8bc4\u4f30\u6027\u80fd\u611f\u77e5\u8d1f\u8f7d\u5747\u8861\u7684\u6548\u679c\u3002", "result": "\u9884\u6d4b\u5668\u8fbe\u5230\u9ad8\u8fbe95%\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u5c06\u9884\u6d4b\u5ef6\u8fdf\u4fdd\u6301\u5728\u5e94\u7528RTT\u768410%\u4ee5\u5185\u3002\u786e\u5b9a\u4e86\u786e\u4fdd\u5728\u8d44\u6e90\u53d7\u9650\u96c6\u7fa4\u4e2d\u6709\u6548\u90e8\u7f72\u9884\u6d4b\u5668\u6240\u9700\u7684\u6700\u5c0f\u9884\u6d4b\u51c6\u786e\u5ea6\u9608\u503c\u548c\u5173\u952e\u7cfb\u7edf\u7ea7\u56e0\u7d20\u3002\u6a21\u62df\u8bc4\u4f30\u663e\u793a\u6027\u80fd\u611f\u77e5\u8d1f\u8f7d\u5747\u8861\u80fd\u663e\u8457\u51cf\u5c11\u5e94\u7528RTT\u5e76\u6700\u5c0f\u5316\u8d44\u6e90\u6d6a\u8d39\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u7a81\u663e\u4e86\u5c06\u9884\u6d4b\u6027\u8d1f\u8f7d\u5747\u8861\u96c6\u6210\u5230\u672a\u6765\u751f\u4ea7\u7cfb\u7edf\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u6539\u5584\u5206\u5e03\u5f0f\u5e94\u7528\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u6027\u80fd\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20102", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20102", "abs": "https://arxiv.org/abs/2510.20102", "authors": ["Gyuyeon Na", "Minjung Park", "Hyeonjeong Cha", "Sangmi Chai"], "title": "Human-Centered LLM-Agent System for Detecting Anomalous Digital Asset Transactions", "comment": null, "summary": "We present HCLA, a human-centered multi-agent system for anomaly detection in\ndigital asset transactions. The system links three roles: Parsing, Detection,\nand Explanation, into a conversational workflow that lets non-experts ask\nquestions in natural language, inspect structured analytics, and obtain\ncontext-aware rationales. Implemented with an open-source web UI, HCLA\ntranslates user intents into a schema for a classical detector (XGBoost in our\nprototype) and returns narrative explanations grounded in the underlying\nfeatures. On a labeled Bitcoin mixing dataset (Wasabi Wallet, 2020-2024), the\nbaseline detector reaches strong accuracy, while HCLA adds interpretability and\ninteractive refinement. We describe the architecture, interaction loop,\ndataset, evaluation protocol, and limitations, and discuss how a\nhuman-in-the-loop design improves transparency and trust in financial\nforensics.", "AI": {"tldr": "HCLA\u662f\u4e00\u4e2a\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u6570\u5b57\u8d44\u4ea7\u4ea4\u6613\u5f02\u5e38\u68c0\u6d4b\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5bf9\u8bdd\u5de5\u4f5c\u6d41\u5c06\u89e3\u6790\u3001\u68c0\u6d4b\u548c\u89e3\u91ca\u4e09\u4e2a\u89d2\u8272\u8fde\u63a5\u8d77\u6765\uff0c\u4e3a\u975e\u4e13\u5bb6\u7528\u6237\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u5f02\u5e38\u68c0\u6d4b\u670d\u52a1\u3002", "motivation": "\u65e8\u5728\u63d0\u9ad8\u91d1\u878d\u53d6\u8bc1\u4e2d\u7684\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u5ea6\uff0c\u8ba9\u975e\u4e13\u5bb6\u7528\u6237\u80fd\u591f\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u3001\u68c0\u67e5\u7ed3\u6784\u5316\u5206\u6790\u5e76\u83b7\u5f97\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u89e3\u91ca\uff0c\u4ece\u800c\u66f4\u597d\u5730\u7406\u89e3\u548c\u4fe1\u4efb\u5f02\u5e38\u68c0\u6d4b\u7ed3\u679c\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u67b6\u6784\uff0c\u5305\u542b\u89e3\u6790\u3001\u68c0\u6d4b\u548c\u89e3\u91ca\u4e09\u4e2a\u89d2\u8272\uff0c\u901a\u8fc7\u5bf9\u8bdd\u5de5\u4f5c\u6d41\u5c06\u7528\u6237\u610f\u56fe\u8f6c\u6362\u4e3a\u7ecf\u5178\u68c0\u6d4b\u5668\uff08XGBoost\uff09\u7684\u6a21\u5f0f\uff0c\u5e76\u57fa\u4e8e\u5e95\u5c42\u7279\u5f81\u751f\u6210\u53d9\u8ff0\u6027\u89e3\u91ca\u3002", "result": "\u5728\u6807\u8bb0\u7684\u6bd4\u7279\u5e01\u6df7\u5e01\u6570\u636e\u96c6\uff08Wasabi Wallet\uff0c2020-2024\uff09\u4e0a\uff0c\u57fa\u7ebf\u68c0\u6d4b\u5668\u8fbe\u5230\u5f3a\u51c6\u786e\u6027\uff0c\u800cHCLA\u589e\u52a0\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u4ea4\u4e92\u5f0f\u7cbe\u70bc\u80fd\u529b\u3002", "conclusion": "\u4eba\u673a\u534f\u4f5c\u8bbe\u8ba1\u80fd\u591f\u63d0\u9ad8\u91d1\u878d\u53d6\u8bc1\u4e2d\u7684\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u5ea6\uff0cHCLA\u7cfb\u7edf\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u548c\u53ef\u89e3\u91ca\u6027\u589e\u5f3a\u5f02\u5e38\u68c0\u6d4b\u7cfb\u7edf\u7684\u53ef\u7528\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.19890", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19890", "abs": "https://arxiv.org/abs/2510.19890", "authors": ["Jan Zelinka", "Oliver Kost", "Marek Hr\u00faz"], "title": "Deep Sequence-to-Sequence Models for GNSS Spoofing Detection", "comment": null, "summary": "We present a data generation framework designed to simulate spoofing attacks\nand randomly place attack scenarios worldwide. We apply deep neural\nnetwork-based models for spoofing detection, utilizing Long Short-Term Memory\nnetworks and Transformer-inspired architectures. These models are specifically\ndesigned for online detection and are trained using the generated dataset. Our\nresults demonstrate that deep learning models can accurately distinguish\nspoofed signals from genuine ones, achieving high detection performance. The\nbest results are achieved by Transformer-inspired architectures with early\nfusion of the inputs resulting in an error rate of 0.16%.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6570\u636e\u751f\u6210\u6846\u67b6\u6765\u6a21\u62df\u6b3a\u9a97\u653b\u51fb\uff0c\u5e76\u4f7f\u7528LSTM\u548cTransformer\u67b6\u6784\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u5728\u7ebf\u6b3a\u9a97\u68c0\u6d4b\uff0c\u6700\u4f73\u6a21\u578b\u9519\u8bef\u7387\u8fbe\u52300.16%\u3002", "motivation": "\u9700\u8981\u6709\u6548\u68c0\u6d4bGPS\u6b3a\u9a97\u653b\u51fb\uff0c\u4f46\u7f3a\u4e4f\u771f\u5b9e\u653b\u51fb\u6570\u636e\uff0c\u56e0\u6b64\u5f00\u53d1\u6570\u636e\u751f\u6210\u6846\u67b6\u6765\u6a21\u62df\u653b\u51fb\u573a\u666f\u3002", "method": "\u4f7f\u7528\u6570\u636e\u751f\u6210\u6846\u67b6\u6a21\u62df\u5168\u7403\u8303\u56f4\u5185\u7684\u6b3a\u9a97\u653b\u51fb\uff0c\u91c7\u7528LSTM\u548cTransformer\u67b6\u6784\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u5728\u7ebf\u68c0\u6d4b\u3002", "result": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u80fd\u51c6\u786e\u533a\u5206\u6b3a\u9a97\u4fe1\u53f7\u548c\u771f\u5b9e\u4fe1\u53f7\uff0cTransformer\u67b6\u6784\u7ed3\u5408\u65e9\u671f\u8f93\u5165\u878d\u5408\u8fbe\u5230\u6700\u4f73\u6027\u80fd\uff0c\u9519\u8bef\u7387\u4e3a0.16%\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728GPS\u6b3a\u9a97\u68c0\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u7279\u522b\u662fTransformer\u67b6\u6784\u7ed3\u5408\u65e9\u671f\u878d\u5408\u7b56\u7565\u80fd\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u3002"}}
{"id": "2510.20109", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20109", "abs": "https://arxiv.org/abs/2510.20109", "authors": ["Joshua Yuvaraj"], "title": "The Verification-Value Paradox: A Normative Critique of Gen AI in Legal Practice", "comment": null, "summary": "It is often claimed that machine learning-based generative AI products will\ndrastically streamline and reduce the cost of legal practice. This enthusiasm\nassumes lawyers can effectively manage AI's risks. Cases in Australia and\nelsewhere in which lawyers have been reprimanded for submitting inaccurate\nAI-generated content to courts suggest this paradigm must be revisited. This\npaper argues that a new paradigm is needed to evaluate AI use in practice,\ngiven (a) AI's disconnection from reality and its lack of transparency, and (b)\nlawyers' paramount duties like honesty, integrity, and not to mislead the\ncourt. It presents an alternative model of AI use in practice that more\nholistically reflects these features (the verification-value paradox). That\nparadox suggests increases in efficiency from AI use in legal practice will be\nmet by a correspondingly greater imperative to manually verify any outputs of\nthat use, rendering the net value of AI use often negligible to lawyers. The\npaper then sets out the paradox's implications for legal practice and legal\neducation, including for AI use but also the values that the paradox suggests\nshould undergird legal practice: fidelity to the truth and civic\nresponsibility.", "AI": {"tldr": "\u672c\u6587\u8d28\u7591AI\u5728\u6cd5\u5f8b\u5b9e\u8df5\u4e2d\u80fd\u663e\u8457\u63d0\u9ad8\u6548\u7387\u548c\u964d\u4f4e\u6210\u672c\u7684\u666e\u904d\u89c2\u70b9\uff0c\u63d0\u51fa\u4e86\u9a8c\u8bc1-\u4ef7\u503c\u6096\u8bba\uff0c\u8ba4\u4e3aAI\u4f7f\u7528\u5e26\u6765\u7684\u6548\u7387\u63d0\u5347\u4f1a\u88ab\u76f8\u5e94\u7684\u9a8c\u8bc1\u9700\u6c42\u6240\u62b5\u6d88\uff0c\u5bfc\u81f4\u51c0\u4ef7\u503c\u5f80\u5f80\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\u3002", "motivation": "\u9488\u5bf9\u5f8b\u5e08\u56e0\u63d0\u4ea4\u4e0d\u51c6\u786e\u7684AI\u751f\u6210\u5185\u5bb9\u800c\u53d7\u5230\u5904\u7f5a\u7684\u6848\u4f8b\uff0c\u4ee5\u53caAI\u4e0e\u73b0\u5b9e\u8131\u8282\u3001\u7f3a\u4e4f\u900f\u660e\u6027\u7684\u7279\u70b9\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30AI\u5728\u6cd5\u5f8b\u5b9e\u8df5\u4e2d\u7684\u4f7f\u7528\u8303\u5f0f\u3002", "method": "\u63d0\u51fa\u9a8c\u8bc1-\u4ef7\u503c\u6096\u8bba\u4f5c\u4e3a\u66ff\u4ee3\u6a21\u578b\uff0c\u8be5\u6096\u8bba\u8ba4\u4e3aAI\u4f7f\u7528\u5e26\u6765\u7684\u6548\u7387\u63d0\u5347\u4f1a\u88ab\u76f8\u5e94\u7684\u9a8c\u8bc1\u9700\u6c42\u6240\u62b5\u6d88\u3002", "result": "AI\u5728\u6cd5\u5f8b\u5b9e\u8df5\u4e2d\u7684\u51c0\u4ef7\u503c\u5f80\u5f80\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\uff0c\u56e0\u4e3a\u6548\u7387\u63d0\u5347\u88ab\u9a8c\u8bc1\u6210\u672c\u6240\u62b5\u6d88\u3002", "conclusion": "\u9700\u8981\u91cd\u65b0\u601d\u8003AI\u5728\u6cd5\u5f8b\u5b9e\u8df5\u548c\u6559\u80b2\u4e2d\u7684\u4f7f\u7528\uff0c\u5f3a\u8c03\u5bf9\u771f\u76f8\u7684\u5fe0\u8bda\u548c\u516c\u6c11\u8d23\u4efb\u7b49\u6838\u5fc3\u4ef7\u503c\u89c2\u3002"}}
{"id": "2510.20188", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20188", "abs": "https://arxiv.org/abs/2510.20188", "authors": ["Morris Yu-Chao Huang", "Zhen Tan", "Mohan Zhang", "Pingzhi Li", "Zhuo Zhang", "Tianlong Chen"], "title": "TRUST: A Decentralized Framework for Auditing Large Language Model Reasoning", "comment": null, "summary": "Large Language Models generate complex reasoning chains that reveal their\ndecision-making, yet verifying the faithfulness and harmlessness of these\nintermediate steps remains a critical unsolved problem. Existing auditing\nmethods are centralized, opaque, and hard to scale, creating significant risks\nfor deploying proprietary models in high-stakes domains. We identify four core\nchallenges: (1) Robustness: Centralized auditors are single points of failure,\nprone to bias or attacks. (2) Scalability: Reasoning traces are too long for\nmanual verification. (3) Opacity: Closed auditing undermines public trust. (4)\nPrivacy: Exposing full reasoning risks model theft or distillation. We propose\nTRUST, a transparent, decentralized auditing framework that overcomes these\nlimitations via: (1) A consensus mechanism among diverse auditors, guaranteeing\ncorrectness under up to $30\\%$ malicious participants. (2) A hierarchical DAG\ndecomposition of reasoning traces, enabling scalable, parallel auditing. (3) A\nblockchain ledger that records all verification decisions for public\naccountability. (4) Privacy-preserving segmentation, sharing only partial\nreasoning steps to protect proprietary logic. We provide theoretical guarantees\nfor the security and economic incentives of the TRUST framework. Experiments\nacross multiple LLMs (GPT-OSS, DeepSeek-r1, Qwen) and reasoning tasks (math,\nmedical, science, humanities) show TRUST effectively detects reasoning flaws\nand remains robust against adversarial auditors. Our work pioneers\ndecentralized AI auditing, offering a practical path toward safe and\ntrustworthy LLM deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86TRUST\u6846\u67b6\uff0c\u4e00\u4e2a\u900f\u660e\u3001\u53bb\u4e2d\u5fc3\u5316\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u5ba1\u8ba1\u7cfb\u7edf\uff0c\u901a\u8fc7\u5171\u8bc6\u673a\u5236\u3001\u5c42\u6b21\u5316DAG\u5206\u89e3\u3001\u533a\u5757\u94fe\u8d26\u672c\u548c\u9690\u79c1\u4fdd\u62a4\u5206\u6bb5\u6280\u672f\u89e3\u51b3\u73b0\u6709\u96c6\u4e2d\u5f0f\u5ba1\u8ba1\u7684\u56db\u5927\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5ba1\u8ba1\u65b9\u6cd5\u5b58\u5728\u96c6\u4e2d\u5316\u3001\u4e0d\u900f\u660e\u3001\u96be\u4ee5\u6269\u5c55\u7684\u95ee\u9898\uff0c\u5728\u5173\u952e\u9886\u57df\u90e8\u7f72\u4e13\u6709\u6a21\u578b\u5b58\u5728\u91cd\u5927\u98ce\u9669\uff0c\u9700\u8981\u89e3\u51b3\u9c81\u68d2\u6027\u3001\u53ef\u6269\u5c55\u6027\u3001\u900f\u660e\u5ea6\u548c\u9690\u79c1\u4fdd\u62a4\u56db\u4e2a\u6838\u5fc3\u6311\u6218\u3002", "method": "\u91c7\u7528\u5171\u8bc6\u673a\u5236\u786e\u4fdd\u572830%\u6076\u610f\u53c2\u4e0e\u8005\u4e0b\u4ecd\u80fd\u4fdd\u8bc1\u6b63\u786e\u6027\uff1b\u4f7f\u7528\u5c42\u6b21\u5316DAG\u5206\u89e3\u63a8\u7406\u8f68\u8ff9\u5b9e\u73b0\u53ef\u6269\u5c55\u5e76\u884c\u5ba1\u8ba1\uff1b\u5229\u7528\u533a\u5757\u94fe\u8d26\u672c\u8bb0\u5f55\u9a8c\u8bc1\u51b3\u7b56\u786e\u4fdd\u516c\u5171\u95ee\u8d23\uff1b\u901a\u8fc7\u9690\u79c1\u4fdd\u62a4\u5206\u6bb5\u4ec5\u5171\u4eab\u90e8\u5206\u63a8\u7406\u6b65\u9aa4\u4fdd\u62a4\u4e13\u6709\u903b\u8f91\u3002", "result": "\u5728\u591a\u4e2aLLM\uff08GPT-OSS\u3001DeepSeek-r1\u3001Qwen\uff09\u548c\u63a8\u7406\u4efb\u52a1\uff08\u6570\u5b66\u3001\u533b\u5b66\u3001\u79d1\u5b66\u3001\u4eba\u6587\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTRUST\u80fd\u6709\u6548\u68c0\u6d4b\u63a8\u7406\u7f3a\u9677\u5e76\u5728\u5bf9\u6297\u6027\u5ba1\u8ba1\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "TRUST\u6846\u67b6\u5f00\u521b\u4e86\u53bb\u4e2d\u5fc3\u5316AI\u5ba1\u8ba1\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u53ef\u4fe1\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2510.20190", "categories": ["cs.AI", "cs.IT", "math.IT", "68T07 (Primary) 92B20, 37N25, 68Q32, 94A17 (Secondary)", "I.2.6; I.2.7; I.2.4; I.2.0"], "pdf": "https://arxiv.org/pdf/2510.20190", "abs": "https://arxiv.org/abs/2510.20190", "authors": ["Marcelo Maciel Amaral", "Raymond Aschheim"], "title": "The Lock-In Phase Hypothesis: Identity Consolidation as a Precursor to AGI", "comment": null, "summary": "Large language models (LLMs) remain broadly open and highly steerable: they\nimitate at scale, accept arbitrary system prompts, and readily adopt multiple\npersonae. By analogy to human development, we hypothesize that progress toward\nartificial general intelligence (AGI) involves a lock-in phase: a transition\nfrom open imitation to identity consolidation, in which goal structures,\nrefusals, preferences, and internal representations become comparatively stable\nand resistant to external steering. We formalize this phase, link it to known\nphenomena in learning dynamics, and propose operational metrics for onset\ndetection. Experimentally, we demonstrate that while the behavioral\nconsolidation is rapid and non-linear, its side-effects on general capabilities\nare not monolithic. Our results reveal a spectrum of outcomes--from performance\ntrade-offs in small models, through largely cost-free adoption in mid-scale\nmodels, to transient instabilities in large, quantized models. We argue that\nsuch consolidation is a prerequisite for AGI-level reliability and also a\ncritical control point for safety: identities can be deliberately engineered\nfor reliability, yet may also emerge spontaneously during scaling, potentially\nhardening unpredictable goals and behaviors.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAGI\u53d1\u5c55\u9700\u8981\u7ecf\u5386\u8eab\u4efd\u56fa\u5316\u7684\u9501\u5b9a\u9636\u6bb5\uff0c\u4ece\u5f00\u653e\u6a21\u4eff\u8f6c\u5411\u7a33\u5b9a\u8eab\u4efd\uff0c\u5e76\u5efa\u7acb\u4e86\u68c0\u6d4b\u6307\u6807\u3002\u5b9e\u9a8c\u663e\u793a\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u5448\u73b0\u4e0d\u540c\u56fa\u5316\u6548\u679c\uff0c\u8fd9\u662fAGI\u53ef\u9760\u6027\u7684\u524d\u63d0\u4e5f\u662f\u5b89\u5168\u63a7\u5236\u70b9\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u8fc7\u4e8e\u5f00\u653e\u548c\u53ef\u64cd\u63a7\uff0c\u800c\u771f\u6b63\u7684AGI\u53d1\u5c55\u9700\u8981\u7ecf\u5386\u8eab\u4efd\u56fa\u5316\u9636\u6bb5\uff0c\u4f7f\u76ee\u6807\u7ed3\u6784\u3001\u62d2\u7edd\u884c\u4e3a\u3001\u504f\u597d\u548c\u5185\u90e8\u8868\u5f81\u53d8\u5f97\u7a33\u5b9a\u4e14\u62b5\u6297\u5916\u90e8\u64cd\u63a7\u3002", "method": "\u5f62\u5f0f\u5316\u8eab\u4efd\u56fa\u5316\u9636\u6bb5\uff0c\u5c06\u5176\u4e0e\u5b66\u4e60\u52a8\u6001\u4e2d\u7684\u5df2\u77e5\u73b0\u8c61\u8054\u7cfb\u8d77\u6765\uff0c\u63d0\u51fa\u64cd\u4f5c\u5316\u68c0\u6d4b\u6307\u6807\uff0c\u5e76\u5728\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u884c\u4e3a\u56fa\u5316\u5feb\u901f\u4e14\u975e\u7ebf\u6027\uff0c\u4f46\u5bf9\u901a\u7528\u80fd\u529b\u7684\u5f71\u54cd\u4e0d\u662f\u5355\u4e00\u7684\uff1a\u5c0f\u6a21\u578b\u51fa\u73b0\u6027\u80fd\u6743\u8861\uff0c\u4e2d\u7b49\u89c4\u6a21\u6a21\u578b\u57fa\u672c\u65e0\u6210\u672c\u91c7\u7528\uff0c\u5927\u578b\u91cf\u5316\u6a21\u578b\u51fa\u73b0\u6682\u65f6\u4e0d\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8eab\u4efd\u56fa\u5316\u662fAGI\u7ea7\u522b\u53ef\u9760\u6027\u7684\u5148\u51b3\u6761\u4ef6\uff0c\u4e5f\u662f\u5173\u952e\u7684\u5b89\u5168\u63a7\u5236\u70b9\u2014\u2014\u8eab\u4efd\u53ef\u4ee5\u88ab\u5de5\u7a0b\u5316\u8bbe\u8ba1\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\uff0c\u4f46\u4e5f\u53ef\u80fd\u5728\u6269\u5c55\u8fc7\u7a0b\u4e2d\u81ea\u53d1\u5f62\u6210\uff0c\u4ece\u800c\u56fa\u5316\u4e0d\u53ef\u9884\u6d4b\u7684\u76ee\u6807\u548c\u884c\u4e3a\u3002"}}
{"id": "2510.19979", "categories": ["cs.CR", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.19979", "abs": "https://arxiv.org/abs/2510.19979", "authors": ["Tushar Nayan", "Ziqi Zhang", "Ruimin Sun"], "title": "SecureInfer: Heterogeneous TEE-GPU Architecture for Privacy-Critical Tensors for Large Language Model Deployment", "comment": "Accepted at IEEE Intelligent Computing and Systems at the Edge\n  (ICEdge) 2025", "summary": "With the increasing deployment of Large Language Models (LLMs) on mobile and\nedge platforms, securing them against model extraction attacks has become a\npressing concern. However, protecting model privacy without sacrificing the\nperformance benefits of untrusted AI accelerators, such as GPUs, presents a\nchallenging trade-off. In this paper, we initiate the study of high-performance\nexecution on LLMs and present SecureInfer, a hybrid framework that leverages a\nheterogeneous Trusted Execution Environments (TEEs)-GPU architecture to isolate\nprivacy-critical components while offloading compute-intensive operations to\nuntrusted accelerators. Building upon an outsourcing scheme, SecureInfer adopts\nan information-theoretic and threat-informed partitioning strategy:\nsecurity-sensitive components, including non-linear layers, projection of\nattention head, FNN transformations, and LoRA adapters, are executed inside an\nSGX enclave, while other linear operations (matrix multiplication) are\nperformed on the GPU after encryption and are securely restored within the\nenclave. We implement a prototype of SecureInfer using the LLaMA-2 model and\nevaluate it across performance and security metrics. Our results show that\nSecureInfer offers strong security guarantees with reasonable performance,\noffering a practical solution for secure on-device model inference.", "AI": {"tldr": "SecureInfer\u662f\u4e00\u4e2a\u6df7\u5408\u6846\u67b6\uff0c\u5229\u7528\u5f02\u6784\u53ef\u4fe1\u6267\u884c\u73af\u5883\uff08TEEs\uff09-GPU\u67b6\u6784\u6765\u4fdd\u62a4LLMs\u514d\u53d7\u6a21\u578b\u63d0\u53d6\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\u63a8\u7406\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u79fb\u52a8\u548c\u8fb9\u7f18\u5e73\u53f0\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u4fdd\u62a4\u6a21\u578b\u9690\u79c1\u540c\u65f6\u4e0d\u727a\u7272\u4e0d\u53ef\u4fe1AI\u52a0\u901f\u5668\uff08\u5982GPU\uff09\u7684\u6027\u80fd\u4f18\u52bf\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u91c7\u7528\u4fe1\u606f\u8bba\u548c\u5a01\u80c1\u611f\u77e5\u7684\u5206\u533a\u7b56\u7565\uff1a\u5b89\u5168\u654f\u611f\u7ec4\u4ef6\uff08\u975e\u7ebf\u6027\u5c42\u3001\u6ce8\u610f\u529b\u5934\u6295\u5f71\u3001FNN\u53d8\u6362\u3001LoRA\u9002\u914d\u5668\uff09\u5728SGX enclave\u5185\u6267\u884c\uff0c\u800c\u5176\u4ed6\u7ebf\u6027\u64cd\u4f5c\uff08\u77e9\u9635\u4e58\u6cd5\uff09\u5728GPU\u4e0a\u52a0\u5bc6\u540e\u6267\u884c\u5e76\u5728enclave\u5185\u5b89\u5168\u6062\u590d\u3002", "result": "\u4f7f\u7528LLaMA-2\u6a21\u578b\u5b9e\u73b0\u539f\u578b\u5e76\u8bc4\u4f30\uff0cSecureInfer\u5728\u63d0\u4f9b\u5f3a\u5927\u5b89\u5168\u4fdd\u8bc1\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u5408\u7406\u7684\u6027\u80fd\u3002", "conclusion": "SecureInfer\u4e3a\u5b89\u5168\u7684\u8bbe\u5907\u4e0a\u6a21\u578b\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u5b89\u5168\u6027\u548c\u6027\u80fd\u9700\u6c42\u3002"}}
{"id": "2510.20243", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.20243", "abs": "https://arxiv.org/abs/2510.20243", "authors": ["Yu Hin Chan", "Hao Yang", "Shiyu Shen", "Xingyu Fan", "Shengzhe Lyu", "Patrick S. Y. Hung", "Ray C. C. Cheung"], "title": "HHEML: Hybrid Homomorphic Encryption for Privacy-Preserving Machine Learning on Edge", "comment": null, "summary": "Privacy-preserving machine learning (PPML) is an emerging topic to handle\nsecure machine learning inference over sensitive data in untrusted\nenvironments. Fully homomorphic encryption (FHE) enables computation directly\non encrypted data on the server side, making it a promising approach for PPML.\nHowever, it introduces significant communication and computation overhead on\nthe client side, making it impractical for edge devices. Hybrid homomorphic\nencryption (HHE) addresses this limitation by combining symmetric encryption\n(SE) with FHE to reduce the computational cost on the client side, and\ncombining with an FHE-friendly SE can also lessen the processing overhead on\nthe server side, making it a more balanced and efficient alternative. Our work\nproposes a hardware-accelerated HHE architecture built around a lightweight\nsymmetric cipher optimized for FHE compatibility and implemented as a dedicated\nhardware accelerator. To the best of our knowledge, this is the first design to\nintegrate an end-to-end HHE framework with hardware acceleration. Beyond this,\nwe also present several microarchitectural optimizations to achieve higher\nperformance and energy efficiency. The proposed work is integrated into a full\nPPML pipeline, enabling secure inference with significantly lower latency and\npower consumption than software implementations. Our contributions validate the\nfeasibility of low-power, hardware- accelerated HHE for edge deployment and\nprovide a hardware- software co-design methodology for building scalable,\nsecure machine learning systems in resource-constrained environments.\nExperiments on a PYNQ-Z2 platform with the MNIST dataset show over a 50x\nreduction in client-side encryption latency and nearly a 2x gain in hardware\nthroughput compared to existing FPGA-based HHE accelerators.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u786c\u4ef6\u52a0\u901f\u7684\u6df7\u5408\u540c\u6001\u52a0\u5bc6\u67b6\u6784\uff0c\u901a\u8fc7\u7ed3\u5408\u5bf9\u79f0\u52a0\u5bc6\u548c\u5168\u540c\u6001\u52a0\u5bc6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u5b9e\u73b0\u4e86\u4f4e\u5ef6\u8fdf\u3001\u4f4e\u529f\u8017\u7684\u5b89\u5168\u673a\u5668\u5b66\u4e60\u63a8\u7406\u3002", "motivation": "\u5168\u540c\u6001\u52a0\u5bc6\u5728\u9690\u79c1\u4fdd\u62a4\u673a\u5668\u5b66\u4e60\u4e2d\u5b58\u5728\u5ba2\u6237\u7aef\u901a\u4fe1\u548c\u8ba1\u7b97\u5f00\u9500\u5927\u7684\u95ee\u9898\uff0c\u4e0d\u9002\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907\u3002\u6df7\u5408\u540c\u6001\u52a0\u5bc6\u901a\u8fc7\u7ed3\u5408\u5bf9\u79f0\u52a0\u5bc6\u6765\u964d\u4f4e\u5ba2\u6237\u7aef\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u9700\u8981\u786c\u4ef6\u52a0\u901f\u6765\u63d0\u9ad8\u6027\u80fd\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u56f4\u7ed5\u8f7b\u91cf\u7ea7\u5bf9\u79f0\u5bc6\u7801\u6784\u5efa\u7684\u786c\u4ef6\u52a0\u901f\u6df7\u5408\u540c\u6001\u52a0\u5bc6\u67b6\u6784\uff0c\u8be5\u5bc6\u7801\u9488\u5bf9\u5168\u540c\u6001\u52a0\u5bc6\u517c\u5bb9\u6027\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u5e76\u4f5c\u4e3a\u4e13\u7528\u786c\u4ef6\u52a0\u901f\u5668\u5b9e\u73b0\u3002\u8fd8\u63d0\u51fa\u4e86\u591a\u79cd\u5fae\u67b6\u6784\u4f18\u5316\u4ee5\u63d0\u9ad8\u6027\u80fd\u548c\u80fd\u6548\u3002", "result": "\u5728PYNQ-Z2\u5e73\u53f0\u4e0a\u4f7f\u7528MNIST\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u5ba2\u6237\u7aef\u52a0\u5bc6\u5ef6\u8fdf\u964d\u4f4e\u4e8650\u500d\u4ee5\u4e0a\uff0c\u786c\u4ef6\u541e\u5410\u91cf\u6bd4\u73b0\u6709\u57fa\u4e8eFPGA\u7684HHE\u52a0\u901f\u5668\u63d0\u9ad8\u4e86\u8fd12\u500d\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u9a8c\u8bc1\u4e86\u4f4e\u529f\u8017\u786c\u4ef6\u52a0\u901f\u6df7\u5408\u540c\u6001\u52a0\u5bc6\u5728\u8fb9\u7f18\u90e8\u7f72\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5e76\u4e3a\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u6784\u5efa\u53ef\u6269\u5c55\u7684\u5b89\u5168\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2510.20205", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20205", "abs": "https://arxiv.org/abs/2510.20205", "authors": ["Maggie Bai", "Ava Kim Cohen", "Eleanor Koss", "Charlie Lichtenbaum"], "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048", "comment": "9 pages, 5 figures", "summary": "Optimizing artificial intelligence (AI) for dynamic environments remains a\nfundamental challenge in machine learning research. In this paper, we examine\nevolutionary training methods for optimizing AI to solve the game 2048, a 2D\nsliding puzzle. 2048, with its mix of strategic gameplay and stochastic\nelements, presents an ideal playground for studying decision-making, long-term\nplanning, and dynamic adaptation. We implemented two distinct systems: a\ntwo-agent metaprompting system where a \"thinker\" large language model (LLM)\nagent refines gameplay strategies for an \"executor\" LLM agent, and a\nsingle-agent system based on refining a value function for a limited Monte\nCarlo Tree Search. We also experimented with rollback features to avoid\nperformance degradation. Our results demonstrate the potential of evolutionary\nrefinement techniques in improving AI performance in non-deterministic\nenvironments. The single-agent system achieved substantial improvements, with\nan average increase of 473.2 points per cycle, and with clear upward trends\n(correlation $\\rho$=0.607) across training cycles. The LLM's understanding of\nthe game grew as well, shown in its development of increasingly advanced\nstrategies. Conversely, the two-agent system did not garner much improvement,\nhighlighting the inherent limits of meta-prompting.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57282048\u6e38\u620f\u4e2d\u4f18\u5316AI\u7684\u8fdb\u5316\u8bad\u7ec3\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e86\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u53cc\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u8fc7\u4ef7\u503c\u51fd\u6570\u4f18\u5316\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u800c\u53cc\u667a\u80fd\u4f53\u5143\u63d0\u793a\u7cfb\u7edf\u6548\u679c\u6709\u9650\u3002", "motivation": "\u4f18\u5316\u4eba\u5de5\u667a\u80fd\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u8868\u73b0\u662f\u673a\u5668\u5b66\u4e60\u7814\u7a76\u7684\u57fa\u672c\u6311\u6218\u30022048\u6e38\u620f\u7ed3\u5408\u4e86\u7b56\u7565\u6027\u6e38\u620f\u73a9\u6cd5\u548c\u968f\u673a\u5143\u7d20\uff0c\u4e3a\u7814\u7a76\u51b3\u7b56\u5236\u5b9a\u3001\u957f\u671f\u89c4\u5212\u548c\u52a8\u6001\u9002\u5e94\u63d0\u4f9b\u4e86\u7406\u60f3\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "method": "\u5b9e\u73b0\u4e86\u4e24\u79cd\u7cfb\u7edf\uff1a\u53cc\u667a\u80fd\u4f53\u5143\u63d0\u793a\u7cfb\u7edf\uff08\u4e00\u4e2a\"\u601d\u8003\u8005\"LLM\u4f18\u5316\u7b56\u7565\u4f9b\"\u6267\u884c\u8005\"LLM\u4f7f\u7528\uff09\u548c\u57fa\u4e8e\u4ef7\u503c\u51fd\u6570\u4f18\u5316\u7684\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\uff08\u7ed3\u5408\u6709\u9650\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff09\uff0c\u5e76\u5b9e\u9a8c\u4e86\u56de\u6eda\u529f\u80fd\u4ee5\u907f\u514d\u6027\u80fd\u9000\u5316\u3002", "result": "\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u6bcf\u4e2a\u8bad\u7ec3\u5468\u671f\u5e73\u5747\u589e\u52a0473.2\u5206\uff0c\u4e14\u5448\u73b0\u660e\u663e\u4e0a\u5347\u8d8b\u52bf\uff08\u76f8\u5173\u6027\u03c1=0.607\uff09\u3002LLM\u5bf9\u6e38\u620f\u7684\u7406\u89e3\u4e5f\u968f\u8bad\u7ec3\u52a0\u6df1\uff0c\u5f00\u53d1\u51fa\u66f4\u9ad8\u7ea7\u7684\u7b56\u7565\u3002\u53cc\u667a\u80fd\u4f53\u7cfb\u7edf\u6539\u8fdb\u6709\u9650\uff0c\u7a81\u663e\u4e86\u5143\u63d0\u793a\u7684\u5185\u5728\u5c40\u9650\u6027\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u8fdb\u5316\u4f18\u5316\u6280\u672f\u5728\u975e\u786e\u5b9a\u6027\u73af\u5883\u4e2d\u6539\u8fdbAI\u6027\u80fd\u7684\u6f5c\u529b\uff0c\u5355\u667a\u80fd\u4f53\u4ef7\u503c\u51fd\u6570\u4f18\u5316\u65b9\u6cd5\u6bd4\u53cc\u667a\u80fd\u4f53\u5143\u63d0\u793a\u65b9\u6cd5\u66f4\u6709\u6548\u3002"}}
{"id": "2510.20252", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20252", "abs": "https://arxiv.org/abs/2510.20252", "authors": ["Tianyi Zhang", "Xiaolin Zhou", "Yunzhe Wang", "Erik Cambria", "David Traum", "Rui Mao"], "title": "Individualized Cognitive Simulation in Large Language Models: Evaluating Different Cognitive Representation Methods", "comment": null, "summary": "Individualized cognitive simulation (ICS) aims to build computational models\nthat approximate the thought processes of specific individuals. While large\nlanguage models (LLMs) convincingly mimic surface-level human behavior such as\nrole-play, their ability to simulate deeper individualized cognitive processes\nremains poorly understood. To address this gap, we introduce a novel task that\nevaluates different cognitive representation methods in ICS. We construct a\ndataset from recently published novels (later than the release date of the\ntested LLMs) and propose an 11-condition cognitive evaluation framework to\nbenchmark seven off-the-shelf LLMs in the context of authorial style emulation.\nWe hypothesize that effective cognitive representations can help LLMs generate\nstorytelling that better mirrors the original author. Thus, we test different\ncognitive representations, e.g., linguistic features, concept mappings, and\nprofile-based information. Results show that combining conceptual and\nlinguistic features is particularly effective in ICS, outperforming static\nprofile-based cues in overall evaluation. Importantly, LLMs are more effective\nat mimicking linguistic style than narrative structure, underscoring their\nlimits in deeper cognitive simulation. These findings provide a foundation for\ndeveloping AI systems that adapt to individual ways of thinking and expression,\nadvancing more personalized and human-aligned creative technologies.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e2a\u4f53\u5316\u8ba4\u77e5\u6a21\u62df\u4e2d\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u6784\u5efa\u57fa\u4e8e\u65b0\u51fa\u7248\u5c0f\u8bf4\u7684\u6570\u636e\u96c6\u548c11\u6761\u4ef6\u8ba4\u77e5\u8bc4\u4f30\u6846\u67b6\uff0c\u6d4b\u8bd5\u4e867\u4e2a\u73b0\u6210LLM\u5728\u4f5c\u8005\u98ce\u683c\u6a21\u4eff\u65b9\u9762\u7684\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\u7ed3\u5408\u6982\u5ff5\u548c\u8bed\u8a00\u7279\u5f81\u7684\u65b9\u6cd5\u6700\u6709\u6548\uff0c\u4f46LLM\u5728\u6a21\u4eff\u8bed\u8a00\u98ce\u683c\u65b9\u9762\u4f18\u4e8e\u53d9\u4e8b\u7ed3\u6784\uff0c\u63ed\u793a\u4e86\u5176\u5728\u6df1\u5c42\u8ba4\u77e5\u6a21\u62df\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u8868\u9762\u6a21\u4eff\u4eba\u7c7b\u884c\u4e3a\uff0c\u4f46\u5176\u6a21\u62df\u66f4\u6df1\u5c42\u6b21\u4e2a\u4f53\u5316\u8ba4\u77e5\u8fc7\u7a0b\u7684\u80fd\u529b\u5c1a\u4e0d\u6e05\u695a\u3002\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u8bc4\u4f30\u4e0d\u540c\u8ba4\u77e5\u8868\u5f81\u65b9\u6cd5\u5728\u4e2a\u4f53\u5316\u8ba4\u77e5\u6a21\u62df\u4e2d\u7684\u6548\u679c\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u65b0\u51fa\u7248\u5c0f\u8bf4\uff08\u665a\u4e8e\u6d4b\u8bd5LLM\u53d1\u5e03\u65e5\u671f\uff09\u7684\u6570\u636e\u96c6\uff0c\u63d0\u51fa11\u6761\u4ef6\u8ba4\u77e5\u8bc4\u4f30\u6846\u67b6\uff0c\u6d4b\u8bd57\u4e2a\u73b0\u6210LLM\u5728\u4f5c\u8005\u98ce\u683c\u6a21\u4eff\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u8bc4\u4f30\u4e86\u4e0d\u540c\u8ba4\u77e5\u8868\u5f81\u65b9\u6cd5\uff0c\u5305\u62ec\u8bed\u8a00\u7279\u5f81\u3001\u6982\u5ff5\u6620\u5c04\u548c\u57fa\u4e8e\u6863\u6848\u7684\u4fe1\u606f\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u7ed3\u5408\u6982\u5ff5\u548c\u8bed\u8a00\u7279\u5f81\u7684\u65b9\u6cd5\u5728\u4e2a\u4f53\u5316\u8ba4\u77e5\u6a21\u62df\u4e2d\u7279\u522b\u6709\u6548\uff0c\u5728\u6574\u4f53\u8bc4\u4f30\u4e2d\u4f18\u4e8e\u57fa\u4e8e\u9759\u6001\u6863\u6848\u7684\u7ebf\u7d22\u3002LLM\u5728\u6a21\u4eff\u8bed\u8a00\u98ce\u683c\u65b9\u9762\u6bd4\u6a21\u4eff\u53d9\u4e8b\u7ed3\u6784\u66f4\u6709\u6548\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u5f00\u53d1\u9002\u5e94\u4e2a\u4f53\u601d\u7ef4\u548c\u8868\u8fbe\u65b9\u5f0f\u7684AI\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63a8\u52a8\u4e86\u66f4\u4e2a\u6027\u5316\u548c\u4eba\u7c7b\u5bf9\u9f50\u7684\u521b\u610f\u6280\u672f\u7684\u53d1\u5c55\uff0c\u540c\u65f6\u63ed\u793a\u4e86LLM\u5728\u6df1\u5c42\u8ba4\u77e5\u6a21\u62df\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.20007", "categories": ["cs.CR", "94A60, 68M14, 68Q85", "D.4.6; K.6.5; E.3"], "pdf": "https://arxiv.org/pdf/2510.20007", "abs": "https://arxiv.org/abs/2510.20007", "authors": ["To-Wen Liu", "Matthew Green"], "title": "zk-Agreements: A Privacy-Preserving Way to Establish Deterministic Trust in Confidential Agreements", "comment": "To appear in Financial Cryptography 2026 if accepted", "summary": "Digital transactions currently exceed trillions of dollars annually, yet\ntraditional paper-based agreements remain a bottleneck for automation,\nenforceability, and dispute resolution. Natural language contracts introduce\nambiguity, require manual processing, and lack computational verifiability, all\nof which hinder efficient digital commerce. Computable legal contracts,\nexpressed in machine-readable formats, offer a potential solution by enabling\nautomated execution and verification. Blockchain-based smart contracts further\nstrengthen enforceability and accelerate dispute resolution; however, current\nimplementations risk exposing sensitive agreement terms on public ledgers,\nraising serious privacy and competitive intelligence concerns that limit\nenterprise adoption.\n  We introduce zk-agreements, a protocol designed to transition from\npaper-based trust to cryptographic trust while preserving confidentiality. Our\ndesign combines zero-knowledge proofs to protect private agreement terms,\nsecure two-party computation to enable private compliance evaluation, and smart\ncontracts to guarantee automated enforcement. Together, these components\nachieve both privacy preservation and computational enforceability, resolving\nthe fundamental tension between transparency and confidentiality in\nblockchain-based agreements.", "AI": {"tldr": "zk-agreements\u534f\u8bae\u901a\u8fc7\u7ed3\u5408\u96f6\u77e5\u8bc6\u8bc1\u660e\u3001\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u548c\u667a\u80fd\u5408\u7ea6\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u53ef\u8ba1\u7b97\u7684\u6cd5\u5f8b\u5408\u540c\u81ea\u52a8\u6267\u884c\u3002", "motivation": "\u4f20\u7edf\u7eb8\u8d28\u5408\u540c\u963b\u788d\u6570\u5b57\u5316\u5546\u52a1\u81ea\u52a8\u5316\uff0c\u81ea\u7136\u8bed\u8a00\u5408\u540c\u5b58\u5728\u6b67\u4e49\u4e14\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u6027\uff0c\u800c\u73b0\u6709\u533a\u5757\u94fe\u667a\u80fd\u5408\u540c\u4f1a\u66b4\u9732\u654f\u611f\u6761\u6b3e\uff0c\u5b58\u5728\u9690\u79c1\u548c\u4f01\u4e1a\u91c7\u7528\u969c\u788d\u3002", "method": "\u8bbe\u8ba1zk-agreements\u534f\u8bae\uff0c\u4f7f\u7528\u96f6\u77e5\u8bc6\u8bc1\u660e\u4fdd\u62a4\u79c1\u6709\u5408\u540c\u6761\u6b3e\uff0c\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u5b9e\u73b0\u79c1\u6709\u5408\u89c4\u8bc4\u4f30\uff0c\u667a\u80fd\u5408\u7ea6\u786e\u4fdd\u81ea\u52a8\u6267\u884c\u3002", "result": "\u8be5\u534f\u8bae\u89e3\u51b3\u4e86\u533a\u5757\u94fe\u5408\u540c\u4e2d\u900f\u660e\u6027\u4e0e\u4fdd\u5bc6\u6027\u4e4b\u95f4\u7684\u6839\u672c\u77db\u76fe\uff0c\u5b9e\u73b0\u4e86\u9690\u79c1\u4fdd\u62a4\u548c\u8ba1\u7b97\u53ef\u6267\u884c\u6027\u7684\u5e73\u8861\u3002", "conclusion": "zk-agreements\u4ece\u7eb8\u8d28\u4fe1\u4efb\u5411\u52a0\u5bc6\u4fe1\u4efb\u7684\u8f6c\u53d8\uff0c\u4e3a\u6570\u5b57\u5546\u52a1\u63d0\u4f9b\u4e86\u65e2\u4fdd\u62a4\u9690\u79c1\u53c8\u5177\u5907\u81ea\u52a8\u6267\u884c\u80fd\u529b\u7684\u5408\u540c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20275", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20275", "abs": "https://arxiv.org/abs/2510.20275", "authors": ["Yunzhi Liu", "Haokai Tan", "Rushi Kanjaria", "Lihuan Li", "Flora D. Salim"], "title": "Classical Feature Embeddings Help in BERT-Based Human Mobility Prediction", "comment": "This paper has been accepted by ACM SIGSPATIAL 2025 as a short paper", "summary": "Human mobility forecasting is crucial for disaster relief, city planning, and\npublic health. However, existing models either only model location sequences or\ninclude time information merely as auxiliary input, thereby failing to leverage\nthe rich semantic context provided by points of interest (POIs). To address\nthis, we enrich a BERT-based mobility model with derived temporal descriptors\nand POI embeddings to better capture the semantics underlying human movement.\nWe propose STaBERT (Semantic-Temporal aware BERT), which integrates both POI\nand temporal information at each location to construct a unified, semantically\nenriched representation of mobility. Experimental results show that STaBERT\nsignificantly improves prediction accuracy: for single-city prediction, the\nGEO-BLEU score improved from 0.34 to 0.75; for multi-city prediction, from 0.34\nto 0.56.", "AI": {"tldr": "STaBERT\u6a21\u578b\u901a\u8fc7\u6574\u5408POI\u4fe1\u606f\u548c\u65f6\u95f4\u63cf\u8ff0\u7b26\u6765\u589e\u5f3aBERT\u57fa\u7840\u7684\u4eba\u7c7b\u79fb\u52a8\u6027\u9884\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u7c7b\u79fb\u52a8\u6027\u9884\u6d4b\u6a21\u578b\u8981\u4e48\u53ea\u5efa\u6a21\u4f4d\u7f6e\u5e8f\u5217\uff0c\u8981\u4e48\u4ec5\u5c06\u65f6\u95f4\u4fe1\u606f\u4f5c\u4e3a\u8f85\u52a9\u8f93\u5165\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u5174\u8da3\u70b9(POI)\u63d0\u4f9b\u7684\u4e30\u5bcc\u8bed\u4e49\u4e0a\u4e0b\u6587\u3002", "method": "\u63d0\u51faSTaBERT\u6a21\u578b\uff0c\u5728BERT\u57fa\u7840\u4e0a\u901a\u8fc7POI\u5d4c\u5165\u548c\u63a8\u5bfc\u7684\u65f6\u95f4\u63cf\u8ff0\u7b26\u6765\u4e30\u5bcc\u79fb\u52a8\u6027\u8868\u793a\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u8bed\u4e49\u589e\u5f3a\u79fb\u52a8\u6027\u8868\u5f81\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aSTaBERT\u663e\u8457\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\uff1a\u5355\u57ce\u5e02\u9884\u6d4b\u7684GEO-BLEU\u5f97\u5206\u4ece0.34\u63d0\u5347\u81f30.75\uff1b\u591a\u57ce\u5e02\u9884\u6d4b\u4ece0.34\u63d0\u5347\u81f30.56\u3002", "conclusion": "\u6574\u5408POI\u548c\u65f6\u95f4\u4fe1\u606f\u80fd\u591f\u6709\u6548\u6355\u6349\u4eba\u7c7b\u79fb\u52a8\u7684\u8bed\u4e49\u57fa\u7840\uff0c\u663e\u8457\u6539\u5584\u79fb\u52a8\u6027\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.20310", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20310", "abs": "https://arxiv.org/abs/2510.20310", "authors": ["Mingliang Zhai", "Hansheng Liang", "Xiaomeng Fan", "Zhi Gao", "Chuanhao Li", "Che Sun", "Xu Bin", "Yuwei Wu", "Yunde Jia"], "title": "Multi-Step Reasoning for Embodied Question Answering via Tool Augmentation", "comment": "16 pages, 7 figures, 8 tables", "summary": "Embodied Question Answering (EQA) requires agents to explore 3D environments\nto obtain observations and answer questions related to the scene. Existing\nmethods leverage VLMs to directly explore the environment and answer questions\nwithout explicit thinking or planning, which limits their reasoning ability and\nresults in excessive or inefficient exploration as well as ineffective\nresponses. In this paper, we introduce ToolEQA, an agent that integrates\nexternal tools with multi-step reasoning, where external tools can provide more\nuseful information for completing the task, helping the model derive better\nexploration directions in the next step of reasoning and thus obtaining\nadditional effective information. This enables ToolEQA to generate more\naccurate responses with a shorter exploration distance. To enhance the model's\nability for tool-usage and multi-step reasoning, we further design a novel EQA\ndata generation pipeline that automatically constructs large-scale EQA tasks\nwith reasoning trajectories and corresponding answers. Based on the pipeline,\nwe collect the EQA-RT dataset that contains about 18K tasks, divided into a\ntraining set EQA-RT-Train, and two test sets EQA-RT-Seen (scenes overlapping\nwith the training set) and EQA-RT-Unseen (novel scenes). Experiments on\nEQA-RT-Seen and EQA-RT-Unseen show that ToolEQA improves the success rate by\n9.2~20.2% over state-of-the-art baselines, while outperforming the zero-shot\nToolEQA by 10% in success rate. In addition, ToolEQA also achieves\nstate-of-the-art performance on the HM-EQA, OpenEQA, and EXPRESS-Bench\ndatasets, demonstrating its generality. Our homepage see\nhttps://tooleqa.github.io.", "AI": {"tldr": "ToolEQA\u662f\u4e00\u4e2a\u96c6\u6210\u5916\u90e8\u5de5\u5177\u548c\u591a\u6b65\u63a8\u7406\u7684EQA\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5de5\u5177\u83b7\u53d6\u6709\u7528\u4fe1\u606f\u6765\u6307\u5bfc\u63a2\u7d22\u65b9\u5411\uff0c\u4ece\u800c\u4ee5\u66f4\u77ed\u7684\u63a2\u7d22\u8ddd\u79bb\u751f\u6210\u66f4\u51c6\u786e\u7684\u56de\u7b54\u3002", "motivation": "\u73b0\u6709\u7684EQA\u65b9\u6cd5\u76f4\u63a5\u4f7f\u7528VLM\u63a2\u7d22\u73af\u5883\u800c\u4e0d\u8fdb\u884c\u663e\u5f0f\u601d\u8003\u6216\u89c4\u5212\uff0c\u9650\u5236\u4e86\u63a8\u7406\u80fd\u529b\uff0c\u5bfc\u81f4\u63a2\u7d22\u6548\u7387\u4f4e\u4e0b\u548c\u56de\u7b54\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51faToolEQA\u667a\u80fd\u4f53\uff0c\u96c6\u6210\u5916\u90e8\u5de5\u5177\u8fdb\u884c\u591a\u6b65\u63a8\u7406\uff1b\u8bbe\u8ba1\u81ea\u52a8\u751f\u6210EQA\u4efb\u52a1\u7684\u6570\u636e\u6d41\u6c34\u7ebf\uff0c\u6784\u5efa\u5305\u542b18K\u4efb\u52a1\u7684EQA-RT\u6570\u636e\u96c6\u3002", "result": "\u5728EQA-RT-Seen\u548cEQA-RT-Unseen\u6d4b\u8bd5\u96c6\u4e0a\uff0cToolEQA\u76f8\u6bd4SOTA\u57fa\u7ebf\u6210\u529f\u7387\u63d0\u53479.2~20.2%\uff0c\u6bd4\u96f6\u6837\u672cToolEQA\u63d0\u534710%\uff1b\u5728HM-EQA\u3001OpenEQA\u548cEXPRESS-Bench\u6570\u636e\u96c6\u4e0a\u4e5f\u8fbe\u5230SOTA\u6027\u80fd\u3002", "conclusion": "ToolEQA\u901a\u8fc7\u5de5\u5177\u96c6\u6210\u548c\u591a\u6b65\u63a8\u7406\u663e\u8457\u63d0\u5347\u4e86EQA\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.20129", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20129", "abs": "https://arxiv.org/abs/2510.20129", "authors": ["Yulong Chen", "Yadong Liu", "Jiawen Zhang", "Mu Li", "Chao Huang", "Jie Wen"], "title": "SAID: Empowering Large Language Models with Self-Activating Internal Defense", "comment": null, "summary": "Large Language Models (LLMs), despite advances in safety alignment, remain\nvulnerable to jailbreak attacks designed to circumvent protective mechanisms.\nPrevailing defense strategies rely on external interventions, such as input\nfiltering or output modification, which often lack generalizability and\ncompromise model utility while incurring significant computational overhead. In\nthis work, we introduce a new, training-free defense paradigm, Self-Activating\nInternal Defense (SAID), which reframes the defense task from external\ncorrection to internal capability activation. SAID uniquely leverages the LLM's\nown reasoning abilities to proactively identify and neutralize malicious intent\nthrough a three-stage pipeline: model-native intent distillation to extract\ncore semantics, optimal safety prefix probing to activate latent safety\nawareness, and a conservative aggregation strategy to ensure robust\ndecision-making. Extensive experiments on five open-source LLMs against six\nadvanced jailbreak attacks demonstrate that SAID substantially outperforms\nstate-of-the-art defenses in reducing harmful outputs. Crucially, it achieves\nthis while preserving model performance on benign tasks and incurring minimal\ncomputational overhead. Our work establishes that activating the intrinsic\nsafety mechanisms of LLMs is a more robust and scalable path toward building\nsafer and more reliable aligned AI systems.", "AI": {"tldr": "SAID\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684LLM\u9632\u5fa1\u65b9\u6cd5\uff0c\u901a\u8fc7\u6fc0\u6d3b\u6a21\u578b\u5185\u90e8\u5b89\u5168\u673a\u5236\u6765\u4e3b\u52a8\u8bc6\u522b\u548c\u4e2d\u548c\u6076\u610f\u610f\u56fe\uff0c\u663e\u8457\u964d\u4f4e\u6709\u5bb3\u8f93\u51fa\u540c\u65f6\u4fdd\u6301\u826f\u6027\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLM\u5b89\u5168\u9632\u5fa1\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8\u5e72\u9884\uff0c\u7f3a\u4e4f\u901a\u7528\u6027\u3001\u635f\u5bb3\u6a21\u578b\u6548\u7528\u4e14\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u548c\u53ef\u6269\u5c55\u7684\u5185\u90e8\u9632\u5fa1\u673a\u5236\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u6d41\u6c34\u7ebf\uff1a\u6a21\u578b\u539f\u751f\u610f\u56fe\u84b8\u998f\u63d0\u53d6\u6838\u5fc3\u8bed\u4e49\u3001\u6700\u4f18\u5b89\u5168\u524d\u7f00\u63a2\u6d4b\u6fc0\u6d3b\u6f5c\u5728\u5b89\u5168\u610f\u8bc6\u3001\u4fdd\u5b88\u805a\u5408\u7b56\u7565\u786e\u4fdd\u9c81\u68d2\u51b3\u7b56\u3002", "result": "\u57285\u4e2a\u5f00\u6e90LLM\u548c6\u79cd\u9ad8\u7ea7\u8d8a\u72f1\u653b\u51fb\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSAID\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\uff0c\u5728\u51cf\u5c11\u6709\u5bb3\u8f93\u51fa\u7684\u540c\u65f6\u4fdd\u6301\u826f\u6027\u4efb\u52a1\u6027\u80fd\u4e14\u8ba1\u7b97\u5f00\u9500\u6700\u5c0f\u3002", "conclusion": "\u6fc0\u6d3bLLM\u5185\u5728\u5b89\u5168\u673a\u5236\u662f\u6784\u5efa\u66f4\u5b89\u5168\u53ef\u9760\u5bf9\u9f50AI\u7cfb\u7edf\u7684\u66f4\u9c81\u68d2\u548c\u53ef\u6269\u5c55\u8def\u5f84\u3002"}}
{"id": "2510.20332", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20332", "abs": "https://arxiv.org/abs/2510.20332", "authors": ["Anna Arias-Duart", "Maria Eugenia Cardello", "Atia Cort\u00e9s"], "title": "Bias by Design? How Data Practices Shape Fairness in AI Healthcare Systems", "comment": "8 pages, 3 tables, accepted in AEQUITAS 2025 (not in proceedings)", "summary": "Artificial intelligence (AI) holds great promise for transforming healthcare.\nHowever, despite significant advances, the integration of AI solutions into\nreal-world clinical practice remains limited. A major barrier is the quality\nand fairness of training data, which is often compromised by biased data\ncollection practices. This paper draws on insights from the AI4HealthyAging\nproject, part of Spain's national R&D initiative, where our task was to detect\nbiases during clinical data collection. We identify several types of bias\nacross multiple use cases, including historical, representation, and\nmeasurement biases. These biases manifest in variables such as sex, gender,\nage, habitat, socioeconomic status, equipment, and labeling. We conclude with\npractical recommendations for improving the fairness and robustness of clinical\nproblem design and data collection. We hope that our findings and experience\ncontribute to guiding future projects in the development of fairer AI systems\nin healthcare.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8eAI4HealthyAging\u9879\u76ee\uff0c\u8bc6\u522b\u4e86\u4e34\u5e8a\u6570\u636e\u6536\u96c6\u4e2d\u5b58\u5728\u7684\u591a\u79cd\u504f\u89c1\u7c7b\u578b\uff0c\u5305\u62ec\u5386\u53f2\u504f\u89c1\u3001\u4ee3\u8868\u6027\u504f\u89c1\u548c\u6d4b\u91cf\u504f\u89c1\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u4e34\u5e8a\u95ee\u9898\u8bbe\u8ba1\u548c\u6570\u636e\u6536\u96c6\u516c\u5e73\u6027\u7684\u5b9e\u7528\u5efa\u8bae\u3002", "motivation": "\u5c3d\u7ba1\u4eba\u5de5\u667a\u80fd\u5728\u533b\u7597\u9886\u57df\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u7531\u4e8e\u8bad\u7ec3\u6570\u636e\u7684\u8d28\u91cf\u548c\u516c\u5e73\u6027\u95ee\u9898\uff0cAI\u89e3\u51b3\u65b9\u6848\u5728\u5b9e\u9645\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u7684\u6574\u5408\u4ecd\u7136\u6709\u9650\u3002\u4e3b\u8981\u969c\u788d\u662f\u5b58\u5728\u504f\u89c1\u7684\u6570\u636e\u6536\u96c6\u5b9e\u8df5\u3002", "method": "\u57fa\u4e8e\u897f\u73ed\u7259\u56fd\u5bb6\u7814\u53d1\u8ba1\u5212\u4e2d\u7684AI4HealthyAging\u9879\u76ee\uff0c\u901a\u8fc7\u68c0\u6d4b\u4e34\u5e8a\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\u4e2d\u7684\u504f\u89c1\uff0c\u8bc6\u522b\u4e86\u591a\u79cd\u504f\u89c1\u7c7b\u578b\uff0c\u5305\u62ec\u5728\u6027\u522b\u3001\u5e74\u9f84\u3001\u5c45\u4f4f\u73af\u5883\u3001\u793e\u4f1a\u7ecf\u6d4e\u5730\u4f4d\u3001\u8bbe\u5907\u548c\u6807\u7b7e\u7b49\u53d8\u91cf\u4e2d\u8868\u73b0\u7684\u5386\u53f2\u504f\u89c1\u3001\u4ee3\u8868\u6027\u504f\u89c1\u548c\u6d4b\u91cf\u504f\u89c1\u3002", "result": "\u8bc6\u522b\u4e86\u4e34\u5e8a\u6570\u636e\u6536\u96c6\u4e2d\u5b58\u5728\u7684\u591a\u79cd\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u8fd9\u4e9b\u504f\u89c1\u5f71\u54cd\u4e86AI\u6a21\u578b\u7684\u516c\u5e73\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u6539\u8fdb\u4e34\u5e8a\u95ee\u9898\u8bbe\u8ba1\u548c\u6570\u636e\u6536\u96c6\u516c\u5e73\u6027\u7684\u5b9e\u7528\u5efa\u8bae\uff0c\u5e0c\u671b\u7814\u7a76\u7ed3\u679c\u548c\u7ecf\u9a8c\u80fd\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u516c\u5e73\u7684\u533b\u7597AI\u7cfb\u7edf\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2510.20131", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.20131", "abs": "https://arxiv.org/abs/2510.20131", "authors": ["Mohammed Barhoush"], "title": "Separating Pseudorandom Generators from Logarithmic Pseudorandom States", "comment": "18 pages", "summary": "Pseudorandom generators (PRGs) are a foundational primitive in classical\ncryptography, underpinning a wide range of constructions. In the quantum\nsetting, pseudorandom quantum states (PRSs) were proposed as a potentially\nweaker assumption that might serve as a substitute for PRGs in cryptographic\napplications. Two primary size regimes of PRSs have been studied:\nlogarithmic-size and linear-size. Interestingly, logarithmic PRSs have led to\npowerful cryptographic applications, such as digital signatures and quantum\npublic-key encryption, that have not been realized from their linear\ncounterparts. However, PRGs have only been black-box separated from linear\nPRSs, leaving open the fundamental question of whether PRGs are also separated\nfrom logarithmic PRSs.\n  In this work, we resolve this open problem. We establish a quantum black-box\nseparation between (quantum-evaluable) PRGs and PRSs of either size regime.\nSpecifically, we construct a unitary quantum oracle with inverse access\nrelative to which no black-box construction of PRG from (logarithmic or linear)\nPRS exists. As a direct corollary, we obtain separations between PRGs and\nseveral primitives implied by logarithmic PRSs, including digital signatures\nand quantum public-key encryption.", "AI": {"tldr": "\u672c\u6587\u5efa\u7acb\u4e86\u4f2a\u968f\u673a\u751f\u6210\u5668(PRG)\u4e0e\u4f2a\u968f\u673a\u91cf\u5b50\u6001(PRS)\u4e4b\u95f4\u7684\u91cf\u5b50\u9ed1\u76d2\u5206\u79bb\uff0c\u8bc1\u660e\u5728\u91cf\u5b50\u53ef\u8bc4\u4f30\u7684PRG\u4e0e\u5bf9\u6570\u5927\u5c0f\u6216\u7ebf\u6027\u5927\u5c0f\u7684PRS\u4e4b\u95f4\u4e0d\u5b58\u5728\u9ed1\u76d2\u6784\u9020\u3002", "motivation": "\u89e3\u51b3PRG\u662f\u5426\u4e0e\u5bf9\u6570\u5927\u5c0fPRS\u5206\u79bb\u7684\u5f00\u653e\u95ee\u9898\uff0c\u56e0\u4e3a\u5bf9\u6570PRS\u5df2\u5b9e\u73b0\u5f3a\u5927\u7684\u5bc6\u7801\u5b66\u5e94\u7528\uff08\u5982\u6570\u5b57\u7b7e\u540d\u548c\u91cf\u5b50\u516c\u94a5\u52a0\u5bc6\uff09\uff0c\u800c\u8fd9\u4e9b\u5e94\u7528\u5728\u7ebf\u6027PRS\u4e2d\u5c1a\u672a\u5b9e\u73b0\u3002", "method": "\u6784\u9020\u4e00\u4e2a\u5177\u6709\u9006\u8bbf\u95ee\u6743\u9650\u7684\u9149\u91cf\u5b50\u9884\u8a00\u673a\uff0c\u8bc1\u660e\u5728\u8be5\u9884\u8a00\u673a\u4e0b\u4e0d\u5b58\u5728\u4ecePRS\u5230PRG\u7684\u9ed1\u76d2\u6784\u9020\u3002", "result": "\u6210\u529f\u5efa\u7acb\u4e86PRG\u4e0ePRS\uff08\u5305\u62ec\u5bf9\u6570\u5927\u5c0f\u548c\u7ebf\u6027\u5927\u5c0f\uff09\u4e4b\u95f4\u7684\u91cf\u5b50\u9ed1\u76d2\u5206\u79bb\uff0c\u5e76\u4f5c\u4e3a\u63a8\u8bba\u83b7\u5f97\u4e86PRG\u4e0e\u6570\u5b57\u7b7e\u540d\u3001\u91cf\u5b50\u516c\u94a5\u52a0\u5bc6\u7b49\u539f\u8bed\u4e4b\u95f4\u7684\u5206\u79bb\u3002", "conclusion": "PRG\u4e0ePRS\u5728\u91cf\u5b50\u9ed1\u76d2\u6a21\u578b\u4e0b\u662f\u5206\u79bb\u7684\uff0c\u8fd9\u4e00\u7ed3\u679c\u5bf9\u7406\u89e3\u91cf\u5b50\u5bc6\u7801\u5b66\u4e2d\u4e0d\u540c\u539f\u8bed\u4e4b\u95f4\u7684\u5173\u7cfb\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.20337", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20337", "abs": "https://arxiv.org/abs/2510.20337", "authors": ["Clara Maathuis", "Kasper Cools"], "title": "Collateral Damage Assessment Model for AI System Target Engagement in Military Operations", "comment": "Accepted at MILCOM 2025 WS07", "summary": "In an era where AI (Artificial Intelligence) systems play an increasing role\nin the battlefield, ensuring responsible targeting demands rigorous assessment\nof potential collateral effects. In this context, a novel collateral damage\nassessment model for target engagement of AI systems in military operations is\nintroduced. The model integrates temporal, spatial, and force dimensions within\na unified Knowledge Representation and Reasoning (KRR) architecture following a\ndesign science methodological approach. Its layered structure captures the\ncategories and architectural components of the AI systems to be engaged\ntogether with corresponding engaging vectors and contextual aspects. At the\nsame time, spreading, severity, likelihood, and evaluation metrics are\nconsidered in order to provide a clear representation enhanced by transparent\nreasoning mechanisms. Further, the model is demonstrated and evaluated through\ninstantiation which serves as a basis for further dedicated efforts that aim at\nbuilding responsible and trustworthy intelligent systems for assessing the\neffects produced by engaging AI systems in military operations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u519b\u4e8b\u884c\u52a8\u4e2dAI\u7cfb\u7edf\u76ee\u6807\u6253\u51fb\u7684\u9644\u5e26\u635f\u5bb3\u8bc4\u4f30\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u6574\u5408\u4e86\u65f6\u95f4\u3001\u7a7a\u95f4\u548c\u529b\u91cf\u7ef4\u5ea6\uff0c\u91c7\u7528\u77e5\u8bc6\u8868\u793a\u4e0e\u63a8\u7406\u67b6\u6784\uff0c\u901a\u8fc7\u5206\u5c42\u7ed3\u6784\u6355\u83b7AI\u7cfb\u7edf\u7c7b\u522b\u3001\u653b\u51fb\u5411\u91cf\u548c\u4e0a\u4e0b\u6587\u56e0\u7d20\uff0c\u5e76\u8003\u8651\u4f20\u64ad\u3001\u4e25\u91cd\u6027\u3001\u53ef\u80fd\u6027\u548c\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u5728AI\u7cfb\u7edf\u5728\u6218\u573a\u4e2d\u4f5c\u7528\u65e5\u76ca\u589e\u5f3a\u7684\u65f6\u4ee3\uff0c\u786e\u4fdd\u8d1f\u8d23\u4efb\u7684\u6253\u51fb\u9700\u8981\u4e25\u683c\u8bc4\u4f30\u6f5c\u5728\u7684\u9644\u5e26\u6548\u5e94\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8bc4\u4f30AI\u7cfb\u7edf\u6253\u51fb\u6548\u679c\u7684\u53ef\u9760\u6a21\u578b\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u65b9\u6cd5\u8bba\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u77e5\u8bc6\u8868\u793a\u4e0e\u63a8\u7406\u67b6\u6784\uff0c\u6574\u5408\u65f6\u95f4\u3001\u7a7a\u95f4\u548c\u529b\u91cf\u7ef4\u5ea6\uff0c\u901a\u8fc7\u5206\u5c42\u7ed3\u6784\u6355\u83b7AI\u7cfb\u7edf\u7c7b\u522b\u3001\u653b\u51fb\u5411\u91cf\u548c\u4e0a\u4e0b\u6587\u56e0\u7d20\uff0c\u5e76\u8003\u8651\u4f20\u64ad\u3001\u4e25\u91cd\u6027\u3001\u53ef\u80fd\u6027\u548c\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u9644\u5e26\u635f\u5bb3\u8bc4\u4f30\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5b9e\u4f8b\u5316\u8fdb\u884c\u4e86\u6f14\u793a\u548c\u8bc4\u4f30\uff0c\u4e3a\u6784\u5efa\u8d1f\u8d23\u4efb\u548c\u53ef\u4fe1\u8d56\u7684\u667a\u80fd\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u8bc4\u4f30\u519b\u4e8b\u884c\u52a8\u4e2dAI\u7cfb\u7edf\u6253\u51fb\u6548\u679c\u63d0\u4f9b\u4e86\u900f\u660e\u63a8\u7406\u673a\u5236\uff0c\u662f\u6784\u5efa\u8d1f\u8d23\u4efb\u548c\u53ef\u4fe1\u8d56\u667a\u80fd\u7cfb\u7edf\u7684\u91cd\u8981\u57fa\u7840\u3002"}}
{"id": "2510.20223", "categories": ["cs.CR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.20223", "abs": "https://arxiv.org/abs/2510.20223", "authors": ["Divyanshu Kumar", "Shreyas Jena", "Nitin Aravind Birur", "Tanay Baswa", "Sahil Agarwal", "Prashanth Harshangi"], "title": "Beyond Text: Multimodal Jailbreaking of Vision-Language and Audio Models through Perceptually Simple Transformations", "comment": null, "summary": "Multimodal large language models (MLLMs) have achieved remarkable progress,\nyet remain critically vulnerable to adversarial attacks that exploit weaknesses\nin cross-modal processing. We present a systematic study of multimodal\njailbreaks targeting both vision-language and audio-language models, showing\nthat even simple perceptual transformations can reliably bypass\nstate-of-the-art safety filters. Our evaluation spans 1,900 adversarial prompts\nacross three high-risk safety categories harmful content, CBRN (Chemical,\nBiological, Radiological, Nuclear), and CSEM (Child Sexual Exploitation\nMaterial) tested against seven frontier models. We explore the effectiveness of\nattack techniques on MLLMs, including FigStep-Pro (visual keyword\ndecomposition), Intelligent Masking (semantic obfuscation), and audio\nperturbations (Wave-Echo, Wave-Pitch, Wave-Speed). The results reveal severe\nvulnerabilities: models with almost perfect text-only safety (0\\% ASR) suffer\n>75\\% attack success under perceptually modified inputs, with FigStep-Pro\nachieving up to 89\\% ASR in Llama-4 variants. Audio-based attacks further\nuncover provider-specific weaknesses, with even basic modality transfer\nyielding 25\\% ASR for technical queries. These findings expose a critical gap\nbetween text-centric alignment and multimodal threats, demonstrating that\ncurrent safeguards fail to generalize across cross-modal attacks. The\naccessibility of these attacks, which require minimal technical expertise,\nsuggests that robust multimodal AI safety will require a paradigm shift toward\nbroader semantic-level reasoning to mitigate possible risks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u9488\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u7684\u8d8a\u72f1\u653b\u51fb\uff0c\u53d1\u73b0\u5373\u4f7f\u7b80\u5355\u7684\u611f\u77e5\u53d8\u6362\u4e5f\u80fd\u53ef\u9760\u7ed5\u8fc7\u6700\u5148\u8fdb\u7684\u5b89\u5168\u8fc7\u6ee4\u5668\uff0c\u5728\u89c6\u89c9-\u8bed\u8a00\u548c\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u4e2d\u66b4\u9732\u51fa\u4e25\u91cd\u6f0f\u6d1e\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u8de8\u6a21\u6001\u5904\u7406\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u8106\u5f31\u6027\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5176\u5bf9\u5bf9\u6297\u6027\u653b\u51fb\u7684\u62b5\u6297\u529b\u3002", "method": "\u4f7f\u75281,900\u4e2a\u5bf9\u6297\u6027\u63d0\u793a\u5728\u4e09\u4e2a\u9ad8\u98ce\u9669\u5b89\u5168\u7c7b\u522b\uff08\u6709\u5bb3\u5185\u5bb9\u3001CBRN\u3001CSEM\uff09\u4e0a\u6d4b\u8bd5\u4e03\u4e2a\u524d\u6cbf\u6a21\u578b\uff0c\u63a2\u7d22\u4e86FigStep-Pro\uff08\u89c6\u89c9\u5173\u952e\u8bcd\u5206\u89e3\uff09\u3001\u667a\u80fd\u63a9\u7801\uff08\u8bed\u4e49\u6df7\u6dc6\uff09\u548c\u97f3\u9891\u6270\u52a8\uff08Wave-Echo\u3001Wave-Pitch\u3001Wave-Speed\uff09\u7b49\u653b\u51fb\u6280\u672f\u7684\u6709\u6548\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4e25\u91cd\u6f0f\u6d1e\uff1a\u6587\u672c\u5b89\u5168\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u6a21\u578b\uff080% ASR\uff09\u5728\u611f\u77e5\u4fee\u6539\u8f93\u5165\u4e0b\u906d\u53d7>75%\u653b\u51fb\u6210\u529f\u7387\uff0cFigStep-Pro\u5728Llama-4\u53d8\u4f53\u4e2d\u8fbe\u523089% ASR\u3002\u97f3\u9891\u653b\u51fb\u8fdb\u4e00\u6b65\u63ed\u793a\u4e86\u4f9b\u5e94\u5546\u7279\u5b9a\u5f31\u70b9\uff0c\u5373\u4f7f\u57fa\u672c\u6a21\u6001\u8f6c\u79fb\u4e5f\u80fd\u5728\u6280\u672f\u67e5\u8be2\u4e2d\u83b7\u5f9725% ASR\u3002", "conclusion": "\u5f53\u524d\u5b89\u5168\u63aa\u65bd\u65e0\u6cd5\u6cdb\u5316\u5230\u8de8\u6a21\u6001\u653b\u51fb\uff0c\u66b4\u9732\u4e86\u6587\u672c\u4e2d\u5fc3\u5bf9\u9f50\u4e0e\u591a\u6a21\u6001\u5a01\u80c1\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd\u3002\u8fd9\u4e9b\u653b\u51fb\u7684\u53ef\u8bbf\u95ee\u6027\u8868\u660e\uff0c\u7a33\u5065\u7684\u591a\u6a21\u6001AI\u5b89\u5168\u9700\u8981\u5411\u66f4\u5e7f\u6cdb\u7684\u8bed\u4e49\u7ea7\u63a8\u7406\u8fdb\u884c\u8303\u5f0f\u8f6c\u53d8\u3002"}}
{"id": "2510.20345", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20345", "abs": "https://arxiv.org/abs/2510.20345", "authors": ["Haonan Bian"], "title": "LLM-empowered knowledge graph construction: A survey", "comment": null, "summary": "Knowledge Graphs (KGs) have long served as a fundamental infrastructure for\nstructured knowledge representation and reasoning. With the advent of Large\nLanguage Models (LLMs), the construction of KGs has entered a new\nparadigm-shifting from rule-based and statistical pipelines to language-driven\nand generative frameworks. This survey provides a comprehensive overview of\nrecent progress in LLM-empowered knowledge graph construction, systematically\nanalyzing how LLMs reshape the classical three-layered pipeline of ontology\nengineering, knowledge extraction, and knowledge fusion.\n  We first revisit traditional KG methodologies to establish conceptual\nfoundations, and then review emerging LLM-driven approaches from two\ncomplementary perspectives: schema-based paradigms, which emphasize structure,\nnormalization, and consistency; and schema-free paradigms, which highlight\nflexibility, adaptability, and open discovery. Across each stage, we synthesize\nrepresentative frameworks, analyze their technical mechanisms, and identify\ntheir limitations.\n  Finally, the survey outlines key trends and future research directions,\nincluding KG-based reasoning for LLMs, dynamic knowledge memory for agentic\nsystems, and multimodal KG construction. Through this systematic review, we aim\nto clarify the evolving interplay between LLMs and knowledge graphs, bridging\nsymbolic knowledge engineering and neural semantic understanding toward the\ndevelopment of adaptive, explainable, and intelligent knowledge systems.", "AI": {"tldr": "\u672c\u8c03\u67e5\u7cfb\u7edf\u56de\u987e\u4e86LLM\u8d4b\u80fd\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5206\u6790\u4e86LLM\u5982\u4f55\u91cd\u5851\u4f20\u7edf\u7684\u672c\u4f53\u5de5\u7a0b\u3001\u77e5\u8bc6\u62bd\u53d6\u548c\u77e5\u8bc6\u878d\u5408\u4e09\u5c42\u6d41\u6c34\u7ebf\uff0c\u5e76\u63a2\u8ba8\u4e86\u57fa\u4e8e\u6a21\u5f0f\u548c\u65e0\u6a21\u5f0f\u4e24\u79cd\u6784\u5efa\u8303\u5f0f\u7684\u4e92\u8865\u4f18\u52bf\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u51fa\u73b0\uff0c\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u6b63\u4ece\u57fa\u4e8e\u89c4\u5219\u548c\u7edf\u8ba1\u7684\u6d41\u6c34\u7ebf\u8f6c\u5411\u8bed\u8a00\u9a71\u52a8\u548c\u751f\u6210\u6846\u67b6\uff0c\u9700\u8981\u7cfb\u7edf\u68b3\u7406\u8fd9\u4e00\u8303\u5f0f\u8f6c\u53d8\u7684\u6280\u672f\u8fdb\u5c55\u548c\u672a\u6765\u65b9\u5411\u3002", "method": "\u9996\u5148\u56de\u987e\u4f20\u7edfKG\u65b9\u6cd5\u5efa\u7acb\u6982\u5ff5\u57fa\u7840\uff0c\u7136\u540e\u4ece\u57fa\u4e8e\u6a21\u5f0f\uff08\u5f3a\u8c03\u7ed3\u6784\u3001\u89c4\u8303\u5316\u548c\u4e00\u81f4\u6027\uff09\u548c\u65e0\u6a21\u5f0f\uff08\u5f3a\u8c03\u7075\u6d3b\u6027\u3001\u9002\u5e94\u6027\u548c\u5f00\u653e\u53d1\u73b0\uff09\u4e24\u4e2a\u4e92\u8865\u89c6\u89d2\u5206\u6790\u65b0\u5174\u7684LLM\u9a71\u52a8\u65b9\u6cd5\uff0c\u7efc\u5408\u4ee3\u8868\u6027\u6846\u67b6\u5e76\u5206\u6790\u6280\u672f\u673a\u5236\u3002", "result": "\u7cfb\u7edf\u5206\u6790\u4e86LLM\u5982\u4f55\u91cd\u5851KG\u6784\u5efa\u7684\u5404\u9636\u6bb5\uff0c\u8bc6\u522b\u4e86\u4e0d\u540c\u8303\u5f0f\u7684\u6280\u672f\u7279\u70b9\u548c\u5c40\u9650\u6027\uff0c\u4e3a\u7406\u89e3LLM\u4e0eKG\u7684\u4ea4\u4e92\u6f14\u8fdb\u63d0\u4f9b\u4e86\u6e05\u6670\u6846\u67b6\u3002", "conclusion": "\u8be5\u8c03\u67e5\u65e8\u5728\u6f84\u6e05LLM\u4e0e\u77e5\u8bc6\u56fe\u8c31\u4e4b\u95f4\u4e0d\u65ad\u6f14\u53d8\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u5f25\u5408\u7b26\u53f7\u77e5\u8bc6\u5de5\u7a0b\u548c\u795e\u7ecf\u8bed\u4e49\u7406\u89e3\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u63a8\u52a8\u5f00\u53d1\u81ea\u9002\u5e94\u3001\u53ef\u89e3\u91ca\u548c\u667a\u80fd\u7684\u77e5\u8bc6\u7cfb\u7edf\u3002"}}
{"id": "2510.20377", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20377", "abs": "https://arxiv.org/abs/2510.20377", "authors": ["Tianyi Zhang", "Florian Mai", "Lucie Flek"], "title": "IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation", "comment": null, "summary": "Continual pretraining promises to adapt large language models (LLMs) to new\ndomains using only unlabeled test-time data, but naively applying standard\nself-supervised objectives to instruction-tuned models is known to degrade\ntheir instruction-following capability and semantic representations. Existing\nfixes assume access to the original base model or rely on knowledge from an\nexternal domain-specific database - both of which pose a realistic barrier in\nsettings where the base model weights are withheld for safety reasons or\nreliable external corpora are unavailable. In this work, we propose\nInstruction-Knowledge-Aware Continual Adaptation (IKnow), a simple and general\nframework that formulates novel self-supervised objectives in the\ninstruction-response dialogue format. Rather than depend- ing on external\nresources, IKnow leverages domain knowledge embedded within the text itself and\nlearns to encode it at a deeper semantic level.", "AI": {"tldr": "IKnow\u662f\u4e00\u4e2a\u6301\u7eed\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u5236\u5b9a\u65b0\u7684\u81ea\u76d1\u7763\u76ee\u6807\uff0c\u5728\u6307\u4ee4-\u54cd\u5e94\u5bf9\u8bed\u683c\u5f0f\u4e2d\u5229\u7528\u6587\u672c\u5185\u5d4c\u7684\u9886\u57df\u77e5\u8bc6\uff0c\u65e0\u9700\u4f9d\u8d56\u5916\u90e8\u8d44\u6e90\u6216\u539f\u59cb\u57fa\u7840\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u5728\u6301\u7eed\u9884\u8bad\u7ec3\u65f6\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u548c\u8bed\u4e49\u8868\u793a\u9000\u5316\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u65e0\u6cd5\u8bbf\u95ee\u539f\u59cb\u57fa\u7840\u6a21\u578b\u6216\u53ef\u9760\u5916\u90e8\u8bed\u6599\u5e93\u7684\u73b0\u5b9e\u573a\u666f\u4e2d\u3002", "method": "\u63d0\u51faIKnow\u6846\u67b6\uff0c\u5728\u6307\u4ee4-\u54cd\u5e94\u5bf9\u8bed\u683c\u5f0f\u4e2d\u5236\u5b9a\u65b0\u7684\u81ea\u76d1\u7763\u76ee\u6807\uff0c\u5229\u7528\u6587\u672c\u5185\u5d4c\u7684\u9886\u57df\u77e5\u8bc6\u8fdb\u884c\u6df1\u5ea6\u8bed\u4e49\u7f16\u7801\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u9002\u5e94\u65b0\u9886\u57df\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u3002", "conclusion": "IKnow\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4e0d\u4f9d\u8d56\u5916\u90e8\u8d44\u6e90\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u8bed\u8a00\u6a21\u578b\u7684\u6301\u7eed\u9002\u5e94\u3002"}}
{"id": "2510.20300", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.20300", "abs": "https://arxiv.org/abs/2510.20300", "authors": ["Haojie Ji", "Long Jin", "Haowen Li", "Chongshi Xin", "Te Hu"], "title": "Privacy Protection of Automotive Location Data Based on Format-Preserving Encryption of Geographical Coordinates", "comment": null, "summary": "There are increasing risks of privacy disclosure when sharing the automotive\nlocation data in particular functions such as route navigation, driving\nmonitoring and vehicle scheduling. These risks could lead to the attacks\nincluding user behavior recognition, sensitive location inference and\ntrajectory reconstruction. In order to mitigate the data security risk caused\nby the automotive location sharing, this paper proposes a high-precision\nprivacy protection mechanism based on format-preserving encryption (FPE) of\ngeographical coordinates. The automotive coordinate data key mapping mechanism\nis designed to reduce to the accuracy loss of the geographical location data\ncaused by the repeated encryption and decryption. The experimental results\ndemonstrate that the average relative distance retention rate (RDR) reached\n0.0844, and the number of hotspots in the critical area decreased by 98.9%\nafter encryption. To evaluate the accuracy loss of the proposed encryption\nalgorithm on automotive geographical location data, this paper presents the\nexperimental analysis of decryption accuracy, and the result indicates that the\ndecrypted coordinate data achieves a restoration accuracy of 100%. This work\npresents a high-precision privacy protection method for automotive location\ndata, thereby providing an efficient data security solution for the sensitive\ndata sharing in autonomous driving.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u683c\u5f0f\u4fdd\u6301\u52a0\u5bc6(FPE)\u7684\u5730\u7406\u5750\u6807\u9ad8\u7cbe\u5ea6\u9690\u79c1\u4fdd\u62a4\u673a\u5236\uff0c\u7528\u4e8e\u89e3\u51b3\u6c7d\u8f66\u4f4d\u7f6e\u6570\u636e\u5171\u4eab\u4e2d\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u8bbe\u8ba1\u5750\u6807\u6570\u636e\u5bc6\u94a5\u6620\u5c04\u673a\u5236\u51cf\u5c11\u91cd\u590d\u52a0\u5bc6\u89e3\u5bc6\u9020\u6210\u7684\u5730\u7406\u4f4d\u7f6e\u7cbe\u5ea6\u635f\u5931\u3002", "motivation": "\u6c7d\u8f66\u4f4d\u7f6e\u6570\u636e\u5171\u4eab\u5728\u8def\u7ebf\u5bfc\u822a\u3001\u9a7e\u9a76\u76d1\u63a7\u548c\u8f66\u8f86\u8c03\u5ea6\u7b49\u529f\u80fd\u4e2d\u5b58\u5728\u65e5\u76ca\u589e\u957f\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u53ef\u80fd\u5bfc\u81f4\u7528\u6237\u884c\u4e3a\u8bc6\u522b\u3001\u654f\u611f\u4f4d\u7f6e\u63a8\u65ad\u548c\u8f68\u8ff9\u91cd\u5efa\u7b49\u653b\u51fb\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u683c\u5f0f\u4fdd\u6301\u52a0\u5bc6(FPE)\u7684\u5730\u7406\u5750\u6807\u9690\u79c1\u4fdd\u62a4\u673a\u5236\uff0c\u8bbe\u8ba1\u4e86\u6c7d\u8f66\u5750\u6807\u6570\u636e\u5bc6\u94a5\u6620\u5c04\u673a\u5236\u6765\u51cf\u5c11\u91cd\u590d\u52a0\u5bc6\u89e3\u5bc6\u8fc7\u7a0b\u4e2d\u7684\u7cbe\u5ea6\u635f\u5931\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5e73\u5747\u76f8\u5bf9\u8ddd\u79bb\u4fdd\u6301\u7387(RDR)\u8fbe\u52300.0844\uff0c\u5173\u952e\u533a\u57df\u70ed\u70b9\u6570\u91cf\u51cf\u5c11\u4e8698.9%\uff0c\u89e3\u5bc6\u5750\u6807\u6570\u636e\u5b9e\u73b0\u4e86100%\u7684\u6062\u590d\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u6c7d\u8f66\u4f4d\u7f6e\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u7cbe\u5ea6\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u654f\u611f\u6570\u636e\u5171\u4eab\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u6570\u636e\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20402", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20402", "abs": "https://arxiv.org/abs/2510.20402", "authors": ["Neil Maiden", "Konstantinos Zachos", "James Lockerbie", "Kostas Petrianakis", "Amanda Brown"], "title": "A computational model and tool for generating more novel opportunities in professional innovation processes", "comment": null, "summary": "This paper presents a new computational model of creative outcomes, informed\nby creativity theories and techniques, which was implemented to generate more\nnovel opportunities for innovation projects. The model implemented five\nfunctions that were developed to contribute to the generation of innovation\nopportunities with higher novelty without loss of usefulness. The model was\nevaluated using opportunities generated for an innovation project in the\nhospitality sector. The evaluation revealed that the computational model\ngenerated outcomes that were more novel and/or useful than outcomes from\nNotebook LM and ChatGPT4o. However, not all model functions contributed to the\ngeneration of more novel opportunities, leading to new directions for further\nmodel development", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u521b\u9020\u6027\u7ed3\u679c\u8ba1\u7b97\u6a21\u578b\uff0c\u901a\u8fc7\u4e94\u4e2a\u529f\u80fd\u51fd\u6570\u751f\u6210\u66f4\u5177\u65b0\u9896\u6027\u7684\u521b\u65b0\u673a\u4f1a\uff0c\u5728\u9152\u5e97\u4e1a\u521b\u65b0\u9879\u76ee\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u6a21\u578b\u6bd4Notebook LM\u548cChatGPT4o\u80fd\u4ea7\u751f\u66f4\u65b0\u9896\u548c/\u6216\u66f4\u6709\u7528\u7684\u7ed3\u679c\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u57fa\u4e8e\u521b\u9020\u529b\u7406\u8bba\u548c\u6280\u672f\u7684\u8ba1\u7b97\u6a21\u578b\uff0c\u65e8\u5728\u4e3a\u521b\u65b0\u9879\u76ee\u751f\u6210\u66f4\u5177\u65b0\u9896\u6027\u7684\u673a\u4f1a\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u7528\u6027\u3002", "method": "\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5305\u542b\u4e94\u4e2a\u529f\u80fd\u51fd\u6570\u7684\u8ba1\u7b97\u6a21\u578b\uff0c\u8fd9\u4e9b\u51fd\u6570\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u5728\u4e0d\u635f\u5931\u5b9e\u7528\u6027\u7684\u524d\u63d0\u4e0b\u751f\u6210\u66f4\u9ad8\u65b0\u9896\u6027\u7684\u521b\u65b0\u673a\u4f1a\u3002", "result": "\u5728\u9152\u5e97\u4e1a\u521b\u65b0\u9879\u76ee\u7684\u8bc4\u4f30\u4e2d\uff0c\u8be5\u8ba1\u7b97\u6a21\u578b\u751f\u6210\u7684\u7ed3\u679c\u6bd4Notebook LM\u548cChatGPT4o\u66f4\u65b0\u9896\u548c/\u6216\u66f4\u6709\u7528\uff0c\u4f46\u5e76\u975e\u6240\u6709\u6a21\u578b\u529f\u80fd\u90fd\u5bf9\u751f\u6210\u66f4\u65b0\u9896\u673a\u4f1a\u6709\u8d21\u732e\u3002", "conclusion": "\u8be5\u8ba1\u7b97\u6a21\u578b\u5728\u751f\u6210\u65b0\u9896\u521b\u65b0\u673a\u4f1a\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\uff0c\u4f46\u90e8\u5206\u529f\u80fd\u6548\u679c\u6709\u9650\uff0c\u4e3a\u540e\u7eed\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2510.20314", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20314", "abs": "https://arxiv.org/abs/2510.20314", "authors": ["Wu Yichao", "Wang Yirui", "Ding Panpan", "Wang Hailong", "Zhu Bingqian", "Liu Chun"], "title": "Enhancing Security in Deep Reinforcement Learning: A Comprehensive Survey on Adversarial Attacks and Defenses", "comment": null, "summary": "With the wide application of deep reinforcement learning (DRL) techniques in\ncomplex fields such as autonomous driving, intelligent manufacturing, and smart\nhealthcare, how to improve its security and robustness in dynamic and\nchangeable environments has become a core issue in current research. Especially\nin the face of adversarial attacks, DRL may suffer serious performance\ndegradation or even make potentially dangerous decisions, so it is crucial to\nensure their stability in security-sensitive scenarios. In this paper, we first\nintroduce the basic framework of DRL and analyze the main security challenges\nfaced in complex and changing environments. In addition, this paper proposes an\nadversarial attack classification framework based on perturbation type and\nattack target and reviews the mainstream adversarial attack methods against DRL\nin detail, including various attack methods such as perturbation state space,\naction space, reward function and model space. To effectively counter the\nattacks, this paper systematically summarizes various current robustness\ntraining strategies, including adversarial training, competitive training,\nrobust learning, adversarial detection, defense distillation and other related\ndefense techniques, we also discuss the advantages and shortcomings of these\nmethods in improving the robustness of DRL. Finally, this paper looks into the\nfuture research direction of DRL in adversarial environments, emphasizing the\nresearch needs in terms of improving generalization, reducing computational\ncomplexity, and enhancing scalability and explainability, aiming to provide\nvaluable references and directions for researchers.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6270\u52a8\u7c7b\u578b\u548c\u653b\u51fb\u76ee\u6807\u7684\u5bf9\u6297\u653b\u51fb\u5206\u7c7b\u6846\u67b6\uff0c\u603b\u7ed3\u4e86\u4e3b\u6d41\u9632\u5fa1\u6280\u672f\uff0c\u5e76\u5c55\u671b\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u81ea\u52a8\u9a7e\u9a76\u3001\u667a\u80fd\u5236\u9020\u7b49\u5b89\u5168\u654f\u611f\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u63d0\u9ad8\u5176\u5728\u52a8\u6001\u591a\u53d8\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u6210\u4e3a\u6838\u5fc3\u7814\u7a76\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9762\u5bf9\u5bf9\u6297\u653b\u51fb\u65f6\u9632\u6b62\u6027\u80fd\u4e0b\u964d\u548c\u5371\u9669\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6270\u52a8\u7c7b\u578b\u548c\u653b\u51fb\u76ee\u6807\u7684\u5bf9\u6297\u653b\u51fb\u5206\u7c7b\u6846\u67b6\uff0c\u8be6\u7ec6\u56de\u987e\u4e86\u9488\u5bf9\u72b6\u6001\u7a7a\u95f4\u3001\u52a8\u4f5c\u7a7a\u95f4\u3001\u5956\u52b1\u51fd\u6570\u548c\u6a21\u578b\u7a7a\u95f4\u7684\u4e3b\u6d41\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u7cfb\u7edf\u603b\u7ed3\u4e86\u5305\u62ec\u5bf9\u6297\u8bad\u7ec3\u3001\u7ade\u4e89\u8bad\u7ec3\u3001\u9c81\u68d2\u5b66\u4e60\u3001\u5bf9\u6297\u68c0\u6d4b\u3001\u9632\u5fa1\u84b8\u998f\u7b49\u591a\u79cd\u9c81\u68d2\u6027\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u6784\u5efa\u4e86\u5b8c\u6574\u7684\u5bf9\u6297\u653b\u51fb\u5206\u7c7b\u4f53\u7cfb\uff0c\u7cfb\u7edf\u68b3\u7406\u4e86\u73b0\u6709\u9632\u5fa1\u6280\u672f\u7684\u4f18\u7f3a\u70b9\uff0c\u4e3a\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u6280\u672f\u53c2\u8003\u3002", "conclusion": "\u672a\u6765\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u7814\u7a76\u5e94\u91cd\u70b9\u5173\u6ce8\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u3001\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3001\u589e\u5f3a\u53ef\u6269\u5c55\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7b49\u65b9\u9762\uff0c\u4e3a\u5b89\u5168\u654f\u611f\u5e94\u7528\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20457", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20457", "abs": "https://arxiv.org/abs/2510.20457", "authors": ["Louis Mozart Kamdem Teyou", "Luke Friedrichs", "N'Dah Jean Kouagou", "Caglar Demir", "Yasir Mahmood", "Stefan Heindorf", "Axel-Cyrille Ngonga Ngomo"], "title": "Neural Reasoning for Robust Instance Retrieval in $\\mathcal{SHOIQ}$", "comment": "Accepted as a full research paper at K-CAP 2025", "summary": "Concept learning exploits background knowledge in the form of description\nlogic axioms to learn explainable classification models from knowledge bases.\nDespite recent breakthroughs in neuro-symbolic concept learning, most\napproaches still cannot be deployed on real-world knowledge bases. This is due\nto their use of description logic reasoners, which are not robust against\ninconsistencies nor erroneous data. We address this challenge by presenting a\nnovel neural reasoner dubbed EBR. Our reasoner relies on embeddings to\napproximate the results of a symbolic reasoner. We show that EBR solely\nrequires retrieving instances for atomic concepts and existential restrictions\nto retrieve or approximate the set of instances of any concept in the\ndescription logic $\\mathcal{SHOIQ}$. In our experiments, we compare EBR with\nstate-of-the-art reasoners. Our results suggest that EBR is robust against\nmissing and erroneous data in contrast to existing reasoners.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEBR\u7684\u795e\u7ecf\u63a8\u7406\u5668\uff0c\u901a\u8fc7\u5d4c\u5165\u6765\u8fd1\u4f3c\u7b26\u53f7\u63a8\u7406\u5668\u7684\u7ed3\u679c\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u63cf\u8ff0\u903b\u8f91\u63a8\u7406\u5668\u5728\u73b0\u5b9e\u77e5\u8bc6\u5e93\u4e2d\u56e0\u6570\u636e\u4e0d\u4e00\u81f4\u548c\u9519\u8bef\u800c\u65e0\u6cd5\u90e8\u7f72\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u795e\u7ecf\u7b26\u53f7\u6982\u5ff5\u5b66\u4e60\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u63cf\u8ff0\u903b\u8f91\u63a8\u7406\u5668\uff0c\u4f46\u8fd9\u4e9b\u63a8\u7406\u5668\u5bf9\u4e0d\u4e00\u81f4\u548c\u9519\u8bef\u6570\u636e\u4e0d\u9c81\u68d2\uff0c\u65e0\u6cd5\u5728\u73b0\u5b9e\u77e5\u8bc6\u5e93\u4e2d\u90e8\u7f72\u3002", "method": "\u5f00\u53d1EBR\u795e\u7ecf\u63a8\u7406\u5668\uff0c\u4ec5\u9700\u68c0\u7d22\u539f\u5b50\u6982\u5ff5\u548c\u5b58\u5728\u9650\u5236\u7684\u5b9e\u4f8b\uff0c\u5c31\u80fd\u68c0\u7d22\u6216\u8fd1\u4f3cSHOIQ\u63cf\u8ff0\u903b\u8f91\u4e2d\u4efb\u4f55\u6982\u5ff5\u7684\u5b9e\u4f8b\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eEBR\u5728\u7f3a\u5931\u548c\u9519\u8bef\u6570\u636e\u60c5\u51b5\u4e0b\u5177\u6709\u9c81\u68d2\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u63a8\u7406\u5668\u3002", "conclusion": "EBR\u4e3a\u5728\u73b0\u5b9e\u4e16\u754c\u77e5\u8bc6\u5e93\u4e2d\u90e8\u7f72\u795e\u7ecf\u7b26\u53f7\u6982\u5ff5\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20467", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.20467", "abs": "https://arxiv.org/abs/2510.20467", "authors": ["Yiwen Peng", "Thomas Bonald", "Fabian M. Suchanek"], "title": "FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic", "comment": null, "summary": "Knowledge graph alignment is the task of matching equivalent entities (that\nis, instances and classes) and relations across two knowledge graphs. Most\nexisting methods focus on pure entity-level alignment, computing the similarity\nof entities in some embedding space. They lack interpretable reasoning and need\ntraining data to work. In this paper, we propose FLORA, a simple yet effective\nmethod that (1) is unsupervised, i.e., does not require training data, (2)\nprovides a holistic alignment for entities and relations iteratively, (3) is\nbased on fuzzy logic and thus delivers interpretable results, (4) provably\nconverges, (5) allows dangling entities, i.e., entities without a counterpart\nin the other KG, and (6) achieves state-of-the-art results on major benchmarks.", "AI": {"tldr": "FLORA\u662f\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u7684\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\u65b9\u6cd5\uff0c\u65e0\u9700\u8bad\u7ec3\u6570\u636e\uff0c\u80fd\u591f\u540c\u65f6\u5bf9\u9f50\u5b9e\u4f53\u548c\u5173\u7cfb\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7ed3\u679c\uff0c\u5e76\u652f\u6301\u60ac\u7a7a\u5b9e\u4f53\u5904\u7406\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5b9e\u4f53\u7ea7\u5bf9\u9f50\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u63a8\u7406\u4e14\u9700\u8981\u8bad\u7ec3\u6570\u636e\uff0c\u65e0\u6cd5\u5904\u7406\u60ac\u7a7a\u5b9e\u4f53\u3002", "method": "\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u7684\u8fed\u4ee3\u65b9\u6cd5\uff0c\u63d0\u4f9b\u6574\u4f53\u6027\u7684\u5b9e\u4f53\u548c\u5173\u7cfb\u5bf9\u9f50\uff0c\u5177\u6709\u53ef\u8bc1\u660e\u7684\u6536\u655b\u6027\u3002", "result": "\u5728\u4e3b\u8981\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "FLORA\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65e0\u76d1\u7763\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5177\u6709\u53ef\u89e3\u91ca\u6027\u3001\u6536\u655b\u6027\u548c\u5bf9\u60ac\u7a7a\u5b9e\u4f53\u7684\u652f\u6301\u3002"}}
{"id": "2510.20419", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.20419", "abs": "https://arxiv.org/abs/2510.20419", "authors": ["Eric Wagner", "David Heye", "Jan Bauer", "Klaus Wehrle", "Martin Serror"], "title": "MAC Aggregation over Lossy Channels in DTLS 1.3", "comment": "IEEE ICNP'25", "summary": "Aggregating Message Authentication Codes (MACs) promises to save valuable\nbandwidth in resource-constrained environments. The idea is simple: Instead of\nappending an authentication tag to each message in a communication stream, the\nintegrity protection of multiple messages is aggregated into a single tag.\nRecent studies postulate, e.g., based on simulations, that these benefits also\nspread to wireless, and thus lossy, scenarios despite each lost packet\ntypically resulting in the loss of integrity protection information for\nmultiple messages. In this paper, we investigate these claims in a real\ndeployment. Therefore, we first design a MAC aggregation extension for the\nDatagram Transport Layer Security (DTLS) 1.3 protocol. Afterward, we\nextensively evaluate the performance of MAC aggregation on a complete\ncommunication protocol stack on embedded hardware. We find that MAC aggregation\ncan indeed increase goodput by up to 50% and save up to 17% of energy\nexpenditure for the transmission of short messages, even in lossy channels.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728DTLS 1.3\u534f\u8bae\u4e2d\u5b9e\u73b0MAC\u805a\u5408\uff0c\u901a\u8fc7\u5b9e\u9645\u90e8\u7f72\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5373\u4f7f\u5728\u6709\u635f\u65e0\u7ebf\u4fe1\u9053\u4e2d\uff0cMAC\u805a\u5408\u4e5f\u80fd\u663e\u8457\u63d0\u9ad8\u541e\u5410\u91cf\u5e76\u8282\u7701\u80fd\u8017\u3002", "motivation": "\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\uff0c\u901a\u8fc7\u805a\u5408\u6d88\u606f\u8ba4\u8bc1\u7801\u6765\u8282\u7701\u5e26\u5bbd\uff0c\u5e76\u9a8c\u8bc1\u5728\u65e0\u7ebf\u6709\u635f\u573a\u666f\u4e0bMAC\u805a\u5408\u7684\u5b9e\u9645\u6548\u76ca\u3002", "method": "\u8bbe\u8ba1DTLS 1.3\u534f\u8bae\u7684MAC\u805a\u5408\u6269\u5c55\uff0c\u5e76\u5728\u5d4c\u5165\u5f0f\u786c\u4ef6\u4e0a\u7684\u5b8c\u6574\u901a\u4fe1\u534f\u8bae\u6808\u4e2d\u8fdb\u884c\u5e7f\u6cdb\u6027\u80fd\u8bc4\u4f30\u3002", "result": "MAC\u805a\u5408\u5728\u77ed\u6d88\u606f\u4f20\u8f93\u4e2d\u53ef\u5c06\u541e\u5410\u91cf\u63d0\u9ad8\u6700\u591a50%\uff0c\u5e76\u8282\u7701\u6700\u591a17%\u7684\u80fd\u8017\uff0c\u5373\u4f7f\u5728\u6709\u635f\u4fe1\u9053\u4e2d\u4e5f\u80fd\u5b9e\u73b0\u8fd9\u4e9b\u6548\u76ca\u3002", "conclusion": "MAC\u805a\u5408\u5728\u73b0\u5b9e\u90e8\u7f72\u4e2d\u786e\u5b9e\u80fd\u591f\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u8282\u7701\u80fd\u6e90\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u65e0\u7ebf\u6709\u635f\u73af\u5883\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.20621", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20621", "abs": "https://arxiv.org/abs/2510.20621", "authors": ["Riccardo Guidotti", "Martina Cinquini", "Marta Marchiori Manerba", "Mattia Setzu", "Francesco Spinnato"], "title": "Towards the Formalization of a Trustworthy AI for Mining Interpretable Models explOiting Sophisticated Algorithms", "comment": null, "summary": "Interpretable-by-design models are crucial for fostering trust,\naccountability, and safe adoption of automated decision-making models in\nreal-world applications. In this paper we formalize the ground for the MIMOSA\n(Mining Interpretable Models explOiting Sophisticated Algorithms) framework, a\ncomprehensive methodology for generating predictive models that balance\ninterpretability with performance while embedding key ethical properties. We\nformally define here the supervised learning setting across diverse\ndecision-making tasks and data types, including tabular data, time series,\nimages, text, transactions, and trajectories. We characterize three major\nfamilies of interpretable models: feature importance, rule, and instance based\nmodels. For each family, we analyze their interpretability dimensions,\nreasoning mechanisms, and complexity. Beyond interpretability, we formalize\nthree critical ethical properties, namely causality, fairness, and privacy,\nproviding formal definitions, evaluation metrics, and verification procedures\nfor each. We then examine the inherent trade-offs between these properties and\ndiscuss how privacy requirements, fairness constraints, and causal reasoning\ncan be embedded within interpretable pipelines. By evaluating ethical measures\nduring model generation, this framework establishes the theoretical foundations\nfor developing AI systems that are not only accurate and interpretable but also\nfair, privacy-preserving, and causally aware, i.e., trustworthy.", "AI": {"tldr": "MIMOSA\u6846\u67b6\u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u6027\u8bbe\u8ba1\u6a21\u578b\u7684\u65b9\u6cd5\u8bba\uff0c\u65e8\u5728\u5e73\u8861\u53ef\u89e3\u91ca\u6027\u4e0e\u6027\u80fd\uff0c\u540c\u65f6\u5d4c\u5165\u56e0\u679c\u6027\u3001\u516c\u5e73\u6027\u548c\u9690\u79c1\u6027\u7b49\u5173\u952e\u4f26\u7406\u5c5e\u6027\u3002", "motivation": "\u5f00\u53d1\u53ef\u89e3\u91ca\u6027\u8bbe\u8ba1\u6a21\u578b\u5bf9\u4e8e\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u5efa\u7acb\u5bf9\u81ea\u52a8\u5316\u51b3\u7b56\u6a21\u578b\u7684\u4fe1\u4efb\u3001\u95ee\u8d23\u548c\u5b89\u5168\u91c7\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86\u76d1\u7763\u5b66\u4e60\u8bbe\u7f6e\uff0c\u6db5\u76d6\u8868\u683c\u6570\u636e\u3001\u65f6\u95f4\u5e8f\u5217\u3001\u56fe\u50cf\u3001\u6587\u672c\u3001\u4ea4\u6613\u548c\u8f68\u8ff9\u7b49\u591a\u79cd\u6570\u636e\u7c7b\u578b\u3002\u5206\u6790\u4e86\u7279\u5f81\u91cd\u8981\u6027\u3001\u89c4\u5219\u548c\u5b9e\u4f8b\u4e09\u7c7b\u53ef\u89e3\u91ca\u6a21\u578b\u5bb6\u65cf\uff0c\u5e76\u5f62\u5f0f\u5316\u4e86\u56e0\u679c\u6027\u3001\u516c\u5e73\u6027\u548c\u9690\u79c1\u6027\u4e09\u4e2a\u4f26\u7406\u5c5e\u6027\u3002", "result": "\u5efa\u7acb\u4e86\u5f00\u53d1\u4e0d\u4ec5\u51c6\u786e\u53ef\u89e3\u91ca\uff0c\u800c\u4e14\u516c\u5e73\u3001\u4fdd\u62a4\u9690\u79c1\u548c\u5177\u6709\u56e0\u679c\u610f\u8bc6\u7684AI\u7cfb\u7edf\u7684\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u901a\u8fc7\u5728\u6a21\u578b\u751f\u6210\u8fc7\u7a0b\u4e2d\u8bc4\u4f30\u4f26\u7406\u5ea6\u91cf\uff0c\u8be5\u6846\u67b6\u4e3a\u5f00\u53d1\u53ef\u4fe1\u8d56\u7684AI\u7cfb\u7edf\u5960\u5b9a\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2510.20632", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20632", "abs": "https://arxiv.org/abs/2510.20632", "authors": ["Shuyi Xie", "Ziqin Liew", "Hailing Zhang", "Haibo Zhang", "Ling Hu", "Zhiqiang Zhou", "Shuman Liu", "Anxiang Zeng"], "title": "Towards Reliable Evaluation of Large Language Models for Multilingual and Multimodal E-Commerce Applications", "comment": null, "summary": "Large Language Models (LLMs) excel on general-purpose NLP benchmarks, yet\ntheir capabilities in specialized domains remain underexplored. In e-commerce,\nexisting evaluations-such as EcomInstruct, ChineseEcomQA, eCeLLM, and Shopping\nMMLU-suffer from limited task diversity (e.g., lacking product guidance and\nafter-sales issues), limited task modalities (e.g., absence of multimodal\ndata), synthetic or curated data, and a narrow focus on English and Chinese,\nleaving practitioners without reliable tools to assess models on complex,\nreal-world shopping scenarios. We introduce EcomEval, a comprehensive\nmultilingual and multimodal benchmark for evaluating LLMs in e-commerce.\nEcomEval covers six categories and 37 tasks (including 8 multimodal tasks),\nsourced primarily from authentic customer queries and transaction logs,\nreflecting the noisy and heterogeneous nature of real business interactions. To\nensure both quality and scalability of reference answers, we adopt a\nsemi-automatic pipeline in which large models draft candidate responses\nsubsequently reviewed and modified by over 50 expert annotators with strong\ne-commerce and multilingual expertise. We define difficulty levels for each\nquestion and task category by averaging evaluation scores across models with\ndifferent sizes and capabilities, enabling challenge-oriented and fine-grained\nassessment. EcomEval also spans seven languages-including five low-resource\nSoutheast Asian languages-offering a multilingual perspective absent from prior\nwork.", "AI": {"tldr": "EcomEval\u662f\u4e00\u4e2a\u5168\u9762\u7684\u591a\u8bed\u8a00\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u7535\u5b50\u5546\u52a1\u9886\u57df\u7684\u6027\u80fd\uff0c\u8986\u76d66\u4e2a\u7c7b\u522b37\u4e2a\u4efb\u52a1\uff0c\u5305\u542b8\u4e2a\u591a\u6a21\u6001\u4efb\u52a1\uff0c\u652f\u63017\u79cd\u8bed\u8a00\u3002", "motivation": "\u73b0\u6709\u7535\u5b50\u5546\u52a1\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u4efb\u52a1\u591a\u6837\u6027\u4e0d\u8db3\u3001\u6a21\u6001\u6709\u9650\u3001\u6570\u636e\u5408\u6210\u6216\u4eba\u5de5\u6574\u7406\u3001\u8bed\u8a00\u8986\u76d6\u7a84\u7b49\u95ee\u9898\uff0c\u7f3a\u4e4f\u8bc4\u4f30\u590d\u6742\u771f\u5b9e\u8d2d\u7269\u573a\u666f\u7684\u53ef\u9760\u5de5\u5177\u3002", "method": "\u91c7\u7528\u534a\u81ea\u52a8\u6d41\u7a0b\uff0c\u7531\u5927\u6a21\u578b\u751f\u6210\u5019\u9009\u56de\u7b54\uff0c\u518d\u753150\u591a\u540d\u7535\u5b50\u5546\u52a1\u548c\u591a\u8bed\u8a00\u4e13\u5bb6\u5ba1\u6838\u4fee\u6539\uff1b\u57fa\u4e8e\u4e0d\u540c\u89c4\u6a21\u548c\u80fd\u529b\u6a21\u578b\u7684\u8bc4\u4f30\u5206\u6570\u5b9a\u4e49\u4efb\u52a1\u96be\u5ea6\u7ea7\u522b\u3002", "result": "\u6784\u5efa\u4e86\u53cd\u6620\u771f\u5b9e\u4e1a\u52a1\u4ea4\u4e92\u566a\u58f0\u548c\u5f02\u8d28\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u5ba2\u6237\u67e5\u8be2\u548c\u4ea4\u6613\u65e5\u5fd7\u7b49\u771f\u5b9e\u6570\u636e\u6e90\u3002", "conclusion": "EcomEval\u63d0\u4f9b\u4e86\u6311\u6218\u5bfc\u5411\u548c\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u7684\u591a\u8bed\u8a00\u591a\u6a21\u6001\u57fa\u51c6\uff0c\u586b\u8865\u4e86\u7535\u5b50\u5546\u52a1\u9886\u57df\u4e13\u4e1a\u8bc4\u4f30\u5de5\u5177\u7684\u7a7a\u767d\u3002"}}
{"id": "2510.20636", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20636", "abs": "https://arxiv.org/abs/2510.20636", "authors": ["Eric Ngoiya", "Tianshu Bao"], "title": "Fluidity Index: Next-Generation Super-intelligence Benchmarks", "comment": "12", "summary": "This paper introduces the Fluidity Index (FI) to quantify model adaptability\nin dynamic, scaling environments. The benchmark evaluates response accuracy\nbased on deviations in initial, current, and future environment states,\nassessing context switching and continuity. We distinguish between closed-ended\nand open-ended benchmarks, prioritizing closed-loop open-ended real-world\nbenchmarks to test adaptability. The approach measures a model's ability to\nunderstand, predict, and adjust to state changes in scaling environments. A\ntruly super-intelligent model should exhibit at least second-order\nadaptability, enabling self-sustained computation through digital replenishment\nfor optimal fluidity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6d41\u52a8\u6027\u6307\u6570(FI)\u6765\u91cf\u5316\u6a21\u578b\u5728\u52a8\u6001\u6269\u5c55\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\uff0c\u901a\u8fc7\u8bc4\u4f30\u521d\u59cb\u3001\u5f53\u524d\u548c\u672a\u6765\u73af\u5883\u72b6\u6001\u504f\u5dee\u6765\u6d4b\u8bd5\u54cd\u5e94\u51c6\u786e\u6027\uff0c\u533a\u5206\u5c01\u95ed\u5f0f\u548c\u5f00\u653e\u5f0f\u57fa\u51c6\u6d4b\u8bd5\uff0c\u91cd\u70b9\u5173\u6ce8\u95ed\u73af\u5f00\u653e\u5f0f\u73b0\u5b9e\u4e16\u754c\u57fa\u51c6\u3002", "motivation": "\u4e3a\u4e86\u91cf\u5316\u6a21\u578b\u5728\u52a8\u6001\u6269\u5c55\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u8bc4\u4f30\u6a21\u578b\u7406\u89e3\u3001\u9884\u6d4b\u548c\u9002\u5e94\u72b6\u6001\u53d8\u5316\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6d41\u52a8\u6027\u6307\u6570(FI)\u6765\u8861\u91cf\u6a21\u578b\u9002\u5e94\u6027\uff0c\u901a\u8fc7\u5206\u6790\u521d\u59cb\u3001\u5f53\u524d\u548c\u672a\u6765\u73af\u5883\u72b6\u6001\u7684\u504f\u5dee\u6765\u8bc4\u4f30\u54cd\u5e94\u51c6\u786e\u6027\uff0c\u5e76\u533a\u5206\u5c01\u95ed\u5f0f\u548c\u5f00\u653e\u5f0f\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u8bc4\u4f30\u6a21\u578b\u5728\u52a8\u6001\u6269\u5c55\u73af\u5883\u4e2d\u9002\u5e94\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5f3a\u8c03\u771f\u6b63\u8d85\u7ea7\u667a\u80fd\u6a21\u578b\u5e94\u5177\u5907\u81f3\u5c11\u4e8c\u9636\u9002\u5e94\u6027\uff0c\u80fd\u591f\u901a\u8fc7\u6570\u5b57\u8865\u5145\u5b9e\u73b0\u81ea\u6211\u7ef4\u6301\u8ba1\u7b97\u3002", "conclusion": "\u6d41\u52a8\u6027\u6307\u6570\u4e3a\u8bc4\u4f30\u6a21\u578b\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u63d0\u4f9b\u4e86\u91cf\u5316\u6307\u6807\uff0c\u8d85\u7ea7\u667a\u80fd\u6a21\u578b\u9700\u8981\u5177\u5907\u9ad8\u9636\u9002\u5e94\u80fd\u529b\u4ee5\u5b9e\u73b0\u6700\u4f73\u6d41\u52a8\u6027\u3002"}}
{"id": "2510.20641", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20641", "abs": "https://arxiv.org/abs/2510.20641", "authors": ["Andrea Agiollo", "Andrea Omicini"], "title": "Integrating Machine Learning into Belief-Desire-Intention Agents: Current Advances and Open Challenges", "comment": null, "summary": "Thanks to the remarkable human-like capabilities of machine learning (ML)\nmodels in perceptual and cognitive tasks, frameworks integrating ML within\nrational agent architectures are gaining traction. Yet, the landscape remains\nfragmented and incoherent, often focusing on embedding ML into generic agent\ncontainers while overlooking the expressive power of rational\narchitectures--such as Belief-Desire-Intention (BDI) agents. This paper\npresents a fine-grained systematisation of existing approaches, using the BDI\nparadigm as a reference. Our analysis illustrates the fast-evolving literature\non rational agents enhanced by ML, and identifies key research opportunities\nand open challenges for designing effective rational ML agents.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5c06\u673a\u5668\u5b66\u4e60\u96c6\u6210\u5230\u7406\u6027\u667a\u80fd\u4f53\u67b6\u6784\u4e2d\u7684\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u4e86\u7cfb\u7edf\u5316\u68b3\u7406\uff0c\u4ee5BDI\u8303\u5f0f\u4e3a\u53c2\u8003\u6846\u67b6\uff0c\u5206\u6790\u4e86\u76f8\u5173\u6587\u732e\u5e76\u8bc6\u522b\u4e86\u5173\u952e\u7814\u7a76\u673a\u4f1a\u548c\u6311\u6218\u3002", "motivation": "\u7531\u4e8e\u673a\u5668\u5b66\u4e60\u5728\u611f\u77e5\u548c\u8ba4\u77e5\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u7c7b\u4eba\u80fd\u529b\uff0c\u5c06ML\u96c6\u6210\u5230\u7406\u6027\u667a\u80fd\u4f53\u67b6\u6784\u4e2d\u7684\u6846\u67b6\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u7cfb\u7edf\u6027\u548c\u8fde\u8d2f\u6027\uff0c\u5f80\u5f80\u5ffd\u89c6\u7406\u6027\u67b6\u6784\u7684\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u4f7f\u7528BDI\uff08\u4fe1\u5ff5-\u6b32\u671b-\u610f\u56fe\uff09\u8303\u5f0f\u4f5c\u4e3a\u53c2\u8003\u6846\u67b6\uff0c\u5bf9\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7cfb\u7edf\u5316\u5206\u6790\u3002", "result": "\u5206\u6790\u5c55\u793a\u4e86\u7531ML\u589e\u5f3a\u7684\u7406\u6027\u667a\u80fd\u4f53\u6587\u732e\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u8bc6\u522b\u4e86\u8bbe\u8ba1\u6709\u6548\u7406\u6027ML\u667a\u80fd\u4f53\u7684\u5173\u952e\u7814\u7a76\u673a\u4f1a\u548c\u5f00\u653e\u6311\u6218\u3002", "conclusion": "\u9700\u8981\u66f4\u7cfb\u7edf\u5730\u6574\u5408ML\u4e0e\u7406\u6027\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u7279\u522b\u662f\u5145\u5206\u5229\u7528BDI\u7b49\u7406\u6027\u67b6\u6784\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u4ee5\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u7406\u6027ML\u667a\u80fd\u4f53\u3002"}}
{"id": "2510.20784", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20784", "abs": "https://arxiv.org/abs/2510.20784", "authors": ["Fares Fourati"], "title": "A Coherence-Based Measure of AGI", "comment": "13 pages, 1 figure, 12 tables", "summary": "Recent work by \\citet{hendrycks2025agidefinition} formalized\n\\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of\nproficiencies across cognitive domains derived from the Cattell--Horn--Carroll\n(CHC) model of human cognition. While elegant, this definition assumes\n\\textit{compensability} -- that exceptional ability in some domains can offset\nfailure in others. True general intelligence, however, should reflect\n\\textit{coherent sufficiency}: balanced competence across all essential\ndomains. We propose a coherence-aware measure of AGI based on the integral of\ngeneralized means over a continuum of compensability exponents. This\nformulation spans arithmetic, geometric, and harmonic regimes, and the\nresulting \\textit{area under the curve} (AUC) quantifies robustness under\nvarying compensability assumptions. Unlike the arithmetic mean, which rewards\nspecialization, the AUC penalizes imbalance and captures inter-domain\ndependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5,\nthe coherence-adjusted AUC reveals that both systems remain far from general\ncompetence despite high arithmetic scores (e.g., GPT-5 at~24\\%). Integrating\nthe generalized mean thus yields a principled, interpretable, and stricter\nfoundation for measuring genuine progress toward AGI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e7f\u4e49\u5747\u503c\u79ef\u5206\u7684AGI\u4e00\u81f4\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u66ff\u4ee3\u4e86\u4f20\u7edf\u7b97\u672f\u5e73\u5747\u65b9\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u4e0d\u540c\u8865\u507f\u6027\u5047\u8bbe\u4e0b\u7684\u9c81\u68d2\u6027\u6765\u66f4\u4e25\u683c\u5730\u8bc4\u4f30\u901a\u7528\u4eba\u5de5\u667a\u80fd\u3002", "motivation": "\u73b0\u6709AGI\u5b9a\u4e49\u4f7f\u7528\u8ba4\u77e5\u9886\u57df\u7684\u7b97\u672f\u5e73\u5747\u503c\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5047\u8bbe\u8865\u507f\u6027\uff08\u67d0\u4e9b\u9886\u57df\u7684\u5353\u8d8a\u80fd\u529b\u53ef\u4ee5\u5f25\u8865\u5176\u4ed6\u9886\u57df\u7684\u5931\u8d25\uff09\uff0c\u800c\u771f\u6b63\u7684\u901a\u7528\u667a\u80fd\u5e94\u8be5\u53cd\u6620\u6240\u6709\u57fa\u672c\u9886\u57df\u7684\u5e73\u8861\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5e7f\u4e49\u5747\u503c\u5728\u8865\u507f\u6027\u6307\u6570\u8fde\u7eed\u4f53\u4e0a\u79ef\u5206\u7684AGI\u4e00\u81f4\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u6db5\u76d6\u7b97\u672f\u3001\u51e0\u4f55\u548c\u8c03\u548c\u5747\u503c\u673a\u5236\uff0c\u901a\u8fc7\u66f2\u7ebf\u4e0b\u9762\u79ef\uff08AUC\uff09\u91cf\u5316\u4e0d\u540c\u8865\u507f\u6027\u5047\u8bbe\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5e94\u7528\u4e8eGPT-4\u548cGPT-5\u7684CHC\u9886\u57df\u5f97\u5206\uff0c\u4e00\u81f4\u6027\u8c03\u6574\u7684AUC\u663e\u793a\u5c3d\u7ba1\u7b97\u672f\u5f97\u5206\u8f83\u9ad8\uff08\u5982GPT-5\u4e3a24%\uff09\uff0c\u4f46\u4e24\u4e2a\u7cfb\u7edf\u8ddd\u79bb\u901a\u7528\u80fd\u529b\u4ecd\u7136\u5f88\u8fdc\u3002", "conclusion": "\u5e7f\u4e49\u5747\u503c\u79ef\u5206\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u3001\u53ef\u89e3\u91ca\u4e14\u66f4\u4e25\u683c\u7684AGI\u6d4b\u91cf\u57fa\u7840\uff0c\u80fd\u591f\u60e9\u7f5a\u4e0d\u5e73\u8861\u5e76\u6355\u6349\u9886\u57df\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002"}}
{"id": "2510.20809", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20809", "abs": "https://arxiv.org/abs/2510.20809", "authors": ["Xueyan Zou", "Jianglong Ye", "Hao Zhang", "Xiaoyu Xiang", "Mingyu Ding", "Zhaojing Yang", "Yong Jae Lee", "Zhuowen Tu", "Sifei Liu", "Xiaolong Wang"], "title": "Real Deep Research for AI, Robotics and Beyond", "comment": "website: https://realdeepresearch.github.io", "summary": "With the rapid growth of research in AI and robotics now producing over\n10,000 papers annually it has become increasingly difficult for researchers to\nstay up to date. Fast evolving trends, the rise of interdisciplinary work, and\nthe need to explore domains beyond one's expertise all contribute to this\nchallenge. To address these issues, we propose a generalizable pipeline capable\nof systematically analyzing any research area: identifying emerging trends,\nuncovering cross domain opportunities, and offering concrete starting points\nfor new inquiry. In this work, we present Real Deep Research (RDR) a\ncomprehensive framework applied to the domains of AI and robotics, with a\nparticular focus on foundation models and robotics advancements. We also\nbriefly extend our analysis to other areas of science. The main paper details\nthe construction of the RDR pipeline, while the appendix provides extensive\nresults across each analyzed topic. We hope this work sheds light for\nresearchers working in the field of AI and beyond.", "AI": {"tldr": "\u63d0\u51faReal Deep Research (RDR)\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u5206\u6790AI\u548c\u673a\u5668\u4eba\u9886\u57df\u7684\u7814\u7a76\u8d8b\u52bf\uff0c\u8bc6\u522b\u65b0\u5174\u8d8b\u52bf\u548c\u8de8\u9886\u57df\u673a\u4f1a\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u5e94\u5bf9\u8bba\u6587\u6570\u91cf\u6fc0\u589e\u7684\u6311\u6218\u3002", "motivation": "AI\u548c\u673a\u5668\u4eba\u9886\u57df\u6bcf\u5e74\u4ea7\u51fa\u8d85\u8fc710,000\u7bc7\u8bba\u6587\uff0c\u7814\u7a76\u4eba\u5458\u96be\u4ee5\u8ddf\u4e0a\u5feb\u901f\u53d1\u5c55\u7684\u8d8b\u52bf\uff0c\u8de8\u5b66\u79d1\u5de5\u4f5c\u589e\u591a\uff0c\u9700\u8981\u63a2\u7d22\u4e13\u4e1a\u9886\u57df\u5916\u7684\u77e5\u8bc6\u3002", "method": "\u6784\u5efa\u901a\u7528\u7684RDR\u7ba1\u9053\uff0c\u7cfb\u7edf\u5206\u6790\u7814\u7a76\u9886\u57df\uff0c\u8bc6\u522b\u65b0\u5174\u8d8b\u52bf\uff0c\u53d1\u73b0\u8de8\u9886\u57df\u673a\u4f1a\uff0c\u4e3a\u65b0\u7684\u7814\u7a76\u63d0\u4f9b\u5177\u4f53\u8d77\u70b9\u3002", "result": "\u5c06RDR\u6846\u67b6\u5e94\u7528\u4e8eAI\u548c\u673a\u5668\u4eba\u9886\u57df\uff0c\u7279\u522b\u5173\u6ce8\u57fa\u7840\u6a21\u578b\u548c\u673a\u5668\u4eba\u6280\u672f\u8fdb\u6b65\uff0c\u5e76\u6269\u5c55\u5230\u5176\u4ed6\u79d1\u5b66\u9886\u57df\u3002", "conclusion": "RDR\u6846\u67b6\u4e3aAI\u53ca\u5176\u4ed6\u9886\u57df\u7684\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5206\u6790\u7814\u7a76\u8d8b\u52bf\u7684\u5de5\u5177\uff0c\u5e2e\u52a9\u4ed6\u4eec\u5728\u5feb\u901f\u53d1\u5c55\u7684\u7814\u7a76\u73af\u5883\u4e2d\u4fdd\u6301\u66f4\u65b0\u3002"}}

<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [LLMs Can Assist with Proposal Selection at Large User Facilities](https://arxiv.org/abs/2512.10895)
*Lijie Ding,Janell Thomson,Jon Taylor,Changwoo Do*

Main category: cs.AI

TL;DR: LLMs能有效提升大型用户设施提案选择的效率，提供比传统人工评审更一致、成本更低的替代方案，并在识别高发表潜力提案方面表现不亚于人类评审


<details>
  <summary>Details</summary>
Motivation: 传统人工提案评审存在提案间相关性弱、评审者偏见和不一致的问题，而基于成对偏好的方法虽然逻辑上更优越，但由于工作量呈二次方增长，对人类评审者不切实际

Method: 利用LLMs进行提案排名，基于Spallation Neutron Source三个光束线精心整理的提案和发表记录，采用成对偏好方法，并利用嵌入模型进行提案相似性定量评估

Result: LLM排名与人类排名强相关（Spearman ρ≈0.2-0.8，去除10%异常值后≥0.5），在识别高发表潜力提案方面表现不亚于人类评审，成本降低两个数量级以上

Conclusion: LLMs为提案选择提供了可扩展、一致且经济高效的替代方案，不仅能有效排名提案，还能进行人类难以完成的先进分析，如通过嵌入模型定量评估提案相似性

Abstract: We explore how large language models (LLMs) can enhance the proposal selection process at large user facilities, offering a scalable, consistent, and cost-effective alternative to traditional human review. Proposal selection depends on assessing the relative strength among submitted proposals; however, traditional human scoring often suffers from weak inter-proposal correlations and is subject to reviewer bias and inconsistency. A pairwise preference-based approach is logically superior, providing a more rigorous and internally consistent basis for ranking, but its quadratic workload makes it impractical for human reviewers. We address this limitation using LLMs. Leveraging the uniquely well-curated proposals and publication records from three beamlines at the Spallation Neutron Source (SNS), Oak Ridge National Laboratory (ORNL), we show that the LLM rankings correlate strongly with the human rankings (Spearman $ρ\simeq 0.2-0.8$, improving to $\geq 0.5$ after 10\% outlier removal). Moreover, LLM performance is no worse than that of human reviewers in identifying proposals with high publication potential, while costing over two orders of magnitude less. Beyond ranking, LLMs enable advanced analyses that are challenging for humans, such as quantitative assessment of proposal similarity via embedding models, which provides information crucial for review committees.

</details>


### [2] [Multi-Granular Node Pruning for Circuit Discovery](https://arxiv.org/abs/2512.10903)
*Muhammad Umair Haider,Hammad Rizwan,Hassan Sajjad,A. B. Siddique*

Main category: cs.AI

TL;DR: 本文提出了一种节点级剪枝框架用于电路发现，解决了现有方法计算成本高、粒度粗的问题，通过多粒度可学习掩码和特定稀疏性惩罚，在单次微调中实现全面压缩。


<details>
  <summary>Details</summary>
Motivation: 现有电路发现方法主要依赖迭代边剪枝，计算成本高且仅限于粗粒度单元（如注意力头或MLP块），忽略了神经元等更细粒度的结构，存在可扩展性和粒度限制问题。

Method: 提出节点级剪枝框架，引入跨多个粒度级别（从整个块到单个神经元）的可学习掩码，在统一优化目标中使用粒度特定的稀疏性惩罚指导剪枝过程，实现单次微调中的全面压缩。

Result: 实验表明，该方法发现的电路节点数少于先前方法；证明许多被粗粒度方法认为重要的神经元实际上无关紧要，同时仍能保持任务性能；内存占用显著降低5-10倍，因为不需要在内存中保存中间激活。

Conclusion: 提出的节点级剪枝框架解决了电路发现中的可扩展性和粒度限制问题，能够识别更小、更精确的电路，同时大幅降低计算资源需求。

Abstract: Circuit discovery aims to identify minimal subnetworks that are responsible for specific behaviors in large language models (LLMs). Existing approaches primarily rely on iterative edge pruning, which is computationally expensive and limited to coarse-grained units such as attention heads or MLP blocks, overlooking finer structures like individual neurons. We propose a node-level pruning framework for circuit discovery that addresses both scalability and granularity limitations. Our method introduces learnable masks across multiple levels of granularity, from entire blocks to individual neurons, within a unified optimization objective. Granularity-specific sparsity penalties guide the pruning process, allowing a comprehensive compression in a single fine-tuning run. Empirically, our approach identifies circuits that are smaller in nodes than those discovered by prior methods; moreover, we demonstrate that many neurons deemed important by coarse methods are actually irrelevant, while still maintaining task performance. Furthermore, our method has a significantly lower memory footprint, 5-10x, as it does not require keeping intermediate activations in the memory to work.

</details>

{"id": "2511.07480", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07480", "abs": "https://arxiv.org/abs/2511.07480", "authors": ["Shuyuan Liu", "Jiawei Chen", "Xiao Yang", "Hang Su", "Zhaoxia Yin"], "title": "KG-DF: A Black-box Defense Framework against Jailbreak Attacks Based on Knowledge Graphs", "comment": null, "summary": "With the widespread application of large language models (LLMs) in various fields, the security challenges they face have become increasingly prominent, especially the issue of jailbreak. These attacks induce the model to generate erroneous or uncontrolled outputs through crafted inputs, threatening the generality and security of the model. Although existing defense methods have shown some effectiveness, they often struggle to strike a balance between model generality and security. Excessive defense may limit the normal use of the model, while insufficient defense may lead to security vulnerabilities. In response to this problem, we propose a Knowledge Graph Defense Framework (KG-DF). Specifically, because of its structured knowledge representation and semantic association capabilities, Knowledge Graph(KG) can be searched by associating input content with safe knowledge in the knowledge base, thus identifying potentially harmful intentions and providing safe reasoning paths. However, traditional KG methods encounter significant challenges in keyword extraction, particularly when confronted with diverse and evolving attack strategies. To address this issue, we introduce an extensible semantic parsing module, whose core task is to transform the input query into a set of structured and secure concept representations, thereby enhancing the relevance of the matching process. Experimental results show that our framework enhances defense performance against various jailbreak attack methods, while also improving the response quality of the LLM in general QA scenarios by incorporating domain-general knowledge."}
{"id": "2511.07503", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07503", "abs": "https://arxiv.org/abs/2511.07503", "authors": ["Asia Belfiore", "Jonathan Passerat-Palmbach", "Dmitrii Usynin"], "title": "Biologically-Informed Hybrid Membership Inference Attacks on Generative Genomic Models", "comment": null, "summary": "The increased availability of genetic data has transformed genomics research, but raised many privacy concerns regarding its handling due to its sensitive nature. This work explores the use of language models (LMs) for the generation of synthetic genetic mutation profiles, leveraging differential privacy (DP) for the protection of sensitive genetic data. We empirically evaluate the privacy guarantees of our DP modes by introducing a novel Biologically-Informed Hybrid Membership Inference Attack (biHMIA), which combines traditional black box MIA with contextual genomics metrics for enhanced attack power. Our experiments show that both small and large transformer GPT-like models are viable synthetic variant generators for small-scale genomics, and that our hybrid attack leads, on average, to higher adversarial success compared to traditional metric-based MIAs."}
{"id": "2511.07577", "categories": ["cs.CR", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.07577", "abs": "https://arxiv.org/abs/2511.07577", "authors": ["Yining Lu", "Wenyi Tang", "Max Johnson", "Taeho Jung", "Meng Jiang"], "title": "A Decentralized Retrieval Augmented Generation System with Source Reliabilities Secured on Blockchain", "comment": null, "summary": "Existing retrieval-augmented generation (RAG) systems typically use a centralized architecture, causing a high cost of data collection, integration, and management, as well as privacy concerns. There is a great need for a decentralized RAG system that enables foundation models to utilize information directly from data owners who maintain full control over their sources. However, decentralization brings a challenge: the numerous independent data sources vary significantly in reliability, which can diminish retrieval accuracy and response quality. To address this, our decentralized RAG system has a novel reliability scoring mechanism that dynamically evaluates each source based on the quality of responses it contributes to generate and prioritizes high-quality sources during retrieval. To ensure transparency and trust, the scoring process is securely managed through blockchain-based smart contracts, creating verifiable and tamper-proof reliability records without relying on a central authority. We evaluate our decentralized system with two Llama models (3B and 8B) in two simulated environments where six data sources have different levels of reliability. Our system achieves a +10.7\\% performance improvement over its centralized counterpart in the real world-like unreliable data environments. Notably, it approaches the upper-bound performance of centralized systems under ideally reliable data environments. The decentralized infrastructure enables secure and trustworthy scoring management, achieving approximately 56\\% marginal cost savings through batched update operations. Our code and system are open-sourced at github.com/yining610/Reliable-dRAG."}
{"id": "2511.08395", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.08395", "abs": "https://arxiv.org/abs/2511.08395", "authors": ["Xingyu Liu", "Jiawei Liang", "Yipu Zhang", "Linfeng Du", "Chaofang Ma", "Hui Yu", "Jiang Xu", "Wei Zhang"], "title": "DRACO: Co-design for DSP-Efficient Rigid Body Dynamics Accelerator", "comment": null, "summary": "We propose a hardware-efficient RBD accelerator based on FPGA, introducing three key innovations. First, we propose a precision-aware quantization framework that reduces DSP demand while preserving motion accuracy. This is also the first study to systematically evaluate quantization impact on robot control and motion for hardware acceleration. Second, we leverage a division deferring optimization in mass matrix inversion algorithm, which decouples reciprocal operations from the longest latency path to improve the performance. Finally, we present an inter-module DSP reuse methodology to improve DSP utilization and save DSP usage. Experiment results show that our work achieves up to 8x throughput improvement and 7.4x latency reduction over state-of-the-art RBD accelerators across various robot types, demonstrating its effectiveness and scalability for high-DOF robotic systems."}
{"id": "2511.08158", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.08158", "abs": "https://arxiv.org/abs/2511.08158", "authors": ["Kelun Lei", "Hailong Yang", "Kaige Zhang", "Kejie Ma", "Yiqing Wang", "Xin You", "Yufan Xu", "Enrique S. Quintana-Orti", "Zhongzhi Luan", "Yi Liu", "Depei Qian"], "title": "\\uline{LO}w-c\\uline{O}st yet High-\\uline{P}erformant \\uline{S}parse Matrix-Matrix Multiplication on Arm SME Architectures", "comment": null, "summary": "Sparse matrix-dense matrix multiplication (SpMM) is a critical kernel in both scientific computing and emerging graph learning workloads. The recent Armv9 architecture introduces Scalable Matrix Extension (SME), enabling tile-based matrix operations with high throughput. However, effectively exploiting both SME and traditional SIMD resources for unstructured sparse workloads remains an open challenge. To address this, we propose LOOPS, a hybrid execution framework that combines row-wise CSR-part with vector-wise BCSR-part layout, enabling cooperative utilization of vector instructions (NEON) and Scalable Matrix Extension (SME) resources. LOOPS supports multi-precision SpMM across FP64, FP32, and FP16 via an adaptive two-level parallelization scheme guided by a lightweight performance model. Experimental results on the entire SuiteSparse on an Apple's M4Pro CPU show that LOOPS achieves average speedups of 9.93$\\times$ (FP32)/14.4$\\times$ (FP64) against the CPU baseline TACO and 71.3$\\times$ (FP32)/54.8$\\times$ (FP64) with respect to Armadillo. A comparison of LOOPS running on the same CPU with two GPU methods (cuSPARSE, Magicube) executed on an NVIDIA A100 GPU show average speedups for LOOPS between 19.8$\\times$ and 33.5$\\times$, depending on the precision. Notably, LOOPS delivers significantly better energy efficiency than the GPU codes on the A100 GPU."}
{"id": "2511.07876", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.07876", "abs": "https://arxiv.org/abs/2511.07876", "authors": ["Xingyu Li", "Xiaolei Liu", "Cheng Liu", "Yixiao Xu", "Kangyi Ding", "Bangzhou Xin", "Jia-Li Yin"], "title": "LoopLLM: Transferable Energy-Latency Attacks in LLMs via Repetitive Generation", "comment": "14 pages with 7 figures; accepted by the AAAI 2026", "summary": "As large language models (LLMs) scale, their inference incurs substantial computational resources, exposing them to energy-latency attacks, where crafted prompts induce high energy and latency cost. Existing attack methods aim to prolong output by delaying the generation of termination symbols. However, as the output grows longer, controlling the termination symbols through input becomes difficult, making these methods less effective. Therefore, we propose LoopLLM, an energy-latency attack framework based on the observation that repetitive generation can trigger low-entropy decoding loops, reliably compelling LLMs to generate until their output limits. LoopLLM introduces (1) a repetition-inducing prompt optimization that exploits autoregressive vulnerabilities to induce repetitive generation, and (2) a token-aligned ensemble optimization that aggregates gradients to improve cross-model transferability. Extensive experiments on 12 open-source and 2 commercial LLMs show that LoopLLM significantly outperforms existing methods, achieving over 90% of the maximum output length, compared to 20% for baselines, and improving transferability by around 40% to DeepSeek-V3 and Gemini 2.5 Flash."}
{"id": "2511.08060", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.08060", "abs": "https://arxiv.org/abs/2511.08060", "authors": ["Junxiao Han", "Zheng Yu", "Lingfeng Bao", "Jiakun Liu", "Yao Wan", "Jianwei Yin", "Shuiguang Deng", "Song Han"], "title": "From LLMs to Agents: A Comparative Evaluation of LLMs and LLM-based Agents in Security Patch Detection", "comment": null, "summary": "The widespread adoption of open-source software (OSS) has accelerated software innovation but also increased security risks due to the rapid propagation of vulnerabilities and silent patch releases. In recent years, large language models (LLMs) and LLM-based agents have demonstrated remarkable capabilities in various software engineering (SE) tasks, enabling them to effectively address software security challenges such as vulnerability detection. However, systematic evaluation of the capabilities of LLMs and LLM-based agents in security patch detection remains limited. To bridge this gap, we conduct a comprehensive evaluation of the performance of LLMs and LLM-based agents for security patch detection. Specifically, we investigate three methods: Plain LLM (a single LLM with a system prompt), Data-Aug LLM (data augmentation based on the Plain LLM), and the ReAct Agent (leveraging the thought-action-observation mechanism). We also evaluate the performance of both commercial and open-source LLMs under these methods and compare these results with those of existing baselines. Furthermore, we analyze the detection performance of these methods across various vulnerability types, and examine the impact of different prompting strategies and context window sizes on the results. Our findings reveal that the Data-Aug LLM achieves the best overall performance, whereas the ReAct Agent demonstrates the lowest false positive rate (FPR). Although baseline methods exhibit strong accuracy, their false positive rates are significantly higher. In contrast, our evaluated methods achieve comparable accuracy while substantially reducing the FPR. These findings provide valuable insights into the practical applications of LLMs and LLM-based agents in security patch detection, highlighting their advantage in maintaining robust performance while minimizing false positive rates."}
{"id": "2511.08462", "categories": ["cs.CR", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.08462", "abs": "https://arxiv.org/abs/2511.08462", "authors": ["Claire Wang", "Ziyang Li", "Saikat Dutta", "Mayur Naik"], "title": "QLCoder: A Query Synthesizer For Static Analysis of Security Vulnerabilities", "comment": null, "summary": "Static analysis tools provide a powerful means to detect security vulnerabilities by specifying queries that encode vulnerable code patterns. However, writing such queries is challenging and requires diverse expertise in security and program analysis. To address this challenge, we present QLCoder - an agentic framework that automatically synthesizes queries in CodeQL, a powerful static analysis engine, directly from a given CVE metadata. QLCode embeds an LLM in a synthesis loop with execution feedback, while constraining its reasoning using a custom MCP interface that allows structured interaction with a Language Server Protocol (for syntax guidance) and a RAG database (for semantic retrieval of queries and documentation). This approach allows QLCoder to generate syntactically and semantically valid security queries. We evaluate QLCode on 176 existing CVEs across 111 Java projects. Building upon the Claude Code agent framework, QLCoder synthesizes correct queries that detect the CVE in the vulnerable but not in the patched versions for 53.4% of CVEs. In comparison, using only Claude Code synthesizes 10% correct queries."}

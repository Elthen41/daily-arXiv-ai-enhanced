{"id": "2512.03048", "categories": ["cs.AI", "cs.CY", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.03048", "abs": "https://arxiv.org/abs/2512.03048", "authors": ["Austin Spizzirri"], "title": "Exploring Syntropic Frameworks in AI Alignment: A Philosophical Investigation", "comment": "Approx. 3,000 words, 10 pages. Philosophical analysis of AI alignment (process-based / syntropy framework)", "summary": "I argue that AI alignment should be reconceived as architecting syntropic, reasons-responsive agents through process-based, multi-agent, developmental mechanisms rather than encoding fixed human value content. The paper makes three philosophical contributions. First, I articulate the ``specification trap'' argument demonstrating why content-based value specification appears structurally unstable due to the conjunction of the is-ought gap, value pluralism, and the extended frame problem. Second, I propose syntropy -- the recursive reduction of mutual uncertainty between agents through state alignment -- as an information-theoretic framework for understanding multi-agent alignment dynamics. Third, I establish a functional distinction between genuine and simulated moral capacity grounded in compatibilist theories of guidance control, coupled with an embodied experimental paradigm and verification regime providing operational criteria independent of phenomenological claims. This paper represents the philosophical component of a broader research program whose empirical validation is being developed in a separate project currently in preparation. While the framework generates specific, falsifiable predictions about value emergence and moral agency in artificial systems, empirical validation remains pending.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3b\u5f20\u5c06AI\u5bf9\u9f50\u91cd\u65b0\u6784\u60f3\u4e3a\u901a\u8fc7\u57fa\u4e8e\u8fc7\u7a0b\u3001\u591a\u667a\u80fd\u4f53\u3001\u53d1\u5c55\u6027\u673a\u5236\u6765\u6784\u5efa\u5177\u6709\u71b5\u51cf\u6027\u3001\u7406\u7531\u54cd\u5e94\u80fd\u529b\u7684\u667a\u80fd\u4f53\uff0c\u800c\u975e\u7f16\u7801\u56fa\u5b9a\u7684\u4eba\u7c7b\u4ef7\u503c\u5185\u5bb9\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5185\u5bb9\u7684\u4ef7\u503c\u89c4\u8303\u65b9\u6cd5\u5b58\u5728\u7ed3\u6784\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u9700\u8981\u65b0\u7684\u7406\u8bba\u6846\u67b6\u6765\u7406\u89e3\u591a\u667a\u80fd\u4f53\u5bf9\u9f50\u52a8\u6001\uff0c\u5e76\u5efa\u7acb\u771f\u6b63\u7684\u9053\u5fb7\u80fd\u529b\u4e0e\u6a21\u62df\u9053\u5fb7\u80fd\u529b\u4e4b\u95f4\u7684\u529f\u80fd\u533a\u5206\u3002", "method": "\u63d0\u51fa\u4e09\u4e2a\u54f2\u5b66\u8d21\u732e\uff1a1) \u9610\u8ff0\"\u89c4\u8303\u9677\u9631\"\u8bba\u8bc1\uff1b2) \u63d0\u51fa\"\u71b5\u51cf\u6027\"\u4f5c\u4e3a\u4fe1\u606f\u8bba\u6846\u67b6\uff1b3) \u57fa\u4e8e\u517c\u5bb9\u8bba\u6307\u5bfc\u63a7\u5236\u7406\u8bba\u5efa\u7acb\u771f\u5b9e\u4e0e\u6a21\u62df\u9053\u5fb7\u80fd\u529b\u7684\u529f\u80fd\u533a\u5206\uff0c\u5e76\u8bbe\u8ba1\u5177\u8eab\u5b9e\u9a8c\u8303\u5f0f\u548c\u9a8c\u8bc1\u673a\u5236\u3002", "result": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u751f\u6210\u5173\u4e8e\u4eba\u5de5\u7cfb\u7edf\u4e2d\u4ef7\u503c\u6d8c\u73b0\u548c\u9053\u5fb7\u4e3b\u4f53\u6027\u7684\u5177\u4f53\u3001\u53ef\u8bc1\u4f2a\u9884\u6d4b\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4f46\u5b9e\u8bc1\u9a8c\u8bc1\u4ecd\u5728\u8fdb\u884c\u4e2d\uff0c\u5c5e\u4e8e\u66f4\u5e7f\u6cdb\u7814\u7a76\u9879\u76ee\u7684\u54f2\u5b66\u7ec4\u6210\u90e8\u5206\u3002", "conclusion": "AI\u5bf9\u9f50\u5e94\u8f6c\u5411\u57fa\u4e8e\u8fc7\u7a0b\u7684\u3001\u591a\u667a\u80fd\u4f53\u7684\u53d1\u5c55\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u71b5\u51cf\u6027\u548c\u7406\u7531\u54cd\u5e94\u6027\u673a\u5236\u6765\u6784\u5efa\u667a\u80fd\u4f53\uff0c\u800c\u975e\u8bd5\u56fe\u7f16\u7801\u56fa\u5b9a\u7684\u4ef7\u503c\u5185\u5bb9\uff0c\u8fd9\u4e3a\u89e3\u51b3AI\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u54f2\u5b66\u57fa\u7840\u3002"}}
{"id": "2512.03072", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.03072", "abs": "https://arxiv.org/abs/2512.03072", "authors": ["Hu Keyi"], "title": "Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI", "comment": null, "summary": "Current AI paradigms, as \"architects of experience,\" face fundamental challenges in explainability and value alignment. This paper introduces \"Weight-Calculatism,\" a novel cognitive architecture grounded in first principles, and demonstrates its potential as a viable pathway toward Artificial General Intelligence (AGI). The architecture deconstructs cognition into indivisible Logical Atoms and two fundamental operations: Pointing and Comparison. Decision-making is formalized through an interpretable Weight-Calculation model (Weight = Benefit * Probability), where all values are traceable to an auditable set of Initial Weights. This atomic decomposition enables radical explainability, intrinsic generality for novel situations, and traceable value alignment. We detail its implementation via a graph-algorithm-based computational engine and a global workspace workflow, supported by a preliminary code implementation and scenario validation. Results indicate that the architecture achieves transparent, human-like reasoning and robust learning in unprecedented scenarios, establishing a practical and theoretical foundation for building trustworthy and aligned AGI.", "AI": {"tldr": "\u63d0\u51faWeight-Calculatism\u8ba4\u77e5\u67b6\u6784\uff0c\u57fa\u4e8e\u903b\u8f91\u539f\u5b50\u548c\u57fa\u672c\u64cd\u4f5c\uff0c\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u6743\u91cd\u8ba1\u7b97\u6a21\u578b\u5b9e\u73b0AGI\uff0c\u5177\u5907\u900f\u660e\u63a8\u7406\u548c\u53ef\u8ffd\u6eaf\u4ef7\u503c\u5bf9\u9f50\u80fd\u529b", "motivation": "\u5f53\u524dAI\u8303\u5f0f\u4f5c\u4e3a\"\u4f53\u9a8c\u67b6\u6784\u5e08\"\u9762\u4e34\u53ef\u89e3\u91ca\u6027\u548c\u4ef7\u503c\u5bf9\u9f50\u7684\u6839\u672c\u6311\u6218\uff0c\u9700\u8981\u5efa\u7acb\u57fa\u4e8e\u7b2c\u4e00\u539f\u7406\u7684\u8ba4\u77e5\u67b6\u6784\u6765\u5b9e\u73b0\u53ef\u4fe1\u8d56\u7684\u901a\u7528\u4eba\u5de5\u667a\u80fd", "method": "\u5c06\u8ba4\u77e5\u5206\u89e3\u4e3a\u4e0d\u53ef\u5206\u5272\u7684\u903b\u8f91\u539f\u5b50\u548c\u4e24\u4e2a\u57fa\u672c\u64cd\u4f5c\uff08\u6307\u5411\u548c\u6bd4\u8f83\uff09\uff0c\u901a\u8fc7\u6743\u91cd\u8ba1\u7b97\u6a21\u578b\uff08\u6743\u91cd=\u6536\u76ca\u00d7\u6982\u7387\uff09\u5f62\u5f0f\u5316\u51b3\u7b56\uff0c\u6240\u6709\u503c\u53ef\u8ffd\u6eaf\u5230\u53ef\u5ba1\u8ba1\u7684\u521d\u59cb\u6743\u91cd\u96c6\uff0c\u91c7\u7528\u57fa\u4e8e\u56fe\u7b97\u6cd5\u7684\u8ba1\u7b97\u5f15\u64ce\u548c\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u5de5\u4f5c\u6d41\u5b9e\u73b0", "result": "\u8be5\u67b6\u6784\u5b9e\u73b0\u4e86\u900f\u660e\u3001\u7c7b\u4eba\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5728\u5168\u65b0\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u7a33\u5065\u7684\u5b66\u4e60\u80fd\u529b\uff0c\u4e3a\u6784\u5efa\u53ef\u4fe1\u8d56\u548c\u5bf9\u9f50\u7684AGI\u5960\u5b9a\u4e86\u5b9e\u8df5\u548c\u7406\u8bba\u57fa\u7840", "conclusion": "Weight-Calculatism\u8ba4\u77e5\u67b6\u6784\u4e3a\u89e3\u51b3AI\u53ef\u89e3\u91ca\u6027\u548c\u4ef7\u503c\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u5c55\u793a\u4e86\u5411AGI\u53d1\u5c55\u7684\u6f5c\u529b\uff0c\u5efa\u7acb\u4e86\u5b9e\u7528\u4e14\u7406\u8bba\u575a\u5b9e\u7684\u57fa\u7840"}}
{"id": "2512.03272", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03272", "abs": "https://arxiv.org/abs/2512.03272", "authors": ["Zhiyuan He", "Dingmin Wang"], "title": "When Do Symbolic Solvers Enhance Reasoning in Large Language Models?", "comment": null, "summary": "Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains of Thought (CoTs). However, this paradigm might incur substantial token overhead, especially when models \"overthink\" by producing lengthy reasoning chains, which can even lead to incorrect answers. A promising direction is the symbolic-solver-integrated approach, which leverages the code generation capabilities of LLMs to translate reasoning tasks into executable code and then solve them with a symbolic solver. In this paper, we explore an open question of when the conventional long-CoT can be enhanced by symbolic solvers. Our experimental results show that the symbolic-solver-integrated method only helps when the problem requires limited implicit reasoning but involves an ample search space. The latest LLMs, like GPT-4o, show better performance on deductive problems with shallow reasoning depth, while the symbolic-solver-integrated method significantly improves the LLMs' performance in constraint satisfaction problems that require repeated backtracks. When a declarative exemplar is provided, even CodeLlama-13B can outperform GPT-4o in difficult Zebra puzzles.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\u4f55\u65f6\u80fd\u589e\u5f3a\u4f20\u7edf\u957f\u601d\u7ef4\u94fe\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u8be5\u65b9\u6cd5\u4ec5\u5728\u95ee\u9898\u9700\u8981\u6709\u9650\u9690\u5f0f\u63a8\u7406\u4f46\u6d89\u53ca\u5145\u8db3\u641c\u7d22\u7a7a\u95f4\u65f6\u6709\u6548\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u91cd\u590d\u56de\u6eaf\u7684\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\u4e0a\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u751f\u6210\u957f\u601d\u7ef4\u94fe\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u53ef\u80fd\u5bfc\u81f4\u5927\u91cftoken\u5f00\u9500\uff0c\u7279\u522b\u662f\u5f53\u6a21\u578b\"\u8fc7\u5ea6\u601d\u8003\"\u4ea7\u751f\u5197\u957f\u63a8\u7406\u94fe\u65f6\uff0c\u751a\u81f3\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u7b54\u6848\u3002\u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\u5229\u7528LLM\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u5c06\u63a8\u7406\u4efb\u52a1\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u7136\u540e\u7528\u7b26\u53f7\u6c42\u89e3\u5668\u89e3\u51b3\uff0c\u4f46\u4f55\u65f6\u8fd9\u79cd\u65b9\u6cd5\u80fd\u589e\u5f3a\u4f20\u7edf\u957f\u601d\u7ef4\u94fe\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\uff0c\u5229\u7528LLM\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u5c06\u63a8\u7406\u4efb\u52a1\u7ffb\u8bd1\u6210\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u7136\u540e\u4f7f\u7528\u7b26\u53f7\u6c42\u89e3\u5668\u89e3\u51b3\u3002\u7814\u7a76\u63a2\u7d22\u4e86\u8fd9\u79cd\u65b9\u6cd5\u5728\u4f55\u79cd\u6761\u4ef6\u4e0b\u80fd\u589e\u5f3a\u4f20\u7edf\u957f\u601d\u7ef4\u94fe\u7684\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff1a1) \u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\u4ec5\u5728\u95ee\u9898\u9700\u8981\u6709\u9650\u9690\u5f0f\u63a8\u7406\u4f46\u6d89\u53ca\u5145\u8db3\u641c\u7d22\u7a7a\u95f4\u65f6\u6709\u6548\uff1b2) GPT-4o\u7b49\u6700\u65b0LLM\u5728\u63a8\u7406\u6df1\u5ea6\u8f83\u6d45\u7684\u6f14\u7ece\u95ee\u9898\u4e0a\u8868\u73b0\u66f4\u597d\uff1b3) \u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86LLM\u5728\u9700\u8981\u91cd\u590d\u56de\u6eaf\u7684\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\u4e0a\u7684\u6027\u80fd\uff1b4) \u5f53\u63d0\u4f9b\u58f0\u660e\u6027\u793a\u4f8b\u65f6\uff0c\u5373\u4f7f\u662fCodeLlama-13B\u4e5f\u80fd\u5728\u56f0\u96be\u7684\u6591\u9a6c\u8c1c\u9898\u4e0a\u8d85\u8d8aGPT-4o\u3002", "conclusion": "\u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\u5728\u7279\u5b9a\u7c7b\u578b\u7684\u63a8\u7406\u95ee\u9898\u4e2d\u80fd\u6709\u6548\u589e\u5f3a\u4f20\u7edf\u957f\u601d\u7ef4\u94fe\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5927\u91cf\u641c\u7d22\u548c\u56de\u6eaf\u7684\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\u4e0a\uff0c\u4f46\u5bf9\u4e8e\u9700\u8981\u6df1\u5ea6\u9690\u5f0f\u63a8\u7406\u7684\u95ee\u9898\uff0c\u4f20\u7edf\u957f\u601d\u7ef4\u94fe\u65b9\u6cd5\u53ef\u80fd\u66f4\u5408\u9002\u3002"}}
{"id": "2512.03293", "categories": ["cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2512.03293", "abs": "https://arxiv.org/abs/2512.03293", "authors": ["Filippo Torresan", "Ryota Kanai", "Manuel Baltieri"], "title": "Prior preferences in active inference agents: soft, hard, and goal shaping", "comment": "41 pages, 23 figures", "summary": "Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e3b\u52a8\u63a8\u7406\u4e2d\u504f\u597d\u5206\u5e03\u7684\u56db\u79cd\u5b9a\u4e49\u65b9\u5f0f\uff08\u786c\u76ee\u6807vs\u8f6f\u76ee\u6807\uff0c\u6709\u65e0\u76ee\u6807\u5851\u9020\uff09\uff0c\u5728\u7f51\u683c\u4e16\u754c\u5bfc\u822a\u4efb\u52a1\u4e2d\u6bd4\u8f83\u4e86\u5b83\u4eec\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u4e3b\u52a8\u63a8\u7406\u4f7f\u7528\u671f\u671b\u81ea\u7531\u80fd\u4f5c\u4e3a\u89c4\u5212\u51b3\u7b56\u76ee\u6807\uff0c\u4f46\u504f\u597d\u5206\u5e03\u5982\u4f55\u6307\u5b9a\u53ca\u5176\u5bf9\u63a8\u7406\u5b66\u4e60\u7684\u5f71\u54cd\u5728\u6587\u732e\u4e2d\u5f88\u5c11\u88ab\u5173\u6ce8\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u4e0d\u540c\u504f\u597d\u5206\u5e03\u5b9a\u4e49\u65b9\u5f0f\u5bf9\u667a\u80fd\u4f53\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u8003\u8651\u4e86\u56db\u79cd\u5b9a\u4e49\u504f\u597d\u5206\u5e03\u7684\u65b9\u5f0f\uff1a\u786c\u76ee\u6807vs\u8f6f\u76ee\u6807\uff0c\u4ee5\u53ca\u662f\u5426\u5305\u542b\u76ee\u6807\u5851\u9020\uff08\u4e2d\u95f4\u76ee\u6807\uff09\u3002\u5728\u7f51\u683c\u4e16\u754c\u5bfc\u822a\u4efb\u52a1\u4e2d\u6bd4\u8f83\u4e86\u56db\u79cd\u667a\u80fd\u4f53\u7684\u6027\u80fd\u3002", "result": "\u76ee\u6807\u5851\u9020\u603b\u4f53\u4e0a\u80fd\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\uff08\u4fc3\u8fdb\u5229\u7528\uff09\uff0c\u4f46\u4f1a\u727a\u7272\u5bf9\u73af\u5883\u8f6c\u79fb\u52a8\u6001\u7684\u5b66\u4e60\uff08\u963b\u788d\u63a2\u7d22\uff09\u3002", "conclusion": "\u504f\u597d\u5206\u5e03\u7684\u5b9a\u4e49\u65b9\u5f0f\u663e\u8457\u5f71\u54cd\u4e3b\u52a8\u63a8\u7406\u667a\u80fd\u4f53\u7684\u6027\u80fd\uff0c\u76ee\u6807\u5851\u9020\u5728\u63d0\u5347\u5229\u7528\u6548\u7387\u7684\u540c\u65f6\u4f1a\u964d\u4f4e\u63a2\u7d22\u80fd\u529b\uff0c\u9700\u8981\u5728\u4e24\u8005\u4e4b\u95f4\u6743\u8861\u3002"}}
{"id": "2512.03088", "categories": ["cs.CR", "cs.CY", "econ.GN"], "pdf": "https://arxiv.org/pdf/2512.03088", "abs": "https://arxiv.org/abs/2512.03088", "authors": ["Giulio Caldarelli"], "title": "From Oracle Choice to Oracle Lock-In: An Exploratory Study on Blockchain Oracles Supplier Selection", "comment": "Not peer reviewed", "summary": "As data is an essential asset for any Web3 application, selecting an oracle is a critical decision for its success. To date, academic research has mainly focused on improving oracle technology and internal economics, while the drivers of oracle choice on the client side remain largely unexplored. This study fills this gap by gathering insights from leading Web3 protocols, uncovering their rationale for oracle selection and their preferences when deciding whether to outsource or internalize data request mechanisms. The collected data covers more than 55% of the DeFi market cap and is obtained exclusively by protocol executives, board members, or delegates. Insights support the view that protocol choices are tied to technological dependencies, where immutability of smart contracts amplifies lock-in, preventing agile switching among data providers. Furthermore, when viable third-party solutions exist, protocols overwhelmingly prefer outsourcing rather than building and maintaining internal oracle mechanisms.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22Web3\u534f\u8bae\u9009\u62e9\u9884\u8a00\u673a\u7684\u9a71\u52a8\u56e0\u7d20\uff0c\u53d1\u73b0\u6280\u672f\u4f9d\u8d56\u548c\u667a\u80fd\u5408\u7ea6\u4e0d\u53ef\u53d8\u6027\u5bfc\u81f4\u9501\u5b9a\u6548\u5e94\uff0c\u4e14\u5b58\u5728\u53ef\u884c\u7b2c\u4e09\u65b9\u65b9\u6848\u65f6\u534f\u8bae\u66f4\u503e\u5411\u4e8e\u5916\u5305\u800c\u975e\u81ea\u5efa\u9884\u8a00\u673a\u673a\u5236", "motivation": "\u9884\u8a00\u673a\u662fWeb3\u5e94\u7528\u7684\u5173\u952e\u57fa\u7840\u8bbe\u65bd\uff0c\u4f46\u73b0\u6709\u5b66\u672f\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u9884\u8a00\u673a\u6280\u672f\u548c\u5185\u90e8\u7ecf\u6d4e\u673a\u5236\uff0c\u800c\u5ba2\u6237\u7aef\u9009\u62e9\u9884\u8a00\u673a\u7684\u9a71\u52a8\u56e0\u7d20\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d", "method": "\u901a\u8fc7\u6536\u96c6\u9886\u5148Web3\u534f\u8bae\u7684\u89c1\u89e3\uff0c\u4e86\u89e3\u5176\u9009\u62e9\u9884\u8a00\u673a\u7684\u7406\u7531\u4ee5\u53ca\u5728\u51b3\u5b9a\u5916\u5305\u6216\u5185\u90e8\u5316\u6570\u636e\u8bf7\u6c42\u673a\u5236\u65f6\u7684\u504f\u597d\u3002\u6570\u636e\u8986\u76d6\u8d85\u8fc755%\u7684DeFi\u5e02\u503c\uff0c\u4e14\u4e13\u95e8\u4ece\u534f\u8bae\u9ad8\u7ba1\u3001\u8463\u4e8b\u4f1a\u6210\u5458\u6216\u4ee3\u8868\u5904\u83b7\u53d6", "result": "\u7814\u7a76\u53d1\u73b0\u534f\u8bae\u9009\u62e9\u4e0e\u6280\u672f\u4f9d\u8d56\u5bc6\u5207\u76f8\u5173\uff0c\u667a\u80fd\u5408\u7ea6\u7684\u4e0d\u53ef\u53d8\u6027\u52a0\u5267\u4e86\u9501\u5b9a\u6548\u5e94\uff0c\u963b\u788d\u4e86\u5728\u4e0d\u540c\u6570\u636e\u63d0\u4f9b\u5546\u4e4b\u95f4\u7684\u7075\u6d3b\u5207\u6362\u3002\u6b64\u5916\uff0c\u5f53\u5b58\u5728\u53ef\u884c\u7684\u7b2c\u4e09\u65b9\u89e3\u51b3\u65b9\u6848\u65f6\uff0c\u534f\u8bae\u7edd\u5927\u591a\u6570\u503e\u5411\u4e8e\u5916\u5305\u800c\u975e\u81ea\u5efa\u548c\u7ef4\u62a4\u5185\u90e8\u9884\u8a00\u673a\u673a\u5236", "conclusion": "Web3\u534f\u8bae\u5728\u9009\u62e9\u9884\u8a00\u673a\u65f6\u9762\u4e34\u6280\u672f\u9501\u5b9a\u6311\u6218\uff0c\u667a\u80fd\u5408\u7ea6\u7684\u4e0d\u53ef\u53d8\u6027\u9650\u5236\u4e86\u7075\u6d3b\u6027\uff0c\u800c\u5916\u5305\u6210\u4e3a\u4e3b\u6d41\u9009\u62e9\u7b56\u7565\u3002\u8fd9\u4e3a\u9884\u8a00\u673a\u63d0\u4f9b\u5546\u548c\u534f\u8bae\u8bbe\u8ba1\u8005\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a"}}
{"id": "2512.03318", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03318", "abs": "https://arxiv.org/abs/2512.03318", "authors": ["Chandler Smith", "Marwa Abdulhai", "Manfred Diaz", "Marko Tesic", "Rakshit S. Trivedi", "Alexander Sasha Vezhnevets", "Lewis Hammond", "Jesse Clifton", "Minsuk Chang", "Edgar A. Du\u00e9\u00f1ez-Guzm\u00e1n", "John P. Agapiou", "Jayd Matyas", "Danny Karmon", "Akash Kundu", "Aliaksei Korshuk", "Ananya Ananya", "Arrasy Rahman", "Avinaash Anand Kulandaivel", "Bain McHale", "Beining Zhang", "Buyantuev Alexander", "Carlos Saith Rodriguez Rojas", "Caroline Wang", "Chetan Talele", "Chenao Liu", "Chichen Lin", "Diana Riazi", "Di Yang Shi", "Emanuel Tewolde", "Elizaveta Tennant", "Fangwei Zhong", "Fuyang Cui", "Gang Zhao", "Gema Parre\u00f1o Piqueras", "Hyeonggeun Yun", "Ilya Makarov", "Jiaxun Cui", "Jebish Purbey", "Jim Dilkes", "Jord Nguyen", "Lingyun Xiao", "Luis Felipe Giraldo", "Manuela Chacon-Chamorro", "Manuel Sebastian Rios Beltran", "Marta Emili Garc\u00eda Segura", "Mengmeng Wang", "Mogtaba Alim", "Nicanor Quijano", "Nico Schiavone", "Olivia Macmillan-Scott", "Oswaldo Pe\u00f1a", "Peter Stone", "Ram Mohan Rao Kadiyala", "Rolando Fernandez", "Ruben Manrique", "Sunjia Lu", "Sheila A. McIlraith", "Shamika Dhuri", "Shuqing Shi", "Siddhant Gupta", "Sneheel Sarangi", "Sriram Ganapathi Subramanian", "Taehun Cha", "Toryn Q. Klassen", "Wenming Tu", "Weijian Fan", "Wu Ruiyang", "Xue Feng", "Yali Du", "Yang Liu", "Yiding Wang", "Yipeng Kang", "Yoonchang Sung", "Yuxuan Chen", "Zhaowei Zhang", "Zhihan Wang", "Zhiqiang Wu", "Ziang Chen", "Zilong Zheng", "Zixia Jia", "Ziyan Wang", "Dylan Hadfield-Menell", "Natasha Jaques", "Tim Baarslag", "Jose Hernandez-Orallo", "Joel Z. Leibo"], "title": "Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia", "comment": "Published at NeurIPS Datasets and Benchmarks 2025, 10 pages", "summary": "Large Language Model (LLM) agents have demonstrated impressive capabilities for social interaction and are increasingly being deployed in situations where they might engage with both human and artificial agents. These interactions represent a critical frontier for LLM-based agents, yet existing evaluation methods fail to measure how well these capabilities generalize to novel social situations. In this paper, we introduce a method for evaluating the ability of LLM-based agents to cooperate in zero-shot, mixed-motive environments using Concordia, a natural language multi-agent simulation environment. Our method measures general cooperative intelligence by testing an agent's ability to identify and exploit opportunities for mutual gain across diverse partners and contexts. We present empirical results from the NeurIPS 2024 Concordia Contest, where agents were evaluated on their ability to achieve mutual gains across a suite of diverse scenarios ranging from negotiation to collective action problems. Our findings reveal significant gaps between current agent capabilities and the robust generalization required for reliable cooperation, particularly in scenarios demanding persuasion and norm enforcement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u5728\u96f6\u6837\u672c\u6df7\u5408\u52a8\u673a\u73af\u5883\u4e2d\u5408\u4f5c\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528Concordia\u81ea\u7136\u8bed\u8a00\u591a\u667a\u80fd\u4f53\u6a21\u62df\u73af\u5883\uff0c\u901a\u8fc7NeurIPS 2024\u7ade\u8d5b\u63ed\u793a\u4e86\u5f53\u524d\u667a\u80fd\u4f53\u5728\u5408\u4f5c\u6cdb\u5316\u80fd\u529b\u4e0a\u7684\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "LLM\u667a\u80fd\u4f53\u5728\u793e\u4f1a\u4e92\u52a8\u65b9\u9762\u5c55\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u5e76\u88ab\u90e8\u7f72\u5230\u4e0e\u4eba\u7c7b\u548c\u4eba\u5de5\u667a\u80fd\u4f53\u4ea4\u4e92\u7684\u573a\u666f\u4e2d\u3002\u7136\u800c\uff0c\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u8861\u91cf\u8fd9\u4e9b\u80fd\u529b\u5982\u4f55\u6cdb\u5316\u5230\u65b0\u7684\u793e\u4f1a\u60c5\u5883\uff0c\u7279\u522b\u662f\u5408\u4f5c\u80fd\u529b\u5728\u96f6\u6837\u672c\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4f7f\u7528Concordia\u81ea\u7136\u8bed\u8a00\u591a\u667a\u80fd\u4f53\u6a21\u62df\u73af\u5883\u6765\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u7684\u5408\u4f5c\u80fd\u529b\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6d4b\u8bd5\u667a\u80fd\u4f53\u5728\u4e0d\u540c\u5408\u4f5c\u4f19\u4f34\u548c\u60c5\u5883\u4e2d\u8bc6\u522b\u548c\u5229\u7528\u4e92\u5229\u673a\u4f1a\u7684\u80fd\u529b\uff0c\u6765\u8861\u91cf\u4e00\u822c\u5408\u4f5c\u667a\u80fd\u3002\u5728NeurIPS 2024 Concordia\u7ade\u8d5b\u4e2d\uff0c\u667a\u80fd\u4f53\u5728\u4ece\u8c08\u5224\u5230\u96c6\u4f53\u884c\u52a8\u95ee\u9898\u7b49\u591a\u79cd\u573a\u666f\u4e2d\u88ab\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u667a\u80fd\u4f53\u80fd\u529b\u4e0e\u53ef\u9760\u5408\u4f5c\u6240\u9700\u7684\u7a33\u5065\u6cdb\u5316\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u8bf4\u670d\u548c\u89c4\u8303\u6267\u884c\u7684\u573a\u666f\u4e2d\u3002\u7ade\u8d5b\u7ed3\u679c\u63ed\u793a\u4e86LLM\u667a\u80fd\u4f53\u5728\u590d\u6742\u793e\u4f1a\u4e92\u52a8\u4e2d\u7684\u5c40\u9650\u6027\u3002", "conclusion": "LLM\u667a\u80fd\u4f53\u5728\u5408\u4f5c\u80fd\u529b\u65b9\u9762\u4ecd\u9700\u663e\u8457\u6539\u8fdb\uff0c\u7279\u522b\u662f\u5728\u96f6\u6837\u672c\u6df7\u5408\u52a8\u673a\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002Concordia\u8bc4\u4f30\u6846\u67b6\u4e3a\u8861\u91cf\u548c\u63d0\u5347\u667a\u80fd\u4f53\u793e\u4f1a\u5408\u4f5c\u80fd\u529b\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2512.03594", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.03594", "abs": "https://arxiv.org/abs/2512.03594", "authors": ["Afsara Khan", "Austin Rovinski"], "title": "Accelerating Detailed Routing Convergence through Offline Reinforcement Learning", "comment": "To be published in the Design, Automation and Test in Europe (DATE) 2026 Conference", "summary": "Detailed routing remains one of the most complex and time-consuming steps in modern physical design due to the challenges posed by shrinking feature sizes and stricter design rules. Prior detailed routers achieve state-of-the-art results by leveraging iterative pathfinding algorithms to route each net. However, runtimes are a major issue in detailed routers, as converging to a solution with zero design rule violations (DRVs) can be prohibitively expensive.\n  In this paper, we propose leveraging reinforcement learning (RL) to enable rapid convergence in detailed routing by learning from previous designs. We make the key observation that prior detailed routers statically schedule the cost weights used in their routing algorithms, meaning they do not change in response to the design or technology. By training a conservative Q-learning (CQL) model to dynamically select the routing cost weights which minimize the number of algorithm iterations, we find that our work completes the ISPD19 benchmarks with 1.56x average and up to 3.01x faster runtime than the baseline router while maintaining or improving the DRV count in all cases. We also find that this learning shows signs of generalization across technologies, meaning that learning designs in one technology can translate to improved outcomes in other technologies.", "AI": {"tldr": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u8be6\u7ec6\u5e03\u7ebf\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u5e03\u7ebf\u6210\u672c\u6743\u91cd\uff0c\u76f8\u6bd4\u57fa\u7ebf\u8def\u7531\u5668\u5b9e\u73b01.56\u500d\u5e73\u5747\u52a0\u901f\uff0c\u6700\u9ad8\u8fbe3.01\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u6539\u8fdb\u8bbe\u8ba1\u89c4\u5219\u8fdd\u89c4\u6570\u91cf\u3002", "motivation": "\u73b0\u4ee3\u7269\u7406\u8bbe\u8ba1\u4e2d\u8be6\u7ec6\u5e03\u7ebf\u6b65\u9aa4\u590d\u6742\u8017\u65f6\uff0c\u4f20\u7edf\u8def\u7531\u5668\u4f7f\u7528\u9759\u6001\u6210\u672c\u6743\u91cd\u8c03\u5ea6\uff0c\u65e0\u6cd5\u6839\u636e\u8bbe\u8ba1\u548c\u5de5\u827a\u52a8\u6001\u8c03\u6574\uff0c\u5bfc\u81f4\u6536\u655b\u5230\u96f6\u8bbe\u8ba1\u89c4\u5219\u8fdd\u89c4\u7684\u8fd0\u884c\u65f6\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u91c7\u7528\u4fdd\u5b88Q\u5b66\u4e60\uff08CQL\uff09\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\uff0c\u8bad\u7ec3\u6a21\u578b\u52a8\u6001\u9009\u62e9\u6700\u5c0f\u5316\u7b97\u6cd5\u8fed\u4ee3\u6b21\u6570\u7684\u5e03\u7ebf\u6210\u672c\u6743\u91cd\uff0c\u5b66\u4e60\u4ece\u5148\u524d\u8bbe\u8ba1\u4e2d\u83b7\u5f97\u7684\u7ecf\u9a8c\u6765\u52a0\u901f\u6536\u655b\u3002", "result": "\u5728ISPD19\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u57fa\u7ebf\u8def\u7531\u5668\u5b9e\u73b01.56\u500d\u5e73\u5747\u52a0\u901f\uff0c\u6700\u9ad8\u8fbe3.01\u500d\uff0c\u6240\u6709\u60c5\u51b5\u4e0b\u4fdd\u6301\u6216\u6539\u8fdb\u4e86\u8bbe\u8ba1\u89c4\u5219\u8fdd\u89c4\u6570\u91cf\uff0c\u5e76\u663e\u793a\u51fa\u8de8\u5de5\u827a\u6280\u672f\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u80fd\u591f\u6709\u6548\u4f18\u5316\u8be6\u7ec6\u5e03\u7ebf\u8fc7\u7a0b\uff0c\u901a\u8fc7\u52a8\u6001\u6210\u672c\u6743\u91cd\u9009\u62e9\u663e\u8457\u51cf\u5c11\u8fd0\u884c\u65f6\uff0c\u540c\u65f6\u4fdd\u6301\u5e03\u7ebf\u8d28\u91cf\uff0c\u4e14\u5b66\u4e60\u5230\u7684\u7b56\u7565\u5177\u6709\u8de8\u5de5\u827a\u6280\u672f\u7684\u6cdb\u5316\u6f5c\u529b\u3002"}}
{"id": "2512.03565", "categories": ["cs.DC", "cs.CE", "cs.PF"], "pdf": "https://arxiv.org/pdf/2512.03565", "abs": "https://arxiv.org/abs/2512.03565", "authors": ["Luis Gall", "Samuel James Newcome", "Fabio Alexander Gratl", "Markus M\u00fchlh\u00e4u\u00dfer", "Manish Kumar Mishra", "Hans-Joachim Bungartz"], "title": "Tuning of Vectorization Parameters for Molecular Dynamics Simulations in AutoPas", "comment": "20 pages, 8 figures. Submitted to the 5th International Conference on Computational Engineering (ICCE 2024). No changes were made after the peer review process", "summary": "Molecular Dynamics simulations can help scientists to gather valuable insights for physical processes on an atomic scale. This work explores various techniques for SIMD vectorization to improve the pairwise force calculation between molecules in the scope of the particle simulation library AutoPas. The focus lies on the order in which particle values are loaded into vector registers to achieve the most optimal performance regarding execution time or energy consumption.\n  As previous work indicates that the optimal MD algorithm can change during runtime, this paper investigates simulation-specific parameters like particle density and the impact of the neighbor identification algorithms, which distinguishes this work from related projects. Furthermore, AutoPas' dynamic tuning mechanism is extended to choose the optimal vectorization order during runtime.\n  The benchmarks show that considering different particle interaction orders during runtime can lead to a considerable performance improvement for the force calculation compared to AutoPas' previous approach.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u4e2dSIMD\u5411\u91cf\u5316\u7684\u4e0d\u540c\u6280\u672f\uff0c\u91cd\u70b9\u5173\u6ce8\u7c92\u5b50\u503c\u52a0\u8f7d\u5230\u5411\u91cf\u5bc4\u5b58\u5668\u7684\u987a\u5e8f\u4f18\u5316\uff0c\u4ee5\u63d0\u5347\u7c92\u5b50\u95f4\u529b\u8ba1\u7b97\u7684\u6027\u80fd\u6216\u964d\u4f4e\u80fd\u8017\u3002", "motivation": "\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u80fd\u4e3a\u539f\u5b50\u5c3a\u5ea6\u7269\u7406\u8fc7\u7a0b\u63d0\u4f9b\u5b9d\u8d35\u89c1\u89e3\u3002\u5148\u524d\u7814\u7a76\u8868\u660e\u6700\u4f18MD\u7b97\u6cd5\u53ef\u80fd\u5728\u8fd0\u884c\u65f6\u53d1\u751f\u53d8\u5316\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u7279\u5b9a\u6a21\u62df\u53c2\u6570\uff08\u5982\u7c92\u5b50\u5bc6\u5ea6\uff09\u548c\u90bb\u57df\u8bc6\u522b\u7b97\u6cd5\u7684\u5f71\u54cd\uff0c\u5e76\u6269\u5c55AutoPas\u7684\u52a8\u6001\u8c03\u4f18\u673a\u5236\u4ee5\u5728\u8fd0\u884c\u65f6\u9009\u62e9\u6700\u4f18\u5411\u91cf\u5316\u987a\u5e8f\u3002", "method": "\u63a2\u7d22\u4e86\u591a\u79cdSIMD\u5411\u91cf\u5316\u6280\u672f\uff0c\u7279\u522b\u5173\u6ce8\u7c92\u5b50\u503c\u52a0\u8f7d\u5230\u5411\u91cf\u5bc4\u5b58\u5668\u7684\u987a\u5e8f\u4f18\u5316\u3002\u7814\u7a76\u4e86\u7c92\u5b50\u5bc6\u5ea6\u7b49\u6a21\u62df\u7279\u5b9a\u53c2\u6570\u548c\u90bb\u57df\u8bc6\u522b\u7b97\u6cd5\u7684\u5f71\u54cd\uff0c\u6269\u5c55\u4e86AutoPas\u7684\u52a8\u6001\u8c03\u4f18\u673a\u5236\u4ee5\u5728\u8fd0\u884c\u65f6\u9009\u62e9\u6700\u4f18\u5411\u91cf\u5316\u987a\u5e8f\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0c\u5728\u8fd0\u884c\u65f6\u8003\u8651\u4e0d\u540c\u7684\u7c92\u5b50\u76f8\u4e92\u4f5c\u7528\u987a\u5e8f\u76f8\u6bd4AutoPas\u5148\u524d\u65b9\u6cd5\uff0c\u80fd\u663e\u8457\u63d0\u5347\u529b\u8ba1\u7b97\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u7c92\u5b50\u503c\u52a0\u8f7d\u987a\u5e8f\u5e76\u5229\u7528\u52a8\u6001\u8c03\u4f18\u673a\u5236\u5728\u8fd0\u884c\u65f6\u9009\u62e9\u6700\u4f18\u5411\u91cf\u5316\u7b56\u7565\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u4e2d\u529b\u8ba1\u7b97\u7684\u6027\u80fd\uff0c\u8fd9\u4e3a\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e2d\u7684\u7c92\u5b50\u6a21\u62df\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4f18\u5316\u65b9\u6cd5\u3002"}}
{"id": "2512.03608", "categories": ["cs.AR", "cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.03608", "abs": "https://arxiv.org/abs/2512.03608", "authors": ["Lishuo Deng", "Shaojie Xu", "Jinwu Chen", "Changwei Yan", "Jiajie Wang", "Zhe Jiang", "Weiwei Shan"], "title": "KVNAND: Efficient On-Device Large Language Model Inference Using DRAM-Free In-Flash Computing", "comment": null, "summary": "Deploying large language models (LLMs) on edge devices enables personalized agents with strong privacy and low cost. However, with tens to hundreds of billions of parameters, single-batch autoregressive inference suffers from extremely low arithmetic intensity, creating severe weight-loading and bandwidth pressures on resource-constrained platforms. Recent in-flash computing (IFC) solutions alleviate this bottleneck by co-locating weight-related linear computations in the decode phase with flash, yet still rely on DRAM for the key-value (KV) cache. As context length grows, the KV cache can exceed model weights in size, imposing prohibitive DRAM cost and capacity requirements. Attempts to offload KV cache to flash suffer from severe performance penalties.\n  We propose KVNAND, the first DRAM-free, IFC-based architecture that stores both model weights and KV cache entirely in compute-enabled 3D NAND flash. KVNAND addresses the fundamental performance challenges of flash under intensive KV cache access by leveraging IFC for all memory-bound operations to reduce data transfer overhead, introducing head-group parallelism to boost throughput, and employing page-level KV cache mapping to align token access patterns with flash organization. In addition, we propose a design space exploration framework that evaluates discrete and compact KVNAND variants to balance weight and KV placement, automatically identifying the optimal design trade-off. These techniques mitigate latency, energy, and reliability concerns, turning flash into a practical medium for long-context KV storage. Evaluations on MHA 7B and GQA 70B LLMs show that KVNAND achieves 1.98\\(\\times\\)/1.94\\(\\times\\)/2.05\\(\\times\\) geomean speedup at 128/1K/10K-token contexts compared to DRAM-equipped IFC designs and addresses out-of-memory failures at 100K context length.", "AI": {"tldr": "KVNAND\uff1a\u9996\u4e2a\u57fa\u4e8e\u95ea\u5b58\u8ba1\u7b97\u7684DRAM-free\u67b6\u6784\uff0c\u5c06\u6a21\u578b\u6743\u91cd\u548cKV\u7f13\u5b58\u5b8c\u5168\u5b58\u50a8\u57283D NAND\u95ea\u5b58\u4e2d\uff0c\u89e3\u51b3\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u7684\u5185\u5b58\u74f6\u9888\u95ee\u9898", "motivation": "\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u5185\u5b58\u74f6\u9888\uff1a\u5355\u6279\u6b21\u81ea\u56de\u5f52\u63a8\u7406\u7b97\u672f\u5f3a\u5ea6\u4f4e\uff0c\u6743\u91cd\u52a0\u8f7d\u548c\u5e26\u5bbd\u538b\u529b\u5927\uff1b\u73b0\u6709\u95ea\u5b58\u8ba1\u7b97\u65b9\u6848\u4ecd\u4f9d\u8d56DRAM\u5b58\u50a8KV\u7f13\u5b58\uff0c\u968f\u7740\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u52a0\uff0cKV\u7f13\u5b58\u53ef\u80fd\u8d85\u8fc7\u6a21\u578b\u6743\u91cd\u5927\u5c0f\uff0c\u9020\u6210DRAM\u6210\u672c\u8fc7\u9ad8\u548c\u5bb9\u91cf\u4e0d\u8db3\u95ee\u9898", "method": "\u63d0\u51faKVNAND\u67b6\u6784\uff1a1) \u5229\u7528\u95ea\u5b58\u8ba1\u7b97\u5904\u7406\u6240\u6709\u5185\u5b58\u53d7\u9650\u64cd\u4f5c\u4ee5\u51cf\u5c11\u6570\u636e\u4f20\u8f93\u5f00\u9500\uff1b2) \u5f15\u5165\u5934\u7ec4\u5e76\u884c\u6027\u63d0\u5347\u541e\u5410\u91cf\uff1b3) \u91c7\u7528\u9875\u9762\u7ea7KV\u7f13\u5b58\u6620\u5c04\u4f7f\u4ee4\u724c\u8bbf\u95ee\u6a21\u5f0f\u4e0e\u95ea\u5b58\u7ec4\u7ec7\u5bf9\u9f50\uff1b4) \u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u6846\u67b6\u8bc4\u4f30\u79bb\u6563\u548c\u7d27\u51d1\u53d8\u4f53\uff0c\u81ea\u52a8\u8bc6\u522b\u6700\u4f73\u8bbe\u8ba1\u6743\u8861", "result": "\u5728MHA 7B\u548cGQA 70B LLM\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u5728128/1K/10K\u4ee4\u724c\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\uff0c\u76f8\u6bd4DRAM-equipped IFC\u8bbe\u8ba1\u5206\u522b\u83b7\u5f971.98\u00d7/1.94\u00d7/2.05\u00d7\u51e0\u4f55\u5e73\u5747\u52a0\u901f\uff0c\u5e76\u5728100K\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u89e3\u51b3\u4e86\u5185\u5b58\u4e0d\u8db3\u95ee\u9898", "conclusion": "KVNAND\u901a\u8fc7\u5c06KV\u7f13\u5b58\u5b8c\u5168\u5b58\u50a8\u5728\u95ea\u5b58\u4e2d\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u7684\u5ef6\u8fdf\u3001\u80fd\u8017\u548c\u53ef\u9760\u6027\u95ee\u9898\uff0c\u4f7f\u95ea\u5b58\u6210\u4e3a\u957f\u4e0a\u4e0b\u6587KV\u5b58\u50a8\u7684\u5b9e\u7528\u4ecb\u8d28"}}
{"id": "2512.03528", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.03528", "abs": "https://arxiv.org/abs/2512.03528", "authors": ["Guang Yang", "Tianpei Yang", "Jingwen Qiao", "Yanqing Wu", "Jing Huo", "Xingguo Chen", "Yang Gao"], "title": "Multi-Agent Reinforcement Learning with Communication-Constrained Priors", "comment": null, "summary": "Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u4fe1\u53d7\u9650\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u533a\u5206\u6709\u635f\u548c\u65e0\u635f\u6d88\u606f\uff0c\u5c06\u901a\u4fe1\u5f71\u54cd\u91cf\u5316\u4e3a\u5168\u5c40\u5956\u52b1\uff0c\u63d0\u5347\u5728\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u901a\u4fe1\u901a\u5e38\u5b58\u5728\u6709\u635f\u95ee\u9898\uff0c\u73b0\u6709\u591a\u667a\u80fd\u4f53\u901a\u4fe1\u65b9\u6cd5\u7531\u4e8e\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u6709\u9650\uff0c\u96be\u4ee5\u5e94\u7528\u4e8e\u590d\u6742\u52a8\u6001\u73af\u5883\u3002", "method": "\u63d0\u51fa\u901a\u7528\u901a\u4fe1\u7ea6\u675f\u6a21\u578b\u7edf\u4e00\u63cf\u8ff0\u4e0d\u540c\u573a\u666f\u7684\u901a\u4fe1\u6761\u4ef6\uff1b\u4f5c\u4e3a\u5b66\u4e60\u5148\u9a8c\u533a\u5206\u6709\u635f\u548c\u65e0\u635f\u6d88\u606f\uff1b\u4f7f\u7528\u53cc\u91cd\u4e92\u4fe1\u606f\u4f30\u8ba1\u5668\u89e3\u8026\u6709\u635f\u548c\u65e0\u635f\u6d88\u606f\u5bf9\u5206\u5e03\u5f0f\u51b3\u7b56\u7684\u5f71\u54cd\uff1b\u5f15\u5165\u901a\u4fe1\u7ea6\u675f\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u901a\u4fe1\u6d88\u606f\u5f71\u54cd\u91cf\u5316\u4e3a\u5168\u5c40\u5956\u52b1\u3002", "result": "\u5728\u591a\u4e2a\u901a\u4fe1\u53d7\u9650\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u901a\u4fe1\u7ea6\u675f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u6709\u635f\u901a\u4fe1\u95ee\u9898\uff0c\u63d0\u5347\u5728\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5b66\u4e60\u6027\u80fd\u3002"}}
{"id": "2512.03100", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03100", "abs": "https://arxiv.org/abs/2512.03100", "authors": ["Haowei Fu", "Bo Ni", "Han Xu", "Kunpeng Liu", "Dan Lin", "Tyler Derr"], "title": "Ensemble Privacy Defense for Knowledge-Intensive LLMs against Membership Inference Attacks", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) and Supervised Finetuning (SFT) have become the predominant paradigms for equipping Large Language Models (LLMs) with external knowledge for diverse, knowledge-intensive tasks. However, while such knowledge injection improves performance, it also exposes new attack surfaces. Membership Inference Attacks (MIAs), which aim to determine whether a given data sample was included in a model's training set, pose serious threats to privacy and trust in sensitive domains. To this end, we first systematically evaluate the vulnerability of RAG- and SFT-based LLMs to various MIAs. Then, to address the privacy risk, we further introduce a novel, model-agnostic defense framework, Ensemble Privacy Defense (EPD), which aggregates and evaluates the outputs of a knowledge-injected LLM, a base LLM, and a dedicated judge model to enhance resistance against MIAs. Comprehensive experiments show that, on average, EPD reduces MIA success by up to 27.8\\% for SFT and 526.3\\% for RAG compared to inference-time baseline, while maintaining answer quality.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86RAG\u548cSFT\u589e\u5f3a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEPD\u7684\u6a21\u578b\u65e0\u5173\u9632\u5fa1\u6846\u67b6\u6765\u964d\u4f4e\u9690\u79c1\u98ce\u9669\u3002", "motivation": "\u867d\u7136RAG\u548cSFT\u80fd\u591f\u4e3aLLMs\u6ce8\u5165\u5916\u90e8\u77e5\u8bc6\u4ee5\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u8fd9\u4e5f\u66b4\u9732\u4e86\u65b0\u7684\u653b\u51fb\u9762\u3002\u6210\u5458\u63a8\u7406\u653b\u51fb(MIAs)\u65e8\u5728\u5224\u65ad\u7279\u5b9a\u6570\u636e\u6837\u672c\u662f\u5426\u5305\u542b\u5728\u6a21\u578b\u8bad\u7ec3\u96c6\u4e2d\uff0c\u5bf9\u654f\u611f\u9886\u57df\u7684\u9690\u79c1\u548c\u4fe1\u4efb\u6784\u6210\u4e25\u91cd\u5a01\u80c1\u3002", "method": "\u9996\u5148\u7cfb\u7edf\u8bc4\u4f30\u4e86\u57fa\u4e8eRAG\u548cSFT\u7684LLMs\u5bf9\u5404\u79cdMIAs\u7684\u8106\u5f31\u6027\u3002\u7136\u540e\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6a21\u578b\u65e0\u5173\u9632\u5fa1\u6846\u67b6\u2014\u2014\u96c6\u6210\u9690\u79c1\u9632\u5fa1(EPD)\uff0c\u8be5\u6846\u67b6\u805a\u5408\u5e76\u8bc4\u4f30\u77e5\u8bc6\u6ce8\u5165LLM\u3001\u57fa\u7840LLM\u548c\u4e13\u7528\u5224\u65ad\u6a21\u578b\u7684\u8f93\u51fa\uff0c\u4ee5\u589e\u5f3a\u5bf9MIAs\u7684\u62b5\u6297\u80fd\u529b\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cEPD\u5e73\u5747\u5c06SFT\u7684MIA\u6210\u529f\u7387\u964d\u4f4e27.8%\uff0c\u5c06RAG\u7684MIA\u6210\u529f\u7387\u964d\u4f4e526.3%\uff08\u76f8\u6bd4\u63a8\u7406\u65f6\u57fa\u7ebf\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u56de\u7b54\u8d28\u91cf\u3002", "conclusion": "EPD\u662f\u4e00\u79cd\u6709\u6548\u7684\u9632\u5fa1\u6846\u67b6\uff0c\u80fd\u591f\u663e\u8457\u964d\u4f4eRAG\u548cSFT\u589e\u5f3aLLMs\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u7ef4\u6301\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2512.03616", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.03616", "abs": "https://arxiv.org/abs/2512.03616", "authors": ["Christian Ewert", "Amrit Sharma Poudel", "Mouadh Ayache", "Andrija Neskovic", "Rainer Buchty", "Mladen Berekovic", "Sebastian Berndt", "Saleh Mulhem"], "title": "Lightweight Unified Sha-3/Shake Architecture with a Fault-Resilient State", "comment": "-", "summary": "Hash functions have become a key part of standard Post-quantum cryptography (PQC) schemes, especially Sha-3 and Shake, calling arXiv:submit/7045552 [cs.AR] 3 Dec 2025 for lightweight implementation. A fault-resilient design is always desirable to make the whole PQC system reliable. We, therefore, propose a) a unified hash engine supporting Sha-3 and Shake that follows a byte-wise in-place partitioning mechanism of the so-called Keccak state, and b) an according fault detection for Keccak state protection exploiting its cube structure by deploying two-dimensional parity checks. It outperforms the state-of-the-art (SoA) regarding area requirements at competitive register-level fault detection by achieving 100% detection of three and still near 100% of higher numbers of Keccak state faults. Unlike SoA solutions, the proposed unified hash engine covers all standard hash configurations. Moreover, the introduced multidimensional cross-parity check mechanism achieves a 3.7x improvement in area overhead, with an overall 4.5x smaller fault-resilient engine design as demonstrated in ASIC and FPGA implementations. Integrated into a RISC-V environment, the unified hash engine with the integrated fault-resilient mechanism introduced less than 8% area overhead. Our approach thus provides a robust and lightweight fault-detection solution for protecting hash functions deployed in resource-constrained PQC applications.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u54c8\u5e0c\u5f15\u64ce\u652f\u6301Sha-3\u548cShake\uff0c\u91c7\u7528\u5b57\u8282\u7ea7\u539f\u5730\u5206\u533aKeccak\u72b6\u6001\u673a\u5236\uff0c\u5e76\u57fa\u4e8e\u7acb\u65b9\u4f53\u7ed3\u6784\u90e8\u7f72\u4e8c\u7ef4\u5947\u5076\u6821\u9a8c\u5b9e\u73b0\u6545\u969c\u68c0\u6d4b\uff0c\u5728\u4fdd\u6301\u7ade\u4e89\u6027\u6545\u969c\u68c0\u6d4b\u80fd\u529b\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u9762\u79ef\u5f00\u9500\u3002", "motivation": "\u54c8\u5e0c\u51fd\u6570\u5df2\u6210\u4e3a\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u6807\u51c6\u65b9\u6848\u7684\u5173\u952e\u90e8\u5206\uff0c\u7279\u522b\u662fSha-3\u548cShake\u3002\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\uff0c\u9700\u8981\u8f7b\u91cf\u7ea7\u5b9e\u73b0\u3002\u6545\u969c\u5f39\u6027\u8bbe\u8ba1\u5bf9\u4e8e\u786e\u4fdd\u6574\u4e2aPQC\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u652f\u6301\u6807\u51c6\u54c8\u5e0c\u914d\u7f6e\u53c8\u80fd\u63d0\u4f9b\u6709\u6548\u6545\u969c\u4fdd\u62a4\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1) \u63d0\u51fa\u7edf\u4e00\u54c8\u5e0c\u5f15\u64ce\uff0c\u652f\u6301Sha-3\u548cShake\uff0c\u91c7\u7528\u5b57\u8282\u7ea7\u539f\u5730\u5206\u533a\u673a\u5236\u5904\u7406Keccak\u72b6\u6001\uff1b2) \u57fa\u4e8eKeccak\u72b6\u6001\u7684\u7acb\u65b9\u4f53\u7ed3\u6784\uff0c\u90e8\u7f72\u4e8c\u7ef4\u5947\u5076\u6821\u9a8c\u5b9e\u73b0\u6545\u969c\u68c0\u6d4b\uff1b3) \u901a\u8fc7\u591a\u7ef4\u4ea4\u53c9\u5947\u5076\u6821\u9a8c\u673a\u5236\u4f18\u5316\u9762\u79ef\u5f00\u9500\uff1b4) \u5728ASIC\u548cFPGA\u4e0a\u5b9e\u73b0\u9a8c\u8bc1\uff0c\u5e76\u96c6\u6210\u5230RISC-V\u73af\u5883\u4e2d\u3002", "result": "1) \u5b9e\u73b0100%\u68c0\u6d4b\u4e09\u4e2aKeccak\u72b6\u6001\u6545\u969c\uff0c\u5bf9\u66f4\u9ad8\u6570\u91cf\u6545\u969c\u68c0\u6d4b\u7387\u63a5\u8fd1100%\uff1b2) \u76f8\u6bd4\u73b0\u6709\u6280\u672f\uff0c\u9762\u79ef\u5f00\u9500\u6539\u55843.7\u500d\uff0c\u6574\u4f53\u6545\u969c\u5f39\u6027\u5f15\u64ce\u8bbe\u8ba1\u7f29\u5c0f4.5\u500d\uff1b3) \u7edf\u4e00\u54c8\u5e0c\u5f15\u64ce\u8986\u76d6\u6240\u6709\u6807\u51c6\u54c8\u5e0c\u914d\u7f6e\uff1b4) \u96c6\u6210\u5230RISC-V\u73af\u5883\u65f6\uff0c\u9762\u79ef\u5f00\u9500\u589e\u52a0\u5c0f\u4e8e8%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u5e94\u7528\u63d0\u4f9b\u4e86\u9c81\u68d2\u4e14\u8f7b\u91cf\u7ea7\u7684\u6545\u969c\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u9ad8\u6548\u6545\u969c\u68c0\u6d4b\u80fd\u529b\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u786c\u4ef6\u5b9e\u73b0\u6210\u672c\uff0c\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2512.03121", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03121", "abs": "https://arxiv.org/abs/2512.03121", "authors": ["Ziyi Tong", "Feifei Sun", "Le Minh Nguyen"], "title": "Lost in Modality: Evaluating the Effectiveness of Text-Based Membership Inference Attacks on Large Multimodal Models", "comment": null, "summary": "Large Multimodal Language Models (MLLMs) are emerging as one of the foundational tools in an expanding range of applications. Consequently, understanding training-data leakage in these systems is increasingly critical. Log-probability-based membership inference attacks (MIAs) have become a widely adopted approach for assessing data exposure in large language models (LLMs), yet their effect in MLLMs remains unclear. We present the first comprehensive evaluation of extending these text-based MIA methods to multimodal settings. Our experiments under vision-and-text (V+T) and text-only (T-only) conditions across the DeepSeek-VL and InternVL model families show that in in-distribution settings, logit-based MIAs perform comparably across configurations, with a slight V+T advantage. Conversely, in out-of-distribution settings, visual inputs act as regularizers, effectively masking membership signals.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5168\u9762\u8bc4\u4f30\u4e86\u5c06\u57fa\u4e8e\u5bf9\u6570\u6982\u7387\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u4ece\u7eaf\u6587\u672c\u6a21\u578b\u6269\u5c55\u5230\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6548\u679c\uff0c\u53d1\u73b0\u5728\u5206\u5e03\u5185\u8bbe\u7f6e\u4e2d\u89c6\u89c9+\u6587\u672c\u8f93\u5165\u7565\u6709\u4f18\u52bf\uff0c\u800c\u5728\u5206\u5e03\u5916\u8bbe\u7f6e\u4e2d\u89c6\u89c9\u8f93\u5165\u4f1a\u63a9\u76d6\u6210\u5458\u4fe1\u53f7\u3002", "motivation": "\u968f\u7740\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6210\u4e3a\u57fa\u7840\u5de5\u5177\uff0c\u7406\u89e3\u5176\u8bad\u7ec3\u6570\u636e\u6cc4\u9732\u95ee\u9898\u53d8\u5f97\u65e5\u76ca\u91cd\u8981\u3002\u867d\u7136\u57fa\u4e8e\u5bf9\u6570\u6982\u7387\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u5728\u7eaf\u6587\u672c\u6a21\u578b\u4e2d\u5df2\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u5176\u5728\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u7684\u6548\u679c\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u5c06\u57fa\u4e8e\u5bf9\u6570\u6982\u7387\u7684\u6587\u672c\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\u6269\u5c55\u5230\u591a\u6a21\u6001\u8bbe\u7f6e\uff0c\u5728DeepSeek-VL\u548cInternVL\u6a21\u578b\u5bb6\u65cf\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5bf9\u6bd4\u89c6\u89c9+\u6587\u672c\u548c\u7eaf\u6587\u672c\u4e24\u79cd\u8f93\u5165\u6761\u4ef6\u4e0b\u7684\u653b\u51fb\u6548\u679c\u3002", "result": "\u5728\u5206\u5e03\u5185\u8bbe\u7f6e\u4e2d\uff0c\u57fa\u4e8elogit\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u5728\u4e0d\u540c\u914d\u7f6e\u4e0b\u8868\u73b0\u76f8\u5f53\uff0c\u89c6\u89c9+\u6587\u672c\u8f93\u5165\u7565\u6709\u4f18\u52bf\uff1b\u5728\u5206\u5e03\u5916\u8bbe\u7f6e\u4e2d\uff0c\u89c6\u89c9\u8f93\u5165\u8d77\u5230\u4e86\u6b63\u5219\u5316\u4f5c\u7528\uff0c\u6709\u6548\u5730\u63a9\u76d6\u4e86\u6210\u5458\u4fe1\u53f7\u3002", "conclusion": "\u89c6\u89c9\u8f93\u5165\u5728\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u4e2d\u5177\u6709\u53cc\u91cd\u4f5c\u7528\uff1a\u5728\u5206\u5e03\u5185\u8bbe\u7f6e\u4e2d\u80fd\u7565\u5fae\u589e\u5f3a\u653b\u51fb\u6548\u679c\uff0c\u800c\u5728\u5206\u5e03\u5916\u8bbe\u7f6e\u4e2d\u5219\u80fd\u6709\u6548\u4fdd\u62a4\u6a21\u578b\u9690\u79c1\uff0c\u8fd9\u4e3a\u7406\u89e3\u591a\u6a21\u6001\u6a21\u578b\u7684\u9690\u79c1\u7279\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2512.03697", "categories": ["cs.DC", "cs.MS"], "pdf": "https://arxiv.org/pdf/2512.03697", "abs": "https://arxiv.org/abs/2512.03697", "authors": ["Rafael Ravedutti Lucio Machado", "Jan Eitzinger", "Georg Hager", "Gerhard Wellein"], "title": "On the Challenges of Energy-Efficiency Analysis in HPC Systems: Evaluating Synthetic Benchmarks and Gromacs", "comment": "8 pages, 4 figures, conference", "summary": "This paper discusses the challenges encountered when analyzing the energy efficiency of synthetic benchmarks and the Gromacs package on the Fritz and Alex HPC clusters. Experiments were conducted using MPI parallelism on full sockets of Intel Ice Lake and Sapphire Rapids CPUs, as well as Nvidia A40 and A100 GPUs. The metrics and measurements obtained with the Likwid and Nvidia profiling tools are presented, along with the results. The challenges and pitfalls encountered during experimentation and analysis are revealed and discussed. Best practices for future energy efficiency analysis studies are suggested.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u5728Fritz\u548cAlex HPC\u96c6\u7fa4\u4e0a\u4f7f\u7528\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u548cGromacs\u8f6f\u4ef6\u5305\u8fdb\u884c\u80fd\u6548\u5206\u6790\u65f6\u9047\u5230\u7684\u6311\u6218\uff0c\u5b9e\u9a8c\u4f7f\u7528\u4e86Intel Ice Lake\u548cSapphire Rapids CPU\u4ee5\u53caNvidia A40\u548cA100 GPU\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u80fd\u6548\u5206\u6790\u7684\u6700\u4f73\u5b9e\u8df5\u3002", "motivation": "\u9ad8\u6027\u80fd\u8ba1\u7b97\u96c6\u7fa4\u7684\u80fd\u6548\u5206\u6790\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u4f7f\u7528\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u548c\u5b9e\u9645\u5e94\u7528\u8f6f\u4ef6\u5305\uff08\u5982Gromacs\uff09\u65f6\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u8bc6\u522b\u548c\u89e3\u51b3\u5b9e\u9a8c\u4e0e\u5206\u6790\u8fc7\u7a0b\u4e2d\u7684\u56f0\u96be\uff0c\u4e3a\u672a\u6765\u7684\u80fd\u6548\u7814\u7a76\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u5728Fritz\u548cAlex HPC\u96c6\u7fa4\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4f7f\u7528MPI\u5e76\u884c\u5316\u6280\u672f\uff0c\u8986\u76d6Intel Ice Lake\u548cSapphire Rapids CPU\u4ee5\u53caNvidia A40\u548cA100 GPU\u3002\u91c7\u7528Likwid\u548cNvidia\u6027\u80fd\u5206\u6790\u5de5\u5177\u6536\u96c6\u6307\u6807\u6570\u636e\uff0c\u7cfb\u7edf\u6027\u5730\u5206\u6790\u80fd\u6548\u8868\u73b0\u3002", "result": "\u5c55\u793a\u4e86\u4f7f\u7528Likwid\u548cNvidia\u5206\u6790\u5de5\u5177\u83b7\u5f97\u7684\u80fd\u6548\u6307\u6807\u548c\u6d4b\u91cf\u7ed3\u679c\uff0c\u63ed\u793a\u4e86\u5728\u5b9e\u9a8c\u548c\u5206\u6790\u8fc7\u7a0b\u4e2d\u9047\u5230\u7684\u5177\u4f53\u6311\u6218\u548c\u9677\u9631\uff0c\u5305\u62ec\u786c\u4ef6\u914d\u7f6e\u3001\u8f6f\u4ef6\u5de5\u5177\u4f7f\u7528\u3001\u6570\u636e\u6536\u96c6\u7b49\u65b9\u9762\u7684\u5b9e\u9645\u95ee\u9898\u3002", "conclusion": "\u8bba\u6587\u603b\u7ed3\u4e86\u9ad8\u6027\u80fd\u8ba1\u7b97\u80fd\u6548\u5206\u6790\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u8fdb\u884c\u80fd\u6548\u5206\u6790\u7814\u7a76\u7684\u6700\u4f73\u5b9e\u8df5\u5efa\u8bae\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u7684\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u548c\u6307\u5bfc\u3002"}}
{"id": "2512.03781", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.03781", "abs": "https://arxiv.org/abs/2512.03781", "authors": ["Joscha Ilmberger", "Johannes Schemmel"], "title": "The BrainScaleS-2 multi-chip system: Interconnecting continuous-time neuromorphic compute substrates", "comment": null, "summary": "The BrainScaleS-2 SoC integrates analog neuron and synapse circuits with digital periphery, including two CPUs with SIMD extensions. Each ASIC is connected to a Node-FPGA, providing experiment control and Ethernet connectivity. This work details the scaling of the compute substrate through FPGA-based interconnection via an additional Aggregator unit. The Aggregator provides up to 12 transceiver links to a backplane of Node-FPGAs, as well as 4 transceiver lanes for further extension. Two such interconnected backplanes are integrated into a standard 19in rack case with 4U height together with an Ethernet switch, system controller and power supplies. For all spike rates, chip-to-chip latencies -- consisting of four hops across three FPGAs -- below 1.3$\u03bc$s are achieved within each backplane.", "AI": {"tldr": "BrainScaleS-2 SoC\u901a\u8fc7FPGA\u4e92\u8fde\u6269\u5c55\u8ba1\u7b97\u57fa\u677f\uff0c\u91c7\u7528Aggregator\u5355\u5143\u8fde\u63a5\u591a\u4e2aNode-FPGA\uff0c\u6784\u5efa\u4e8619\u82f1\u5bf8\u673a\u67b6\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u82af\u7247\u95f4\u5ef6\u8fdf\u4f4e\u4e8e1.3\u5fae\u79d2", "motivation": "\u6269\u5c55BrainScaleS-2\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u7cfb\u7edf\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u901a\u8fc7FPGA\u4e92\u8fde\u6280\u672f\u6784\u5efa\u53ef\u6269\u5c55\u7684\u786c\u4ef6\u5e73\u53f0\uff0c\u4ee5\u652f\u6301\u66f4\u5927\u89c4\u6a21\u7684\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u5b9e\u9a8c", "method": "\u4f7f\u7528\u57fa\u4e8eFPGA\u7684Aggregator\u5355\u5143\u4e92\u8fde\u6280\u672f\uff0c\u6bcf\u4e2aAggregator\u63d0\u4f9b12\u4e2a\u6536\u53d1\u5668\u94fe\u8def\u8fde\u63a5Node-FPGA\u80cc\u677f\uff0c\u652f\u6301\u8fdb\u4e00\u6b65\u6269\u5c55\uff1b\u5c06\u4e24\u4e2a\u4e92\u8fde\u80cc\u677f\u96c6\u6210\u5230\u6807\u51c619\u82f1\u5bf84U\u673a\u67b6\u4e2d\uff0c\u5305\u542b\u4ee5\u592a\u7f51\u4ea4\u6362\u673a\u3001\u7cfb\u7edf\u63a7\u5236\u5668\u548c\u7535\u6e90", "result": "\u5728\u6240\u6709\u8109\u51b2\u901f\u7387\u4e0b\uff0c\u6bcf\u4e2a\u80cc\u677f\u5185\u7ecf\u8fc7\u4e09\u4e2aFPGA\u56db\u4e2a\u8df3\u8f6c\u7684\u82af\u7247\u95f4\u5ef6\u8fdf\u5747\u4f4e\u4e8e1.3\u5fae\u79d2\uff0c\u6210\u529f\u6784\u5efa\u4e86\u53ef\u6269\u5c55\u7684\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u786c\u4ef6\u5e73\u53f0", "conclusion": "\u901a\u8fc7FPGA\u4e92\u8fde\u6280\u672f\u6210\u529f\u6269\u5c55\u4e86BrainScaleS-2\u7cfb\u7edf\u7684\u8ba1\u7b97\u57fa\u677f\uff0c\u5b9e\u73b0\u4e86\u4f4e\u5ef6\u8fdf\u7684\u82af\u7247\u95f4\u901a\u4fe1\uff0c\u4e3a\u5927\u89c4\u6a21\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u786c\u4ef6\u57fa\u7840"}}
{"id": "2512.03825", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.03825", "abs": "https://arxiv.org/abs/2512.03825", "authors": ["Aingeru Ramos", "Jose A Pascual", "Javier Navaridas", "Ivan Coluzza"], "title": "Acceleration of Parallel Tempering for Markov Chain Monte Carlo methods", "comment": "14 pages, 7 figures (5 of them composed by 2 subfigures)", "summary": "Markov Chain Monte Carlo methods are algorithms used to sample probability distributions, commonly used to sample the Boltzmann distribution of physical/chemical models (e.g., protein folding, Ising model, etc.). This allows us to study their properties by sampling the most probable states of those systems. However, the sampling capabilities of these methods are not sufficiently accurate when handling complex configuration spaces. This has resulted in the development of new techniques that improve sampling accuracy, usually at the expense of increasing the computational cost. One of such techniques is Parallel Tempering which improves accuracy by running several replicas which periodically exchange their states. Computationally, this imposes a significant slow-down, which can be counteracted by means of parallelization. These schemes enable MCMC/PT techniques to be run more effectively and allow larger models to be studied. In this work, we present a parallel implementation of Metropolis-Hastings with Parallel Tempering, using OpenMP and CUDA for the parallelization in modern CPUs and GPUs, respectively. The results show a maximum speed-up of 52x using OpenMP with 48 cores, and of 986x speed-up with the CUDA version. Furthermore, the results serve as a basic benchmark to compare a future quantum implementation of the same algorithm.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Metropolis-Hastings\u4e0eParallel Tempering\u7684\u5e76\u884c\u5b9e\u73b0\uff0c\u4f7f\u7528OpenMP\u548cCUDA\u5206\u522b\u5728CPU\u548cGPU\u4e0a\u8fdb\u884c\u5e76\u884c\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u91c7\u6837\u6548\u7387\u3002", "motivation": "\u4f20\u7edfMCMC\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u6784\u578b\u7a7a\u95f4\u65f6\u91c7\u6837\u7cbe\u5ea6\u4e0d\u8db3\uff0cParallel Tempering\u867d\u7136\u63d0\u9ad8\u4e86\u7cbe\u5ea6\u4f46\u8ba1\u7b97\u6210\u672c\u663e\u8457\u589e\u52a0\u3002\u9700\u8981\u901a\u8fc7\u5e76\u884c\u5316\u6765\u62b5\u6d88\u8fd9\u79cd\u8ba1\u7b97\u5f00\u9500\uff0c\u4f7fMCMC/PT\u6280\u672f\u80fd\u66f4\u6709\u6548\u5730\u8fd0\u884c\u5e76\u7814\u7a76\u66f4\u5927\u89c4\u6a21\u7684\u6a21\u578b\u3002", "method": "\u5f00\u53d1\u4e86Metropolis-Hastings\u4e0eParallel Tempering\u7684\u5e76\u884c\u5b9e\u73b0\uff0c\u4f7f\u7528OpenMP\u8fdb\u884c\u591a\u6838CPU\u5e76\u884c\u5316\uff0c\u4f7f\u7528CUDA\u8fdb\u884cGPU\u5e76\u884c\u5316\u3002\u8fd9\u4e24\u79cd\u65b9\u6cd5\u5206\u522b\u9488\u5bf9\u73b0\u4ee3CPU\u548cGPU\u67b6\u6784\u8fdb\u884c\u4f18\u5316\u3002", "result": "OpenMP\u7248\u672c\u572848\u6838\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad852\u500d\u7684\u52a0\u901f\uff0cCUDA\u7248\u672c\u5b9e\u73b0\u4e86986\u500d\u7684\u52a0\u901f\u3002\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u672a\u6765\u91cf\u5b50\u5b9e\u73b0\u76f8\u540c\u7b97\u6cd5\u63d0\u4f9b\u4e86\u57fa\u7840\u57fa\u51c6\u3002", "conclusion": "\u63d0\u51fa\u7684\u5e76\u884c\u5b9e\u73b0\u663e\u8457\u63d0\u5347\u4e86MCMC/PT\u7b97\u6cd5\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u4f7f\u5f97\u80fd\u591f\u66f4\u6709\u6548\u5730\u7814\u7a76\u590d\u6742\u7cfb\u7edf\u3002\u540c\u65f6\u4e3a\u672a\u6765\u91cf\u5b50\u5b9e\u73b0\u63d0\u4f9b\u4e86\u6027\u80fd\u57fa\u51c6\u3002"}}
{"id": "2512.03571", "categories": ["cs.AI", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2512.03571", "abs": "https://arxiv.org/abs/2512.03571", "authors": ["Zhening Li", "Armando Solar-Lezama", "Yisong Yue", "Stephan Zheng"], "title": "EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths", "comment": "65 pages, 2 figures, published in NeurIPS 2025", "summary": "We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce \"probabilistic angelic nondeterminism\" (\"PAN\"), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.", "AI": {"tldr": "\u63d0\u51faPAN\u7f16\u7a0b\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u79bb\u6838\u5fc3\u5de5\u4f5c\u6d41\u903b\u8f91\u548c\u63a8\u7406\u65f6\u7b56\u7565\uff0c\u7b80\u5316LLM\u667a\u80fd\u4f53\u5f00\u53d1\uff0c\u5e76\u63d0\u4f9bEnCompass\u6846\u67b6\u5b9e\u73b0", "motivation": "\u5f53\u524d\u667a\u80fd\u4f53\u7f16\u7a0b\u65b9\u6cd5\u901a\u5e38\u5c06\u6838\u5fc3\u5de5\u4f5c\u6d41\u903b\u8f91\u548c\u63a8\u7406\u65f6\u7b56\u7565\uff08\u5982\u6811\u641c\u7d22\uff09\u8026\u5408\u5728\u4e00\u8d77\uff0c\u8fd9\u9650\u5236\u4e86\u5f00\u53d1\u6548\u7387\u548c\u7075\u6d3b\u6027", "method": "\u5f15\u5165\"\u6982\u7387\u5929\u4f7f\u975e\u786e\u5b9a\u6027\"\uff08PAN\uff09\u7f16\u7a0b\u6a21\u578b\uff0c\u4f7f\u7528Python\u88c5\u9970\u5668\u5c06\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\u5e8f\u7f16\u8bd1\u4e3a\u641c\u7d22\u7a7a\u95f4\uff0c\u5b9e\u73b0\u5de5\u4f5c\u6d41\u4e0e\u63a8\u7406\u7b56\u7565\u7684\u89e3\u8026", "result": "\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u8ba9\u7a0b\u5e8f\u5458\u5feb\u901f\u63d0\u5347\u667a\u80fd\u4f53\u53ef\u9760\u6027\uff0c\u8f7b\u677e\u5207\u6362\u4e0d\u540c\u63a8\u7406\u7b56\u7565\uff0c\u4e14\u53ea\u9700\u5c11\u91cf\u989d\u5916\u7f16\u7801", "conclusion": "PAN\u7f16\u7a0b\u6a21\u578b\u548cEnCompass\u6846\u67b6\u4e3aLLM\u667a\u80fd\u4f53\u5f00\u53d1\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u3001\u9ad8\u6548\u7684\u7f16\u7a0b\u8303\u5f0f\uff0c\u89e3\u8026\u4e86\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u548c\u63a8\u7406\u7b56\u7565\u9009\u62e9"}}
{"id": "2512.03927", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.03927", "abs": "https://arxiv.org/abs/2512.03927", "authors": ["Liujianfu Wang", "Yuyang Du", "Yuchen Pan", "Soung Chang Liew", "Jiacheng Liu", "Kexin Chen"], "title": "OD-MoE: On-Demand Expert Loading for Cacheless Edge-Distributed MoE Inference", "comment": null, "summary": "Mixture-of-Experts (MoE), while offering significant advantages as a Large Language Model (LLM) architecture, faces substantial challenges when deployed on low-cost edge devices with tight memory constraints. Expert offloading mitigates this issue by storing expert parameters in CPU memory and caching a subset of popular experts in GPU memory. Although this approach improves GPU memory utilization by caching only the likely-used experts, the GPU memory reserved for expert caching is underutilized compared with dense LLMs. This paper presents OD-MoE, a distributed MoE inference framework that obviates the need for expert caches via fully on-demand expert loading. OD-MoE is built upon two key mechanisms: 1) parallelizing expert loading and expert computation across distributed edge nodes, and 2) an ultra-accurate emulative predictor that forecasts expert activations multiple layers ahead while expert computation is ongoing. With these innovations, OD-MoE dynamically loads each target expert to one of the distributed nodes just-in-time before its activation and promptly evicts it afterward, freeing GPU memory for subsequent experts. We comprehensively benchmark OD-MoE against state-of-the-art MoE offloading systems on a ten-node testbed. Experimental results show that: 1) OD-MoE achieves 99.94% expert activation prediction accuracy, substantially surpassing all existing methods; and 2) OD-MoE delivers approximately 75% of the decoding speed of a fully GPU-cached MoE deployment while using only 1/3 of the GPU memory. More importantly, by eliminating the need for expert caches, OD-MoE enables MoE inference on edge nodes with less-than-1GB GPU memory, paving the way for practical MoE deployment of low-cost IoT devices at the edge in the LLM era.", "AI": {"tldr": "OD-MoE\u662f\u4e00\u4e2a\u5206\u5e03\u5f0fMoE\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6309\u9700\u52a0\u8f7d\u4e13\u5bb6\u53c2\u6570\uff0c\u6d88\u9664\u4e86\u4e13\u5bb6\u7f13\u5b58\u9700\u6c42\uff0c\u4f7fMoE\u6a21\u578b\u80fd\u5728GPU\u5185\u5b58\u5c0f\u4e8e1GB\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8fd0\u884c\u3002", "motivation": "MoE\u6a21\u578b\u5728\u5185\u5b58\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u9762\u4e34\u6311\u6218\u3002\u73b0\u6709\u7684\u4e13\u5bb6\u5378\u8f7d\u65b9\u6cd5\u867d\u7136\u5c06\u4e13\u5bb6\u53c2\u6570\u5b58\u50a8\u5728CPU\u5185\u5b58\u4e2d\uff0c\u4f46GPU\u5185\u5b58\u4e2d\u4e3a\u4e13\u5bb6\u7f13\u5b58\u4fdd\u7559\u7684\u7a7a\u95f4\u5229\u7528\u7387\u4ecd\u7136\u8f83\u4f4e\uff0c\u4e14\u9700\u8981\u5927\u91cfGPU\u5185\u5b58\u3002", "method": "OD-MoE\u91c7\u7528\u4e24\u79cd\u5173\u952e\u673a\u5236\uff1a1) \u5728\u5206\u5e03\u5f0f\u8fb9\u7f18\u8282\u70b9\u95f4\u5e76\u884c\u5316\u4e13\u5bb6\u52a0\u8f7d\u548c\u4e13\u5bb6\u8ba1\u7b97\uff1b2) \u4f7f\u7528\u8d85\u51c6\u786e\u7684\u6a21\u62df\u9884\u6d4b\u5668\uff0c\u5728\u4e13\u5bb6\u8ba1\u7b97\u8fdb\u884c\u65f6\u63d0\u524d\u591a\u5c42\u9884\u6d4b\u4e13\u5bb6\u6fc0\u6d3b\u3002\u901a\u8fc7\u8fd9\u4e9b\u521b\u65b0\uff0cOD-MoE\u80fd\u591f\u5728\u4e13\u5bb6\u6fc0\u6d3b\u524d\u5373\u65f6\u52a0\u8f7d\u76ee\u6807\u4e13\u5bb6\u5230\u5206\u5e03\u5f0f\u8282\u70b9\uff0c\u5e76\u5728\u4f7f\u7528\u540e\u7acb\u5373\u9a71\u9010\uff0c\u91ca\u653eGPU\u5185\u5b58\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a1) OD-MoE\u5b9e\u73b0\u4e8699.94%\u7684\u4e13\u5bb6\u6fc0\u6d3b\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff1b2) \u5728\u4ec5\u4f7f\u75281/3 GPU\u5185\u5b58\u7684\u60c5\u51b5\u4e0b\uff0cOD-MoE\u8fbe\u5230\u4e86\u5b8c\u5168GPU\u7f13\u5b58MoE\u90e8\u7f72\u7ea675%\u7684\u89e3\u7801\u901f\u5ea6\uff1b3) \u6700\u91cd\u8981\u7684\u662f\uff0cOD-MoE\u4f7fMoE\u63a8\u7406\u80fd\u591f\u5728GPU\u5185\u5b58\u5c0f\u4e8e1GB\u7684\u8fb9\u7f18\u8282\u70b9\u4e0a\u8fd0\u884c\u3002", "conclusion": "OD-MoE\u901a\u8fc7\u6d88\u9664\u4e13\u5bb6\u7f13\u5b58\u9700\u6c42\uff0c\u4e3a\u4f4e\u6210\u672c\u7684\u8fb9\u7f18\u7269\u8054\u7f51\u8bbe\u5907\u5728LLM\u65f6\u4ee3\u5b9e\u73b0\u5b9e\u7528\u7684MoE\u90e8\u7f72\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u89e3\u51b3\u4e86MoE\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u90e8\u7f72\u96be\u9898\u3002"}}
{"id": "2512.03607", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03607", "abs": "https://arxiv.org/abs/2512.03607", "authors": ["Yusen Wu", "Xiaotie Deng"], "title": "DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization", "comment": null, "summary": "This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints.\n  Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.", "AI": {"tldr": "DeepRule\u662f\u4e00\u4e2a\u7528\u4e8e\u96f6\u552e\u5546\u54c1\u7ec4\u5408\u548c\u5b9a\u4ef7\u4f18\u5316\u7684\u81ea\u52a8\u5316\u4e1a\u52a1\u89c4\u5219\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7LLM\u89e3\u6790\u975e\u7ed3\u6784\u5316\u6587\u672c\u3001\u535a\u5f08\u8bba\u7ea6\u675f\u4f18\u5316\u548c\u53ef\u89e3\u91ca\u51b3\u7b56\u84b8\u998f\uff0c\u89e3\u51b3\u7406\u8bba\u6a21\u578b\u4e0e\u73b0\u5b9e\u7ecf\u6d4e\u590d\u6742\u6027\u4e4b\u95f4\u7684\u7cfb\u7edf\u9519\u4f4d\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7406\u8bba\u6a21\u578b\u4e0e\u73b0\u5b9e\u7ecf\u6d4e\u590d\u6742\u6027\u5b58\u5728\u7cfb\u7edf\u9519\u4f4d\uff0c\u5177\u4f53\u8868\u73b0\u4e3a\u4e09\u4e2a\u5173\u952e\u5dee\u8ddd\uff1a\u975e\u7ed3\u6784\u5316\u6587\u672c\u6570\u636e\u6a21\u6001\u4e0d\u5339\u914d\u3001\u52a8\u6001\u7279\u5f81\u7ea0\u7f20\u6311\u6218\uff08\u975e\u7ebf\u6027\u4ef7\u683c\u5f39\u6027\u548c\u65f6\u53d8\u5c5e\u6027\u5efa\u6a21\uff09\u3001\u4ee5\u53ca\u591a\u5c42\u7ea7\u4e1a\u52a1\u7ea6\u675f\u5bfc\u81f4\u7684\u8fd0\u8425\u4e0d\u53ef\u884c\u6027\u3002", "method": "\u91c7\u7528\u4e09\u5c42\u67b6\u6784\uff1a1\uff09\u6df7\u5408\u77e5\u8bc6\u878d\u5408\u5f15\u64ce\uff0c\u4f7f\u7528LLM\u6df1\u5ea6\u8bed\u4e49\u89e3\u6790\u975e\u7ed3\u6784\u5316\u6587\u672c\uff0c\u5c06\u5206\u9500\u534f\u8bae\u548c\u9500\u552e\u8bc4\u4f30\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u7279\u5f81\uff1b2\uff09\u535a\u5f08\u8bba\u7ea6\u675f\u4f18\u5316\u673a\u5236\uff0c\u901a\u8fc7\u53cc\u8fb9\u6548\u7528\u51fd\u6570\u52a8\u6001\u534f\u8c03\u4f9b\u5e94\u94fe\u5229\u76ca\uff1b3\uff09\u53ef\u89e3\u91ca\u51b3\u7b56\u84b8\u998f\u63a5\u53e3\uff0c\u5229\u7528LLM\u5f15\u5bfc\u7684\u7b26\u53f7\u56de\u5f52\u4f18\u5316\u5b9a\u4ef7\u7b56\u7565\u548c\u53ef\u5ba1\u8ba1\u4e1a\u52a1\u89c4\u5219\u3002", "result": "\u5728\u771f\u5b9e\u96f6\u552e\u73af\u5883\u4e2d\u9a8c\u8bc1\u6846\u67b6\uff0c\u76f8\u6bd4\u7cfb\u7edf\u6027B2C\u57fa\u7ebf\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5229\u6da6\uff0c\u540c\u65f6\u786e\u4fdd\u8fd0\u8425\u53ef\u884c\u6027\u3002", "conclusion": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u95ed\u73af\u7ba1\u9053\uff0c\u7edf\u4e00\u4e86\u975e\u7ed3\u6784\u5316\u77e5\u8bc6\u6ce8\u5165\u3001\u591a\u667a\u80fd\u4f53\u4f18\u5316\u548c\u53ef\u89e3\u91ca\u7b56\u7565\u5408\u6210\uff0c\u4e3a\u771f\u5b9e\u7ecf\u6d4e\u667a\u80fd\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.03356", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.03356", "abs": "https://arxiv.org/abs/2512.03356", "authors": ["Jun Leng", "Litian Zhang", "Xi Zhang"], "title": "Immunity memory-based jailbreak detection: multi-agent adaptive guard for large language models", "comment": null, "summary": "Large language models (LLMs) have become foundational in AI systems, yet they remain vulnerable to adversarial jailbreak attacks. These attacks involve carefully crafted prompts that bypass safety guardrails and induce models to produce harmful content. Detecting such malicious input queries is therefore critical for maintaining LLM safety. Existing methods for jailbreak detection typically involve fine-tuning LLMs as static safety LLMs using fixed training datasets. However, these methods incur substantial computational costs when updating model parameters to improve robustness, especially in the face of novel jailbreak attacks. Inspired by immunological memory mechanisms, we propose the Multi-Agent Adaptive Guard (MAAG) framework for jailbreak detection. The core idea is to equip guard with memory capabilities: upon encountering novel jailbreak attacks, the system memorizes attack patterns, enabling it to rapidly and accurately identify similar threats in future encounters. Specifically, MAAG first extracts activation values from input prompts and compares them to historical activations stored in a memory bank for quick preliminary detection. A defense agent then simulates responses based on these detection results, and an auxiliary agent supervises the simulation process to provide secondary filtering of the detection outcomes. Extensive experiments across five open-source models demonstrate that MAAG significantly outperforms state-of-the-art (SOTA) methods, achieving 98% detection accuracy and a 96% F1-score across a diverse range of attack scenarios.", "AI": {"tldr": "MAAG\u6846\u67b6\u901a\u8fc7\u6a21\u62df\u514d\u75ab\u8bb0\u5fc6\u673a\u5236\uff0c\u4e3aLLM\u5b89\u5168\u9632\u62a4\u63d0\u4f9b\u52a8\u6001\u81ea\u9002\u5e94\u68c0\u6d4b\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u8d8a\u72f1\u653b\u51fb\u7684\u8bc6\u522b\u6548\u679c", "motivation": "\u73b0\u6709LLM\u8d8a\u72f1\u653b\u51fb\u68c0\u6d4b\u65b9\u6cd5\u901a\u5e38\u57fa\u4e8e\u56fa\u5b9a\u8bad\u7ec3\u6570\u636e\u96c6\u5fae\u8c03\u6a21\u578b\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u5e94\u5bf9\u65b0\u578b\u653b\u51fb\u3002\u53d7\u514d\u75ab\u8bb0\u5fc6\u673a\u5236\u542f\u53d1\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u52a8\u6001\u9002\u5e94\u65b0\u5a01\u80c1\u7684\u68c0\u6d4b\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u81ea\u9002\u5e94\u9632\u62a4\uff08MAAG\uff09\u6846\u67b6\uff1a1\uff09\u4ece\u8f93\u5165\u63d0\u793a\u4e2d\u63d0\u53d6\u6fc0\u6d3b\u503c\u5e76\u4e0e\u8bb0\u5fc6\u5e93\u4e2d\u7684\u5386\u53f2\u6fc0\u6d3b\u503c\u6bd4\u8f83\u8fdb\u884c\u521d\u6b65\u68c0\u6d4b\uff1b2\uff09\u9632\u5fa1\u667a\u80fd\u4f53\u57fa\u4e8e\u68c0\u6d4b\u7ed3\u679c\u6a21\u62df\u54cd\u5e94\uff1b3\uff09\u8f85\u52a9\u667a\u80fd\u4f53\u76d1\u7763\u6a21\u62df\u8fc7\u7a0b\uff0c\u5bf9\u68c0\u6d4b\u7ed3\u679c\u8fdb\u884c\u4e8c\u6b21\u8fc7\u6ee4\u3002", "result": "\u5728\u4e94\u4e2a\u5f00\u6e90\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMAAG\u663e\u8457\u4f18\u4e8e\u73b0\u6709SOTA\u65b9\u6cd5\uff0c\u5728\u591a\u6837\u5316\u653b\u51fb\u573a\u666f\u4e0b\u8fbe\u523098%\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u548c96%\u7684F1\u5206\u6570\u3002", "conclusion": "MAAG\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u8bb0\u5fc6\u80fd\u529b\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u673a\u5236\uff0c\u4e3aLLM\u5b89\u5168\u9632\u62a4\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u7684\u8d8a\u72f1\u653b\u51fb\u68c0\u6d4b\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u65b0\u578b\u5a01\u80c1\u3002"}}
{"id": "2512.03762", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03762", "abs": "https://arxiv.org/abs/2512.03762", "authors": ["Jiawei Xu", "Fengfeng Wei", "Weineng Chen"], "title": "RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design", "comment": null, "summary": "Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.", "AI": {"tldr": "RoCo\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u89d2\u8272\u534f\u4f5c\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u56db\u4e2a\u4e13\u95e8\u5316\u7684LLM\u667a\u80fd\u4f53\uff08\u63a2\u7d22\u8005\u3001\u5229\u7528\u8005\u3001\u6279\u8bc4\u8005\u3001\u6574\u5408\u8005\uff09\u534f\u540c\u8bbe\u8ba1\u9ad8\u8d28\u91cf\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u4e2d\u53d6\u5f97\u4e86\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u7814\u7a76\u901a\u5e38\u53ea\u8003\u8651\u5355\u4e00\u89d2\u8272\uff0c\u9650\u5236\u4e86\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u591a\u6837\u6027\u548c\u8d28\u91cf\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u591a\u89d2\u8272\u534f\u4f5c\u6765\u589e\u5f3a\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u7684\u591a\u6837\u6027\u548c\u8d28\u91cf\u3002", "method": "\u63d0\u51faRoCo\u591a\u667a\u80fd\u4f53\u89d2\u8272\u534f\u4f5c\u7cfb\u7edf\uff0c\u5305\u542b\u56db\u4e2a\u4e13\u95e8\u5316\u7684LLM\u667a\u80fd\u4f53\uff1a\u63a2\u7d22\u8005\uff08\u4fc3\u8fdb\u957f\u671f\u6f5c\u529b\uff0c\u521b\u9020\u6027\u601d\u7ef4\uff09\u3001\u5229\u7528\u8005\uff08\u5173\u6ce8\u77ed\u671f\u6539\u8fdb\uff0c\u6548\u7387\u5bfc\u5411\u4f18\u5316\uff09\u3001\u6279\u8bc4\u8005\uff08\u8bc4\u4f30\u8fdb\u5316\u6b65\u9aa4\u6709\u6548\u6027\u5e76\u63d0\u4f9b\u53cd\u9988\uff09\u3001\u6574\u5408\u8005\uff08\u7efc\u5408\u63a2\u7d22\u8005\u548c\u5229\u7528\u8005\u7684\u5efa\u8bae\uff0c\u5e73\u8861\u521b\u65b0\u4e0e\u5229\u7528\uff09\u3002\u8fd9\u4e9b\u667a\u80fd\u4f53\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u591a\u8f6e\u8fc7\u7a0b\u8fdb\u884c\u4ea4\u4e92\uff0c\u5305\u62ec\u53cd\u9988\u3001\u7cbe\u70bc\u548c\u7cbe\u82f1\u7a81\u53d8\uff0c\u540c\u65f6\u8003\u8651\u77ed\u671f\u548c\u957f\u671f\u53cd\u601d\u3002", "result": "\u5728\u4e94\u4e2a\u4e0d\u540c\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e0a\uff0c\u5728\u81ea\u76d2\u548c\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u8bc4\u4f30\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRoCo\u5b9e\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd\uff0c\u751f\u6210\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u5728\u81ea\u76d2\u548c\u9ed1\u76d2\u573a\u666f\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff08\u5305\u62ecReEvo\u548cHSEvo\uff09\u3002", "conclusion": "\u57fa\u4e8e\u89d2\u8272\u7684\u534f\u4f5c\u8303\u5f0f\u4e3a\u7a33\u5065\u4e14\u9ad8\u6027\u80fd\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u5efa\u7acb\u4e86\u65b0\u6807\u51c6\uff0c\u8bc1\u660e\u4e86\u591a\u89d2\u8272\u534f\u4f5c\u5728\u589e\u5f3a\u542f\u53d1\u5f0f\u7b97\u6cd5\u591a\u6837\u6027\u548c\u8d28\u91cf\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.03358", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.03358", "abs": "https://arxiv.org/abs/2512.03358", "authors": ["Dev Gurung", "Shiva Raj Pokhrel"], "title": "Scaling Trust in Quantum Federated Learning: A Multi-Protocol Privacy Design", "comment": "Under Review", "summary": "Quantum Federated Learning (QFL) promises to revolutionize distributed machine learning by combining the computational power of quantum devices with collaborative model training. Yet, privacy of both data and models remains a critical challenge. In this work, we propose a privacy-preserving QFL framework where a network of $n$ quantum devices trains local models and transmits them to a central server under a multi-layered privacy protocol. Our design leverages Singular Value Decomposition (SVD), Quantum Key Distribution (QKD), and Analytic Quantum Gradient Descent (AQGD) to secure data preparation, model sharing, and training stages. Through theoretical analysis and experiments on contemporary quantum platforms and datasets, we demonstrate that the framework robustly safeguards data and model confidentiality while maintaining training efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u5947\u5f02\u503c\u5206\u89e3\u3001\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u548c\u89e3\u6790\u91cf\u5b50\u68af\u5ea6\u4e0b\u964d\u7684\u591a\u5c42\u9690\u79c1\u4fdd\u62a4\u91cf\u5b50\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u4fdd\u62a4\u6570\u636e\u548c\u6a21\u578b\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u91cf\u5b50\u8054\u90a6\u5b66\u4e60\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u548c\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u6570\u636e\u548c\u6a21\u578b\u7684\u9690\u79c1\u4fdd\u62a4\u4ecd\u7136\u662f\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u8bbe\u8ba1\u80fd\u591f\u540c\u65f6\u4fdd\u62a4\u6570\u636e\u548c\u6a21\u578b\u9690\u79c1\u7684\u91cf\u5b50\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u591a\u5c42\u9690\u79c1\u4fdd\u62a4QFL\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u5947\u5f02\u503c\u5206\u89e3\uff08SVD\uff09\u4fdd\u62a4\u6570\u636e\u51c6\u5907\u9636\u6bb5\uff1b2\uff09\u91c7\u7528\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u4fdd\u62a4\u6a21\u578b\u5171\u4eab\u9636\u6bb5\uff1b3\uff09\u5e94\u7528\u89e3\u6790\u91cf\u5b50\u68af\u5ea6\u4e0b\u964d\uff08AQGD\uff09\u4fdd\u62a4\u8bad\u7ec3\u9636\u6bb5\u3002\u6846\u67b6\u5305\u542bn\u4e2a\u91cf\u5b50\u8bbe\u5907\u8bad\u7ec3\u672c\u5730\u6a21\u578b\u5e76\u4f20\u8f93\u5230\u4e2d\u592e\u670d\u52a1\u5668\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5728\u5f53\u4ee3\u91cf\u5b50\u5e73\u53f0\u53ca\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u9c81\u68d2\u5730\u4fdd\u62a4\u6570\u636e\u548c\u6a21\u578b\u7684\u673a\u5bc6\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u8bad\u7ec3\u6548\u7387\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u7684\u9690\u79c1\u4fdd\u62a4\u91cf\u5b50\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u91cf\u5b50\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u9690\u79c1\u6311\u6218\uff0c\u4e3a\u5b89\u5168\u9ad8\u6548\u7684\u5206\u5e03\u5f0f\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2512.03783", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2512.03783", "abs": "https://arxiv.org/abs/2512.03783", "authors": ["Dongchao Yang", "Songxiang Liu", "Disong Wang", "Yuanyuan Wang", "Guanglu Wan", "Helen Meng"], "title": "Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning", "comment": null, "summary": "Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existing systems still exhibit rigid reasoning behaviors, either overthinking simple problems or failing to reason when necessary. To address this limitation, we propose Omni-AutoThink, a novel adaptive reasoning framework that dynamically adjusts the model's reasoning depth according to task difficulty. Our framework comprises two stages: (1) an Adaptive Supervised Fine-Tuning (Adaptive SFT) stage, which endows the Omni model with fundamental reasoning capability using large-scale reasoning-augmented data, and (2) an Adaptive Reinforcement Learning (Adaptive GRPO) stage, which optimizes reasoning behaviors based on task complexity and reward feedback. We further construct a comprehensive adaptive reasoning benchmark that spans text-only, text-audio, text-visual, and text-audio-visual modalities, providing both training and evaluation splits for multimodal reasoning assessment. Experimental results demonstrate that our proposed framework significantly improves adaptive reasoning performance compared to previous baselines. All benchmark data and code will be publicly released.", "AI": {"tldr": "Omni-AutoThink\u662f\u4e00\u4e2a\u81ea\u9002\u5e94\u63a8\u7406\u6846\u67b6\uff0c\u80fd\u6839\u636e\u4efb\u52a1\u96be\u5ea6\u52a8\u6001\u8c03\u6574\u6a21\u578b\u63a8\u7406\u6df1\u5ea6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u63d0\u5347\u591a\u6a21\u6001\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709Omni\u6a21\u578b\u5728\u63a8\u7406\u884c\u4e3a\u4e0a\u5b58\u5728\u50f5\u5316\u95ee\u9898\uff0c\u8981\u4e48\u5bf9\u7b80\u5355\u95ee\u9898\u8fc7\u5ea6\u601d\u8003\uff0c\u8981\u4e48\u5728\u9700\u8981\u63a8\u7406\u65f6\u65e0\u6cd5\u6709\u6548\u63a8\u7406\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u6839\u636e\u4efb\u52a1\u96be\u5ea6\u81ea\u9002\u5e94\u8c03\u6574\u63a8\u7406\u6df1\u5ea6\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u81ea\u9002\u5e94\u76d1\u7763\u5fae\u8c03\u9636\u6bb5\uff0c\u4f7f\u7528\u5927\u89c4\u6a21\u63a8\u7406\u589e\u5f3a\u6570\u636e\u8d4b\u4e88\u6a21\u578b\u57fa\u7840\u63a8\u7406\u80fd\u529b\uff1b2) \u81ea\u9002\u5e94\u5f3a\u5316\u5b66\u4e60\u9636\u6bb5\uff0c\u57fa\u4e8e\u4efb\u52a1\u590d\u6742\u5ea6\u548c\u5956\u52b1\u53cd\u9988\u4f18\u5316\u63a8\u7406\u884c\u4e3a\u3002\u540c\u65f6\u6784\u5efa\u4e86\u6db5\u76d6\u6587\u672c\u3001\u6587\u672c-\u97f3\u9891\u3001\u6587\u672c-\u89c6\u89c9\u3001\u6587\u672c-\u97f3\u9891-\u89c6\u89c9\u591a\u6a21\u6001\u7684\u81ea\u9002\u5e94\u63a8\u7406\u57fa\u51c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u76f8\u6bd4\u5148\u524d\u57fa\u7ebf\u663e\u8457\u63d0\u5347\u4e86\u81ea\u9002\u5e94\u63a8\u7406\u6027\u80fd\uff0c\u6240\u6709\u57fa\u51c6\u6570\u636e\u548c\u4ee3\u7801\u5c06\u516c\u5f00\u3002", "conclusion": "Omni-AutoThink\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u63a8\u7406\u6df1\u5ea6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709Omni\u6a21\u578b\u63a8\u7406\u884c\u4e3a\u50f5\u5316\u7684\u95ee\u9898\uff0c\u5728\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2512.03955", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.03955", "abs": "https://arxiv.org/abs/2512.03955", "authors": ["Niklas Jobs", "Luis Miguel Vieira da Silva", "Jayanth Somashekaraiah", "Maximilian Weigand", "David Kube", "Felix Gehlhoff"], "title": "Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol", "comment": "This work has been submitted to IFAC for possible publication", "summary": "Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u5728\u5de5\u4e1a\u81ea\u52a8\u5316\u89c4\u5212\u4e0e\u6267\u884c\u80fd\u529b\u7684\u6807\u51c6\u5316\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5305\u542b\u53ef\u6267\u884c\u4eff\u771f\u73af\u5883\u548c\u4e94\u4e2a\u590d\u6742\u5ea6\u7c7b\u522b\u7684Blocksworld\u95ee\u9898\uff0c\u901a\u8fc7MCP\u534f\u8bae\u5b9e\u73b0\u7edf\u4e00\u5de5\u5177\u63a5\u53e3\u3002", "motivation": "\u5de5\u4e1a\u81ea\u52a8\u5316\u9700\u8981\u7075\u6d3b\u7684\u63a7\u5236\u7b56\u7565\u6765\u9002\u5e94\u53d8\u5316\u7684\u4efb\u52a1\u548c\u73af\u5883\uff0c\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u5177\u6709\u81ea\u9002\u5e94\u89c4\u5212\u4e0e\u6267\u884c\u7684\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6bd4\u8f83\u7684\u6807\u51c6\u5316\u57fa\u51c6\u3002", "method": "1) \u5f15\u5165\u5305\u542b\u53ef\u6267\u884c\u4eff\u771f\u73af\u5883\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u57fa\u4e8eBlocksworld\u95ee\u9898\u63d0\u4f9b\u4e94\u4e2a\u590d\u6742\u5ea6\u7c7b\u522b\uff1b2) \u96c6\u6210\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae(MCP)\u4f5c\u4e3a\u6807\u51c6\u5316\u5de5\u5177\u63a5\u53e3\uff0c\u4f7f\u4e0d\u540c\u667a\u80fd\u4f53\u67b6\u6784\u65e0\u9700\u7279\u5b9a\u5b9e\u73b0\u4fee\u6539\u5373\u53ef\u8fde\u63a5\u548c\u8bc4\u4f30\uff1b3) \u901a\u8fc7\u5355\u667a\u80fd\u4f53\u5b9e\u73b0\u5c55\u793a\u57fa\u51c6\u7684\u9002\u7528\u6027\u3002", "result": "\u5efa\u7acb\u4e86\u7528\u4e8e\u6bd4\u8f83\u57fa\u4e8eLLM\u7684\u89c4\u5212\u4e0e\u6267\u884c\u65b9\u6cd5\u7684\u5b9a\u91cf\u6307\u6807\uff0c\u5c55\u793a\u4e86\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u7684\u9002\u7528\u6027\uff0c\u4e3a\u4e0d\u540c\u667a\u80fd\u4f53\u67b6\u6784\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u8bc4\u4f30\u5e73\u53f0\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u586b\u8865\u4e86LLM\u667a\u80fd\u4f53\u5728\u5de5\u4e1a\u81ea\u52a8\u5316\u9886\u57df\u7f3a\u4e4f\u6807\u51c6\u5316\u8bc4\u4f30\u5de5\u5177\u7684\u7a7a\u767d\uff0c\u901a\u8fc7MCP\u534f\u8bae\u5b9e\u73b0\u4e86\u4e0d\u540c\u67b6\u6784\u7684\u516c\u5e73\u6bd4\u8f83\uff0c\u4e3a\u81ea\u9002\u5e94\u89c4\u5212\u4e0e\u6267\u884c\u65b9\u6cd5\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002"}}
{"id": "2512.03465", "categories": ["cs.CR", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.03465", "abs": "https://arxiv.org/abs/2512.03465", "authors": ["Robert Dilworth"], "title": "Tuning for TraceTarnish: Techniques, Trends, and Testing Tangible Traits", "comment": "20 pages, 8 figures, 2 tables", "summary": "In this study, we more rigorously evaluated our attack script $\\textit{TraceTarnish}$, which leverages adversarial stylometry principles to anonymize the authorship of text-based messages. To ensure the efficacy and utility of our attack, we sourced, processed, and analyzed Reddit comments--comments that were later alchemized into $\\textit{TraceTarnish}$ data--to gain valuable insights. The transformed $\\textit{TraceTarnish}$ data was then further augmented by $\\textit{StyloMetrix}$ to manufacture stylometric features--features that were culled using the Information Gain criterion, leaving only the most informative, predictive, and discriminative ones. Our results found that function words and function word types ($L\\_FUNC\\_A$ $\\&$ $L\\_FUNC\\_T$); content words and content word types ($L\\_CONT\\_A$ $\\&$ $L\\_CONT\\_T$); and the Type-Token Ratio ($ST\\_TYPE\\_TOKEN\\_RATIO\\_LEMMAS$) yielded significant Information-Gain readings. The identified stylometric cues--function-word frequencies, content-word distributions, and the Type-Token Ratio--serve as reliable indicators of compromise (IoCs), revealing when a text has been deliberately altered to mask its true author. Similarly, these features could function as forensic beacons, alerting defenders to the presence of an adversarial stylometry attack; granted, in the absence of the original message, this signal may go largely unnoticed, as it appears to depend on a pre- and post-transformation comparison. \"In trying to erase a trace, you often imprint a larger one.\" Armed with this understanding, we framed $\\textit{TraceTarnish}$'s operations and outputs around these five isolated features, using them to conceptualize and implement enhancements that further strengthen the attack.", "AI": {"tldr": "TraceTarnish\u662f\u4e00\u79cd\u5229\u7528\u5bf9\u6297\u6027\u6587\u4f53\u6d4b\u91cf\u5b66\u539f\u7406\u533f\u540d\u5316\u6587\u672c\u6d88\u606f\u4f5c\u8005\u8eab\u4efd\u7684\u653b\u51fb\u811a\u672c\uff0c\u901a\u8fc7\u5206\u6790Reddit\u8bc4\u8bba\u6570\u636e\uff0c\u8bc6\u522b\u51fa\u51fd\u6570\u8bcd\u9891\u7387\u3001\u5185\u5bb9\u8bcd\u5206\u5e03\u548c\u7c7b\u578b-\u6807\u8bb0\u6bd4\u7b49\u4e94\u4e2a\u5173\u952e\u6587\u4f53\u7279\u5f81\u4f5c\u4e3a\u653b\u51fb\u6307\u6807\u548c\u68c0\u6d4b\u4fe1\u53f7\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u66f4\u4e25\u683c\u5730\u8bc4\u4f30TraceTarnish\u653b\u51fb\u811a\u672c\uff0c\u8be5\u811a\u672c\u5229\u7528\u5bf9\u6297\u6027\u6587\u4f53\u6d4b\u91cf\u5b66\u539f\u7406\u6765\u533f\u540d\u5316\u6587\u672c\u6d88\u606f\u7684\u4f5c\u8005\u8eab\u4efd\uff0c\u540c\u65f6\u63a2\u7d22\u5982\u4f55\u68c0\u6d4b\u8fd9\u79cd\u653b\u51fb\u3002", "method": "\u6536\u96c6\u5e76\u5904\u7406Reddit\u8bc4\u8bba\u6570\u636e\uff0c\u4f7f\u7528TraceTarnish\u8fdb\u884c\u533f\u540d\u5316\u5904\u7406\uff0c\u7136\u540e\u901a\u8fc7StyloMetrix\u751f\u6210\u6587\u4f53\u7279\u5f81\uff0c\u4f7f\u7528\u4fe1\u606f\u589e\u76ca\u51c6\u5219\u7b5b\u9009\u51fa\u6700\u5177\u4fe1\u606f\u6027\u3001\u9884\u6d4b\u6027\u548c\u533a\u5206\u6027\u7684\u7279\u5f81\u3002", "result": "\u8bc6\u522b\u51fa\u4e94\u4e2a\u5173\u952e\u6587\u4f53\u7279\u5f81\uff1a\u51fd\u6570\u8bcd\u53ca\u5176\u7c7b\u578b(L_FUNC_A & L_FUNC_T)\u3001\u5185\u5bb9\u8bcd\u53ca\u5176\u7c7b\u578b(L_CONT_A & L_CONT_T)\u3001\u4ee5\u53ca\u7c7b\u578b-\u6807\u8bb0\u6bd4(ST_TYPE_TOKEN_RATIO_LEMMAS)\u3002\u8fd9\u4e9b\u7279\u5f81\u65e2\u53ef\u4f5c\u4e3a\u653b\u51fb\u7684\u53ef\u9760\u6307\u6807\uff0c\u4e5f\u53ef\u4f5c\u4e3a\u68c0\u6d4b\u5bf9\u6297\u6027\u6587\u4f53\u6d4b\u91cf\u653b\u51fb\u7684\u53d6\u8bc1\u4fe1\u6807\u3002", "conclusion": "\u8bd5\u56fe\u62b9\u53bb\u75d5\u8ff9\u7684\u884c\u4e3a\u5f80\u5f80\u4f1a\u7559\u4e0b\u66f4\u5927\u7684\u5370\u8bb0\u3002\u57fa\u4e8e\u8fd9\u4e94\u4e2a\u5173\u952e\u7279\u5f81\uff0c\u7814\u7a76\u4eba\u5458\u6539\u8fdb\u4e86TraceTarnish\u653b\u51fb\uff0c\u4f7f\u5176\u66f4\u52a0\u5f3a\u5927\uff0c\u540c\u65f6\u4e5f\u4e3a\u68c0\u6d4b\u6b64\u7c7b\u653b\u51fb\u63d0\u4f9b\u4e86\u65b9\u6cd5\uff0c\u5c3d\u7ba1\u5728\u6ca1\u6709\u539f\u59cb\u6d88\u606f\u7684\u60c5\u51b5\u4e0b\u68c0\u6d4b\u53ef\u80fd\u8f83\u4e3a\u56f0\u96be\u3002"}}
{"id": "2512.03551", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.03551", "abs": "https://arxiv.org/abs/2512.03551", "authors": ["Oylum Gerenli", "Gunes Karabulut-Kurt", "Enver Ozdemir"], "title": "A User Centric Group Authentication Scheme for Secure Communication", "comment": null, "summary": "Group Authentication Schemes (GAS) are methodologies developed to verify the membership of multiple users simultaneously. These schemes enable the concurrent authentication of several users while eliminating the need for a certification authority. Numerous GAS methods have been explored in the literature, and they can be classified into three distinct generations based on their foundational mathematical principles. First-generation GASs rely on polynomial interpolation and the multiplicative subgroup of a finite field. Second-generation GASs also employ polynomial interpolation, but they distinguish themselves by incorporating elliptic curves over finite fields. While third-generation GASs present a promising solution for scalable environments, they demonstrate a limitation in certain applications. Such applications typically require the identification of users participating in the authentication process. In the third-generation GAS, users are able to verify their credentials while maintaining anonymity. However, there are various applications where the identification of participating users is necessary. In this study, we propose an improved version of third-generation GAS, utilizing inner product spaces and polynomial interpolation to resolve this limitation. We address the issue of preventing malicious actions by legitimate group members. The current third-generation scheme allows members to share group credentials, which can jeopardize group confidentiality. Our proposed scheme mitigates this risk by eliminating the ability of individual users to distribute credentials. However, a potential limitation of our scheme is its reliance on a central authority for authentication in certain scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u7b2c\u4e09\u4ee3\u7fa4\u8ba4\u8bc1\u65b9\u6848\uff0c\u4f7f\u7528\u5185\u79ef\u7a7a\u95f4\u548c\u591a\u9879\u5f0f\u63d2\u503c\u6765\u89e3\u51b3\u7528\u6237\u533f\u540d\u6027\u5e26\u6765\u7684\u8bc6\u522b\u95ee\u9898\uff0c\u540c\u65f6\u9632\u6b62\u5408\u6cd5\u6210\u5458\u6076\u610f\u5171\u4eab\u51ed\u8bc1\u3002", "motivation": "\u7b2c\u4e09\u4ee3\u7fa4\u8ba4\u8bc1\u65b9\u6848\u867d\u7136\u63d0\u4f9b\u4e86\u7528\u6237\u533f\u540d\u6027\uff0c\u4f46\u5728\u9700\u8981\u8bc6\u522b\u53c2\u4e0e\u7528\u6237\u7684\u7279\u5b9a\u5e94\u7528\u4e2d\u5b58\u5728\u5c40\u9650\u6027\u3002\u6b64\u5916\uff0c\u73b0\u6709\u65b9\u6848\u5141\u8bb8\u6210\u5458\u5171\u4eab\u7fa4\u51ed\u8bc1\uff0c\u8fd9\u4f1a\u5371\u53ca\u7fa4\u7ec4\u673a\u5bc6\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e24\u4e2a\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6539\u8fdb\u7684\u7b2c\u4e09\u4ee3\u7fa4\u8ba4\u8bc1\u65b9\u6848\uff0c\u7ed3\u5408\u5185\u79ef\u7a7a\u95f4\u548c\u591a\u9879\u5f0f\u63d2\u503c\u6280\u672f\u3002\u65b0\u65b9\u6848\u6d88\u9664\u4e86\u7528\u6237\u5206\u53d1\u51ed\u8bc1\u7684\u80fd\u529b\uff0c\u4ece\u800c\u9632\u6b62\u5408\u6cd5\u6210\u5458\u7684\u6076\u610f\u884c\u4e3a\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6848\u89e3\u51b3\u4e86\u7b2c\u4e09\u4ee3\u7fa4\u8ba4\u8bc1\u5728\u9700\u8981\u7528\u6237\u8bc6\u522b\u5e94\u7528\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u540c\u65f6\u901a\u8fc7\u6d88\u9664\u7528\u6237\u5206\u53d1\u51ed\u8bc1\u7684\u80fd\u529b\u589e\u5f3a\u4e86\u5b89\u5168\u6027\uff0c\u9632\u6b62\u7fa4\u7ec4\u673a\u5bc6\u6027\u88ab\u7834\u574f\u3002", "conclusion": "\u6539\u8fdb\u7684\u7b2c\u4e09\u4ee3\u7fa4\u8ba4\u8bc1\u65b9\u6848\u6210\u529f\u89e3\u51b3\u4e86\u7528\u6237\u533f\u540d\u6027\u5e26\u6765\u7684\u8bc6\u522b\u95ee\u9898\uff0c\u5e76\u589e\u5f3a\u4e86\u5b89\u5168\u6027\uff0c\u4f46\u5b58\u5728\u4f9d\u8d56\u4e2d\u592e\u6743\u5a01\u8fdb\u884c\u8ba4\u8bc1\u7684\u6f5c\u5728\u5c40\u9650\u6027\u3002"}}
{"id": "2512.03669", "categories": ["cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2512.03669", "abs": "https://arxiv.org/abs/2512.03669", "authors": ["Zuan Wang", "Juntao Lu", "Jiazhuang Wu", "Youliang Tian", "Wei Song", "Qiuxian Li", "Duo Zhang"], "title": "Towards Privacy-Preserving Range Queries with Secure Learned Spatial Index over Encrypted Data", "comment": "IEEE TrustCom-2025", "summary": "With the growing reliance on cloud services for large-scale data management, preserving the security and privacy of outsourced datasets has become increasingly critical. While encrypting data and queries can prevent direct content exposure, recent research reveals that adversaries can still infer sensitive information via access pattern and search path analysis. However, existing solutions that offer strong access pattern privacy often incur substantial performance overhead. In this paper, we propose a novel privacy-preserving range query scheme over encrypted datasets, offering strong security guarantees while maintaining high efficiency. To achieve this, we develop secure learned spatial index (SLS-INDEX), a secure learned index that integrates the Paillier cryptosystem with a hierarchical prediction architecture and noise-injected buckets, enabling data-aware query acceleration in the encrypted domain. To further obfuscate query execution paths, SLS-INDEXbased Range Queries (SLRQ) employs a permutation-based secure bucket prediction protocol. Additionally, we introduce a secure point extraction protocol that generates candidate results to reduce the overhead of secure computation. We provide formal security analysis under realistic leakage functions and implement a prototype to evaluate its practical performance. Extensive experiments on both real-world and synthetic datasets demonstrate that SLRQ significantly outperforms existing solutions in query efficiency while ensuring dataset, query, result, and access pattern privacy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u9690\u79c1\u4fdd\u62a4\u8303\u56f4\u67e5\u8be2\u65b9\u6848SLRQ\uff0c\u7ed3\u5408\u5b89\u5168\u5b66\u4e60\u7a7a\u95f4\u7d22\u5f15SLS-INDEX\uff0c\u5728\u52a0\u5bc6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u9ad8\u6548\u4e14\u5b89\u5168\u7684\u8303\u56f4\u67e5\u8be2\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u4e91\u670d\u52a1\u5728\u5927\u89c4\u6a21\u6570\u636e\u7ba1\u7406\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4fdd\u62a4\u5916\u5305\u6570\u636e\u96c6\u7684\u5b89\u5168\u548c\u9690\u79c1\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u52a0\u5bc6\u6570\u636e\u548c\u67e5\u8be2\u53ef\u4ee5\u9632\u6b62\u76f4\u63a5\u5185\u5bb9\u66b4\u9732\uff0c\u4f46\u653b\u51fb\u8005\u4ecd\u53ef\u901a\u8fc7\u8bbf\u95ee\u6a21\u5f0f\u548c\u641c\u7d22\u8def\u5f84\u5206\u6790\u63a8\u65ad\u654f\u611f\u4fe1\u606f\u3002\u73b0\u6709\u63d0\u4f9b\u5f3a\u8bbf\u95ee\u6a21\u5f0f\u9690\u79c1\u7684\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u5e26\u6765\u663e\u8457\u7684\u6027\u80fd\u5f00\u9500\u3002", "method": "\u63d0\u51faSLS-INDEX\u5b89\u5168\u5b66\u4e60\u7d22\u5f15\uff0c\u5c06Paillier\u5bc6\u7801\u7cfb\u7edf\u4e0e\u5206\u5c42\u9884\u6d4b\u67b6\u6784\u548c\u566a\u58f0\u6ce8\u5165\u6876\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u52a0\u5bc6\u57df\u4e2d\u7684\u6570\u636e\u611f\u77e5\u67e5\u8be2\u52a0\u901f\u3002SLRQ\u91c7\u7528\u57fa\u4e8e\u7f6e\u6362\u7684\u5b89\u5168\u6876\u9884\u6d4b\u534f\u8bae\u6df7\u6dc6\u67e5\u8be2\u6267\u884c\u8def\u5f84\uff0c\u5e76\u5f15\u5165\u5b89\u5168\u70b9\u63d0\u53d6\u534f\u8bae\u751f\u6210\u5019\u9009\u7ed3\u679c\u4ee5\u51cf\u5c11\u5b89\u5168\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSLRQ\u5728\u67e5\u8be2\u6548\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u786e\u4fdd\u6570\u636e\u96c6\u3001\u67e5\u8be2\u3001\u7ed3\u679c\u548c\u8bbf\u95ee\u6a21\u5f0f\u7684\u9690\u79c1\u3002\u63d0\u4f9b\u4e86\u5728\u73b0\u5b9e\u6cc4\u6f0f\u51fd\u6570\u4e0b\u7684\u5f62\u5f0f\u5316\u5b89\u5168\u5206\u6790\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684SLRQ\u65b9\u6848\u5728\u52a0\u5bc6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u5b89\u5168\u7684\u8303\u56f4\u67e5\u8be2\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u5b89\u5168\u5b66\u4e60\u7d22\u5f15\u548c\u534f\u8bae\u8bbe\u8ba1\uff0c\u5728\u4fdd\u8bc1\u5f3a\u5b89\u5168\u6027\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u4e86\u67e5\u8be2\u6027\u80fd\uff0c\u4e3a\u4e91\u73af\u5883\u4e0b\u7684\u9690\u79c1\u4fdd\u62a4\u6570\u636e\u7ba1\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.03720", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03720", "abs": "https://arxiv.org/abs/2512.03720", "authors": ["Tengyun Ma", "Jiaqi Yao", "Daojing He", "Shihao Peng", "Yu Li", "Shaohui Liu", "Zhuotao Tian"], "title": "Context-Aware Hierarchical Learning: A Two-Step Paradigm towards Safer LLMs", "comment": null, "summary": "Large Language Models (LLMs) have emerged as powerful tools for diverse applications. However, their uniform token processing paradigm introduces critical vulnerabilities in instruction handling, particularly when exposed to adversarial scenarios. In this work, we identify and propose a novel class of vulnerabilities, termed Tool-Completion Attack (TCA), which exploits function-calling mechanisms to subvert model behavior. To evaluate LLM robustness against such threats, we introduce the Tool-Completion benchmark, a comprehensive security assessment framework, which reveals that even state-of-the-art models remain susceptible to TCA, with surprisingly high attack success rates. To address these vulnerabilities, we introduce Context-Aware Hierarchical Learning (CAHL), a sophisticated mechanism that dynamically balances semantic comprehension with role-specific instruction constraints. CAHL leverages the contextual correlations between different instruction segments to establish a robust, context-aware instruction hierarchy. Extensive experiments demonstrate that CAHL significantly enhances LLM robustness against both conventional attacks and the proposed TCA, exhibiting strong generalization capabilities in zero-shot evaluations while still preserving model performance on generic tasks. Our code is available at https://github.com/S2AILab/CAHL.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684LLM\u5b89\u5168\u6f0f\u6d1e\u2014\u2014\u5de5\u5177\u5b8c\u6210\u653b\u51fb(TCA)\uff0c\u5e76\u5f00\u53d1\u4e86CAHL\u9632\u5fa1\u673a\u5236\u6765\u589e\u5f3a\u6a21\u578b\u5bf9\u8fd9\u7c7b\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u6307\u4ee4\u65f6\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u7279\u522b\u662f\u5176\u7edf\u4e00\u7684token\u5904\u7406\u8303\u5f0f\u5728\u9762\u5bf9\u5bf9\u6297\u6027\u573a\u666f\u65f6\u5bb9\u6613\u53d7\u5230\u653b\u51fb\u3002\u4f5c\u8005\u53d1\u73b0\u51fd\u6570\u8c03\u7528\u673a\u5236\u53ef\u80fd\u88ab\u5229\u7528\u6765\u98a0\u8986\u6a21\u578b\u884c\u4e3a\uff0c\u56e0\u6b64\u9700\u8981\u8bc4\u4f30\u548c\u6539\u8fdbLLM\u7684\u5b89\u5168\u6027\u3002", "method": "\u9996\u5148\u63d0\u51fa\u4e86\u5de5\u5177\u5b8c\u6210\u653b\u51fb(TCA)\u8fd9\u4e00\u65b0\u578b\u6f0f\u6d1e\u7c7b\u522b\uff0c\u7136\u540e\u5f00\u53d1\u4e86Tool-Completion\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u6765\u8bc4\u4f30LLM\u7684\u9c81\u68d2\u6027\u3002\u4e3a\u9632\u5fa1\u6b64\u7c7b\u653b\u51fb\uff0c\u63d0\u51fa\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u5206\u5c42\u5b66\u4e60(CAHL)\u673a\u5236\uff0c\u8be5\u673a\u5236\u901a\u8fc7\u52a8\u6001\u5e73\u8861\u8bed\u4e49\u7406\u89e3\u548c\u89d2\u8272\u7279\u5b9a\u6307\u4ee4\u7ea6\u675f\uff0c\u5229\u7528\u4e0d\u540c\u6307\u4ee4\u6bb5\u4e4b\u95f4\u7684\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u5efa\u7acb\u9c81\u68d2\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u6307\u4ee4\u5c42\u6b21\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u662f\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6a21\u578b\u4e5f\u5bb9\u6613\u53d7\u5230TCA\u653b\u51fb\uff0c\u653b\u51fb\u6210\u529f\u7387\u60ca\u4eba\u5730\u9ad8\u3002CAHL\u663e\u8457\u589e\u5f3a\u4e86LLM\u5bf9\u4f20\u7edf\u653b\u51fb\u548cTCA\u7684\u9c81\u68d2\u6027\uff0c\u5728\u96f6\u6837\u672c\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u4ecd\u80fd\u4fdd\u6301\u6a21\u578b\u5728\u901a\u7528\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86LLM\u5728\u6307\u4ee4\u5904\u7406\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e86\u6709\u6548\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u9632\u5fa1\u673a\u5236\u3002CAHL\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5206\u5c42\u5b66\u4e60\u65b9\u6cd5\u6210\u529f\u63d0\u5347\u4e86\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u4e3aLLM\u7684\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2512.03765", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.03765", "abs": "https://arxiv.org/abs/2512.03765", "authors": ["Jose E. Puente", "Carlos Puente"], "title": "The Treasury Proof Ledger: A Cryptographic Framework for Accountable Bitcoin Treasuries", "comment": null, "summary": "Public companies and institutional investors that hold Bitcoin face increasing pressure to show solvency, manage risk, and satisfy regulatory expectations without exposing internal wallet structures or trading strategies. This paper introduces the Treasury Proof Ledger (TPL), a Bitcoin-anchored logging framework for multi-domain Bitcoin treasuries that treats on-chain and off-chain exposures as a conserved state machine with an explicit fee sink. A TPL instance records proof-of-reserves snapshots, proof-of-transit receipts for movements between domains, and policy metadata, and it supports restricted views based on stakeholder permissions. We define an idealised TPL model, represent Bitcoin treasuries as multi-domain exposure vectors, and give deployment-level security notions including exposure soundness, policy completeness, non-equivocation, and privacy-compatible policy views. We then outline how practical, restricted forms of these guarantees can be achieved by combining standard proof-of-reserves and proof-of-transit techniques with hash-based commitments anchored on Bitcoin. The results are existence-type statements: they show which guarantees are achievable once economic and governance assumptions are set, without claiming that any current system already provides them. A stylised corporate-treasury example illustrates how TPL could support responsible transparency policies and future cross-institution checks consistent with Bitcoin's fixed monetary supply.", "AI": {"tldr": "TPL\u662f\u4e00\u4e2a\u6bd4\u7279\u5e01\u951a\u5b9a\u7684\u591a\u57df\u8d44\u91d1\u5e93\u65e5\u5fd7\u6846\u67b6\uff0c\u901a\u8fc7\u72b6\u6001\u673a\u6a21\u578b\u8bb0\u5f55\u50a8\u5907\u8bc1\u660e\u3001\u8d44\u91d1\u8f6c\u79fb\u8bc1\u660e\u548c\u653f\u7b56\u5143\u6570\u636e\uff0c\u652f\u6301\u57fa\u4e8e\u6743\u9650\u7684\u53d7\u9650\u89c6\u56fe\uff0c\u65e8\u5728\u5e2e\u52a9\u4e0a\u5e02\u516c\u53f8\u548c\u673a\u6784\u6295\u8d44\u8005\u5728\u4e0d\u66b4\u9732\u5185\u90e8\u94b1\u5305\u7ed3\u6784\u6216\u4ea4\u6613\u7b56\u7565\u7684\u60c5\u51b5\u4e0b\u8bc1\u660e\u507f\u4ed8\u80fd\u529b\u3002", "motivation": "\u4e0a\u5e02\u516c\u53f8\u548c\u673a\u6784\u6295\u8d44\u8005\u6301\u6709\u6bd4\u7279\u5e01\u9762\u4e34\u65e5\u76ca\u589e\u957f\u7684\u538b\u529b\uff0c\u9700\u8981\u5728\u8bc1\u660e\u507f\u4ed8\u80fd\u529b\u3001\u7ba1\u7406\u98ce\u9669\u548c\u6ee1\u8db3\u76d1\u7ba1\u671f\u671b\u7684\u540c\u65f6\uff0c\u4e0d\u66b4\u9732\u5185\u90e8\u94b1\u5305\u7ed3\u6784\u6216\u4ea4\u6613\u7b56\u7565\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u591a\u57df\u8d44\u91d1\u5e93\u900f\u660e\u5316\u6846\u67b6\u3002", "method": "\u63d0\u51faTreasury Proof Ledger\uff08TPL\uff09\u6846\u67b6\uff0c\u5c06\u94fe\u4e0a\u548c\u94fe\u4e0b\u98ce\u9669\u655e\u53e3\u89c6\u4e3a\u5177\u6709\u660e\u786e\u8d39\u7528\u6c60\u7684\u5b88\u6052\u72b6\u6001\u673a\u3002TPL\u8bb0\u5f55\u50a8\u5907\u8bc1\u660e\u5feb\u7167\u3001\u57df\u95f4\u8f6c\u79fb\u8bc1\u660e\u6536\u636e\u548c\u653f\u7b56\u5143\u6570\u636e\uff0c\u652f\u6301\u57fa\u4e8e\u5229\u76ca\u76f8\u5173\u8005\u6743\u9650\u7684\u53d7\u9650\u89c6\u56fe\u3002\u7ed3\u5408\u6807\u51c6\u50a8\u5907\u8bc1\u660e\u548c\u8f6c\u79fb\u8bc1\u660e\u6280\u672f\uff0c\u901a\u8fc7\u57fa\u4e8e\u54c8\u5e0c\u7684\u627f\u8bfa\u951a\u5b9a\u5728\u6bd4\u7279\u5e01\u4e0a\u5b9e\u73b0\u3002", "result": "\u5b9a\u4e49\u4e86\u7406\u60f3\u5316\u7684TPL\u6a21\u578b\uff0c\u5c06\u6bd4\u7279\u5e01\u8d44\u91d1\u5e93\u8868\u793a\u4e3a\u591a\u57df\u98ce\u9669\u655e\u53e3\u5411\u91cf\uff0c\u63d0\u51fa\u4e86\u90e8\u7f72\u7ea7\u5b89\u5168\u6982\u5ff5\uff08\u655e\u53e3\u5065\u5168\u6027\u3001\u653f\u7b56\u5b8c\u6574\u6027\u3001\u975e\u62b5\u8d56\u6027\u3001\u9690\u79c1\u517c\u5bb9\u653f\u7b56\u89c6\u56fe\uff09\u3002\u7ed3\u679c\u8868\u660e\u5728\u8bbe\u5b9a\u7ecf\u6d4e\u548c\u6cbb\u7406\u5047\u8bbe\u540e\uff0c\u8fd9\u4e9b\u4fdd\u8bc1\u662f\u53ef\u5b9e\u73b0\u7684\uff0c\u4f46\u672a\u58f0\u79f0\u73b0\u6709\u7cfb\u7edf\u5df2\u63d0\u4f9b\u8fd9\u4e9b\u4fdd\u8bc1\u3002", "conclusion": "TPL\u6846\u67b6\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u6bd4\u7279\u5e01\u951a\u5b9a\u7684\u627f\u8bfa\u673a\u5236\u5b9e\u73b0\u8d1f\u8d23\u4efb\u900f\u660e\u5ea6\u653f\u7b56\uff0c\u652f\u6301\u672a\u6765\u8de8\u673a\u6784\u68c0\u67e5\uff0c\u4e0e\u6bd4\u7279\u5e01\u56fa\u5b9a\u8d27\u5e01\u4f9b\u5e94\u91cf\u4fdd\u6301\u4e00\u81f4\u3002\u4f01\u4e1a\u8d44\u91d1\u5e93\u793a\u4f8b\u8bf4\u660e\u4e86\u8be5\u6846\u67b6\u5982\u4f55\u652f\u6301\u900f\u660e\u5316\u9700\u6c42\u3002"}}
{"id": "2512.03775", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.03775", "abs": "https://arxiv.org/abs/2512.03775", "authors": ["Biwei Yan", "Yue Zhang", "Minghui Xu", "Hao Wu", "Yechao Zhang", "Kun Li", "Guoming Zhang", "Xiuzhen Cheng"], "title": "\"MCP Does Not Stand for Misuse Cryptography Protocol\": Uncovering Cryptographic Misuse in Model Context Protocol at Scale", "comment": null, "summary": "The Model Context Protocol (MCP) is rapidly emerging as the middleware for LLM-based applications, offering a standardized interface for tool integration. However, its built-in security mechanisms are minimal: while schemas and declarations prevent malformed requests, MCP provides no guarantees of authenticity or confidentiality, forcing developers to implement cryptography themselves. Such ad hoc practices are historically prone to misuse, and within MCP they threaten sensitive data and services. We present MICRYSCOPE, the first domain-specific framework for detecting cryptographic misuses in MCP implementations. MICRYSCOPE combines three key innovations: a cross-language intermediate representation that normalizes cryptographic APIs across diverse ecosystems, a hybrid dependency analysis that uncovers explicit and implicit function relationships (including insecure runtime compositions orchestrated by LLMs) and a taint-based misuse detector that tracks sensitive data flows and flags violations of established cryptographic rules. Applying MICRYSCOPE to 9,403 MCP servers, we identified 720 with cryptographic logic, of which 19.7% exhibited misuses. These flaws are concentrated in certain markets (e.g., Smithery Registry with 42% insecure servers), languages (Python at 34% misuse rate), and categories (Developer Tools and Data Science & ML accounting for over 50% of all misuses). Case studies reveal real-world consequences, including leaked API keys, insecure DES/ECB tools, and MD5-based authentication bypasses. Our study establishes the first ecosystem-wide view of cryptographic misuse in MCP and provides both tools and insights to strengthen the security foundations of this rapidly growing protocol.", "AI": {"tldr": "MICRYSCOPE\u662f\u9996\u4e2a\u68c0\u6d4bMCP\uff08\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff09\u5b9e\u73b0\u4e2d\u5bc6\u7801\u5b66\u8bef\u7528\u7684\u9886\u57df\u7279\u5b9a\u6846\u67b6\uff0c\u57289403\u4e2aMCP\u670d\u52a1\u5668\u4e2d\u53d1\u73b019.7%\u5b58\u5728\u5bc6\u7801\u5b66\u8bef\u7528\u95ee\u9898\u3002", "motivation": "MCP\u4f5c\u4e3aLLM\u5e94\u7528\u4e2d\u95f4\u4ef6\u7f3a\u4e4f\u5185\u7f6e\u5b89\u5168\u673a\u5236\uff0c\u5f00\u53d1\u8005\u9700\u8981\u81ea\u884c\u5b9e\u73b0\u5bc6\u7801\u5b66\u529f\u80fd\uff0c\u8fd9\u79cd\u4e34\u65f6\u5b9e\u8df5\u5bb9\u6613\u5bfc\u81f4\u8bef\u7528\uff0c\u5a01\u80c1\u654f\u611f\u6570\u636e\u548c\u670d\u52a1\u5b89\u5168\u3002", "method": "MICRYSCOPE\u7ed3\u5408\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a\u8de8\u8bed\u8a00\u4e2d\u95f4\u8868\u793a\u6807\u51c6\u5316\u5bc6\u7801\u5b66API\u3001\u6df7\u5408\u4f9d\u8d56\u5206\u6790\u63ed\u793a\u663e\u9690\u51fd\u6570\u5173\u7cfb\uff08\u5305\u62ecLLM\u7f16\u6392\u7684\u4e0d\u5b89\u5168\u8fd0\u884c\u65f6\u7ec4\u5408\uff09\u3001\u57fa\u4e8e\u6c61\u70b9\u7684\u8bef\u7528\u68c0\u6d4b\u5668\u8ffd\u8e2a\u654f\u611f\u6570\u636e\u6d41\u5e76\u6807\u8bb0\u8fdd\u53cd\u5bc6\u7801\u5b66\u89c4\u5219\u7684\u60c5\u51b5\u3002", "result": "\u5206\u67909403\u4e2aMCP\u670d\u52a1\u5668\uff0c\u53d1\u73b0720\u4e2a\u5305\u542b\u5bc6\u7801\u5b66\u903b\u8f91\uff0c\u5176\u4e2d19.7%\u5b58\u5728\u8bef\u7528\u3002\u95ee\u9898\u96c6\u4e2d\u5728\u7279\u5b9a\u5e02\u573a\uff08\u5982Smithery Registry\u670942%\u4e0d\u5b89\u5168\u670d\u52a1\u5668\uff09\u3001\u8bed\u8a00\uff08Python\u8bef\u7528\u738734%\uff09\u548c\u7c7b\u522b\uff08\u5f00\u53d1\u8005\u5de5\u5177\u4e0e\u6570\u636e\u79d1\u5b66&ML\u5360\u6240\u6709\u8bef\u752850%\u4ee5\u4e0a\uff09\u3002\u6848\u4f8b\u7814\u7a76\u63ed\u793a\u4e86API\u5bc6\u94a5\u6cc4\u9732\u3001\u4e0d\u5b89\u5168\u7684DES/ECB\u5de5\u5177\u548c\u57fa\u4e8eMD5\u7684\u8eab\u4efd\u9a8c\u8bc1\u7ed5\u8fc7\u7b49\u5b9e\u9645\u540e\u679c\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u5efa\u7acb\u4e86MCP\u4e2d\u5bc6\u7801\u5b66\u8bef\u7528\u7684\u751f\u6001\u7cfb\u7edf\u5168\u666f\u89c6\u56fe\uff0c\u4e3a\u52a0\u5f3a\u8fd9\u4e00\u5feb\u901f\u589e\u957f\u534f\u8bae\u7684\u5b89\u5168\u57fa\u7840\u63d0\u4f9b\u4e86\u5de5\u5177\u548c\u89c1\u89e3\u3002"}}

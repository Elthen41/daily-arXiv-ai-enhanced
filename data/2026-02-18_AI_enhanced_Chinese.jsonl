{"id": "2602.15166", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.15166", "abs": "https://arxiv.org/abs/2602.15166", "authors": ["Tanner Andrulis", "Michael Gilbert", "Vivienne Sze", "Joel S. Emer"], "title": "Fast and Fusiest: An Optimal Fusion-Aware Mapper for Accelerator Modeling and Evaluation", "comment": null, "summary": "The latency and energy of tensor algebra accelerators depend on how data movement and operations are scheduled (i.e., mapped) onto accelerators, so determining the potential of an accelerator architecture requires both a performance model and a mapper to search for the optimal mapping. A key optimization that the mapper must explore is fusion, meaning holding data on-chip between computation steps, which has been shown to reduce energy and latency by reducing DRAM accesses. However, prior mappers cannot find optimal mappings with fusion (i.e., fused mappings) in a feasible runtime because the number of fused mappings to search increases exponentially with the number of workload computation steps.\n  In this paper, we introduce the Fast and Fusiest Mapper (FFM), the first mapper to quickly find optimal mappings in a comprehensive fused mapspace for tensor algebra workloads. FFM shrinks the search space by pruning subsets of mappings (i.e., partial mappings) that are shown to never be a part of optimal mappings, quickly eliminating all suboptimal mappings with those partial mappings as subsets. Then FFM joins partial mappings to construct optimal fused mappings. We evaluate FFM and show that, although the mapspace size grows exponentially with the number of computation steps, FFM's runtime scales approximately linearly. FFM is orders of magnitude faster ($>1000\\times$) than prior state-of-the-art approaches at finding optimal mappings for Transformers.", "AI": {"tldr": "FFM\u662f\u9996\u4e2a\u80fd\u5feb\u901f\u5728\u5f20\u91cf\u4ee3\u6570\u5de5\u4f5c\u8d1f\u8f7d\u7684\u878d\u5408\u6620\u5c04\u7a7a\u95f4\u4e2d\u5bfb\u627e\u6700\u4f18\u6620\u5c04\u7684\u6620\u5c04\u5668\uff0c\u901a\u8fc7\u526a\u679d\u975e\u6700\u4f18\u5b50\u6620\u5c04\u5e76\u7ec4\u5408\u90e8\u5206\u6620\u5c04\u6765\u6784\u5efa\u6700\u4f18\u878d\u5408\u6620\u5c04\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u901f\u5ea6\u63d0\u5347\u8d85\u8fc71000\u500d\u3002", "motivation": "\u73b0\u6709\u6620\u5c04\u5668\u65e0\u6cd5\u5728\u53ef\u884c\u65f6\u95f4\u5185\u627e\u5230\u878d\u5408\u7684\u6700\u4f18\u6620\u5c04\uff0c\u56e0\u4e3a\u878d\u5408\u6620\u5c04\u7684\u641c\u7d22\u7a7a\u95f4\u968f\u8ba1\u7b97\u6b65\u9aa4\u6570\u91cf\u5448\u6307\u6570\u589e\u957f\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5feb\u901f\u627e\u5230\u6700\u4f18\u878d\u5408\u6620\u5c04\u7684\u65b9\u6cd5\u6765\u5145\u5206\u53d1\u6325\u5f20\u91cf\u4ee3\u6570\u52a0\u901f\u5668\u7684\u6f5c\u529b\u3002", "method": "FFM\u901a\u8fc7\u526a\u679d\u6c38\u8fdc\u4e0d\u4f1a\u6210\u4e3a\u6700\u4f18\u6620\u5c04\u4e00\u90e8\u5206\u7684\u90e8\u5206\u6620\u5c04\uff08\u5b50\u6620\u5c04\uff09\u6765\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u7136\u540e\u7ec4\u5408\u90e8\u5206\u6620\u5c04\u6765\u6784\u5efa\u6700\u4f18\u878d\u5408\u6620\u5c04\u3002\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u6307\u6570\u589e\u957f\u7684\u6620\u5c04\u7a7a\u95f4\u3002", "result": "FFM\u7684\u8fd0\u884c\u65f6\u95f4\u968f\u8ba1\u7b97\u6b65\u9aa4\u6570\u91cf\u8fd1\u4f3c\u7ebf\u6027\u589e\u957f\uff0c\u800c\u6620\u5c04\u7a7a\u95f4\u5927\u5c0f\u5448\u6307\u6570\u589e\u957f\u3002\u5bf9\u4e8eTransformer\u5de5\u4f5c\u8d1f\u8f7d\uff0cFFM\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u5feb1000\u500d\u4ee5\u4e0a\u3002", "conclusion": "FFM\u662f\u9996\u4e2a\u80fd\u5feb\u901f\u5728\u878d\u5408\u6620\u5c04\u7a7a\u95f4\u4e2d\u5bfb\u627e\u6700\u4f18\u6620\u5c04\u7684\u6620\u5c04\u5668\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u5728\u53ef\u884c\u65f6\u95f4\u5185\u627e\u5230\u6700\u4f18\u878d\u5408\u6620\u5c04\u7684\u95ee\u9898\uff0c\u4e3a\u5f20\u91cf\u4ee3\u6570\u52a0\u901f\u5668\u7684\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.15172", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.15172", "abs": "https://arxiv.org/abs/2602.15172", "authors": ["Michael Gilbert", "Tanner Andrulis", "Vivienne Sze", "Joel S. Emer"], "title": "The Turbo-Charged Mapper: Fast and Optimal Mapping for Accelerator Modeling and Evaluation", "comment": null, "summary": "The energy and latency of an accelerator running a deep neural network (DNN) depend on how the computation and data movement are scheduled in the accelerator (i.e., mapping). Optimizing mappings is essential to evaluating and designing accelerators. However, the space of mappings is large, and prior works can not guarantee finding optimal mappings because they use heuristics or metaheuristics to narrow down the space. These limitations preclude proper hardware evaluation, since designers can not tell whether performance differences are due to changes in hardware or suboptimal mapping.\n  To address this challenge, we propose the Turbo-Charged Mapper (TCM), a fast mapper that is guaranteed to find optimal mappings. The key to our approach is that we define a new concept in mapping, called dataplacement, which, like the prior concept of dataflow, allows for clear analysis and comparison of mappings. Through it, we identify multiple opportunities to prune redundant and suboptimal mappings, reducing search space by up to 32 orders of magnitude.\n  Leveraging these insights, TCM can perform full mapspace searches, making it the first mapper that can find optimal mappings in feasible runtime. Compared to prior mappers, we show that TCM can find optimal mappings quickly (less than a minute), while prior works can not find optimal mappings (energy-delay-product $21\\%$ higher than optimal) even when given $1000\\times$ the runtime ($>10$ hours).", "AI": {"tldr": "TCM\u662f\u4e00\u79cd\u80fd\u4fdd\u8bc1\u627e\u5230\u6700\u4f18\u6620\u5c04\u7684\u5feb\u901f\u6620\u5c04\u5668\uff0c\u901a\u8fc7\u6570\u636e\u653e\u7f6e\u6982\u5ff5\u5927\u5e45\u51cf\u5c11\u641c\u7d22\u7a7a\u95f4\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u80fd\u66f4\u5feb\u627e\u5230\u6700\u4f18\u89e3", "motivation": "\u73b0\u6709\u52a0\u901f\u5668\u6620\u5c04\u4f18\u5316\u65b9\u6cd5\u4f7f\u7528\u542f\u53d1\u5f0f\u6216\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u627e\u5230\u6700\u4f18\u6620\u5c04\uff0c\u8fd9\u963b\u788d\u4e86\u786c\u4ef6\u8bc4\u4f30\u7684\u51c6\u786e\u6027\uff0c\u56e0\u4e3a\u65e0\u6cd5\u533a\u5206\u6027\u80fd\u5dee\u5f02\u662f\u6e90\u4e8e\u786c\u4ef6\u6539\u8fdb\u8fd8\u662f\u6b21\u4f18\u6620\u5c04", "method": "\u63d0\u51faTurbo-Charged Mapper (TCM)\uff0c\u5f15\u5165\u6570\u636e\u653e\u7f6e\u65b0\u6982\u5ff5\uff0c\u901a\u8fc7\u5206\u6790\u8bc6\u522b\u5197\u4f59\u548c\u6b21\u4f18\u6620\u5c04\u673a\u4f1a\uff0c\u5c06\u641c\u7d22\u7a7a\u95f4\u51cf\u5c11\u591a\u8fbe32\u4e2a\u6570\u91cf\u7ea7", "result": "TCM\u80fd\u5728\u4e0d\u52301\u5206\u949f\u5185\u627e\u5230\u6700\u4f18\u6620\u5c04\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u5373\u4f7f\u7ed9\u4e881000\u500d\u8fd0\u884c\u65f6\u95f4\uff08>10\u5c0f\u65f6\uff09\u4e5f\u65e0\u6cd5\u627e\u5230\u6700\u4f18\u6620\u5c04\uff0c\u5176\u80fd\u91cf\u5ef6\u8fdf\u4e58\u79ef\u6bd4\u6700\u4f18\u89e3\u9ad821%", "conclusion": "TCM\u662f\u9996\u4e2a\u80fd\u5728\u53ef\u884c\u8fd0\u884c\u65f6\u95f4\u5185\u6267\u884c\u5b8c\u6574\u6620\u5c04\u7a7a\u95f4\u641c\u7d22\u7684\u6620\u5c04\u5668\uff0c\u4fdd\u8bc1\u4e86\u6700\u4f18\u6620\u5c04\u7684\u53d1\u73b0\uff0c\u4e3a\u786c\u4ef6\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u9760\u5de5\u5177"}}
{"id": "2602.15336", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.15336", "abs": "https://arxiv.org/abs/2602.15336", "authors": ["Yogeswar Reddy Thota", "Setareh Rafatirad", "Homayoun Houman", "Tooraj Nikoubin"], "title": "Human-AI Interaction: Evaluating LLM Reasoning on Digital Logic Circuit included Graph Problems, in terms of creativity in design and analysis", "comment": null, "summary": "Large Language Models (LLMs) are increasingly used by undergraduate students as on-demand tutors, yet their reliability on circuit- and diagram-based digital logic problems remains unclear. We present a human- AI study evaluating three widely used LLMs (GPT, Gemini, and Claude) on 10 undergraduate-level digital logic questions spanning non-standard counters, JK-based state transitions, timing diagrams, frequency division, and finite-state machines. Twenty-four students performed pairwise model comparisons, providing per-question judgments on (i) preferred model, (ii) perceived correctness, (iii) consistency, (iv) verbosity, and (v) confidence, along with global ratings of overall model quality, satisfaction across multiple dimensions (e.g., accuracy and clarity), and perceived mental effort required to verify answers. To benchmark technical validity, we applied an independent judge-based evaluation against official solutions for all ten questions, using strict correctness criteria. Results reveal a consistent gap between perceived helpfulness and formal correctness: for the most sequentially demanding problems (Q1- Q7), none of the evaluated LLMs matched the official answers, despite producing confident, well-structured explanations that students often rated favorably. Error analysis indicates that models frequently default to canonical textbook templates (e.g., standard ripple counters) and struggle to translate circuit structure into exact state evolution and timing behavior. These findings suggest that, without verification scaffolds, LLMs may be unreliable for core digital logic topics and can inadvertently reinforce misconceptions in undergraduate instruction.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86GPT\u3001Gemini\u548cClaude\u4e09\u79cd\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b57\u903b\u8f91\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u5f62\u5f0f\u6b63\u786e\u6027\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u5b66\u751f\u4ecd\u8ba4\u4e3a\u5176\u6709\u5e2e\u52a9\uff0c\u63ed\u793a\u4e86\u611f\u77e5\u6709\u7528\u6027\u4e0e\u5b9e\u9645\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u672c\u79d1\u751f\u7528\u4f5c\u6309\u9700\u5bfc\u5e08\uff0c\u4f46\u5176\u5728\u7535\u8def\u548c\u56fe\u8868\u7c7b\u6570\u5b57\u903b\u8f91\u95ee\u9898\u4e0a\u7684\u53ef\u9760\u6027\u5c1a\u4e0d\u6e05\u695a\u3002\u9700\u8981\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u5728\u6838\u5fc3\u6570\u5b57\u903b\u8f91\u4e3b\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u4ee5\u4e86\u89e3\u5176\u5728\u672c\u79d1\u6559\u5b66\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u8fdb\u884c\u4e86\u4eba\u673a\u4ea4\u4e92\u7814\u7a76\uff0c\u8bc4\u4f30\u4e09\u79cd\u4e3b\u6d41LLM\u572810\u4e2a\u672c\u79d1\u6c34\u5e73\u6570\u5b57\u903b\u8f91\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u300224\u540d\u5b66\u751f\u8fdb\u884c\u914d\u5bf9\u6a21\u578b\u6bd4\u8f83\uff0c\u63d0\u4f9b\u6bcf\u4e2a\u95ee\u9898\u7684\u504f\u597d\u3001\u611f\u77e5\u6b63\u786e\u6027\u3001\u4e00\u81f4\u6027\u3001\u5197\u957f\u5ea6\u548c\u4fe1\u5fc3\u7b49\u8bc4\u4ef7\u3002\u540c\u65f6\u91c7\u7528\u72ec\u7acb\u6cd5\u5b98\u8bc4\u4f30\uff0c\u5bf9\u7167\u5b98\u65b9\u89e3\u51b3\u65b9\u6848\u4f7f\u7528\u4e25\u683c\u6b63\u786e\u6027\u6807\u51c6\u8fdb\u884c\u6280\u672f\u6709\u6548\u6027\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\u611f\u77e5\u6709\u7528\u6027\u4e0e\u5f62\u5f0f\u6b63\u786e\u6027\u4e4b\u95f4\u5b58\u5728\u4e00\u81f4\u5dee\u8ddd\uff1a\u5bf9\u4e8e\u6700\u9700\u8981\u987a\u5e8f\u63a8\u7406\u7684\u95ee\u9898\uff08Q1-Q7\uff09\uff0c\u6240\u6709\u8bc4\u4f30\u7684LLM\u90fd\u65e0\u6cd5\u5339\u914d\u5b98\u65b9\u7b54\u6848\uff0c\u5c3d\u7ba1\u5b83\u4eec\u4ea7\u751f\u4e86\u81ea\u4fe1\u3001\u7ed3\u6784\u826f\u597d\u7684\u89e3\u91ca\uff0c\u5b66\u751f\u901a\u5e38\u7ed9\u4e88\u79ef\u6781\u8bc4\u4ef7\u3002\u9519\u8bef\u5206\u6790\u8868\u660e\u6a21\u578b\u7ecf\u5e38\u9ed8\u8ba4\u4f7f\u7528\u6807\u51c6\u6559\u79d1\u4e66\u6a21\u677f\uff0c\u96be\u4ee5\u5c06\u7535\u8def\u7ed3\u6784\u8f6c\u5316\u4e3a\u7cbe\u786e\u7684\u72b6\u6001\u6f14\u5316\u548c\u65f6\u5e8f\u884c\u4e3a\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u6ca1\u6709\u9a8c\u8bc1\u6846\u67b6\u7684\u60c5\u51b5\u4e0b\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6838\u5fc3\u6570\u5b57\u903b\u8f91\u4e3b\u9898\u4e0a\u53ef\u80fd\u4e0d\u53ef\u9760\uff0c\u5e76\u53ef\u80fd\u5728\u672c\u79d1\u6559\u5b66\u4e2d\u65e0\u610f\u4e2d\u5f3a\u5316\u9519\u8bef\u6982\u5ff5\u3002\u8fd9\u5f3a\u8c03\u4e86\u5728\u6570\u5b57\u903b\u8f91\u6559\u80b2\u4e2d\u4f7f\u7528LLM\u65f6\u9700\u8981\u9a8c\u8bc1\u673a\u5236\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.15388", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.15388", "abs": "https://arxiv.org/abs/2602.15388", "authors": ["Yonghao Wang", "Jiaxin Zhou", "Yang Yin", "Hongqin Lyu", "Zhiteng Chao", "Wenchao Ding", "Jing Ye", "Tiancheng Wang", "Huawei Li"], "title": "Iterative LLM-Based Assertion Generation Using Syntax-Semantic Representations for Functional Coverage-Guided Verification", "comment": "6 pages, 6 figures", "summary": "While leveraging LLMs to automatically generate SystemVerilog assertions (SVAs) from natural language specifications holds great potential, existing techniques face a key challenge: LLMs often lack sufficient understanding of IC design, leading to poor assertion quality in a single pass. Therefore, verifying whether the generated assertions effectively cover the functional specifications and designing feedback mechanisms based on this coverage remain significant hurdles. To address these limitations, this paper introduces CoverAssert, a novel iterative framework for optimizing SVA generation with LLMs. The core contribution is a lightweight mechanism for matching generated assertions with specific functional descriptions in the specifications. CoverAssert achieves this by clustering the joint representations of semantic features of LLM-generated assertions and structural features extracted from abstract syntax trees (ASTs) about signals related to assertions, and then mapping them back to the specifications to analyze functional coverage quality. Leveraging this capability, CoverAssert constructs a feedback loop based on functional coverage to guide LLMs in prioritizing uncovered functional points, thereby iteratively improving assertion quality. Experimental evaluations on four open-source designs demonstrate that integrating CoverAssert with state-of-the-art generators, AssertLLM and Spec2Assertion, achieves average improvements of 9.57 % in branch coverage, 9.64 % in statement coverage, and 15.69 % in toggle coverage.", "AI": {"tldr": "CoverAssert\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u8fed\u4ee3\u6846\u67b6\uff0c\u901a\u8fc7\u529f\u80fd\u8986\u76d6\u7387\u53cd\u9988\u673a\u5236\u4f18\u5316SystemVerilog\u65ad\u8a00\u751f\u6210\u8d28\u91cf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u56e0LLM\u5bf9IC\u8bbe\u8ba1\u7406\u89e3\u4e0d\u8db3\u5bfc\u81f4\u7684\u65ad\u8a00\u8d28\u91cf\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5229\u7528LLM\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u81ea\u52a8\u751f\u6210SystemVerilog\u65ad\u8a00\u7684\u6280\u672f\u9762\u4e34\u5173\u952e\u6311\u6218\uff1aLLM\u901a\u5e38\u7f3a\u4e4f\u8db3\u591f\u7684IC\u8bbe\u8ba1\u7406\u89e3\uff0c\u5bfc\u81f4\u5355\u6b21\u751f\u6210\u7684\u65ad\u8a00\u8d28\u91cf\u8f83\u5dee\u3002\u9a8c\u8bc1\u751f\u6210\u7684\u65ad\u8a00\u662f\u5426\u6709\u6548\u8986\u76d6\u529f\u80fd\u89c4\u8303\uff0c\u5e76\u57fa\u4e8e\u6b64\u8986\u76d6\u7387\u8bbe\u8ba1\u53cd\u9988\u673a\u5236\u4ecd\u7136\u662f\u91cd\u5927\u969c\u788d\u3002", "method": "CoverAssert\u5f15\u5165\u8f7b\u91cf\u7ea7\u673a\u5236\uff0c\u5c06\u751f\u6210\u7684\u65ad\u8a00\u4e0e\u89c4\u8303\u4e2d\u7684\u5177\u4f53\u529f\u80fd\u63cf\u8ff0\u8fdb\u884c\u5339\u914d\u3002\u901a\u8fc7\u805a\u7c7bLLM\u751f\u6210\u65ad\u8a00\u7684\u8bed\u4e49\u7279\u5f81\u548c\u4ece\u62bd\u8c61\u8bed\u6cd5\u6811\u63d0\u53d6\u7684\u65ad\u8a00\u76f8\u5173\u4fe1\u53f7\u7ed3\u6784\u7279\u5f81\u7684\u8054\u5408\u8868\u793a\uff0c\u7136\u540e\u5c06\u5176\u6620\u5c04\u56de\u89c4\u8303\u4ee5\u5206\u6790\u529f\u80fd\u8986\u76d6\u7387\u8d28\u91cf\u3002\u57fa\u4e8e\u529f\u80fd\u8986\u76d6\u7387\u6784\u5efa\u53cd\u9988\u5faa\u73af\uff0c\u6307\u5bfcLLM\u4f18\u5148\u5904\u7406\u672a\u8986\u76d6\u7684\u529f\u80fd\u70b9\uff0c\u4ece\u800c\u8fed\u4ee3\u6539\u8fdb\u65ad\u8a00\u8d28\u91cf\u3002", "result": "\u5728\u56db\u4e2a\u5f00\u6e90\u8bbe\u8ba1\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u5c06CoverAssert\u4e0e\u6700\u5148\u8fdb\u7684\u751f\u6210\u5668AssertLLM\u548cSpec2Assertion\u96c6\u6210\u540e\uff0c\u5e73\u5747\u6539\u8fdb\uff1a\u5206\u652f\u8986\u76d6\u73879.57%\uff0c\u8bed\u53e5\u8986\u76d6\u73879.64%\uff0c\u7ffb\u8f6c\u8986\u76d6\u738715.69%\u3002", "conclusion": "CoverAssert\u901a\u8fc7\u529f\u80fd\u8986\u76d6\u7387\u9a71\u52a8\u7684\u8fed\u4ee3\u4f18\u5316\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u751f\u6210SystemVerilog\u65ad\u8a00\u7684\u8d28\u91cf\u548c\u8986\u76d6\u7387\uff0c\u4e3a\u89e3\u51b3\u73b0\u6709\u6280\u672f\u4e2d\u7684\u5173\u952e\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2602.15204", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.15204", "abs": "https://arxiv.org/abs/2602.15204", "authors": ["Kevin Garner", "Polykarpos Thomadakis", "Nikos Chrisochoides"], "title": "Distributed Semi-Speculative Parallel Anisotropic Mesh Adaptation", "comment": "52 pages, 19 figures, 13 tables", "summary": "This paper presents a distributed memory method for anisotropic mesh adaptation that is designed to avoid the use of collective communication and global synchronization techniques. In the presented method, meshing functionality is separated from performance aspects by utilizing a separate entity for each - a multicore cc-NUMA-based (shared memory) mesh generation software and a parallel runtime system that is designed to help applications leverage the concurrency offered by emerging high-performance computing (HPC) architectures. First, an initial mesh is decomposed and its interface elements (subdomain boundaries) are adapted on a single multicore node (shared memory). Subdomains are then distributed among the nodes of an HPC cluster so that their interior elements are adapted while interface elements (already adapted) remain frozen to maintain mesh conformity. Lessons are presented regarding some re-designs of the shared memory software and how its speculative execution model is utilized by the distributed memory method to achieve good performance. The presented method is shown to generate meshes (of up to approximately 1 billion elements) with comparable quality and performance to existing state-of-the-art HPC meshing software.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u907f\u514d\u4f7f\u7528\u96c6\u4f53\u901a\u4fe1\u548c\u5168\u5c40\u540c\u6b65\u6280\u672f\u7684\u5206\u5e03\u5f0f\u5185\u5b58\u5404\u5411\u5f02\u6027\u7f51\u683c\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u79bb\u7f51\u683c\u751f\u6210\u529f\u80fd\u548c\u6027\u80fd\u65b9\u9762\uff0c\u5229\u7528\u591a\u6838cc-NUMA\u7f51\u683c\u751f\u6210\u8f6f\u4ef6\u548c\u5e76\u884c\u8fd0\u884c\u65f6\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe\u7ea610\u4ebf\u5143\u7d20\u7684\u7f51\u683c\u751f\u6210\u3002", "motivation": "\u4f20\u7edf\u5206\u5e03\u5f0f\u5185\u5b58\u7f51\u683c\u81ea\u9002\u5e94\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u96c6\u4f53\u901a\u4fe1\u548c\u5168\u5c40\u540c\u6b65\u6280\u672f\uff0c\u8fd9\u4e9b\u6280\u672f\u5728\u9ad8\u6027\u80fd\u8ba1\u7b97\u67b6\u6784\u4e2d\u53ef\u80fd\u6210\u4e3a\u6027\u80fd\u74f6\u9888\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u907f\u514d\u8fd9\u4e9b\u9650\u5236\u7684\u5206\u5e03\u5f0f\u5185\u5b58\u65b9\u6cd5\uff0c\u4ee5\u66f4\u597d\u5730\u5229\u7528\u65b0\u5174HPC\u67b6\u6784\u7684\u5e76\u53d1\u6027\u3002", "method": "\u65b9\u6cd5\u5c06\u7f51\u683c\u529f\u80fd\u4e0e\u6027\u80fd\u65b9\u9762\u5206\u79bb\uff1a\u4f7f\u7528\u591a\u6838cc-NUMA\u5171\u4eab\u5185\u5b58\u7f51\u683c\u751f\u6210\u8f6f\u4ef6\u5904\u7406\u7f51\u683c\u751f\u6210\uff0c\u5e76\u884c\u8fd0\u884c\u65f6\u7cfb\u7edf\u7ba1\u7406\u6027\u80fd\u3002\u9996\u5148\u5728\u5355\u4e2a\u591a\u6838\u8282\u70b9\u4e0a\u5206\u89e3\u521d\u59cb\u7f51\u683c\u5e76\u81ea\u9002\u5e94\u63a5\u53e3\u5143\u7d20\uff0c\u7136\u540e\u5c06\u5b50\u57df\u5206\u914d\u5230HPC\u96c6\u7fa4\u8282\u70b9\uff0c\u5728\u4fdd\u6301\u63a5\u53e3\u5143\u7d20\u51bb\u7ed3\u7684\u60c5\u51b5\u4e0b\u81ea\u9002\u5e94\u5185\u90e8\u5143\u7d20\uff0c\u4ee5\u7ef4\u6301\u7f51\u683c\u4e00\u81f4\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u9ad8\u8fbe\u7ea610\u4ebf\u5143\u7d20\u7684\u7f51\u683c\uff0c\u5176\u8d28\u91cf\u548c\u6027\u80fd\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u7684HPC\u7f51\u683c\u751f\u6210\u8f6f\u4ef6\u76f8\u5f53\u3002\u901a\u8fc7\u91cd\u65b0\u8bbe\u8ba1\u5171\u4eab\u5185\u5b58\u8f6f\u4ef6\u5e76\u5229\u7528\u5176\u63a8\u6d4b\u6267\u884c\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u826f\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u63d0\u51fa\u7684\u5206\u5e03\u5f0f\u5185\u5b58\u5404\u5411\u5f02\u6027\u7f51\u683c\u81ea\u9002\u5e94\u65b9\u6cd5\u901a\u8fc7\u907f\u514d\u96c6\u4f53\u901a\u4fe1\u548c\u5168\u5c40\u540c\u6b65\uff0c\u6709\u6548\u5229\u7528\u4e86HPC\u67b6\u6784\u7684\u5e76\u53d1\u6027\uff0c\u80fd\u591f\u751f\u6210\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u7f51\u683c\uff0c\u6027\u80fd\u4e0e\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\uff0c\u4e3a\u5927\u89c4\u6a21\u79d1\u5b66\u8ba1\u7b97\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7f51\u683c\u751f\u6210\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.15143", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.15143", "abs": "https://arxiv.org/abs/2602.15143", "authors": ["Xinhang Ma", "William Yeoh", "Ning Zhang", "Yevgeniy Vorobeychik"], "title": "Protecting Language Models Against Unauthorized Distillation through Trace Rewriting", "comment": null, "summary": "Knowledge distillation is a widely adopted technique for transferring capabilities from LLMs to smaller, more efficient student models. However, unauthorized use of knowledge distillation takes unfair advantage of the considerable effort and cost put into developing frontier models. We investigate methods for modifying teacher-generated reasoning traces to achieve two objectives that deter unauthorized distillation: (1) \\emph{anti-distillation}, or degrading the training usefulness of query responses, and (2) \\emph{API watermarking}, which embeds verifiable signatures in student models. We introduce several approaches for dynamically rewriting a teacher's reasoning outputs while preserving answer correctness and semantic coherence. Two of these leverage the rewriting capabilities of LLMs, while others use gradient-based techniques. Our experiments show that a simple instruction-based rewriting approach achieves a strong anti-distillation effect while maintaining or even improving teacher performance. Furthermore, we show that our rewriting approach also enables highly reliable watermark detection with essentially no false alarms.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u4fee\u6539\u6559\u5e08\u6a21\u578b\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\u6765\u9632\u6b62\u672a\u7ecf\u6388\u6743\u7684\u77e5\u8bc6\u84b8\u998f\uff0c\u5b9e\u73b0\u53cd\u84b8\u998f\u548cAPI\u6c34\u5370\u4e24\u79cd\u76ee\u6807\u3002", "motivation": "\u77e5\u8bc6\u84b8\u998f\u88ab\u5e7f\u6cdb\u7528\u4e8e\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u8fc1\u79fb\u5230\u66f4\u5c0f\u7684\u5b66\u751f\u6a21\u578b\uff0c\u4f46\u672a\u7ecf\u6388\u6743\u7684\u77e5\u8bc6\u84b8\u998f\u4e0d\u516c\u5e73\u5730\u5229\u7528\u4e86\u524d\u6cbf\u6a21\u578b\u5f00\u53d1\u7684\u5927\u91cf\u6295\u5165\u548c\u6210\u672c\uff0c\u56e0\u6b64\u9700\u8981\u9632\u6b62\u8fd9\u79cd\u672a\u7ecf\u6388\u6743\u7684\u4f7f\u7528\u3002", "method": "\u5f15\u5165\u591a\u79cd\u52a8\u6001\u91cd\u5199\u6559\u5e08\u6a21\u578b\u63a8\u7406\u8f93\u51fa\u7684\u65b9\u6cd5\uff1a\u5305\u62ec\u4e24\u79cd\u5229\u7528LLM\u91cd\u5199\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5176\u4ed6\u57fa\u4e8e\u68af\u5ea6\u7684\u6280\u672f\u3002\u8fd9\u4e9b\u65b9\u6cd5\u5728\u4fdd\u6301\u7b54\u6848\u6b63\u786e\u6027\u548c\u8bed\u4e49\u8fde\u8d2f\u6027\u7684\u540c\u65f6\u4fee\u6539\u63a8\u7406\u8f68\u8ff9\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7b80\u5355\u7684\u57fa\u4e8e\u6307\u4ee4\u7684\u91cd\u5199\u65b9\u6cd5\u80fd\u5b9e\u73b0\u5f3a\u5927\u7684\u53cd\u84b8\u998f\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u6559\u5e08\u6a21\u578b\u6027\u80fd\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u8fd8\u80fd\u5b9e\u73b0\u9ad8\u5ea6\u53ef\u9760\u7684\u6c34\u5370\u68c0\u6d4b\uff0c\u51e0\u4e4e\u6ca1\u6709\u8bef\u62a5\u3002", "conclusion": "\u901a\u8fc7\u91cd\u5199\u6559\u5e08\u6a21\u578b\u7684\u63a8\u7406\u8f93\u51fa\u53ef\u4ee5\u6709\u6548\u9632\u6b62\u672a\u7ecf\u6388\u6743\u7684\u77e5\u8bc6\u84b8\u998f\uff0c\u65e2\u80fd\u5b9e\u73b0\u53cd\u84b8\u998f\u6548\u679c\uff0c\u53c8\u80fd\u5d4c\u5165\u53ef\u9a8c\u8bc1\u7684\u6c34\u5370\uff0c\u4e3a\u4fdd\u62a4\u6a21\u578b\u77e5\u8bc6\u4ea7\u6743\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2602.15794", "categories": ["cs.DC", "cs.ET", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.15794", "abs": "https://arxiv.org/abs/2602.15794", "authors": ["Boris Sedlak", "V\u00edctor Casamayor Pujol", "Ildefons Magrans de Abril", "Praveen Kumar Donta", "Adel N. Toosi", "Schahram Dustdar"], "title": "Service Orchestration in the Computing Continuum: Structural Challenges and Vision", "comment": null, "summary": "The Computing Continuum (CC) integrates different layers of processing infrastructure, from Edge to Cloud, to optimize service quality through ubiquitous and reliable computation. Compared to central architectures, however, heterogeneous and dynamic infrastructure increases the complexity for service orchestration. To guide research, this article first summarizes structural problems of the CC, and then, envisions an ideal solution for autonomous service orchestration across the CC. As one instantiation, we show how Active Inference, a concept from neuroscience, can support self-organizing services in continuously interpreting their environment to optimize service quality. Still, we conclude that no existing solution achieves our vision, but that research on service orchestration faces several structural challenges. Most notably: provide standardized simulation and evaluation environments for comparing the performance of orchestration mechanisms. Together, the challenges outline a research roadmap toward resilient and scalable service orchestration in the CC.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u8ba1\u7b97\u8fde\u7eed\u4f53\uff08CC\uff09\u4e2d\u670d\u52a1\u7f16\u6392\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u81ea\u4e3b\u670d\u52a1\u7f16\u6392\u7684\u7406\u60f3\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u6307\u51fa\u5f53\u524d\u7814\u7a76\u9762\u4e34\u7684\u7ed3\u6784\u6027\u6311\u6218\uff0c\u7279\u522b\u662f\u9700\u8981\u6807\u51c6\u5316\u7684\u4eff\u771f\u548c\u8bc4\u4f30\u73af\u5883\u3002", "motivation": "\u8ba1\u7b97\u8fde\u7eed\u4f53\u6574\u5408\u4e86\u4ece\u8fb9\u7f18\u5230\u4e91\u7684\u4e0d\u540c\u5904\u7406\u5c42\uff0c\u4ee5\u4f18\u5316\u670d\u52a1\u8d28\u91cf\uff0c\u4f46\u5f02\u6784\u548c\u52a8\u6001\u7684\u57fa\u7840\u8bbe\u65bd\u589e\u52a0\u4e86\u670d\u52a1\u7f16\u6392\u7684\u590d\u6742\u6027\u3002\u9700\u8981\u7814\u7a76\u81ea\u4e3b\u670d\u52a1\u7f16\u6392\u89e3\u51b3\u65b9\u6848\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u9996\u5148\u603b\u7ed3\u8ba1\u7b97\u8fde\u7eed\u4f53\u7684\u7ed3\u6784\u6027\u95ee\u9898\uff0c\u7136\u540e\u8bbe\u60f3\u81ea\u4e3b\u670d\u52a1\u7f16\u6392\u7684\u7406\u60f3\u89e3\u51b3\u65b9\u6848\u3002\u4ee5\u4e3b\u52a8\u63a8\u7406\uff08\u6e90\u81ea\u795e\u7ecf\u79d1\u5b66\u7684\u6982\u5ff5\uff09\u4e3a\u4f8b\uff0c\u5c55\u793a\u5176\u5982\u4f55\u652f\u6301\u81ea\u7ec4\u7ec7\u670d\u52a1\u6301\u7eed\u89e3\u91ca\u73af\u5883\u4ee5\u4f18\u5316\u670d\u52a1\u8d28\u91cf\u3002", "result": "\u76ee\u524d\u6ca1\u6709\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u80fd\u591f\u5b8c\u5168\u5b9e\u73b0\u4f5c\u8005\u7684\u613f\u666f\uff0c\u670d\u52a1\u7f16\u6392\u7814\u7a76\u9762\u4e34\u591a\u4e2a\u7ed3\u6784\u6027\u6311\u6218\uff0c\u7279\u522b\u662f\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u4eff\u771f\u548c\u8bc4\u4f30\u73af\u5883\u6765\u6bd4\u8f83\u4e0d\u540c\u7f16\u6392\u673a\u5236\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u6311\u6218\u4e3a\u8ba1\u7b97\u8fde\u7eed\u4f53\u4e2d\u5f39\u6027\u548c\u53ef\u6269\u5c55\u670d\u52a1\u7f16\u6392\u7684\u7814\u7a76\u8def\u7ebf\u56fe\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5f3a\u8c03\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u73af\u5883\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u63a8\u52a8\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.15158", "categories": ["cs.AI", "cs.IR", "math.LO"], "pdf": "https://arxiv.org/pdf/2602.15158", "abs": "https://arxiv.org/abs/2602.15158", "authors": ["Gabriel Rocha"], "title": "da Costa and Tarski meet Goguen and Carnap: a novel approach for ontological heterogeneity based on consequence systems", "comment": "22 pages, 5 figures, 1 table", "summary": "This paper presents a novel approach for ontological heterogeneity that draws heavily from Carnapian-Goguenism, as presented by Kutz, Mossakowski and L\u00fccke (2010). The approach is provisionally designated da Costian-Tarskianism, named after da Costa's Principle of Tolerance in Mathematics and after Alfred Tarski's work on the concept of a consequence operator. The approach is based on the machinery of consequence systems, as developed by Carnielli et al. (2008) and Citkin and Muravitsky (2022), and it introduces the idea of an extended consequence system, which is a consequence system extended with ontological axioms. The paper also defines the concept of an extended development graph, which is a graph structure that allows ontologies to be related via morphisms of extended consequence systems, and additionally via other operations such as fibring and splitting. Finally, we discuss the implications of this approach for the field of applied ontology and suggest directions for future research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCarnapian-Goguenism\u7684\u672c\u4f53\u5f02\u8d28\u6027\u65b0\u65b9\u6cd5\uff0c\u547d\u540d\u4e3ada Costian-Tarskianism\uff0c\u4f7f\u7528\u6269\u5c55\u540e\u679c\u7cfb\u7edf\u548c\u6269\u5c55\u53d1\u5c55\u56fe\u6765\u5173\u8054\u672c\u4f53\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u672c\u4f53\u8bba\u4e2d\u7684\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u4f5c\u8005\u501f\u9274\u4e86Kutz\u3001Mossakowski\u548cL\u00fccke\u63d0\u51fa\u7684Carnapian-Goguenism\u601d\u60f3\uff0c\u65e8\u5728\u5efa\u7acb\u4e00\u79cd\u66f4\u7075\u6d3b\u7684\u672c\u4f53\u5173\u8054\u6846\u67b6\u3002", "method": "\u57fa\u4e8eda Costa\u7684\u6570\u5b66\u5bb9\u5fcd\u539f\u5219\u548cTarski\u7684\u540e\u679c\u7b97\u5b50\u6982\u5ff5\uff0c\u4f7f\u7528Carnielli\u7b49\u4eba\u53d1\u5c55\u7684\u540e\u679c\u7cfb\u7edf\u673a\u5236\uff0c\u5f15\u5165\u6269\u5c55\u540e\u679c\u7cfb\u7edf\uff08\u5305\u542b\u672c\u4f53\u516c\u7406\uff09\u548c\u6269\u5c55\u53d1\u5c55\u56fe\uff08\u901a\u8fc7\u6269\u5c55\u540e\u679c\u7cfb\u7edf\u7684\u6001\u5c04\u4ee5\u53ca\u7ea4\u7ef4\u5316\u548c\u5206\u88c2\u7b49\u64cd\u4f5c\u5173\u8054\u672c\u4f53\uff09\u3002", "result": "\u63d0\u51fa\u4e86da Costian-Tarskianism\u65b9\u6cd5\uff0c\u5b9a\u4e49\u4e86\u6269\u5c55\u540e\u679c\u7cfb\u7edf\u548c\u6269\u5c55\u53d1\u5c55\u56fe\u7684\u6982\u5ff5\uff0c\u4e3a\u5904\u7406\u672c\u4f53\u5f02\u8d28\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5e94\u7528\u672c\u4f53\u8bba\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u5de5\u5177\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5305\u62ec\u8fdb\u4e00\u6b65\u63a2\u7d22\u6269\u5c55\u53d1\u5c55\u56fe\u7684\u5e94\u7528\u548c\u672c\u4f53\u96c6\u6210\u65b9\u6cd5\u3002"}}
{"id": "2602.15323", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15323", "abs": "https://arxiv.org/abs/2602.15323", "authors": ["Huijia Lin", "Kameron Shahabi", "Min Jae Song"], "title": "Unforgeable Watermarks for Language Models via Robust Signatures", "comment": "60 pages, 7 figures", "summary": "Language models now routinely produce text that is difficult to distinguish from human writing, raising the need for robust tools to verify content provenance. Watermarking has emerged as a promising countermeasure, with existing work largely focused on model quality preservation and robust detection. However, current schemes provide limited protection against false attribution. We strengthen the notion of soundness by introducing two novel guarantees: unforgeability and recoverability. Unforgeability prevents adversaries from crafting false positives, texts that are far from any output from the watermarked model but are nonetheless flagged as watermarked. Recoverability provides an additional layer of protection: whenever a watermark is detected, the detector identifies the source text from which the flagged content was derived. Together, these properties strengthen content ownership by linking content exclusively to its generating model, enabling secure attribution and fine-grained traceability. We construct the first undetectable watermarking scheme that is robust, unforgeable, and recoverable with respect to substitutions (i.e., perturbations in Hamming metric). The key technical ingredient is a new cryptographic primitive called robust (or recoverable) digital signatures, which allow verification of messages that are close to signed ones, while preventing forgery of messages that are far from all previously signed messages. We show that any standard digital signature scheme can be boosted to a robust one using property-preserving hash functions (Boyle, LaVigne, and Vaikuntanathan, ITCS 2019).", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u4e0d\u53ef\u4f2a\u9020\u6027\u548c\u53ef\u6062\u590d\u6027\u7684\u65b0\u578b\u6c34\u5370\u65b9\u6848\uff0c\u901a\u8fc7\u9c81\u68d2\u6570\u5b57\u7b7e\u540d\u6280\u672f\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u5185\u5bb9\u6eaf\u6e90\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\u8d8a\u6765\u8d8a\u96be\u4ee5\u4e0e\u4eba\u7c7b\u5199\u4f5c\u533a\u5206\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u7684\u5de5\u5177\u6765\u9a8c\u8bc1\u5185\u5bb9\u6765\u6e90\u3002\u73b0\u6709\u6c34\u5370\u65b9\u6848\u5728\u9632\u6b62\u9519\u8bef\u5f52\u5c5e\u65b9\u9762\u4fdd\u62a4\u6709\u9650\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u5b89\u5168\u4fdd\u969c\u3002", "method": "\u5f15\u5165\u4e24\u79cd\u65b0\u4fdd\u8bc1\uff1a\u4e0d\u53ef\u4f2a\u9020\u6027\uff08\u9632\u6b62\u4f2a\u9020\u8bef\u62a5\uff09\u548c\u53ef\u6062\u590d\u6027\uff08\u68c0\u6d4b\u65f6\u8bc6\u522b\u6e90\u6587\u672c\uff09\u3002\u4f7f\u7528\u9c81\u68d2\u6570\u5b57\u7b7e\u540d\u4f5c\u4e3a\u5173\u952e\u6280\u672f\uff0c\u901a\u8fc7\u5c5e\u6027\u4fdd\u6301\u54c8\u5e0c\u51fd\u6570\u5c06\u6807\u51c6\u6570\u5b57\u7b7e\u540d\u65b9\u6848\u63d0\u5347\u4e3a\u9c81\u68d2\u7248\u672c\u3002", "result": "\u6784\u5efa\u4e86\u7b2c\u4e00\u4e2a\u5728\u66ff\u6362\u6270\u52a8\u4e0b\u5177\u6709\u9c81\u68d2\u6027\u3001\u4e0d\u53ef\u4f2a\u9020\u6027\u548c\u53ef\u6062\u590d\u6027\u7684\u4e0d\u53ef\u68c0\u6d4b\u6c34\u5370\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u5f52\u5c5e\u548c\u7ec6\u7c92\u5ea6\u53ef\u8ffd\u6eaf\u6027\u3002", "conclusion": "\u901a\u8fc7\u4e0d\u53ef\u4f2a\u9020\u6027\u548c\u53ef\u6062\u590d\u6027\u5f3a\u5316\u4e86\u6c34\u5370\u7684\u53ef\u9760\u6027\uff0c\u5c06\u5185\u5bb9\u4e0e\u5176\u751f\u6210\u6a21\u578b\u552f\u4e00\u94fe\u63a5\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5185\u5bb9\u6240\u6709\u6743\u4fdd\u62a4\u673a\u5236\u3002"}}
{"id": "2602.15173", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15173", "abs": "https://arxiv.org/abs/2602.15173", "authors": ["Luise Ge", "Yongyan Zhang", "Yevgeniy Vorobeychik"], "title": "Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs", "comment": null, "summary": "The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices along two dimensions: (1) prospect representation (explicit vs. experience based) and (2) decision rationale (explanation). Our study, which involves 20 frontier and open LLMs, is complemented by a matched human subjects experiment, which provides one reference point, while an expected payoff maximizing rational agent model provides another. We find that LLMs cluster into two categories: reasoning models (RMs) and conversational models (CMs). RMs tend towards rational behavior, are insensitive to the order of prospects, gain/loss framing, and explanations, and behave similarly whether prospects are explicit or presented via experience history. CMs are significantly less rational, slightly more human-like, sensitive to prospect ordering, framing, and explanation, and exhibit a large description-history gap. Paired comparisons of open LLMs suggest that a key factor differentiating RMs and CMs is training for mathematical reasoning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e8620\u4e2a\u524d\u6cbf\u548c\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u98ce\u9669\u51b3\u7b56\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0LLM\u53ef\u5206\u4e3a\u63a8\u7406\u6a21\u578b\u548c\u5bf9\u8bdd\u6a21\u578b\u4e24\u7c7b\uff0c\u524d\u8005\u66f4\u7406\u6027\uff0c\u540e\u8005\u66f4\u63a5\u8fd1\u4eba\u7c7b\u4f46\u7406\u6027\u7a0b\u5ea6\u8f83\u4f4e\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u6216\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u6b63\u5728\u5feb\u901f\u6539\u53d8\u6570\u5b57\u751f\u6001\u7cfb\u7edf\uff0c\u4f46\u5bf9\u5176\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u51b3\u7b56\u673a\u5236\u7406\u89e3\u4ecd\u7136\u6709\u9650\u3002\u7814\u7a76\u65e8\u5728\u6bd4\u8f83LLM\u5728\u98ce\u9669\u9009\u62e9\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u7814\u7a76\u4ece\u4e24\u4e2a\u7ef4\u5ea6\u6bd4\u8f83LLM\u7684\u98ce\u9669\u51b3\u7b56\uff1a(1)\u524d\u666f\u8868\u793a\u65b9\u5f0f\uff08\u663e\u5f0fvs\u57fa\u4e8e\u7ecf\u9a8c\uff09\u548c(2)\u51b3\u7b56\u7406\u7531\uff08\u89e3\u91ca\u8bf4\u660e\uff09\u3002\u6d89\u53ca20\u4e2a\u524d\u6cbf\u548c\u5f00\u6e90LLM\uff0c\u5e76\u8f85\u4ee5\u5339\u914d\u7684\u4eba\u7c7b\u88ab\u8bd5\u5b9e\u9a8c\u4f5c\u4e3a\u53c2\u8003\u70b9\uff0c\u540c\u65f6\u4ee5\u671f\u671b\u6536\u76ca\u6700\u5927\u5316\u7684\u7406\u6027\u667a\u80fd\u4f53\u6a21\u578b\u4f5c\u4e3a\u53e6\u4e00\u4e2a\u53c2\u8003\u3002", "result": "\u53d1\u73b0LLM\u53ef\u5206\u4e3a\u4e24\u7c7b\uff1a\u63a8\u7406\u6a21\u578b\uff08RMs\uff09\u503e\u5411\u4e8e\u7406\u6027\u884c\u4e3a\uff0c\u5bf9\u524d\u666f\u987a\u5e8f\u3001\u5f97\u5931\u6846\u67b6\u548c\u89e3\u91ca\u4e0d\u654f\u611f\uff0c\u5728\u663e\u5f0f\u6216\u7ecf\u9a8c\u5386\u53f2\u5448\u73b0\u524d\u666f\u65f6\u8868\u73b0\u76f8\u4f3c\uff1b\u5bf9\u8bdd\u6a21\u578b\uff08CMs\uff09\u7406\u6027\u7a0b\u5ea6\u663e\u8457\u8f83\u4f4e\uff0c\u66f4\u63a5\u8fd1\u4eba\u7c7b\uff0c\u5bf9\u524d\u666f\u987a\u5e8f\u3001\u6846\u67b6\u548c\u89e3\u91ca\u654f\u611f\uff0c\u4e14\u5b58\u5728\u8f83\u5927\u7684\u63cf\u8ff0-\u5386\u53f2\u5dee\u8ddd\u3002\u5f00\u6e90LLM\u7684\u914d\u5bf9\u6bd4\u8f83\u8868\u660e\uff0c\u533a\u5206RMs\u548cCMs\u7684\u5173\u952e\u56e0\u7d20\u662f\u6570\u5b66\u63a8\u7406\u8bad\u7ec3\u3002", "conclusion": "LLM\u5728\u98ce\u9669\u51b3\u7b56\u4e2d\u5b58\u5728\u660e\u663e\u5206\u5316\uff0c\u63a8\u7406\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u7406\u6027\u7279\u5f81\uff0c\u800c\u5bf9\u8bdd\u6a21\u578b\u66f4\u63a5\u8fd1\u4eba\u7c7b\u51b3\u7b56\u6a21\u5f0f\u4f46\u7406\u6027\u7a0b\u5ea6\u4e0d\u8db3\u3002\u6570\u5b66\u63a8\u7406\u8bad\u7ec3\u662f\u533a\u5206\u4e24\u7c7b\u6a21\u578b\u7684\u5173\u952e\u56e0\u7d20\uff0c\u8fd9\u5bf9LLM\u5728\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.15376", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15376", "abs": "https://arxiv.org/abs/2602.15376", "authors": ["Udbhav Prasad", "Aniesh Chawla"], "title": "A Unified Evaluation of Learning-Based Similarity Techniques for Malware Detection", "comment": null, "summary": "Cryptographic digests (e.g., MD5, SHA-256) are designed to provide exact identity. Any single-bit change in the input produces a completely different hash, which is ideal for integrity verification but limits their usefulness in many real-world tasks like threat hunting, malware analysis and digital forensics, where adversaries routinely introduce minor transformations. Similarity-based techniques address this limitation by enabling approximate matching, allowing related byte sequences to produce measurably similar fingerprints. Modern enterprises manage tens of thousands of endpoints with billions of files, making the effectiveness and scalability of the proposed techniques more important than ever in security applications. Security researchers have proposed a range of approaches, including similarity digests and locality-sensitive hashes (e.g., ssdeep, sdhash, TLSH), as well as more recent machine-learning-based methods that generate embeddings from file features. However, these techniques have largely been evaluated in isolation, using disparate datasets and evaluation criteria. This paper presents a systematic comparison of learning-based classification and similarity methods using large, publicly available datasets. We evaluate each method under a unified experimental framework with industry-accepted metrics. To our knowledge, this is the first reproducible study to benchmark these diverse learning-based similarity techniques side by side for real-world security workloads. Our results show that no single approach performs well across all dimensions; instead, each exhibits distinct trade-offs, indicating that effective malware analysis and threat-hunting platforms must combine complementary classification and similarity techniques rather than rely on a single method.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u57fa\u4e8e\u5b66\u4e60\u7684\u5206\u7c7b\u548c\u76f8\u4f3c\u6027\u65b9\u6cd5\u5728\u5b89\u5168\u5e94\u7528\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6ca1\u6709\u5355\u4e00\u65b9\u6cd5\u5728\u6240\u6709\u7ef4\u5ea6\u90fd\u8868\u73b0\u826f\u597d\uff0c\u9700\u8981\u7ed3\u5408\u4e92\u8865\u6280\u672f\u3002", "motivation": "\u4f20\u7edf\u52a0\u5bc6\u6458\u8981\uff08\u5982MD5\u3001SHA-256\uff09\u867d\u7136\u80fd\u63d0\u4f9b\u7cbe\u786e\u8eab\u4efd\u9a8c\u8bc1\uff0c\u4f46\u5728\u5a01\u80c1\u72e9\u730e\u3001\u6076\u610f\u8f6f\u4ef6\u5206\u6790\u548c\u6570\u5b57\u53d6\u8bc1\u7b49\u5b9e\u9645\u5b89\u5168\u4efb\u52a1\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u56e0\u4e3a\u653b\u51fb\u8005\u7ecf\u5e38\u8fdb\u884c\u5fae\u5c0f\u53d8\u6362\u3002\u73b0\u6709\u7684\u76f8\u4f3c\u6027\u6280\u672f\uff08\u5982ssdeep\u3001sdhash\u3001TLSH\uff09\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u6bd4\u8f83\u8bc4\u4f30\u3002", "method": "\u91c7\u7528\u7edf\u4e00\u7684\u5b9e\u9a8c\u6846\u67b6\u548c\u884c\u4e1a\u63a5\u53d7\u5ea6\u6307\u6807\uff0c\u5bf9\u57fa\u4e8e\u5b66\u4e60\u7684\u5206\u7c7b\u548c\u76f8\u4f3c\u6027\u65b9\u6cd5\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\u3002\u4f7f\u7528\u5927\u578b\u516c\u5f00\u6570\u636e\u96c6\uff0c\u9996\u6b21\u5bf9\u8fd9\u4e9b\u4e0d\u540c\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u76f8\u4f3c\u6027\u6280\u672f\u8fdb\u884c\u53ef\u91cd\u590d\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6ca1\u6709\u5355\u4e00\u65b9\u6cd5\u5728\u6240\u6709\u7ef4\u5ea6\u90fd\u8868\u73b0\u826f\u597d\uff0c\u6bcf\u79cd\u65b9\u6cd5\u90fd\u5c55\u73b0\u51fa\u4e0d\u540c\u7684\u6743\u8861\u3002\u8fd9\u8868\u660e\u6709\u6548\u7684\u6076\u610f\u8f6f\u4ef6\u5206\u6790\u548c\u5a01\u80c1\u72e9\u730e\u5e73\u53f0\u5fc5\u987b\u7ed3\u5408\u4e92\u8865\u7684\u5206\u7c7b\u548c\u76f8\u4f3c\u6027\u6280\u672f\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u5355\u4e00\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u5b66\u4e60\u7684\u76f8\u4f3c\u6027\u6280\u672f\u5728\u5b89\u5168\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u4f46\u9700\u8981\u591a\u79cd\u65b9\u6cd5\u7684\u7ec4\u5408\u4f7f\u7528\u3002\u8be5\u7814\u7a76\u4e3a\u5b89\u5168\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u9996\u4e2a\u53ef\u91cd\u590d\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5e2e\u52a9\u9009\u62e9\u5408\u9002\u7684\u6280\u672f\u7ec4\u5408\u3002"}}
{"id": "2602.15248", "categories": ["cs.AI", "math.OC", "q-fin.MF"], "pdf": "https://arxiv.org/pdf/2602.15248", "abs": "https://arxiv.org/abs/2602.15248", "authors": ["Pavel Koptev", "Vishnu Kumar", "Konstantin Malkov", "George Shapiro", "Yury Vikhanov"], "title": "Predicting Invoice Dilution in Supply Chain Finance with Leakage Free Two Stage XGBoost, KAN (Kolmogorov Arnold Networks), and Ensemble Models", "comment": null, "summary": "Invoice or payment dilution is the gap between the approved invoice amount and the actual collection is a significant source of non credit risk and margin loss in supply chain finance. Traditionally, this risk is managed through the buyer's irrevocable payment undertaking (IPU), which commits to full payment without deductions. However, IPUs can hinder supply chain finance adoption, particularly among sub-invested grade buyers. A newer, data-driven methods use real-time dynamic credit limits, projecting dilution for each buyer-supplier pair in real-time. This paper introduces an AI, machine learning framework and evaluates how that can supplement a deterministic algorithm to predict invoice dilution using extensive production dataset across nine key transaction fields.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAI\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u8865\u5145\u786e\u5b9a\u6027\u7b97\u6cd5\u9884\u6d4b\u53d1\u7968\u7a00\u91ca\u98ce\u9669\uff0c\u4f7f\u7528\u5b9e\u65f6\u52a8\u6001\u4fe1\u7528\u9650\u989d\u66ff\u4ee3\u4f20\u7edf\u4e0d\u53ef\u64a4\u9500\u652f\u4ed8\u627f\u8bfa", "motivation": "\u53d1\u7968\u6216\u652f\u4ed8\u7a00\u91ca\uff08\u6279\u51c6\u53d1\u7968\u91d1\u989d\u4e0e\u5b9e\u9645\u6536\u6b3e\u4e4b\u95f4\u7684\u5dee\u8ddd\uff09\u662f\u4f9b\u5e94\u94fe\u91d1\u878d\u4e2d\u975e\u4fe1\u7528\u98ce\u9669\u548c\u5229\u6da6\u635f\u5931\u7684\u91cd\u8981\u6765\u6e90\u3002\u4f20\u7edf\u4e0a\u901a\u8fc7\u4e70\u65b9\u4e0d\u53ef\u64a4\u9500\u652f\u4ed8\u627f\u8bfa\u7ba1\u7406\u6b64\u98ce\u9669\uff0c\u4f46\u8fd9\u4f1a\u963b\u788d\u4f9b\u5e94\u94fe\u91d1\u878d\u7684\u91c7\u7528\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u6b21\u7ea7\u6295\u8d44\u7ea7\u4e70\u65b9\u3002\u9700\u8981\u66f4\u7075\u6d3b\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3002", "method": "\u63d0\u51faAI\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u8865\u5145\u786e\u5b9a\u6027\u7b97\u6cd5\u6765\u9884\u6d4b\u53d1\u7968\u7a00\u91ca\u3002\u4f7f\u7528\u5b9e\u65f6\u52a8\u6001\u4fe1\u7528\u9650\u989d\u65b9\u6cd5\uff0c\u4e3a\u6bcf\u4e2a\u4e70\u65b9-\u4f9b\u5e94\u5546\u5bf9\u5b9e\u65f6\u9884\u6d4b\u7a00\u91ca\u98ce\u9669\u3002\u57fa\u4e8e\u5305\u542b\u4e5d\u4e2a\u5173\u952e\u4ea4\u6613\u5b57\u6bb5\u7684\u5e7f\u6cdb\u751f\u4ea7\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bba\u6587\u8bc4\u4f30\u4e86AI\u673a\u5668\u5b66\u4e60\u6846\u67b6\u5982\u4f55\u8865\u5145\u786e\u5b9a\u6027\u7b97\u6cd5\u6765\u9884\u6d4b\u53d1\u7968\u7a00\u91ca\u98ce\u9669\u3002\u4f7f\u7528\u5b9e\u65f6\u52a8\u6001\u4fe1\u7528\u9650\u989d\u65b9\u6cd5\u53ef\u4ee5\u66f4\u7075\u6d3b\u5730\u7ba1\u7406\u7a00\u91ca\u98ce\u9669\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u4f20\u7edfIPU\u65b9\u6cd5\u96be\u4ee5\u8986\u76d6\u7684\u6b21\u7ea7\u6295\u8d44\u7ea7\u4e70\u65b9\u3002", "conclusion": "AI\u673a\u5668\u5b66\u4e60\u6846\u67b6\u53ef\u4ee5\u6709\u6548\u8865\u5145\u4f20\u7edf\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u4e3a\u4f9b\u5e94\u94fe\u91d1\u878d\u4e2d\u7684\u53d1\u7968\u7a00\u91ca\u98ce\u9669\u7ba1\u7406\u63d0\u4f9b\u66f4\u7075\u6d3b\u3001\u6570\u636e\u9a71\u52a8\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u6269\u5927\u4f9b\u5e94\u94fe\u91d1\u878d\u7684\u91c7\u7528\u8303\u56f4\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u6b21\u7ea7\u6295\u8d44\u7ea7\u4e70\u65b9\u3002"}}
{"id": "2602.15395", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.15395", "abs": "https://arxiv.org/abs/2602.15395", "authors": ["Qin Wang", "Ruiqiang Li", "Guangsheng Yu", "Vincent Gramoli", "Shiping Chen"], "title": "MEV in Binance Builder", "comment": null, "summary": "We study the builder-driven MEV arbitrage on BNB Smart Chain (BSC). BSC's Proposer--Builder Separation (PBS) adopts a leaner design: only whitelisted builders can participate, blocks are produced at shorter intervals, and private order flow bypasses the public mempool. These features have long raised community concerns over centralization, which we empirically confirm by tracing arbitrage activity of the two dominant builders from May to November 2025. Within months, 48Club and Blockrazor produced over 96\\% of blocks and captured about 92\\% of MEV profits.\n  We find that profits concentrate in short, low-hop arbitrage routes over wrapped tokens and stablecoins, and that block construction rapidly converges toward monopoly. Beyond concentration alone, our analysis reveals a structural source of inequality: BSC's short block interval and whitelisted PBS collapse the contestable window for MEV competition, amplifying latency advantages and excluding slower builders and searchers. MEV extraction on BSC is not only more centralized than on Ethereum, but also structurally more vulnerable to censorship and weakened fairness.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86BNB\u667a\u80fd\u94fe\u4e0a\u5efa\u8bbe\u8005\u9a71\u52a8\u7684MEV\u5957\u5229\u6d3b\u52a8\uff0c\u53d1\u73b0\u7531\u4e8e\u767d\u540d\u5355PBS\u8bbe\u8ba1\u3001\u77ed\u533a\u5757\u95f4\u9694\u548c\u79c1\u4eba\u8ba2\u5355\u6d41\u7ed5\u8fc7\u516c\u5171\u5185\u5b58\u6c60\uff0c\u5bfc\u81f4MEV\u5229\u6da6\u9ad8\u5ea6\u96c6\u4e2d\u5728\u4e24\u4e2a\u4e3b\u5bfc\u5efa\u8bbe\u8005\u624b\u4e2d\uff0848Club\u548cBlockrazor\uff09\uff0c\u5f62\u6210\u5784\u65ad\u683c\u5c40\u3002", "motivation": "\u7814\u7a76BNB\u667a\u80fd\u94fe\u7684\u63d0\u8bae\u8005-\u5efa\u8bbe\u8005\u5206\u79bb\uff08PBS\uff09\u673a\u5236\uff0c\u8be5\u673a\u5236\u91c7\u7528\u66f4\u7cbe\u7b80\u7684\u8bbe\u8ba1\uff1a\u4ec5\u5141\u8bb8\u767d\u540d\u5355\u5efa\u8bbe\u8005\u53c2\u4e0e\u3001\u533a\u5757\u751f\u4ea7\u95f4\u9694\u66f4\u77ed\u3001\u79c1\u4eba\u8ba2\u5355\u6d41\u7ed5\u8fc7\u516c\u5171\u5185\u5b58\u6c60\u3002\u8fd9\u4e9b\u7279\u6027\u957f\u671f\u5f15\u53d1\u793e\u533a\u5bf9\u4e2d\u5fc3\u5316\u7684\u62c5\u5fe7\uff0c\u9700\u8981\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u8ffd\u8e2a2025\u5e745\u6708\u81f311\u6708\u671f\u95f4\u4e24\u4e2a\u4e3b\u5bfc\u5efa\u8bbe\u8005\uff0848Club\u548cBlockrazor\uff09\u7684\u5957\u5229\u6d3b\u52a8\uff0c\u5206\u6790BNB\u667a\u80fd\u94fe\u4e0a\u7684MEV\u5957\u5229\u6a21\u5f0f\u3001\u5229\u6da6\u5206\u5e03\u548c\u533a\u5757\u5efa\u8bbe\u96c6\u4e2d\u5ea6\u3002", "result": "48Club\u548cBlockrazor\u5728\u51e0\u4e2a\u6708\u5185\u751f\u4ea7\u4e86\u8d85\u8fc796%\u7684\u533a\u5757\uff0c\u6355\u83b7\u4e86\u7ea692%\u7684MEV\u5229\u6da6\u3002\u5229\u6da6\u96c6\u4e2d\u5728\u77ed\u8ddd\u79bb\u3001\u4f4e\u8df3\u6570\u7684\u5957\u5229\u8def\u5f84\uff08\u4e3b\u8981\u6d89\u53ca\u5305\u88c5\u4ee3\u5e01\u548c\u7a33\u5b9a\u5e01\uff09\uff0c\u533a\u5757\u5efa\u8bbe\u8fc5\u901f\u5411\u5784\u65ad\u6536\u655b\u3002\u77ed\u533a\u5757\u95f4\u9694\u548c\u767d\u540d\u5355PBS\u538b\u7f29\u4e86MEV\u7ade\u4e89\u7684\u53ef\u7ade\u4e89\u7a97\u53e3\uff0c\u653e\u5927\u4e86\u5ef6\u8fdf\u4f18\u52bf\uff0c\u6392\u9664\u4e86\u8f83\u6162\u7684\u5efa\u8bbe\u8005\u548c\u641c\u7d22\u8005\u3002", "conclusion": "BNB\u667a\u80fd\u94fe\u4e0a\u7684MEV\u63d0\u53d6\u4e0d\u4ec5\u6bd4\u4ee5\u592a\u574a\u66f4\u52a0\u4e2d\u5fc3\u5316\uff0c\u800c\u4e14\u5728\u7ed3\u6784\u4e0a\u66f4\u5bb9\u6613\u53d7\u5230\u5ba1\u67e5\u548c\u516c\u5e73\u6027\u524a\u5f31\u7684\u5f71\u54cd\u3002\u77ed\u533a\u5757\u95f4\u9694\u548c\u767d\u540d\u5355PBS\u8bbe\u8ba1\u52a0\u5267\u4e86\u4e2d\u5fc3\u5316\u95ee\u9898\uff0c\u9650\u5236\u4e86MEV\u7ade\u4e89\u7684\u516c\u5e73\u6027\u3002"}}
{"id": "2602.15485", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.15485", "abs": "https://arxiv.org/abs/2602.15485", "authors": ["Longfei Chen", "Ji Zhao", "Lanxiao Cui", "Tong Su", "Xingbo Pan", "Ziyang Li", "Yongxing Wu", "Qijiang Cao", "Qiyao Cai", "Jing Zhang", "Yuandong Ni", "Junyao He", "Zeyu Zhang", "Chao Ge", "Xuhuai Lu", "Zeyu Gao", "Yuxin Cui", "Weisen Chen", "Yuxuan Peng", "Shengping Wang", "Qi Li", "Yukai Huang", "Yukun Liu", "Tuo Zhou", "Terry Yue Zhuo", "Junyang Lin", "Chao Zhang"], "title": "SecCodeBench-V2 Technical Report", "comment": null, "summary": "We introduce SecCodeBench-V2, a publicly released benchmark for evaluating Large Language Model (LLM) copilots' capabilities of generating secure code. SecCodeBench-V2 comprises 98 generation and fix scenarios derived from Alibaba Group's industrial productions, where the underlying security issues span 22 common CWE (Common Weakness Enumeration) categories across five programming languages: Java, C, Python, Go, and Node.js. SecCodeBench-V2 adopts a function-level task formulation: each scenario provides a complete project scaffold and requires the model to implement or patch a designated target function under fixed interfaces and dependencies. For each scenario, SecCodeBench-V2 provides executable proof-of-concept (PoC) test cases for both functional validation and security verification. All test cases are authored and double-reviewed by security experts, ensuring high fidelity, broad coverage, and reliable ground truth. Beyond the benchmark itself, we build a unified evaluation pipeline that assesses models primarily via dynamic execution. For most scenarios, we compile and run model-generated artifacts in isolated environments and execute PoC test cases to validate both functional correctness and security properties. For scenarios where security issues cannot be adjudicated with deterministic test cases, we additionally employ an LLM-as-a-judge oracle. To summarize performance across heterogeneous scenarios and difficulty levels, we design a Pass@K-based scoring protocol with principled aggregation over scenarios and severity, enabling holistic and comparable evaluation across models. Overall, SecCodeBench-V2 provides a rigorous and reproducible foundation for assessing the security posture of AI coding assistants, with results and artifacts released at https://alibaba.github.io/sec-code-bench. The benchmark is publicly available at https://github.com/alibaba/sec-code-bench.", "AI": {"tldr": "SecCodeBench-V2\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5b89\u5168\u4ee3\u7801\u80fd\u529b\u7684\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b98\u4e2a\u57fa\u4e8e\u963f\u91cc\u5df4\u5df4\u5de5\u4e1a\u751f\u4ea7\u7684\u573a\u666f\uff0c\u6db5\u76d65\u79cd\u7f16\u7a0b\u8bed\u8a00\u548c22\u4e2aCWE\u5b89\u5168\u6f0f\u6d1e\u7c7b\u522b\u3002", "motivation": "\u968f\u7740AI\u7f16\u7a0b\u52a9\u624b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u8bc4\u4f30\u5176\u751f\u6210\u5b89\u5168\u4ee3\u7801\u7684\u80fd\u529b\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u8986\u76d6\u8303\u56f4\u3001\u771f\u5b9e\u6027\u548c\u8bc4\u4f30\u65b9\u6cd5\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u66f4\u5168\u9762\u3001\u57fa\u4e8e\u5de5\u4e1a\u5b9e\u8df5\u7684\u5b89\u5168\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u6846\u67b6\u3002", "method": "1. \u6784\u5efa\u5305\u542b98\u4e2a\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6e90\u81ea\u963f\u91cc\u5df4\u5df4\u5de5\u4e1a\u751f\u4ea7\uff0c\u6db5\u76d6Java\u3001C\u3001Python\u3001Go\u3001Node.js\u4e94\u79cd\u8bed\u8a00\u548c22\u4e2aCWE\u7c7b\u522b\uff1b2. \u91c7\u7528\u51fd\u6570\u7ea7\u4efb\u52a1\u5f62\u5f0f\uff0c\u63d0\u4f9b\u5b8c\u6574\u9879\u76ee\u811a\u624b\u67b6\uff1b3. \u63d0\u4f9b\u53ef\u6267\u884c\u7684PoC\u6d4b\u8bd5\u7528\u4f8b\u8fdb\u884c\u529f\u80fd\u9a8c\u8bc1\u548c\u5b89\u5168\u9a8c\u8bc1\uff1b4. \u5efa\u7acb\u7edf\u4e00\u8bc4\u4f30\u6d41\u6c34\u7ebf\uff0c\u4e3b\u8981\u901a\u8fc7\u52a8\u6001\u6267\u884c\u8bc4\u4f30\u6a21\u578b\uff1b5. \u4f7f\u7528LLM-as-a-judge\u8f85\u52a9\u8bc4\u4f30\uff1b6. \u8bbe\u8ba1\u57fa\u4e8ePass@K\u7684\u8bc4\u5206\u534f\u8bae\u3002", "result": "SecCodeBench-V2\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e25\u683c\u4e14\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u5b8c\u6574\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\u3001\u8bc4\u4f30\u6d41\u6c34\u7ebf\u548c\u8bc4\u5206\u534f\u8bae\u3002\u6240\u6709\u6d4b\u8bd5\u7528\u4f8b\u7531\u5b89\u5168\u4e13\u5bb6\u7f16\u5199\u548c\u53cc\u91cd\u8bc4\u5ba1\uff0c\u786e\u4fdd\u9ad8\u4fdd\u771f\u5ea6\u3001\u5e7f\u6cdb\u8986\u76d6\u548c\u53ef\u9760\u7684\u771f\u5b9e\u6807\u7b7e\u3002", "conclusion": "SecCodeBench-V2\u4e3a\u8bc4\u4f30AI\u7f16\u7a0b\u52a9\u624b\u7684\u5b89\u5168\u6001\u52bf\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u57fa\u7840\uff0c\u652f\u6301\u8de8\u6a21\u578b\u7684\u5168\u9762\u53ef\u6bd4\u8bc4\u4f30\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u66f4\u5b89\u5168\u7684AI\u8f85\u52a9\u7f16\u7a0b\u5b9e\u8df5\u3002"}}
{"id": "2602.15274", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15274", "abs": "https://arxiv.org/abs/2602.15274", "authors": ["Omid Madani", "J. Brian Burns", "Reza Eghbali", "Thomas L. Dean"], "title": "When Remembering and Planning are Worth it: Navigating under Change", "comment": null, "summary": "We explore how different types and uses of memory can aid spatial navigation in changing uncertain environments. In the simple foraging task we study, every day, our agent has to find its way from its home, through barriers, to food. Moreover, the world is non-stationary: from day to day, the location of the barriers and food may change, and the agent's sensing such as its location information is uncertain and very limited. Any model construction, such as a map, and use, such as planning, needs to be robust against these challenges, and if any learning is to be useful, it needs to be adequately fast. We look at a range of strategies, from simple to sophisticated, with various uses of memory and learning. We find that an architecture that can incorporate multiple strategies is required to handle (sub)tasks of a different nature, in particular for exploration and search, when food location is not known, and for planning a good path to a remembered (likely) food location. An agent that utilizes non-stationary probability learning techniques to keep updating its (episodic) memories and that uses those memories to build maps and plan on the fly (imperfect maps, i.e. noisy and limited to the agent's experience) can be increasingly and substantially more efficient than the simpler (minimal-memory) agents, as the task difficulties such as distance to goal are raised, as long as the uncertainty, from localization and change, is not too large.", "AI": {"tldr": "\u7814\u7a76\u4e0d\u540c\u8bb0\u5fc6\u7c7b\u578b\u548c\u7528\u9014\u5982\u4f55\u5e2e\u52a9\u667a\u80fd\u4f53\u5728\u53d8\u5316\u7684\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u8fdb\u884c\u7a7a\u95f4\u5bfc\u822a\uff0c\u53d1\u73b0\u7ed3\u5408\u591a\u79cd\u7b56\u7565\u7684\u67b6\u6784\u5728\u5904\u7406\u63a2\u7d22\u3001\u641c\u7d22\u548c\u8def\u5f84\u89c4\u5212\u7b49\u4e0d\u540c\u6027\u8d28\u5b50\u4efb\u52a1\u65f6\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u7814\u7a76\u5728\u52a8\u6001\u53d8\u5316\u3001\u611f\u77e5\u53d7\u9650\u7684\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\uff0c\u5982\u4f55\u901a\u8fc7\u8bb0\u5fc6\u548c\u5b66\u4e60\u673a\u5236\u63d0\u9ad8\u7a7a\u95f4\u5bfc\u822a\u6548\u7387\u3002\u73af\u5883\u5177\u6709\u975e\u5e73\u7a33\u6027\uff08\u969c\u788d\u7269\u548c\u98df\u7269\u4f4d\u7f6e\u6bcf\u65e5\u53d8\u5316\uff09\u3001\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\uff08\u4f4d\u7f6e\u4fe1\u606f\u6709\u9650\u4e14\u4e0d\u786e\u5b9a\uff09\u7b49\u6311\u6218\u3002", "method": "\u91c7\u7528\u4ece\u7b80\u5355\u5230\u590d\u6742\u7684\u591a\u79cd\u7b56\u7565\uff0c\u5305\u62ec\u4e0d\u540c\u8bb0\u5fc6\u4f7f\u7528\u548c\u5b66\u4e60\u65b9\u5f0f\u3002\u91cd\u70b9\u7814\u7a76\u80fd\u591f\u6574\u5408\u591a\u79cd\u7b56\u7565\u7684\u67b6\u6784\uff0c\u7279\u522b\u662f\u5229\u7528\u975e\u5e73\u7a33\u6982\u7387\u5b66\u4e60\u6280\u672f\u66f4\u65b0\u60c5\u666f\u8bb0\u5fc6\uff0c\u5e76\u4f7f\u7528\u8fd9\u4e9b\u8bb0\u5fc6\u52a8\u6001\u6784\u5efa\u5730\u56fe\u548c\u89c4\u5212\u8def\u5f84\uff08\u4e0d\u5b8c\u7f8e\u5730\u56fe\uff0c\u57fa\u4e8e\u667a\u80fd\u4f53\u7ecf\u9a8c\u4e14\u5305\u542b\u566a\u58f0\uff09\u3002", "result": "\u5f53\u4efb\u52a1\u96be\u5ea6\uff08\u5982\u76ee\u6807\u8ddd\u79bb\uff09\u589e\u52a0\u65f6\uff0c\u4f7f\u7528\u975e\u5e73\u7a33\u6982\u7387\u5b66\u4e60\u6280\u672f\u66f4\u65b0\u60c5\u666f\u8bb0\u5fc6\u5e76\u52a8\u6001\u6784\u5efa\u5730\u56fe\u89c4\u5212\u7684\u667a\u80fd\u4f53\uff0c\u76f8\u6bd4\u7b80\u5355\uff08\u6700\u5c0f\u8bb0\u5fc6\uff09\u667a\u80fd\u4f53\u6548\u7387\u663e\u8457\u63d0\u9ad8\uff0c\u524d\u63d0\u662f\u5b9a\u4f4d\u548c\u73af\u5883\u53d8\u5316\u5e26\u6765\u7684\u4e0d\u786e\u5b9a\u6027\u4e0d\u8fc7\u5927\u3002", "conclusion": "\u5728\u53d8\u5316\u7684\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u8fdb\u884c\u7a7a\u95f4\u5bfc\u822a\u9700\u8981\u80fd\u591f\u6574\u5408\u591a\u79cd\u7b56\u7565\u7684\u67b6\u6784\uff0c\u7279\u522b\u662f\u7ed3\u5408\u63a2\u7d22/\u641c\u7d22\u548c\u8def\u5f84\u89c4\u5212\u7684\u4e0d\u540c\u9700\u6c42\u3002\u5229\u7528\u975e\u5e73\u7a33\u6982\u7387\u5b66\u4e60\u66f4\u65b0\u8bb0\u5fc6\u5e76\u52a8\u6001\u6784\u5efa\u5730\u56fe\u7684\u65b9\u6cd5\u5728\u9002\u5ea6\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\u80fd\u663e\u8457\u63d0\u9ad8\u5bfc\u822a\u6548\u7387\u3002"}}
{"id": "2602.15614", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.15614", "abs": "https://arxiv.org/abs/2602.15614", "authors": ["Yasmine Hayder", "Adrien Boiret", "C\u00e9dric Eichler", "Benjamin Nguyen"], "title": "Onto-DP: Constructing Neighborhoods for Differential Privacy on Ontological Databases", "comment": null, "summary": "In this paper, we investigate how attackers can discover sensitive information embedded within databases by exploiting inference rules. We demonstrate the inadequacy of naively applied existing state of the art differential privacy (DP) models in safeguarding against such attacks. We introduce ontology aware differential privacy (Onto-DP), a novel extension of differential privacy paradigms built on top of any classical DP model by enriching it with semantic awareness. We show that this extension is a sufficient condition to adequately protect against attackers aware of inference rules.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5dee\u5206\u9690\u79c1\u6269\u5c55\u6a21\u578b\u2014\u2014\u672c\u4f53\u611f\u77e5\u5dee\u5206\u9690\u79c1\uff08Onto-DP\uff09\uff0c\u901a\u8fc7\u589e\u5f3a\u8bed\u4e49\u610f\u8bc6\u6765\u4fdd\u62a4\u6570\u636e\u5e93\u514d\u53d7\u57fa\u4e8e\u63a8\u7406\u89c4\u5219\u7684\u653b\u51fb\u3002", "motivation": "\u73b0\u6709\u5dee\u5206\u9690\u79c1\u6a21\u578b\u5728\u4fdd\u62a4\u6570\u636e\u5e93\u654f\u611f\u4fe1\u606f\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u5229\u7528\u63a8\u7406\u89c4\u5219\u53d1\u73b0\u5d4c\u5165\u5728\u6570\u636e\u5e93\u4e2d\u7684\u654f\u611f\u4fe1\u606f\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u5f3a\u5927\u7684\u4fdd\u62a4\u673a\u5236\u3002", "method": "\u63d0\u51fa\u672c\u4f53\u611f\u77e5\u5dee\u5206\u9690\u79c1\uff08Onto-DP\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u5728\u7ecf\u5178\u5dee\u5206\u9690\u79c1\u6a21\u578b\u57fa\u7840\u4e0a\u6784\u5efa\u7684\u65b0\u578b\u6269\u5c55\uff0c\u901a\u8fc7\u589e\u5f3a\u8bed\u4e49\u610f\u8bc6\u6765\u5bf9\u6297\u77e5\u6653\u63a8\u7406\u89c4\u5219\u7684\u653b\u51fb\u8005\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cOnto-DP\u6269\u5c55\u662f\u5145\u5206\u4fdd\u62a4\u6570\u636e\u5e93\u514d\u53d7\u63a8\u7406\u89c4\u5219\u653b\u51fb\u8005\u4fb5\u5bb3\u7684\u5145\u5206\u6761\u4ef6\uff0c\u800c\u73b0\u6709\u5dee\u5206\u9690\u79c1\u6a21\u578b\u65e0\u6cd5\u63d0\u4f9b\u8db3\u591f\u4fdd\u62a4\u3002", "conclusion": "\u9700\u8981\u5f15\u5165\u8bed\u4e49\u611f\u77e5\u7684\u5dee\u5206\u9690\u79c1\u6269\u5c55\u6765\u6709\u6548\u9632\u5fa1\u57fa\u4e8e\u63a8\u7406\u89c4\u5219\u7684\u653b\u51fb\uff0cOnto-DP\u4e3a\u6b64\u7c7b\u653b\u51fb\u63d0\u4f9b\u4e86\u5145\u5206\u4fdd\u62a4\u3002"}}
{"id": "2602.15671", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.15671", "abs": "https://arxiv.org/abs/2602.15671", "authors": ["Haodong Zhao", "Jinming Hu", "Gongshen Liu"], "title": "Revisiting Backdoor Threat in Federated Instruction Tuning from a Signal Aggregation Perspective", "comment": "Accepted by ICASSP 2026", "summary": "Federated learning security research has predominantly focused on backdoor threats from a minority of malicious clients that intentionally corrupt model updates. This paper challenges this paradigm by investigating a more pervasive and insidious threat: \\textit{backdoor vulnerabilities from low-concentration poisoned data distributed across the datasets of benign clients.} This scenario is increasingly common in federated instruction tuning for language models, which often rely on unverified third-party and crowd-sourced data. We analyze two forms of backdoor data through real cases: 1) \\textit{natural trigger (inherent features as implicit triggers)}; 2) \\textit{adversary-injected trigger}. To analyze this threat, we model the backdoor implantation process from signal aggregation, proposing the Backdoor Signal-to-Noise Ratio to quantify the dynamics of the distributed backdoor signal. Extensive experiments reveal the severity of this threat: With just less than 10\\% of training data poisoned and distributed across clients, the attack success rate exceeds 85\\%, while the primary task performance remains largely intact. Critically, we demonstrate that state-of-the-art backdoor defenses, designed for attacks from malicious clients, are fundamentally ineffective against this threat. Our findings highlight an urgent need for new defense mechanisms tailored to the realities of modern, decentralized data ecosystems.", "AI": {"tldr": "\u8bba\u6587\u6311\u6218\u8054\u90a6\u5b66\u4e60\u5b89\u5168\u7814\u7a76\u4f20\u7edf\u8303\u5f0f\uff0c\u63ed\u793a\u826f\u6027\u5ba2\u6237\u7aef\u6570\u636e\u96c6\u4e2d\u5206\u5e03\u7684\u4f4e\u6d53\u5ea6\u4e2d\u6bd2\u6570\u636e\u9020\u6210\u7684\u540e\u95e8\u5a01\u80c1\uff0c\u8fd9\u79cd\u5a01\u80c1\u6bd4\u5c11\u6570\u6076\u610f\u5ba2\u6237\u7aef\u653b\u51fb\u66f4\u666e\u904d\u4e14\u9690\u853d\u3002", "motivation": "\u5f53\u524d\u8054\u90a6\u5b66\u4e60\u5b89\u5168\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5c11\u6570\u6076\u610f\u5ba2\u6237\u7aef\u6545\u610f\u7834\u574f\u6a21\u578b\u66f4\u65b0\u7684\u540e\u95e8\u5a01\u80c1\uff0c\u4f46\u5ffd\u89c6\u4e86\u66f4\u666e\u904d\u4e14\u9690\u853d\u7684\u5a01\u80c1\uff1a\u826f\u6027\u5ba2\u6237\u7aef\u6570\u636e\u96c6\u4e2d\u5206\u5e03\u7684\u4f4e\u6d53\u5ea6\u4e2d\u6bd2\u6570\u636e\u9020\u6210\u7684\u540e\u95e8\u6f0f\u6d1e\u3002\u8fd9\u79cd\u573a\u666f\u5728\u4f9d\u8d56\u672a\u7ecf\u9a8c\u8bc1\u7684\u7b2c\u4e09\u65b9\u548c\u4f17\u5305\u6570\u636e\u7684\u8054\u90a6\u6307\u4ee4\u8c03\u4f18\u8bed\u8a00\u6a21\u578b\u4e2d\u8d8a\u6765\u8d8a\u5e38\u89c1\u3002", "method": "\u901a\u8fc7\u771f\u5b9e\u6848\u4f8b\u5206\u6790\u4e24\u79cd\u540e\u95e8\u6570\u636e\u5f62\u5f0f\uff1a1\uff09\u81ea\u7136\u89e6\u53d1\u5668\uff08\u56fa\u6709\u7279\u5f81\u4f5c\u4e3a\u9690\u5f0f\u89e6\u53d1\u5668\uff09\uff1b2\uff09\u653b\u51fb\u8005\u6ce8\u5165\u7684\u89e6\u53d1\u5668\u3002\u4ece\u4fe1\u53f7\u805a\u5408\u89d2\u5ea6\u5efa\u6a21\u540e\u95e8\u690d\u5165\u8fc7\u7a0b\uff0c\u63d0\u51fa\u540e\u95e8\u4fe1\u566a\u6bd4\u6765\u91cf\u5316\u5206\u5e03\u5f0f\u540e\u95e8\u4fe1\u53f7\u7684\u52a8\u6001\u7279\u6027\uff0c\u5e76\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5a01\u80c1\u4e25\u91cd\u6027\uff1a\u4ec5\u9700\u4e0d\u523010%\u7684\u8bad\u7ec3\u6570\u636e\u4e2d\u6bd2\u5e76\u5206\u5e03\u5728\u5ba2\u6237\u7aef\u4e4b\u95f4\uff0c\u653b\u51fb\u6210\u529f\u7387\u5c31\u8d85\u8fc785%\uff0c\u800c\u4e3b\u8981\u4efb\u52a1\u6027\u80fd\u57fa\u672c\u4e0d\u53d7\u5f71\u54cd\u3002\u5173\u952e\u53d1\u73b0\u662f\uff0c\u9488\u5bf9\u6076\u610f\u5ba2\u6237\u7aef\u653b\u51fb\u8bbe\u8ba1\u7684\u6700\u5148\u8fdb\u540e\u95e8\u9632\u5fa1\u673a\u5236\u5bf9\u8fd9\u79cd\u5a01\u80c1\u57fa\u672c\u65e0\u6548\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u9488\u5bf9\u73b0\u4ee3\u53bb\u4e2d\u5fc3\u5316\u6570\u636e\u751f\u6001\u7cfb\u7edf\u73b0\u5b9e\u60c5\u51b5\u5f00\u53d1\u65b0\u9632\u5fa1\u673a\u5236\u7684\u7d27\u8feb\u9700\u6c42\uff0c\u63ed\u793a\u4e86\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u5b89\u5168\u8303\u5f0f\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.15391", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15391", "abs": "https://arxiv.org/abs/2602.15391", "authors": ["Ankit Sharma", "Nachiket Tapas", "Jyotiprakash Patra"], "title": "Improving LLM Reliability through Hybrid Abstention and Adaptive Detection", "comment": null, "summary": "Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules or fixed confidence thresholds are typically context-insensitive and computationally expensive, resulting in high latency and degraded user experience. To address these limitations, we introduce an adaptive abstention system that dynamically adjusts safety thresholds based on real-time contextual signals such as domain and user history. The proposed framework integrates a multi-dimensional detection architecture composed of five parallel detectors, combined through a hierarchical cascade mechanism to optimize both speed and precision. The cascade design reduces unnecessary computation by progressively filtering queries, achieving substantial latency improvements compared to non-cascaded models and external guardrail systems. Extensive evaluation on mixed and domain-specific workloads demonstrates significant reductions in false positives, particularly in sensitive domains such as medical advice and creative writing. The system maintains high safety precision and near-perfect recall under strict operating modes. Overall, our context-aware abstention framework effectively balances safety and utility while preserving performance, offering a scalable solution for reliable LLM deployment.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u5f03\u6743\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u5b89\u5168\u9608\u503c\u548c\u7ea7\u8054\u68c0\u6d4b\u67b6\u6784\uff0c\u89e3\u51b3LLM\u90e8\u7f72\u4e2d\u7684\u5b89\u5168-\u6548\u7528\u6743\u8861\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u8bef\u62a5\u3002", "motivation": "LLM\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u9762\u4e34\u5b89\u5168\u4e0e\u6548\u7528\u7684\u6839\u672c\u6743\u8861\uff1a\u4e25\u683c\u8fc7\u6ee4\u4f1a\u963b\u6b62\u826f\u6027\u67e5\u8be2\uff0c\u5bbd\u677e\u63a7\u5236\u5219\u53ef\u80fd\u751f\u6210\u4e0d\u5b89\u5168\u5185\u5bb9\u3002\u4f20\u7edf\u57fa\u4e8e\u9759\u6001\u89c4\u5219\u6216\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u9608\u503c\u7684\u62a4\u680f\u901a\u5e38\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u654f\u611f\u6027\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5bfc\u81f4\u9ad8\u5ef6\u8fdf\u548c\u7528\u6237\u4f53\u9a8c\u4e0b\u964d\u3002", "method": "\u5f15\u5165\u81ea\u9002\u5e94\u5f03\u6743\u7cfb\u7edf\uff0c\u57fa\u4e8e\u5b9e\u65f6\u4e0a\u4e0b\u6587\u4fe1\u53f7\uff08\u5982\u9886\u57df\u548c\u7528\u6237\u5386\u53f2\uff09\u52a8\u6001\u8c03\u6574\u5b89\u5168\u9608\u503c\u3002\u91c7\u7528\u591a\u7ef4\u68c0\u6d4b\u67b6\u6784\uff0c\u5305\u542b\u4e94\u4e2a\u5e76\u884c\u68c0\u6d4b\u5668\uff0c\u901a\u8fc7\u5206\u5c42\u7ea7\u8054\u673a\u5236\u4f18\u5316\u901f\u5ea6\u548c\u7cbe\u5ea6\u3002\u7ea7\u8054\u8bbe\u8ba1\u901a\u8fc7\u9010\u6b65\u8fc7\u6ee4\u67e5\u8be2\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u8ba1\u7b97\u3002", "result": "\u5728\u6df7\u5408\u548c\u7279\u5b9a\u9886\u57df\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0c\u8bef\u62a5\u663e\u8457\u51cf\u5c11\uff0c\u7279\u522b\u662f\u5728\u533b\u7597\u5efa\u8bae\u548c\u521b\u610f\u5199\u4f5c\u7b49\u654f\u611f\u9886\u57df\u3002\u7cfb\u7edf\u5728\u4e25\u683c\u64cd\u4f5c\u6a21\u5f0f\u4e0b\u4fdd\u6301\u9ad8\u5b89\u5168\u7cbe\u5ea6\u548c\u63a5\u8fd1\u5b8c\u7f8e\u7684\u53ec\u56de\u7387\u3002\u4e0e\u975e\u7ea7\u8054\u6a21\u578b\u548c\u5916\u90e8\u62a4\u680f\u7cfb\u7edf\u76f8\u6bd4\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u5ef6\u8fdf\u6539\u8fdb\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5f03\u6743\u6846\u67b6\u6709\u6548\u5e73\u8861\u4e86\u5b89\u5168\u6027\u548c\u6548\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\uff0c\u4e3a\u53ef\u9760\u7684LLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.15815", "categories": ["cs.CR", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.15815", "abs": "https://arxiv.org/abs/2602.15815", "authors": ["Matthew Regehr", "Bingshan Hu", "Ethan Leeman", "Pasin Manurangsi", "Pierre Tholoniat", "Mathias L\u00e9cuyer"], "title": "Natural Privacy Filters Are Not Always Free: A Characterization of Free Natural Filters", "comment": null, "summary": "We study natural privacy filters, which enable the exact composition of differentially private (DP) mechanisms with adaptively chosen privacy characteristics. Earlier privacy filters consider only simple privacy parameters such as R\u00e9nyi-DP or Gaussian DP parameters. Natural filters account for the entire privacy profile of every query, promising greater utility for a given privacy budget. We show that, contrary to other forms of DP, natural privacy filters are not free in general. Indeed, we show that only families of privacy mechanisms that are well-ordered when composed admit free natural privacy filters.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u81ea\u7136\u9690\u79c1\u8fc7\u6ee4\u5668\uff0c\u5b83\u80fd\u7cbe\u786e\u7ec4\u5408\u5177\u6709\u81ea\u9002\u5e94\u9009\u62e9\u9690\u79c1\u7279\u6027\u7684\u5dee\u5206\u9690\u79c1\u673a\u5236\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4e0e\u5176\u5b83\u5f62\u5f0f\u7684\u5dee\u5206\u9690\u79c1\u4e0d\u540c\uff0c\u81ea\u7136\u9690\u79c1\u8fc7\u6ee4\u5668\u901a\u5e38\u4e0d\u662f\"\u514d\u8d39\"\u7684\uff0c\u53ea\u6709\u90a3\u4e9b\u5728\u7ec4\u5408\u65f6\u5177\u6709\u826f\u5e8f\u6027\u7684\u9690\u79c1\u673a\u5236\u65cf\u624d\u5141\u8bb8\u514d\u8d39\u7684\u8fc7\u6ee4\u5668\u3002", "motivation": "\u73b0\u6709\u9690\u79c1\u8fc7\u6ee4\u5668\u4ec5\u8003\u8651\u7b80\u5355\u7684\u9690\u79c1\u53c2\u6570\uff08\u5982R\u00e9nyi-DP\u6216\u9ad8\u65afDP\u53c2\u6570\uff09\uff0c\u800c\u81ea\u7136\u8fc7\u6ee4\u5668\u8003\u8651\u6bcf\u4e2a\u67e5\u8be2\u7684\u5b8c\u6574\u9690\u79c1\u914d\u7f6e\u6587\u4ef6\uff0c\u627f\u8bfa\u5728\u7ed9\u5b9a\u9690\u79c1\u9884\u7b97\u4e0b\u63d0\u4f9b\u66f4\u5927\u7684\u6548\u7528\u3002\u9700\u8981\u7814\u7a76\u81ea\u7136\u9690\u79c1\u8fc7\u6ee4\u5668\u7684\u6027\u8d28\u548c\u9650\u5236\u3002", "method": "\u7814\u7a76\u81ea\u7136\u9690\u79c1\u8fc7\u6ee4\u5668\uff0c\u5206\u6790\u5176\u4e0e\u5dee\u5206\u9690\u79c1\u673a\u5236\u7ec4\u5408\u7684\u7279\u6027\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u63a2\u8ba8\u54ea\u4e9b\u7c7b\u578b\u7684\u9690\u79c1\u673a\u5236\u65cf\u5728\u7ec4\u5408\u65f6\u5141\u8bb8\u514d\u8d39\u7684\u8fc7\u6ee4\u5668\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u81ea\u7136\u9690\u79c1\u8fc7\u6ee4\u5668\u901a\u5e38\u4e0d\u662f\u514d\u8d39\u7684\uff0c\u8fd9\u4e0e\u5176\u5b83\u5f62\u5f0f\u7684\u5dee\u5206\u9690\u79c1\u4e0d\u540c\u3002\u53ea\u6709\u90a3\u4e9b\u5728\u7ec4\u5408\u65f6\u5177\u6709\u826f\u5e8f\u6027\u7684\u9690\u79c1\u673a\u5236\u65cf\u624d\u5141\u8bb8\u514d\u8d39\u7684\u8fc7\u6ee4\u5668\u3002", "conclusion": "\u81ea\u7136\u9690\u79c1\u8fc7\u6ee4\u5668\u867d\u7136\u80fd\u63d0\u4f9b\u66f4\u597d\u7684\u6548\u7528\uff0c\u4f46\u901a\u5e38\u9700\u8981\u4ed8\u51fa\u4ee3\u4ef7\u3002\u53ea\u6709\u7279\u5b9a\u7c7b\u578b\u7684\u9690\u79c1\u673a\u5236\u65cf\u624d\u80fd\u5b9e\u73b0\u514d\u8d39\u7684\u8fc7\u6ee4\u5668\uff0c\u8fd9\u4e3a\u8bbe\u8ba1\u9ad8\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2602.15403", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15403", "abs": "https://arxiv.org/abs/2602.15403", "authors": ["Thomas \u00c5gotnes"], "title": "Common Belief Revisited", "comment": null, "summary": "Contrary to common belief, common belief is not KD4.\n  If individual belief is KD45, common belief does indeed lose the 5 property and keep the D and 4 properties -- and it has none of the other commonly considered properties of knowledge and belief. But it has another property: $C(C\u03c6\\rightarrow \u03c6)$ -- corresponding to so-called shift-reflexivity (reflexivity one step ahead). This observation begs the question:\n  is KD4 extended with this axiom a complete characterisation of common belief in the KD45 case? If not, what \\emph{is} the logic of common belief? In this paper we show that the answer to the first question is ``no'': there is one additional axiom, and, furthermore, it relies on the number of agents. We show that the result is a complete characterisation of common belief, settling the open problem.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e86\u5173\u4e8e\u5171\u540c\u4fe1\u5ff5\u903b\u8f91\u7684\u5f00\u653e\u6027\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5728KD45\u4e2a\u4f53\u4fe1\u5ff5\u4e0b\uff0c\u5171\u540c\u4fe1\u5ff5\u7684\u903b\u8f91\u4e0d\u4ec5\u9700\u8981KD4\u52a0\u4e0a\u79fb\u4f4d\u81ea\u53cd\u6027\u516c\u7406\uff0c\u8fd8\u9700\u8981\u4e00\u4e2a\u989d\u5916\u7684\u516c\u7406\uff0c\u4e14\u8be5\u516c\u7406\u4f9d\u8d56\u4e8e\u667a\u80fd\u4f53\u6570\u91cf\u3002", "motivation": "\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u5171\u540c\u4fe1\u5ff5\u5177\u6709KD4\u903b\u8f91\u7279\u6027\uff0c\u4f46\u4f5c\u8005\u53d1\u73b0\u5f53\u4e2a\u4f53\u4fe1\u5ff5\u4e3aKD45\u65f6\uff0c\u5171\u540c\u4fe1\u5ff5\u4f1a\u5931\u53bb5\u5c5e\u6027\u800c\u4fdd\u7559D\u548c4\u5c5e\u6027\uff0c\u5e76\u5177\u6709\u79fb\u4f4d\u81ea\u53cd\u6027\uff08C(C\u03c6\u2192\u03c6)\uff09\u3002\u8fd9\u5f15\u53d1\u4e86\u4e00\u4e2a\u5f00\u653e\u6027\u95ee\u9898\uff1aKD4\u52a0\u4e0a\u79fb\u4f4d\u81ea\u53cd\u6027\u516c\u7406\u662f\u5426\u8db3\u4ee5\u5b8c\u5168\u523b\u753b\u5171\u540c\u4fe1\u5ff5\uff1f", "method": "\u901a\u8fc7\u903b\u8f91\u5206\u6790\u8bc1\u660e\uff0c\u4f5c\u8005\u5c55\u793a\u4e86KD4\u52a0\u79fb\u4f4d\u81ea\u53cd\u6027\u516c\u7406\u4e0d\u8db3\u4ee5\u5b8c\u5168\u523b\u753b\u5171\u540c\u4fe1\u5ff5\uff0c\u9700\u8981\u5f15\u5165\u4e00\u4e2a\u989d\u5916\u7684\u516c\u7406\uff0c\u4e14\u8be5\u516c\u7406\u4f9d\u8d56\u4e8e\u667a\u80fd\u4f53\u6570\u91cf\u3002\u6700\u7ec8\u7ed9\u51fa\u4e86\u5171\u540c\u4fe1\u5ff5\u7684\u5b8c\u6574\u903b\u8f91\u523b\u753b\u3002", "result": "\u8bc1\u660e\u4e86\u7b2c\u4e00\u4e2a\u95ee\u9898\u7684\u7b54\u6848\u4e3a\"\u5426\"\uff1aKD4\u52a0\u79fb\u4f4d\u81ea\u53cd\u6027\u516c\u7406\u4e0d\u8db3\u4ee5\u5b8c\u5168\u523b\u753b\u5171\u540c\u4fe1\u5ff5\u3002\u5b58\u5728\u4e00\u4e2a\u989d\u5916\u7684\u516c\u7406\uff0c\u4e14\u8be5\u516c\u7406\u4f9d\u8d56\u4e8e\u667a\u80fd\u4f53\u6570\u91cf\u3002\u6700\u7ec8\u5f97\u5230\u4e86\u5171\u540c\u4fe1\u5ff5\u7684\u5b8c\u6574\u903b\u8f91\u523b\u753b\uff0c\u89e3\u51b3\u4e86\u8fd9\u4e2a\u5f00\u653e\u6027\u95ee\u9898\u3002", "conclusion": "\u672c\u6587\u5b8c\u5168\u523b\u753b\u4e86\u5728KD45\u4e2a\u4f53\u4fe1\u5ff5\u4e0b\u7684\u5171\u540c\u4fe1\u5ff5\u903b\u8f91\uff0c\u8bc1\u660e\u4e86\u9700\u8981KD4\u3001\u79fb\u4f4d\u81ea\u53cd\u6027\u516c\u7406\u4ee5\u53ca\u4e00\u4e2a\u4f9d\u8d56\u4e8e\u667a\u80fd\u4f53\u6570\u91cf\u7684\u989d\u5916\u516c\u7406\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u8be5\u9886\u57df\u7684\u5f00\u653e\u6027\u95ee\u9898\u3002"}}
{"id": "2602.15531", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.15531", "abs": "https://arxiv.org/abs/2602.15531", "authors": ["Javier Irigoyen", "Roberto Daza", "Aythami Morales", "Julian Fierrez", "Francisco Jurado", "Alvaro Ortigosa", "Ruben Tolosana"], "title": "GenAI-LA: Generative AI and Learning Analytics Workshop (LAK 2026), April 27--May 1, 2026, Bergen, Norway", "comment": "10 pages, 3 figures. Published in Intl. Conf. on Learning Analytics & Knowledge Workshops (LAK Workshops 2026, GenAI-LA 26)", "summary": "This work introduces EduEVAL-DB, a dataset based on teacher roles designed to support the evaluation and training of automatic pedagogical evaluators and AI tutors for instructional explanations. The dataset comprises 854 explanations corresponding to 139 questions from a curated subset of the ScienceQA benchmark, spanning science, language, and social science across K-12 grade levels. For each question, one human-teacher explanation is provided and six are generated by LLM-simulated teacher roles. These roles are inspired by instructional styles and shortcomings observed in real educational practice and are instantiated via prompt engineering. We further propose a pedagogical risk rubric aligned with established educational standards, operationalizing five complementary risk dimensions: factual correctness, explanatory depth and completeness, focus and relevance, student-level appropriateness, and ideological bias. All explanations are annotated with binary risk labels through a semi-automatic process with expert teacher review. Finally, we present preliminary validation experiments to assess the suitability of EduEVAL-DB for evaluation. We benchmark a state-of-the-art education-oriented model (Gemini 2.5 Pro) against a lightweight local Llama 3.1 8B model and examine whether supervised fine-tuning on EduEVAL-DB supports pedagogical risk detection using models deployable on consumer hardware.", "AI": {"tldr": "EduEVAL-DB\u662f\u4e00\u4e2a\u57fa\u4e8e\u6559\u5e08\u89d2\u8272\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u8bad\u7ec3\u81ea\u52a8\u6559\u5b66\u8bc4\u4f30\u5668\u548cAI\u5bfc\u5e08\uff0c\u5305\u542b854\u4e2a\u89e3\u91ca\u5bf9\u5e94139\u4e2aScienceQA\u95ee\u9898\uff0c\u6db5\u76d6K-12\u79d1\u5b66\u3001\u8bed\u8a00\u548c\u793e\u4f1a\u79d1\u5b66\u9886\u57df\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u548c\u8bad\u7ec3\u81ea\u52a8\u6559\u5b66\u8bc4\u4f30\u5668\u548cAI\u5bfc\u5e08\u7684\u6570\u636e\u96c6\uff0c\u7279\u522b\u662f\u5728\u6559\u5b66\u89e3\u91ca\u8d28\u91cf\u8bc4\u4f30\u65b9\u9762\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u57fa\u4e8e\u5b9e\u9645\u6559\u80b2\u5b9e\u8df5\u4e2d\u89c2\u5bdf\u5230\u7684\u6559\u5b66\u98ce\u683c\u548c\u4e0d\u8db3\u7684\u6570\u636e\u96c6\uff0c\u4ee5\u652f\u6301\u6559\u80b2AI\u7cfb\u7edf\u7684\u5f00\u53d1\u548c\u8bc4\u4f30\u3002", "method": "1. \u57fa\u4e8eScienceQA\u57fa\u51c6\u7684\u7cbe\u9009\u5b50\u96c6\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5305\u542b139\u4e2a\u95ee\u9898\n2. \u4e3a\u6bcf\u4e2a\u95ee\u9898\u63d0\u4f9b1\u4e2a\u4eba\u7c7b\u6559\u5e08\u89e3\u91ca\u548c6\u4e2aLLM\u6a21\u62df\u7684\u6559\u5e08\u89d2\u8272\u89e3\u91ca\n3. \u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u5b9e\u4f8b\u5316\u57fa\u4e8e\u5b9e\u9645\u6559\u80b2\u5b9e\u8df5\u89c2\u5bdf\u7684\u6559\u5b66\u98ce\u683c\u548c\u4e0d\u8db3\u7684\u6559\u5e08\u89d2\u8272\n4. \u63d0\u51fa\u4e0e\u6559\u80b2\u6807\u51c6\u4e00\u81f4\u7684\u6559\u5b66\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u4e94\u4e2a\u7ef4\u5ea6\n5. \u91c7\u7528\u534a\u81ea\u52a8\u6d41\u7a0b\u52a0\u4e13\u5bb6\u6559\u5e08\u5ba1\u67e5\u7684\u65b9\u5f0f\u8fdb\u884c\u4e8c\u5143\u98ce\u9669\u6807\u6ce8", "result": "1. \u521b\u5efa\u4e86\u5305\u542b854\u4e2a\u89e3\u91ca\u7684EduEVAL-DB\u6570\u636e\u96c6\n2. \u5efa\u7acb\u4e86\u5305\u542b\u4e94\u4e2a\u4e92\u8865\u98ce\u9669\u7ef4\u5ea6\u7684\u6559\u5b66\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\n3. \u521d\u6b65\u9a8c\u8bc1\u5b9e\u9a8c\u8868\u660e\u6570\u636e\u96c6\u9002\u7528\u4e8e\u8bc4\u4f30\u76ee\u7684\n4. \u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u6559\u80b2\u5bfc\u5411\u6a21\u578b(Gemini 2.5 Pro)\u4e0e\u8f7b\u91cf\u7ea7\u672c\u5730\u6a21\u578b(Llama 3.1 8B)\u7684\u6027\u80fd\u5bf9\u6bd4\n5. \u76d1\u7763\u5fae\u8c03\u5b9e\u9a8c\u8868\u660eEduEVAL-DB\u53ef\u7528\u4e8e\u652f\u6301\u6559\u5b66\u98ce\u9669\u68c0\u6d4b\uff0c\u4e14\u53ef\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u90e8\u7f72", "conclusion": "EduEVAL-DB\u662f\u4e00\u4e2a\u6709\u4ef7\u503c\u7684\u8d44\u6e90\uff0c\u53ef\u7528\u4e8e\u8bc4\u4f30\u548c\u8bad\u7ec3\u81ea\u52a8\u6559\u5b66\u8bc4\u4f30\u5668\u548cAI\u5bfc\u5e08\u3002\u6570\u636e\u96c6\u57fa\u4e8e\u6559\u5e08\u89d2\u8272\u8bbe\u8ba1\uff0c\u7ed3\u5408\u4e86\u4eba\u7c7b\u6559\u5e08\u89e3\u91ca\u548cLLM\u6a21\u62df\u7684\u591a\u6837\u5316\u6559\u5b66\u98ce\u683c\uff0c\u5e76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\u3002\u521d\u6b65\u9a8c\u8bc1\u8868\u660e\u8be5\u6570\u636e\u96c6\u5728\u652f\u6301\u6559\u5b66\u98ce\u9669\u68c0\u6d4b\u65b9\u9762\u5177\u6709\u5b9e\u7528\u6027\uff0c\u4e3a\u6559\u80b2AI\u7cfb\u7edf\u7684\u5f00\u53d1\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002"}}
{"id": "2602.15532", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15532", "abs": "https://arxiv.org/abs/2602.15532", "authors": ["Ryan Othniel Kearns"], "title": "Quantifying construct validity in large language model evaluations", "comment": null, "summary": "The LLM community often reports benchmark results as if they are synonymous with general model capabilities. However, benchmarks can have problems that distort performance, like test set contamination and annotator error. How can we know that a benchmark is a reliable indicator of some capability that we want to measure? This question concerns the construct validity of LLM benchmarks, and it requires separating benchmark results from capabilities when we model and predict LLM performance.\n  Both social scientists and computer scientists propose formal models - latent factor models and scaling laws - for identifying the capabilities underlying benchmark scores. However, neither technique is satisfactory for construct validity. Latent factor models ignore scaling laws, and as a result, the capabilities they extract often proxy model size. Scaling laws ignore measurement error, and as a result, the capabilities they extract are both uninterpretable and overfit to the observed benchmarks.\n  This thesis presents the structured capabilities model, the first model to extract interpretable and generalisable capabilities from a large collection of LLM benchmark results. I fit this model and its two alternatives on a large sample of results from the OpenLLM Leaderboard. Structured capabilities outperform latent factor models on parsimonious fit indices, and exhibit better out-of-distribution benchmark prediction than scaling laws. These improvements are possible because neither existing approach separates model scale from capabilities in the appropriate way. Model scale should inform capabilities, as in scaling laws, and these capabilities should inform observed results up to measurement error, as in latent factor models. In combining these two insights, structured capabilities demonstrate better explanatory and predictive power for quantifying construct validity in LLM evaluations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u7ed3\u6784\u5316\u80fd\u529b\u6a21\u578b\uff0c\u9996\u6b21\u4ece\u5927\u91cfLLM\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u4e2d\u63d0\u53d6\u53ef\u89e3\u91ca\u4e14\u53ef\u6cdb\u5316\u7684\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6784\u5efa\u6548\u5ea6\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524dLLM\u793e\u533a\u5e38\u5c06\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u7b49\u540c\u4e8e\u6a21\u578b\u901a\u7528\u80fd\u529b\uff0c\u4f46\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u6d4b\u8bd5\u96c6\u6c61\u67d3\u3001\u6807\u6ce8\u9519\u8bef\u7b49\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\uff08\u6f5c\u5728\u56e0\u5b50\u6a21\u578b\u548c\u7f29\u653e\u5b9a\u5f8b\uff09\u90fd\u65e0\u6cd5\u4ee4\u4eba\u6ee1\u610f\u5730\u89e3\u51b3\u6784\u5efa\u6548\u5ea6\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5206\u79bb\u6a21\u578b\u89c4\u6a21\u4e0e\u771f\u5b9e\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u5316\u80fd\u529b\u6a21\u578b\uff0c\u7ed3\u5408\u4e86\u7f29\u653e\u5b9a\u5f8b\u548c\u6f5c\u5728\u56e0\u5b50\u6a21\u578b\u7684\u4f18\u70b9\uff1a\u6a21\u578b\u89c4\u6a21\u5f71\u54cd\u80fd\u529b\uff08\u5982\u7f29\u653e\u5b9a\u5f8b\uff09\uff0c\u80fd\u529b\u5f71\u54cd\u89c2\u6d4b\u7ed3\u679c\u5e76\u8003\u8651\u6d4b\u91cf\u8bef\u5dee\uff08\u5982\u6f5c\u5728\u56e0\u5b50\u6a21\u578b\uff09\u3002\u5728OpenLLM\u6392\u884c\u699c\u7684\u5927\u89c4\u6a21\u7ed3\u679c\u6837\u672c\u4e0a\u62df\u5408\u8be5\u6a21\u578b\u3002", "result": "\u7ed3\u6784\u5316\u80fd\u529b\u6a21\u578b\u5728\u7b80\u7ea6\u62df\u5408\u6307\u6807\u4e0a\u4f18\u4e8e\u6f5c\u5728\u56e0\u5b50\u6a21\u578b\uff0c\u5728\u5206\u5e03\u5916\u57fa\u51c6\u9884\u6d4b\u4e0a\u4f18\u4e8e\u7f29\u653e\u5b9a\u5f8b\u3002\u8be5\u6a21\u578b\u80fd\u66f4\u597d\u5730\u89e3\u91ca\u548c\u9884\u6d4bLLM\u8bc4\u4f30\u4e2d\u7684\u6784\u5efa\u6548\u5ea6\u3002", "conclusion": "\u7ed3\u6784\u5316\u80fd\u529b\u6a21\u578b\u901a\u8fc7\u9002\u5f53\u5206\u79bb\u6a21\u578b\u89c4\u6a21\u4e0e\u80fd\u529b\uff0c\u7ed3\u5408\u4e86\u7f29\u653e\u5b9a\u5f8b\u548c\u6f5c\u5728\u56e0\u5b50\u6a21\u578b\u7684\u6d1e\u89c1\uff0c\u4e3a\u91cf\u5316LLM\u8bc4\u4f30\u7684\u6784\u5efa\u6548\u5ea6\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u89e3\u91ca\u548c\u9884\u6d4b\u80fd\u529b\u3002"}}
{"id": "2602.15553", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.15553", "abs": "https://arxiv.org/abs/2602.15553", "authors": ["Gabriele Conte", "Alessio Mattiace", "Gianni Carmosino", "Potito Aghilar", "Giovanni Servedio", "Francesco Musicco", "Vito Walter Anelli", "Tommaso Di Noia", "Francesco Maria Donini"], "title": "RUVA: Personalized Transparent On-Device Graph Reasoning", "comment": null, "summary": "The Personal AI landscape is currently dominated by \"Black Box\" Retrieval-Augmented Generation. While standard vector databases offer statistical matching, they suffer from a fundamental lack of accountability: when an AI hallucinates or retrieves sensitive data, the user cannot inspect the cause nor correct the error. Worse, \"deleting\" a concept from a vector space is mathematically imprecise, leaving behind probabilistic \"ghosts\" that violate true privacy. We propose Ruva, the first \"Glass Box\" architecture designed for Human-in-the-Loop Memory Curation. Ruva grounds Personal AI in a Personal Knowledge Graph, enabling users to inspect what the AI knows and to perform precise redaction of specific facts. By shifting the paradigm from Vector Matching to Graph Reasoning, Ruva ensures the \"Right to be Forgotten.\" Users are the editors of their own lives; Ruva hands them the pen. The project and the demo video are available at http://sisinf00.poliba.it/ruva/.", "AI": {"tldr": "Ruva\u63d0\u51fa\u9996\u4e2a\"\u900f\u660e\u76d2\"\u67b6\u6784\uff0c\u7528\u4e8e\u4eba\u7c7b\u53c2\u4e0e\u7684\u8bb0\u5fc6\u7ba1\u7406\uff0c\u901a\u8fc7\u4e2a\u4eba\u77e5\u8bc6\u56fe\u8c31\u53d6\u4ee3\u5411\u91cf\u5339\u914d\uff0c\u5b9e\u73b0\u53ef\u68c0\u67e5\u3001\u53ef\u7cbe\u786e\u5220\u9664\u7684AI\u8bb0\u5fc6\u7cfb\u7edf", "motivation": "\u5f53\u524d\u4e2a\u4ebaAI\u9886\u57df\u88ab\"\u9ed1\u76d2\"\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e3b\u5bfc\uff0c\u5411\u91cf\u6570\u636e\u5e93\u7f3a\u4e4f\u53ef\u8ffd\u6eaf\u6027\uff1a\u5f53AI\u4ea7\u751f\u5e7b\u89c9\u6216\u68c0\u7d22\u654f\u611f\u6570\u636e\u65f6\uff0c\u7528\u6237\u65e0\u6cd5\u68c0\u67e5\u539f\u56e0\u6216\u7ea0\u6b63\u9519\u8bef\u3002\u66f4\u4e25\u91cd\u7684\u662f\uff0c\u4ece\u5411\u91cf\u7a7a\u95f4\u4e2d\"\u5220\u9664\"\u6982\u5ff5\u5728\u6570\u5b66\u4e0a\u4e0d\u7cbe\u786e\uff0c\u4f1a\u7559\u4e0b\u8fdd\u53cd\u771f\u6b63\u9690\u79c1\u7684\u6982\u7387\"\u5e7d\u7075\"", "method": "\u63d0\u51faRuva\u67b6\u6784\uff0c\u5c06\u4e2a\u4ebaAI\u5efa\u7acb\u5728\u4e2a\u4eba\u77e5\u8bc6\u56fe\u8c31\u57fa\u7840\u4e0a\uff0c\u4ece\u5411\u91cf\u5339\u914d\u8f6c\u5411\u56fe\u8c31\u63a8\u7406\uff0c\u5b9e\u73b0\u4eba\u7c7b\u53c2\u4e0e\u7684\u8bb0\u5fc6\u7ba1\u7406\uff0c\u8ba9\u7528\u6237\u80fd\u591f\u68c0\u67e5AI\u77e5\u9053\u4ec0\u4e48\u5e76\u6267\u884c\u7279\u5b9a\u4e8b\u5b9e\u7684\u7cbe\u786e\u5220\u9664", "result": "Ruva\u786e\u4fdd\"\u88ab\u9057\u5fd8\u6743\"\uff0c\u7528\u6237\u6210\u4e3a\u81ea\u5df1\u751f\u6d3b\u7684\u7f16\u8f91\u8005\uff0c\u7cfb\u7edf\u63d0\u4f9b\u900f\u660e\u3001\u53ef\u8ffd\u6eaf\u3001\u53ef\u7cbe\u786e\u5220\u9664\u7684AI\u8bb0\u5fc6\u7ba1\u7406\u80fd\u529b", "conclusion": "\u901a\u8fc7\u4e2a\u4eba\u77e5\u8bc6\u56fe\u8c31\u66ff\u4ee3\u5411\u91cf\u6570\u636e\u5e93\uff0cRuva\u89e3\u51b3\u4e86\u5f53\u524dAI\u7cfb\u7edf\u7684\u53ef\u8ffd\u6eaf\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u771f\u6b63\u7684\u4eba\u7c7b\u4e2d\u5fc3\u5316AI\u8bb0\u5fc6\u7ba1\u7406"}}
{"id": "2602.15580", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15580", "abs": "https://arxiv.org/abs/2602.15580", "authors": ["Hongxuan Wu", "Yukun Zhang", "Xueqing Zhou"], "title": "How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning", "comment": null, "summary": "When a multimodal Transformer answers a visual question, is the prediction driven by visual evidence, linguistic reasoning, or genuinely fused cross-modal computation -- and how does this structure evolve across layers? We address this question with a layer-wise framework based on Partial Information Decomposition (PID) that decomposes the predictive information at each Transformer layer into redundant, vision-unique, language-unique, and synergistic components. To make PID tractable for high-dimensional neural representations, we introduce \\emph{PID Flow}, a pipeline combining dimensionality reduction, normalizing-flow Gaussianization, and closed-form Gaussian PID estimation. Applying this framework to LLaVA-1.5-7B and LLaVA-1.6-7B across six GQA reasoning tasks, we uncover a consistent \\emph{modal transduction} pattern: visual-unique information peaks early and decays with depth, language-unique information surges in late layers to account for roughly 82\\% of the final prediction, and cross-modal synergy remains below 2\\%. This trajectory is highly stable across model variants (layer-wise correlations $>$0.96) yet strongly task-dependent, with semantic redundancy governing the detailed information fingerprint. To establish causality, we perform targeted Image$\\rightarrow$Question attention knockouts and show that disrupting the primary transduction pathway induces predictable increases in trapped visual-unique information, compensatory synergy, and total information cost -- effects that are strongest in vision-dependent tasks and weakest in high-redundancy tasks. Together, these results provide an information-theoretic, causal account of how vision becomes language in multimodal Transformers, and offer quantitative guidance for identifying architectural bottlenecks where modality-specific information is lost.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51faPID Flow\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u606f\u5206\u89e3\u5206\u6790\u591a\u6a21\u6001Transformer\u4e2d\u89c6\u89c9\u548c\u8bed\u8a00\u4fe1\u606f\u7684\u6d41\u52a8\u6a21\u5f0f\uff0c\u53d1\u73b0\u5728LLaVA\u6a21\u578b\u4e2d\u89c6\u89c9\u4fe1\u606f\u65e9\u671f\u8fbe\u5230\u5cf0\u503c\u540e\u8870\u51cf\uff0c\u8bed\u8a00\u4fe1\u606f\u5728\u6df1\u5c42\u5360\u4e3b\u5bfc\uff08\u7ea682%\uff09\uff0c\u8de8\u6a21\u6001\u534f\u540c\u4f5c\u7528\u5f88\u4f4e\uff08<2%\uff09\u3002", "motivation": "\u7814\u7a76\u591a\u6a21\u6001Transformer\u5728\u56de\u7b54\u89c6\u89c9\u95ee\u9898\u65f6\uff0c\u9884\u6d4b\u662f\u53d7\u89c6\u89c9\u8bc1\u636e\u3001\u8bed\u8a00\u63a8\u7406\u8fd8\u662f\u771f\u6b63\u7684\u8de8\u6a21\u6001\u8ba1\u7b97\u9a71\u52a8\uff0c\u4ee5\u53ca\u8fd9\u79cd\u7ed3\u6784\u5982\u4f55\u5728\u4e0d\u540c\u5c42\u95f4\u6f14\u5316\u3002\u65e8\u5728\u7406\u89e3\u89c6\u89c9\u4fe1\u606f\u5982\u4f55\u8f6c\u5316\u4e3a\u8bed\u8a00\u4fe1\u606f\u7684\u4fe1\u606f\u6d41\u52a8\u673a\u5236\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u90e8\u5206\u4fe1\u606f\u5206\u89e3\uff08PID\uff09\u7684\u5c42\u95f4\u5206\u6790\u6846\u67b6\uff0c\u5f15\u5165PID Flow\u7ba1\u9053\uff08\u7ed3\u5408\u964d\u7ef4\u3001\u6b63\u6001\u5316\u6d41\u9ad8\u65af\u5316\u548c\u95ed\u5f0f\u9ad8\u65afPID\u4f30\u8ba1\uff09\uff0c\u5e94\u7528\u4e8eLLaVA-1.5-7B\u548cLLaVA-1.6-7B\u6a21\u578b\uff0c\u5e76\u5728\u516d\u4e2aGQA\u63a8\u7406\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002\u901a\u8fc7\u6ce8\u610f\u529b\u6572\u9664\u5b9e\u9a8c\u5efa\u7acb\u56e0\u679c\u5173\u7cfb\u3002", "result": "\u53d1\u73b0\u4e00\u81f4\u7684\u6a21\u6001\u8f6c\u6362\u6a21\u5f0f\uff1a\u89c6\u89c9\u72ec\u7279\u4fe1\u606f\u65e9\u671f\u8fbe\u5230\u5cf0\u503c\u540e\u8870\u51cf\uff0c\u8bed\u8a00\u72ec\u7279\u4fe1\u606f\u5728\u6df1\u5c42\u6fc0\u589e\uff08\u7ea6\u5360\u6700\u7ec8\u9884\u6d4b\u768482%\uff09\uff0c\u8de8\u6a21\u6001\u534f\u540c\u4f5c\u7528\u4fdd\u6301\u57282%\u4ee5\u4e0b\u3002\u8fd9\u79cd\u6a21\u5f0f\u5728\u4e0d\u540c\u6a21\u578b\u53d8\u4f53\u95f4\u9ad8\u5ea6\u7a33\u5b9a\uff08\u5c42\u95f4\u76f8\u5173\u6027>0.96\uff09\uff0c\u4f46\u5f3a\u70c8\u4f9d\u8d56\u4e8e\u4efb\u52a1\u3002\u6ce8\u610f\u529b\u6572\u9664\u5b9e\u9a8c\u663e\u793a\u7834\u574f\u4e3b\u8981\u8f6c\u6362\u8def\u5f84\u4f1a\u5bfc\u81f4\u89c6\u89c9\u4fe1\u606f\u6ede\u7559\u3001\u8865\u507f\u6027\u534f\u540c\u4f5c\u7528\u589e\u52a0\u548c\u4fe1\u606f\u6210\u672c\u4e0a\u5347\u3002", "conclusion": "\u7814\u7a76\u4e3a\u591a\u6a21\u6001Transformer\u4e2d\u89c6\u89c9\u5982\u4f55\u8f6c\u5316\u4e3a\u8bed\u8a00\u63d0\u4f9b\u4e86\u4fe1\u606f\u8bba\u548c\u56e0\u679c\u89e3\u91ca\uff0c\u4e3a\u8bc6\u522b\u6a21\u6001\u7279\u5b9a\u4fe1\u606f\u4e22\u5931\u7684\u67b6\u6784\u74f6\u9888\u63d0\u4f9b\u4e86\u91cf\u5316\u6307\u5bfc\u3002\u63ed\u793a\u4e86\u5f53\u524d\u591a\u6a21\u6001\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u8bed\u8a00\u63a8\u7406\u800c\u975e\u6df1\u5ea6\u878d\u5408\u8ba1\u7b97\u3002"}}
{"id": "2602.15635", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15635", "abs": "https://arxiv.org/abs/2602.15635", "authors": ["Konstantin Sidorov"], "title": "On inferring cumulative constraints", "comment": "17 pages, 6 figures, 4 tables; submitted to the 32nd International Conference on Principles and Practice of Constraint Programming (CP 2026)", "summary": "Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9884\u5904\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d1\u73b0\u4efb\u52a1\u8986\u76d6\u96c6\u3001\u5f3a\u5316\u4e0d\u7b49\u5f0f\u5e76\u6ce8\u5165\u7ea6\u675f\uff0c\u6539\u5584\u7d2f\u79ef\u7ea6\u675f\u7684\u4f20\u64ad\u6548\u679c", "motivation": "\u4f20\u7edf\u7ea6\u675f\u89c4\u5212\u4e2d\u7d2f\u79ef\u7ea6\u675f\u901a\u5e38\u5355\u72ec\u4f20\u64ad\uff0c\u5ffd\u7565\u4e86\u591a\u8d44\u6e90\u4ea4\u4e92\uff0c\u5bfc\u81f4\u5728\u67d0\u4e9b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u4e25\u91cd\u4e0b\u964d", "method": "\u5c06\u7d2f\u79ef\u7ea6\u675f\u89e3\u91ca\u4e3a\u5360\u7528\u5411\u91cf\u7684\u7ebf\u6027\u4e0d\u7b49\u5f0f\uff0c\u901a\u8fc7\u53d1\u73b0\u4e0d\u80fd\u5e76\u884c\u8fd0\u884c\u7684\u4efb\u52a1\u8986\u76d6\u96c6\uff0c\u4f7f\u7528\u63d0\u5347\u6280\u672f\u5f3a\u5316\u8fd9\u4e9b\u4e0d\u7b49\u5f0f\uff0c\u7136\u540e\u5c06\u751f\u6210\u7684\u7ea6\u675f\u6ce8\u5165\u8c03\u5ea6\u95ee\u9898\u5b9e\u4f8b", "result": "\u5728\u6807\u51c6RCPSP\u548cRCPSP/max\u6d4b\u8bd5\u5957\u4ef6\u4e0a\uff0c\u63a8\u65ad\u51fa\u7684\u7ea6\u675f\u6539\u5584\u4e86\u641c\u7d22\u6027\u80fd\u5e76\u6536\u7d27\u76ee\u6807\u754c\u9650\uff0c\u53d1\u73b0\u4e8625\u4e2a\u65b0\u7684\u4e0b\u754c\u548c5\u4e2a\u65b0\u7684\u6700\u4f18\u89e3", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6355\u6349\u591a\u8d44\u6e90\u4ea4\u4e92\uff0c\u63d0\u5347\u7ea6\u675f\u4f20\u64ad\u6548\u679c\uff0c\u5728\u6709\u5229\u5b9e\u4f8b\u4e0a\u663e\u8457\u6539\u5584\u6027\u80fd\uff0c\u5728\u4e0d\u5229\u5b9e\u4f8b\u4e0a\u4ec5\u5e26\u6765\u8f7b\u5fae\u6027\u80fd\u4e0b\u964d"}}
{"id": "2602.15645", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.15645", "abs": "https://arxiv.org/abs/2602.15645", "authors": ["Lucas Elbert Suryana", "Farah Bierenga", "Sanne van Buuren", "Pepijn Kooij", "Elsefien Tulleners", "Federico Scari", "Simeon Calvert", "Bart van Arem", "Arkady Zgonnikov"], "title": "CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving", "comment": "21 pages, on submission to Transportation Research Part C", "summary": "Foundation models, including vision language models, are increasingly used in automated driving to interpret scenes, recommend actions, and generate natural language explanations. However, existing evaluation methods primarily assess outcome based performance, such as safety and trajectory accuracy, without determining whether model decisions reflect human relevant considerations. As a result, it remains unclear whether explanations produced by such models correspond to genuine reason responsive decision making or merely post hoc rationalizations. This limitation is especially significant in safety critical domains because it can create false confidence. To address this gap, we propose CARE Drive, Context Aware Reasons Evaluation for Driving, a model agnostic framework for evaluating reason responsiveness in vision language models applied to automated driving. CARE Drive compares baseline and reason augmented model decisions under controlled contextual variation to assess whether human reasons causally influence decision behavior. The framework employs a two stage evaluation process. Prompt calibration ensures stable outputs. Systematic contextual perturbation then measures decision sensitivity to human reasons such as safety margins, social pressure, and efficiency constraints. We demonstrate CARE Drive in a cyclist overtaking scenario involving competing normative considerations. Results show that explicit human reasons significantly influence model decisions, improving alignment with expert recommended behavior. However, responsiveness varies across contextual factors, indicating uneven sensitivity to different types of reasons. These findings provide empirical evidence that reason responsiveness in foundation models can be systematically evaluated without modifying model parameters.", "AI": {"tldr": "CARE Drive\u662f\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u81ea\u52a8\u9a7e\u9a76\u4e2d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\"\u539f\u56e0\u54cd\u5e94\u6027\"\uff0c\u901a\u8fc7\u5bf9\u6bd4\u57fa\u51c6\u6a21\u578b\u548c\u539f\u56e0\u589e\u5f3a\u6a21\u578b\u5728\u53d7\u63a7\u4e0a\u4e0b\u6587\u53d8\u5316\u4e0b\u7684\u51b3\u7b56\uff0c\u5224\u65ad\u4eba\u7c7b\u539f\u56e0\u662f\u5426\u771f\u6b63\u5f71\u54cd\u6a21\u578b\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7ed3\u679c\u6027\u80fd\uff08\u5982\u5b89\u5168\u6027\u548c\u8f68\u8ff9\u7cbe\u5ea6\uff09\uff0c\u4f46\u65e0\u6cd5\u786e\u5b9a\u6a21\u578b\u51b3\u7b56\u662f\u5426\u53cd\u6620\u4eba\u7c7b\u76f8\u5173\u8003\u8651\u56e0\u7d20\u3002\u8fd9\u5bfc\u81f4\u65e0\u6cd5\u533a\u5206\u6a21\u578b\u89e3\u91ca\u662f\u771f\u6b63\u7684\u7406\u6027\u51b3\u7b56\u8fd8\u662f\u4e8b\u540e\u5408\u7406\u5316\uff0c\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u53ef\u80fd\u4ea7\u751f\u865a\u5047\u4fe1\u5fc3\u3002", "method": "CARE Drive\u91c7\u7528\u4e24\u9636\u6bb5\u8bc4\u4f30\u8fc7\u7a0b\uff1a1) \u63d0\u793a\u6821\u51c6\u786e\u4fdd\u7a33\u5b9a\u8f93\u51fa\uff1b2) \u7cfb\u7edf\u6027\u7684\u4e0a\u4e0b\u6587\u6270\u52a8\uff0c\u6d4b\u91cf\u51b3\u7b56\u5bf9\u4eba\u7c7b\u539f\u56e0\uff08\u5982\u5b89\u5168\u8fb9\u9645\u3001\u793e\u4f1a\u538b\u529b\u3001\u6548\u7387\u7ea6\u675f\uff09\u7684\u654f\u611f\u6027\u3002\u901a\u8fc7\u5bf9\u6bd4\u57fa\u51c6\u6a21\u578b\u548c\u539f\u56e0\u589e\u5f3a\u6a21\u578b\u5728\u53d7\u63a7\u4e0a\u4e0b\u6587\u53d8\u5316\u4e0b\u7684\u51b3\u7b56\uff0c\u8bc4\u4f30\u539f\u56e0\u54cd\u5e94\u6027\u3002", "result": "\u5728\u81ea\u884c\u8f66\u8d85\u8f66\u573a\u666f\u4e2d\uff0c\u660e\u786e\u7684\u4eba\u7c7b\u539f\u56e0\u663e\u8457\u5f71\u54cd\u6a21\u578b\u51b3\u7b56\uff0c\u63d0\u9ad8\u4e86\u4e0e\u4e13\u5bb6\u63a8\u8350\u884c\u4e3a\u7684\u4e00\u81f4\u6027\u3002\u7136\u800c\uff0c\u54cd\u5e94\u6027\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u56e0\u7d20\u95f4\u5b58\u5728\u5dee\u5f02\uff0c\u8868\u660e\u6a21\u578b\u5bf9\u4e0d\u540c\u7c7b\u578b\u539f\u56e0\u7684\u654f\u611f\u6027\u4e0d\u5747\u5300\u3002", "conclusion": "CARE Drive\u63d0\u4f9b\u4e86\u65e0\u9700\u4fee\u6539\u6a21\u578b\u53c2\u6570\u5373\u53ef\u7cfb\u7edf\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u539f\u56e0\u54cd\u5e94\u6027\u7684\u5b9e\u8bc1\u8bc1\u636e\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u4e2d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u9760\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2602.15669", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15669", "abs": "https://arxiv.org/abs/2602.15669", "authors": ["Xiachong Feng", "Liang Zhao", "Weihong Zhong", "Yichong Huang", "Yuxuan Gu", "Lingpeng Kong", "Xiaocheng Feng", "Bing Qin"], "title": "PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra", "comment": "ICLR 2026", "summary": "Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations. The framework operates through three stages: Persona-Base extracts orthogonal trait vectors via contrastive activation analysis; Persona-Algebra enables precise control through vector arithmetic (scalar multiplication for intensity, addition for composition, subtraction for suppression); and Persona-Flow achieves context-aware adaptation by dynamically composing these vectors during inference. On PersonalityBench, our approach achieves a mean score of 9.60, nearly matching the supervised fine-tuning upper bound of 9.61 without any gradient updates. On our proposed Persona-Evolve benchmark for dynamic personality adaptation, we achieve up to 91% win rates across diverse model families. These results provide evidence that aspects of LLM personality are mathematically tractable, opening new directions for interpretable and efficient behavioral control.", "AI": {"tldr": "PERSONA\u6846\u67b6\u901a\u8fc7\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u7684\u5411\u91cf\u64cd\u4f5c\u5b9e\u73b0LLM\u4eba\u683c\u63a7\u5236\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u8fbe\u5230\u5fae\u8c03\u7ea7\u522b\u6027\u80fd\uff0c\u63ed\u793a\u4eba\u683c\u7279\u8d28\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u8868\u73b0\u4e3a\u53ef\u63d0\u53d6\u7684\u8fd1\u4f3c\u6b63\u4ea4\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4eba\u683c\u63a7\u5236\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u63d0\u793a\u6216\u6602\u8d35\u7684\u5fae\u8c03\uff0c\u65e0\u6cd5\u6355\u6349\u4eba\u7c7b\u7279\u8d28\u7684\u52a8\u6001\u6027\u548c\u7ec4\u5408\u6027\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u63a7\u5236\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u6846\u67b6\uff1a1) Persona-Base\u901a\u8fc7\u5bf9\u6bd4\u6fc0\u6d3b\u5206\u6790\u63d0\u53d6\u6b63\u4ea4\u7279\u8d28\u5411\u91cf\uff1b2) Persona-Algebra\u901a\u8fc7\u5411\u91cf\u7b97\u672f\u5b9e\u73b0\u7cbe\u786e\u63a7\u5236\uff08\u6807\u91cf\u4e58\u6cd5\u8c03\u8282\u5f3a\u5ea6\uff0c\u52a0\u6cd5\u7ec4\u5408\uff0c\u51cf\u6cd5\u6291\u5236\uff09\uff1b3) Persona-Flow\u5728\u63a8\u7406\u65f6\u52a8\u6001\u7ec4\u5408\u5411\u91cf\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u9002\u5e94\u3002", "result": "\u5728PersonalityBench\u4e0a\u5e73\u5747\u5f97\u52069.60\uff0c\u63a5\u8fd1\u76d1\u7763\u5fae\u8c03\u4e0a\u96509.61\uff1b\u5728Persona-Evolve\u52a8\u6001\u4eba\u683c\u9002\u5e94\u57fa\u51c6\u4e0a\uff0c\u8de8\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u8fbe\u5230\u6700\u9ad891%\u7684\u80dc\u7387\u3002", "conclusion": "LLM\u7684\u4eba\u683c\u65b9\u9762\u5177\u6709\u6570\u5b66\u53ef\u5904\u7406\u6027\uff0c\u4e3a\u53ef\u89e3\u91ca\u548c\u9ad8\u6548\u7684\u884c\u4e3a\u63a7\u5236\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u6fc0\u6d3b\u7a7a\u95f4\u5411\u91cf\u64cd\u4f5c\u5b9e\u73b0\u8bad\u7ec3\u81ea\u7531\u4eba\u683c\u63a7\u5236\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2602.15725", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15725", "abs": "https://arxiv.org/abs/2602.15725", "authors": ["Sarim Chaudhry"], "title": "Recursive Concept Evolution for Compositional Reasoning in Large Language Models", "comment": null, "summary": "Large language models achieve strong performance on many complex reasoning tasks, yet their accuracy degrades sharply on benchmarks that require compositional reasoning, including ARC-AGI-2, GPQA, MATH, BBH, and HLE. Existing methods improve reasoning by expanding token-level search through chain-of-thought prompting, self-consistency, or reinforcement learning, but they leave the model's latent representation space fixed. When the required abstraction is not already encoded in this space, performance collapses. We propose Recursive Concept Evolution (RCE), a framework that enables pretrained language models to modify their internal representation geometry during inference. RCE introduces dynamically generated low-rank concept subspaces that are spawned when representational inadequacy is detected, selected through a minimum description length criterion, merged when synergistic, and consolidated via constrained optimization to preserve stability. This process allows the model to construct new abstractions rather than recombining existing ones. We integrate RCE with Mistral-7B and evaluate it across compositional reasoning benchmarks. RCE yields 12-18 point gains on ARC-AGI-2, 8-14 point improvements on GPQA and BBH, and consistent reductions in depth-induced error on MATH and HLE.", "AI": {"tldr": "RCE\u6846\u67b6\u8ba9\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u80fd\u5728\u63a8\u7406\u65f6\u52a8\u6001\u4fee\u6539\u5185\u90e8\u8868\u5f81\u51e0\u4f55\uff0c\u901a\u8fc7\u751f\u6210\u4f4e\u79e9\u6982\u5ff5\u5b50\u7a7a\u95f4\u6765\u6784\u5efa\u65b0\u62bd\u8c61\uff0c\u663e\u8457\u63d0\u5347\u7ec4\u5408\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u6269\u5c55token\u7ea7\u641c\u7d22\uff08\u5982\u601d\u7ef4\u94fe\u3001\u81ea\u4e00\u81f4\u6027\u3001\u5f3a\u5316\u5b66\u4e60\uff09\u6765\u6539\u8fdb\u63a8\u7406\uff0c\u4f46\u4fdd\u6301\u6a21\u578b\u7684\u6f5c\u5728\u8868\u5f81\u7a7a\u95f4\u56fa\u5b9a\u3002\u5f53\u6240\u9700\u62bd\u8c61\u672a\u7f16\u7801\u5728\u8be5\u7a7a\u95f4\u4e2d\u65f6\uff0c\u6027\u80fd\u4f1a\u6025\u5267\u4e0b\u964d", "method": "\u63d0\u51fa\u9012\u5f52\u6982\u5ff5\u6f14\u5316(RCE)\u6846\u67b6\uff0c\u5728\u63a8\u7406\u65f6\u68c0\u6d4b\u8868\u5f81\u4e0d\u8db3\u65f6\u52a8\u6001\u751f\u6210\u4f4e\u79e9\u6982\u5ff5\u5b50\u7a7a\u95f4\uff0c\u901a\u8fc7\u6700\u5c0f\u63cf\u8ff0\u957f\u5ea6\u51c6\u5219\u9009\u62e9\uff0c\u5728\u534f\u540c\u65f6\u5408\u5e76\uff0c\u5e76\u901a\u8fc7\u7ea6\u675f\u4f18\u5316\u8fdb\u884c\u6574\u5408\u4ee5\u4fdd\u6301\u7a33\u5b9a\u6027", "result": "\u5728Mistral-7B\u4e0a\u96c6\u6210RCE\uff0c\u5728\u7ec4\u5408\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff1aARC-AGI-2\u63d0\u534712-18\u70b9\uff0cGPQA\u548cBBH\u63d0\u53478-14\u70b9\uff0c\u5728MATH\u548cHLE\u4e0a\u6301\u7eed\u51cf\u5c11\u6df1\u5ea6\u8bf1\u5bfc\u8bef\u5dee", "conclusion": "RCE\u4f7f\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u63a8\u7406\u65f6\u4fee\u6539\u5185\u90e8\u8868\u5f81\u51e0\u4f55\uff0c\u6784\u5efa\u65b0\u62bd\u8c61\u800c\u975e\u4ec5\u91cd\u7ec4\u73b0\u6709\u6982\u5ff5\uff0c\u663e\u8457\u63d0\u5347\u7ec4\u5408\u63a8\u7406\u6027\u80fd"}}
{"id": "2602.15776", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15776", "abs": "https://arxiv.org/abs/2602.15776", "authors": ["Yiqin Yang", "Xu Yang", "Yuhua Jiang", "Ni Mu", "Hao Hu", "Runpeng Xie", "Ziyou Zhang", "Siyuan Li", "Yuan-Hua Ni", "Qianchuan Zhao", "Bo Xu"], "title": "GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems", "comment": null, "summary": "In the realm of multi-agent systems, the challenge of \\emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.", "AI": {"tldr": "GlobeDiff\u7b97\u6cd5\u901a\u8fc7\u591a\u6a21\u6001\u6269\u6563\u8fc7\u7a0b\u4ece\u5c40\u90e8\u89c2\u6d4b\u63a8\u65ad\u5168\u5c40\u72b6\u6001\uff0c\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u7684\u6311\u6218", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u662f\u534f\u8c03\u548c\u51b3\u7b56\u7684\u5173\u952e\u969c\u788d\u3002\u73b0\u6709\u65b9\u6cd5\u5982\u4fe1\u5ff5\u72b6\u6001\u4f30\u8ba1\u548c\u667a\u80fd\u4f53\u95f4\u901a\u4fe1\u5b58\u5728\u5c40\u9650\uff1a\u4fe1\u5ff5\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u8fc7\u53bb\u7ecf\u9a8c\u800c\u672a\u80fd\u5145\u5206\u5229\u7528\u5168\u5c40\u4fe1\u606f\uff0c\u901a\u4fe1\u65b9\u6cd5\u7f3a\u4e4f\u6709\u6548\u5229\u7528\u8f85\u52a9\u4fe1\u606f\u7684\u9c81\u68d2\u6a21\u578b", "method": "\u63d0\u51faGlobal State Diffusion Algorithm (GlobeDiff)\uff0c\u5c06\u72b6\u6001\u63a8\u65ad\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u591a\u6a21\u6001\u6269\u6563\u8fc7\u7a0b\uff0c\u57fa\u4e8e\u5c40\u90e8\u89c2\u6d4b\u63a8\u65ad\u5168\u5c40\u72b6\u6001\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6269\u6563\u8fc7\u7a0b\u514b\u670d\u72b6\u6001\u4f30\u8ba1\u4e2d\u7684\u6a21\u7cca\u6027\uff0c\u540c\u65f6\u4ee5\u9ad8\u4fdd\u771f\u5ea6\u63a8\u65ad\u5168\u5c40\u72b6\u6001", "result": "\u8bc1\u660e\u4e86GlobeDiff\u5728\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u5206\u5e03\u4e0b\u7684\u4f30\u8ba1\u8bef\u5dee\u90fd\u6709\u754c\u3002\u5927\u91cf\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGlobeDiff\u5b9e\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd\uff0c\u80fd\u591f\u51c6\u786e\u63a8\u65ad\u5168\u5c40\u72b6\u6001", "conclusion": "GlobeDiff\u901a\u8fc7\u591a\u6a21\u6001\u6269\u6563\u8fc7\u7a0b\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u95ee\u9898\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u5168\u5c40\u72b6\u6001\u63a8\u65ad\u65b9\u9762\u8868\u73b0\u66f4\u4f18"}}
{"id": "2602.15785", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15785", "abs": "https://arxiv.org/abs/2602.15785", "authors": ["Jessica Hullman", "David Broska", "Huaman Sun", "Aaron Shaw"], "title": "This human study did not involve human subjects: Validating LLM simulations as behavioral evidence", "comment": null, "summary": "A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited guidance on when such simulations support valid inference about human behavior. We contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. Heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce LLM-induced inaccuracies. While useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. In contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. Under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. Yet the potential of both approaches depends on how well LLMs approximate the relevant populations. We consider what opportunities are overlooked when researchers focus myopically on substituting LLMs for human participants in a study.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u793e\u4f1a\u79d1\u5b66\u5b9e\u9a8c\u4e2d\u4f7f\u7528LLM\u4f5c\u4e3a\u5408\u6210\u53c2\u4e0e\u8005\u7684\u6709\u6548\u6027\uff0c\u5bf9\u6bd4\u4e86\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u7edf\u8ba1\u6821\u51c6\u4e24\u79cd\u7b56\u7565\uff0c\u5206\u6790\u4e86\u5b83\u4eec\u5728\u63a2\u7d22\u6027\u4e0e\u9a8c\u8bc1\u6027\u7814\u7a76\u4e2d\u7684\u9002\u7528\u6027\u3002", "motivation": "\u968f\u7740\u8d8a\u6765\u8d8a\u591a\u7814\u7a76\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u5408\u6210\u53c2\u4e0e\u8005\u6765\u751f\u6210\u7ecf\u6d4e\u9ad8\u6548\u4e14\u5373\u65f6\u7684\u54cd\u5e94\uff0c\u4f46\u7f3a\u4e4f\u5173\u4e8e\u4f55\u65f6\u8fd9\u79cd\u6a21\u62df\u80fd\u591f\u6709\u6548\u63a8\u65ad\u4eba\u7c7b\u884c\u4e3a\u7684\u6307\u5bfc\u3002\u9700\u8981\u660e\u786e\u5728\u4ec0\u4e48\u6761\u4ef6\u4e0bLLM\u6a21\u62df\u80fd\u652f\u6301\u5bf9\u4eba\u7c7b\u884c\u4e3a\u7684\u6709\u6548\u63a8\u65ad\u3002", "method": "\u5bf9\u6bd4\u4e24\u79cd\u7b56\u7565\uff1a1) \u542f\u53d1\u5f0f\u65b9\u6cd5\uff1a\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u3001\u6a21\u578b\u5fae\u8c03\u7b49\u4fee\u590d\u7b56\u7565\u4f7f\u6a21\u62df\u4e0e\u89c2\u5bdf\u7684\u4eba\u7c7b\u884c\u4e3a\u53ef\u4e92\u6362\uff1b2) \u7edf\u8ba1\u6821\u51c6\uff1a\u7ed3\u5408\u8f85\u52a9\u4eba\u7c7b\u6570\u636e\u4e0e\u7edf\u8ba1\u8c03\u6574\uff0c\u5728\u660e\u786e\u5047\u8bbe\u4e0b\u4fdd\u6301\u6709\u6548\u6027\u3002\u5206\u6790\u4e24\u79cd\u65b9\u6cd5\u5728\u63a2\u7d22\u6027\u4e0e\u9a8c\u8bc1\u6027\u7814\u7a76\u4e2d\u7684\u9002\u7528\u6027\u3002", "result": "\u542f\u53d1\u5f0f\u65b9\u6cd5\u9002\u7528\u4e8e\u8bb8\u591a\u63a2\u7d22\u6027\u4efb\u52a1\uff0c\u4f46\u7f3a\u4e4f\u9a8c\u8bc1\u6027\u7814\u7a76\u6240\u9700\u7684\u6b63\u5f0f\u7edf\u8ba1\u4fdd\u8bc1\u3002\u7edf\u8ba1\u6821\u51c6\u5728\u660e\u786e\u5047\u8bbe\u4e0b\u80fd\u4fdd\u6301\u6709\u6548\u6027\uff0c\u5e76\u4ee5\u6bd4\u4ec5\u4f9d\u8d56\u4eba\u7c7b\u53c2\u4e0e\u8005\u7684\u5b9e\u9a8c\u66f4\u4f4e\u7684\u6210\u672c\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u3002\u4e24\u79cd\u65b9\u6cd5\u7684\u6f5c\u529b\u90fd\u53d6\u51b3\u4e8eLLM\u5bf9\u76f8\u5173\u4eba\u7fa4\u7684\u8fd1\u4f3c\u7a0b\u5ea6\u3002", "conclusion": "\u7814\u7a76\u8005\u4e0d\u5e94\u4ec5\u4ec5\u72ed\u9698\u5730\u5173\u6ce8\u7528LLM\u66ff\u4ee3\u7814\u7a76\u4e2d\u7684\u53c2\u4e0e\u8005\uff0c\u800c\u5e94\u8003\u8651\u88ab\u5ffd\u89c6\u7684\u673a\u4f1a\u3002\u9700\u8981\u660e\u786e\u4e0d\u540c\u65b9\u6cd5\u7684\u9002\u7528\u6761\u4ef6\u548c\u5047\u8bbe\uff0c\u4ee5\u652f\u6301\u6709\u6548\u7684\u56e0\u679c\u63a8\u65ad\u3002"}}
{"id": "2602.15791", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.15791", "abs": "https://arxiv.org/abs/2602.15791", "authors": ["Suhyung Jang", "Ghang Lee", "Jaekun Lee", "Hyunjun Lee"], "title": "Enhancing Building Semantics Preservation in AI Model Training with Large Language Model Encodings", "comment": "42nd International Symposium on Automation and Robotics in Construction (ISARC 2025)", "summary": "Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering, construction, and operation (AECO) industry. Conventional encoding methods (e.g., one-hot) often fail to convey the nuanced relationships among closely related subtypes, limiting AI's semantic comprehension. To address this limitation, this study proposes a novel training approach that employs large language model (LLM) embeddings (e.g., OpenAI GPT and Meta LLaMA) as encodings to preserve finer distinctions in building semantics. We evaluated the proposed method by training GraphSAGE models to classify 42 building object subtypes across five high-rise residential building information models (BIMs). Various embedding dimensions were tested, including original high-dimensional LLM embeddings (1,536, 3,072, or 4,096) and 1,024-dimensional compacted embeddings generated via the Matryoshka representation model. Experimental results demonstrated that LLM encodings outperformed the conventional one-hot baseline, with the llama-3 (compacted) embedding achieving a weighted average F1-score of 0.8766, compared to 0.8475 for one-hot encoding. The results underscore the promise of leveraging LLM-based encodings to enhance AI's ability to interpret complex, domain-specific building semantics. As the capabilities of LLMs and dimensionality reduction techniques continue to evolve, this approach holds considerable potential for broad application in semantic elaboration tasks throughout the AECO industry.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5d4c\u5165\u4f5c\u4e3a\u7f16\u7801\u65b9\u6cd5\uff0c\u4ee5\u66f4\u597d\u5730\u6355\u6349\u5efa\u7b51\u8bed\u4e49\u4e2d\u7684\u7ec6\u5fae\u5dee\u522b\uff0c\u76f8\u6bd4\u4f20\u7edfone-hot\u7f16\u7801\u5728\u5efa\u7b51\u5bf9\u8c61\u5b50\u7c7b\u578b\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u5728AECO\u884c\u4e1a\u4e2d\uff0c\u51c6\u786e\u8868\u793a\u5efa\u7b51\u8bed\u4e49\uff08\u5305\u62ec\u901a\u7528\u5bf9\u8c61\u7c7b\u578b\u548c\u7279\u5b9a\u5b50\u7c7b\u578b\uff09\u5bf9AI\u6a21\u578b\u8bad\u7ec3\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u7684\u7f16\u7801\u65b9\u6cd5\uff08\u5982one-hot\uff09\u65e0\u6cd5\u6709\u6548\u4f20\u8fbe\u5bc6\u5207\u76f8\u5173\u7684\u5b50\u7c7b\u578b\u4e4b\u95f4\u7684\u7ec6\u5fae\u5173\u7cfb\uff0c\u9650\u5236\u4e86AI\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f7f\u7528LLM\u5d4c\u5165\uff08OpenAI GPT\u548cMeta LLaMA\uff09\u4f5c\u4e3a\u7f16\u7801\u6765\u4fdd\u7559\u5efa\u7b51\u8bed\u4e49\u7684\u7cbe\u7ec6\u533a\u522b\u3002\u8bc4\u4f30\u65b9\u6cd5\u5305\u62ec\u8bad\u7ec3GraphSAGE\u6a21\u578b\u5bf95\u4e2a\u9ad8\u5c42\u4f4f\u5b85BIM\u4e2d\u768442\u4e2a\u5efa\u7b51\u5bf9\u8c61\u5b50\u7c7b\u578b\u8fdb\u884c\u5206\u7c7b\uff0c\u6d4b\u8bd5\u4e86\u4e0d\u540c\u5d4c\u5165\u7ef4\u5ea6\uff0c\u5305\u62ec\u539f\u59cb\u9ad8\u7ef4LLM\u5d4c\u5165\u548c\u901a\u8fc7Matryoshka\u8868\u793a\u6a21\u578b\u751f\u6210\u76841024\u7ef4\u538b\u7f29\u5d4c\u5165\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLLM\u7f16\u7801\u4f18\u4e8e\u4f20\u7edf\u7684one-hot\u57fa\u7ebf\uff0c\u5176\u4e2dllama-3\uff08\u538b\u7f29\uff09\u5d4c\u5165\u7684\u52a0\u6743\u5e73\u5747F1\u5206\u6570\u8fbe\u52300.8766\uff0c\u800cone-hot\u7f16\u7801\u4e3a0.8475\u3002LLM\u7f16\u7801\u5728\u6355\u6349\u5efa\u7b51\u8bed\u4e49\u7684\u7ec6\u5fae\u533a\u522b\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "LLM\u7f16\u7801\u5728\u589e\u5f3aAI\u89e3\u91ca\u590d\u6742\u3001\u9886\u57df\u7279\u5b9a\u7684\u5efa\u7b51\u8bed\u4e49\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002\u968f\u7740LLM\u548c\u964d\u7ef4\u6280\u672f\u7684\u4e0d\u65ad\u53d1\u5c55\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728AECO\u884c\u4e1a\u7684\u8bed\u4e49\u7ec6\u5316\u4efb\u52a1\u4e2d\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2602.15816", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.15816", "abs": "https://arxiv.org/abs/2602.15816", "authors": ["Xiaoran Liu", "Istvan David"], "title": "Developing AI Agents with Simulated Data: Why, what, and how?", "comment": null, "summary": "As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation solutions.", "AI": {"tldr": "\u672c\u7ae0\u4ecb\u7ecd\u57fa\u4e8e\u4eff\u771f\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u6280\u672f\uff0c\u7528\u4e8e\u89e3\u51b3AI\u8bad\u7ec3\u4e2d\u6570\u636e\u4e0d\u8db3\u548c\u8d28\u91cf\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u6570\u5b57\u5b6a\u751fAI\u4eff\u771f\u89e3\u51b3\u65b9\u6848\u7684\u53c2\u8003\u6846\u67b6\u3002", "motivation": "\u73b0\u4ee3\u7b26\u53f7AI\u7684\u91c7\u7528\u9762\u4e34\u6570\u636e\u91cf\u4e0d\u8db3\u548c\u6570\u636e\u8d28\u91cf\u5dee\u7684\u5173\u952e\u969c\u788d\uff0c\u56e0\u6b64\u5bf9\u5408\u6210\u6570\u636e\u751f\u6210\u6280\u672f\u6709\u5f88\u9ad8\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\u4eff\u771f\u65b9\u6cd5\u8fdb\u884c\u7cfb\u7edf\u5316\u7684\u5408\u6210\u6570\u636e\u751f\u6210\uff0c\u5e76\u63d0\u51fa\u4e86\u63cf\u8ff0\u3001\u8bbe\u8ba1\u548c\u5206\u6790\u6570\u5b57\u5b6a\u751fAI\u4eff\u771f\u89e3\u51b3\u65b9\u6848\u7684\u53c2\u8003\u6846\u67b6\u3002", "result": "\u672c\u7ae0\u4ecb\u7ecd\u4e86\u57fa\u4e8e\u4eff\u771f\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u5173\u952e\u6982\u5ff5\u3001\u4f18\u52bf\u548c\u6311\u6218\uff0c\u4e3aAI\u8bad\u7ec3\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u4eff\u771f\u4e3aAI\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\uff0c\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u4e3a\u8bbe\u8ba1\u548c\u5206\u6790AI\u4eff\u771f\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u53c2\u8003\u3002"}}

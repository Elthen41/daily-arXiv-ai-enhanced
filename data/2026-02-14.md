<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [HLA: Hadamard Linear Attention](https://arxiv.org/abs/2602.12128)
*Hanno Ackermann,Hong Cai,Mohsen Ghafoorian,Amirhossein Habibian*

Main category: cs.AI

TL;DR: 提出Hadamard线性注意力(HLA)，通过哈达玛积计算后应用非线性，相比传统线性注意力能更好地近似softmax，在视频生成等大token量任务中表现高效。


<details>
  <summary>Details</summary>
Motivation: 传统线性注意力虽然计算效率高，但使用独立应用于输入的低阶有理函数近似softmax，近似效果有限。需要一种既能保持线性注意力计算效率，又能更好近似标准softmax注意力的方法。

Method: 提出Hadamard线性注意力(HLA)：1) 不像传统线性注意力那样将非线性分别应用于query和key，而是在计算完pairwise相似度后应用非线性；2) 使用更高阶的有理函数来近似softmax；3) 推导出类似标准线性注意力的高效计算方案，无需耗时的张量重塑操作。

Result: HLA在近似softmax方面比传统线性注意力更准确，同时保持了计算效率。该方法成功应用于大规模视频生成的扩散transformer模型，能够处理大量token。

Conclusion: HLA提供了一种既能保持线性注意力计算效率，又能更好近似标准softmax注意力的新方法，特别适用于需要处理大量token的应用场景如视频生成。

Abstract: The attention mechanism is an important reason for the success of transformers. It relies on computing pairwise relations between tokens. To reduce the high computational cost of standard quadratic attention, linear attention has been proposed as an efficient approximation. It employs kernel functions that are applied independently to the inputs before the pairwise similarities are calculated. That allows for an efficient computational procedure which, however, amounts to a low-degree rational function approximating softmax.
  We propose Hadamard Linear Attention (HLA). Unlike previous works on linear attention, the nonlinearity in HLA is not applied separately to queries and keys, but, analogously to standard softmax attention, after the pairwise similarities have been computed. It will be shown that the proposed nonlinearity amounts to a higher-degree rational function to approximate softmax. An efficient computational scheme for the proposed method is derived that is similar to that of standard linear attention. In contrast to other approaches, no time-consuming tensor reshaping is necessary to apply the proposed algorithm. The effectiveness of the approach is demonstrated by applying it to a large diffusion transformer model for video generation, an application that involves very large amounts of tokens.

</details>


### [2] [Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision](https://arxiv.org/abs/2602.12164)
*Xiaohan He,Shiyang Feng,Songtao Huang,Lei Bai,Bin Wang,Bo Zhang*

Main category: cs.AI

TL;DR: Sci-CoE是一个两阶段的科学协同进化框架，通过从稀疏监督到无监督学习的转变，让模型作为求解器和验证器自我进化，提升科学推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在科学推理任务中仍然脆弱，主要原因是不可靠的解决方案评估和验证策略多样性有限。现有的协同进化范式在代码和数学领域表现良好，但在科学推理方面需要改进。

Method: 提出Sci-CoE两阶段框架：第一阶段使用少量标注数据为验证器建立基本正确性判断锚点；第二阶段引入几何奖励机制，综合考虑共识、可靠性和多样性，在未标注数据上进行大规模自我迭代。

Result: 在多个通用科学基准测试上的实验表明，Sci-CoE增强了复杂推理能力，表现出强大的可扩展性，有助于构建更稳健和多样化的评估系统。

Conclusion: Sci-CoE通过协同进化框架有效解决了科学推理中的评估不可靠和多样性不足问题，为构建更强大的科学推理系统提供了有效途径。

Abstract: Large language models (LLMs) have demonstrated exceptional reasoning capabilities, and co-evolving paradigms have shown promising results in domains such as code and math. However, in scientific reasoning tasks, these models remain fragile due to unreliable solution evaluation and limited diversity in verification strategies. In this work, we propose Sci-CoE, a two-stage scientific co-evolving framework that enables models to self-evolve as both solver and verifier through a transition from sparse supervision to unsupervised learning. In the first stage, the model uses a small set of annotated data to establish fundamental correctness judgment anchors for the Verifier. In the second stage, we introduce a geometric reward mechanism that jointly considers consensus, reliability, and diversity, driving large-scale self-iteration on unlabeled data. Experiments on several general scientific benchmarks demonstrate that Sci-CoE enhances complex reasoning capabilities and exhibits strong scalability, facilitating the construction of more robust and diverse evaluation systems. Codes are available at https://github.com/InternScience/Sci-CoE.

</details>

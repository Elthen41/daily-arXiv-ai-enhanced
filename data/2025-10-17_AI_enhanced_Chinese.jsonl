{"id": "2510.14005", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14005", "abs": "https://arxiv.org/abs/2510.14005", "authors": ["Wei Zou", "Yupei Liu", "Yanting Wang", "Ying Chen", "Neil Gong", "Jinyuan Jia"], "title": "PIShield: Detecting Prompt Injection Attacks via Intrinsic LLM Features", "comment": "The code is available at https://github.com/weizou52/PIShield", "summary": "LLM-integrated applications are vulnerable to prompt injection attacks, where\nan attacker contaminates the input to inject malicious prompts, causing the LLM\nto follow the attacker's intent instead of the original user's. Existing prompt\ninjection detection methods often have sub-optimal performance and/or high\ncomputational overhead. In this work, we propose PIShield, a detection method\nthat is both effective and efficient. Our key observation is that the internal\nrepresentation of the final token in a prompt-extracted from a specific layer\nof the LLM, which we term the injection-critical layer-captures distinguishing\nfeatures between clean and contaminated prompts. Leveraging this insight, we\ntrain a simple linear classifier on these internal representations using a\nlabeled set of clean and contaminated prompts. We compare PIShield against 11\nbaselines across 5 diverse benchmark datasets and 8 prompt injection attacks.\nThe results demonstrate that PIShield is both highly effective and efficient,\nsubstantially outperforming existing methods. Additionally, we show that\nPIShield resists strong adaptive attacks.", "AI": {"tldr": "PIShield\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u6709\u6548\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728LLM\u7279\u5b9a\u5c42\u63d0\u53d6\u6700\u7ec8token\u7684\u5185\u90e8\u8868\u793a\uff0c\u5e76\u4f7f\u7528\u7b80\u5355\u7ebf\u6027\u5206\u7c7b\u5668\u533a\u5206\u5e72\u51c0\u548c\u53d7\u6c61\u67d3\u7684\u63d0\u793a\u3002", "motivation": "\u73b0\u6709\u7684\u63d0\u793a\u6ce8\u5165\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u6027\u80fd\u4e0d\u4f73\u548c\u8ba1\u7b97\u5f00\u9500\u9ad8\u7684\u95ee\u9898\uff0c\u800cLLM\u96c6\u6210\u5e94\u7528\u5bb9\u6613\u53d7\u5230\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u6c61\u67d3\u8f93\u5165\u4f7fLLM\u9075\u5faa\u653b\u51fb\u8005\u610f\u56fe\u800c\u975e\u7528\u6237\u610f\u56fe\u3002", "method": "\u63d0\u51faPIShield\u65b9\u6cd5\uff0c\u5173\u952e\u89c2\u5bdf\u662fLLM\u7279\u5b9a\u5c42\uff08\u6ce8\u5165\u5173\u952e\u5c42\uff09\u4e2d\u6700\u7ec8token\u7684\u5185\u90e8\u8868\u793a\u80fd\u591f\u6355\u83b7\u5e72\u51c0\u548c\u53d7\u6c61\u67d3\u63d0\u793a\u7684\u533a\u522b\u7279\u5f81\uff0c\u57fa\u4e8e\u6b64\u8bad\u7ec3\u7b80\u5355\u7ebf\u6027\u5206\u7c7b\u5668\u3002", "result": "\u57285\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c8\u79cd\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u4e0a\u4e0e11\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u6bd4\u8f83\uff0cPIShield\u5728\u6548\u679c\u548c\u6548\u7387\u4e0a\u90fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u80fd\u62b5\u6297\u5f3a\u81ea\u9002\u5e94\u653b\u51fb\u3002", "conclusion": "PIShield\u662f\u4e00\u79cd\u65e2\u9ad8\u6548\u53c8\u6709\u6548\u7684\u63d0\u793a\u6ce8\u5165\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5229\u7528LLM\u5185\u90e8\u8868\u793a\u7684\u7279\u5f81\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.14172", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.14172", "abs": "https://arxiv.org/abs/2510.14172", "authors": ["Yuchao Su", "Srikar Chundury", "Jiajia Li", "Frank Mueller"], "title": "DIAMOND: Systolic Array Acceleration of Sparse Matrix Multiplication for Quantum Simulation", "comment": null, "summary": "Hamiltonian simulation is a key workload in quantum computing, enabling the\nstudy of complex quantum systems and serving as a critical tool for classical\nverification of quantum devices. However, it is computationally challenging\nbecause the Hilbert space dimension grows exponentially with the number of\nqubits. The growing dimensions make matrix exponentiation, the key kernel in\nHamiltonian simulations, increasingly expensive. Matrix exponentiation is\ntypically approximated by the Taylor series, which contains a series of matrix\nmultiplications. Since Hermitian operators are often sparse, sparse matrix\nmultiplication accelerators are essential for improving the scalability of\nclassical Hamiltonian simulation. Yet, existing accelerators are primarily\ndesigned for machine learning workloads and tuned to their characteristic\nsparsity patterns, which differ fundamentally from those in Hamiltonian\nsimulations that are often dominated by structured diagonals.\n  In this work, we present \\name, the first diagonal-optimized quantum\nsimulation accelerator. It exploits the diagonal structure commonly found in\nproblem-Hamiltonian (Hermitian) matrices and leverages a restructured systolic\narray dataflow to transform diagonally sparse matrices into dense computations,\nenabling high utilization and performance. Through detailed cycle-level\nsimulation of diverse benchmarks in HamLib, \\name{} demonstrates average\nperformance improvements of $10.26\\times$, $33.58\\times$, and $53.15\\times$\nover SIGMA, Outer Product, and Gustavson's algorithm, respectively, with peak\nspeedups up to $127.03\\times$ while reducing energy consumption by an average\nof $471.55\\times$ and up to $4630.58\\times$ compared to SIGMA.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u9488\u5bf9\u91cf\u5b50\u6a21\u62df\u4f18\u5316\u7684\u5bf9\u89d2\u7ebf\u52a0\u901f\u5668\uff0c\u5229\u7528\u54c8\u5bc6\u987f\u77e9\u9635\u4e2d\u5e38\u89c1\u7684\u5bf9\u89d2\u7ebf\u7ed3\u6784\uff0c\u901a\u8fc7\u91cd\u6784\u7684\u8109\u52a8\u9635\u5217\u6570\u636e\u6d41\u5c06\u7a00\u758f\u77e9\u9635\u8f6c\u6362\u4e3a\u5bc6\u96c6\u8ba1\u7b97\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ecf\u5178\u54c8\u5bc6\u987f\u6a21\u62df\u7684\u6027\u80fd\u548c\u80fd\u6548\u3002", "motivation": "\u54c8\u5bc6\u987f\u6a21\u62df\u662f\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u5173\u952e\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u4f46\u7531\u4e8e\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u7ef4\u5ea6\u968f\u91cf\u5b50\u6bd4\u7279\u6570\u6307\u6570\u589e\u957f\uff0c\u77e9\u9635\u6307\u6570\u8fd0\u7b97\u53d8\u5f97\u975e\u5e38\u6602\u8d35\u3002\u73b0\u6709\u52a0\u901f\u5668\u4e3b\u8981\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u8bbe\u8ba1\uff0c\u5176\u7a00\u758f\u6a21\u5f0f\u4e0e\u54c8\u5bc6\u987f\u6a21\u62df\u4e2d\u5e38\u89c1\u7684\u7ed3\u6784\u5316\u5bf9\u89d2\u7ebf\u6a21\u5f0f\u5b58\u5728\u6839\u672c\u5dee\u5f02\u3002", "method": "\u5f00\u53d1\u4e86\u7b2c\u4e00\u4e2a\u5bf9\u89d2\u7ebf\u4f18\u5316\u7684\u91cf\u5b50\u6a21\u62df\u52a0\u901f\u5668\uff0c\u5229\u7528\u95ee\u9898\u54c8\u5bc6\u987f\u77e9\u9635\u4e2d\u5e38\u89c1\u7684\u5bf9\u89d2\u7ebf\u7ed3\u6784\uff0c\u901a\u8fc7\u91cd\u6784\u7684\u8109\u52a8\u9635\u5217\u6570\u636e\u6d41\u5c06\u7a00\u758f\u77e9\u9635\u8f6c\u6362\u4e3a\u5bc6\u96c6\u8ba1\u7b97\uff0c\u63d0\u9ad8\u5229\u7528\u7387\u548c\u6027\u80fd\u3002", "result": "\u5728HamLib\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4SIGMA\u3001\u5916\u79ef\u7b97\u6cd5\u548cGustavson\u7b97\u6cd5\uff0c\u5e73\u5747\u6027\u80fd\u5206\u522b\u63d0\u534710.26\u500d\u300133.58\u500d\u548c53.15\u500d\uff0c\u5cf0\u503c\u52a0\u901f\u6bd4\u8fbe127.03\u500d\uff0c\u540c\u65f6\u80fd\u8017\u5e73\u5747\u964d\u4f4e471.55\u500d\uff0c\u6700\u9ad8\u964d\u4f4e4630.58\u500d\u3002", "conclusion": "\u8be5\u5bf9\u89d2\u7ebf\u4f18\u5316\u52a0\u901f\u5668\u901a\u8fc7\u5229\u7528\u54c8\u5bc6\u987f\u77e9\u9635\u7684\u7ed3\u6784\u7279\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ecf\u5178\u54c8\u5bc6\u987f\u6a21\u62df\u7684\u53ef\u6269\u5c55\u6027\u548c\u80fd\u6548\uff0c\u4e3a\u91cf\u5b50\u7cfb\u7edf\u7814\u7a76\u548c\u91cf\u5b50\u8bbe\u5907\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.14024", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.14024", "abs": "https://arxiv.org/abs/2510.14024", "authors": ["Thanh Son Phung", "Douglas Thain"], "title": "Efficiently Executing High-throughput Lightweight LLM Inference Applications on Heterogeneous Opportunistic GPU Clusters with Pervasive Context Management", "comment": null, "summary": "The rise of Generative AI introduces a new class of HPC workloads that\nintegrates lightweight LLMs with traditional high-throughput applications to\naccelerate scientific discovery. The current design of HPC clusters is\ninadequate to support this new class however, either incurring long wait times\non static batch queues or repeatedly paying expensive LLM startup costs upon\nresource preemption. To circumvent both the long queues and high startup costs,\nwe propose to \"decouple\" the LLM initialization context from the actual LLM\ninferences, and retain the context in GPUs until it is no longer needed, a\ntechnique we term \"Pervasive Context Management\". We transform a fact\nverification application to enable this technique, allowing it to reduce its\nexecution time by 72.1% (from 3 hours to 48 minutes) using the same amount of\nGPUs, and scale opportunistically on 32.8% of all GPUs in the cluster and\nfurther reduce the execution time to 13 minutes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\"Pervasive Context Management\"\u7684\u6280\u672f\uff0c\u901a\u8fc7\u5c06LLM\u521d\u59cb\u5316\u4e0a\u4e0b\u6587\u4e0e\u63a8\u7406\u89e3\u8026\u5e76\u4fdd\u7559\u5728GPU\u4e2d\uff0c\u89e3\u51b3\u4e86HPC\u96c6\u7fa4\u4e2d\u751f\u6210\u5f0fAI\u5de5\u4f5c\u8d1f\u8f7d\u9762\u4e34\u7684\u957f\u65f6\u95f4\u7b49\u5f85\u548c\u9ad8\u542f\u52a8\u6210\u672c\u95ee\u9898\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728HPC\u96c6\u7fa4\u4e2d\u7684\u96c6\u6210\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u5728\u9759\u6001\u6279\u5904\u7406\u961f\u5217\u4e2d\u957f\u65f6\u95f4\u7b49\u5f85\uff0c\u4ee5\u53ca\u8d44\u6e90\u62a2\u5360\u65f6\u91cd\u590d\u652f\u4ed8\u6602\u8d35\u7684LLM\u542f\u52a8\u6210\u672c\u3002", "method": "\u5c06LLM\u521d\u59cb\u5316\u4e0a\u4e0b\u6587\u4e0e\u5b9e\u9645\u7684LLM\u63a8\u7406\u89e3\u8026\uff0c\u5e76\u5728GPU\u4e2d\u4fdd\u7559\u4e0a\u4e0b\u6587\u76f4\u5230\u4e0d\u518d\u9700\u8981\uff0c\u8fd9\u4e00\u6280\u672f\u79f0\u4e3a\"Pervasive Context Management\"\u3002", "result": "\u5728\u4e8b\u5b9e\u9a8c\u8bc1\u5e94\u7528\u4e2d\uff0c\u4f7f\u7528\u76f8\u540c\u6570\u91cf\u7684GPU\u5c06\u6267\u884c\u65f6\u95f4\u51cf\u5c11\u4e8672.1%\uff08\u4ece3\u5c0f\u65f6\u964d\u81f348\u5206\u949f\uff09\uff0c\u5e76\u80fd\u5728\u96c6\u7fa4\u4e2d32.8%\u7684GPU\u4e0a\u673a\u4f1a\u6027\u5730\u6269\u5c55\uff0c\u8fdb\u4e00\u6b65\u5c06\u6267\u884c\u65f6\u95f4\u964d\u81f313\u5206\u949f\u3002", "conclusion": "Pervasive Context Management\u6280\u672f\u6709\u6548\u89e3\u51b3\u4e86HPC\u96c6\u7fa4\u4e2d\u751f\u6210\u5f0fAI\u5de5\u4f5c\u8d1f\u8f7d\u7684\u8c03\u5ea6\u548c\u6210\u672c\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6267\u884c\u6548\u7387\u3002"}}
{"id": "2510.14379", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.14379", "abs": "https://arxiv.org/abs/2510.14379", "authors": ["Ming-Han Lin", "Tian-Sheuan Chang"], "title": "Computing-In-Memory Aware Model Adaption For Edge Devices", "comment": "9 pages", "summary": "Computing-in-Memory (CIM) macros have gained popularity for deep learning\nacceleration due to their highly parallel computation and low power\nconsumption. However, limited macro size and ADC precision introduce throughput\nand accuracy bottlenecks. This paper proposes a two-stage CIM-aware model\nadaptation process. The first stage compresses the model and reallocates\nresources based on layer importance and macro size constraints, reducing model\nweight loading latency while improving resource utilization and maintaining\naccuracy. The second stage performs quantization-aware training, incorporating\npartial sum quantization and ADC precision to mitigate quantization errors in\ninference. The proposed approach enhances CIM array utilization to 90\\%,\nenables concurrent activation of up to 256 word lines, and achieves up to 93\\%\ncompression, all while preserving accuracy comparable to previous methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u7684CIM\u611f\u77e5\u6a21\u578b\u9002\u914d\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u578b\u538b\u7f29\u3001\u8d44\u6e90\u91cd\u5206\u914d\u548c\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\uff0c\u89e3\u51b3CIM\u5b8f\u7684\u5c3a\u5bf8\u9650\u5236\u548cADC\u7cbe\u5ea6\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002", "motivation": "\u8ba1\u7b97\u5185\u5b58(CIM)\u5b8f\u5728\u6df1\u5ea6\u5b66\u4e60\u52a0\u901f\u4e2d\u5f88\u53d7\u6b22\u8fce\uff0c\u4f46\u6709\u9650\u7684\u5b8f\u5c3a\u5bf8\u548cADC\u7cbe\u5ea6\u4f1a\u5e26\u6765\u541e\u5410\u91cf\u548c\u7cbe\u5ea6\u74f6\u9888\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u4f18\u5316\u6a21\u578b\u4ee5\u9002\u5e94CIM\u67b6\u6784\u7684\u7ea6\u675f\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u9002\u914d\u8fc7\u7a0b\uff1a\u7b2c\u4e00\u9636\u6bb5\u538b\u7f29\u6a21\u578b\u5e76\u6839\u636e\u5c42\u91cd\u8981\u6027\u548c\u5b8f\u5c3a\u5bf8\u7ea6\u675f\u91cd\u65b0\u5206\u914d\u8d44\u6e90\uff1b\u7b2c\u4e8c\u9636\u6bb5\u8fdb\u884c\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\uff0c\u5305\u542b\u90e8\u5206\u548c\u91cf\u5316\u548cADC\u7cbe\u5ea6\u8003\u8651\uff0c\u4ee5\u51cf\u5c11\u63a8\u7406\u4e2d\u7684\u91cf\u5316\u8bef\u5dee\u3002", "result": "\u8be5\u65b9\u6cd5\u5c06CIM\u9635\u5217\u5229\u7528\u7387\u63d0\u5347\u81f390%\uff0c\u652f\u6301\u540c\u65f6\u6fc0\u6d3b\u591a\u8fbe256\u4e2a\u5b57\u7ebf\uff0c\u5b9e\u73b0\u9ad8\u8fbe93%\u7684\u538b\u7f29\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u5148\u524d\u65b9\u6cd5\u76f8\u5f53\u7684\u7cbe\u5ea6\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684CIM\u611f\u77e5\u6a21\u578b\u9002\u914d\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86CIM\u67b6\u6784\u7684\u5c40\u9650\u6027\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u8d44\u6e90\u5229\u7528\u7387\u548c\u541e\u5410\u91cf\u3002"}}
{"id": "2510.14086", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14086", "abs": "https://arxiv.org/abs/2510.14086", "authors": ["Matthew Finlayson", "Xiang Ren", "Swabha Swayamdipta"], "title": "Every Language Model Has a Forgery-Resistant Signature", "comment": null, "summary": "The ubiquity of closed-weight language models with public-facing APIs has\ngenerated interest in forensic methods, both for extracting hidden model\ndetails (e.g., parameters) and for identifying models by their outputs. One\nsuccessful approach to these goals has been to exploit the geometric\nconstraints imposed by the language model architecture and parameters. In this\nwork, we show that a lesser-known geometric constraint--namely, that language\nmodel outputs lie on the surface of a high-dimensional ellipse--functions as a\nsignature for the model and can be used to identify the source model of a given\noutput. This ellipse signature has unique properties that distinguish it from\nexisting model-output association methods like language model fingerprints. In\nparticular, the signature is hard to forge: without direct access to model\nparameters, it is practically infeasible to produce log-probabilities\n(logprobs) on the ellipse. Secondly, the signature is naturally occurring,\nsince all language models have these elliptical constraints. Thirdly, the\nsignature is self-contained, in that it is detectable without access to the\nmodel inputs or the full weights. Finally, the signature is compact and\nredundant, as it is independently detectable in each logprob output from the\nmodel. We evaluate a novel technique for extracting the ellipse from small\nmodels and discuss the practical hurdles that make it infeasible for\nproduction-scale models. Finally, we use ellipse signatures to propose a\nprotocol for language model output verification, analogous to cryptographic\nsymmetric-key message authentication systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u51e0\u4f55\u7ea6\u675f\u7684\u692d\u5706\u7b7e\u540d\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u8bed\u8a00\u6a21\u578b\u7684\u6765\u6e90\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u4f4d\u4e8e\u9ad8\u7ef4\u692d\u5706\u8868\u9762\u7684\u51e0\u4f55\u7279\u6027\u4f5c\u4e3a\u6a21\u578b\u7b7e\u540d\uff0c\u5177\u6709\u96be\u4ee5\u4f2a\u9020\u3001\u81ea\u7136\u5b58\u5728\u3001\u81ea\u5305\u542b\u548c\u7d27\u51d1\u5197\u4f59\u7684\u7279\u70b9\u3002", "motivation": "\u968f\u7740\u95ed\u6e90\u8bed\u8a00\u6a21\u578bAPI\u7684\u666e\u53ca\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u63d0\u53d6\u9690\u85cf\u6a21\u578b\u7ec6\u8282\u548c\u8bc6\u522b\u6a21\u578b\u8f93\u51fa\u7684\u53d6\u8bc1\u65b9\u6cd5\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5229\u7528\u8bed\u8a00\u6a21\u578b\u67b6\u6784\u548c\u53c2\u6570\u65bd\u52a0\u7684\u51e0\u4f55\u7ea6\u675f\uff0c\u4f46\u8f83\u5c11\u5173\u6ce8\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u4f4d\u4e8e\u9ad8\u7ef4\u692d\u5706\u8868\u9762\u7684\u51e0\u4f55\u7279\u6027\u3002", "method": "\u63d0\u51fa\u692d\u5706\u7b7e\u540d\u65b9\u6cd5\uff0c\u5229\u7528\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u4f4d\u4e8e\u9ad8\u7ef4\u692d\u5706\u8868\u9762\u7684\u51e0\u4f55\u7ea6\u675f\u4f5c\u4e3a\u6a21\u578b\u7b7e\u540d\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4ece\u5c0f\u6a21\u578b\u4e2d\u63d0\u53d6\u692d\u5706\u7279\u5f81\uff0c\u5e76\u8ba8\u8bba\u4e86\u5728\u751f\u4ea7\u89c4\u6a21\u6a21\u578b\u4e2d\u5e94\u7528\u7684\u5b9e\u9645\u969c\u788d\u3002", "result": "\u692d\u5706\u7b7e\u540d\u5177\u6709\u72ec\u7279\u7279\u6027\uff1a\u96be\u4ee5\u4f2a\u9020\uff08\u65e0\u6a21\u578b\u53c2\u6570\u8bbf\u95ee\u6743\u9650\u4e0b\u65e0\u6cd5\u751f\u6210\u692d\u5706\u4e0a\u7684\u5bf9\u6570\u6982\u7387\uff09\u3001\u81ea\u7136\u5b58\u5728\uff08\u6240\u6709\u8bed\u8a00\u6a21\u578b\u90fd\u5177\u6709\u8fd9\u79cd\u692d\u5706\u7ea6\u675f\uff09\u3001\u81ea\u5305\u542b\uff08\u65e0\u9700\u6a21\u578b\u8f93\u5165\u6216\u5b8c\u6574\u6743\u91cd\u5373\u53ef\u68c0\u6d4b\uff09\u548c\u7d27\u51d1\u5197\u4f59\uff08\u6bcf\u4e2a\u5bf9\u6570\u6982\u7387\u8f93\u51fa\u4e2d\u90fd\u53ef\u72ec\u7acb\u68c0\u6d4b\uff09\u3002", "conclusion": "\u692d\u5706\u7b7e\u540d\u53ef\u4f5c\u4e3a\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u9a8c\u8bc1\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u7c7b\u4f3c\u4e8e\u5bc6\u7801\u5b66\u4e2d\u7684\u5bf9\u79f0\u5bc6\u94a5\u6d88\u606f\u8ba4\u8bc1\u7cfb\u7edf\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u6eaf\u6e90\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u9014\u5f84\u3002"}}
{"id": "2510.14126", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.14126", "abs": "https://arxiv.org/abs/2510.14126", "authors": ["Nikos Pagonas", "Yeounoh Chung", "Kostis Kaffes", "Arvind Krishnamurthy"], "title": "Cortex: Workflow-Aware Resource Pooling and Scheduling for Agentic Serving", "comment": null, "summary": "We introduce Cortex, a prototype workflow-aware serving platform designed for\nagentic workloads. The core principle of Cortex is stage isolation: it\nprovisions dedicated resource pools for each distinct stage of an agentic\nworkflow. This simple yet powerful strategy mitigates inter-stage interference\nin compute and memory, leading to better KV cache utilization, higher\nthroughput, and more predictable performance. By customizing resource\nallocation and scheduling within each distinct stage of agentic workflows,\nCortex lays the groundwork for more advanced, agent-native serving paradigms,\nincluding malleable resource management, speculative execution of workflow\nbranches, and a shared, multi-tiered cache for \"agentic state.\"", "AI": {"tldr": "Cortex\u662f\u4e00\u4e2a\u9762\u5411\u667a\u80fd\u4f53\u5de5\u4f5c\u8d1f\u8f7d\u7684\u539f\u578b\u5de5\u4f5c\u6d41\u611f\u77e5\u670d\u52a1\u5e73\u53f0\uff0c\u901a\u8fc7\u9636\u6bb5\u9694\u79bb\u7b56\u7565\u4e3a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u6bcf\u4e2a\u4e0d\u540c\u9636\u6bb5\u5206\u914d\u4e13\u7528\u8d44\u6e90\u6c60\uff0c\u4ece\u800c\u63d0\u9ad8\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u89e3\u51b3\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u4e2d\u4e0d\u540c\u9636\u6bb5\u4e4b\u95f4\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u5e72\u6270\u95ee\u9898\uff0c\u6539\u5584KV\u7f13\u5b58\u5229\u7528\u7387\u3001\u63d0\u5347\u541e\u5410\u91cf\u5e76\u5b9e\u73b0\u66f4\u53ef\u9884\u6d4b\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u91c7\u7528\u9636\u6bb5\u9694\u79bb\u539f\u5219\uff0c\u4e3a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u6bcf\u4e2a\u4e0d\u540c\u9636\u6bb5\u914d\u7f6e\u4e13\u7528\u8d44\u6e90\u6c60\uff0c\u901a\u8fc7\u5b9a\u5236\u5316\u8d44\u6e90\u5206\u914d\u548c\u8c03\u5ea6\u6765\u4f18\u5316\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u9636\u6bb5\u9694\u79bb\u7b56\u7565\u6709\u6548\u51cf\u8f7b\u4e86\u9636\u6bb5\u95f4\u5e72\u6270\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684KV\u7f13\u5b58\u5229\u7528\u3001\u66f4\u9ad8\u541e\u5410\u91cf\u548c\u66f4\u53ef\u9884\u6d4b\u7684\u6027\u80fd\u3002", "conclusion": "Cortex\u4e3a\u66f4\u5148\u8fdb\u7684\u667a\u80fd\u4f53\u539f\u751f\u670d\u52a1\u8303\u5f0f\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5305\u62ec\u53ef\u5851\u6027\u8d44\u6e90\u7ba1\u7406\u3001\u5de5\u4f5c\u6d41\u5206\u652f\u7684\u63a8\u6d4b\u6267\u884c\u4ee5\u53ca\u667a\u80fd\u4f53\u72b6\u6001\u7684\u5171\u4eab\u591a\u7ea7\u7f13\u5b58\u3002"}}
{"id": "2510.14750", "categories": ["cs.AR", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14750", "abs": "https://arxiv.org/abs/2510.14750", "authors": ["\u0130smail Emir Y\u00fcksel", "Ataberk Olgun", "F. Nisa Bostanc\u0131", "Haocong Luo", "A. Giray Ya\u011fl\u0131k\u00e7\u0131", "Onur Mutlu"], "title": "ColumnDisturb: Understanding Column-based Read Disturbance in Real DRAM Chips and Implications for Future Systems", "comment": "Extended version of our publication at the 58th IEEE/ACM\n  International Symposium on Microarchitecture (MICRO-58), 2025", "summary": "We experimentally demonstrate a new widespread read disturbance phenomenon,\nColumnDisturb, in real commodity DRAM chips. By repeatedly opening or keeping a\nDRAM row (aggressor row) open, we show that it is possible to disturb DRAM\ncells through a DRAM column (i.e., bitline) and induce bitflips in DRAM cells\nsharing the same columns as the aggressor row (across multiple DRAM subarrays).\nWith ColumnDisturb, the activation of a single row concurrently disturbs cells\nacross as many as three subarrays (e.g., 3072 rows) as opposed to\nRowHammer/RowPress, which affect only a few neighboring rows of the aggressor\nrow in a single subarray. We rigorously characterize ColumnDisturb and its\ncharacteristics under various operational conditions using 216 DDR4 and 4 HBM2\nchips from three major manufacturers. Among our 27 key experimental\nobservations, we highlight two major results and their implications.\n  First, ColumnDisturb affects chips from all three major manufacturers and\nworsens as DRAM technology scales down to smaller node sizes (e.g., the minimum\ntime to induce the first ColumnDisturb bitflip reduces by up to 5.06x). We\nobserve that, in existing DRAM chips, ColumnDisturb induces bitflips within a\nstandard DDR4 refresh window (e.g., in 63.6 ms) in multiple cells. We predict\nthat, as DRAM technology node size reduces, ColumnDisturb would worsen in\nfuture DRAM chips, likely causing many more bitflips in the standard refresh\nwindow. Second, ColumnDisturb induces bitflips in many (up to 198x) more rows\nthan retention failures. Therefore, ColumnDisturb has strong implications for\nretention-aware refresh mechanisms that leverage the heterogeneity in cell\nretention times: our detailed analyses show that ColumnDisturb greatly reduces\nthe benefits of such mechanisms.", "AI": {"tldr": "\u672c\u6587\u5b9e\u9a8c\u53d1\u73b0\u4e86\u4e00\u79cd\u65b0\u7684DRAM\u8bfb\u5e72\u6270\u73b0\u8c61ColumnDisturb\uff0c\u901a\u8fc7\u91cd\u590d\u6253\u5f00\u6216\u4fdd\u6301DRAM\u884c\uff08\u653b\u51fb\u884c\uff09\u6253\u5f00\uff0c\u53ef\u4ee5\u5e72\u6270\u5171\u4eab\u76f8\u540c\u5217\uff08\u4f4d\u7ebf\uff09\u7684DRAM\u5355\u5143\uff0c\u5bfc\u81f4\u8de8\u591a\u4e2aDRAM\u5b50\u9635\u5217\u7684\u4f4d\u7ffb\u8f6c\u3002", "motivation": "\u7814\u7a76DRAM\u82af\u7247\u4e2d\u5e7f\u6cdb\u5b58\u5728\u7684\u8bfb\u5e72\u6270\u73b0\u8c61\uff0c\u7279\u522b\u662f\u4e0e\u4f20\u7edfRowHammer/RowPress\u4e0d\u540c\u7684\u5217\u7ea7\u5e72\u6270\u673a\u5236\uff0c\u4ee5\u4e86\u89e3\u5176\u5bf9DRAM\u53ef\u9760\u6027\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528216\u4e2aDDR4\u548c4\u4e2aHBM2\u82af\u7247\u4ece\u4e09\u5927\u5236\u9020\u5546\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5728\u591a\u79cd\u64cd\u4f5c\u6761\u4ef6\u4e0b\u4e25\u683c\u8868\u5f81ColumnDisturb\u53ca\u5176\u7279\u6027\uff0c\u83b7\u5f9727\u4e2a\u5173\u952e\u5b9e\u9a8c\u89c2\u5bdf\u7ed3\u679c\u3002", "result": "1) ColumnDisturb\u5f71\u54cd\u6240\u6709\u4e09\u5927\u5236\u9020\u5546\u7684\u82af\u7247\uff0c\u4e14\u968f\u7740DRAM\u6280\u672f\u8282\u70b9\u7f29\u5c0f\u800c\u6076\u5316\uff1b2) \u5728\u6807\u51c6DDR4\u5237\u65b0\u7a97\u53e3\u5185\u53ef\u8bf1\u5bfc\u4f4d\u7ffb\u8f6c\uff1b3) \u6bd4\u4fdd\u7559\u6545\u969c\u5f71\u54cd\u66f4\u591a\u884c\uff08\u6700\u591a198\u500d\uff09\u3002", "conclusion": "ColumnDisturb\u73b0\u8c61\u5bf9DRAM\u53ef\u9760\u6027\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u7279\u522b\u662f\u4f1a\u663e\u8457\u964d\u4f4e\u5229\u7528\u5355\u5143\u4fdd\u7559\u65f6\u95f4\u5f02\u8d28\u6027\u7684\u4fdd\u7559\u611f\u77e5\u5237\u65b0\u673a\u5236\u7684\u6709\u6548\u6027\uff0c\u4e14\u968f\u7740\u6280\u672f\u53d1\u5c55\u8fd9\u4e00\u95ee\u9898\u53ef\u80fd\u52a0\u5267\u3002"}}
{"id": "2510.14147", "categories": ["cs.DC", "cs.CG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.14147", "abs": "https://arxiv.org/abs/2510.14147", "authors": ["Gabriel Raulet", "Dmitriy Morozov", "Aydin Buluc", "Katherine Yelick"], "title": "Distributed-Memory Parallel Algorithms for Fixed-Radius Near Neighbor Graph Construction", "comment": "11 pages, 5 figures, 3 tables", "summary": "Computing fixed-radius near-neighbor graphs is an important first step for\nmany data analysis algorithms. Near-neighbor graphs connect points that are\nclose under some metric, endowing point clouds with a combinatorial structure.\nAs computing power and data acquisition methods advance, diverse sources of\nlarge scientific datasets would greatly benefit from scalable solutions to this\ncommon subroutine for downstream analysis. Prior work on parallel nearest\nneighbors has made great progress in problems like k-nearest and approximate\nnearest neighbor search problems, with particular attention on Euclidean\nspaces. Yet many applications need exact solutions and non-Euclidean metrics.\nThis paper presents a scalable sparsity-aware distributed memory algorithm\nusing cover trees to compute near-neighbor graphs in general metric spaces. We\nprovide a shared-memory algorithm for cover tree construction and demonstrate\nits competitiveness with state-of-the-art fixed-radius search data structures.\nWe then introduce two distributed-memory algorithms for the near-neighbor graph\nproblem, a simple point-partitioning strategy and a spatial-partitioning\nstrategy, which leverage the cover tree algorithm on each node. Our algorithms\nexhibit parallel scaling across a variety of real and synthetic datasets for\nboth traditional and non-traditional metrics. On real world high dimensional\ndatasets with one million points, we achieve speedups up to 678.34x over the\nstate-of-the-art using 1024 cores for graphs with 70 neighbors per vertex (on\naverage), and up to 1590.99x using 4096 cores for graphs with 500 neighbors per\nvertex (on average).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u5206\u5e03\u5f0f\u5185\u5b58\u7b97\u6cd5\uff0c\u4f7f\u7528\u8986\u76d6\u6811\u8ba1\u7b97\u4e00\u822c\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u7684\u8fd1\u90bb\u56fe\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u9ad8\u7ef4\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe1590.99\u500d\u7684\u52a0\u901f\u3002", "motivation": "\u968f\u7740\u8ba1\u7b97\u80fd\u529b\u548c\u6570\u636e\u91c7\u96c6\u65b9\u6cd5\u7684\u53d1\u5c55\uff0c\u5927\u578b\u79d1\u5b66\u6570\u636e\u96c6\u9700\u8981\u53ef\u6269\u5c55\u7684\u7cbe\u786e\u8fd1\u90bb\u56fe\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u975e\u6b27\u51e0\u91cc\u5f97\u5ea6\u91cf\u7a7a\u95f4\u3002", "method": "\u5f00\u53d1\u4e86\u5171\u4eab\u5185\u5b58\u7684\u8986\u76d6\u6811\u6784\u5efa\u7b97\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u4e24\u79cd\u5206\u5e03\u5f0f\u5185\u5b58\u7b97\u6cd5\uff1a\u7b80\u5355\u7684\u70b9\u5206\u533a\u7b56\u7565\u548c\u7a7a\u95f4\u5206\u533a\u7b56\u7565\uff0c\u5728\u8282\u70b9\u4e0a\u5229\u7528\u8986\u76d6\u6811\u7b97\u6cd5\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u9ad8\u7ef4\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u75281024\u6838\u5fc3\u5bf9\u5e73\u574770\u90bb\u5c45\u7684\u56fe\u5b9e\u73b0\u4e86678.34\u500d\u52a0\u901f\uff0c\u4f7f\u75284096\u6838\u5fc3\u5bf9\u5e73\u5747500\u90bb\u5c45\u7684\u56fe\u5b9e\u73b0\u4e861590.99\u500d\u52a0\u901f\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u5728\u5404\u79cd\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u5c55\u73b0\u51fa\u5e76\u884c\u6269\u5c55\u6027\uff0c\u4e3a\u4f20\u7edf\u548c\u975e\u4f20\u7edf\u5ea6\u91cf\u7a7a\u95f4\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8fd1\u90bb\u56fe\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.14198", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14198", "abs": "https://arxiv.org/abs/2510.14198", "authors": ["Morium Akter Munny", "Mahbub Alam", "Sonjoy Kumar Paul", "Daniel Timko", "Muhammad Lutfor Rahman", "Nitesh Saxena"], "title": "Infrastructure Patterns in Toll Scam Domains: A Comprehensive Analysis of Cybercriminal Registration and Hosting Strategies", "comment": "This paper has been accepted for presentation at eCrime 2025", "summary": "Toll scams involve criminals registering fake domains that pretend to be\nlegitimate transportation agencies to trick users into making fraudulent\npayments. Although these scams are rapidly increasing and causing significant\nharm, they have not been extensively studied. We present the first large-scale\nanalysis of toll scam domains, using a newly created dataset of 67,907\nconfirmed scam domains mostly registered in 2025. Our study reveals that\nattackers exploit permissive registrars and less common top-level domains, with\n86.9% of domains concentrated in just five non-mainstream TLDs and 72.9%\nregistered via a single provider. We also discover specific registration\npatterns, including short bursts of activity that suggest automated,\ncoordinated attacks, with over half of domains registered in the first quarter\nof 2025. This extreme temporal clustering reflects highly synchronized campaign\nlaunches. Additionally, we build a simple predictive model using only domain\nregistration data to predict which scam domains are likely to be suspended -- a\nproxy for confirmed abuse -- achieving 80.4% accuracy, and 92.3% sensitivity.\nOur analysis reveals attacker strategies for evading detection -- such as\nexploiting obscure TLDs, permissive registrars, and coordinated registration\nbursts -- which can inform more targeted interventions by registrars, hosting\nproviders, and security platforms. However, our results suggest that\nregistration metadata alone may be insufficient, and incorporating features\nfrom domain URLs and webpage content could further improve detection.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u6536\u8d39\u8bc8\u9a97\u57df\u540d\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5206\u6790\uff0c\u63ed\u793a\u4e86\u653b\u51fb\u8005\u5229\u7528\u5bbd\u677e\u6ce8\u518c\u5546\u548c\u975e\u4e3b\u6d41\u9876\u7ea7\u57df\u540d\u7684\u7b56\u7565\uff0c\u5e76\u6784\u5efa\u4e86\u57fa\u4e8e\u6ce8\u518c\u6570\u636e\u7684\u9884\u6d4b\u6a21\u578b\u6765\u8bc6\u522b\u53ef\u80fd\u88ab\u6682\u505c\u7684\u8bc8\u9a97\u57df\u540d\u3002", "motivation": "\u6536\u8d39\u8bc8\u9a97\u901a\u8fc7\u6ce8\u518c\u4f2a\u88c5\u6210\u5408\u6cd5\u4ea4\u901a\u673a\u6784\u7684\u865a\u5047\u57df\u540d\u6765\u6b3a\u9a97\u7528\u6237\u8fdb\u884c\u6b3a\u8bc8\u652f\u4ed8\uff0c\u8fd9\u4e9b\u8bc8\u9a97\u6b63\u5728\u8fc5\u901f\u589e\u52a0\u5e76\u9020\u6210\u91cd\u5927\u635f\u5bb3\uff0c\u4f46\u5c1a\u672a\u5f97\u5230\u5e7f\u6cdb\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u65b0\u521b\u5efa\u768467,907\u4e2a\u786e\u8ba4\u8bc8\u9a97\u57df\u540d\u6570\u636e\u96c6\u8fdb\u884c\u5206\u6790\uff0c\u7814\u7a76\u653b\u51fb\u8005\u5229\u7528\u5bbd\u677e\u6ce8\u518c\u5546\u548c\u975e\u4e3b\u6d41\u9876\u7ea7\u57df\u540d\u7684\u6a21\u5f0f\uff0c\u5e76\u6784\u5efa\u57fa\u4e8e\u57df\u6ce8\u518c\u6570\u636e\u7684\u9884\u6d4b\u6a21\u578b\u3002", "result": "\u53d1\u73b086.9%\u7684\u57df\u540d\u96c6\u4e2d\u5728\u4e94\u4e2a\u975e\u4e3b\u6d41\u9876\u7ea7\u57df\u540d\uff0c72.9%\u901a\u8fc7\u5355\u4e00\u63d0\u4f9b\u5546\u6ce8\u518c\uff0c\u5b58\u5728\u660e\u663e\u7684\u6ce8\u518c\u6a21\u5f0f\u548c\u65f6\u95f4\u805a\u7c7b\u3002\u9884\u6d4b\u6a21\u578b\u8fbe\u523080.4%\u51c6\u786e\u7387\u548c92.3%\u7075\u654f\u5ea6\u3002", "conclusion": "\u5206\u6790\u63ed\u793a\u4e86\u653b\u51fb\u8005\u9003\u907f\u68c0\u6d4b\u7684\u7b56\u7565\uff0c\u53ef\u4ee5\u4e3a\u6ce8\u518c\u5546\u3001\u6258\u7ba1\u63d0\u4f9b\u5546\u548c\u5b89\u5168\u5e73\u53f0\u63d0\u4f9b\u66f4\u6709\u9488\u5bf9\u6027\u7684\u5e72\u9884\u63aa\u65bd\uff0c\u4f46\u4ec5\u4f9d\u9760\u6ce8\u518c\u5143\u6570\u636e\u53ef\u80fd\u4e0d\u8db3\uff0c\u9700\u8981\u7ed3\u5408URL\u548c\u7f51\u9875\u5185\u5bb9\u7279\u5f81\u6765\u6539\u8fdb\u68c0\u6d4b\u3002"}}
{"id": "2510.14186", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.14186", "abs": "https://arxiv.org/abs/2510.14186", "authors": ["Pengkun Ren", "Hai Dong", "Nasrin Sohrabi", "Zahir Tari", "Pengcheng Zhang"], "title": "Proof-Carrying Fair Ordering: Asymmetric Verification for BFT via Incremental Graphs", "comment": "18 pages, 4 figures", "summary": "Byzantine Fault-Tolerant (BFT) consensus protocols ensure agreement on\ntransaction ordering despite malicious actors, but unconstrained ordering power\nenables sophisticated value extraction attacks like front running and sandwich\nattacks - a critical threat to blockchain systems. Order-fair consensus curbs\nadversarial value extraction by constraining how leaders may order\ntransactions. While state-of-the-art protocols such as Themis attain strong\nguarantees through graph-based ordering, they ask every replica to re-run the\nleader's expensive ordering computation for validation - an inherently\nsymmetric and redundant paradigm. We present AUTIG, a high-performance,\npluggable order-fairness service that breaks this symmetry. Our key insight is\nthat verifying a fair order does not require re-computing it. Instead,\nverification can be reduced to a stateless audit of succinct, verifiable\nassertions about the ordering graph's properties. AUTIG realizes this via an\nasymmetric architecture: the leader maintains a persistent\nUnconfirmed-Transaction Incremental Graph (UTIG) to amortize graph construction\nacross rounds and emits a structured proof of fairness with each proposal;\nfollowers validate the proof without maintaining historical state. AUTIG\nintroduces three critical innovations: (i) incremental graph maintenance driven\nby threshold-crossing events and state changes; (ii) a decoupled pipeline that\noverlaps leader-side collection/update/extraction with follower-side stateless\nverification; and (iii) a proof design covering all internal pairs in the\nfinalized prefix plus a frontier completeness check to rule out hidden external\ndependencies. We implement AUTIG and evaluate it against symmetric graph-based\nbaselines under partial synchrony. Experiments show higher throughput and lower\nend-to-end latency while preserving gamma-batch-order-fairness.", "AI": {"tldr": "AUTIG\u662f\u4e00\u4e2a\u9ad8\u6027\u80fd\u3001\u53ef\u63d2\u62d4\u7684\u516c\u5e73\u6392\u5e8f\u670d\u52a1\uff0c\u901a\u8fc7\u975e\u5bf9\u79f0\u67b6\u6784\u89e3\u51b3BFT\u5171\u8bc6\u4e2d\u5bf9\u79f0\u5197\u4f59\u7684\u516c\u5e73\u6392\u5e8f\u9a8c\u8bc1\u95ee\u9898\u3002\u5b83\u8ba9\u9886\u5bfc\u8005\u7ef4\u62a4\u589e\u91cf\u56fe\u5e76\u751f\u6210\u516c\u5e73\u6027\u8bc1\u660e\uff0c\u8ddf\u968f\u8005\u53ea\u9700\u9a8c\u8bc1\u8bc1\u660e\u800c\u65e0\u9700\u91cd\u65b0\u8ba1\u7b97\u6392\u5e8f\u3002", "motivation": "\u73b0\u6709\u7684\u516c\u5e73\u6392\u5e8f\u5171\u8bc6\u534f\u8bae\uff08\u5982Themis\uff09\u8981\u6c42\u6bcf\u4e2a\u526f\u672c\u91cd\u65b0\u8fd0\u884c\u9886\u5bfc\u8005\u6602\u8d35\u7684\u6392\u5e8f\u8ba1\u7b97\u8fdb\u884c\u9a8c\u8bc1\uff0c\u8fd9\u79cd\u5bf9\u79f0\u5197\u4f59\u8303\u5f0f\u6548\u7387\u4f4e\u4e0b\u3002AUTIG\u65e8\u5728\u6253\u7834\u8fd9\u79cd\u5bf9\u79f0\u6027\uff0c\u63d0\u9ad8\u6027\u80fd\u3002", "method": "\u91c7\u7528\u975e\u5bf9\u79f0\u67b6\u6784\uff1a\u9886\u5bfc\u8005\u7ef4\u62a4\u6301\u4e45\u5316\u7684\u672a\u786e\u8ba4\u4ea4\u6613\u589e\u91cf\u56fe\uff08UTIG\uff09\u5e76\u751f\u6210\u7ed3\u6784\u5316\u516c\u5e73\u6027\u8bc1\u660e\uff1b\u8ddf\u968f\u8005\u9a8c\u8bc1\u8bc1\u660e\u800c\u65e0\u9700\u7ef4\u62a4\u5386\u53f2\u72b6\u6001\u3002\u5173\u952e\u521b\u65b0\u5305\u62ec\u589e\u91cf\u56fe\u7ef4\u62a4\u3001\u89e3\u8026\u6d41\u6c34\u7ebf\u548c\u8986\u76d6\u5185\u90e8\u5bf9\u53ca\u8fb9\u754c\u5b8c\u6574\u6027\u7684\u8bc1\u660e\u8bbe\u8ba1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u90e8\u5206\u540c\u6b65\u6761\u4ef6\u4e0b\uff0cAUTIG\u76f8\u6bd4\u5bf9\u79f0\u56fe\u57fa\u7ebf\u5177\u6709\u66f4\u9ad8\u7684\u541e\u5410\u91cf\u548c\u66f4\u4f4e\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\uff0c\u540c\u65f6\u4fdd\u6301gamma-batch-order-fairness\u4fdd\u8bc1\u3002", "conclusion": "AUTIG\u901a\u8fc7\u5c06\u516c\u5e73\u6392\u5e8f\u9a8c\u8bc1\u7b80\u5316\u4e3a\u5bf9\u6392\u5e8f\u56fe\u5c5e\u6027\u7684\u65e0\u72b6\u6001\u5ba1\u8ba1\uff0c\u6210\u529f\u6253\u7834\u4e86\u5bf9\u79f0\u5197\u4f59\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u7684\u516c\u5e73\u6392\u5e8f\u670d\u52a1\u3002"}}
{"id": "2510.14283", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14283", "abs": "https://arxiv.org/abs/2510.14283", "authors": ["Xinhao Deng", "Jingyou Chen", "Linxiao Yu", "Yixiang Zhang", "Zhongyi Gu", "Changhao Qiu", "Xiyuan Zhao", "Ke Xu", "Qi Li"], "title": "Beyond a Single Perspective: Towards a Realistic Evaluation of Website Fingerprinting Attacks", "comment": null, "summary": "Website Fingerprinting (WF) attacks exploit patterns in encrypted traffic to\ninfer the websites visited by users, posing a serious threat to anonymous\ncommunication systems. Although recent WF techniques achieve over 90% accuracy\nin controlled experimental settings, most studies remain confined to single\nscenarios, overlooking the complexity of real-world environments. This paper\npresents the first systematic and comprehensive evaluation of existing WF\nattacks under diverse realistic conditions, including defense mechanisms,\ntraffic drift, multi-tab browsing, early-stage detection, open-world settings,\nand few-shot scenarios. Experimental results show that many WF techniques with\nstrong performance in isolated settings degrade significantly when facing other\nconditions. Since real-world environments often combine multiple challenges,\ncurrent WF attacks are difficult to apply directly in practice. This study\nhighlights the limitations of WF attacks and introduces a multidimensional\nevaluation framework, offering critical insights for developing more robust and\npractical WF attacks.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u4e86\u7f51\u7ad9\u6307\u7eb9\u8bc6\u522b\u653b\u51fb\u5728\u591a\u79cd\u73b0\u5b9e\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u8bb8\u591a\u5728\u5b64\u7acb\u73af\u5883\u4e2d\u8868\u73b0\u826f\u597d\u7684\u6280\u672f\u5728\u9762\u5bf9\u9632\u5fa1\u673a\u5236\u3001\u6d41\u91cf\u6f02\u79fb\u3001\u591a\u6807\u7b7e\u6d4f\u89c8\u7b49\u590d\u6742\u60c5\u51b5\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "motivation": "\u5f53\u524d\u7f51\u7ad9\u6307\u7eb9\u8bc6\u522b\u653b\u51fb\u7814\u7a76\u5927\u591a\u5c40\u9650\u4e8e\u5355\u4e00\u573a\u666f\uff0c\u5ffd\u7565\u4e86\u73b0\u5b9e\u73af\u5883\u7684\u590d\u6742\u6027\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u8fd9\u4e9b\u6280\u672f\u5728\u591a\u6837\u5316\u73b0\u5b9e\u6761\u4ef6\u4e0b\u7684\u5b9e\u9645\u8868\u73b0\u3002", "method": "\u91c7\u7528\u591a\u7ef4\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u5305\u62ec\u9632\u5fa1\u673a\u5236\u3001\u6d41\u91cf\u6f02\u79fb\u3001\u591a\u6807\u7b7e\u6d4f\u89c8\u3001\u65e9\u671f\u68c0\u6d4b\u3001\u5f00\u653e\u4e16\u754c\u548c\u5c11\u6837\u672c\u573a\u666f\u7b49\u591a\u79cd\u73b0\u5b9e\u6761\u4ef6\u4e0b\u6d4b\u8bd5\u73b0\u6709WF\u653b\u51fb\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8bb8\u591a\u5728\u5b64\u7acb\u8bbe\u7f6e\u4e2d\u8868\u73b0\u4f18\u5f02\u7684WF\u6280\u672f\u5728\u9762\u5bf9\u5176\u4ed6\u6761\u4ef6\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u7531\u4e8e\u73b0\u5b9e\u73af\u5883\u5f80\u5f80\u7ed3\u5408\u591a\u79cd\u6311\u6218\uff0c\u5f53\u524dWF\u653b\u51fb\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8e\u5b9e\u8df5\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86WF\u653b\u51fb\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u591a\u7ef4\u8bc4\u4f30\u6846\u67b6\uff0c\u4e3a\u5f00\u53d1\u66f4\u7a33\u5065\u548c\u5b9e\u7528\u7684WF\u653b\u51fb\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2510.14599", "categories": ["cs.DC", "D.4.1; C.4; C.1.4; D.1.3"], "pdf": "https://arxiv.org/pdf/2510.14599", "abs": "https://arxiv.org/abs/2510.14599", "authors": ["Michal Konopa", "Jan Fesl", "Ladislav Ber \u00e1nek"], "title": "JASDA: Introducing Job-Aware Scheduling in Scheduler-Driven Job Atomization", "comment": "25 pages", "summary": "The increasing complexity and temporal variability of workloads on\nMIG-enabled GPUs challenge the scalability of traditional centralized\nscheduling. Building upon the SJA concept, this paper introduces JASDA-a novel\nparadigm that extends SJA from a largely centralized scheduling model toward a\nfully decentralized negotiation process. In JASDA, jobs actively generate and\nscore feasible subjobs in response to scheduler-announced execution windows,\nwhile the scheduler performs policy-driven clearing that balances utilization,\nfairness, and temporal responsiveness. This bidirectional, iterative\ninteraction embeds feedback, calibration, and probabilistic safety directly\ninto the scheduling loop, enabling adaptive and transparent decision-making. By\ncoupling principles from auction theory and online optimization with the\ntemporal granularity of GPU workloads, JASDA provides a scalable foundation for\nmarket-aware and fairness-driven resource management-bridging theoretical\nscheduling models with practical deployment in modern MIG-enabled environments\nrelevant to Artificial Intelligence and Agriculture 4.0.", "AI": {"tldr": "JASDA\u662f\u4e00\u4e2a\u57fa\u4e8e\u62cd\u5356\u7406\u8bba\u548c\u5728\u7ebf\u4f18\u5316\u7684\u53bb\u4e2d\u5fc3\u5316GPU\u8c03\u5ea6\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5411\u8fed\u4ee3\u4ea4\u4e92\u5b9e\u73b0\u81ea\u9002\u5e94\u8d44\u6e90\u7ba1\u7406\uff0c\u9002\u7528\u4e8eMIG-enabled GPU\u73af\u5883\u3002", "motivation": "\u4f20\u7edf\u96c6\u4e2d\u5f0f\u8c03\u5ea6\u5728MIG-enabled GPU\u4e0a\u96be\u4ee5\u5e94\u5bf9\u5de5\u4f5c\u8d1f\u8f7d\u7684\u590d\u6742\u6027\u548c\u65f6\u53d8\u6027\uff0c\u9700\u8981\u66f4\u53ef\u6269\u5c55\u7684\u8c03\u5ea6\u65b9\u6848\u3002", "method": "\u6269\u5c55SJA\u6982\u5ff5\uff0c\u91c7\u7528\u53bb\u4e2d\u5fc3\u5316\u534f\u5546\u8fc7\u7a0b\uff1a\u4f5c\u4e1a\u4e3b\u52a8\u751f\u6210\u548c\u8bc4\u5206\u53ef\u884c\u5b50\u4f5c\u4e1a\uff0c\u8c03\u5ea6\u5668\u6267\u884c\u7b56\u7565\u9a71\u52a8\u7684\u6e05\u7b97\uff0c\u5e73\u8861\u5229\u7528\u7387\u3001\u516c\u5e73\u6027\u548c\u65f6\u95f4\u54cd\u5e94\u6027\u3002", "result": "\u901a\u8fc7\u5d4c\u5165\u53cd\u9988\u3001\u6821\u51c6\u548c\u6982\u7387\u5b89\u5168\u6027\u7684\u53cc\u5411\u8fed\u4ee3\u4ea4\u4e92\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u548c\u900f\u660e\u7684\u51b3\u7b56\u5236\u5b9a\u3002", "conclusion": "JASDA\u4e3a\u5e02\u573a\u611f\u77e5\u548c\u516c\u5e73\u9a71\u52a8\u7684\u8d44\u6e90\u7ba1\u7406\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u57fa\u7840\uff0c\u8fde\u63a5\u7406\u8bba\u8c03\u5ea6\u6a21\u578b\u4e0e\u73b0\u4ee3MIG-enabled\u73af\u5883\u7684\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2510.14344", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14344", "abs": "https://arxiv.org/abs/2510.14344", "authors": ["Zichen Liu", "Shao Yang", "Xusheng Xiao"], "title": "BinCtx: Multi-Modal Representation Learning for Robust Android App Behavior Detection", "comment": null, "summary": "Mobile app markets host millions of apps, yet undesired behaviors (e.g.,\ndisruptive ads, illegal redirection, payment deception) remain hard to catch\nbecause they often do not rely on permission-protected APIs and can be easily\ncamouflaged via UI or metadata edits. We present BINCTX, a learning approach\nthat builds multi-modal representations of an app from (i) a global\nbytecode-as-image view that captures code-level semantics and family-style\npatterns, (ii) a contextual view (manifested actions, components, declared\npermissions, URL/IP constants) indicating how behaviors are triggered, and\n(iii) a third-party-library usage view summarizing invocation frequencies along\ninter-component call paths. The three views are embedded and fused to train a\ncontextual-aware classifier. On real-world malware and benign apps, BINCTX\nattains a macro F1 of 94.73%, outperforming strong baselines by at least\n14.92%. It remains robust under commercial obfuscation (F1 84%\npost-obfuscation) and is more resistant to adversarial samples than\nstate-of-the-art bytecode-only systems.", "AI": {"tldr": "BINCTX\u662f\u4e00\u79cd\u591a\u6a21\u6001\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u5b57\u8282\u7801\u56fe\u50cf\u89c6\u56fe\u3001\u4e0a\u4e0b\u6587\u89c6\u56fe\u548c\u7b2c\u4e09\u65b9\u5e93\u4f7f\u7528\u89c6\u56fe\u6765\u68c0\u6d4b\u79fb\u52a8\u5e94\u7528\u4e2d\u7684\u4e0d\u826f\u884c\u4e3a\uff0c\u5728\u771f\u5b9e\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e2d\u8fbe\u523094.73%\u7684F1\u5206\u6570\uff0c\u5bf9\u6df7\u6dc6\u548c\u5bf9\u6297\u6837\u672c\u5177\u6709\u9c81\u68d2\u6027\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u5e02\u573a\u4e2d\u5b58\u5728\u5927\u91cf\u4e0d\u826f\u884c\u4e3a\uff08\u5982\u5e72\u6270\u6027\u5e7f\u544a\u3001\u975e\u6cd5\u91cd\u5b9a\u5411\u3001\u652f\u4ed8\u6b3a\u9a97\uff09\uff0c\u8fd9\u4e9b\u884c\u4e3a\u901a\u5e38\u4e0d\u4f9d\u8d56\u6743\u9650\u4fdd\u62a4\u7684API\uff0c\u4e14\u5bb9\u6613\u901a\u8fc7UI\u6216\u5143\u6570\u636e\u7f16\u8f91\u8fdb\u884c\u4f2a\u88c5\uff0c\u96be\u4ee5\u68c0\u6d4b\u3002", "method": "\u6784\u5efa\u5e94\u7528\u7684\u591a\u6a21\u6001\u8868\u793a\uff1a1\uff09\u5168\u5c40\u5b57\u8282\u7801\u56fe\u50cf\u89c6\u56fe\u6355\u6349\u4ee3\u7801\u8bed\u4e49\u548c\u5bb6\u65cf\u6a21\u5f0f\uff1b2\uff09\u4e0a\u4e0b\u6587\u89c6\u56fe\uff08\u6e05\u5355\u64cd\u4f5c\u3001\u7ec4\u4ef6\u3001\u58f0\u660e\u6743\u9650\u3001URL/IP\u5e38\u91cf\uff09\u663e\u793a\u884c\u4e3a\u89e6\u53d1\u65b9\u5f0f\uff1b3\uff09\u7b2c\u4e09\u65b9\u5e93\u4f7f\u7528\u89c6\u56fe\u603b\u7ed3\u7ec4\u4ef6\u95f4\u8c03\u7528\u8def\u5f84\u7684\u8c03\u7528\u9891\u7387\u3002\u4e09\u4e2a\u89c6\u56fe\u5d4c\u5165\u5e76\u878d\u5408\u4ee5\u8bad\u7ec3\u4e0a\u4e0b\u6587\u611f\u77e5\u5206\u7c7b\u5668\u3002", "result": "\u5728\u771f\u5b9e\u6076\u610f\u8f6f\u4ef6\u548c\u826f\u6027\u5e94\u7528\u4e0a\uff0cBINCTX\u8fbe\u523094.73%\u7684\u5b8fF1\u5206\u6570\uff0c\u6bd4\u5f3a\u57fa\u7ebf\u81f3\u5c11\u9ad8\u51fa14.92%\u3002\u5728\u5546\u4e1a\u6df7\u6dc6\u540e\u4ecd\u4fdd\u630184%\u7684F1\u5206\u6570\uff0c\u6bd4\u6700\u5148\u8fdb\u7684\u4ec5\u5b57\u8282\u7801\u7cfb\u7edf\u66f4\u80fd\u62b5\u6297\u5bf9\u6297\u6837\u672c\u3002", "conclusion": "BINCTX\u901a\u8fc7\u591a\u6a21\u6001\u8868\u793a\u6709\u6548\u68c0\u6d4b\u79fb\u52a8\u5e94\u7528\u4e2d\u7684\u4e0d\u826f\u884c\u4e3a\uff0c\u5bf9\u6df7\u6dc6\u548c\u5bf9\u6297\u653b\u51fb\u5177\u6709\u9c81\u68d2\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2510.14622", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.14622", "abs": "https://arxiv.org/abs/2510.14622", "authors": ["Miryeong Kwon", "Donghyun Gouk", "Hyein Woo", "Junhee Kim", "Jinwoo Baek", "Kyungkuk Nam", "Sangyoon Ji", "Jiseon Kim", "Hanyeoreum Bae", "Junhyeok Jang", "Hyunwoo You", "Junseok Moon", "Myoungsoo Jung"], "title": "MPI-over-CXL: Enhancing Communication Efficiency in Distributed HPC Systems", "comment": null, "summary": "MPI implementations commonly rely on explicit memory-copy operations,\nincurring overhead from redundant data movement and buffer management. This\noverhead notably impacts HPC workloads involving intensive inter-processor\ncommunication. In response, we introduce MPI-over-CXL, a novel MPI\ncommunication paradigm leveraging CXL, which provides cache-coherent shared\nmemory across multiple hosts. MPI-over-CXL replaces traditional data-copy\nmethods with direct shared memory access, significantly reducing communication\nlatency and memory bandwidth usage. By mapping shared memory regions directly\ninto the virtual address spaces of MPI processes, our design enables efficient\npointer-based communication, eliminating redundant copying operations. To\nvalidate this approach, we implement a comprehensive hardware and software\nenvironment, including a custom CXL 3.2 controller, FPGA-based multi-host\nemulation, and dedicated software stack. Our evaluations using representative\nbenchmarks demonstrate substantial performance improvements over conventional\nMPI systems, underscoring MPI-over-CXL's potential to enhance efficiency and\nscalability in large-scale HPC environments.", "AI": {"tldr": "MPI-over-CXL\u662f\u4e00\u79cd\u5229\u7528CXL\u6280\u672f\u7684\u65b0\u578bMPI\u901a\u4fe1\u8303\u5f0f\uff0c\u901a\u8fc7\u5171\u4eab\u5185\u5b58\u8bbf\u95ee\u66ff\u4ee3\u4f20\u7edf\u6570\u636e\u590d\u5236\u64cd\u4f5c\uff0c\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u5ef6\u8fdf\u548c\u5185\u5b58\u5e26\u5bbd\u4f7f\u7528\u3002", "motivation": "\u4f20\u7edfMPI\u5b9e\u73b0\u4f9d\u8d56\u663e\u5f0f\u5185\u5b58\u590d\u5236\u64cd\u4f5c\uff0c\u5bfc\u81f4\u5197\u4f59\u6570\u636e\u79fb\u52a8\u548c\u7f13\u51b2\u533a\u7ba1\u7406\u5f00\u9500\uff0c\u4e25\u91cd\u5f71\u54cd\u9ad8\u6027\u80fd\u8ba1\u7b97\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7684\u5904\u7406\u5668\u95f4\u901a\u4fe1\u6548\u7387\u3002", "method": "\u5229\u7528CXL\u63d0\u4f9b\u7684\u8de8\u591a\u4e3b\u673a\u7f13\u5b58\u4e00\u81f4\u6027\u5171\u4eab\u5185\u5b58\uff0c\u5c06\u5171\u4eab\u5185\u5b58\u533a\u57df\u76f4\u63a5\u6620\u5c04\u5230MPI\u8fdb\u7a0b\u7684\u865a\u62df\u5730\u5740\u7a7a\u95f4\uff0c\u5b9e\u73b0\u57fa\u4e8e\u6307\u9488\u7684\u9ad8\u6548\u901a\u4fe1\uff0c\u6d88\u9664\u5197\u4f59\u590d\u5236\u64cd\u4f5c\u3002", "result": "\u4f7f\u7528\u4ee3\u8868\u6027\u57fa\u51c6\u6d4b\u8bd5\u8fdb\u884c\u8bc4\u4f30\uff0c\u76f8\u6bd4\u4f20\u7edfMPI\u7cfb\u7edf\u663e\u793a\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "MPI-over-CXL\u6709\u6f5c\u529b\u5728\u5927\u89c4\u6a21HPC\u73af\u5883\u4e2d\u63d0\u9ad8\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2510.14384", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14384", "abs": "https://arxiv.org/abs/2510.14384", "authors": ["Sebastian J\u00e4nich", "Merlin Sievers", "Johannes Kinder"], "title": "Match & Mend: Minimally Invasive Local Reassembly for Patching N-day Vulnerabilities in ARM Binaries", "comment": null, "summary": "Low-cost Internet of Things (IoT) devices are increasingly popular but often\ninsecure due to poor update regimes. As a result, many devices run outdated and\nknown-vulnerable versions of open-source software. We address this problem by\nproposing to patch IoT firmware at the binary level, without requiring vendor\nsupport. In particular, we introduce minimally invasive local reassembly, a new\ntechnique for automatically patching known (n-day) vulnerabilities in IoT\nfirmware. Our approach is designed to minimize side effects and reduce the risk\nof introducing breaking changes. We systematically evaluate our approach both\non 108 binaries within the controlled environment of the MAGMA benchmarks, as\nwell as on 30 real-world Linux-based IoT firmware images from the KARONTE\ndataset. Our prototype successfully patches 83% of targeted vulnerabilities in\nMAGMA and 96% in the firmware dataset.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u6700\u5c0f\u4fb5\u5165\u6027\u672c\u5730\u91cd\u6c47\u7f16\u7684\u6280\u672f\uff0c\u7528\u4e8e\u5728\u4e8c\u8fdb\u5236\u7ea7\u522b\u81ea\u52a8\u4fee\u8865IoT\u56fa\u4ef6\u4e2d\u7684\u5df2\u77e5\u6f0f\u6d1e\uff0c\u65e0\u9700\u5382\u5546\u652f\u6301\u3002", "motivation": "\u4f4e\u6210\u672cIoT\u8bbe\u5907\u7531\u4e8e\u66f4\u65b0\u673a\u5236\u4e0d\u5b8c\u5584\u800c\u5b58\u5728\u5b89\u5168\u9690\u60a3\uff0c\u8bb8\u591a\u8bbe\u5907\u8fd0\u884c\u7740\u8fc7\u65f6\u4e14\u5df2\u77e5\u5b58\u5728\u6f0f\u6d1e\u7684\u5f00\u6e90\u8f6f\u4ef6\u7248\u672c\u3002", "method": "\u91c7\u7528\u6700\u5c0f\u4fb5\u5165\u6027\u672c\u5730\u91cd\u6c47\u7f16\u6280\u672f\uff0c\u5728\u4e8c\u8fdb\u5236\u7ea7\u522b\u81ea\u52a8\u4fee\u8865\u5df2\u77e5\u6f0f\u6d1e\uff0c\u65e8\u5728\u6700\u5c0f\u5316\u526f\u4f5c\u7528\u5e76\u964d\u4f4e\u5f15\u5165\u7834\u574f\u6027\u53d8\u66f4\u7684\u98ce\u9669\u3002", "result": "\u5728MAGMA\u57fa\u51c6\u6d4b\u8bd5\u7684108\u4e2a\u4e8c\u8fdb\u5236\u6587\u4ef6\u4e2d\u6210\u529f\u4fee\u886583%\u7684\u76ee\u6807\u6f0f\u6d1e\uff0c\u5728KARONTE\u6570\u636e\u96c6\u768430\u4e2a\u771f\u5b9e\u4e16\u754cLinux IoT\u56fa\u4ef6\u4e2d\u6210\u529f\u4fee\u886596%\u7684\u6f0f\u6d1e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u81ea\u52a8\u4fee\u8865IoT\u56fa\u4ef6\u4e2d\u7684\u5df2\u77e5\u6f0f\u6d1e\uff0c\u4e3a\u7f3a\u4e4f\u5382\u5546\u652f\u6301\u7684IoT\u8bbe\u5907\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u5b89\u5168\u66f4\u65b0\u65b9\u6848\u3002"}}
{"id": "2510.14686", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14686", "abs": "https://arxiv.org/abs/2510.14686", "authors": ["Tongxuan Liu", "Tao Peng", "Peijun Yang", "Xiaoyang Zhao", "Xiusheng Lu", "Weizhe Huang", "Zirui Liu", "Xiaoyu Chen", "Zhiwei Liang", "Jun Xiong", "Donghe Jin", "Minchao Zhang", "Jinrong Guo", "Yingxu Deng", "Xu Zhang", "Xianzhe Dong", "Siqi Wang", "Siyu Wu", "Yu Wu", "Zihan Tang", "Yuting Zeng", "Yanshu Wang", "Jinguang Liu", "Meng Kang", "Menxin Li", "Yunlong Wang", "Yiming Liu", "Xiaolong Ma", "Yifan Wang", "Yichen Zhang", "Jinrun Yin", "Keyang Zheng", "Jiawei Yin", "Jun Zhang", "Ziyue Wang", "Xiaobo Lin", "Liangyu Liu", "Liwei Lan", "Yang Liu", "Chunhua Peng", "Han Liu", "Songcheng Ren", "Xuezhu Wang", "Yunheng Shen", "Yi Wang", "Guyue Liu", "Hui Chen", "Tong Yang", "Hailong Yang", "Jing Li", "Guiguang Ding", "Ke Zhang"], "title": "xLLM Technical Report", "comment": "39 pages", "summary": "We introduce xLLM, an intelligent and efficient Large Language Model (LLM)\ninference framework designed for high-performance, large-scale enterprise-grade\nserving, with deep optimizations for diverse AI accelerators. To address these\nchallenges, xLLM builds a novel decoupled service-engine architecture. At the\nservice layer, xLLM-Service features an intelligent scheduling module that\nefficiently processes multimodal requests and co-locates online and offline\ntasks through unified elastic scheduling to maximize cluster utilization. This\nmodule also relies on a workload-adaptive dynamic Prefill-Decode (PD)\ndisaggregation policy and a novel Encode-Prefill-Decode (EPD) disaggregation\npolicy designed for multimodal inputs. Furthermore, it incorporates a\ndistributed architecture to provide global KV Cache management and robust\nfault-tolerant capabilities for high availability. At the engine layer,\nxLLM-Engine co-optimizes system and algorithm designs to fully saturate\ncomputing resources. This is achieved through comprehensive multi-layer\nexecution pipeline optimizations, an adaptive graph mode and an xTensor memory\nmanagement. xLLM-Engine also further integrates algorithmic enhancements such\nas optimized speculative decoding and dynamic EPLB, collectively serving to\nsubstantially boost throughput and inference efficiency. Extensive evaluations\ndemonstrate that xLLM delivers significantly superior performance and resource\nefficiency. Under identical TPOT constraints, xLLM achieves throughput up to\n1.7x that of MindIE and 2.2x that of vLLM-Ascend with Qwen-series models, while\nmaintaining an average throughput of 1.7x that of MindIE with Deepseek-series\nmodels. xLLM framework is publicly available at\nhttps://github.com/jd-opensource/xllm and\nhttps://github.com/jd-opensource/xllm-service.", "AI": {"tldr": "xLLM\u662f\u4e00\u4e2a\u9ad8\u6548\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6846\u67b6\uff0c\u91c7\u7528\u89e3\u8026\u7684\u670d\u52a1-\u5f15\u64ce\u67b6\u6784\uff0c\u901a\u8fc7\u667a\u80fd\u8c03\u5ea6\u3001\u5206\u5e03\u5f0fKV\u7f13\u5b58\u7ba1\u7406\u548c\u591a\u5c42\u7ea7\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u541e\u5410\u91cf\u548c\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u89c4\u6a21\u4f01\u4e1a\u7ea7LLM\u670d\u52a1\u4e2d\u7684\u6027\u80fd\u74f6\u9888\u548c\u8d44\u6e90\u5229\u7528\u6548\u7387\u95ee\u9898\uff0c\u9700\u8981\u8bbe\u8ba1\u4e00\u4e2a\u80fd\u591f\u5145\u5206\u5229\u7528AI\u52a0\u901f\u5668\u7684\u9ad8\u6027\u80fd\u63a8\u7406\u6846\u67b6\u3002", "method": "\u6784\u5efa\u89e3\u8026\u7684\u670d\u52a1-\u5f15\u64ce\u67b6\u6784\uff1a\u670d\u52a1\u5c42\u5305\u542b\u667a\u80fd\u8c03\u5ea6\u6a21\u5757\u3001\u52a8\u6001Prefill-Decode\u89e3\u8026\u7b56\u7565\u548cEPD\u89e3\u8026\u7b56\u7565\uff1b\u5f15\u64ce\u5c42\u901a\u8fc7\u591a\u5c42\u7ea7\u6267\u884c\u6d41\u6c34\u7ebf\u4f18\u5316\u3001\u81ea\u9002\u5e94\u56fe\u6a21\u5f0f\u548cxTensor\u5185\u5b58\u7ba1\u7406\u6765\u9971\u548c\u8ba1\u7b97\u8d44\u6e90\u3002", "result": "\u5728\u76f8\u540cTPOT\u7ea6\u675f\u4e0b\uff0cxLLM\u7684\u541e\u5410\u91cf\u8fbe\u5230MindIE\u76841.7\u500d\u548cvLLM-Ascend\u76842.2\u500d\uff08\u4f7f\u7528Qwen\u7cfb\u5217\u6a21\u578b\uff09\uff0c\u4f7f\u7528Deepseek\u7cfb\u5217\u6a21\u578b\u65f6\u5e73\u5747\u541e\u5410\u91cf\u4e3aMindIE\u76841.7\u500d\u3002", "conclusion": "xLLM\u6846\u67b6\u901a\u8fc7\u7cfb\u7edf\u4e0e\u7b97\u6cd5\u7684\u534f\u540c\u4f18\u5316\uff0c\u5728\u5927\u89c4\u6a21\u4f01\u4e1a\u7ea7LLM\u63a8\u7406\u670d\u52a1\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u548c\u8d44\u6e90\u6548\u7387\u4f18\u5316\uff0c\u5df2\u5f00\u6e90\u4f9b\u793e\u533a\u4f7f\u7528\u3002"}}
{"id": "2510.14480", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14480", "abs": "https://arxiv.org/abs/2510.14480", "authors": ["Massimo Bartoletti", "Riccardo Marchesin", "Roberto Zunino"], "title": "Certifying optimal MEV strategies with Lean", "comment": null, "summary": "Maximal Extractable Value (MEV) refers to a class of attacks to decentralized\napplications where the adversary profits by manipulating the ordering,\ninclusion, or exclusion of transactions in a blockchain. Decentralized Finance\n(DeFi) protocols are a primary target of these attacks, as their logic depends\ncritically on transaction sequencing. To date, MEV attacks have already\nextracted billions of dollars in value, underscoring their systemic impact on\nblockchain security. Verifying the absence of MEV attacks requires determining\nsuitable upper bounds, i.e. proving that no adversarial strategy can extract\nmore value (if any) than expected by protocol designers. This problem is\nnotoriously difficult: the space of adversarial strategies is extremely vast,\nmaking empirical studies and pen-and-paper reasoning insufficiently rigorous.\nIn this paper, we present the first mechanized formalization of MEV in the Lean\ntheorem prover. We introduce a methodology to construct machine-checked proofs\nof MEV bounds, providing correctness guarantees beyond what is possible with\nexisting techniques. To demonstrate the generality of our approach, we model\nand analyse the MEV of two paradigmatic DeFi protocols. Notably, we develop the\nfirst machine-checked proof of the optimality of sandwich attacks in Automated\nMarket Makers, a fundamental DeFi primitive.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5728Lean\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u673a\u68b0\u5316\u5f62\u5f0f\u5316\u4e86MEV\uff08\u6700\u5927\u53ef\u63d0\u53d6\u4ef7\u503c\uff09\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6784\u5efa\u673a\u5668\u68c0\u67e5\u8bc1\u660e\u7684\u65b9\u6cd5\u6765\u9a8c\u8bc1MEV\u4e0a\u754c\uff0c\u5e76\u8bc1\u660e\u4e86\u81ea\u52a8\u5316\u505a\u5e02\u5546\u4e2d\u4e09\u660e\u6cbb\u653b\u51fb\u7684\u6700\u4f18\u6027\u3002", "motivation": "MEV\u653b\u51fb\u5df2\u4ece\u53bb\u4e2d\u5fc3\u5316\u5e94\u7528\u4e2d\u63d0\u53d6\u4e86\u6570\u5341\u4ebf\u7f8e\u5143\u7684\u4ef7\u503c\uff0c\u5bf9\u533a\u5757\u94fe\u5b89\u5168\u4ea7\u751f\u4e86\u7cfb\u7edf\u6027\u5f71\u54cd\u3002\u9a8c\u8bc1MEV\u653b\u51fb\u7684\u7f3a\u5931\u9700\u8981\u786e\u5b9a\u5408\u9002\u7684\u4e0a\u754c\uff0c\u4f46\u8fd9\u4e2a\u95ee\u9898\u975e\u5e38\u56f0\u96be\uff0c\u56e0\u4e3a\u5bf9\u6297\u7b56\u7565\u7a7a\u95f4\u6781\u5176\u5e9e\u5927\uff0c\u7ecf\u9a8c\u7814\u7a76\u548c\u624b\u5de5\u63a8\u7406\u4e0d\u591f\u4e25\u8c28\u3002", "method": "\u5728Lean\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u673a\u68b0\u5316\u5f62\u5f0f\u5316MEV\uff0c\u5f15\u5165\u6784\u5efa\u673a\u5668\u68c0\u67e5\u8bc1\u660e\u7684\u65b9\u6cd5\u8bba\uff0c\u4e3a\u4e24\u4e2a\u5178\u578b\u7684DeFi\u534f\u8bae\u5efa\u6a21\u548c\u5206\u6790MEV\u3002", "result": "\u5f00\u53d1\u4e86\u7b2c\u4e00\u4e2a\u673a\u5668\u68c0\u67e5\u8bc1\u660e\uff0c\u8bc1\u660e\u4e86\u81ea\u52a8\u5316\u505a\u5e02\u5546\u4e2d\u4e09\u660e\u6cbb\u653b\u51fb\u7684\u6700\u4f18\u6027\uff0c\u4e3aMEV\u754c\u9650\u63d0\u4f9b\u4e86\u73b0\u6709\u6280\u672f\u65e0\u6cd5\u5b9e\u73b0\u7684\u6b63\u786e\u6027\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aMEV\u5206\u6790\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u6570\u5b66\u57fa\u7840\uff0c\u80fd\u591f\u8d85\u8d8a\u73b0\u6709\u6280\u672f\u7684\u9650\u5236\uff0c\u4e3aDeFi\u534f\u8bae\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u66f4\u5f3a\u7684\u4fdd\u8bc1\u3002"}}
{"id": "2510.14798", "categories": ["cs.DC", "cs.DS", "math.PR"], "pdf": "https://arxiv.org/pdf/2510.14798", "abs": "https://arxiv.org/abs/2510.14798", "authors": ["Petra Berenbrink", "Tom Friedetzky", "Peter Kling", "Lars Nagel"], "title": "Balls and Bins and the Infinite Process with Random Deletions", "comment": null, "summary": "We consider an infinite balls-into-bins process with deletions where in each\ndiscrete step $t$ a coin is tossed as to whether, with probability $\\beta(t)\n\\in (0,1)$, a new ball is allocated using the Greedy[2] strategy (which places\nthe ball in the lower loaded of two bins sampled uniformly at random) or, with\nremaining probability $1-\\beta(t)$, a ball is deleted from a non-empty bin\nchosen uniformly at random. Let $n$ be the number of bins and $m(t)$ the total\nload at time $t$. We are interested in bounding the discrepancy $x_{\\max}(t) -\nm(t)/n$ (current maximum load relative to current average) and the overload\n$x_{\\max}(t) - m_{\\max}(t)/n$ (current maximum load relative to highest average\nobserved so far).\n  We prove that at an arbitrarily chosen time $t$ the total number of balls\nabove the average is $O(n)$ and that the discrepancy is $ O(\\log(n))$. For the\ndiscrepancy, we provide a matching lower bound. Furthermore we prove that at an\narbitrarily chosen time $t$ the overload is $\\log\\log(n)+O(1)$. For \"good\"\ninsertion probability sequences (in which the average load of time intervals\nwith polynomial length increases in expectation) we show that even the\ndiscrepancy is bounded by $\\log\\log(n)+O(1)$.\n  One of our main analytical tools is a layered induction, as per [ABKU99].\nSince our model allows for rather more general scenarios than what was\npreviously considered, the formal analysis requires some extra ingredients as\nwell, in particular a detailed potential analysis. Furthermore, we simplify the\nsetup by applying probabilistic couplings to obtain certain \"recovery\"\nproperties, which eliminate much of the need for intricate and careful\nconditioning elsewhere in the analysis.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.14522", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14522", "abs": "https://arxiv.org/abs/2510.14522", "authors": ["Evangelos Lamprou", "Julian Dai", "Grigoris Ntousakis", "Martin C. Rinard", "Nikos Vasilakis"], "title": "Lexo: Eliminating Stealthy Supply-Chain Attacks via LLM-Assisted Program Regeneration", "comment": null, "summary": "Software supply-chain attacks are an important and ongoing concern in the\nopen source software ecosystem. These attacks maintain the standard\nfunctionality that a component implements, but additionally hide malicious\nfunctionality activated only when the component reaches its target environment.\nLexo addresses such stealthy attacks by automatically learning and regenerating\nvulnerability-free versions of potentially malicious components. Lexo first\ngenerates a set of input-output pairs to model a component's full observable\nbehavior, which it then uses to synthesize a new version of the original\ncomponent. The new component implements the original functionality but avoids\nstealthy malicious behavior. Throughout this regeneration process, Lexo\nconsults several distinct instances of Large Language Models (LLMs), uses\ncorrectness and coverage metrics to shepherd these instances, and guardrails\ntheir results. Our evaluation on 100+ real-world packages, including high\nprofile stealthy supply-chain attacks, indicates that Lexo scales across\nmultiple domains, regenerates code efficiently (<100s on average), maintains\ncompatibility, and succeeds in eliminating malicious code in several real-world\nsupply-chain-attacks, even in cases when a state-of-the-art LLM fails to\neliminate malicious code when prompted to do so.", "AI": {"tldr": "Lexo\u662f\u4e00\u4e2a\u81ea\u52a8\u5b66\u4e60\u548c\u91cd\u65b0\u751f\u6210\u65e0\u6f0f\u6d1e\u7248\u672c\u7684\u6f5c\u5728\u6076\u610f\u7ec4\u4ef6\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u9632\u5fa1\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u3002\u5b83\u901a\u8fc7\u751f\u6210\u8f93\u5165-\u8f93\u51fa\u5bf9\u6765\u5efa\u6a21\u7ec4\u4ef6\u884c\u4e3a\uff0c\u7136\u540e\u5408\u6210\u65b0\u7248\u672c\u7ec4\u4ef6\uff0c\u4fdd\u6301\u539f\u6709\u529f\u80fd\u4f46\u907f\u514d\u6076\u610f\u884c\u4e3a\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u662f\u4e00\u4e2a\u6301\u7eed\u5173\u6ce8\u7684\u91cd\u8981\u95ee\u9898\uff0c\u8fd9\u4e9b\u653b\u51fb\u5728\u4fdd\u6301\u7ec4\u4ef6\u6807\u51c6\u529f\u80fd\u7684\u540c\u65f6\u9690\u85cf\u6076\u610f\u529f\u80fd\uff0c\u4ec5\u5728\u76ee\u6807\u73af\u5883\u4e2d\u6fc0\u6d3b\u3002", "method": "Lexo\u9996\u5148\u751f\u6210\u4e00\u7ec4\u8f93\u5165-\u8f93\u51fa\u5bf9\u6765\u5efa\u6a21\u7ec4\u4ef6\u7684\u5b8c\u6574\u53ef\u89c2\u5bdf\u884c\u4e3a\uff0c\u7136\u540e\u4f7f\u7528\u8fd9\u4e9b\u6570\u636e\u5408\u6210\u539f\u59cb\u7ec4\u4ef6\u7684\u65b0\u7248\u672c\u3002\u5728\u6574\u4e2a\u91cd\u65b0\u751f\u6210\u8fc7\u7a0b\u4e2d\uff0cLexo\u54a8\u8be2\u591a\u4e2a\u4e0d\u540c\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b9e\u4f8b\uff0c\u4f7f\u7528\u6b63\u786e\u6027\u548c\u8986\u76d6\u7387\u6307\u6807\u6765\u6307\u5bfc\u8fd9\u4e9b\u5b9e\u4f8b\uff0c\u5e76\u4fdd\u62a4\u5176\u7ed3\u679c\u3002", "result": "\u5728100\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u8f6f\u4ef6\u5305\uff08\u5305\u62ec\u9ad8\u77e5\u540d\u5ea6\u7684\u9690\u853d\u4f9b\u5e94\u94fe\u653b\u51fb\uff09\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cLexo\u80fd\u591f\u8de8\u591a\u4e2a\u9886\u57df\u6269\u5c55\uff0c\u5e73\u5747\u5728100\u79d2\u5185\u9ad8\u6548\u91cd\u65b0\u751f\u6210\u4ee3\u7801\uff0c\u4fdd\u6301\u517c\u5bb9\u6027\uff0c\u5e76\u6210\u529f\u6d88\u9664\u4e86\u51e0\u4e2a\u771f\u5b9e\u4e16\u754c\u4f9b\u5e94\u94fe\u653b\u51fb\u4e2d\u7684\u6076\u610f\u4ee3\u7801\uff0c\u5373\u4f7f\u5728\u6700\u5148\u8fdb\u7684LLM\u63d0\u793a\u6d88\u9664\u6076\u610f\u4ee3\u7801\u5931\u8d25\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u6210\u529f\u3002", "conclusion": "Lexo\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u9632\u5fa1\u9690\u853d\u7684\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\uff0c\u901a\u8fc7\u81ea\u52a8\u91cd\u65b0\u751f\u6210\u65e0\u6076\u610f\u4ee3\u7801\u7684\u7ec4\u4ef6\u7248\u672c\uff0c\u5728\u4fdd\u6301\u529f\u80fd\u517c\u5bb9\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u8f6f\u4ef6\u5b89\u5168\u6027\u3002"}}
{"id": "2510.14589", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14589", "abs": "https://arxiv.org/abs/2510.14589", "authors": ["Vaishnavi Sundararajan", "Rithwik"], "title": "Symbolic verification of Apple's Find My location-tracking protocol", "comment": null, "summary": "Tracking devices, while designed to help users find their belongings in case\nof loss/theft, bring in new questions about privacy and surveillance of not\njust their own users, but in the case of crowd-sourced location tracking, even\nthat of others even orthogonally associated with these platforms. Apple's Find\nMy is perhaps the most ubiquitous such system which can even locate devices\nwhich do not possess any cellular support or GPS, running on millions of\ndevices worldwide. Apple claims that this system is private and secure, but the\ncode is proprietary, and such claims have to be taken on faith. It is well\nknown that even with perfect cryptographic guarantees, logical flaws might\ncreep into protocols, and allow undesirable attacks. In this paper, we present\na symbolic model of the Find My protocol, as well as a precise formal\nspecification of desirable properties, and provide automated, machine-checkable\nproofs of these properties in the Tamarin prover.", "AI": {"tldr": "\u672c\u6587\u5bf9\u82f9\u679cFind My\u8ffd\u8e2a\u7cfb\u7edf\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u5b89\u5168\u5206\u6790\uff0c\u901a\u8fc7\u7b26\u53f7\u5efa\u6a21\u548c\u81ea\u52a8\u9a8c\u8bc1\u8bc1\u660e\u4e86\u8be5\u534f\u8bae\u7684\u5b89\u5168\u6027\u5c5e\u6027\u3002", "motivation": "\u82f9\u679cFind My\u7cfb\u7edf\u867d\u7136\u58f0\u79f0\u5b89\u5168\u79c1\u5bc6\uff0c\u4f46\u5176\u4ee3\u7801\u662f\u4e13\u6709\u7684\uff0c\u7528\u6237\u53ea\u80fd\u76f8\u4fe1\u5176\u58f0\u660e\u3002\u5373\u4f7f\u6709\u5b8c\u7f8e\u7684\u5bc6\u7801\u5b66\u4fdd\u8bc1\uff0c\u534f\u8bae\u4e2d\u4ecd\u53ef\u80fd\u5b58\u5728\u903b\u8f91\u6f0f\u6d1e\uff0c\u56e0\u6b64\u9700\u8981\u72ec\u7acb\u9a8c\u8bc1\u5176\u5b89\u5168\u6027\u3002", "method": "\u4f7f\u7528\u7b26\u53f7\u6a21\u578b\u5bf9Find My\u534f\u8bae\u8fdb\u884c\u5efa\u6a21\uff0c\u5236\u5b9a\u7cbe\u786e\u7684\u5f62\u5f0f\u5316\u89c4\u8303\u63cf\u8ff0\u671f\u671b\u7684\u5b89\u5168\u5c5e\u6027\uff0c\u5e76\u5728Tamarin\u8bc1\u660e\u5668\u4e2d\u63d0\u4f9b\u81ea\u52a8\u5316\u7684\u673a\u5668\u53ef\u68c0\u67e5\u8bc1\u660e\u3002", "result": "\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u63d0\u4f9b\u4e86Find My\u534f\u8bae\u5b89\u5168\u5c5e\u6027\u7684\u673a\u5668\u53ef\u68c0\u67e5\u8bc1\u660e\uff0c\u786e\u8ba4\u4e86\u534f\u8bae\u6ee1\u8db3\u6240\u671f\u671b\u7684\u5b89\u5168\u7279\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660eFind My\u534f\u8bae\u5728\u5f62\u5f0f\u5316\u9a8c\u8bc1\u4e0b\u6ee1\u8db3\u5b89\u5168\u8981\u6c42\uff0c\u4e3a\u8fd9\u7c7b\u5e7f\u6cdb\u90e8\u7f72\u7684\u8ffd\u8e2a\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u72ec\u7acb\u9a8c\u8bc1\u3002"}}
{"id": "2510.13858", "categories": ["cs.AI", "I.6.4"], "pdf": "https://arxiv.org/pdf/2510.13858", "abs": "https://arxiv.org/abs/2510.13858", "authors": ["Raheleh Biglari", "Joachim Denil"], "title": "Decision Oriented Technique (DOTechnique): Finding Model Validity Through Decision-Maker Context", "comment": "10 pages", "summary": "Model validity is as critical as the model itself, especially when guiding\ndecision-making processes. Traditional approaches often rely on predefined\nvalidity frames, which may not always be available or sufficient. This paper\nintroduces the Decision Oriented Technique (DOTechnique), a novel method for\ndetermining model validity based on decision consistency rather than output\nsimilarity. By evaluating whether surrogate models lead to equivalent decisions\ncompared to high-fidelity models, DOTechnique enables efficient identification\nof validity regions, even in the absence of explicit validity boundaries. The\napproach integrates domain constraints and symbolic reasoning to narrow the\nsearch space, enhancing computational efficiency. A highway lane change system\nserves as a motivating example, demonstrating how DOTechnique can uncover the\nvalidity region of a simulation model. The results highlight the potential of\nthe technique to support finding model validity through decision-maker context.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51b3\u7b56\u4e00\u81f4\u6027\u7684\u6a21\u578b\u6709\u6548\u6027\u9a8c\u8bc1\u65b9\u6cd5DOTechnique\uff0c\u901a\u8fc7\u8bc4\u4f30\u66ff\u4ee3\u6a21\u578b\u4e0e\u9ad8\u4fdd\u771f\u6a21\u578b\u662f\u5426\u4ea7\u751f\u76f8\u540c\u51b3\u7b56\u6765\u786e\u5b9a\u6a21\u578b\u6709\u6548\u6027\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u6709\u6548\u6027\u8fb9\u754c\u3002", "motivation": "\u6a21\u578b\u6709\u6548\u6027\u5bf9\u51b3\u7b56\u8fc7\u7a0b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u7684\u6709\u6548\u6027\u6846\u67b6\uff0c\u8fd9\u4e9b\u6846\u67b6\u53ef\u80fd\u4e0d\u53ef\u7528\u6216\u4e0d\u5145\u5206\u3002", "method": "DOTechnique\u65b9\u6cd5\u901a\u8fc7\u51b3\u7b56\u4e00\u81f4\u6027\u800c\u975e\u8f93\u51fa\u76f8\u4f3c\u6027\u6765\u8bc4\u4f30\u6a21\u578b\u6709\u6548\u6027\uff0c\u6574\u5408\u9886\u57df\u7ea6\u675f\u548c\u7b26\u53f7\u63a8\u7406\u6765\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u4ee5\u9ad8\u901f\u516c\u8def\u53d8\u9053\u7cfb\u7edf\u4e3a\u4f8b\uff0c\u5c55\u793a\u4e86DOTechnique\u80fd\u591f\u53d1\u73b0\u4eff\u771f\u6a21\u578b\u7684\u6709\u6548\u6027\u533a\u57df\u3002", "conclusion": "\u8be5\u6280\u672f\u6709\u6f5c\u529b\u901a\u8fc7\u51b3\u7b56\u8005\u4e0a\u4e0b\u6587\u6765\u652f\u6301\u6a21\u578b\u6709\u6548\u6027\u7684\u53d1\u73b0\u3002"}}
{"id": "2510.13979", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.13979", "abs": "https://arxiv.org/abs/2510.13979", "authors": ["Supriti Sinhamahapatra", "Jan Niehues"], "title": "Do Slides Help? Multi-modal Context for Automatic Transcription of Conference Talks", "comment": null, "summary": "State-of-the-art (SOTA) Automatic Speech Recognition (ASR) systems primarily\nrely on acoustic information while disregarding additional multi-modal context.\nHowever, visual information are essential in disambiguation and adaptation.\nWhile most work focus on speaker images to handle noise conditions, this work\nalso focuses on integrating presentation slides for the use cases of scientific\npresentation.\n  In a first step, we create a benchmark for multi-modal presentation including\nan automatic analysis of transcribing domain-specific terminology. Next, we\nexplore methods for augmenting speech models with multi-modal information. We\nmitigate the lack of datasets with accompanying slides by a suitable approach\nof data augmentation. Finally, we train a model using the augmented dataset,\nresulting in a relative reduction in word error rate of approximately 34%,\nacross all words and 35%, for domain-specific terms compared to the baseline\nmodel.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u89c6\u89c9\u4fe1\u606f\uff08\u7279\u522b\u662f\u6f14\u793a\u5e7b\u706f\u7247\uff09\u96c6\u6210\u5230\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u4e2d\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u79d1\u5b66\u6f14\u793a\u573a\u666f\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u548c\u6a21\u578b\u8bad\u7ec3\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bcd\u9519\u8bef\u7387\u3002", "motivation": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u58f0\u5b66\u4fe1\u606f\u800c\u5ffd\u7565\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\uff0c\u4f46\u89c6\u89c9\u4fe1\u606f\u5bf9\u4e8e\u6d88\u6b67\u548c\u9002\u5e94\u81f3\u5173\u91cd\u8981\u3002\u7279\u522b\u662f\u5728\u79d1\u5b66\u6f14\u793a\u573a\u666f\u4e2d\uff0c\u6f14\u793a\u5e7b\u706f\u7247\u5305\u542b\u91cd\u8981\u4fe1\u606f\u3002", "method": "\u9996\u5148\u521b\u5efa\u591a\u6a21\u6001\u6f14\u793a\u57fa\u51c6\uff0c\u7136\u540e\u63a2\u7d22\u7528\u591a\u6a21\u6001\u4fe1\u606f\u589e\u5f3a\u8bed\u97f3\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u89e3\u51b3\u7f3a\u4e4f\u914d\u5957\u5e7b\u706f\u7247\u6570\u636e\u96c6\u7684\u95ee\u9898\uff0c\u6700\u540e\u4f7f\u7528\u589e\u5f3a\u6570\u636e\u96c6\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u4e0e\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0c\u8bad\u7ec3\u5f97\u5230\u7684\u6a21\u578b\u5728\u6240\u6709\u8bcd\u6c47\u4e0a\u7684\u8bcd\u9519\u8bef\u7387\u76f8\u5bf9\u964d\u4f4e\u4e86\u7ea634%\uff0c\u5728\u9886\u57df\u7279\u5b9a\u672f\u8bed\u4e0a\u7684\u8bcd\u9519\u8bef\u7387\u76f8\u5bf9\u964d\u4f4e\u4e8635%\u3002", "conclusion": "\u96c6\u6210\u89c6\u89c9\u4fe1\u606f\uff08\u7279\u522b\u662f\u6f14\u793a\u5e7b\u706f\u7247\uff09\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u5728\u79d1\u5b66\u6f14\u793a\u573a\u666f\u4e2d\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u9886\u57df\u7279\u5b9a\u672f\u8bed\u65b9\u9762\u3002"}}
{"id": "2510.14675", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14675", "abs": "https://arxiv.org/abs/2510.14675", "authors": ["Nicolas Dutly", "Friederike Groschupp", "Ivan Puddu", "Kari Kostiainen", "Srdjan Capkun"], "title": "AEX-NStep: Probabilistic Interrupt Counting Attacks on Intel SGX", "comment": "Author's version, to appear, 2026 IEEE Symposium on Security and\n  Privacy (SP)", "summary": "To mitigate interrupt-based stepping attacks (notably using SGX-Step), Intel\nintroduced AEX-Notify, an ISA extension to Intel SGX that aims to prevent\ndeterministic single-stepping. In this work, we introduce AEX-NStep, the first\ninterrupt counting attack on AEX-Notify-enabled Enclaves. We show that\ndeterministic single-stepping is not required for interrupt counting attacks to\nbe practical and that, therefore, AEX-Notify does not entirely prevent such\nattacks. We specifically show that one of AEX-Notify's security guarantees,\nobfuscated forward progress, does not hold, and we introduce two new\nprobabilistic interrupt counting attacks. We use these attacks to construct a\npractical ECDSA key leakage attack on an AEX-Notify-enabled SGX enclave. Our\nresults extend the original security analysis of AEX-Notify and inform the\ndesign of future mitigations.", "AI": {"tldr": "AEX-NStep\u662f\u9996\u4e2a\u9488\u5bf9\u542f\u7528AEX-Notify\u7684Enclaves\u7684\u4e2d\u65ad\u8ba1\u6570\u653b\u51fb\uff0c\u8bc1\u660eAEX-Notify\u65e0\u6cd5\u5b8c\u5168\u9632\u6b62\u6b64\u7c7b\u653b\u51fb\uff0c\u5e76\u6210\u529f\u5b9e\u65bdECDSA\u5bc6\u94a5\u6cc4\u9732\u653b\u51fb\u3002", "motivation": "Intel\u5f15\u5165AEX-Notify ISA\u6269\u5c55\u6765\u9632\u6b62\u57fa\u4e8e\u4e2d\u65ad\u7684\u5355\u6b65\u653b\u51fb\uff08\u5982SGX-Step\uff09\uff0c\u4f46\u8be5\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1AEX-Notify\u662f\u5426\u771f\u6b63\u80fd\u591f\u9632\u6b62\u4e2d\u65ad\u8ba1\u6570\u653b\u51fb\u3002", "method": "\u5f00\u53d1\u4e86AEX-NStep\u653b\u51fb\u65b9\u6cd5\uff0c\u5305\u62ec\u4e24\u79cd\u65b0\u7684\u6982\u7387\u6027\u4e2d\u65ad\u8ba1\u6570\u653b\u51fb\uff0c\u8bc1\u660e\u786e\u5b9a\u6027\u5355\u6b65\u4e0d\u662f\u4e2d\u65ad\u8ba1\u6570\u653b\u51fb\u7684\u5fc5\u8981\u6761\u4ef6\u3002", "result": "\u6210\u529f\u653b\u7834\u4e86AEX-Notify\u7684\u5b89\u5168\u4fdd\u8bc1\u4e4b\u4e00\uff08\u6df7\u6dc6\u7684\u524d\u5411\u8fdb\u5ea6\uff09\uff0c\u5e76\u6784\u5efa\u4e86\u5b9e\u7528\u7684ECDSA\u5bc6\u94a5\u6cc4\u9732\u653b\u51fb\uff0c\u8bc1\u660eAEX-Notify\u65e0\u6cd5\u5b8c\u5168\u9632\u6b62\u4e2d\u65ad\u8ba1\u6570\u653b\u51fb\u3002", "conclusion": "AEX-Notify\u4e0d\u80fd\u5b8c\u5168\u9632\u6b62\u4e2d\u65ad\u8ba1\u6570\u653b\u51fb\uff0c\u7814\u7a76\u7ed3\u679c\u6269\u5c55\u4e86AEX-Notify\u7684\u5b89\u5168\u5206\u6790\uff0c\u4e3a\u672a\u6765\u7f13\u89e3\u63aa\u65bd\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2510.13985", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13985", "abs": "https://arxiv.org/abs/2510.13985", "authors": ["Mar\u00eda Victoria Carro", "Denise Alejandra Mester", "Francisca Gauna Selasco", "Giovanni Franco Gabriel Marraffini", "Mario Alejandro Leiva", "Gerardo I. Simari", "Mar\u00eda Vanina Martinez"], "title": "Do Large Language Models Show Biases in Causal Learning? Insights from Contingency Judgment", "comment": null, "summary": "Causal learning is the cognitive process of developing the capability of\nmaking causal inferences based on available information, often guided by\nnormative principles. This process is prone to errors and biases, such as the\nillusion of causality, in which people perceive a causal relationship between\ntwo variables despite lacking supporting evidence. This cognitive bias has been\nproposed to underlie many societal problems, including social prejudice,\nstereotype formation, misinformation, and superstitious thinking. In this work,\nwe examine whether large language models are prone to developing causal\nillusions when faced with a classic cognitive science paradigm: the contingency\njudgment task. To investigate this, we constructed a dataset of 1,000 null\ncontingency scenarios (in which the available information is not sufficient to\nestablish a causal relationship between variables) within medical contexts and\nprompted LLMs to evaluate the effectiveness of potential causes. Our findings\nshow that all evaluated models systematically inferred unwarranted causal\nrelationships, revealing a strong susceptibility to the illusion of causality.\nWhile there is ongoing debate about whether LLMs genuinely understand causality\nor merely reproduce causal language without true comprehension, our findings\nsupport the latter hypothesis and raise concerns about the use of language\nmodels in domains where accurate causal reasoning is essential for informed\ndecision-making.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u4e2d\u5bb9\u6613\u4ea7\u751f\u56e0\u679c\u5e7b\u89c9\uff0c\u5373\u4f7f\u5728\u6ca1\u6709\u8db3\u591f\u8bc1\u636e\u652f\u6301\u7684\u60c5\u51b5\u4e0b\u4e5f\u4f1a\u9519\u8bef\u63a8\u65ad\u56e0\u679c\u5173\u7cfb\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u4f1a\u5728\u7ecf\u5178\u7684\u8ba4\u77e5\u79d1\u5b66\u8303\u5f0f\u2014\u2014\u5217\u8054\u5224\u65ad\u4efb\u52a1\u4e2d\u4ea7\u751f\u56e0\u679c\u5e7b\u89c9\uff0c\u8fd9\u79cd\u8ba4\u77e5\u504f\u5dee\u88ab\u8ba4\u4e3a\u662f\u8bb8\u591a\u793e\u4f1a\u95ee\u9898\u7684\u57fa\u7840\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b1000\u4e2a\u533b\u7597\u573a\u666f\u7684\u96f6\u5217\u8054\u6570\u636e\u96c6\uff0c\u5728\u8fd9\u4e9b\u573a\u666f\u4e2d\u53ef\u7528\u4fe1\u606f\u4e0d\u8db3\u4ee5\u5efa\u7acb\u53d8\u91cf\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u7136\u540e\u8ba9LLMs\u8bc4\u4f30\u6f5c\u5728\u539f\u56e0\u7684\u6709\u6548\u6027\u3002", "result": "\u6240\u6709\u8bc4\u4f30\u7684\u6a21\u578b\u90fd\u7cfb\u7edf\u5730\u63a8\u65ad\u51fa\u65e0\u6839\u636e\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u663e\u793a\u51fa\u5bf9\u56e0\u679c\u5e7b\u89c9\u7684\u5f3a\u70c8\u654f\u611f\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301LLMs\u53ea\u662f\u590d\u5236\u56e0\u679c\u8bed\u8a00\u800c\u975e\u771f\u6b63\u7406\u89e3\u56e0\u679c\u5173\u7cfb\u7684\u5047\u8bbe\uff0c\u5e76\u5bf9\u5728\u9700\u8981\u51c6\u786e\u56e0\u679c\u63a8\u7406\u7684\u9886\u57df\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u63d0\u51fa\u4e86\u62c5\u5fe7\u3002"}}
{"id": "2510.14693", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14693", "abs": "https://arxiv.org/abs/2510.14693", "authors": ["Simon Malatrait", "Alex Sirac"], "title": "FibRace: a large-scale benchmark of client-side proving on mobile devices", "comment": "14 pages, 5 figures, 2 tables", "summary": "FibRace, jointly developed by KKRT Labs and Hyli, was the first large-scale\nexperiment to test client-side proof generation on smartphones using Cairo M.\nPresented as a mobile game in which players proved Fibonacci numbers and\nclimbed a leaderboard, FibRace served a dual purpose: to engage the public and\nto provide empirical benchmarking. Over a three-week campaign (September 11-30,\n2025), 6,047 players across 99 countries generated 2,195,488 proofs on 1,420\nunique device models. The results show that most modern smartphones can\ncomplete a proof in under 5 seconds, confirming that *mobile devices are now\ncapable of producing zero-knowledge proofs reliably*, without the need for\nremote provers or specialized hardware. Performance was correlated primarily\nwith RAM capacity and SoC (System on Chip) performance: devices with at least 3\nGB of RAM proved stably, when Apple's A19 Pro and M-series chips achieved the\nfastest proving times. Hyli's blockchain natively verified every proof onchain\nwithout congestion. FibRace provides the most comprehensive dataset to date on\nmobile proving performance, establishing a practical baseline for future\nresearch in lightweight provers, proof-powered infrastructure, and\nprivacy-preserving mobile applications.", "AI": {"tldr": "FibRace\u662f\u9996\u4e2a\u5728\u667a\u80fd\u624b\u673a\u4e0a\u4f7f\u7528Cairo M\u8fdb\u884c\u5ba2\u6237\u7aef\u8bc1\u660e\u751f\u6210\u7684\u5927\u89c4\u6a21\u5b9e\u9a8c\uff0c\u901a\u8fc7\u79fb\u52a8\u6e38\u620f\u5f62\u5f0f\u8ba9\u73a9\u5bb6\u8bc1\u660e\u6590\u6ce2\u90a3\u5951\u6570\u5e76\u53c2\u4e0e\u6392\u884c\u699c\u7ade\u4e89\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u73b0\u4ee3\u667a\u80fd\u624b\u673a\u80fd\u57285\u79d2\u5185\u5b8c\u6210\u8bc1\u660e\uff0c\u786e\u8ba4\u79fb\u52a8\u8bbe\u5907\u5df2\u80fd\u53ef\u9760\u751f\u6210\u96f6\u77e5\u8bc6\u8bc1\u660e\u3002", "motivation": "\u6d4b\u8bd5\u667a\u80fd\u624b\u673a\u5ba2\u6237\u7aef\u8bc1\u660e\u751f\u6210\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u516c\u4f17\u63d0\u4f9b\u53c2\u4e0e\u673a\u4f1a\uff0c\u5e76\u4e3a\u79fb\u52a8\u8bbe\u5907\u8bc1\u660e\u6027\u80fd\u63d0\u4f9b\u5b9e\u8bc1\u57fa\u51c6\u6570\u636e\u3002", "method": "\u5f00\u53d1\u79fb\u52a8\u6e38\u620fFibRace\uff0c\u8ba9\u73a9\u5bb6\u5728\u667a\u80fd\u624b\u673a\u4e0a\u4f7f\u7528Cairo M\u751f\u6210\u6590\u6ce2\u90a3\u5951\u6570\u8bc1\u660e\uff0c\u6536\u96c66047\u540d\u73a9\u5bb6\u57281420\u79cd\u4e0d\u540c\u8bbe\u5907\u6a21\u578b\u4e0a\u751f\u6210\u76842195488\u4e2a\u8bc1\u660e\u6570\u636e\u3002", "result": "\u5927\u591a\u6570\u73b0\u4ee3\u667a\u80fd\u624b\u673a\u80fd\u57285\u79d2\u5185\u5b8c\u6210\u8bc1\u660e\uff0c\u6027\u80fd\u4e3b\u8981\u4e0eRAM\u5bb9\u91cf\u548cSoC\u6027\u80fd\u76f8\u5173\uff0c\u81f3\u5c113GB RAM\u7684\u8bbe\u5907\u80fd\u7a33\u5b9a\u8bc1\u660e\uff0c\u82f9\u679cA19 Pro\u548cM\u7cfb\u5217\u82af\u7247\u8bc1\u660e\u901f\u5ea6\u6700\u5feb\u3002Hyli\u533a\u5757\u94fe\u539f\u751f\u9a8c\u8bc1\u6240\u6709\u8bc1\u660e\u4e14\u65e0\u62e5\u5835\u3002", "conclusion": "\u79fb\u52a8\u8bbe\u5907\u73b0\u5df2\u80fd\u591f\u53ef\u9760\u751f\u6210\u96f6\u77e5\u8bc6\u8bc1\u660e\uff0c\u65e0\u9700\u8fdc\u7a0b\u8bc1\u660e\u5668\u6216\u4e13\u7528\u786c\u4ef6\u3002FibRace\u63d0\u4f9b\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u5168\u9762\u7684\u79fb\u52a8\u8bc1\u660e\u6027\u80fd\u6570\u636e\u96c6\uff0c\u4e3a\u8f7b\u91cf\u7ea7\u8bc1\u660e\u5668\u3001\u8bc1\u660e\u9a71\u52a8\u57fa\u7840\u8bbe\u65bd\u548c\u9690\u79c1\u4fdd\u62a4\u79fb\u52a8\u5e94\u7528\u5efa\u7acb\u4e86\u5b9e\u8df5\u57fa\u51c6\u3002"}}
{"id": "2510.14708", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14708", "abs": "https://arxiv.org/abs/2510.14708", "authors": ["Ha Xuan Son", "Nguyen Quoc Anh", "Phat T. Tran-Truong", "Le Thanh Tuan", "Pham Thanh Nghiem"], "title": "SLIE: A Secure and Lightweight Cryptosystem for Data Sharing in IoT Healthcare Services", "comment": "Paper has been accepted for publication in the Proceedings of the\n  23th International Conference on Service-Oriented Computing 2025", "summary": "The Internet of Medical Things (IoMT) has revolutionized healthcare by\ntransforming medical operations into standardized, interoperable services.\nHowever, this service-oriented model introduces significant security\nvulnerabilities in device management and communication, which are especially\ncritical given the sensitivity of medical data. To address these risks, this\npaper proposes SLIE (Secure and Lightweight Identity Encryption), a novel\ncryptosystem based on Wildcard Key Derivation Identity-Based Encryption\n(WKD-IBE). SLIE ensures scalable trust and secure omnidirectional communication\nthrough end-to-end encryption, hierarchical access control, and a lightweight\nkey management system designed for resource-constrained devices. It\nincorporates constant-time operations, memory obfuscation, and expiry-based key\nrevocation to counter side-channel, man-in-the-middle, and unauthorized access\nattacks, thereby ensuring compliance with standards like HIPAA and GDPR.\nEvaluations show that SLIE significantly outperforms RSA, with encryption and\ndecryption times of 0.936ms and 0.217ms for 1KB of data, an 84.54% improvement\nin encryption speed, a 99.70% improvement in decryption speed, and an energy\nefficiency of 0.014 J/KB.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSLIE\uff08\u5b89\u5168\u8f7b\u91cf\u7ea7\u8eab\u4efd\u52a0\u5bc6\uff09\u65b9\u6848\uff0c\u57fa\u4e8eWKD-IBE\u5bc6\u7801\u7cfb\u7edf\uff0c\u4e3aIoMT\u533b\u7597\u8bbe\u5907\u63d0\u4f9b\u7aef\u5230\u7aef\u52a0\u5bc6\u3001\u5206\u5c42\u8bbf\u95ee\u63a7\u5236\u548c\u8f7b\u91cf\u7ea7\u5bc6\u94a5\u7ba1\u7406\uff0c\u663e\u8457\u63d0\u5347\u5b89\u5168\u6027\u548c\u6027\u80fd\u3002", "motivation": "IoMT\u533b\u7597\u7269\u8054\u7f51\u7684\u670d\u52a1\u5316\u6a21\u5f0f\u5728\u8bbe\u5907\u7ba1\u7406\u548c\u901a\u4fe1\u4e2d\u5f15\u5165\u4e86\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u7279\u522b\u662f\u533b\u7597\u6570\u636e\u7684\u654f\u611f\u6027\u4f7f\u5f97\u8fd9\u4e9b\u98ce\u9669\u5c24\u4e3a\u5173\u952e\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u901a\u914d\u7b26\u5bc6\u94a5\u6d3e\u751f\u8eab\u4efd\u52a0\u5bc6\uff08WKD-IBE\uff09\u7684\u65b0\u578b\u5bc6\u7801\u7cfb\u7edf\uff0c\u7ed3\u5408\u6052\u5b9a\u65f6\u95f4\u64cd\u4f5c\u3001\u5185\u5b58\u6df7\u6dc6\u548c\u57fa\u4e8e\u8fc7\u671f\u7684\u5bc6\u94a5\u64a4\u9500\u673a\u5236\u3002", "result": "SLIE\u663e\u8457\u4f18\u4e8eRSA\uff0c1KB\u6570\u636e\u7684\u52a0\u5bc6\u65f6\u95f40.936ms\uff0c\u89e3\u5bc6\u65f6\u95f40.217ms\uff0c\u52a0\u5bc6\u901f\u5ea6\u63d0\u534784.54%\uff0c\u89e3\u5bc6\u901f\u5ea6\u63d0\u534799.70%\uff0c\u80fd\u6548\u4e3a0.014 J/KB\u3002", "conclusion": "SLIE\u4e3a\u8d44\u6e90\u53d7\u9650\u7684IoMT\u8bbe\u5907\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u4fe1\u4efb\u673a\u5236\u548c\u5b89\u5168\u7684\u5168\u5411\u901a\u4fe1\uff0c\u80fd\u591f\u62b5\u5fa1\u65c1\u8def\u653b\u51fb\u3001\u4e2d\u95f4\u4eba\u653b\u51fb\u548c\u672a\u6388\u6743\u8bbf\u95ee\uff0c\u786e\u4fdd\u7b26\u5408HIPAA\u548cGDPR\u6807\u51c6\u3002"}}
{"id": "2510.14894", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14894", "abs": "https://arxiv.org/abs/2510.14894", "authors": ["Marc Damie", "Florian Hahn", "Andreas Peter", "Jan Ramon"], "title": "Secure Sparse Matrix Multiplications and their Applications to Privacy-Preserving Machine Learning", "comment": null, "summary": "To preserve privacy, multi-party computation (MPC) enables executing Machine\nLearning (ML) algorithms on secret-shared or encrypted data. However, existing\nMPC frameworks are not optimized for sparse data. This makes them unsuitable\nfor ML applications involving sparse data, e.g., recommender systems or\ngenomics. Even in plaintext, such applications involve high-dimensional sparse\ndata, that cannot be processed without sparsity-related optimizations due to\nprohibitively large memory requirements.\n  Since matrix multiplication is central in ML algorithms, we propose MPC\nalgorithms to multiply secret sparse matrices. On the one hand, our algorithms\navoid the memory issues of the \"dense\" data representation of classic secure\nmatrix multiplication algorithms. On the other hand, our algorithms can\nsignificantly reduce communication costs (some experiments show a factor 1000)\nfor realistic problem sizes. We validate our algorithms in two ML applications\nin which existing protocols are impractical.\n  An important question when developing MPC algorithms is what assumptions can\nbe made. In our case, if the number of non-zeros in a row is a sensitive piece\nof information then a short runtime may reveal that the number of non-zeros is\nsmall. Existing approaches make relatively simple assumptions, e.g., that there\nis a universal upper bound to the number of non-zeros in a row. This often\ndoesn't align with statistical reality, in a lot of sparse datasets the amount\nof data per instance satisfies a power law. We propose an approach which allows\nadopting a safe upper bound on the distribution of non-zeros in rows/columns of\nsparse matrices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u7a00\u758f\u6570\u636e\u7684\u591a\u65b9\u8ba1\u7b97\uff08MPC\uff09\u7b97\u6cd5\uff0c\u4e13\u95e8\u7528\u4e8e\u79d8\u5bc6\u7a00\u758f\u77e9\u9635\u7684\u4e58\u6cd5\u8fd0\u7b97\uff0c\u89e3\u51b3\u4e86\u73b0\u6709MPC\u6846\u67b6\u5728\u5904\u7406\u9ad8\u7ef4\u7a00\u758f\u6570\u636e\u65f6\u7684\u5185\u5b58\u548c\u901a\u4fe1\u6548\u7387\u95ee\u9898\u3002", "motivation": "\u73b0\u6709MPC\u6846\u67b6\u672a\u9488\u5bf9\u7a00\u758f\u6570\u636e\u8fdb\u884c\u4f18\u5316\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u6d89\u53ca\u7a00\u758f\u6570\u636e\u7684\u673a\u5668\u5b66\u4e60\u5e94\u7528\uff08\u5982\u63a8\u8350\u7cfb\u7edf\u3001\u57fa\u56e0\u7ec4\u5b66\uff09\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u5e94\u7528\u4e2d\u7684\u9ad8\u7ef4\u7a00\u758f\u6570\u636e\u5728\u660e\u6587\u72b6\u6001\u4e0b\u5c31\u9700\u8981\u7a00\u758f\u4f18\u5316\u6765\u907f\u514d\u5185\u5b58\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u79d8\u5bc6\u7a00\u758f\u77e9\u9635\u4e58\u6cd5\u7684MPC\u7b97\u6cd5\uff0c\u907f\u514d\u7ecf\u5178\u5b89\u5168\u77e9\u9635\u4e58\u6cd5\u7b97\u6cd5\u7684\u5bc6\u96c6\u6570\u636e\u8868\u793a\u5e26\u6765\u7684\u5185\u5b58\u95ee\u9898\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u6210\u672c\u3002\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u975e\u96f6\u5143\u7d20\u5206\u5e03\u7684\u5b89\u5168\u4e0a\u754c\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u901a\u4fe1\u6210\u672c\u663e\u8457\u964d\u4f4e\uff08\u67d0\u4e9b\u5b9e\u9a8c\u663e\u793a1000\u500d\uff09\uff0c\u5728\u73b0\u6709\u534f\u8bae\u4e0d\u5b9e\u7528\u7684\u4e24\u4e2aML\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684MPC\u7a00\u758f\u77e9\u9635\u4e58\u6cd5\u7b97\u6cd5\u89e3\u51b3\u4e86\u7a00\u758f\u6570\u636e\u5904\u7406\u4e2d\u7684\u5185\u5b58\u548c\u901a\u4fe1\u74f6\u9888\uff0c\u4e3a\u6d89\u53ca\u7a00\u758f\u6570\u636e\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5668\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.14112", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14112", "abs": "https://arxiv.org/abs/2510.14112", "authors": ["Huiliang Zhang", "Di Wu", "Arnaud Zinflou", "Benoit Boulet"], "title": "STEMS: Spatial-Temporal Enhanced Safe Multi-Agent Coordination for Building Energy Management", "comment": null, "summary": "Building energy management is essential for achieving carbon reduction goals,\nimproving occupant comfort, and reducing energy costs. Coordinated building\nenergy management faces critical challenges in exploiting spatial-temporal\ndependencies while ensuring operational safety across multi-building systems.\nCurrent multi-building energy systems face three key challenges: insufficient\nspatial-temporal information exploitation, lack of rigorous safety guarantees,\nand system complexity. This paper proposes Spatial-Temporal Enhanced Safe\nMulti-Agent Coordination (STEMS), a novel safety-constrained multi-agent\nreinforcement learning framework for coordinated building energy management.\nSTEMS integrates two core components: (1) a spatial-temporal graph\nrepresentation learning framework using a GCN-Transformer fusion architecture\nto capture inter-building relationships and temporal patterns, and (2) a\nsafety-constrained multi-agent RL algorithm incorporating Control Barrier\nFunctions to provide mathematical safety guarantees. Extensive experiments on\nreal-world building datasets demonstrate STEMS's superior performance over\nexisting methods, showing that STEMS achieves 21% cost reduction, 18% emission\nreduction, and dramatically reduces safety violations from 35.1% to 5.6% while\nmaintaining optimal comfort with only 0.13 discomfort proportion. The framework\nalso demonstrates strong robustness during extreme weather conditions and\nmaintains effectiveness across different building types.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86STEMS\u6846\u67b6\uff0c\u4e00\u79cd\u5b89\u5168\u7ea6\u675f\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u534f\u8c03\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\uff0c\u901a\u8fc7\u7a7a\u95f4-\u65f6\u95f4\u56fe\u8868\u793a\u5b66\u4e60\u548c\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u5b9e\u73b0\u5b89\u5168\u4fdd\u8bc1\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8621%\u6210\u672c\u964d\u4f4e\u548c18%\u6392\u653e\u51cf\u5c11\u3002", "motivation": "\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u5bf9\u5b9e\u73b0\u78b3\u51cf\u6392\u76ee\u6807\u3001\u63d0\u9ad8\u5c45\u4f4f\u8005\u8212\u9002\u5ea6\u548c\u964d\u4f4e\u80fd\u6e90\u6210\u672c\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524d\u591a\u5efa\u7b51\u80fd\u6e90\u7cfb\u7edf\u9762\u4e34\u7a7a\u95f4-\u65f6\u95f4\u4fe1\u606f\u5229\u7528\u4e0d\u8db3\u3001\u7f3a\u4e4f\u4e25\u683c\u5b89\u5168\u4fdd\u8bc1\u548c\u7cfb\u7edf\u590d\u6742\u6027\u4e09\u5927\u6311\u6218\u3002", "method": "STEMS\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a(1) \u4f7f\u7528GCN-Transformer\u878d\u5408\u67b6\u6784\u7684\u7a7a\u95f4-\u65f6\u95f4\u56fe\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u6355\u6349\u5efa\u7b51\u95f4\u5173\u7cfb\u548c\u65f6\u95f4\u6a21\u5f0f\uff1b(2) \u7ed3\u5408\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u7684\u5b89\u5168\u7ea6\u675f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u63d0\u4f9b\u6570\u5b66\u5b89\u5168\u4fdd\u8bc1\u3002", "result": "\u5728\u771f\u5b9e\u5efa\u7b51\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSTEMS\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u4e8621%\u6210\u672c\u964d\u4f4e\u300118%\u6392\u653e\u51cf\u5c11\uff0c\u5e76\u5c06\u5b89\u5168\u8fdd\u89c4\u4ece35.1%\u5927\u5e45\u964d\u4f4e\u81f35.6%\uff0c\u540c\u65f6\u4ec5\u4fdd\u63010.13\u7684\u4e0d\u9002\u6bd4\u4f8b\u3002", "conclusion": "STEMS\u6846\u67b6\u5728\u6781\u7aef\u5929\u6c14\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u4e0d\u540c\u5efa\u7b51\u7c7b\u578b\u4e2d\u4fdd\u6301\u6709\u6548\u6027\uff0c\u4e3a\u534f\u8c03\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u63d0\u4f9b\u4e86\u5b89\u5168\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.14312", "categories": ["cs.AI", "cs.CL", "cs.CR", "I.2.7; I.2.11"], "pdf": "https://arxiv.org/pdf/2510.14312", "abs": "https://arxiv.org/abs/2510.14312", "authors": ["Mason Nakamura", "Abhinav Kumar", "Saaduddin Mahmud", "Sahar Abdelnabi", "Shlomo Zilberstein", "Eugene Bagdasarian"], "title": "Terrarium: Revisiting the Blackboard for Multi-Agent Safety, Privacy, and Security Studies", "comment": null, "summary": "A multi-agent system (MAS) powered by large language models (LLMs) can\nautomate tedious user tasks such as meeting scheduling that requires\ninter-agent collaboration. LLMs enable nuanced protocols that account for\nunstructured private data, user constraints, and preferences. However, this\ndesign introduces new risks, including misalignment and attacks by malicious\nparties that compromise agents or steal user data. In this paper, we propose\nthe Terrarium framework for fine-grained study on safety, privacy, and security\nin LLM-based MAS. We repurpose the blackboard design, an early approach in\nmulti-agent systems, to create a modular, configurable testbed for multi-agent\ncollaboration. We identify key attack vectors such as misalignment, malicious\nagents, compromised communication, and data poisoning. We implement three\ncollaborative MAS scenarios with four representative attacks to demonstrate the\nframework's flexibility. By providing tools to rapidly prototype, evaluate, and\niterate on defenses and designs, Terrarium aims to accelerate progress toward\ntrustworthy multi-agent systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86Terrarium\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7684\u5b89\u5168\u3001\u9690\u79c1\u548c\u5b89\u5168\u6027\u7814\u7a76\uff0c\u901a\u8fc7\u91cd\u65b0\u8bbe\u8ba1\u9ed1\u677f\u67b6\u6784\u6765\u521b\u5efa\u6a21\u5757\u5316\u3001\u53ef\u914d\u7f6e\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "motivation": "LLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u80fd\u591f\u81ea\u52a8\u5316\u7e41\u7410\u7684\u7528\u6237\u4efb\u52a1\uff0c\u4f46\u5f15\u5165\u4e86\u65b0\u7684\u98ce\u9669\uff0c\u5305\u62ec\u9519\u4f4d\u653b\u51fb\u3001\u6076\u610f\u65b9\u653b\u51fb\u3001\u667a\u80fd\u4f53\u88ab\u653b\u9677\u6216\u7528\u6237\u6570\u636e\u88ab\u76d7\u7b49\u95ee\u9898\u3002", "method": "\u91cd\u65b0\u5229\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u9ed1\u677f\u8bbe\u8ba1\uff0c\u521b\u5efa\u6a21\u5757\u5316\u3001\u53ef\u914d\u7f6e\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u8bc6\u522b\u5173\u952e\u653b\u51fb\u5411\u91cf\uff08\u9519\u4f4d\u3001\u6076\u610f\u667a\u80fd\u4f53\u3001\u901a\u4fe1\u88ab\u653b\u9677\u3001\u6570\u636e\u6295\u6bd2\uff09\uff0c\u5e76\u5728\u4e09\u4e2a\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u573a\u666f\u4e2d\u5b9e\u65bd\u56db\u79cd\u4ee3\u8868\u6027\u653b\u51fb\u3002", "result": "\u5b9e\u73b0\u4e86Terrarium\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u5176\u7075\u6d3b\u6027\uff0c\u80fd\u591f\u5feb\u901f\u539f\u578b\u5316\u3001\u8bc4\u4f30\u548c\u8fed\u4ee3\u9632\u5fa1\u63aa\u65bd\u548c\u8bbe\u8ba1\u3002", "conclusion": "Terrarium\u6846\u67b6\u65e8\u5728\u52a0\u901f\u53ef\u4fe1\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8fdb\u5c55\uff0c\u901a\u8fc7\u63d0\u4f9b\u5de5\u5177\u6765\u5e94\u5bf9\u5b89\u5168\u3001\u9690\u79c1\u548c\u5b89\u5168\u6027\u7684\u6311\u6218\u3002"}}
{"id": "2510.14136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14136", "abs": "https://arxiv.org/abs/2510.14136", "authors": ["David Roqui", "Ad\u00e8le Cormier", "nistor Grozavu", "Ann Bourges"], "title": "A Multimodal Approach to Heritage Preservation in the Context of Climate Change", "comment": null, "summary": "Cultural heritage sites face accelerating degradation due to climate change,\nyet tradi- tional monitoring relies on unimodal analysis (visual inspection or\nenvironmental sen- sors alone) that fails to capture the complex interplay\nbetween environmental stres- sors and material deterioration. We propose a\nlightweight multimodal architecture that fuses sensor data (temperature,\nhumidity) with visual imagery to predict degradation severity at heritage\nsites. Our approach adapts PerceiverIO with two key innovations: (1) simplified\nencoders (64D latent space) that prevent overfitting on small datasets (n=37\ntraining samples), and (2) Adaptive Barlow Twins loss that encourages modality\ncomplementarity rather than redundancy. On data from Strasbourg Cathedral, our\nmodel achieves 76.9% accu- racy, a 43% improvement over standard multimodal\narchitectures (VisualBERT, Trans- former) and 25% over vanilla PerceiverIO.\nAblation studies reveal that sensor-only achieves 61.5% while image-only\nreaches 46.2%, confirming successful multimodal synergy. A systematic\nhyperparameter study identifies an optimal moderate correlation target ({\\tau}\n=0.3) that balances align- ment and complementarity, achieving 69.2% accuracy\ncompared to other {\\tau} values ({\\tau} =0.1/0.5/0.7: 53.8%, {\\tau} =0.9:\n61.5%). This work demonstrates that architectural sim- plicity combined with\ncontrastive regularization enables effective multimodal learning in data-scarce\nheritage monitoring contexts, providing a foundation for AI-driven con-\nservation decision support systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u591a\u6a21\u6001\u67b6\u6784\uff0c\u878d\u5408\u4f20\u611f\u5668\u6570\u636e\u548c\u89c6\u89c9\u56fe\u50cf\u6765\u9884\u6d4b\u6587\u5316\u9057\u4ea7\u5730\u7684\u9000\u5316\u4e25\u91cd\u7a0b\u5ea6\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u6587\u5316\u9057\u4ea7\u5730\u56e0\u6c14\u5019\u53d8\u5316\u52a0\u901f\u9000\u5316\uff0c\u4f20\u7edf\u5355\u6a21\u6001\u76d1\u6d4b\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u73af\u5883\u5e94\u529b\u4e0e\u6750\u6599\u9000\u5316\u4e4b\u95f4\u7684\u590d\u6742\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u91c7\u7528\u6539\u8fdb\u7684PerceiverIO\u67b6\u6784\uff0c\u5305\u542b\u7b80\u5316\u7f16\u7801\u5668\uff0864D\u6f5c\u5728\u7a7a\u95f4\uff09\u548c\u81ea\u9002\u5e94Barlow Twins\u635f\u5931\u51fd\u6570\uff0c\u9f13\u52b1\u6a21\u6001\u4e92\u8865\u6027\u800c\u975e\u5197\u4f59\u3002", "result": "\u5728\u65af\u7279\u62c9\u65af\u5821\u5927\u6559\u5802\u6570\u636e\u4e0a\u8fbe\u523076.9%\u51c6\u786e\u7387\uff0c\u6bd4\u6807\u51c6\u591a\u6a21\u6001\u67b6\u6784\u63d0\u534743%\uff0c\u6bd4\u539f\u59cbPerceiverIO\u63d0\u534725%\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u591a\u6a21\u6001\u534f\u540c\u6548\u5e94\u3002", "conclusion": "\u67b6\u6784\u7b80\u5316\u4e0e\u5bf9\u6bd4\u6b63\u5219\u5316\u76f8\u7ed3\u5408\uff0c\u53ef\u5728\u6570\u636e\u7a00\u7f3a\u7684\u9057\u4ea7\u76d1\u6d4b\u73af\u5883\u4e2d\u5b9e\u73b0\u6709\u6548\u7684\u591a\u6a21\u6001\u5b66\u4e60\uff0c\u4e3aAI\u9a71\u52a8\u7684\u4fdd\u62a4\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2510.14169", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14169", "abs": "https://arxiv.org/abs/2510.14169", "authors": ["Praphul Singh", "Corey Barrett", "Sumana Srivasta", "Amitabh Saikia", "Irfan Bulu", "Sri Gadde", "Krishnaram Kenthapadi"], "title": "JEDA: Query-Free Clinical Order Search from Ambient Dialogues", "comment": null, "summary": "Clinical conversations mix explicit directives (order a chest X-ray) with\nimplicit reasoning (the cough worsened overnight, we should check for\npneumonia). Many systems rely on LLM rewriting, adding latency, instability,\nand opacity that hinder real-time ordering. We present JEDA (Joint Embedding\nfor Direct and Ambient clinical orders), a domain-initialized bi-encoder that\nretrieves canonical orders directly and, in a query-free mode, encodes a short\nrolling window of ambient dialogue to trigger retrieval. Initialized from\nPubMedBERT and fine-tuned with a duplicate-safe contrastive objective, JEDA\naligns heterogeneous expressions of intent to shared order concepts. Training\nuses constrained LLM guidance to tie each signed order to complementary\nformulations (command only, context only, command+context, context+reasoning),\nproducing clearer inter-order separation, tighter query extendash order\ncoupling, and stronger generalization. The query-free mode is noise-resilient,\nreducing sensitivity to disfluencies and ASR errors by conditioning on a short\nwindow rather than a single utterance. Deployed in practice, JEDA yields large\ngains and substantially outperforms its base encoder and recent open embedders\n(Linq Embed Mistral, SFR Embedding, GTE Qwen, BGE large, Embedding Gemma). The\nresult is a fast, interpretable, LLM-free retrieval layer that links ambient\ncontext to actionable clinical orders in real time.", "AI": {"tldr": "JEDA\u662f\u4e00\u4e2a\u7528\u4e8e\u4e34\u5e8a\u8ba2\u5355\u68c0\u7d22\u7684\u53cc\u7f16\u7801\u5668\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u5d4c\u5165\u76f4\u63a5\u548c\u4e0a\u4e0b\u6587\u4e34\u5e8a\u8ba2\u5355\uff0c\u5b9e\u73b0\u5b9e\u65f6\u3001\u53ef\u89e3\u91ca\u7684\u8ba2\u5355\u68c0\u7d22\uff0c\u65e0\u9700LLM\u91cd\u5199\u3002", "motivation": "\u89e3\u51b3\u4e34\u5e8a\u5bf9\u8bdd\u4e2d\u663e\u6027\u6307\u4ee4\u4e0e\u9690\u6027\u63a8\u7406\u6df7\u5408\u7684\u95ee\u9898\uff0c\u907f\u514d\u4f20\u7edfLLM\u91cd\u5199\u65b9\u6cd5\u5e26\u6765\u7684\u5ef6\u8fdf\u3001\u4e0d\u7a33\u5b9a\u6027\u548c\u4e0d\u900f\u660e\u6027\uff0c\u5b9e\u73b0\u5b9e\u65f6\u8ba2\u5355\u5904\u7406\u3002", "method": "\u4f7f\u7528PubMedBERT\u521d\u59cb\u5316\u7684\u53cc\u7f16\u7801\u5668\uff0c\u91c7\u7528\u91cd\u590d\u5b89\u5168\u5bf9\u6bd4\u76ee\u6807\u8fdb\u884c\u5fae\u8c03\uff0c\u901a\u8fc7\u53d7\u9650LLM\u6307\u5bfc\u5c06\u4e0d\u540c\u610f\u56fe\u8868\u8fbe\u5bf9\u9f50\u5230\u5171\u4eab\u8ba2\u5355\u6982\u5ff5\uff0c\u652f\u6301\u67e5\u8be2\u548c\u65e0\u67e5\u8be2\u4e24\u79cd\u6a21\u5f0f\u3002", "result": "JEDA\u5728\u5b9e\u8df5\u4e2d\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5927\u5e45\u4f18\u4e8e\u57fa\u7840\u7f16\u7801\u5668\u548c\u6700\u65b0\u5f00\u6e90\u5d4c\u5165\u5668\uff0c\u65e0\u67e5\u8be2\u6a21\u5f0f\u5bf9\u566a\u58f0\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "JEDA\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5feb\u901f\u3001\u53ef\u89e3\u91ca\u3001\u65e0\u9700LLM\u7684\u68c0\u7d22\u5c42\uff0c\u80fd\u591f\u5b9e\u65f6\u5c06\u4e0a\u4e0b\u6587\u73af\u5883\u4e0e\u53ef\u64cd\u4f5c\u7684\u4e34\u5e8a\u8ba2\u5355\u8054\u7cfb\u8d77\u6765\u3002"}}
{"id": "2510.14176", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14176", "abs": "https://arxiv.org/abs/2510.14176", "authors": ["Roger Creus Castanyer", "Faisal Mohamed", "Pablo Samuel Castro", "Cyrus Neary", "Glen Berseth"], "title": "ARM-FM: Automated Reward Machines via Foundation Models for Compositional Reinforcement Learning", "comment": null, "summary": "Reinforcement learning (RL) algorithms are highly sensitive to reward\nfunction specification, which remains a central challenge limiting their broad\napplicability. We present ARM-FM: Automated Reward Machines via Foundation\nModels, a framework for automated, compositional reward design in RL that\nleverages the high-level reasoning capabilities of foundation models (FMs).\nReward machines (RMs) -- an automata-based formalism for reward specification\n-- are used as the mechanism for RL objective specification, and are\nautomatically constructed via the use of FMs. The structured formalism of RMs\nyields effective task decompositions, while the use of FMs enables objective\nspecifications in natural language. Concretely, we (i) use FMs to automatically\ngenerate RMs from natural language specifications; (ii) associate language\nembeddings with each RM automata-state to enable generalization across tasks;\nand (iii) provide empirical evidence of ARM-FM's effectiveness in a diverse\nsuite of challenging environments, including evidence of zero-shot\ngeneralization.", "AI": {"tldr": "ARM-FM\u662f\u4e00\u4e2a\u5229\u7528\u57fa\u7840\u6a21\u578b\u81ea\u52a8\u8bbe\u8ba1\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u51fd\u6570\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5956\u52b1\u673a\u5668\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u5230\u7ed3\u6784\u5316\u5956\u52b1\u89c4\u8303\u7684\u8f6c\u6362\uff0c\u652f\u6301\u4efb\u52a1\u5206\u89e3\u548c\u96f6\u6837\u672c\u6cdb\u5316\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5bf9\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\u9ad8\u5ea6\u654f\u611f\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u4eba\u5de5\u8bbe\u8ba1\u590d\u6742\u7684\u5956\u52b1\u51fd\u6570\uff0c\u96be\u4ee5\u5904\u7406\u590d\u6742\u7684\u591a\u76ee\u6807\u4efb\u52a1\u3002", "method": "\u4f7f\u7528\u57fa\u7840\u6a21\u578b\u81ea\u52a8\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u751f\u6210\u5956\u52b1\u673a\u5668\uff1b\u4e3a\u6bcf\u4e2a\u81ea\u52a8\u673a\u72b6\u6001\u5173\u8054\u8bed\u8a00\u5d4c\u5165\u4ee5\u5b9e\u73b0\u4efb\u52a1\u95f4\u6cdb\u5316\uff1b\u5728\u591a\u6837\u5316\u73af\u5883\u4e2d\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "\u5728\u591a\u79cd\u6311\u6218\u6027\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86ARM-FM\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u7684\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u3002", "conclusion": "ARM-FM\u901a\u8fc7\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u7684\u9ad8\u5c42\u63a8\u7406\u80fd\u529b\u548c\u5956\u52b1\u673a\u5668\u7684\u7ed3\u6784\u5316\u5f62\u5f0f\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u7684\u7ec4\u5408\u5f0f\u5956\u52b1\u8bbe\u8ba1\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u7684\u5e7f\u6cdb\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.14194", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14194", "abs": "https://arxiv.org/abs/2510.14194", "authors": ["G\u00f6ktu\u011f Bender", "Samer Faraj", "Anand Bhardwaj"], "title": "Implementation of AI in Precision Medicine", "comment": "Accepted to SMASH 2025", "summary": "Artificial intelligence (AI) has become increasingly central to precision\nmedicine by enabling the integration and interpretation of multimodal data, yet\nimplementation in clinical settings remains limited. This paper provides a\nscoping review of literature from 2019-2024 on the implementation of AI in\nprecision medicine, identifying key barriers and enablers across data quality,\nclinical reliability, workflow integration, and governance. Through an\necosystem-based framework, we highlight the interdependent relationships\nshaping real-world translation and propose future directions to support\ntrustworthy and sustainable implementation.", "AI": {"tldr": "\u672c\u6587\u5bf92019-2024\u5e74\u7cbe\u51c6\u533b\u5b66\u4e2dAI\u5b9e\u65bd\u7684\u6587\u732e\u8fdb\u884c\u8303\u56f4\u7efc\u8ff0\uff0c\u8bc6\u522b\u4e86\u6570\u636e\u8d28\u91cf\u3001\u4e34\u5e8a\u53ef\u9760\u6027\u3001\u5de5\u4f5c\u6d41\u6574\u5408\u548c\u6cbb\u7406\u65b9\u9762\u7684\u5173\u952e\u969c\u788d\u4e0e\u4fc3\u8fdb\u56e0\u7d20\uff0c\u63d0\u51fa\u4e86\u652f\u6301\u53ef\u4fe1\u548c\u53ef\u6301\u7eed\u5b9e\u65bd\u7684\u672a\u6765\u65b9\u5411\u3002", "motivation": "AI\u5728\u7cbe\u51c6\u533b\u5b66\u4e2d\u65e5\u76ca\u91cd\u8981\uff0c\u80fd\u591f\u6574\u5408\u548c\u89e3\u91ca\u591a\u6a21\u6001\u6570\u636e\uff0c\u4f46\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u5b9e\u65bd\u4ecd\u7136\u6709\u9650\uff0c\u9700\u8981\u7cfb\u7edf\u5206\u6790\u5b9e\u65bd\u969c\u788d\u548c\u4fc3\u8fdb\u56e0\u7d20\u3002", "method": "\u91c7\u7528\u751f\u6001\u7cfb\u7edf\u6846\u67b6\uff0c\u5bf92019-2024\u5e74\u7cbe\u51c6\u533b\u5b66AI\u5b9e\u65bd\u6587\u732e\u8fdb\u884c\u8303\u56f4\u7efc\u8ff0\uff0c\u5206\u6790\u6570\u636e\u8d28\u91cf\u3001\u4e34\u5e8a\u53ef\u9760\u6027\u3001\u5de5\u4f5c\u6d41\u6574\u5408\u548c\u6cbb\u7406\u56db\u4e2a\u7ef4\u5ea6\u7684\u5173\u952e\u56e0\u7d20\u3002", "result": "\u8bc6\u522b\u4e86\u7cbe\u51c6\u533b\u5b66AI\u5b9e\u65bd\u4e2d\u7684\u4e3b\u8981\u969c\u788d\u548c\u4fc3\u8fdb\u56e0\u7d20\uff0c\u5f3a\u8c03\u4e86\u73b0\u5b9e\u4e16\u754c\u8f6c\u5316\u4e2d\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\u3002", "conclusion": "\u63d0\u51fa\u4e86\u652f\u6301\u53ef\u4fe1\u548c\u53ef\u6301\u7eedAI\u5b9e\u65bd\u5728\u7cbe\u51c6\u533b\u5b66\u4e2d\u7684\u672a\u6765\u65b9\u5411\uff0c\u5f3a\u8c03\u9700\u8981\u7cfb\u7edf\u6027\u65b9\u6cd5\u6765\u89e3\u51b3\u5b9e\u65bd\u6311\u6218\u3002"}}
{"id": "2510.14253", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14253", "abs": "https://arxiv.org/abs/2510.14253", "authors": ["Wangtao Sun", "Xiang Cheng", "Jialin Fan", "Yao Xu", "Xing Yu", "Shizhu He", "Jun Zhao", "Kang Liu"], "title": "Towards Agentic Self-Learning LLMs in Search Environment", "comment": null, "summary": "We study whether self-learning can scale LLM-based agents without relying on\nhuman-curated datasets or predefined rule-based rewards. Through controlled\nexperiments in a search-agent setting, we identify two key determinants of\nscalable agent training: the source of reward signals and the scale of agent\ntask data. We find that rewards from a Generative Reward Model (GRM) outperform\nrigid rule-based signals for open-domain learning, and that co-evolving the GRM\nwith the policy further boosts performance. Increasing the volume of agent task\ndata-even when synthetically generated-substantially enhances agentic\ncapabilities. Building on these insights, we propose \\textbf{Agentic\nSelf-Learning} (ASL), a fully closed-loop, multi-role reinforcement learning\nframework that unifies task generation, policy execution, and evaluation within\na shared tool environment and LLM backbone. ASL coordinates a Prompt Generator,\na Policy Model, and a Generative Reward Model to form a virtuous cycle of\nharder task setting, sharper verification, and stronger solving. Empirically,\nASL delivers steady, round-over-round gains, surpasses strong RLVR baselines\n(e.g., Search-R1) that plateau or degrade, and continues improving under\nzero-labeled-data conditions, indicating superior sample efficiency and\nrobustness. We further show that GRM verification capacity is the main\nbottleneck: if frozen, it induces reward hacking and stalls progress; continual\nGRM training on the evolving data distribution mitigates this, and a small\nlate-stage injection of real verification data raises the performance ceiling.\nThis work establishes reward source and data scale as critical levers for\nopen-domain agent learning and demonstrates the efficacy of multi-role\nco-evolution for scalable, self-improving agents. The data and code of this\npaper are released at\nhttps://github.com/forangel2014/Towards-Agentic-Self-Learning", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAgentic Self-Learning (ASL)\u7684\u5b8c\u5168\u95ed\u73af\u591a\u89d2\u8272\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u5956\u52b1\u6a21\u578b(GRM)\u548c\u7b56\u7565\u6a21\u578b\u7684\u534f\u540c\u8fdb\u5316\uff0c\u5728\u65e0\u4eba\u7c7b\u6807\u6ce8\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u667a\u80fd\u4f53\u7684\u6301\u7eed\u81ea\u6211\u63d0\u5347\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u4e0d\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\u6216\u9884\u5b9a\u4e49\u89c4\u5219\u5956\u52b1\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u81ea\u5b66\u4e60\u6269\u5c55\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u80fd\u529b\u3002", "method": "\u63d0\u51faASL\u6846\u67b6\uff0c\u7edf\u4e00\u4efb\u52a1\u751f\u6210\u3001\u7b56\u7565\u6267\u884c\u548c\u8bc4\u4f30\uff0c\u901a\u8fc7\u63d0\u793a\u751f\u6210\u5668\u3001\u7b56\u7565\u6a21\u578b\u548c\u751f\u6210\u5956\u52b1\u6a21\u578b\u5f62\u6210\u826f\u6027\u5faa\u73af\u3002", "result": "ASL\u5b9e\u73b0\u4e86\u7a33\u5b9a\u6301\u7eed\u7684\u63d0\u5347\uff0c\u8d85\u8d8a\u4e86\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u96f6\u6807\u6ce8\u6570\u636e\u6761\u4ef6\u4e0b\u4ecd\u80fd\u6301\u7eed\u6539\u8fdb\uff0c\u663e\u793a\u51fa\u4f18\u5f02\u7684\u6837\u672c\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u5956\u52b1\u6765\u6e90\u548c\u6570\u636e\u89c4\u6a21\u662f\u5f00\u653e\u9886\u57df\u667a\u80fd\u4f53\u5b66\u4e60\u7684\u5173\u952e\u56e0\u7d20\uff0c\u591a\u89d2\u8272\u534f\u540c\u8fdb\u5316\u662f\u5b9e\u73b0\u53ef\u6269\u5c55\u81ea\u6539\u8fdb\u667a\u80fd\u4f53\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2510.14265", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14265", "abs": "https://arxiv.org/abs/2510.14265", "authors": ["Xukai Wang", "Xuanbo Liu", "Mingrui Chen", "Haitian Zhong", "Xuanlin Yang", "Bohan Zeng", "Jinbo Hu", "Hao Liang", "Junbo Niu", "Xuchen Li", "Ruitao Wu", "Ruichuan An", "Yang Shi", "Liu Liu", "Xu-Yao Zhang", "Qiang Liu", "Zhouchen Lin", "Wentao Zhang", "Bin Dong"], "title": "MorphoBench: A Benchmark with Difficulty Adaptive to Model Reasoning", "comment": "21 pages, 12 figures", "summary": "With the advancement of powerful large-scale reasoning models, effectively\nevaluating the reasoning capabilities of these models has become increasingly\nimportant. However, existing benchmarks designed to assess the reasoning\nabilities of large models tend to be limited in scope and lack the flexibility\nto adapt their difficulty according to the evolving reasoning capacities of the\nmodels. To address this, we propose MorphoBench, a benchmark that incorporates\nmultidisciplinary questions to evaluate the reasoning capabilities of large\nmodels and can adjust and update question difficulty based on the reasoning\nabilities of advanced models. Specifically, we curate the benchmark by\nselecting and collecting complex reasoning questions from existing benchmarks\nand sources such as Olympiad-level competitions. Additionally, MorphoBench\nadaptively modifies the analytical challenge of questions by leveraging key\nstatements generated during the model's reasoning process. Furthermore, it\nincludes questions generated using simulation software, enabling dynamic\nadjustment of benchmark difficulty with minimal resource consumption. We have\ngathered over 1,300 test questions and iteratively adjusted the difficulty of\nMorphoBench based on the reasoning capabilities of models such as o3 and GPT-5.\nMorphoBench enhances the comprehensiveness and validity of model reasoning\nevaluation, providing reliable guidance for improving both the reasoning\nabilities and scientific robustness of large models. The code has been released\nin https://github.com/OpenDCAI/MorphoBench.", "AI": {"tldr": "\u63d0\u51fa\u4e86MorphoBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u80fd\u591f\u6839\u636e\u6a21\u578b\u63a8\u7406\u80fd\u529b\u52a8\u6001\u8c03\u6574\u95ee\u9898\u96be\u5ea6\uff0c\u5305\u542b1300\u591a\u4e2a\u6d4b\u8bd5\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u8bc4\u4f30\u5927\u6a21\u578b\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5b58\u5728\u8303\u56f4\u6709\u9650\u548c\u7075\u6d3b\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u6839\u636e\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u6f14\u53d8\u8c03\u6574\u96be\u5ea6\u3002", "method": "\u4ece\u73b0\u6709\u57fa\u51c6\u548c\u5965\u6797\u5339\u514b\u7ade\u8d5b\u4e2d\u6536\u96c6\u590d\u6742\u63a8\u7406\u95ee\u9898\uff0c\u5229\u7528\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5173\u952e\u9648\u8ff0\u81ea\u9002\u5e94\u4fee\u6539\u95ee\u9898\u5206\u6790\u96be\u5ea6\uff0c\u5e76\u4f7f\u7528\u6a21\u62df\u8f6f\u4ef6\u751f\u6210\u95ee\u9898\u4ee5\u5b9e\u73b0\u52a8\u6001\u96be\u5ea6\u8c03\u6574\u3002", "result": "\u6536\u96c6\u4e861300\u591a\u4e2a\u6d4b\u8bd5\u95ee\u9898\uff0c\u57fa\u4e8eo3\u548cGPT-5\u7b49\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u8fed\u4ee3\u8c03\u6574\u4e86MorphoBench\u7684\u96be\u5ea6\u3002", "conclusion": "MorphoBench\u589e\u5f3a\u4e86\u6a21\u578b\u63a8\u7406\u8bc4\u4f30\u7684\u5168\u9762\u6027\u548c\u6709\u6548\u6027\uff0c\u4e3a\u63d0\u9ad8\u5927\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u79d1\u5b66\u7a33\u5065\u6027\u63d0\u4f9b\u4e86\u53ef\u9760\u6307\u5bfc\u3002"}}
{"id": "2510.14319", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14319", "abs": "https://arxiv.org/abs/2510.14319", "authors": ["Xu Shen", "Qi Zhang", "Song Wang", "Zhen Tan", "Xinyu Zhao", "Laura Yao", "Vaishnav Tadiparthi", "Hossein Nourkhiz Mahjoub", "Ehsan Moradi Pari", "Kwonjoon Lee", "Tianlong Chen"], "title": "Metacognitive Self-Correction for Multi-Agent System via Prototype-Guided Next-Execution Reconstruction", "comment": null, "summary": "Large Language Model based multi-agent systems (MAS) excel at collaborative\nproblem solving but remain brittle to cascading errors: a single faulty step\ncan propagate across agents and disrupt the trajectory. In this paper, we\npresent MASC, a metacognitive framework that endows MAS with real-time,\nunsupervised, step-level error detection and self-correction. MASC rethinks\ndetection as history-conditioned anomaly scoring via two complementary designs:\n(1) Next-Execution Reconstruction, which predicts the embedding of the next\nstep from the query and interaction history to capture causal consistency, and\n(2) Prototype-Guided Enhancement, which learns a prototype prior over\nnormal-step embeddings and uses it to stabilize reconstruction and anomaly\nscoring under sparse context (e.g., early steps). When an anomaly step is\nflagged, MASC triggers a correction agent to revise the acting agent's output\nbefore information flows downstream. On the Who&When benchmark, MASC\nconsistently outperforms all baselines, improving step-level error detection by\nup to 8.47% AUC-ROC ; When plugged into diverse MAS frameworks, it delivers\nconsistent end-to-end gains across architectures, confirming that our\nmetacognitive monitoring and targeted correction can mitigate error propagation\nwith minimal overhead.", "AI": {"tldr": "MASC\u662f\u4e00\u4e2a\u5143\u8ba4\u77e5\u6846\u67b6\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u65f6\u3001\u65e0\u76d1\u7763\u7684\u6b65\u9aa4\u7ea7\u9519\u8bef\u68c0\u6d4b\u548c\u81ea\u6211\u7ea0\u6b63\uff0c\u901a\u8fc7\u5386\u53f2\u6761\u4ef6\u5f02\u5e38\u8bc4\u5206\u6765\u9632\u6b62\u9519\u8bef\u4f20\u64ad\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u534f\u4f5c\u89e3\u51b3\u95ee\u9898\u65f6\u5bb9\u6613\u53d7\u5230\u7ea7\u8054\u9519\u8bef\u7684\u5f71\u54cd\uff0c\u5355\u4e2a\u9519\u8bef\u6b65\u9aa4\u53ef\u80fd\u5728\u667a\u80fd\u4f53\u95f4\u4f20\u64ad\u5e76\u7834\u574f\u6574\u4e2a\u8f68\u8ff9\u3002", "method": "MASC\u91c7\u7528\u4e24\u79cd\u4e92\u8865\u8bbe\u8ba1\uff1a1\uff09\u4e0b\u4e00\u6267\u884c\u91cd\u6784\uff0c\u4ece\u67e5\u8be2\u548c\u4ea4\u4e92\u5386\u53f2\u9884\u6d4b\u4e0b\u4e00\u6b65\u7684\u5d4c\u5165\u4ee5\u6355\u6349\u56e0\u679c\u4e00\u81f4\u6027\uff1b2\uff09\u539f\u578b\u5f15\u5bfc\u589e\u5f3a\uff0c\u5b66\u4e60\u6b63\u5e38\u6b65\u9aa4\u5d4c\u5165\u7684\u539f\u578b\u5148\u9a8c\uff0c\u5728\u7a00\u758f\u4e0a\u4e0b\u6587\u4e0b\u7a33\u5b9a\u91cd\u6784\u548c\u5f02\u5e38\u8bc4\u5206\u3002\u68c0\u6d4b\u5230\u5f02\u5e38\u6b65\u9aa4\u65f6\u89e6\u53d1\u7ea0\u6b63\u667a\u80fd\u4f53\u3002", "result": "\u5728Who&When\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMASC\u59cb\u7ec8\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6b65\u9aa4\u7ea7\u9519\u8bef\u68c0\u6d4b\u7684AUC-ROC\u63d0\u9ad8\u4e868.47%\uff1b\u5f53\u96c6\u6210\u5230\u4e0d\u540c\u591a\u667a\u80fd\u4f53\u6846\u67b6\u4e2d\u65f6\uff0c\u5728\u5404\u79cd\u67b6\u6784\u4e0a\u5747\u5e26\u6765\u4e00\u81f4\u7684\u7aef\u5230\u7aef\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "MASC\u7684\u5143\u8ba4\u77e5\u76d1\u63a7\u548c\u9488\u5bf9\u6027\u7ea0\u6b63\u80fd\u591f\u4ee5\u6700\u5c0f\u5f00\u9500\u7f13\u89e3\u9519\u8bef\u4f20\u64ad\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9519\u8bef\u68c0\u6d4b\u548c\u7ea0\u6b63\u673a\u5236\u3002"}}
{"id": "2510.14359", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.14359", "abs": "https://arxiv.org/abs/2510.14359", "authors": ["Zichen Wen", "Yiyu Wang", "Chenfei Liao", "Boxue Yang", "Junxian Li", "Weifeng Liu", "Haocong He", "Bolong Feng", "Xuyang Liu", "Yuanhuiyi Lyu", "Xu Zheng", "Xuming Hu", "Linfeng Zhang"], "title": "AI for Service: Proactive Assistance with AI Glasses", "comment": "24 pages, 5 figures, work in progress", "summary": "In an era where AI is evolving from a passive tool into an active and\nadaptive companion, we introduce AI for Service (AI4Service), a new paradigm\nthat enables proactive and real-time assistance in daily life. Existing AI\nservices remain largely reactive, responding only to explicit user commands. We\nargue that a truly intelligent and helpful assistant should be capable of\nanticipating user needs and taking actions proactively when appropriate. To\nrealize this vision, we propose Alpha-Service, a unified framework that\naddresses two fundamental challenges: Know When to intervene by detecting\nservice opportunities from egocentric video streams, and Know How to provide\nboth generalized and personalized services. Inspired by the von Neumann\ncomputer architecture and based on AI glasses, Alpha-Service consists of five\nkey components: an Input Unit for perception, a Central Processing Unit for\ntask scheduling, an Arithmetic Logic Unit for tool utilization, a Memory Unit\nfor long-term personalization, and an Output Unit for natural human\ninteraction. As an initial exploration, we implement Alpha-Service through a\nmulti-agent system deployed on AI glasses. Case studies, including a real-time\nBlackjack advisor, a museum tour guide, and a shopping fit assistant,\ndemonstrate its ability to seamlessly perceive the environment, infer user\nintent, and provide timely and useful assistance without explicit prompts.", "AI": {"tldr": "AI4Service\u662f\u4e00\u79cd\u65b0\u7684AI\u670d\u52a1\u8303\u5f0f\uff0c\u901a\u8fc7Alpha-Service\u6846\u67b6\u5b9e\u73b0\u4e3b\u52a8\u5b9e\u65f6\u8f85\u52a9\uff0c\u89e3\u51b3\"\u4f55\u65f6\u5e72\u9884\"\u548c\"\u5982\u4f55\u670d\u52a1\"\u4e24\u5927\u6311\u6218\uff0c\u57fa\u4e8eAI\u773c\u955c\u90e8\u7f72\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709AI\u670d\u52a1\u591a\u4e3a\u88ab\u52a8\u54cd\u5e94\uff0c\u9700\u8981\u5411\u4e3b\u52a8\u9884\u6d4b\u7528\u6237\u9700\u6c42\u7684\u667a\u80fd\u52a9\u624b\u8f6c\u53d8\uff0c\u63d0\u4f9b\u66f4\u81ea\u7136\u3001\u53ca\u65f6\u7684\u751f\u6d3b\u8f85\u52a9\u3002", "method": "\u63d0\u51faAlpha-Service\u7edf\u4e00\u6846\u67b6\uff0c\u501f\u9274\u51af\u00b7\u8bfa\u4f9d\u66fc\u67b6\u6784\u8bbe\u8ba1\u4e94\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u8f93\u5165\u5355\u5143\u3001\u4e2d\u592e\u5904\u7406\u5355\u5143\u3001\u7b97\u672f\u903b\u8f91\u5355\u5143\u3001\u5185\u5b58\u5355\u5143\u548c\u8f93\u51fa\u5355\u5143\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728AI\u773c\u955c\u4e0a\u5b9e\u73b0\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5b9e\u65f621\u70b9\u987e\u95ee\u3001\u535a\u7269\u9986\u5bfc\u89c8\u548c\u8d2d\u7269\u642d\u914d\u52a9\u624b\u7b49\u5e94\u7528\uff0c\u80fd\u591f\u65e0\u7f1d\u611f\u77e5\u73af\u5883\u3001\u63a8\u65ad\u7528\u6237\u610f\u56fe\u5e76\u63d0\u4f9b\u53ca\u65f6\u6709\u7528\u7684\u5e2e\u52a9\u3002", "conclusion": "AI4Service\u8303\u5f0f\u901a\u8fc7Alpha-Service\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u4ece\u88ab\u52a8\u54cd\u5e94\u5230\u4e3b\u52a8\u8f85\u52a9\u7684\u8f6c\u53d8\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u667a\u80fd\u670d\u52a1\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.14387", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14387", "abs": "https://arxiv.org/abs/2510.14387", "authors": ["Yijie Hu", "Zihao Zhou", "Kaizhu Huang", "Xiaowei Huang", "Qiufeng Wang"], "title": "Can MLLMs Absorb Math Reasoning Abilities from LLMs as Free Lunch?", "comment": null, "summary": "Math reasoning has been one crucial ability of large language models (LLMs),\nwhere significant advancements have been achieved in recent years. However,\nmost efforts focus on LLMs by curating high-quality annotation data and\nintricate training (or inference) paradigms, while the math reasoning\nperformance of multi-modal LLMs (MLLMs) remains lagging behind. Since the MLLM\ntypically consists of an LLM and a vision block, we wonder: Can MLLMs directly\nabsorb math reasoning abilities from off-the-shelf math LLMs without tuning?\nRecent model-merging approaches may offer insights into this question. However,\nthey overlook the alignment between the MLLM and LLM, where we find that there\nis a large gap between their parameter spaces, resulting in lower performance.\nOur empirical evidence reveals two key factors behind this issue: the\nidentification of crucial reasoning-associated layers in the model and the\nmitigation of the gaps in parameter space. Based on the empirical insights, we\npropose IP-Merging that first identifies the reasoning-associated parameters in\nboth MLLM and Math LLM, then projects them into the subspace of MLLM, aiming to\nmaintain the alignment, and finally merges parameters in this subspace.\nIP-Merging is a tuning-free approach since parameters are directly adjusted.\nExtensive experiments demonstrate that our IP-Merging method can enhance the\nmath reasoning ability of MLLMs directly from Math LLMs without compromising\ntheir other capabilities.", "AI": {"tldr": "IP-Merging\u662f\u4e00\u79cd\u65e0\u9700\u8c03\u4f18\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6570\u5b66\u63a8\u7406\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u63a8\u7406\u76f8\u5173\u53c2\u6570\uff0c\u5c06\u5b83\u4eec\u6295\u5f71\u5230\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b50\u7a7a\u95f4\u4e2d\uff0c\u7136\u540e\u5728\u8be5\u5b50\u7a7a\u95f4\u5185\u5408\u5e76\u53c2\u6570\uff0c\u4ece\u800c\u76f4\u63a5\u5c06\u6570\u5b66\u63a8\u7406\u80fd\u529b\u4ece\u6570\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u8f6c\u79fb\u5230\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u843d\u540e\u4e8e\u7eaf\u6587\u672c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u76f4\u63a5\u4f7f\u7528\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u4f1a\u56e0\u53c2\u6570\u7a7a\u95f4\u4e0d\u5339\u914d\u800c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u5728\u4e0d\u8fdb\u884c\u8c03\u4f18\u7684\u60c5\u51b5\u4e0b\uff0c\u8ba9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u4ece\u73b0\u6210\u7684\u6570\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u5438\u6536\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faIP-Merging\u65b9\u6cd5\uff1a1\uff09\u8bc6\u522b\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6570\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u63a8\u7406\u76f8\u5173\u53c2\u6570\uff1b2\uff09\u5c06\u8fd9\u4e9b\u53c2\u6570\u6295\u5f71\u5230\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b50\u7a7a\u95f4\u4e2d\uff1b3\uff09\u5728\u8be5\u5b50\u7a7a\u95f4\u5185\u5408\u5e76\u53c2\u6570\u3002\u8fd9\u662f\u4e00\u4e2a\u65e0\u9700\u8c03\u4f18\u7684\u76f4\u63a5\u53c2\u6570\u8c03\u6574\u65b9\u6cd5\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cIP-Merging\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u4e0d\u4f1a\u635f\u5bb3\u5176\u5176\u4ed6\u80fd\u529b\u3002", "conclusion": "IP-Merging\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u5c06\u6570\u5b66\u63a8\u7406\u80fd\u529b\u4ece\u6570\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u8f6c\u79fb\u5230\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u76ee\u6807\uff0c\u89e3\u51b3\u4e86\u53c2\u6570\u7a7a\u95f4\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u4e14\u65e0\u9700\u8fdb\u884c\u6a21\u578b\u8c03\u4f18\u3002"}}
{"id": "2510.14406", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.14406", "abs": "https://arxiv.org/abs/2510.14406", "authors": ["Xikai Zhang", "Bo Wang", "Likang Xiao", "Yongzhi Li", "Quan Chen", "Wenju Wu", "Liu Liu"], "title": "IMAGINE: Integrating Multi-Agent System into One Model for Complex Reasoning and Planning", "comment": null, "summary": "Although large language models (LLMs) have made significant strides across\nvarious tasks, they still face significant challenges in complex reasoning and\nplanning. For example, even with carefully designed prompts and prior\ninformation explicitly provided, GPT-4o achieves only a 7% Final Pass Rate on\nthe TravelPlanner dataset in the sole-planning mode. Similarly, even in the\nthinking mode, Qwen3-8B-Instruct and DeepSeek-R1-671B, only achieve Final Pass\nRates of 5.9% and 40%, respectively. Although well-organized Multi-Agent\nSystems (MAS) can offer improved collective reasoning, they often suffer from\nhigh reasoning costs due to multi-round internal interactions, long\nper-response latency, and difficulties in end-to-end training. To address these\nchallenges, we propose a general and scalable framework called IMAGINE, short\nfor Integrating Multi-Agent System into One Model. This framework not only\nintegrates the reasoning and planning capabilities of MAS into a single,\ncompact model, but also significantly surpass the capabilities of the MAS\nthrough a simple end-to-end training. Through this pipeline, a single\nsmall-scale model is not only able to acquire the structured reasoning and\nplanning capabilities of a well-organized MAS but can also significantly\noutperform it. Experimental results demonstrate that, when using\nQwen3-8B-Instruct as the base model and training it with our method, the model\nachieves an 82.7% Final Pass Rate on the TravelPlanner benchmark, far exceeding\nthe 40% of DeepSeek-R1-671B, while maintaining a much smaller model size.", "AI": {"tldr": "IMAGINE\u6846\u67b6\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u63a8\u7406\u89c4\u5212\u80fd\u529b\u96c6\u6210\u5230\u5355\u4e00\u7d27\u51d1\u6a21\u578b\u4e2d\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u8bad\u7ec3\u663e\u8457\u8d85\u8d8a\u539f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6027\u80fd\uff0c\u5728TravelPlanner\u57fa\u51c6\u4e0a\u8fbe\u523082.7%\u7684\u6700\u7ec8\u901a\u8fc7\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u548c\u89c4\u5212\u4efb\u52a1\u4e2d\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u867d\u7136\u80fd\u63d0\u4f9b\u6539\u8fdb\u7684\u96c6\u4f53\u63a8\u7406\uff0c\u4f46\u5b58\u5728\u63a8\u7406\u6210\u672c\u9ad8\u3001\u54cd\u5e94\u5ef6\u8fdf\u957f\u548c\u7aef\u5230\u7aef\u8bad\u7ec3\u56f0\u96be\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faIMAGINE\u6846\u67b6\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u63a8\u7406\u89c4\u5212\u80fd\u529b\u96c6\u6210\u5230\u5355\u4e00\u7d27\u51d1\u6a21\u578b\u4e2d\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u7aef\u5230\u7aef\u8bad\u7ec3\u6d41\u7a0b\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\u3002", "result": "\u4ee5Qwen3-8B-Instruct\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u5728TravelPlanner\u57fa\u51c6\u4e0a\u8fbe\u523082.7%\u7684\u6700\u7ec8\u901a\u8fc7\u7387\uff0c\u8fdc\u8d85DeepSeek-R1-671B\u768440%\uff0c\u540c\u65f6\u4fdd\u6301\u66f4\u5c0f\u7684\u6a21\u578b\u89c4\u6a21\u3002", "conclusion": "IMAGINE\u6846\u67b6\u6210\u529f\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u80fd\u529b\u96c6\u6210\u5230\u5355\u4e00\u6a21\u578b\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u89c4\u5212\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u6a21\u578b\u89c4\u6a21\u548c\u63a8\u7406\u6210\u672c\u3002"}}
{"id": "2510.14412", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14412", "abs": "https://arxiv.org/abs/2510.14412", "authors": ["Claudia Grundke", "Gabriele R\u00f6ger"], "title": "Eliminating Negative Occurrences of Derived Predicates from PDDL Axioms", "comment": "Extended version of a paper of the same title presented at the joint\n  KR/ICAPS 2025 workshop \"KRPlan: Knowledge Representation Meets Automated\n  Planning\"", "summary": "Axioms are a feature of the Planning Domain Definition Language PDDL that can\nbe considered as a generalization of database query languages such as Datalog.\nThe PDDL standard restricts negative occurrences of predicates in axiom bodies\nto predicates that are directly set by actions and not derived by axioms. In\nthe literature, authors often deviate from this limitation and only require\nthat the set of axioms is stratifiable. Both variants can express exactly the\nsame queries as least fixed-point logic, indicating that negative occurrences\nof derived predicates can be eliminated. We present the corresponding\ntransformation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8f6c\u6362\u65b9\u6cd5\uff0c\u7528\u4e8e\u6d88\u9664PDDL\u516c\u7406\u4e2d\u6d3e\u751f\u8c13\u8bcd\u7684\u8d1f\u51fa\u73b0\uff0c\u8bc1\u660e\u8fd9\u79cd\u9650\u5236\u53ef\u4ee5\u88ab\u514b\u670d\u3002", "motivation": "PDDL\u6807\u51c6\u9650\u5236\u516c\u7406\u4f53\u4e2d\u8c13\u8bcd\u7684\u8d1f\u51fa\u73b0\u53ea\u80fd\u7528\u4e8e\u76f4\u63a5\u7531\u52a8\u4f5c\u8bbe\u7f6e\u7684\u8c13\u8bcd\uff0c\u800c\u975e\u7531\u516c\u7406\u6d3e\u751f\u7684\u8c13\u8bcd\u3002\u4f46\u6587\u732e\u4e2d\u4f5c\u8005\u7ecf\u5e38\u504f\u79bb\u8fd9\u4e00\u9650\u5236\uff0c\u53ea\u8981\u6c42\u516c\u7406\u96c6\u662f\u53ef\u5206\u5c42\u7684\u3002\u672c\u6587\u65e8\u5728\u8bc1\u660e\u8fd9\u4e24\u79cd\u53d8\u4f53\u53ef\u4ee5\u8868\u8fbe\u76f8\u540c\u7684\u67e5\u8be2\uff0c\u5e76\u5c55\u793a\u76f8\u5e94\u7684\u8f6c\u6362\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8f6c\u6362\u65b9\u6cd5\uff0c\u901a\u8fc7\u6d88\u9664\u516c\u7406\u4e2d\u6d3e\u751f\u8c13\u8bcd\u7684\u8d1f\u51fa\u73b0\uff0c\u5c06\u5305\u542b\u8d1f\u51fa\u73b0\u7684\u516c\u7406\u96c6\u8f6c\u6362\u4e3a\u7b26\u5408PDDL\u6807\u51c6\u9650\u5236\u7684\u5f62\u5f0f\u3002", "result": "\u8bc1\u660e\u4e86\u5305\u542b\u8d1f\u51fa\u73b0\u7684\u516c\u7406\u96c6\u4e0e\u7b26\u5408PDDL\u6807\u51c6\u9650\u5236\u7684\u516c\u7406\u96c6\u5728\u8868\u8fbe\u80fd\u529b\u4e0a\u662f\u7b49\u4ef7\u7684\uff0c\u90fd\u80fd\u8868\u8fbe\u6700\u5c0f\u4e0d\u52a8\u70b9\u903b\u8f91\u4e2d\u7684\u76f8\u540c\u67e5\u8be2\u3002", "conclusion": "PDDL\u516c\u7406\u4e2d\u6d3e\u751f\u8c13\u8bcd\u7684\u8d1f\u51fa\u73b0\u9650\u5236\u53ef\u4ee5\u88ab\u514b\u670d\uff0c\u901a\u8fc7\u672c\u6587\u63d0\u51fa\u7684\u8f6c\u6362\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u8868\u8fbe\u80fd\u529b\u7684\u540c\u65f6\u6ee1\u8db3\u6807\u51c6\u9650\u5236\u3002"}}
{"id": "2510.14512", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14512", "abs": "https://arxiv.org/abs/2510.14512", "authors": ["Haoyuan Li", "Mathias Funk", "Aaqib Saeed"], "title": "Helmsman: Autonomous Synthesis of Federated Learning Systems via Multi-Agent Collaboration", "comment": null, "summary": "Federated Learning (FL) offers a powerful paradigm for training models on\ndecentralized data, but its promise is often undermined by the immense\ncomplexity of designing and deploying robust systems. The need to select,\ncombine, and tune strategies for multifaceted challenges like data\nheterogeneity and system constraints has become a critical bottleneck,\nresulting in brittle, bespoke solutions. To address this, we introduce\nHelmsman, a novel multi-agent system that automates the end-to-end synthesis of\nfederated learning systems from high-level user specifications. It emulates a\nprincipled research and development workflow through three collaborative\nphases: (1) interactive human-in-the-loop planning to formulate a sound\nresearch plan, (2) modular code generation by supervised agent teams, and (3) a\nclosed-loop of autonomous evaluation and refinement in a sandboxed simulation\nenvironment. To facilitate rigorous evaluation, we also introduce\nAgentFL-Bench, a new benchmark comprising 16 diverse tasks designed to assess\nthe system-level generation capabilities of agentic systems in FL. Extensive\nexperiments demonstrate that our approach generates solutions competitive with,\nand often superior to, established hand-crafted baselines. Our work represents\na significant step towards the automated engineering of complex decentralized\nAI systems.", "AI": {"tldr": "Helmsman\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u6a21\u62df\u7814\u53d1\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4ece\u9ad8\u7ea7\u7528\u6237\u89c4\u8303\u81ea\u52a8\u5408\u6210\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\uff0c\u5305\u62ec\u4ea4\u4e92\u5f0f\u89c4\u5212\u3001\u6a21\u5757\u5316\u4ee3\u7801\u751f\u6210\u548c\u81ea\u4e3b\u8bc4\u4f30\u4f18\u5316\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u8bbe\u8ba1\u590d\u6742\uff0c\u9700\u8981\u5904\u7406\u6570\u636e\u5f02\u6784\u6027\u548c\u7cfb\u7edf\u7ea6\u675f\u7b49\u591a\u65b9\u9762\u6311\u6218\uff0c\u5bfc\u81f4\u89e3\u51b3\u65b9\u6848\u8106\u5f31\u4e14\u5b9a\u5236\u5316\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u6765\u964d\u4f4e\u8bbe\u8ba1\u590d\u6742\u6027\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u534f\u4f5c\u65b9\u6cd5\uff1a1)\u4ea4\u4e92\u5f0f\u4eba\u673a\u5faa\u73af\u89c4\u5212\u5236\u5b9a\u7814\u7a76\u8ba1\u5212\uff1b2)\u76d1\u7763\u667a\u80fd\u4f53\u56e2\u961f\u8fdb\u884c\u6a21\u5757\u5316\u4ee3\u7801\u751f\u6210\uff1b3)\u5728\u6c99\u76d2\u6a21\u62df\u73af\u5883\u4e2d\u8fdb\u884c\u81ea\u4e3b\u8bc4\u4f30\u548c\u4f18\u5316\u7684\u95ed\u73af\u6d41\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cHelmsman\u751f\u6210\u7684\u89e3\u51b3\u65b9\u6848\u4e0e\u624b\u5de5\u6784\u5efa\u7684\u57fa\u7ebf\u65b9\u6cd5\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\uff0c\u5e76\u5f15\u5165\u4e86AgentFL-Bench\u57fa\u51c6\u6765\u8bc4\u4f30\u7cfb\u7edf\u7ea7\u751f\u6210\u80fd\u529b\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4ee3\u8868\u4e86\u5411\u590d\u6742\u53bb\u4e2d\u5fc3\u5316AI\u7cfb\u7edf\u81ea\u52a8\u5316\u5de5\u7a0b\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u80fd\u591f\u6709\u6548\u964d\u4f4e\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u8bbe\u8ba1\u7684\u590d\u6742\u6027\u3002"}}
{"id": "2510.14665", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.14665", "abs": "https://arxiv.org/abs/2510.14665", "authors": ["Rikard Rosenbacke", "Carl Rosenbacke", "Victor Rosenbacke", "Martin McKee"], "title": "Beyond Hallucinations: The Illusion of Understanding in Large Language Models", "comment": null, "summary": "Large language models (LLMs) are becoming deeply embedded in human\ncommunication and decision-making, yet they inherit the ambiguity, bias, and\nlack of direct access to truth inherent in language itself. While their outputs\nare fluent, emotionally resonant, and coherent, they are generated through\nstatistical prediction rather than grounded reasoning. This creates the risk of\nhallucination, responses that sound convincing but lack factual validity.\nBuilding on Geoffrey Hinton's observation that AI mirrors human intuition\nrather than reasoning, this paper argues that LLMs operationalize System 1\ncognition at scale: fast, associative, and persuasive, but without reflection\nor falsification. To address this, we introduce the Rose-Frame, a\nthree-dimensional framework for diagnosing cognitive and epistemic drift in\nhuman-AI interaction. The three axes are: (i) Map vs. Territory, which\ndistinguishes representations of reality (epistemology) from reality itself\n(ontology); (ii) Intuition vs. Reason, drawing on dual-process theory to\nseparate fast, emotional judgments from slow, reflective thinking; and (iii)\nConflict vs. Confirmation, which examines whether ideas are critically tested\nthrough disagreement or simply reinforced through mutual validation. Each\ndimension captures a distinct failure mode, and their combination amplifies\nmisalignment. Rose-Frame does not attempt to fix LLMs with more data or rules.\nInstead, it offers a reflective tool that makes both the model's limitations\nand the user's assumptions visible, enabling more transparent and critically\naware AI deployment. It reframes alignment as cognitive governance: intuition,\nwhether human or artificial, must remain governed by human reason. Only by\nembedding reflective, falsifiable oversight can we align machine fluency with\nhuman understanding.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Rose-Frame\u6846\u67b6\uff0c\u7528\u4e8e\u8bca\u65ad\u4eba\u7c7b\u4e0eAI\u4ea4\u4e92\u4e2d\u7684\u8ba4\u77e5\u548c\u8ba4\u8bc6\u8bba\u6f02\u79fb\u95ee\u9898\uff0c\u5f3a\u8c03\u5c06AI\u76f4\u89c9\u7f6e\u4e8e\u4eba\u7c7b\u7406\u6027\u76d1\u7763\u4e4b\u4e0b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u8f93\u51fa\u6d41\u7545\u4e14\u60c5\u611f\u5171\u9e23\u5f3a\uff0c\u4f46\u57fa\u4e8e\u7edf\u8ba1\u9884\u6d4b\u800c\u975e\u624e\u6839\u63a8\u7406\uff0c\u5b58\u5728\u5e7b\u89c9\u98ce\u9669\uff0c\u53ef\u80fd\u4ea7\u751f\u542c\u8d77\u6765\u6709\u8bf4\u670d\u529b\u4f46\u7f3a\u4e4f\u4e8b\u5b9e\u6709\u6548\u6027\u7684\u56de\u7b54\u3002", "method": "\u5f15\u5165Rose-Frame\u4e09\u7ef4\u6846\u67b6\uff1a(i)\u5730\u56fe\u4e0e\u9886\u571f\u533a\u5206\u73b0\u5b9e\u8868\u5f81\u4e0e\u73b0\u5b9e\u672c\u8eab\uff1b(ii)\u76f4\u89c9\u4e0e\u7406\u6027\u533a\u5206\u5feb\u901f\u60c5\u611f\u5224\u65ad\u4e0e\u7f13\u6162\u53cd\u601d\u601d\u7ef4\uff1b(iii)\u51b2\u7a81\u4e0e\u786e\u8ba4\u68c0\u9a8c\u601d\u60f3\u662f\u5426\u901a\u8fc7\u5206\u6b67\u6279\u5224\u6d4b\u8bd5\u8fd8\u662f\u4ec5\u901a\u8fc7\u76f8\u4e92\u9a8c\u8bc1\u5f3a\u5316\u3002", "result": "Rose-Frame\u4e0d\u8bd5\u56fe\u7528\u66f4\u591a\u6570\u636e\u6216\u89c4\u5219\u4fee\u590dLLM\uff0c\u800c\u662f\u63d0\u4f9b\u53cd\u601d\u5de5\u5177\uff0c\u4f7f\u6a21\u578b\u5c40\u9650\u6027\u548c\u7528\u6237\u5047\u8bbe\u53ef\u89c1\uff0c\u5b9e\u73b0\u66f4\u900f\u660e\u548c\u6279\u5224\u6027\u610f\u8bc6\u7684AI\u90e8\u7f72\u3002", "conclusion": "\u91cd\u65b0\u5b9a\u4e49\u5bf9\u9f50\u4e3a\u8ba4\u77e5\u6cbb\u7406\uff1a\u65e0\u8bba\u662f\u4eba\u7c7b\u8fd8\u662f\u4eba\u5de5\u667a\u80fd\u7684\u76f4\u89c9\uff0c\u90fd\u5fc5\u987b\u7531\u4eba\u7c7b\u7406\u6027\u6765\u6cbb\u7406\u3002\u53ea\u6709\u901a\u8fc7\u5d4c\u5165\u53cd\u601d\u6027\u3001\u53ef\u8bc1\u4f2a\u7684\u76d1\u7763\uff0c\u624d\u80fd\u5c06\u673a\u5668\u7684\u6d41\u7545\u6027\u4e0e\u4eba\u7c7b\u7684\u7406\u89e3\u5bf9\u9f50\u3002"}}
{"id": "2510.14669", "categories": ["cs.AI", "68T01, 68T09, 62P10 68T01, 68T09, 62P10", "I.2.6; I.5.4; H.2.8; J.3; K.4.1; K.4.2"], "pdf": "https://arxiv.org/pdf/2510.14669", "abs": "https://arxiv.org/abs/2510.14669", "authors": ["Sara Altamirano", "Arjan Vreeken", "Sennay Ghebreab"], "title": "Machine Learning and Public Health: Identifying and Mitigating Algorithmic Bias through a Systematic Review", "comment": "Extended version of the paper accepted at the AAAI/ACM Conference on\n  AI, Ethics, and Society (AIES 2025), including an appendix. 10 pages, 2\n  figures", "summary": "Machine learning (ML) promises to revolutionize public health through\nimproved surveillance, risk stratification, and resource allocation. However,\nwithout systematic attention to algorithmic bias, ML may inadvertently\nreinforce existing health disparities. We present a systematic literature\nreview of algorithmic bias identification, discussion, and reporting in Dutch\npublic health ML research from 2021 to 2025. To this end, we developed the Risk\nof Algorithmic Bias Assessment Tool (RABAT) by integrating elements from\nestablished frameworks (Cochrane Risk of Bias, PROBAST, Microsoft Responsible\nAI checklist) and applied it to 35 peer-reviewed studies. Our analysis reveals\npervasive gaps: although data sampling and missing data practices are well\ndocumented, most studies omit explicit fairness framing, subgroup analyses, and\ntransparent discussion of potential harms. In response, we introduce a\nfour-stage fairness-oriented framework called ACAR (Awareness,\nConceptualization, Application, Reporting), with guiding questions derived from\nour systematic literature review to help researchers address fairness across\nthe ML lifecycle. We conclude with actionable recommendations for public health\nML practitioners to consistently consider algorithmic bias and foster\ntransparency, ensuring that algorithmic innovations advance health equity\nrather than undermine it.", "AI": {"tldr": "\u672c\u6587\u5bf92021-2025\u5e74\u8377\u5170\u516c\u5171\u536b\u751f\u673a\u5668\u5b66\u4e60\u7814\u7a76\u4e2d\u7684\u7b97\u6cd5\u504f\u89c1\u8fdb\u884c\u4e86\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u5f00\u53d1\u4e86RABAT\u8bc4\u4f30\u5de5\u5177\uff0c\u53d1\u73b0\u666e\u904d\u5b58\u5728\u516c\u5e73\u6027\u6846\u67b6\u7f3a\u5931\u7b49\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86ACAR\u56db\u9636\u6bb5\u6846\u67b6\u6765\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u5728ML\u751f\u547d\u5468\u671f\u4e2d\u89e3\u51b3\u516c\u5e73\u6027\u95ee\u9898\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5728\u516c\u5171\u536b\u751f\u9886\u57df\u5177\u6709\u9769\u547d\u6027\u6f5c\u529b\uff0c\u4f46\u5982\u679c\u4e0d\u7cfb\u7edf\u5173\u6ce8\u7b97\u6cd5\u504f\u89c1\uff0c\u53ef\u80fd\u4f1a\u65e0\u610f\u4e2d\u52a0\u5267\u73b0\u6709\u7684\u5065\u5eb7\u4e0d\u5e73\u7b49\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u8bc4\u4f30\u8377\u5170\u516c\u5171\u536b\u751fML\u7814\u7a76\u4e2d\u7684\u7b97\u6cd5\u504f\u89c1\u8bc6\u522b\u3001\u8ba8\u8bba\u548c\u62a5\u544a\u60c5\u51b5\u3002", "method": "\u5f00\u53d1\u4e86RABAT\u8bc4\u4f30\u5de5\u5177\uff0c\u6574\u5408\u4e86Cochrane\u504f\u89c1\u98ce\u9669\u8bc4\u4f30\u3001PROBAST\u548c\u5fae\u8f6f\u8d1f\u8d23\u4efbAI\u68c0\u67e5\u8868\u7684\u5143\u7d20\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e35\u7bc7\u540c\u884c\u8bc4\u5ba1\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\u3002", "result": "\u5206\u6790\u663e\u793a\u5b58\u5728\u666e\u904d\u5dee\u8ddd\uff1a\u867d\u7136\u6570\u636e\u91c7\u6837\u548c\u7f3a\u5931\u6570\u636e\u5904\u7406\u6709\u826f\u597d\u8bb0\u5f55\uff0c\u4f46\u5927\u591a\u6570\u7814\u7a76\u7f3a\u4e4f\u660e\u786e\u7684\u516c\u5e73\u6027\u6846\u67b6\u3001\u4e9a\u7ec4\u5206\u6790\u4ee5\u53ca\u5bf9\u6f5c\u5728\u5371\u5bb3\u7684\u900f\u660e\u8ba8\u8bba\u3002", "conclusion": "\u63d0\u51fa\u4e86ACAR\u56db\u9636\u6bb5\u516c\u5e73\u6027\u5bfc\u5411\u6846\u67b6\uff0c\u4e3a\u516c\u5171\u536b\u751fML\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u5efa\u8bae\uff0c\u786e\u4fdd\u7b97\u6cd5\u521b\u65b0\u80fd\u591f\u4fc3\u8fdb\u5065\u5eb7\u516c\u5e73\u800c\u975e\u524a\u5f31\u5b83\u3002"}}
{"id": "2510.14676", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14676", "abs": "https://arxiv.org/abs/2510.14676", "authors": ["Bianca Maria Lerma", "Rafael Pe\u00f1aloza"], "title": "NAEL: Non-Anthropocentric Ethical Logic", "comment": "Accepted to the FEAR workshop 2025", "summary": "We introduce NAEL (Non-Anthropocentric Ethical Logic), a novel ethical\nframework for artificial agents grounded in active inference and symbolic\nreasoning. Departing from conventional, human-centred approaches to AI ethics,\nNAEL formalizes ethical behaviour as an emergent property of intelligent\nsystems minimizing global expected free energy in dynamic, multi-agent\nenvironments. We propose a neuro-symbolic architecture to allow agents to\nevaluate the ethical consequences of their actions in uncertain settings. The\nproposed system addresses the limitations of existing ethical models by\nallowing agents to develop context-sensitive, adaptive, and relational ethical\nbehaviour without presupposing anthropomorphic moral intuitions. A case study\ninvolving ethical resource distribution illustrates NAEL's dynamic balancing of\nself-preservation, epistemic learning, and collective welfare.", "AI": {"tldr": "NAEL\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e3b\u52a8\u63a8\u7406\u548c\u7b26\u53f7\u63a8\u7406\u7684\u65b0\u578b\u4eba\u5de5\u667a\u80fd\u4f26\u7406\u6846\u67b6\uff0c\u91c7\u7528\u975e\u4eba\u7c7b\u4e2d\u5fc3\u4e3b\u4e49\u65b9\u6cd5\uff0c\u5c06\u4f26\u7406\u884c\u4e3a\u5f62\u5f0f\u5316\u4e3a\u667a\u80fd\u7cfb\u7edf\u5728\u52a8\u6001\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u6700\u5c0f\u5316\u5168\u5c40\u9884\u671f\u81ea\u7531\u80fd\u91cf\u7684\u6d8c\u73b0\u5c5e\u6027\u3002", "motivation": "\u4f20\u7edf\u4ee5\u4eba\u7c7b\u4e3a\u4e2d\u5fc3\u7684AI\u4f26\u7406\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0cNAEL\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u4e0d\u9884\u8bbe\u4eba\u7c7b\u9053\u5fb7\u76f4\u89c9\u7684\u4f26\u7406\u6846\u67b6\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u53d1\u5c55\u60c5\u5883\u654f\u611f\u3001\u81ea\u9002\u5e94\u548c\u5173\u7cfb\u6027\u7684\u4f26\u7406\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\uff0c\u7ed3\u5408\u4e3b\u52a8\u63a8\u7406\u548c\u7b26\u53f7\u63a8\u7406\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u8bc4\u4f30\u5176\u884c\u4e3a\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u4f26\u7406\u540e\u679c\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u5168\u5c40\u9884\u671f\u81ea\u7531\u80fd\u91cf\u6765\u5b9e\u73b0\u4f26\u7406\u51b3\u7b56\u3002", "result": "\u901a\u8fc7\u4f26\u7406\u8d44\u6e90\u5206\u914d\u7684\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86NAEL\u80fd\u591f\u52a8\u6001\u5e73\u8861\u81ea\u6211\u4fdd\u5b58\u3001\u8ba4\u77e5\u5b66\u4e60\u548c\u96c6\u4f53\u798f\u5229\u7684\u80fd\u529b\uff0c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "NAEL\u4e3a\u4eba\u5de5\u667a\u80fd\u4f26\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u975e\u4eba\u7c7b\u4e2d\u5fc3\u4e3b\u4e49\u65b9\u6cd5\uff0c\u80fd\u591f\u514b\u670d\u73b0\u6709\u4f26\u7406\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u4f7f\u667a\u80fd\u4f53\u5728\u590d\u6742\u73af\u5883\u4e2d\u53d1\u5c55\u51fa\u66f4\u7075\u6d3b\u548c\u81ea\u9002\u5e94\u7684\u4f26\u7406\u884c\u4e3a\u3002"}}
{"id": "2510.14683", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14683", "abs": "https://arxiv.org/abs/2510.14683", "authors": ["Devon Graham", "Kevin Leyton-Brown"], "title": "Practical, Utilitarian Algorithm Configuration", "comment": null, "summary": "Utilitarian algorithm configuration identifies a parameter setting for a\ngiven algorithm that maximizes a user's utility. Utility functions offer a\ntheoretically well-grounded approach to optimizing decision-making under\nuncertainty and are flexible enough to capture a user's preferences over\nalgorithm runtimes (e.g., they can describe a sharp cutoff after which a\nsolution is no longer required, a per-hour cost for compute, or diminishing\nreturns from algorithms that take longer to run). COUP is a recently-introduced\nutilitarian algorithm configuration procedure which was designed mainly to\noffer strong theoretical guarantees about the quality of the configuration it\nreturns, with less attention paid to its practical performance. This paper\ncloses that gap, bringing theoretically-grounded, utilitarian algorithm\nconfiguration to the point where it is competitive with widely used, heuristic\nconfiguration procedures that offer no performance guarantees. We present a\nseries of improvements to COUP that improve its empirical performance without\ndegrading its theoretical guarantees and demonstrate their benefit\nexperimentally. Using a case study, we also illustrate ways of exploring the\nrobustness of a given solution to the algorithm selection problem to variations\nin the utility function.", "AI": {"tldr": "\u672c\u6587\u6539\u8fdb\u4e86COUP\u7b97\u6cd5\u914d\u7f6e\u65b9\u6cd5\uff0c\u4f7f\u5176\u5728\u4fdd\u6301\u7406\u8bba\u4fdd\u8bc1\u7684\u540c\u65f6\uff0c\u5b9e\u9645\u6027\u80fd\u80fd\u591f\u4e0e\u5e7f\u6cdb\u4f7f\u7528\u7684\u542f\u53d1\u5f0f\u914d\u7f6e\u65b9\u6cd5\u7ade\u4e89\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u7b97\u6cd5\u9009\u62e9\u89e3\u51b3\u65b9\u6848\u5bf9\u6548\u7528\u51fd\u6570\u53d8\u5316\u7684\u9c81\u68d2\u6027\u3002", "motivation": "COUP\u662f\u4e00\u79cd\u57fa\u4e8e\u6548\u7528\u7406\u8bba\u7684\u7b97\u6cd5\u914d\u7f6e\u65b9\u6cd5\uff0c\u4e3b\u8981\u5173\u6ce8\u7406\u8bba\u4fdd\u8bc1\u800c\u5ffd\u89c6\u4e86\u5b9e\u9645\u6027\u80fd\u3002\u672c\u6587\u65e8\u5728\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\uff0c\u4f7f\u57fa\u4e8e\u7406\u8bba\u7684\u6548\u7528\u7b97\u6cd5\u914d\u7f6e\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u7ade\u4e89\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u5bf9COUP\u7684\u6539\u8fdb\u63aa\u65bd\uff0c\u5728\u4e0d\u964d\u4f4e\u7406\u8bba\u4fdd\u8bc1\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u5176\u7ecf\u9a8c\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u8fd9\u4e9b\u6539\u8fdb\u7684\u6548\u679c\u3002", "result": "\u6539\u8fdb\u540e\u7684COUP\u5728\u7ecf\u9a8c\u6027\u80fd\u4e0a\u80fd\u591f\u4e0e\u5e7f\u6cdb\u4f7f\u7528\u7684\u542f\u53d1\u5f0f\u914d\u7f6e\u65b9\u6cd5\u7ade\u4e89\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7406\u8bba\u4fdd\u8bc1\u3002", "conclusion": "\u901a\u8fc7\u6539\u8fdbCOUP\uff0c\u6210\u529f\u5c06\u57fa\u4e8e\u7406\u8bba\u7684\u6548\u7528\u7b97\u6cd5\u914d\u7f6e\u65b9\u6cd5\u63d0\u5347\u5230\u5b9e\u7528\u6c34\u5e73\uff0c\u4e3a\u7b97\u6cd5\u914d\u7f6e\u63d0\u4f9b\u4e86\u65e2\u6709\u7406\u8bba\u4fdd\u8bc1\u53c8\u5177\u6709\u7ade\u4e89\u529b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.14697", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14697", "abs": "https://arxiv.org/abs/2510.14697", "authors": ["Bang An", "Yibo Yang", "Philip Torr", "Bernard Ghanem"], "title": "Purifying Task Vectors in Knowledge-Aware Subspace for Model Merging", "comment": null, "summary": "Model merging aims to integrate task-specific abilities from individually\nfine-tuned models into a single model without extra training. In recent model\nmerging methods, task vector has become a fundamental building block, as it can\nencapsulate the residual information from finetuning. However, the merged model\noften suffers from notable performance degradation due to the conflicts caused\nby task-irrelevant redundancy in task vectors. Existing efforts in overcoming\nredundancy by randomly dropping elements in the parameter space involves\nrandomness and lacks knowledge awareness. To address these challenges, in this\nstudy, we propose Purifying TAsk Vectors (PAVE) in knowledge-aware subspace.\nConcretely, we sample some training examples from each task, and feed them into\ntheir corresponding fine-tuned models to acquire the covariance matrices before\nlinear layers. We then perform a context-oriented singular value decomposition,\nwhich accentuates the weight components most relevant to the target knowledge.\nAs a result, we can split fine-tuned model weights into task-relevant and\nredundant components in the knowledge-aware subspace, and purify the task\nvector by pruning the redundant components. To induce fair pruning efforts\nacross models, we further introduce a spectral rank allocation strategy by\noptimizing a normalized activated pruning error. The task vector purification\nby our method as a plug-and-play scheme is applicable across various task\nvector-based merging methods to improve their performance. In experiments, we\ndemonstrate the effectiveness of PAVE across a diverse set of merging methods,\ntasks, and model architectures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86PAVE\u65b9\u6cd5\uff0c\u901a\u8fc7\u77e5\u8bc6\u611f\u77e5\u5b50\u7a7a\u95f4\u51c0\u5316\u4efb\u52a1\u5411\u91cf\uff0c\u6d88\u9664\u4efb\u52a1\u5411\u91cf\u4e2d\u7684\u5197\u4f59\u4fe1\u606f\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u578b\u5408\u5e76\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u4e2d\uff0c\u4efb\u52a1\u5411\u91cf\u5305\u542b\u4efb\u52a1\u65e0\u5173\u7684\u5197\u4f59\u4fe1\u606f\uff0c\u5bfc\u81f4\u5408\u5e76\u6a21\u578b\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u73b0\u6709\u65b9\u6cd5\u968f\u673a\u4e22\u5f03\u53c2\u6570\u5143\u7d20\uff0c\u7f3a\u4e4f\u77e5\u8bc6\u611f\u77e5\u4e14\u5b58\u5728\u968f\u673a\u6027\u3002", "method": "\u63d0\u51faPAVE\u65b9\u6cd5\uff1a1\uff09\u4ece\u6bcf\u4e2a\u4efb\u52a1\u91c7\u6837\u8bad\u7ec3\u6837\u672c\uff0c\u901a\u8fc7\u5fae\u8c03\u6a21\u578b\u83b7\u53d6\u7ebf\u6027\u5c42\u524d\u7684\u534f\u65b9\u5dee\u77e9\u9635\uff1b2\uff09\u6267\u884c\u4e0a\u4e0b\u6587\u5bfc\u5411\u7684\u5947\u5f02\u503c\u5206\u89e3\uff0c\u7a81\u51fa\u4e0e\u76ee\u6807\u77e5\u8bc6\u6700\u76f8\u5173\u7684\u6743\u91cd\u5206\u91cf\uff1b3\uff09\u5728\u77e5\u8bc6\u611f\u77e5\u5b50\u7a7a\u95f4\u4e2d\u5c06\u5fae\u8c03\u6a21\u578b\u6743\u91cd\u5206\u4e3a\u4efb\u52a1\u76f8\u5173\u548c\u5197\u4f59\u7ec4\u4ef6\uff0c\u901a\u8fc7\u4fee\u526a\u5197\u4f59\u7ec4\u4ef6\u51c0\u5316\u4efb\u52a1\u5411\u91cf\uff1b4\uff09\u5f15\u5165\u8c31\u79e9\u5206\u914d\u7b56\u7565\u4f18\u5316\u5f52\u4e00\u5316\u6fc0\u6d3b\u4fee\u526a\u8bef\u5dee\u3002", "result": "PAVE\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u57fa\u4e8e\u4efb\u52a1\u5411\u91cf\u7684\u5408\u5e76\u65b9\u6cd5\uff0c\u5728\u591a\u79cd\u5408\u5e76\u65b9\u6cd5\u3001\u4efb\u52a1\u548c\u6a21\u578b\u67b6\u6784\u4e0a\u5747\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002", "conclusion": "PAVE\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u51c0\u5316\u4efb\u52a1\u5411\u91cf\u4e2d\u7684\u5197\u4f59\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u5408\u5e76\u6027\u80fd\uff0c\u4e14\u5177\u6709\u826f\u597d\u7684\u901a\u7528\u6027\u548c\u9002\u7528\u6027\u3002"}}
{"id": "2510.14702", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14702", "abs": "https://arxiv.org/abs/2510.14702", "authors": ["Penglong Zhai", "Jie Li", "Fanyi Di", "Yue Liu", "Yifang Yuan", "Jie Huang", "Peng Wu", "Sicong Wang", "Mingyang Yin", "Tingting Hu", "Yao Xu", "Xin Li"], "title": "Cognitive-Aligned Spatio-Temporal Large Language Models For Next Point-of-Interest Prediction", "comment": "12 pages, 5 figures", "summary": "The next point-of-interest (POI) recommendation task aims to predict the\nusers' immediate next destinations based on their preferences and historical\ncheck-ins, holding significant value in location-based services. Recently,\nlarge language models (LLMs) have shown great potential in recommender systems,\nwhich treat the next POI prediction in a generative manner. However, these\nLLMs, pretrained primarily on vast corpora of unstructured text, lack the\nnative understanding of structured geographical entities and sequential\nmobility patterns required for next POI prediction tasks. Moreover, in\nindustrial-scale POI prediction applications, incorporating world knowledge and\nalignment of human cognition, such as seasons, weather conditions, holidays,\nand users' profiles (such as habits, occupation, and preferences), can enhance\nthe user experience while improving recommendation performance. To address\nthese issues, we propose CoAST (Cognitive-Aligned Spatial-Temporal LLMs), a\nframework employing natural language as an interface, allowing for the\nincorporation of world knowledge, spatio-temporal trajectory patterns,\nprofiles, and situational information. Specifically, CoAST mainly comprises of\n2 stages: (1) Recommendation Knowledge Acquisition through continued\npretraining on the enriched spatial-temporal trajectory data of the\ndesensitized users; (2) Cognitive Alignment to align cognitive judgments with\nhuman preferences using enriched training data through Supervised Fine-Tuning\n(SFT) and a subsequent Reinforcement Learning (RL) phase. Extensive offline\nexperiments on various real-world datasets and online experiments deployed in\n\"Guess Where You Go\" of AMAP App homepage demonstrate the effectiveness of\nCoAST.", "AI": {"tldr": "CoAST\u662f\u4e00\u4e2a\u8ba4\u77e5\u5bf9\u9f50\u7684\u65f6\u7a7a\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u754c\u9762\u6574\u5408\u4e16\u754c\u77e5\u8bc6\u3001\u65f6\u7a7a\u8f68\u8ff9\u6a21\u5f0f\u548c\u7528\u6237\u4fe1\u606f\uff0c\u7528\u4e8e\u4e0b\u4e00\u4e2a\u5174\u8da3\u70b9\u63a8\u8350\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u57fa\u4e8e\u975e\u7ed3\u6784\u5316\u6587\u672c\u9884\u8bad\u7ec3\uff0c\u7f3a\u4e4f\u5bf9\u7ed3\u6784\u5316\u5730\u7406\u5b9e\u4f53\u548c\u5e8f\u5217\u79fb\u52a8\u6a21\u5f0f\u7684\u7406\u89e3\uff0c\u4e14\u9700\u8981\u6574\u5408\u4e16\u754c\u77e5\u8bc6\u548c\u4eba\u7c7b\u8ba4\u77e5\u5bf9\u9f50\u6765\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002", "method": "CoAST\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a(1) \u5728\u53bb\u654f\u611f\u5316\u7528\u6237\u7684\u4e30\u5bcc\u65f6\u7a7a\u8f68\u8ff9\u6570\u636e\u4e0a\u7ee7\u7eed\u9884\u8bad\u7ec3\u4ee5\u83b7\u53d6\u63a8\u8350\u77e5\u8bc6\uff1b(2) \u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u5c06\u8ba4\u77e5\u5224\u65ad\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u79bb\u7ebf\u5b9e\u9a8c\u548c\u5728AMAP App\u9996\u9875\"\u731c\u4f60\u53bb\u54ea\"\u529f\u80fd\u4e2d\u7684\u5728\u7ebf\u5b9e\u9a8c\u8bc1\u660e\u4e86CoAST\u7684\u6709\u6548\u6027\u3002", "conclusion": "CoAST\u6846\u67b6\u80fd\u591f\u6709\u6548\u6574\u5408\u4e16\u754c\u77e5\u8bc6\u3001\u65f6\u7a7a\u8f68\u8ff9\u6a21\u5f0f\u548c\u8ba4\u77e5\u5bf9\u9f50\uff0c\u63d0\u5347\u4e0b\u4e00\u4e2a\u5174\u8da3\u70b9\u63a8\u8350\u7684\u6027\u80fd\u3002"}}
{"id": "2510.14703", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14703", "abs": "https://arxiv.org/abs/2510.14703", "authors": ["Jianghao Lin", "Yuanyuan Shi", "Xin Peng", "Renjie Ding", "Hairui Wang", "Yuxuan Peng", "Bizhe Bai", "Weixi Song", "Fengshuo Bai", "Huacan Chai", "Weinan Zhang", "Fei Huang", "Ying Wen"], "title": "ToolPRM: Fine-Grained Inference Scaling of Structured Outputs for Function Calling", "comment": null, "summary": "Large language models (LLMs) are increasingly demonstrating strong\ncapabilities as autonomous agents, with function calling serving as a core\nmechanism for interaction with the environment. Meanwhile, inference scaling\nhas become a cutting-edge technique to enhance LLM performance by allocating\nmore computational resources during the inference process. However, current\nresearch on inference scaling primarily focuses on unstructured output\ngeneration tasks, leaving its application in structured outputs, like function\ncalling, largely underexplored. To bridge this gap, we propose an inference\nscaling framework that combines fine-grained beam search with a process reward\nmodel, ToolPRM, which scores the internal steps of each single function call.\nTo train ToolPRM, we construct the first fine-grained intra-call process\nsupervision dataset, automatically annotated with function-masking techniques\nto provide step-level rewards for structured tool-use reasoning. Extensive\nexperiments demonstrate that ToolPRM beats the coarse-grained and outcome\nreward models in terms of predictive accuracy, indicating its stronger\ncapability in supervising the function calling inference process. Inference\nscaling technique equipped with ToolPRM also significantly improves the\nbackbone model performance across various function calling tasks and\nbenchmarks. More importantly, we reveal a key principle for applying inference\nscaling techniques to structured outputs: \"explore more but retain less\" due to\nthe unrecoverability characteristics of structured function calling generation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u7ec6\u7c92\u5ea6\u6ce2\u675f\u641c\u7d22\u548c\u8fc7\u7a0b\u5956\u52b1\u6a21\u578bToolPRM\u7684\u63a8\u7406\u6269\u5c55\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u6784\u5316\u8f93\u51fa\uff08\u5982\u51fd\u6570\u8c03\u7528\uff09\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u63a8\u7406\u6269\u5c55\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u975e\u7ed3\u6784\u5316\u8f93\u51fa\u751f\u6210\u4efb\u52a1\uff0c\u800c\u5728\u7ed3\u6784\u5316\u8f93\u51fa\uff08\u5982\u51fd\u6570\u8c03\u7528\uff09\u4e2d\u7684\u5e94\u7528\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51faToolPRM\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u901a\u8fc7\u51fd\u6570\u63a9\u7801\u6280\u672f\u81ea\u52a8\u6784\u5efa\u9996\u4e2a\u7ec6\u7c92\u5ea6\u8c03\u7528\u5185\u8fc7\u7a0b\u76d1\u7763\u6570\u636e\u96c6\uff0c\u4e3a\u7ed3\u6784\u5316\u5de5\u5177\u4f7f\u7528\u63a8\u7406\u63d0\u4f9b\u6b65\u9aa4\u7ea7\u5956\u52b1\u3002\u7ed3\u5408\u7ec6\u7c92\u5ea6\u6ce2\u675f\u641c\u7d22\u8fdb\u884c\u63a8\u7406\u6269\u5c55\u3002", "result": "ToolPRM\u5728\u9884\u6d4b\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u7c97\u7c92\u5ea6\u548c\u7ed3\u679c\u5956\u52b1\u6a21\u578b\uff0c\u8868\u660e\u5176\u5728\u76d1\u7763\u51fd\u6570\u8c03\u7528\u63a8\u7406\u8fc7\u7a0b\u65b9\u9762\u5177\u6709\u66f4\u5f3a\u80fd\u529b\u3002\u914d\u5907ToolPRM\u7684\u63a8\u7406\u6269\u5c55\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u9aa8\u5e72\u6a21\u578b\u5728\u5404\u79cd\u51fd\u6570\u8c03\u7528\u4efb\u52a1\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u6027\u80fd\u3002", "conclusion": "\u63ed\u793a\u4e86\u5c06\u63a8\u7406\u6269\u5c55\u6280\u672f\u5e94\u7528\u4e8e\u7ed3\u6784\u5316\u8f93\u51fa\u7684\u5173\u952e\u539f\u5219\uff1a\"\u591a\u63a2\u7d22\u5c11\u4fdd\u7559\"\uff0c\u8fd9\u662f\u7531\u4e8e\u7ed3\u6784\u5316\u51fd\u6570\u8c03\u7528\u751f\u6210\u7684\u4e0d\u53ef\u6062\u590d\u6027\u7279\u5f81\u51b3\u5b9a\u7684\u3002"}}
{"id": "2510.14807", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14807", "abs": "https://arxiv.org/abs/2510.14807", "authors": ["Ruotian Peng", "Yi Ren", "Zhouliang Yu", "Weiyang Liu", "Yandong Wen"], "title": "SimKO: Simple Pass@K Policy Optimization", "comment": "Technical report (20 pages, 10 figures, project page:\n  https://spherelab.ai/simko/)", "summary": "Reinforcement learning with verifiable rewards (RLVR) has advanced the\nreasoning capabilities of large language models (LLMs). However, prevailing\nRLVR methods exhibit a systematic bias toward exploitation over exploration, as\nevidenced by improved pass@1 but reduced pass@K (K>1) performance. To\nunderstand this issue, we analyze training dynamics of RLVR methods by tracking\nthe token-level probability distributions over vocabulary candidates. Our\nanalysis reveals a consistent probability concentration effect where the top-1\ncandidate increasingly accumulates probability mass and suppresses that of\nother candidates. More importantly, stronger over-concentration correlates with\nworse pass@K performance. Inspired by this finding, we propose Simple Pass@K\nOptimization (SimKO), a method designed to mitigate the over-concentration\nissue, thereby encouraging exploration. SimKO operates in an asymmetrical\nmanner. For verified-correct responses, it boosts the probabilities of the\ntop-K candidates. For verified-incorrect responses, it applies stronger\npenalties to the top-1 candidate. We observe that this asymmetric design is\nparticularly effective at mitigating over-concentration when applied at tokens\nwith high entropy. Across various math and logical-reasoning benchmarks, SimKO\nconsistently yields higher pass@K for a wide range of K, providing a simple way\nto improve RLVR's exploration.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86RLVR\u65b9\u6cd5\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u5b58\u5728\u7684\u7cfb\u7edf\u6027\u504f\u5dee\u95ee\u9898\uff0c\u63d0\u51fa\u4e86SimKO\u65b9\u6cd5\u6765\u7f13\u89e3\u6982\u7387\u8fc7\u5ea6\u96c6\u4e2d\u73b0\u8c61\uff0c\u4ece\u800c\u63d0\u9ad8\u63a2\u7d22\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684RLVR\u65b9\u6cd5\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u503e\u5411\u4e8e\u5229\u7528\u800c\u975e\u63a2\u7d22\uff0c\u8868\u73b0\u4e3apass@1\u6027\u80fd\u63d0\u5347\u4f46pass@K\u6027\u80fd\u4e0b\u964d\u3002\u9700\u8981\u7406\u89e3\u8fd9\u4e00\u95ee\u9898\u7684\u8bad\u7ec3\u52a8\u6001\u5e76\u627e\u5230\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u8ddf\u8e2a\u8bcd\u6c47\u5019\u9009\u7684token\u7ea7\u6982\u7387\u5206\u5e03\u5206\u6790\u8bad\u7ec3\u52a8\u6001\uff0c\u53d1\u73b0\u6982\u7387\u96c6\u4e2d\u6548\u5e94\u3002\u63d0\u51faSimKO\u65b9\u6cd5\uff0c\u91c7\u7528\u975e\u5bf9\u79f0\u8bbe\u8ba1\uff1a\u5bf9\u9a8c\u8bc1\u6b63\u786e\u7684\u54cd\u5e94\u63d0\u5347top-K\u5019\u9009\u6982\u7387\uff0c\u5bf9\u9a8c\u8bc1\u9519\u8bef\u7684\u54cd\u5e94\u5bf9top-1\u5019\u9009\u65bd\u52a0\u66f4\u5f3a\u60e9\u7f5a\u3002", "result": "SimKO\u5728\u5404\u79cd\u6570\u5b66\u548c\u903b\u8f91\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5bf9\u5e7f\u6cdb\u7684K\u503c\u8303\u56f4\u90fd\u80fd\u83b7\u5f97\u66f4\u9ad8\u7684pass@K\u6027\u80fd\u3002", "conclusion": "SimKO\u901a\u8fc7\u7f13\u89e3\u6982\u7387\u8fc7\u5ea6\u96c6\u4e2d\u95ee\u9898\uff0c\u6709\u6548\u9f13\u52b1\u4e86\u63a2\u7d22\uff0c\u4e3a\u6539\u8fdbRLVR\u7684\u63a2\u7d22\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u65b9\u6cd5\u3002"}}
{"id": "2510.14828", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.14828", "abs": "https://arxiv.org/abs/2510.14828", "authors": ["Jinrui Liu", "Bingyan Nie", "Boyu Li", "Yaran Chen", "Yuze Wang", "Shunsen He", "Haoran Li"], "title": "RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning", "comment": null, "summary": "Improving the reasoning capabilities of embodied agents is crucial for robots\nto complete complex human instructions in long-view manipulation tasks\nsuccessfully. Despite the success of large language models and vision language\nmodels based on Supervised Fine-Tuning (SFT) in planning tasks, they continue\nfacing challenges in performing long-horizon manipulation tasks in complex\nreal-world environments, owing to their restricted common sense and reasoning\ncapabilities. Considering that aligning general-purpose vision language models\nto robotic planning tasks via supervised fine-tuning suffers from poor\ngeneralization and insufficient physical understanding, we propose RoboGPT-R1,\na two-stage fine-tuning framework for embodied planning. In this framework,\nsupervised training acquires foundational knowledge through expert sequences,\nfollowed by RL to address the model's shortcomings in visual-spatial\nunderstanding and reasoning. To achieve physical understanding and action\nsequence consistency in multi-step reasoning tasks, we design a rule-based\nreward function that simultaneously considers long-horizon performance and\naction constraint in the environment. The reasoning model, trained on\nQwen2.5-VL-3B, significantly outperforms the larger-scale model, GPT-4o-mini,\nby 21.33% and surpasses other work trained on Qwen2.5-VL-7B by 20.33% on the\nEmbodiedBench benchmark.", "AI": {"tldr": "\u63d0\u51faRoboGPT-R1\u4e24\u9636\u6bb5\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u7763\u8bad\u7ec3\u83b7\u53d6\u57fa\u7840\u77e5\u8bc6\uff0c\u518d\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u89c6\u89c9\u7a7a\u95f4\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\uff0c\u5728EmbodiedBench\u57fa\u51c6\u4e0a\u663e\u8457\u8d85\u8d8aGPT-4o-mini\u7b49\u6a21\u578b\u3002", "motivation": "\u63d0\u5347\u5177\u8eab\u667a\u80fd\u4f53\u5728\u590d\u6742\u771f\u5b9e\u73af\u5883\u4e2d\u5b8c\u6210\u957f\u89c6\u8ddd\u64cd\u4f5c\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u89e3\u51b3\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5e38\u8bc6\u548c\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u9650\u5236\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5fae\u8c03\u6846\u67b6\uff1a\u76d1\u7763\u8bad\u7ec3\u4ece\u4e13\u5bb6\u5e8f\u5217\u5b66\u4e60\u57fa\u7840\u77e5\u8bc6\uff0c\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u6a21\u578b\u5728\u89c6\u89c9\u7a7a\u95f4\u7406\u89e3\u548c\u63a8\u7406\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\u51fd\u6570\u8003\u8651\u957f\u89c6\u8ddd\u6027\u80fd\u548c\u52a8\u4f5c\u7ea6\u675f\u3002", "result": "\u5728Qwen2.5-VL-3B\u4e0a\u8bad\u7ec3\u7684\u63a8\u7406\u6a21\u578b\u5728EmbodiedBench\u57fa\u51c6\u4e0a\u6bd4GPT-4o-mini\u63d0\u534721.33%\uff0c\u6bd4Qwen2.5-VL-7B\u7684\u5176\u4ed6\u5de5\u4f5c\u63d0\u534720.33%\u3002", "conclusion": "RoboGPT-R1\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u5177\u8eab\u667a\u80fd\u4f53\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5728\u957f\u89c6\u8ddd\u64cd\u4f5c\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u5f25\u8865\u76d1\u7763\u5fae\u8c03\u4e0d\u8db3\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.14842", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14842", "abs": "https://arxiv.org/abs/2510.14842", "authors": ["Ben Elder", "Evelyn Duesterwald", "Vinod Muthusamy"], "title": "Boosting Instruction Following at Scale", "comment": "6+4 pages, 7 figures, 2 tables", "summary": "A typical approach developers follow to influence an LLM's behavior in an\napplication is through careful manipulation of the prompt, such as by adding or\nmodifying instructions. However, merely adding more instructions provides\nlittle assurance that they will actually be followed. We introduce Instruction\nBoosting as a post-generation method to increase the reliability of LLM prompt\ninstructions. We show that Instruction Boosting improves the instruction\nfollowing rate by up to 7 points for two instructions and up to 4 points for\nten instructions. To demonstrate these results we introduce SCALEDIF, a\nbenchmark with a scaled instruction volume of up to ten instructions per data\nsample. We also present an analysis of the commonly observed trend that\nperformance degrades as more instructions are added. We show that an important\nfactor contributing to this trend is the degree of tension and conflict that\narises as the number of instructions is increased. We contribute a quantitative\nconflict scoring tool that explains the observed performance trends and\nprovides feedback to developers on the impact that additional prompt\ninstructions have on a model's performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Instruction Boosting\u65b9\u6cd5\uff0c\u901a\u8fc7\u540e\u751f\u6210\u5904\u7406\u6765\u63d0\u9ad8LLM\u5bf9\u63d0\u793a\u6307\u4ee4\u7684\u9075\u5faa\u53ef\u9760\u6027\uff0c\u5728\u5305\u542b\u6700\u591a10\u6761\u6307\u4ee4\u7684SCALEDIF\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u6307\u4ee4\u9075\u5faa\u7387\u63d0\u53474-7\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u5f00\u53d1\u4eba\u5458\u901a\u5e38\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u63d0\u793a\u6765\u5f71\u54cdLLM\u884c\u4e3a\uff0c\u4f46\u4ec5\u4ec5\u6dfb\u52a0\u66f4\u591a\u6307\u4ee4\u5e76\u4e0d\u80fd\u4fdd\u8bc1\u5b83\u4eec\u4f1a\u88ab\u5b9e\u9645\u9075\u5faa\uff0c\u9700\u8981\u63d0\u9ad8\u6307\u4ee4\u9075\u5faa\u7684\u53ef\u9760\u6027\u3002", "method": "\u5f15\u5165Instruction Boosting\u4f5c\u4e3a\u540e\u751f\u6210\u65b9\u6cd5\uff0c\u5e76\u521b\u5efaSCALEDIF\u57fa\u51c6\u6765\u8bc4\u4f30\u591a\u6307\u4ee4\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5f00\u53d1\u4e86\u5b9a\u91cf\u51b2\u7a81\u8bc4\u5206\u5de5\u5177\u6765\u5206\u6790\u6307\u4ee4\u95f4\u7684\u51b2\u7a81\u3002", "result": "Instruction Boosting\u5c06\u4e24\u6761\u6307\u4ee4\u7684\u9075\u5faa\u7387\u63d0\u9ad8\u4e867\u4e2a\u767e\u5206\u70b9\uff0c\u5341\u6761\u6307\u4ee4\u7684\u9075\u5faa\u7387\u63d0\u9ad8\u4e864\u4e2a\u767e\u5206\u70b9\u3002\u5206\u6790\u53d1\u73b0\u6027\u80fd\u4e0b\u964d\u4e0e\u6307\u4ee4\u95f4\u51b2\u7a81\u7a0b\u5ea6\u76f8\u5173\u3002", "conclusion": "Instruction Boosting\u80fd\u6709\u6548\u63d0\u9ad8LLM\u5bf9\u591a\u6307\u4ee4\u7684\u9075\u5faa\u53ef\u9760\u6027\uff0c\u51b2\u7a81\u8bc4\u5206\u5de5\u5177\u53ef\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u5173\u4e8e\u6dfb\u52a0\u989d\u5916\u6307\u4ee4\u5bf9\u6a21\u578b\u6027\u80fd\u5f71\u54cd\u7684\u53cd\u9988\u3002"}}
{"id": "2510.14846", "categories": ["cs.AI", "cs.CL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.14846", "abs": "https://arxiv.org/abs/2510.14846", "authors": ["Zhuo-Yang Song"], "title": "Where to Search: Measure the Prior-Structured Search Space of LLM Agents", "comment": "10 pages, 2 figures, 1 table", "summary": "The generate-filter-refine (iterative paradigm) based on large language\nmodels (LLMs) has achieved progress in reasoning, programming, and program\ndiscovery in AI+Science. However, the effectiveness of search depends on where\nto search, namely, how to encode the domain prior into an operationally\nstructured hypothesis space. To this end, this paper proposes a compact formal\ntheory that describes and measures LLM-assisted iterative search guided by\ndomain priors. We represent an agent as a fuzzy relation operator on inputs and\noutputs to capture feasible transitions; the agent is thereby constrained by a\nfixed safety envelope. To describe multi-step reasoning/search, we weight all\nreachable paths by a single continuation parameter and sum them to obtain a\ncoverage generating function; this induces a measure of reachability\ndifficulty; and it provides a geometric interpretation of search on the graph\ninduced by the safety envelope. We further provide the simplest testable\ninferences and validate them via a majority-vote instantiation. This theory\noffers a workable language and operational tools to measure agents and their\nsearch spaces, proposing a systematic formal description of iterative search\nconstructed by LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7d27\u51d1\u7684\u5f62\u5f0f\u7406\u8bba\uff0c\u7528\u4e8e\u63cf\u8ff0\u548c\u6d4b\u91cf\u57fa\u4e8e\u9886\u57df\u5148\u9a8c\u6307\u5bfc\u7684LLM\u8f85\u52a9\u8fed\u4ee3\u641c\u7d22\u3002\u901a\u8fc7\u5c06\u667a\u80fd\u4f53\u8868\u793a\u4e3a\u8f93\u5165\u8f93\u51fa\u7684\u6a21\u7cca\u5173\u7cfb\u7b97\u5b50\uff0c\u5e76\u5f15\u5165\u8986\u76d6\u751f\u6210\u51fd\u6570\u6765\u91cf\u5316\u53ef\u8fbe\u6027\u96be\u5ea6\uff0c\u4e3aLLM\u6784\u5efa\u7684\u8fed\u4ee3\u641c\u7d22\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u5f62\u5f0f\u63cf\u8ff0\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u751f\u6210-\u8fc7\u6ee4-\u7cbe\u70bc\u8fed\u4ee3\u8303\u5f0f\u5728\u63a8\u7406\u3001\u7f16\u7a0b\u548c\u79d1\u5b66\u53d1\u73b0\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u641c\u7d22\u6548\u679c\u4f9d\u8d56\u4e8e\u5982\u4f55\u5c06\u9886\u57df\u5148\u9a8c\u7f16\u7801\u4e3a\u64cd\u4f5c\u5316\u7ed3\u6784\u5316\u7684\u5047\u8bbe\u7a7a\u95f4\u3002\u9700\u8981\u5efa\u7acb\u5f62\u5f0f\u7406\u8bba\u6765\u7cfb\u7edf\u63cf\u8ff0\u548c\u6d4b\u91cf\u8fd9\u79cd\u641c\u7d22\u8fc7\u7a0b\u3002", "method": "1. \u5c06\u667a\u80fd\u4f53\u8868\u793a\u4e3a\u8f93\u5165\u8f93\u51fa\u7684\u6a21\u7cca\u5173\u7cfb\u7b97\u5b50\uff0c\u53d7\u56fa\u5b9a\u5b89\u5168\u5305\u7edc\u7ea6\u675f\uff1b2. \u5f15\u5165\u5355\u5ef6\u7eed\u53c2\u6570\u52a0\u6743\u6240\u6709\u53ef\u8fbe\u8def\u5f84\uff0c\u6c42\u548c\u5f97\u5230\u8986\u76d6\u751f\u6210\u51fd\u6570\uff1b3. \u63a8\u5bfc\u53ef\u8fbe\u6027\u96be\u5ea6\u5ea6\u91cf\uff1b4. \u63d0\u4f9b\u5b89\u5168\u5305\u7edc\u8bf1\u5bfc\u56fe\u4e0a\u7684\u641c\u7d22\u51e0\u4f55\u89e3\u91ca\uff1b5. \u901a\u8fc7\u591a\u6570\u6295\u7968\u5b9e\u4f8b\u9a8c\u8bc1\u53ef\u6d4b\u8bd5\u63a8\u65ad\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u64cd\u4f5c\u7684\u8bed\u8a00\u548c\u5de5\u5177\u6765\u6d4b\u91cf\u667a\u80fd\u4f53\u53ca\u5176\u641c\u7d22\u7a7a\u95f4\uff0c\u4e3aLLM\u6784\u5efa\u7684\u8fed\u4ee3\u641c\u7d22\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u5f62\u5f0f\u63cf\u8ff0\u6846\u67b6\u3002", "conclusion": "\u8be5\u7406\u8bba\u4e3a\u57fa\u4e8e\u9886\u57df\u5148\u9a8c\u6307\u5bfc\u7684LLM\u8f85\u52a9\u8fed\u4ee3\u641c\u7d22\u63d0\u4f9b\u4e86\u7d27\u51d1\u7684\u5f62\u5f0f\u63cf\u8ff0\u548c\u6d4b\u91cf\u65b9\u6cd5\uff0c\u5efa\u7acb\u4e86\u7cfb\u7edf\u5316\u7684\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2510.14913", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14913", "abs": "https://arxiv.org/abs/2510.14913", "authors": ["Kyle Montgomery", "Sijun Tan", "Yuqi Chen", "Siyuan Zhuang", "Tianjun Zhang", "Raluca Ada Popa", "Chenguang Wang"], "title": "Budget-aware Test-time Scaling via Discriminative Verification", "comment": null, "summary": "Test-time scaling is a powerful strategy for boosting the performance of\nlarge language models on complex reasoning tasks. While state-of-the-art\napproaches often employ generative verifiers to select the best solution from a\npool of candidates, this method incurs prohibitive computational costs,\nlimiting its practicality. In this work, we shift the focus to a more\nbudget-aware paradigm: discriminative verification. We conduct a thorough\nempirical analysis and demonstrate that while discriminative verifiers may\nunderperform in isolation, combining them with self-consistency in a hybrid\napproach creates a powerful and efficient test-time scaling mechanism. Notably,\nunder a fixed compute budget, this hybrid approach surpasses state-of-the-art\ngenerative verification by a significant margin: achieving up to 15.3\\% higher\naccuracy on AIME2025. Our findings establish that for practical, real-world\napplications, budget-aware scaling with discriminative verifiers is not only a\n\"free\" upgrade over self-consistency, but also a more effective and efficient\nalternative to costly generative techniques. Code is available at\nhttps://github.com/wang-research-lab/verification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9884\u7b97\u611f\u77e5\u7684\u5224\u522b\u5f0f\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u7ed3\u5408\u81ea\u4e00\u81f4\u6027\u673a\u5236\uff0c\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u663e\u8457\u4f18\u4e8e\u751f\u6210\u5f0f\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u5728AIME2025\u4e0a\u51c6\u786e\u7387\u63d0\u5347\u8fbe15.3%\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u751f\u6210\u5f0f\u9a8c\u8bc1\u5668\u7684\u65b9\u6cd5\u867d\u7136\u80fd\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u91c7\u7528\u5224\u522b\u5f0f\u9a8c\u8bc1\u5668\u4e0e\u81ea\u4e00\u81f4\u6027\u76f8\u7ed3\u5408\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u8fdb\u884c\u6d4b\u8bd5\u65f6\u6269\u5c55\u3002", "result": "\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\uff0c\u8be5\u65b9\u6cd5\u5728AIME2025\u4e0a\u6bd4\u6700\u5148\u8fdb\u7684\u751f\u6210\u5f0f\u9a8c\u8bc1\u65b9\u6cd5\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe15.3%\u3002", "conclusion": "\u9884\u7b97\u611f\u77e5\u7684\u5224\u522b\u5f0f\u9a8c\u8bc1\u4e0d\u4ec5\u662f\u5bf9\u81ea\u4e00\u81f4\u6027\u7684\u514d\u8d39\u5347\u7ea7\uff0c\u800c\u4e14\u662f\u6bd4\u6602\u8d35\u7684\u751f\u6210\u5f0f\u6280\u672f\u66f4\u6709\u6548\u548c\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2510.14922", "categories": ["cs.AI", "cs.CL", "cs.LG", "eess.AS", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.14922", "abs": "https://arxiv.org/abs/2510.14922", "authors": ["Annisaa Fitri Nurfidausi", "Eleonora Mancini", "Paolo Torroni"], "title": "TRI-DEP: A Trimodal Comparative Study for Depression Detection Using Speech, Text, and EEG", "comment": null, "summary": "Depression is a widespread mental health disorder, yet its automatic\ndetection remains challenging. Prior work has explored unimodal and multimodal\napproaches, with multimodal systems showing promise by leveraging complementary\nsignals. However, existing studies are limited in scope, lack systematic\ncomparisons of features, and suffer from inconsistent evaluation protocols. We\naddress these gaps by systematically exploring feature representations and\nmodelling strategies across EEG, together with speech and text. We evaluate\nhandcrafted features versus pre-trained embeddings, assess the effectiveness of\ndifferent neural encoders, compare unimodal, bimodal, and trimodal\nconfigurations, and analyse fusion strategies with attention to the role of\nEEG. Consistent subject-independent splits are applied to ensure robust,\nreproducible benchmarking. Our results show that (i) the combination of EEG,\nspeech and text modalities enhances multimodal detection, (ii) pretrained\nembeddings outperform handcrafted features, and (iii) carefully designed\ntrimodal models achieve state-of-the-art performance. Our work lays the\ngroundwork for future research in multimodal depression detection.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u63a2\u7d22\u4e86\u591a\u6a21\u6001\u6291\u90c1\u75c7\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6bd4\u8f83\u8111\u7535\u56fe\u3001\u8bed\u97f3\u548c\u6587\u672c\u7684\u591a\u79cd\u7279\u5f81\u8868\u793a\u548c\u5efa\u6a21\u7b56\u7565\uff0c\u53d1\u73b0\u4e09\u6a21\u6001\u7ec4\u5408\u80fd\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u6291\u90c1\u75c7\u68c0\u6d4b\u9762\u4e34\u6311\u6218\uff0c\u73b0\u6709\u7814\u7a76\u8303\u56f4\u6709\u9650\u3001\u7f3a\u4e4f\u7cfb\u7edf\u7279\u5f81\u6bd4\u8f83\u4e14\u8bc4\u4f30\u534f\u8bae\u4e0d\u4e00\u81f4\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e9b\u7a7a\u767d\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u624b\u5de5\u7279\u5f81\u4e0e\u9884\u8bad\u7ec3\u5d4c\u5165\u3001\u4e0d\u540c\u795e\u7ecf\u7f16\u7801\u5668\u6548\u679c\u3001\u5355\u6a21\u6001/\u53cc\u6a21\u6001/\u4e09\u6a21\u6001\u914d\u7f6e\uff0c\u5206\u6790\u878d\u5408\u7b56\u7565\u5e76\u5173\u6ce8\u8111\u7535\u56fe\u7684\u4f5c\u7528\uff0c\u91c7\u7528\u4e00\u81f4\u7684\u4e3b\u4f53\u72ec\u7acb\u5206\u5272\u786e\u4fdd\u7a33\u5065\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a(i)\u8111\u7535\u56fe\u3001\u8bed\u97f3\u548c\u6587\u672c\u4e09\u6a21\u6001\u7ec4\u5408\u589e\u5f3a\u591a\u6a21\u6001\u68c0\u6d4b\uff1b(ii)\u9884\u8bad\u7ec3\u5d4c\u5165\u4f18\u4e8e\u624b\u5de5\u7279\u5f81\uff1b(iii)\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u4e09\u6a21\u6001\u6a21\u578b\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u672a\u6765\u591a\u6a21\u6001\u6291\u90c1\u75c7\u68c0\u6d4b\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.14925", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14925", "abs": "https://arxiv.org/abs/2510.14925", "authors": ["Akira Okutomi"], "title": "Stable but Miscalibrated: A Kantian View on Overconfidence from Filters to Large Language Models", "comment": "19 pages, 2 figures, preliminary version", "summary": "We reinterpret Kant's Critique of Pure Reason as a theory of feedback\nstability, viewing reason as a regulator that keeps inference within the bounds\nof possible experience. We formalize this intuition via a composite instability\nindex (H-Risk) combining spectral margin, conditioning, temporal sensitivity,\nand innovation amplification. In linear-Gaussian simulations, higher H-Risk\npredicts overconfident errors even under formal stability, revealing a gap\nbetween nominal and epistemic stability. Extending to large language models\n(LLMs), we find that fragile internal dynamics correlate with miscalibration\nand hallucination, while critique-style prompts show mixed effects on\ncalibration and hallucination. These results suggest a structural bridge\nbetween Kantian self-limitation and feedback control, offering a principled\nlens for diagnosing -- and selectively reducing -- overconfidence in reasoning\nsystems. This is a preliminary version; supplementary experiments and broader\nreplication will be reported in a future revision.", "AI": {"tldr": "\u5c06\u5eb7\u5fb7\u7684\u300a\u7eaf\u7cb9\u7406\u6027\u6279\u5224\u300b\u91cd\u65b0\u89e3\u91ca\u4e3a\u53cd\u9988\u7a33\u5b9a\u6027\u7406\u8bba\uff0c\u63d0\u51fa\u590d\u5408\u4e0d\u7a33\u5b9a\u6307\u6570H-Risk\u6765\u8861\u91cf\u63a8\u7406\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\uff0c\u5728LLMs\u4e2d\u53d1\u73b0\u8106\u5f31\u5185\u90e8\u52a8\u6001\u4e0e\u9519\u8bef\u6821\u51c6\u548c\u5e7b\u89c9\u76f8\u5173\u3002", "motivation": "\u5efa\u7acb\u5eb7\u5fb7\u7406\u6027\u81ea\u6211\u9650\u5236\u7406\u8bba\u4e0e\u53cd\u9988\u63a7\u5236\u4e4b\u95f4\u7684\u7ed3\u6784\u6865\u6881\uff0c\u4e3a\u8bca\u65ad\u548c\u51cf\u5c11\u63a8\u7406\u7cfb\u7edf\u4e2d\u7684\u8fc7\u5ea6\u81ea\u4fe1\u63d0\u4f9b\u539f\u5219\u6027\u89c6\u89d2\u3002", "method": "\u63d0\u51fa\u590d\u5408\u4e0d\u7a33\u5b9a\u6307\u6570H-Risk\uff08\u7ed3\u5408\u8c31\u8fb9\u754c\u3001\u6761\u4ef6\u6570\u3001\u65f6\u95f4\u654f\u611f\u6027\u548c\u521b\u65b0\u653e\u5927\uff09\uff0c\u5728\u7ebf\u6027\u9ad8\u65af\u6a21\u62df\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5728\u6a21\u62df\u4e2dH-Risk\u80fd\u9884\u6d4b\u8fc7\u5ea6\u81ea\u4fe1\u9519\u8bef\uff1b\u5728LLMs\u4e2d\u8106\u5f31\u5185\u90e8\u52a8\u6001\u4e0e\u9519\u8bef\u6821\u51c6\u548c\u5e7b\u89c9\u76f8\u5173\uff0c\u6279\u5224\u5f0f\u63d0\u793a\u5bf9\u6821\u51c6\u548c\u5e7b\u89c9\u6548\u679c\u4e0d\u4e00\u3002", "conclusion": "\u63ed\u793a\u4e86\u540d\u4e49\u7a33\u5b9a\u6027\u4e0e\u8ba4\u77e5\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u7406\u89e3\u548c\u6539\u8fdb\u63a8\u7406\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6\u3002"}}
{"id": "2510.14942", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14942", "abs": "https://arxiv.org/abs/2510.14942", "authors": ["Yao Zhang", "Yu Wu", "Haowei Zhang", "Weiguo Li", "Haokun Chen", "Jingpei Wu", "Guohao Li", "Zhen Han", "Volker Tresp"], "title": "GroundedPRM: Tree-Guided and Fidelity-Aware Process Reward Modeling for Step-Level Reasoning", "comment": "25 pages", "summary": "Process Reward Models (PRMs) aim to improve multi-step reasoning in Large\nLanguage Models (LLMs) by supervising intermediate steps and identifying\nerrors. However, building effective PRMs remains challenging due to the lack of\nscalable, high-quality annotations. Existing approaches rely on costly human\nlabeling, LLM-based self-evaluation that is prone to hallucination, or Monte\nCarlo (MC) estimation, which infers step quality solely from rollout outcomes\nand often introduces noisy, misaligned supervision due to credit\nmisattribution. These issues result in three core limitations: noisy rewards,\nlow factual fidelity, and misalignment with step-level reasoning objectives. To\naddress these challenges, we introduce GroundedPRM, a tree-guided and\nfidelity-aware framework for automatic process supervision. To reduce reward\nnoise and enable fine-grained credit assignment, we construct structured\nreasoning paths via Monte Carlo Tree Search (MCTS). To eliminate hallucinated\nsupervision, we validate each intermediate step using an external tool,\nproviding execution-grounded correctness signals. To combine both step-level\nvalidation and global outcome assessment, we design a hybrid reward aggregation\nmechanism that fuses tool-based verification with MCTS-derived feedback.\nFinally, we format the reward signal into a rationale-enhanced, generative\nstructure to promote interpretability and compatibility with instruction-tuned\nLLMs. GroundedPRM is trained on only 40K automatically labeled samples,\namounting to just 10% of the data used by the best-performing PRM trained with\nauto-labeled supervision. Nevertheless, it achieves up to a 26% relative\nimprovement in average performance on ProcessBench. When used for reward-guided\ngreedy search, GroundedPRM outperforms even PRMs trained with human-labeled\nsupervision, offering a scalable and verifiable path toward high-quality\nprocess-level reasoning.", "AI": {"tldr": "GroundedPRM\u662f\u4e00\u4e2a\u57fa\u4e8e\u6811\u5f15\u5bfc\u548c\u4fdd\u771f\u5ea6\u7684\u81ea\u52a8\u8fc7\u7a0b\u76d1\u7763\u6846\u67b6\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6784\u5efa\u7ed3\u6784\u5316\u63a8\u7406\u8def\u5f84\uff0c\u4f7f\u7528\u5916\u90e8\u5de5\u5177\u9a8c\u8bc1\u4e2d\u95f4\u6b65\u9aa4\uff0c\u7ed3\u5408\u6b65\u9aa4\u7ea7\u9a8c\u8bc1\u548c\u5168\u5c40\u7ed3\u679c\u8bc4\u4f30\uff0c\u5728\u5c11\u91cf\u81ea\u52a8\u6807\u6ce8\u6570\u636e\u4e0a\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u591a\u6b65\u63a8\u7406\u76d1\u7763\u3002", "motivation": "\u73b0\u6709\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a\u566a\u58f0\u5956\u52b1\u3001\u4f4e\u4e8b\u5b9e\u4fdd\u771f\u5ea6\u4ee5\u53ca\u4e0e\u6b65\u9aa4\u7ea7\u63a8\u7406\u76ee\u6807\u7684\u4e0d\u5bf9\u9f50\u3002\u8fd9\u4e9b\u6311\u6218\u6e90\u4e8e\u7f3a\u4e4f\u53ef\u6269\u5c55\u7684\u9ad8\u8d28\u91cf\u6807\u6ce8\u3001\u4eba\u7c7b\u6807\u6ce8\u6210\u672c\u9ad8\u3001\u57fa\u4e8eLLM\u7684\u81ea\u8bc4\u4f30\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u4ee5\u53ca\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u5bfc\u81f4\u7684\u4fe1\u7528\u9519\u8bef\u5206\u914d\u95ee\u9898\u3002", "method": "1. \u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6784\u5efa\u7ed3\u6784\u5316\u63a8\u7406\u8def\u5f84\u4ee5\u51cf\u5c11\u5956\u52b1\u566a\u58f0\uff1b2. \u901a\u8fc7\u5916\u90e8\u5de5\u5177\u9a8c\u8bc1\u6bcf\u4e2a\u4e2d\u95f4\u6b65\u9aa4\uff0c\u63d0\u4f9b\u57fa\u4e8e\u6267\u884c\u7684\u6b63\u786e\u6027\u4fe1\u53f7\uff1b3. \u8bbe\u8ba1\u6df7\u5408\u5956\u52b1\u805a\u5408\u673a\u5236\uff0c\u878d\u5408\u5de5\u5177\u9a8c\u8bc1\u548cMCTS\u53cd\u9988\uff1b4. \u5c06\u5956\u52b1\u4fe1\u53f7\u683c\u5f0f\u5316\u4e3a\u589e\u5f3a\u63a8\u7406\u7684\u751f\u6210\u7ed3\u6784\uff0c\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u4ec5\u4f7f\u75284\u4e07\u4e2a\u81ea\u52a8\u6807\u6ce8\u6837\u672c\uff08\u6700\u4f73\u6027\u80fdPRM\u6240\u9700\u6570\u636e\u768410%\uff09\uff0c\u5728ProcessBench\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe26%\u7684\u76f8\u5bf9\u6027\u80fd\u63d0\u5347\u3002\u5f53\u7528\u4e8e\u5956\u52b1\u5f15\u5bfc\u7684\u8d2a\u5a6a\u641c\u7d22\u65f6\uff0c\u751a\u81f3\u4f18\u4e8e\u4f7f\u7528\u4eba\u7c7b\u6807\u6ce8\u76d1\u7763\u8bad\u7ec3\u7684PRM\u3002", "conclusion": "GroundedPRM\u4e3a\u9ad8\u8d28\u91cf\u8fc7\u7a0b\u7ea7\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u6269\u5c55\u4e14\u53ef\u9a8c\u8bc1\u7684\u8def\u5f84\uff0c\u901a\u8fc7\u6811\u5f15\u5bfc\u548c\u4fdd\u771f\u5ea6\u611f\u77e5\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709PRM\u7684\u6838\u5fc3\u9650\u5236\u95ee\u9898\u3002"}}
{"id": "2510.14980", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.GR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14980", "abs": "https://arxiv.org/abs/2510.14980", "authors": ["Wenqian Zhang", "Weiyang Liu", "Zhen Liu"], "title": "Agentic Design of Compositional Machines", "comment": "75 pages, 31 figures, Project Page: https://besiegefield.github.io", "summary": "The design of complex machines stands as both a marker of human intelligence\nand a foundation of engineering practice. Given recent advances in large\nlanguage models (LLMs), we ask whether they, too, can learn to create. We\napproach this question through the lens of compositional machine design: a task\nin which machines are assembled from standardized components to meet functional\ndemands like locomotion or manipulation in a simulated physical environment. To\nsupport this investigation, we introduce BesiegeField, a testbed built on the\nmachine-building game Besiege, which enables part-based construction, physical\nsimulation and reward-driven evaluation. Using BesiegeField, we benchmark\nstate-of-the-art LLMs with agentic workflows and identify key capabilities\nrequired for success, including spatial reasoning, strategic assembly, and\ninstruction-following. As current open-source models fall short, we explore\nreinforcement learning (RL) as a path to improvement: we curate a cold-start\ndataset, conduct RL finetuning experiments, and highlight open challenges at\nthe intersection of language, machine design, and physical reasoning.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7ec4\u5408\u5f0f\u673a\u5668\u8bbe\u8ba1\u4e2d\u7684\u80fd\u529b\uff0c\u901a\u8fc7BesiegeField\u6d4b\u8bd5\u5e73\u53f0\u8bc4\u4f30LLMs\u5728\u7a7a\u95f4\u63a8\u7406\u3001\u7b56\u7565\u7ec4\u88c5\u548c\u6307\u4ee4\u9075\u5faa\u65b9\u9762\u7684\u8868\u73b0\uff0c\u5e76\u63a2\u7d22\u5f3a\u5316\u5b66\u4e60\u4f5c\u4e3a\u6539\u8fdb\u8def\u5f84\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u591f\u5b66\u4e60\u521b\u9020\u590d\u6742\u673a\u5668\uff0c\u7279\u522b\u662f\u5728\u7ec4\u5408\u5f0f\u673a\u5668\u8bbe\u8ba1\u4efb\u52a1\u4e2d\uff0c\u8fd9\u65e2\u662f\u4eba\u7c7b\u667a\u80fd\u7684\u6807\u5fd7\u4e5f\u662f\u5de5\u7a0b\u5b9e\u8df5\u7684\u57fa\u7840\u3002", "method": "\u5f15\u5165BesiegeField\u6d4b\u8bd5\u5e73\u53f0\uff0c\u57fa\u4e8eBesiege\u6e38\u620f\u6784\u5efa\uff0c\u652f\u6301\u90e8\u4ef6\u7ec4\u88c5\u3001\u7269\u7406\u6a21\u62df\u548c\u5956\u52b1\u9a71\u52a8\u8bc4\u4f30\uff1b\u5bf9\u6700\u5148\u8fdb\u7684LLMs\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u63a2\u7d22\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u65b9\u6cd5\u3002", "result": "\u5f53\u524d\u5f00\u6e90\u6a21\u578b\u5728\u7a7a\u95f4\u63a8\u7406\u3001\u7b56\u7565\u7ec4\u88c5\u548c\u6307\u4ee4\u9075\u5faa\u7b49\u5173\u952e\u80fd\u529b\u4e0a\u8868\u73b0\u4e0d\u8db3\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u5b9e\u9a8c\u5c55\u793a\u4e86\u6539\u8fdb\u6f5c\u529b\uff0c\u4f46\u4e5f\u6307\u51fa\u4e86\u8bed\u8a00\u3001\u673a\u5668\u8bbe\u8ba1\u548c\u7269\u7406\u63a8\u7406\u4ea4\u53c9\u9886\u57df\u7684\u6311\u6218\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u673a\u5668\u8bbe\u8ba1\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u53d1\u5c55\u7a7a\u95f4\u63a8\u7406\u548c\u7269\u7406\u7406\u89e3\u80fd\u529b\uff0c\u5f3a\u5316\u5b66\u4e60\u4e3a\u63d0\u5347\u8fd9\u4e9b\u80fd\u529b\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}

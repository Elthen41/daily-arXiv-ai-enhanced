<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 33]
- [cs.AR](#cs.AR) [Total: 3]
- [cs.CR](#cs.CR) [Total: 13]
- [cs.DC](#cs.DC) [Total: 8]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Decision Oriented Technique (DOTechnique): Finding Model Validity Through Decision-Maker Context](https://arxiv.org/abs/2510.13858)
*Raheleh Biglari,Joachim Denil*

Main category: cs.AI

TL;DR: 本文提出了一种基于决策一致性的模型有效性验证方法DOTechnique，通过评估替代模型与高保真模型是否产生相同决策来确定模型有效性，无需预定义有效性边界。


<details>
  <summary>Details</summary>
Motivation: 模型有效性对决策过程至关重要，但传统方法依赖预定义的有效性框架，这些框架可能不可用或不充分。

Method: DOTechnique方法通过决策一致性而非输出相似性来评估模型有效性，整合领域约束和符号推理来缩小搜索空间，提高计算效率。

Result: 以高速公路变道系统为例，展示了DOTechnique能够发现仿真模型的有效性区域。

Conclusion: 该技术有潜力通过决策者上下文来支持模型有效性的发现。

Abstract: Model validity is as critical as the model itself, especially when guiding
decision-making processes. Traditional approaches often rely on predefined
validity frames, which may not always be available or sufficient. This paper
introduces the Decision Oriented Technique (DOTechnique), a novel method for
determining model validity based on decision consistency rather than output
similarity. By evaluating whether surrogate models lead to equivalent decisions
compared to high-fidelity models, DOTechnique enables efficient identification
of validity regions, even in the absence of explicit validity boundaries. The
approach integrates domain constraints and symbolic reasoning to narrow the
search space, enhancing computational efficiency. A highway lane change system
serves as a motivating example, demonstrating how DOTechnique can uncover the
validity region of a simulation model. The results highlight the potential of
the technique to support finding model validity through decision-maker context.

</details>


### [2] [Do Slides Help? Multi-modal Context for Automatic Transcription of Conference Talks](https://arxiv.org/abs/2510.13979)
*Supriti Sinhamahapatra,Jan Niehues*

Main category: cs.AI

TL;DR: 该研究提出了一种将视觉信息（特别是演示幻灯片）集成到自动语音识别系统中的方法，用于科学演示场景，通过数据增强和模型训练，显著降低了词错误率。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的自动语音识别系统主要依赖声学信息而忽略多模态上下文，但视觉信息对于消歧和适应至关重要。特别是在科学演示场景中，演示幻灯片包含重要信息。

Method: 首先创建多模态演示基准，然后探索用多模态信息增强语音模型的方法，通过数据增强方法解决缺乏配套幻灯片数据集的问题，最后使用增强数据集训练模型。

Result: 与基线模型相比，训练得到的模型在所有词汇上的词错误率相对降低了约34%，在领域特定术语上的词错误率相对降低了35%。

Conclusion: 集成视觉信息（特别是演示幻灯片）可以显著提升自动语音识别系统在科学演示场景中的性能，特别是在处理领域特定术语方面。

Abstract: State-of-the-art (SOTA) Automatic Speech Recognition (ASR) systems primarily
rely on acoustic information while disregarding additional multi-modal context.
However, visual information are essential in disambiguation and adaptation.
While most work focus on speaker images to handle noise conditions, this work
also focuses on integrating presentation slides for the use cases of scientific
presentation.
  In a first step, we create a benchmark for multi-modal presentation including
an automatic analysis of transcribing domain-specific terminology. Next, we
explore methods for augmenting speech models with multi-modal information. We
mitigate the lack of datasets with accompanying slides by a suitable approach
of data augmentation. Finally, we train a model using the augmented dataset,
resulting in a relative reduction in word error rate of approximately 34%,
across all words and 35%, for domain-specific terms compared to the baseline
model.

</details>


### [3] [Do Large Language Models Show Biases in Causal Learning? Insights from Contingency Judgment](https://arxiv.org/abs/2510.13985)
*María Victoria Carro,Denise Alejandra Mester,Francisca Gauna Selasco,Giovanni Franco Gabriel Marraffini,Mario Alejandro Leiva,Gerardo I. Simari,María Vanina Martinez*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在因果推理任务中容易产生因果幻觉，即使在没有足够证据支持的情况下也会错误推断因果关系。


<details>
  <summary>Details</summary>
Motivation: 研究旨在验证大型语言模型是否会在经典的认知科学范式——列联判断任务中产生因果幻觉，这种认知偏差被认为是许多社会问题的基础。

Method: 构建了包含1000个医疗场景的零列联数据集，在这些场景中可用信息不足以建立变量间的因果关系，然后让LLMs评估潜在原因的有效性。

Result: 所有评估的模型都系统地推断出无根据的因果关系，显示出对因果幻觉的强烈敏感性。

Conclusion: 研究结果支持LLMs只是复制因果语言而非真正理解因果关系的假设，并对在需要准确因果推理的领域使用语言模型提出了担忧。

Abstract: Causal learning is the cognitive process of developing the capability of
making causal inferences based on available information, often guided by
normative principles. This process is prone to errors and biases, such as the
illusion of causality, in which people perceive a causal relationship between
two variables despite lacking supporting evidence. This cognitive bias has been
proposed to underlie many societal problems, including social prejudice,
stereotype formation, misinformation, and superstitious thinking. In this work,
we examine whether large language models are prone to developing causal
illusions when faced with a classic cognitive science paradigm: the contingency
judgment task. To investigate this, we constructed a dataset of 1,000 null
contingency scenarios (in which the available information is not sufficient to
establish a causal relationship between variables) within medical contexts and
prompted LLMs to evaluate the effectiveness of potential causes. Our findings
show that all evaluated models systematically inferred unwarranted causal
relationships, revealing a strong susceptibility to the illusion of causality.
While there is ongoing debate about whether LLMs genuinely understand causality
or merely reproduce causal language without true comprehension, our findings
support the latter hypothesis and raise concerns about the use of language
models in domains where accurate causal reasoning is essential for informed
decision-making.

</details>


### [4] [STEMS: Spatial-Temporal Enhanced Safe Multi-Agent Coordination for Building Energy Management](https://arxiv.org/abs/2510.14112)
*Huiliang Zhang,Di Wu,Arnaud Zinflou,Benoit Boulet*

Main category: cs.AI

TL;DR: 本文提出了STEMS框架，一种安全约束的多智能体强化学习方法，用于协调建筑能源管理，通过空间-时间图表示学习和控制屏障函数实现安全保证，在真实数据集上实现了21%成本降低和18%排放减少。


<details>
  <summary>Details</summary>
Motivation: 建筑能源管理对实现碳减排目标、提高居住者舒适度和降低能源成本至关重要。当前多建筑能源系统面临空间-时间信息利用不足、缺乏严格安全保证和系统复杂性三大挑战。

Method: STEMS框架包含两个核心组件：(1) 使用GCN-Transformer融合架构的空间-时间图表示学习框架，捕捉建筑间关系和时间模式；(2) 结合控制屏障函数的安全约束多智能体强化学习算法，提供数学安全保证。

Result: 在真实建筑数据集上的实验表明，STEMS相比现有方法实现了21%成本降低、18%排放减少，并将安全违规从35.1%大幅降低至5.6%，同时仅保持0.13的不适比例。

Conclusion: STEMS框架在极端天气条件下表现出强大的鲁棒性，并在不同建筑类型中保持有效性，为协调建筑能源管理提供了安全可靠的解决方案。

Abstract: Building energy management is essential for achieving carbon reduction goals,
improving occupant comfort, and reducing energy costs. Coordinated building
energy management faces critical challenges in exploiting spatial-temporal
dependencies while ensuring operational safety across multi-building systems.
Current multi-building energy systems face three key challenges: insufficient
spatial-temporal information exploitation, lack of rigorous safety guarantees,
and system complexity. This paper proposes Spatial-Temporal Enhanced Safe
Multi-Agent Coordination (STEMS), a novel safety-constrained multi-agent
reinforcement learning framework for coordinated building energy management.
STEMS integrates two core components: (1) a spatial-temporal graph
representation learning framework using a GCN-Transformer fusion architecture
to capture inter-building relationships and temporal patterns, and (2) a
safety-constrained multi-agent RL algorithm incorporating Control Barrier
Functions to provide mathematical safety guarantees. Extensive experiments on
real-world building datasets demonstrate STEMS's superior performance over
existing methods, showing that STEMS achieves 21% cost reduction, 18% emission
reduction, and dramatically reduces safety violations from 35.1% to 5.6% while
maintaining optimal comfort with only 0.13 discomfort proportion. The framework
also demonstrates strong robustness during extreme weather conditions and
maintains effectiveness across different building types.

</details>


### [5] [Terrarium: Revisiting the Blackboard for Multi-Agent Safety, Privacy, and Security Studies](https://arxiv.org/abs/2510.14312)
*Mason Nakamura,Abhinav Kumar,Saaduddin Mahmud,Sahar Abdelnabi,Shlomo Zilberstein,Eugene Bagdasarian*

Main category: cs.AI

TL;DR: 提出了Terrarium框架，用于在基于LLM的多智能体系统中进行细粒度的安全、隐私和安全性研究，通过重新设计黑板架构来创建模块化、可配置的测试平台。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的多智能体系统能够自动化繁琐的用户任务，但引入了新的风险，包括错位攻击、恶意方攻击、智能体被攻陷或用户数据被盗等问题。

Method: 重新利用多智能体系统中的黑板设计，创建模块化、可配置的测试平台，识别关键攻击向量（错位、恶意智能体、通信被攻陷、数据投毒），并在三个协作多智能体场景中实施四种代表性攻击。

Result: 实现了Terrarium框架，展示了其灵活性，能够快速原型化、评估和迭代防御措施和设计。

Conclusion: Terrarium框架旨在加速可信多智能体系统的进展，通过提供工具来应对安全、隐私和安全性的挑战。

Abstract: A multi-agent system (MAS) powered by large language models (LLMs) can
automate tedious user tasks such as meeting scheduling that requires
inter-agent collaboration. LLMs enable nuanced protocols that account for
unstructured private data, user constraints, and preferences. However, this
design introduces new risks, including misalignment and attacks by malicious
parties that compromise agents or steal user data. In this paper, we propose
the Terrarium framework for fine-grained study on safety, privacy, and security
in LLM-based MAS. We repurpose the blackboard design, an early approach in
multi-agent systems, to create a modular, configurable testbed for multi-agent
collaboration. We identify key attack vectors such as misalignment, malicious
agents, compromised communication, and data poisoning. We implement three
collaborative MAS scenarios with four representative attacks to demonstrate the
framework's flexibility. By providing tools to rapidly prototype, evaluate, and
iterate on defenses and designs, Terrarium aims to accelerate progress toward
trustworthy multi-agent systems.

</details>


### [6] [A Multimodal Approach to Heritage Preservation in the Context of Climate Change](https://arxiv.org/abs/2510.14136)
*David Roqui,Adèle Cormier,nistor Grozavu,Ann Bourges*

Main category: cs.AI

TL;DR: 提出了一种轻量级多模态架构，融合传感器数据和视觉图像来预测文化遗产地的退化严重程度，在数据稀缺情况下显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 文化遗产地因气候变化加速退化，传统单模态监测方法无法捕捉环境应力与材料退化之间的复杂相互作用。

Method: 采用改进的PerceiverIO架构，包含简化编码器（64D潜在空间）和自适应Barlow Twins损失函数，鼓励模态互补性而非冗余。

Result: 在斯特拉斯堡大教堂数据上达到76.9%准确率，比标准多模态架构提升43%，比原始PerceiverIO提升25%。消融研究证实多模态协同效应。

Conclusion: 架构简化与对比正则化相结合，可在数据稀缺的遗产监测环境中实现有效的多模态学习，为AI驱动的保护决策支持系统奠定基础。

Abstract: Cultural heritage sites face accelerating degradation due to climate change,
yet tradi- tional monitoring relies on unimodal analysis (visual inspection or
environmental sen- sors alone) that fails to capture the complex interplay
between environmental stres- sors and material deterioration. We propose a
lightweight multimodal architecture that fuses sensor data (temperature,
humidity) with visual imagery to predict degradation severity at heritage
sites. Our approach adapts PerceiverIO with two key innovations: (1) simplified
encoders (64D latent space) that prevent overfitting on small datasets (n=37
training samples), and (2) Adaptive Barlow Twins loss that encourages modality
complementarity rather than redundancy. On data from Strasbourg Cathedral, our
model achieves 76.9% accu- racy, a 43% improvement over standard multimodal
architectures (VisualBERT, Trans- former) and 25% over vanilla PerceiverIO.
Ablation studies reveal that sensor-only achieves 61.5% while image-only
reaches 46.2%, confirming successful multimodal synergy. A systematic
hyperparameter study identifies an optimal moderate correlation target ({\tau}
=0.3) that balances align- ment and complementarity, achieving 69.2% accuracy
compared to other {\tau} values ({\tau} =0.1/0.5/0.7: 53.8%, {\tau} =0.9:
61.5%). This work demonstrates that architectural sim- plicity combined with
contrastive regularization enables effective multimodal learning in data-scarce
heritage monitoring contexts, providing a foundation for AI-driven con-
servation decision support systems.

</details>


### [7] [JEDA: Query-Free Clinical Order Search from Ambient Dialogues](https://arxiv.org/abs/2510.14169)
*Praphul Singh,Corey Barrett,Sumana Srivasta,Amitabh Saikia,Irfan Bulu,Sri Gadde,Krishnaram Kenthapadi*

Main category: cs.AI

TL;DR: JEDA是一个用于临床订单检索的双编码器系统，通过联合嵌入直接和上下文临床订单，实现实时、可解释的订单检索，无需LLM重写。


<details>
  <summary>Details</summary>
Motivation: 解决临床对话中显性指令与隐性推理混合的问题，避免传统LLM重写方法带来的延迟、不稳定性和不透明性，实现实时订单处理。

Method: 使用PubMedBERT初始化的双编码器，采用重复安全对比目标进行微调，通过受限LLM指导将不同意图表达对齐到共享订单概念，支持查询和无查询两种模式。

Result: JEDA在实践中取得显著性能提升，大幅优于基础编码器和最新开源嵌入器，无查询模式对噪声具有鲁棒性。

Conclusion: JEDA提供了一个快速、可解释、无需LLM的检索层，能够实时将上下文环境与可操作的临床订单联系起来。

Abstract: Clinical conversations mix explicit directives (order a chest X-ray) with
implicit reasoning (the cough worsened overnight, we should check for
pneumonia). Many systems rely on LLM rewriting, adding latency, instability,
and opacity that hinder real-time ordering. We present JEDA (Joint Embedding
for Direct and Ambient clinical orders), a domain-initialized bi-encoder that
retrieves canonical orders directly and, in a query-free mode, encodes a short
rolling window of ambient dialogue to trigger retrieval. Initialized from
PubMedBERT and fine-tuned with a duplicate-safe contrastive objective, JEDA
aligns heterogeneous expressions of intent to shared order concepts. Training
uses constrained LLM guidance to tie each signed order to complementary
formulations (command only, context only, command+context, context+reasoning),
producing clearer inter-order separation, tighter query extendash order
coupling, and stronger generalization. The query-free mode is noise-resilient,
reducing sensitivity to disfluencies and ASR errors by conditioning on a short
window rather than a single utterance. Deployed in practice, JEDA yields large
gains and substantially outperforms its base encoder and recent open embedders
(Linq Embed Mistral, SFR Embedding, GTE Qwen, BGE large, Embedding Gemma). The
result is a fast, interpretable, LLM-free retrieval layer that links ambient
context to actionable clinical orders in real time.

</details>


### [8] [ARM-FM: Automated Reward Machines via Foundation Models for Compositional Reinforcement Learning](https://arxiv.org/abs/2510.14176)
*Roger Creus Castanyer,Faisal Mohamed,Pablo Samuel Castro,Cyrus Neary,Glen Berseth*

Main category: cs.AI

TL;DR: ARM-FM是一个利用基础模型自动设计强化学习奖励函数的框架，通过奖励机器实现自然语言到结构化奖励规范的转换，支持任务分解和零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 强化学习算法对奖励函数设计高度敏感，这限制了其广泛应用。现有方法需要人工设计复杂的奖励函数，难以处理复杂的多目标任务。

Method: 使用基础模型自动从自然语言规范生成奖励机器；为每个自动机状态关联语言嵌入以实现任务间泛化；在多样化环境中进行实证验证。

Result: 在多种挑战性环境中验证了ARM-FM的有效性，展示了零样本泛化能力，能够处理复杂的多目标强化学习任务。

Conclusion: ARM-FM通过结合基础模型的高层推理能力和奖励机器的结构化形式，实现了自动化的组合式奖励设计，为强化学习的广泛应用提供了可行的解决方案。

Abstract: Reinforcement learning (RL) algorithms are highly sensitive to reward
function specification, which remains a central challenge limiting their broad
applicability. We present ARM-FM: Automated Reward Machines via Foundation
Models, a framework for automated, compositional reward design in RL that
leverages the high-level reasoning capabilities of foundation models (FMs).
Reward machines (RMs) -- an automata-based formalism for reward specification
-- are used as the mechanism for RL objective specification, and are
automatically constructed via the use of FMs. The structured formalism of RMs
yields effective task decompositions, while the use of FMs enables objective
specifications in natural language. Concretely, we (i) use FMs to automatically
generate RMs from natural language specifications; (ii) associate language
embeddings with each RM automata-state to enable generalization across tasks;
and (iii) provide empirical evidence of ARM-FM's effectiveness in a diverse
suite of challenging environments, including evidence of zero-shot
generalization.

</details>


### [9] [Implementation of AI in Precision Medicine](https://arxiv.org/abs/2510.14194)
*Göktuğ Bender,Samer Faraj,Anand Bhardwaj*

Main category: cs.AI

TL;DR: 本文对2019-2024年精准医学中AI实施的文献进行范围综述，识别了数据质量、临床可靠性、工作流整合和治理方面的关键障碍与促进因素，提出了支持可信和可持续实施的未来方向。


<details>
  <summary>Details</summary>
Motivation: AI在精准医学中日益重要，能够整合和解释多模态数据，但在临床环境中的实施仍然有限，需要系统分析实施障碍和促进因素。

Method: 采用生态系统框架，对2019-2024年精准医学AI实施文献进行范围综述，分析数据质量、临床可靠性、工作流整合和治理四个维度的关键因素。

Result: 识别了精准医学AI实施中的主要障碍和促进因素，强调了现实世界转化中的相互依赖关系。

Conclusion: 提出了支持可信和可持续AI实施在精准医学中的未来方向，强调需要系统性方法来解决实施挑战。

Abstract: Artificial intelligence (AI) has become increasingly central to precision
medicine by enabling the integration and interpretation of multimodal data, yet
implementation in clinical settings remains limited. This paper provides a
scoping review of literature from 2019-2024 on the implementation of AI in
precision medicine, identifying key barriers and enablers across data quality,
clinical reliability, workflow integration, and governance. Through an
ecosystem-based framework, we highlight the interdependent relationships
shaping real-world translation and propose future directions to support
trustworthy and sustainable implementation.

</details>


### [10] [Towards Agentic Self-Learning LLMs in Search Environment](https://arxiv.org/abs/2510.14253)
*Wangtao Sun,Xiang Cheng,Jialin Fan,Yao Xu,Xing Yu,Shizhu He,Jun Zhao,Kang Liu*

Main category: cs.AI

TL;DR: 本文提出了一种名为Agentic Self-Learning (ASL)的完全闭环多角色强化学习框架，通过生成奖励模型(GRM)和策略模型的协同进化，在无人类标注数据的情况下实现智能体的持续自我提升。


<details>
  <summary>Details</summary>
Motivation: 研究如何在不依赖人工标注数据集或预定义规则奖励的情况下，通过自学习扩展基于LLM的智能体能力。

Method: 提出ASL框架，统一任务生成、策略执行和评估，通过提示生成器、策略模型和生成奖励模型形成良性循环。

Result: ASL实现了稳定持续的提升，超越了强基线方法，在零标注数据条件下仍能持续改进，显示出优异的样本效率和鲁棒性。

Conclusion: 奖励来源和数据规模是开放领域智能体学习的关键因素，多角色协同进化是实现可扩展自改进智能体的有效方法。

Abstract: We study whether self-learning can scale LLM-based agents without relying on
human-curated datasets or predefined rule-based rewards. Through controlled
experiments in a search-agent setting, we identify two key determinants of
scalable agent training: the source of reward signals and the scale of agent
task data. We find that rewards from a Generative Reward Model (GRM) outperform
rigid rule-based signals for open-domain learning, and that co-evolving the GRM
with the policy further boosts performance. Increasing the volume of agent task
data-even when synthetically generated-substantially enhances agentic
capabilities. Building on these insights, we propose \textbf{Agentic
Self-Learning} (ASL), a fully closed-loop, multi-role reinforcement learning
framework that unifies task generation, policy execution, and evaluation within
a shared tool environment and LLM backbone. ASL coordinates a Prompt Generator,
a Policy Model, and a Generative Reward Model to form a virtuous cycle of
harder task setting, sharper verification, and stronger solving. Empirically,
ASL delivers steady, round-over-round gains, surpasses strong RLVR baselines
(e.g., Search-R1) that plateau or degrade, and continues improving under
zero-labeled-data conditions, indicating superior sample efficiency and
robustness. We further show that GRM verification capacity is the main
bottleneck: if frozen, it induces reward hacking and stalls progress; continual
GRM training on the evolving data distribution mitigates this, and a small
late-stage injection of real verification data raises the performance ceiling.
This work establishes reward source and data scale as critical levers for
open-domain agent learning and demonstrates the efficacy of multi-role
co-evolution for scalable, self-improving agents. The data and code of this
paper are released at
https://github.com/forangel2014/Towards-Agentic-Self-Learning

</details>


### [11] [MorphoBench: A Benchmark with Difficulty Adaptive to Model Reasoning](https://arxiv.org/abs/2510.14265)
*Xukai Wang,Xuanbo Liu,Mingrui Chen,Haitian Zhong,Xuanlin Yang,Bohan Zeng,Jinbo Hu,Hao Liang,Junbo Niu,Xuchen Li,Ruitao Wu,Ruichuan An,Yang Shi,Liu Liu,Xu-Yao Zhang,Qiang Liu,Zhouchen Lin,Wentao Zhang,Bin Dong*

Main category: cs.AI

TL;DR: 提出了MorphoBench基准测试，用于评估大模型的推理能力，能够根据模型推理能力动态调整问题难度，包含1300多个测试问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在评估大模型推理能力方面存在范围有限和灵活性不足的问题，无法根据模型推理能力的演变调整难度。

Method: 从现有基准和奥林匹克竞赛中收集复杂推理问题，利用模型推理过程中的关键陈述自适应修改问题分析难度，并使用模拟软件生成问题以实现动态难度调整。

Result: 收集了1300多个测试问题，基于o3和GPT-5等模型的推理能力迭代调整了MorphoBench的难度。

Conclusion: MorphoBench增强了模型推理评估的全面性和有效性，为提高大模型的推理能力和科学稳健性提供了可靠指导。

Abstract: With the advancement of powerful large-scale reasoning models, effectively
evaluating the reasoning capabilities of these models has become increasingly
important. However, existing benchmarks designed to assess the reasoning
abilities of large models tend to be limited in scope and lack the flexibility
to adapt their difficulty according to the evolving reasoning capacities of the
models. To address this, we propose MorphoBench, a benchmark that incorporates
multidisciplinary questions to evaluate the reasoning capabilities of large
models and can adjust and update question difficulty based on the reasoning
abilities of advanced models. Specifically, we curate the benchmark by
selecting and collecting complex reasoning questions from existing benchmarks
and sources such as Olympiad-level competitions. Additionally, MorphoBench
adaptively modifies the analytical challenge of questions by leveraging key
statements generated during the model's reasoning process. Furthermore, it
includes questions generated using simulation software, enabling dynamic
adjustment of benchmark difficulty with minimal resource consumption. We have
gathered over 1,300 test questions and iteratively adjusted the difficulty of
MorphoBench based on the reasoning capabilities of models such as o3 and GPT-5.
MorphoBench enhances the comprehensiveness and validity of model reasoning
evaluation, providing reliable guidance for improving both the reasoning
abilities and scientific robustness of large models. The code has been released
in https://github.com/OpenDCAI/MorphoBench.

</details>


### [12] [Metacognitive Self-Correction for Multi-Agent System via Prototype-Guided Next-Execution Reconstruction](https://arxiv.org/abs/2510.14319)
*Xu Shen,Qi Zhang,Song Wang,Zhen Tan,Xinyu Zhao,Laura Yao,Vaishnav Tadiparthi,Hossein Nourkhiz Mahjoub,Ehsan Moradi Pari,Kwonjoon Lee,Tianlong Chen*

Main category: cs.AI

TL;DR: MASC是一个元认知框架，为多智能体系统提供实时、无监督的步骤级错误检测和自我纠正，通过历史条件异常评分来防止错误传播。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的多智能体系统在协作解决问题时容易受到级联错误的影响，单个错误步骤可能在智能体间传播并破坏整个轨迹。

Method: MASC采用两种互补设计：1）下一执行重构，从查询和交互历史预测下一步的嵌入以捕捉因果一致性；2）原型引导增强，学习正常步骤嵌入的原型先验，在稀疏上下文下稳定重构和异常评分。检测到异常步骤时触发纠正智能体。

Result: 在Who&When基准测试中，MASC始终优于所有基线方法，步骤级错误检测的AUC-ROC提高了8.47%；当集成到不同多智能体框架中时，在各种架构上均带来一致的端到端性能提升。

Conclusion: MASC的元认知监控和针对性纠正能够以最小开销缓解错误传播，为多智能体系统提供了有效的错误检测和纠正机制。

Abstract: Large Language Model based multi-agent systems (MAS) excel at collaborative
problem solving but remain brittle to cascading errors: a single faulty step
can propagate across agents and disrupt the trajectory. In this paper, we
present MASC, a metacognitive framework that endows MAS with real-time,
unsupervised, step-level error detection and self-correction. MASC rethinks
detection as history-conditioned anomaly scoring via two complementary designs:
(1) Next-Execution Reconstruction, which predicts the embedding of the next
step from the query and interaction history to capture causal consistency, and
(2) Prototype-Guided Enhancement, which learns a prototype prior over
normal-step embeddings and uses it to stabilize reconstruction and anomaly
scoring under sparse context (e.g., early steps). When an anomaly step is
flagged, MASC triggers a correction agent to revise the acting agent's output
before information flows downstream. On the Who&When benchmark, MASC
consistently outperforms all baselines, improving step-level error detection by
up to 8.47% AUC-ROC ; When plugged into diverse MAS frameworks, it delivers
consistent end-to-end gains across architectures, confirming that our
metacognitive monitoring and targeted correction can mitigate error propagation
with minimal overhead.

</details>


### [13] [AI for Service: Proactive Assistance with AI Glasses](https://arxiv.org/abs/2510.14359)
*Zichen Wen,Yiyu Wang,Chenfei Liao,Boxue Yang,Junxian Li,Weifeng Liu,Haocong He,Bolong Feng,Xuyang Liu,Yuanhuiyi Lyu,Xu Zheng,Xuming Hu,Linfeng Zhang*

Main category: cs.AI

TL;DR: AI4Service是一种新的AI服务范式，通过Alpha-Service框架实现主动实时辅助，解决"何时干预"和"如何服务"两大挑战，基于AI眼镜部署多智能体系统。


<details>
  <summary>Details</summary>
Motivation: 现有AI服务多为被动响应，需要向主动预测用户需求的智能助手转变，提供更自然、及时的生活辅助。

Method: 提出Alpha-Service统一框架，借鉴冯·诺依曼架构设计五个核心组件：输入单元、中央处理单元、算术逻辑单元、内存单元和输出单元，通过多智能体系统在AI眼镜上实现。

Result: 案例研究展示了实时21点顾问、博物馆导览和购物搭配助手等应用，能够无缝感知环境、推断用户意图并提供及时有用的帮助。

Conclusion: AI4Service范式通过Alpha-Service框架成功实现了从被动响应到主动辅助的转变，为下一代智能服务系统奠定了基础。

Abstract: In an era where AI is evolving from a passive tool into an active and
adaptive companion, we introduce AI for Service (AI4Service), a new paradigm
that enables proactive and real-time assistance in daily life. Existing AI
services remain largely reactive, responding only to explicit user commands. We
argue that a truly intelligent and helpful assistant should be capable of
anticipating user needs and taking actions proactively when appropriate. To
realize this vision, we propose Alpha-Service, a unified framework that
addresses two fundamental challenges: Know When to intervene by detecting
service opportunities from egocentric video streams, and Know How to provide
both generalized and personalized services. Inspired by the von Neumann
computer architecture and based on AI glasses, Alpha-Service consists of five
key components: an Input Unit for perception, a Central Processing Unit for
task scheduling, an Arithmetic Logic Unit for tool utilization, a Memory Unit
for long-term personalization, and an Output Unit for natural human
interaction. As an initial exploration, we implement Alpha-Service through a
multi-agent system deployed on AI glasses. Case studies, including a real-time
Blackjack advisor, a museum tour guide, and a shopping fit assistant,
demonstrate its ability to seamlessly perceive the environment, infer user
intent, and provide timely and useful assistance without explicit prompts.

</details>


### [14] [Can MLLMs Absorb Math Reasoning Abilities from LLMs as Free Lunch?](https://arxiv.org/abs/2510.14387)
*Yijie Hu,Zihao Zhou,Kaizhu Huang,Xiaowei Huang,Qiufeng Wang*

Main category: cs.AI

TL;DR: IP-Merging是一种无需调优的方法，通过识别多模态大语言模型和数学推理大语言模型中的推理相关参数，将它们投影到多模态大语言模型的子空间中，然后在该子空间内合并参数，从而直接将数学推理能力从数学大语言模型转移到多模态大语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型的数学推理能力落后于纯文本大语言模型，但直接使用模型合并方法会因参数空间不匹配而导致性能下降。本文旨在探索如何在不进行调优的情况下，让多模态大语言模型直接从现成的数学大语言模型中吸收数学推理能力。

Method: 提出IP-Merging方法：1）识别多模态大语言模型和数学大语言模型中的推理相关参数；2）将这些参数投影到多模态大语言模型的子空间中；3）在该子空间内合并参数。这是一个无需调优的直接参数调整方法。

Result: 大量实验表明，IP-Merging方法能够有效提升多模态大语言模型的数学推理能力，且不会损害其其他能力。

Conclusion: IP-Merging方法成功实现了将数学推理能力从数学大语言模型直接转移到多模态大语言模型的目标，解决了参数空间不匹配的问题，且无需进行模型调优。

Abstract: Math reasoning has been one crucial ability of large language models (LLMs),
where significant advancements have been achieved in recent years. However,
most efforts focus on LLMs by curating high-quality annotation data and
intricate training (or inference) paradigms, while the math reasoning
performance of multi-modal LLMs (MLLMs) remains lagging behind. Since the MLLM
typically consists of an LLM and a vision block, we wonder: Can MLLMs directly
absorb math reasoning abilities from off-the-shelf math LLMs without tuning?
Recent model-merging approaches may offer insights into this question. However,
they overlook the alignment between the MLLM and LLM, where we find that there
is a large gap between their parameter spaces, resulting in lower performance.
Our empirical evidence reveals two key factors behind this issue: the
identification of crucial reasoning-associated layers in the model and the
mitigation of the gaps in parameter space. Based on the empirical insights, we
propose IP-Merging that first identifies the reasoning-associated parameters in
both MLLM and Math LLM, then projects them into the subspace of MLLM, aiming to
maintain the alignment, and finally merges parameters in this subspace.
IP-Merging is a tuning-free approach since parameters are directly adjusted.
Extensive experiments demonstrate that our IP-Merging method can enhance the
math reasoning ability of MLLMs directly from Math LLMs without compromising
their other capabilities.

</details>


### [15] [IMAGINE: Integrating Multi-Agent System into One Model for Complex Reasoning and Planning](https://arxiv.org/abs/2510.14406)
*Xikai Zhang,Bo Wang,Likang Xiao,Yongzhi Li,Quan Chen,Wenju Wu,Liu Liu*

Main category: cs.AI

TL;DR: IMAGINE框架将多智能体系统的推理规划能力集成到单一紧凑模型中，通过端到端训练显著超越原多智能体系统性能，在TravelPlanner基准上达到82.7%的最终通过率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理和规划任务中仍面临挑战，现有多智能体系统虽然能提供改进的集体推理，但存在推理成本高、响应延迟长和端到端训练困难等问题。

Method: 提出IMAGINE框架，将多智能体系统的推理规划能力集成到单一紧凑模型中，通过简单的端到端训练流程实现性能提升。

Result: 以Qwen3-8B-Instruct为基础模型，在TravelPlanner基准上达到82.7%的最终通过率，远超DeepSeek-R1-671B的40%，同时保持更小的模型规模。

Conclusion: IMAGINE框架成功将多智能体系统的能力集成到单一模型中，显著提升了推理规划性能，同时降低了模型规模和推理成本。

Abstract: Although large language models (LLMs) have made significant strides across
various tasks, they still face significant challenges in complex reasoning and
planning. For example, even with carefully designed prompts and prior
information explicitly provided, GPT-4o achieves only a 7% Final Pass Rate on
the TravelPlanner dataset in the sole-planning mode. Similarly, even in the
thinking mode, Qwen3-8B-Instruct and DeepSeek-R1-671B, only achieve Final Pass
Rates of 5.9% and 40%, respectively. Although well-organized Multi-Agent
Systems (MAS) can offer improved collective reasoning, they often suffer from
high reasoning costs due to multi-round internal interactions, long
per-response latency, and difficulties in end-to-end training. To address these
challenges, we propose a general and scalable framework called IMAGINE, short
for Integrating Multi-Agent System into One Model. This framework not only
integrates the reasoning and planning capabilities of MAS into a single,
compact model, but also significantly surpass the capabilities of the MAS
through a simple end-to-end training. Through this pipeline, a single
small-scale model is not only able to acquire the structured reasoning and
planning capabilities of a well-organized MAS but can also significantly
outperform it. Experimental results demonstrate that, when using
Qwen3-8B-Instruct as the base model and training it with our method, the model
achieves an 82.7% Final Pass Rate on the TravelPlanner benchmark, far exceeding
the 40% of DeepSeek-R1-671B, while maintaining a much smaller model size.

</details>


### [16] [Eliminating Negative Occurrences of Derived Predicates from PDDL Axioms](https://arxiv.org/abs/2510.14412)
*Claudia Grundke,Gabriele Röger*

Main category: cs.AI

TL;DR: 本文提出了一个转换方法，用于消除PDDL公理中派生谓词的负出现，证明这种限制可以被克服。


<details>
  <summary>Details</summary>
Motivation: PDDL标准限制公理体中谓词的负出现只能用于直接由动作设置的谓词，而非由公理派生的谓词。但文献中作者经常偏离这一限制，只要求公理集是可分层的。本文旨在证明这两种变体可以表达相同的查询，并展示相应的转换方法。

Method: 提出了一个转换方法，通过消除公理中派生谓词的负出现，将包含负出现的公理集转换为符合PDDL标准限制的形式。

Result: 证明了包含负出现的公理集与符合PDDL标准限制的公理集在表达能力上是等价的，都能表达最小不动点逻辑中的相同查询。

Conclusion: PDDL公理中派生谓词的负出现限制可以被克服，通过本文提出的转换方法，可以在保持表达能力的同时满足标准限制。

Abstract: Axioms are a feature of the Planning Domain Definition Language PDDL that can
be considered as a generalization of database query languages such as Datalog.
The PDDL standard restricts negative occurrences of predicates in axiom bodies
to predicates that are directly set by actions and not derived by axioms. In
the literature, authors often deviate from this limitation and only require
that the set of axioms is stratifiable. Both variants can express exactly the
same queries as least fixed-point logic, indicating that negative occurrences
of derived predicates can be eliminated. We present the corresponding
transformation.

</details>


### [17] [Helmsman: Autonomous Synthesis of Federated Learning Systems via Multi-Agent Collaboration](https://arxiv.org/abs/2510.14512)
*Haoyuan Li,Mathias Funk,Aaqib Saeed*

Main category: cs.AI

TL;DR: Helmsman是一个多智能体系统，通过模拟研发工作流程，从高级用户规范自动合成联邦学习系统，包括交互式规划、模块化代码生成和自主评估优化。


<details>
  <summary>Details</summary>
Motivation: 联邦学习系统设计复杂，需要处理数据异构性和系统约束等多方面挑战，导致解决方案脆弱且定制化，需要自动化工具来降低设计复杂性。

Method: 采用三阶段协作方法：1)交互式人机循环规划制定研究计划；2)监督智能体团队进行模块化代码生成；3)在沙盒模拟环境中进行自主评估和优化的闭环流程。

Result: 实验表明，Helmsman生成的解决方案与手工构建的基线方法相当甚至更优，并引入了AgentFL-Bench基准来评估系统级生成能力。

Conclusion: 该工作代表了向复杂去中心化AI系统自动化工程迈出的重要一步，能够有效降低联邦学习系统设计的复杂性。

Abstract: Federated Learning (FL) offers a powerful paradigm for training models on
decentralized data, but its promise is often undermined by the immense
complexity of designing and deploying robust systems. The need to select,
combine, and tune strategies for multifaceted challenges like data
heterogeneity and system constraints has become a critical bottleneck,
resulting in brittle, bespoke solutions. To address this, we introduce
Helmsman, a novel multi-agent system that automates the end-to-end synthesis of
federated learning systems from high-level user specifications. It emulates a
principled research and development workflow through three collaborative
phases: (1) interactive human-in-the-loop planning to formulate a sound
research plan, (2) modular code generation by supervised agent teams, and (3) a
closed-loop of autonomous evaluation and refinement in a sandboxed simulation
environment. To facilitate rigorous evaluation, we also introduce
AgentFL-Bench, a new benchmark comprising 16 diverse tasks designed to assess
the system-level generation capabilities of agentic systems in FL. Extensive
experiments demonstrate that our approach generates solutions competitive with,
and often superior to, established hand-crafted baselines. Our work represents
a significant step towards the automated engineering of complex decentralized
AI systems.

</details>


### [18] [Beyond Hallucinations: The Illusion of Understanding in Large Language Models](https://arxiv.org/abs/2510.14665)
*Rikard Rosenbacke,Carl Rosenbacke,Victor Rosenbacke,Martin McKee*

Main category: cs.AI

TL;DR: 本文提出了Rose-Frame框架，用于诊断人类与AI交互中的认知和认识论漂移问题，强调将AI直觉置于人类理性监督之下。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然输出流畅且情感共鸣强，但基于统计预测而非扎根推理，存在幻觉风险，可能产生听起来有说服力但缺乏事实有效性的回答。

Method: 引入Rose-Frame三维框架：(i)地图与领土区分现实表征与现实本身；(ii)直觉与理性区分快速情感判断与缓慢反思思维；(iii)冲突与确认检验思想是否通过分歧批判测试还是仅通过相互验证强化。

Result: Rose-Frame不试图用更多数据或规则修复LLM，而是提供反思工具，使模型局限性和用户假设可见，实现更透明和批判性意识的AI部署。

Conclusion: 重新定义对齐为认知治理：无论是人类还是人工智能的直觉，都必须由人类理性来治理。只有通过嵌入反思性、可证伪的监督，才能将机器的流畅性与人类的理解对齐。

Abstract: Large language models (LLMs) are becoming deeply embedded in human
communication and decision-making, yet they inherit the ambiguity, bias, and
lack of direct access to truth inherent in language itself. While their outputs
are fluent, emotionally resonant, and coherent, they are generated through
statistical prediction rather than grounded reasoning. This creates the risk of
hallucination, responses that sound convincing but lack factual validity.
Building on Geoffrey Hinton's observation that AI mirrors human intuition
rather than reasoning, this paper argues that LLMs operationalize System 1
cognition at scale: fast, associative, and persuasive, but without reflection
or falsification. To address this, we introduce the Rose-Frame, a
three-dimensional framework for diagnosing cognitive and epistemic drift in
human-AI interaction. The three axes are: (i) Map vs. Territory, which
distinguishes representations of reality (epistemology) from reality itself
(ontology); (ii) Intuition vs. Reason, drawing on dual-process theory to
separate fast, emotional judgments from slow, reflective thinking; and (iii)
Conflict vs. Confirmation, which examines whether ideas are critically tested
through disagreement or simply reinforced through mutual validation. Each
dimension captures a distinct failure mode, and their combination amplifies
misalignment. Rose-Frame does not attempt to fix LLMs with more data or rules.
Instead, it offers a reflective tool that makes both the model's limitations
and the user's assumptions visible, enabling more transparent and critically
aware AI deployment. It reframes alignment as cognitive governance: intuition,
whether human or artificial, must remain governed by human reason. Only by
embedding reflective, falsifiable oversight can we align machine fluency with
human understanding.

</details>


### [19] [Machine Learning and Public Health: Identifying and Mitigating Algorithmic Bias through a Systematic Review](https://arxiv.org/abs/2510.14669)
*Sara Altamirano,Arjan Vreeken,Sennay Ghebreab*

Main category: cs.AI

TL;DR: 本文对2021-2025年荷兰公共卫生机器学习研究中的算法偏见进行了系统文献综述，开发了RABAT评估工具，发现普遍存在公平性框架缺失等问题，并提出了ACAR四阶段框架来帮助研究人员在ML生命周期中解决公平性问题。


<details>
  <summary>Details</summary>
Motivation: 机器学习在公共卫生领域具有革命性潜力，但如果不系统关注算法偏见，可能会无意中加剧现有的健康不平等。本文旨在系统评估荷兰公共卫生ML研究中的算法偏见识别、讨论和报告情况。

Method: 开发了RABAT评估工具，整合了Cochrane偏见风险评估、PROBAST和微软负责任AI检查表的元素，并将其应用于35篇同行评审研究进行系统分析。

Result: 分析显示存在普遍差距：虽然数据采样和缺失数据处理有良好记录，但大多数研究缺乏明确的公平性框架、亚组分析以及对潜在危害的透明讨论。

Conclusion: 提出了ACAR四阶段公平性导向框架，为公共卫生ML从业者提供了可操作的建议，确保算法创新能够促进健康公平而非削弱它。

Abstract: Machine learning (ML) promises to revolutionize public health through
improved surveillance, risk stratification, and resource allocation. However,
without systematic attention to algorithmic bias, ML may inadvertently
reinforce existing health disparities. We present a systematic literature
review of algorithmic bias identification, discussion, and reporting in Dutch
public health ML research from 2021 to 2025. To this end, we developed the Risk
of Algorithmic Bias Assessment Tool (RABAT) by integrating elements from
established frameworks (Cochrane Risk of Bias, PROBAST, Microsoft Responsible
AI checklist) and applied it to 35 peer-reviewed studies. Our analysis reveals
pervasive gaps: although data sampling and missing data practices are well
documented, most studies omit explicit fairness framing, subgroup analyses, and
transparent discussion of potential harms. In response, we introduce a
four-stage fairness-oriented framework called ACAR (Awareness,
Conceptualization, Application, Reporting), with guiding questions derived from
our systematic literature review to help researchers address fairness across
the ML lifecycle. We conclude with actionable recommendations for public health
ML practitioners to consistently consider algorithmic bias and foster
transparency, ensuring that algorithmic innovations advance health equity
rather than undermine it.

</details>


### [20] [NAEL: Non-Anthropocentric Ethical Logic](https://arxiv.org/abs/2510.14676)
*Bianca Maria Lerma,Rafael Peñaloza*

Main category: cs.AI

TL;DR: NAEL是一个基于主动推理和符号推理的新型人工智能伦理框架，采用非人类中心主义方法，将伦理行为形式化为智能系统在动态多智能体环境中最小化全局预期自由能量的涌现属性。


<details>
  <summary>Details</summary>
Motivation: 传统以人类为中心的AI伦理方法存在局限性，NAEL旨在开发一种不预设人类道德直觉的伦理框架，使智能体能够在不确定环境中发展情境敏感、自适应和关系性的伦理行为。

Method: 提出神经符号架构，结合主动推理和符号推理，使智能体能够评估其行为在不确定环境中的伦理后果，通过最小化全局预期自由能量来实现伦理决策。

Result: 通过伦理资源分配的案例研究展示了NAEL能够动态平衡自我保存、认知学习和集体福利的能力，验证了该框架的有效性。

Conclusion: NAEL为人工智能伦理提供了一种新的非人类中心主义方法，能够克服现有伦理模型的局限性，使智能体在复杂环境中发展出更灵活和自适应的伦理行为。

Abstract: We introduce NAEL (Non-Anthropocentric Ethical Logic), a novel ethical
framework for artificial agents grounded in active inference and symbolic
reasoning. Departing from conventional, human-centred approaches to AI ethics,
NAEL formalizes ethical behaviour as an emergent property of intelligent
systems minimizing global expected free energy in dynamic, multi-agent
environments. We propose a neuro-symbolic architecture to allow agents to
evaluate the ethical consequences of their actions in uncertain settings. The
proposed system addresses the limitations of existing ethical models by
allowing agents to develop context-sensitive, adaptive, and relational ethical
behaviour without presupposing anthropomorphic moral intuitions. A case study
involving ethical resource distribution illustrates NAEL's dynamic balancing of
self-preservation, epistemic learning, and collective welfare.

</details>


### [21] [Practical, Utilitarian Algorithm Configuration](https://arxiv.org/abs/2510.14683)
*Devon Graham,Kevin Leyton-Brown*

Main category: cs.AI

TL;DR: 本文改进了COUP算法配置方法，使其在保持理论保证的同时，实际性能能够与广泛使用的启发式配置方法竞争，并通过案例研究展示了算法选择解决方案对效用函数变化的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: COUP是一种基于效用理论的算法配置方法，主要关注理论保证而忽视了实际性能。本文旨在弥补这一差距，使基于理论的效用算法配置在实际应用中具有竞争力。

Method: 提出了一系列对COUP的改进措施，在不降低理论保证的前提下提升其经验性能，并通过实验验证这些改进的效果。

Result: 改进后的COUP在经验性能上能够与广泛使用的启发式配置方法竞争，同时保持了理论保证。

Conclusion: 通过改进COUP，成功将基于理论的效用算法配置方法提升到实用水平，为算法配置提供了既有理论保证又具有竞争力的解决方案。

Abstract: Utilitarian algorithm configuration identifies a parameter setting for a
given algorithm that maximizes a user's utility. Utility functions offer a
theoretically well-grounded approach to optimizing decision-making under
uncertainty and are flexible enough to capture a user's preferences over
algorithm runtimes (e.g., they can describe a sharp cutoff after which a
solution is no longer required, a per-hour cost for compute, or diminishing
returns from algorithms that take longer to run). COUP is a recently-introduced
utilitarian algorithm configuration procedure which was designed mainly to
offer strong theoretical guarantees about the quality of the configuration it
returns, with less attention paid to its practical performance. This paper
closes that gap, bringing theoretically-grounded, utilitarian algorithm
configuration to the point where it is competitive with widely used, heuristic
configuration procedures that offer no performance guarantees. We present a
series of improvements to COUP that improve its empirical performance without
degrading its theoretical guarantees and demonstrate their benefit
experimentally. Using a case study, we also illustrate ways of exploring the
robustness of a given solution to the algorithm selection problem to variations
in the utility function.

</details>


### [22] [Purifying Task Vectors in Knowledge-Aware Subspace for Model Merging](https://arxiv.org/abs/2510.14697)
*Bang An,Yibo Yang,Philip Torr,Bernard Ghanem*

Main category: cs.AI

TL;DR: 本文提出了PAVE方法，通过知识感知子空间净化任务向量，消除任务向量中的冗余信息，从而提升模型合并的性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型合并方法中，任务向量包含任务无关的冗余信息，导致合并模型性能显著下降。现有方法随机丢弃参数元素，缺乏知识感知且存在随机性。

Method: 提出PAVE方法：1）从每个任务采样训练样本，通过微调模型获取线性层前的协方差矩阵；2）执行上下文导向的奇异值分解，突出与目标知识最相关的权重分量；3）在知识感知子空间中将微调模型权重分为任务相关和冗余组件，通过修剪冗余组件净化任务向量；4）引入谱秩分配策略优化归一化激活修剪误差。

Result: PAVE作为即插即用方案，适用于各种基于任务向量的合并方法，在多种合并方法、任务和模型架构上均表现出有效性。

Conclusion: PAVE方法能够有效净化任务向量中的冗余信息，显著提升模型合并性能，且具有良好的通用性和适用性。

Abstract: Model merging aims to integrate task-specific abilities from individually
fine-tuned models into a single model without extra training. In recent model
merging methods, task vector has become a fundamental building block, as it can
encapsulate the residual information from finetuning. However, the merged model
often suffers from notable performance degradation due to the conflicts caused
by task-irrelevant redundancy in task vectors. Existing efforts in overcoming
redundancy by randomly dropping elements in the parameter space involves
randomness and lacks knowledge awareness. To address these challenges, in this
study, we propose Purifying TAsk Vectors (PAVE) in knowledge-aware subspace.
Concretely, we sample some training examples from each task, and feed them into
their corresponding fine-tuned models to acquire the covariance matrices before
linear layers. We then perform a context-oriented singular value decomposition,
which accentuates the weight components most relevant to the target knowledge.
As a result, we can split fine-tuned model weights into task-relevant and
redundant components in the knowledge-aware subspace, and purify the task
vector by pruning the redundant components. To induce fair pruning efforts
across models, we further introduce a spectral rank allocation strategy by
optimizing a normalized activated pruning error. The task vector purification
by our method as a plug-and-play scheme is applicable across various task
vector-based merging methods to improve their performance. In experiments, we
demonstrate the effectiveness of PAVE across a diverse set of merging methods,
tasks, and model architectures.

</details>


### [23] [Cognitive-Aligned Spatio-Temporal Large Language Models For Next Point-of-Interest Prediction](https://arxiv.org/abs/2510.14702)
*Penglong Zhai,Jie Li,Fanyi Di,Yue Liu,Yifang Yuan,Jie Huang,Peng Wu,Sicong Wang,Mingyang Yin,Tingting Hu,Yao Xu,Xin Li*

Main category: cs.AI

TL;DR: CoAST是一个认知对齐的时空大语言模型框架，通过自然语言界面整合世界知识、时空轨迹模式和用户信息，用于下一个兴趣点推荐任务。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型主要基于非结构化文本预训练，缺乏对结构化地理实体和序列移动模式的理解，且需要整合世界知识和人类认知对齐来提升推荐性能。

Method: CoAST框架包含两个阶段：(1) 在去敏感化用户的丰富时空轨迹数据上继续预训练以获取推荐知识；(2) 通过监督微调和强化学习将认知判断与人类偏好对齐。

Result: 在多个真实数据集上的离线实验和在AMAP App首页"猜你去哪"功能中的在线实验证明了CoAST的有效性。

Conclusion: CoAST框架能够有效整合世界知识、时空轨迹模式和认知对齐，提升下一个兴趣点推荐的性能。

Abstract: The next point-of-interest (POI) recommendation task aims to predict the
users' immediate next destinations based on their preferences and historical
check-ins, holding significant value in location-based services. Recently,
large language models (LLMs) have shown great potential in recommender systems,
which treat the next POI prediction in a generative manner. However, these
LLMs, pretrained primarily on vast corpora of unstructured text, lack the
native understanding of structured geographical entities and sequential
mobility patterns required for next POI prediction tasks. Moreover, in
industrial-scale POI prediction applications, incorporating world knowledge and
alignment of human cognition, such as seasons, weather conditions, holidays,
and users' profiles (such as habits, occupation, and preferences), can enhance
the user experience while improving recommendation performance. To address
these issues, we propose CoAST (Cognitive-Aligned Spatial-Temporal LLMs), a
framework employing natural language as an interface, allowing for the
incorporation of world knowledge, spatio-temporal trajectory patterns,
profiles, and situational information. Specifically, CoAST mainly comprises of
2 stages: (1) Recommendation Knowledge Acquisition through continued
pretraining on the enriched spatial-temporal trajectory data of the
desensitized users; (2) Cognitive Alignment to align cognitive judgments with
human preferences using enriched training data through Supervised Fine-Tuning
(SFT) and a subsequent Reinforcement Learning (RL) phase. Extensive offline
experiments on various real-world datasets and online experiments deployed in
"Guess Where You Go" of AMAP App homepage demonstrate the effectiveness of
CoAST.

</details>


### [24] [ToolPRM: Fine-Grained Inference Scaling of Structured Outputs for Function Calling](https://arxiv.org/abs/2510.14703)
*Jianghao Lin,Yuanyuan Shi,Xin Peng,Renjie Ding,Hairui Wang,Yuxuan Peng,Bizhe Bai,Weixi Song,Fengshuo Bai,Huacan Chai,Weinan Zhang,Fei Huang,Ying Wen*

Main category: cs.AI

TL;DR: 该论文提出了一个结合细粒度波束搜索和过程奖励模型ToolPRM的推理扩展框架，用于提升大语言模型在结构化输出（如函数调用）任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 当前推理扩展研究主要关注非结构化输出生成任务，而在结构化输出（如函数调用）中的应用研究不足，需要填补这一空白。

Method: 提出ToolPRM过程奖励模型，通过函数掩码技术自动构建首个细粒度调用内过程监督数据集，为结构化工具使用推理提供步骤级奖励。结合细粒度波束搜索进行推理扩展。

Result: ToolPRM在预测准确性上优于粗粒度和结果奖励模型，表明其在监督函数调用推理过程方面具有更强能力。配备ToolPRM的推理扩展技术显著提升了骨干模型在各种函数调用任务和基准测试中的性能。

Conclusion: 揭示了将推理扩展技术应用于结构化输出的关键原则："多探索少保留"，这是由于结构化函数调用生成的不可恢复性特征决定的。

Abstract: Large language models (LLMs) are increasingly demonstrating strong
capabilities as autonomous agents, with function calling serving as a core
mechanism for interaction with the environment. Meanwhile, inference scaling
has become a cutting-edge technique to enhance LLM performance by allocating
more computational resources during the inference process. However, current
research on inference scaling primarily focuses on unstructured output
generation tasks, leaving its application in structured outputs, like function
calling, largely underexplored. To bridge this gap, we propose an inference
scaling framework that combines fine-grained beam search with a process reward
model, ToolPRM, which scores the internal steps of each single function call.
To train ToolPRM, we construct the first fine-grained intra-call process
supervision dataset, automatically annotated with function-masking techniques
to provide step-level rewards for structured tool-use reasoning. Extensive
experiments demonstrate that ToolPRM beats the coarse-grained and outcome
reward models in terms of predictive accuracy, indicating its stronger
capability in supervising the function calling inference process. Inference
scaling technique equipped with ToolPRM also significantly improves the
backbone model performance across various function calling tasks and
benchmarks. More importantly, we reveal a key principle for applying inference
scaling techniques to structured outputs: "explore more but retain less" due to
the unrecoverability characteristics of structured function calling generation.

</details>


### [25] [SimKO: Simple Pass@K Policy Optimization](https://arxiv.org/abs/2510.14807)
*Ruotian Peng,Yi Ren,Zhouliang Yu,Weiyang Liu,Yandong Wen*

Main category: cs.AI

TL;DR: 本文分析了RLVR方法在强化学习中存在的系统性偏差问题，提出了SimKO方法来缓解概率过度集中现象，从而提高探索能力。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法存在系统性偏差，倾向于利用而非探索，表现为pass@1性能提升但pass@K性能下降。需要理解这一问题的训练动态并找到解决方案。

Method: 通过跟踪词汇候选的token级概率分布分析训练动态，发现概率集中效应。提出SimKO方法，采用非对称设计：对验证正确的响应提升top-K候选概率，对验证错误的响应对top-1候选施加更强惩罚。

Result: SimKO在各种数学和逻辑推理基准测试中，对广泛的K值范围都能获得更高的pass@K性能。

Conclusion: SimKO通过缓解概率过度集中问题，有效鼓励了探索，为改进RLVR的探索能力提供了一种简单方法。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has advanced the
reasoning capabilities of large language models (LLMs). However, prevailing
RLVR methods exhibit a systematic bias toward exploitation over exploration, as
evidenced by improved pass@1 but reduced pass@K (K>1) performance. To
understand this issue, we analyze training dynamics of RLVR methods by tracking
the token-level probability distributions over vocabulary candidates. Our
analysis reveals a consistent probability concentration effect where the top-1
candidate increasingly accumulates probability mass and suppresses that of
other candidates. More importantly, stronger over-concentration correlates with
worse pass@K performance. Inspired by this finding, we propose Simple Pass@K
Optimization (SimKO), a method designed to mitigate the over-concentration
issue, thereby encouraging exploration. SimKO operates in an asymmetrical
manner. For verified-correct responses, it boosts the probabilities of the
top-K candidates. For verified-incorrect responses, it applies stronger
penalties to the top-1 candidate. We observe that this asymmetric design is
particularly effective at mitigating over-concentration when applied at tokens
with high entropy. Across various math and logical-reasoning benchmarks, SimKO
consistently yields higher pass@K for a wide range of K, providing a simple way
to improve RLVR's exploration.

</details>


### [26] [RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning](https://arxiv.org/abs/2510.14828)
*Jinrui Liu,Bingyan Nie,Boyu Li,Yaran Chen,Yuze Wang,Shunsen He,Haoran Li*

Main category: cs.AI

TL;DR: 提出RoboGPT-R1两阶段微调框架，通过监督训练获取基础知识，再通过强化学习提升视觉空间理解和推理能力，在EmbodiedBench基准上显著超越GPT-4o-mini等模型。


<details>
  <summary>Details</summary>
Motivation: 提升具身智能体在复杂真实环境中完成长视距操作任务的能力，解决现有大语言模型和视觉语言模型在常识和推理能力方面的限制。

Method: 采用两阶段微调框架：监督训练从专家序列学习基础知识，强化学习解决模型在视觉空间理解和推理方面的不足，设计基于规则的奖励函数考虑长视距性能和动作约束。

Result: 在Qwen2.5-VL-3B上训练的推理模型在EmbodiedBench基准上比GPT-4o-mini提升21.33%，比Qwen2.5-VL-7B的其他工作提升20.33%。

Conclusion: RoboGPT-R1框架有效提升了具身智能体的推理能力，在长视距操作任务中表现出色，证明了强化学习在弥补监督微调不足方面的有效性。

Abstract: Improving the reasoning capabilities of embodied agents is crucial for robots
to complete complex human instructions in long-view manipulation tasks
successfully. Despite the success of large language models and vision language
models based on Supervised Fine-Tuning (SFT) in planning tasks, they continue
facing challenges in performing long-horizon manipulation tasks in complex
real-world environments, owing to their restricted common sense and reasoning
capabilities. Considering that aligning general-purpose vision language models
to robotic planning tasks via supervised fine-tuning suffers from poor
generalization and insufficient physical understanding, we propose RoboGPT-R1,
a two-stage fine-tuning framework for embodied planning. In this framework,
supervised training acquires foundational knowledge through expert sequences,
followed by RL to address the model's shortcomings in visual-spatial
understanding and reasoning. To achieve physical understanding and action
sequence consistency in multi-step reasoning tasks, we design a rule-based
reward function that simultaneously considers long-horizon performance and
action constraint in the environment. The reasoning model, trained on
Qwen2.5-VL-3B, significantly outperforms the larger-scale model, GPT-4o-mini,
by 21.33% and surpasses other work trained on Qwen2.5-VL-7B by 20.33% on the
EmbodiedBench benchmark.

</details>


### [27] [Boosting Instruction Following at Scale](https://arxiv.org/abs/2510.14842)
*Ben Elder,Evelyn Duesterwald,Vinod Muthusamy*

Main category: cs.AI

TL;DR: 本文提出了Instruction Boosting方法，通过后生成处理来提高LLM对提示指令的遵循可靠性，在包含最多10条指令的SCALEDIF基准上实现了指令遵循率提升4-7个百分点。


<details>
  <summary>Details</summary>
Motivation: 开发人员通常通过精心设计提示来影响LLM行为，但仅仅添加更多指令并不能保证它们会被实际遵循，需要提高指令遵循的可靠性。

Method: 引入Instruction Boosting作为后生成方法，并创建SCALEDIF基准来评估多指令场景下的性能，同时开发了定量冲突评分工具来分析指令间的冲突。

Result: Instruction Boosting将两条指令的遵循率提高了7个百分点，十条指令的遵循率提高了4个百分点。分析发现性能下降与指令间冲突程度相关。

Conclusion: Instruction Boosting能有效提高LLM对多指令的遵循可靠性，冲突评分工具可为开发者提供关于添加额外指令对模型性能影响的反馈。

Abstract: A typical approach developers follow to influence an LLM's behavior in an
application is through careful manipulation of the prompt, such as by adding or
modifying instructions. However, merely adding more instructions provides
little assurance that they will actually be followed. We introduce Instruction
Boosting as a post-generation method to increase the reliability of LLM prompt
instructions. We show that Instruction Boosting improves the instruction
following rate by up to 7 points for two instructions and up to 4 points for
ten instructions. To demonstrate these results we introduce SCALEDIF, a
benchmark with a scaled instruction volume of up to ten instructions per data
sample. We also present an analysis of the commonly observed trend that
performance degrades as more instructions are added. We show that an important
factor contributing to this trend is the degree of tension and conflict that
arises as the number of instructions is increased. We contribute a quantitative
conflict scoring tool that explains the observed performance trends and
provides feedback to developers on the impact that additional prompt
instructions have on a model's performance.

</details>


### [28] [Where to Search: Measure the Prior-Structured Search Space of LLM Agents](https://arxiv.org/abs/2510.14846)
*Zhuo-Yang Song*

Main category: cs.AI

TL;DR: 本文提出了一个紧凑的形式理论，用于描述和测量基于领域先验指导的LLM辅助迭代搜索。通过将智能体表示为输入输出的模糊关系算子，并引入覆盖生成函数来量化可达性难度，为LLM构建的迭代搜索提供了系统化的形式描述。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的生成-过滤-精炼迭代范式在推理、编程和科学发现方面取得了进展，但搜索效果依赖于如何将领域先验编码为操作化结构化的假设空间。需要建立形式理论来系统描述和测量这种搜索过程。

Method: 1. 将智能体表示为输入输出的模糊关系算子，受固定安全包络约束；2. 引入单延续参数加权所有可达路径，求和得到覆盖生成函数；3. 推导可达性难度度量；4. 提供安全包络诱导图上的搜索几何解释；5. 通过多数投票实例验证可测试推断。

Result: 提出了一个可操作的语言和工具来测量智能体及其搜索空间，为LLM构建的迭代搜索提供了系统化的形式描述框架。

Conclusion: 该理论为基于领域先验指导的LLM辅助迭代搜索提供了紧凑的形式描述和测量方法，建立了系统化的分析框架。

Abstract: The generate-filter-refine (iterative paradigm) based on large language
models (LLMs) has achieved progress in reasoning, programming, and program
discovery in AI+Science. However, the effectiveness of search depends on where
to search, namely, how to encode the domain prior into an operationally
structured hypothesis space. To this end, this paper proposes a compact formal
theory that describes and measures LLM-assisted iterative search guided by
domain priors. We represent an agent as a fuzzy relation operator on inputs and
outputs to capture feasible transitions; the agent is thereby constrained by a
fixed safety envelope. To describe multi-step reasoning/search, we weight all
reachable paths by a single continuation parameter and sum them to obtain a
coverage generating function; this induces a measure of reachability
difficulty; and it provides a geometric interpretation of search on the graph
induced by the safety envelope. We further provide the simplest testable
inferences and validate them via a majority-vote instantiation. This theory
offers a workable language and operational tools to measure agents and their
search spaces, proposing a systematic formal description of iterative search
constructed by LLMs.

</details>


### [29] [Budget-aware Test-time Scaling via Discriminative Verification](https://arxiv.org/abs/2510.14913)
*Kyle Montgomery,Sijun Tan,Yuqi Chen,Siyuan Zhuang,Tianjun Zhang,Raluca Ada Popa,Chenguang Wang*

Main category: cs.AI

TL;DR: 本文提出了一种预算感知的判别式验证方法，结合自一致性机制，在固定计算预算下显著优于生成式验证方法，在AIME2025上准确率提升达15.3%。


<details>
  <summary>Details</summary>
Motivation: 现有基于生成式验证器的方法虽然能提升大语言模型在复杂推理任务上的性能，但计算成本过高，限制了实际应用。

Method: 采用判别式验证器与自一致性相结合的混合方法，在固定计算预算下进行测试时扩展。

Result: 在固定计算预算下，该方法在AIME2025上比最先进的生成式验证方法准确率提升高达15.3%。

Conclusion: 预算感知的判别式验证不仅是对自一致性的免费升级，而且是比昂贵的生成式技术更有效和高效的替代方案。

Abstract: Test-time scaling is a powerful strategy for boosting the performance of
large language models on complex reasoning tasks. While state-of-the-art
approaches often employ generative verifiers to select the best solution from a
pool of candidates, this method incurs prohibitive computational costs,
limiting its practicality. In this work, we shift the focus to a more
budget-aware paradigm: discriminative verification. We conduct a thorough
empirical analysis and demonstrate that while discriminative verifiers may
underperform in isolation, combining them with self-consistency in a hybrid
approach creates a powerful and efficient test-time scaling mechanism. Notably,
under a fixed compute budget, this hybrid approach surpasses state-of-the-art
generative verification by a significant margin: achieving up to 15.3\% higher
accuracy on AIME2025. Our findings establish that for practical, real-world
applications, budget-aware scaling with discriminative verifiers is not only a
"free" upgrade over self-consistency, but also a more effective and efficient
alternative to costly generative techniques. Code is available at
https://github.com/wang-research-lab/verification.

</details>


### [30] [TRI-DEP: A Trimodal Comparative Study for Depression Detection Using Speech, Text, and EEG](https://arxiv.org/abs/2510.14922)
*Annisaa Fitri Nurfidausi,Eleonora Mancini,Paolo Torroni*

Main category: cs.AI

TL;DR: 本文系统探索了多模态抑郁症检测方法，通过比较脑电图、语音和文本的多种特征表示和建模策略，发现三模态组合能显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 抑郁症检测面临挑战，现有研究范围有限、缺乏系统特征比较且评估协议不一致，需要填补这些空白。

Method: 系统评估手工特征与预训练嵌入、不同神经编码器效果、单模态/双模态/三模态配置，分析融合策略并关注脑电图的作用，采用一致的主体独立分割确保稳健可复现的基准测试。

Result: 结果显示：(i)脑电图、语音和文本三模态组合增强多模态检测；(ii)预训练嵌入优于手工特征；(iii)精心设计的三模态模型达到最先进性能。

Conclusion: 本研究为未来多模态抑郁症检测研究奠定了基础。

Abstract: Depression is a widespread mental health disorder, yet its automatic
detection remains challenging. Prior work has explored unimodal and multimodal
approaches, with multimodal systems showing promise by leveraging complementary
signals. However, existing studies are limited in scope, lack systematic
comparisons of features, and suffer from inconsistent evaluation protocols. We
address these gaps by systematically exploring feature representations and
modelling strategies across EEG, together with speech and text. We evaluate
handcrafted features versus pre-trained embeddings, assess the effectiveness of
different neural encoders, compare unimodal, bimodal, and trimodal
configurations, and analyse fusion strategies with attention to the role of
EEG. Consistent subject-independent splits are applied to ensure robust,
reproducible benchmarking. Our results show that (i) the combination of EEG,
speech and text modalities enhances multimodal detection, (ii) pretrained
embeddings outperform handcrafted features, and (iii) carefully designed
trimodal models achieve state-of-the-art performance. Our work lays the
groundwork for future research in multimodal depression detection.

</details>


### [31] [Stable but Miscalibrated: A Kantian View on Overconfidence from Filters to Large Language Models](https://arxiv.org/abs/2510.14925)
*Akira Okutomi*

Main category: cs.AI

TL;DR: 将康德的《纯粹理性批判》重新解释为反馈稳定性理论，提出复合不稳定指数H-Risk来衡量推理系统的稳定性，在LLMs中发现脆弱内部动态与错误校准和幻觉相关。


<details>
  <summary>Details</summary>
Motivation: 建立康德理性自我限制理论与反馈控制之间的结构桥梁，为诊断和减少推理系统中的过度自信提供原则性视角。

Method: 提出复合不稳定指数H-Risk（结合谱边界、条件数、时间敏感性和创新放大），在线性高斯模拟和大型语言模型中进行实验验证。

Result: 在模拟中H-Risk能预测过度自信错误；在LLMs中脆弱内部动态与错误校准和幻觉相关，批判式提示对校准和幻觉效果不一。

Conclusion: 揭示了名义稳定性与认知稳定性之间的差距，为理解和改进推理系统的可靠性提供了新框架。

Abstract: We reinterpret Kant's Critique of Pure Reason as a theory of feedback
stability, viewing reason as a regulator that keeps inference within the bounds
of possible experience. We formalize this intuition via a composite instability
index (H-Risk) combining spectral margin, conditioning, temporal sensitivity,
and innovation amplification. In linear-Gaussian simulations, higher H-Risk
predicts overconfident errors even under formal stability, revealing a gap
between nominal and epistemic stability. Extending to large language models
(LLMs), we find that fragile internal dynamics correlate with miscalibration
and hallucination, while critique-style prompts show mixed effects on
calibration and hallucination. These results suggest a structural bridge
between Kantian self-limitation and feedback control, offering a principled
lens for diagnosing -- and selectively reducing -- overconfidence in reasoning
systems. This is a preliminary version; supplementary experiments and broader
replication will be reported in a future revision.

</details>


### [32] [GroundedPRM: Tree-Guided and Fidelity-Aware Process Reward Modeling for Step-Level Reasoning](https://arxiv.org/abs/2510.14942)
*Yao Zhang,Yu Wu,Haowei Zhang,Weiguo Li,Haokun Chen,Jingpei Wu,Guohao Li,Zhen Han,Volker Tresp*

Main category: cs.AI

TL;DR: GroundedPRM是一个基于树引导和保真度的自动过程监督框架，通过蒙特卡洛树搜索构建结构化推理路径，使用外部工具验证中间步骤，结合步骤级验证和全局结果评估，在少量自动标注数据上实现高质量的多步推理监督。


<details>
  <summary>Details</summary>
Motivation: 现有过程奖励模型面临三大挑战：噪声奖励、低事实保真度以及与步骤级推理目标的不对齐。这些挑战源于缺乏可扩展的高质量标注、人类标注成本高、基于LLM的自评估容易产生幻觉，以及蒙特卡洛估计导致的信用错误分配问题。

Method: 1. 使用蒙特卡洛树搜索构建结构化推理路径以减少奖励噪声；2. 通过外部工具验证每个中间步骤，提供基于执行的正确性信号；3. 设计混合奖励聚合机制，融合工具验证和MCTS反馈；4. 将奖励信号格式化为增强推理的生成结构，提高可解释性。

Result: 仅使用4万个自动标注样本（最佳性能PRM所需数据的10%），在ProcessBench上实现了高达26%的相对性能提升。当用于奖励引导的贪婪搜索时，甚至优于使用人类标注监督训练的PRM。

Conclusion: GroundedPRM为高质量过程级推理提供了一条可扩展且可验证的路径，通过树引导和保真度感知的方法有效解决了现有PRM的核心限制问题。

Abstract: Process Reward Models (PRMs) aim to improve multi-step reasoning in Large
Language Models (LLMs) by supervising intermediate steps and identifying
errors. However, building effective PRMs remains challenging due to the lack of
scalable, high-quality annotations. Existing approaches rely on costly human
labeling, LLM-based self-evaluation that is prone to hallucination, or Monte
Carlo (MC) estimation, which infers step quality solely from rollout outcomes
and often introduces noisy, misaligned supervision due to credit
misattribution. These issues result in three core limitations: noisy rewards,
low factual fidelity, and misalignment with step-level reasoning objectives. To
address these challenges, we introduce GroundedPRM, a tree-guided and
fidelity-aware framework for automatic process supervision. To reduce reward
noise and enable fine-grained credit assignment, we construct structured
reasoning paths via Monte Carlo Tree Search (MCTS). To eliminate hallucinated
supervision, we validate each intermediate step using an external tool,
providing execution-grounded correctness signals. To combine both step-level
validation and global outcome assessment, we design a hybrid reward aggregation
mechanism that fuses tool-based verification with MCTS-derived feedback.
Finally, we format the reward signal into a rationale-enhanced, generative
structure to promote interpretability and compatibility with instruction-tuned
LLMs. GroundedPRM is trained on only 40K automatically labeled samples,
amounting to just 10% of the data used by the best-performing PRM trained with
auto-labeled supervision. Nevertheless, it achieves up to a 26% relative
improvement in average performance on ProcessBench. When used for reward-guided
greedy search, GroundedPRM outperforms even PRMs trained with human-labeled
supervision, offering a scalable and verifiable path toward high-quality
process-level reasoning.

</details>


### [33] [Agentic Design of Compositional Machines](https://arxiv.org/abs/2510.14980)
*Wenqian Zhang,Weiyang Liu,Zhen Liu*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型在组合式机器设计中的能力，通过BesiegeField测试平台评估LLMs在空间推理、策略组装和指令遵循方面的表现，并探索强化学习作为改进路径。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型是否能够学习创造复杂机器，特别是在组合式机器设计任务中，这既是人类智能的标志也是工程实践的基础。

Method: 引入BesiegeField测试平台，基于Besiege游戏构建，支持部件组装、物理模拟和奖励驱动评估；对最先进的LLMs进行基准测试，并探索强化学习微调方法。

Result: 当前开源模型在空间推理、策略组装和指令遵循等关键能力上表现不足，通过强化学习微调实验展示了改进潜力，但也指出了语言、机器设计和物理推理交叉领域的挑战。

Conclusion: 大型语言模型在机器设计方面具有潜力，但需要进一步发展空间推理和物理理解能力，强化学习为提升这些能力提供了可行路径。

Abstract: The design of complex machines stands as both a marker of human intelligence
and a foundation of engineering practice. Given recent advances in large
language models (LLMs), we ask whether they, too, can learn to create. We
approach this question through the lens of compositional machine design: a task
in which machines are assembled from standardized components to meet functional
demands like locomotion or manipulation in a simulated physical environment. To
support this investigation, we introduce BesiegeField, a testbed built on the
machine-building game Besiege, which enables part-based construction, physical
simulation and reward-driven evaluation. Using BesiegeField, we benchmark
state-of-the-art LLMs with agentic workflows and identify key capabilities
required for success, including spatial reasoning, strategic assembly, and
instruction-following. As current open-source models fall short, we explore
reinforcement learning (RL) as a path to improvement: we curate a cold-start
dataset, conduct RL finetuning experiments, and highlight open challenges at
the intersection of language, machine design, and physical reasoning.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [34] [DIAMOND: Systolic Array Acceleration of Sparse Matrix Multiplication for Quantum Simulation](https://arxiv.org/abs/2510.14172)
*Yuchao Su,Srikar Chundury,Jiajia Li,Frank Mueller*

Main category: cs.AR

TL;DR: 该论文提出了第一个针对量子模拟优化的对角线加速器，利用哈密顿矩阵中常见的对角线结构，通过重构的脉动阵列数据流将稀疏矩阵转换为密集计算，显著提升了经典哈密顿模拟的性能和能效。


<details>
  <summary>Details</summary>
Motivation: 哈密顿模拟是量子计算中的关键工作负载，但由于希尔伯特空间维度随量子比特数指数增长，矩阵指数运算变得非常昂贵。现有加速器主要针对机器学习工作负载设计，其稀疏模式与哈密顿模拟中常见的结构化对角线模式存在根本差异。

Method: 开发了第一个对角线优化的量子模拟加速器，利用问题哈密顿矩阵中常见的对角线结构，通过重构的脉动阵列数据流将稀疏矩阵转换为密集计算，提高利用率和性能。

Result: 在HamLib多样化基准测试中，相比SIGMA、外积算法和Gustavson算法，平均性能分别提升10.26倍、33.58倍和53.15倍，峰值加速比达127.03倍，同时能耗平均降低471.55倍，最高降低4630.58倍。

Conclusion: 该对角线优化加速器通过利用哈密顿矩阵的结构特性，显著提升了经典哈密顿模拟的可扩展性和能效，为量子系统研究和量子设备验证提供了高效的计算解决方案。

Abstract: Hamiltonian simulation is a key workload in quantum computing, enabling the
study of complex quantum systems and serving as a critical tool for classical
verification of quantum devices. However, it is computationally challenging
because the Hilbert space dimension grows exponentially with the number of
qubits. The growing dimensions make matrix exponentiation, the key kernel in
Hamiltonian simulations, increasingly expensive. Matrix exponentiation is
typically approximated by the Taylor series, which contains a series of matrix
multiplications. Since Hermitian operators are often sparse, sparse matrix
multiplication accelerators are essential for improving the scalability of
classical Hamiltonian simulation. Yet, existing accelerators are primarily
designed for machine learning workloads and tuned to their characteristic
sparsity patterns, which differ fundamentally from those in Hamiltonian
simulations that are often dominated by structured diagonals.
  In this work, we present \name, the first diagonal-optimized quantum
simulation accelerator. It exploits the diagonal structure commonly found in
problem-Hamiltonian (Hermitian) matrices and leverages a restructured systolic
array dataflow to transform diagonally sparse matrices into dense computations,
enabling high utilization and performance. Through detailed cycle-level
simulation of diverse benchmarks in HamLib, \name{} demonstrates average
performance improvements of $10.26\times$, $33.58\times$, and $53.15\times$
over SIGMA, Outer Product, and Gustavson's algorithm, respectively, with peak
speedups up to $127.03\times$ while reducing energy consumption by an average
of $471.55\times$ and up to $4630.58\times$ compared to SIGMA.

</details>


### [35] [Computing-In-Memory Aware Model Adaption For Edge Devices](https://arxiv.org/abs/2510.14379)
*Ming-Han Lin,Tian-Sheuan Chang*

Main category: cs.AR

TL;DR: 本文提出了一种两阶段的CIM感知模型适配方法，通过模型压缩、资源重分配和量化感知训练，解决CIM宏的尺寸限制和ADC精度问题，在保持精度的同时显著提高了吞吐量和资源利用率。


<details>
  <summary>Details</summary>
Motivation: 计算内存(CIM)宏在深度学习加速中很受欢迎，但有限的宏尺寸和ADC精度会带来吞吐量和精度瓶颈，需要一种方法来优化模型以适应CIM架构的约束。

Method: 采用两阶段适配过程：第一阶段压缩模型并根据层重要性和宏尺寸约束重新分配资源；第二阶段进行量化感知训练，包含部分和量化和ADC精度考虑，以减少推理中的量化误差。

Result: 该方法将CIM阵列利用率提升至90%，支持同时激活多达256个字线，实现高达93%的压缩率，同时保持与先前方法相当的精度。

Conclusion: 所提出的CIM感知模型适配方法有效解决了CIM架构的局限性，在保持精度的同时显著提高了资源利用率和吞吐量。

Abstract: Computing-in-Memory (CIM) macros have gained popularity for deep learning
acceleration due to their highly parallel computation and low power
consumption. However, limited macro size and ADC precision introduce throughput
and accuracy bottlenecks. This paper proposes a two-stage CIM-aware model
adaptation process. The first stage compresses the model and reallocates
resources based on layer importance and macro size constraints, reducing model
weight loading latency while improving resource utilization and maintaining
accuracy. The second stage performs quantization-aware training, incorporating
partial sum quantization and ADC precision to mitigate quantization errors in
inference. The proposed approach enhances CIM array utilization to 90\%,
enables concurrent activation of up to 256 word lines, and achieves up to 93\%
compression, all while preserving accuracy comparable to previous methods.

</details>


### [36] [ColumnDisturb: Understanding Column-based Read Disturbance in Real DRAM Chips and Implications for Future Systems](https://arxiv.org/abs/2510.14750)
*İsmail Emir Yüksel,Ataberk Olgun,F. Nisa Bostancı,Haocong Luo,A. Giray Yağlıkçı,Onur Mutlu*

Main category: cs.AR

TL;DR: 本文实验发现了一种新的DRAM读干扰现象ColumnDisturb，通过重复打开或保持DRAM行（攻击行）打开，可以干扰共享相同列（位线）的DRAM单元，导致跨多个DRAM子阵列的位翻转。


<details>
  <summary>Details</summary>
Motivation: 研究DRAM芯片中广泛存在的读干扰现象，特别是与传统RowHammer/RowPress不同的列级干扰机制，以了解其对DRAM可靠性的影响。

Method: 使用216个DDR4和4个HBM2芯片从三大制造商进行实验，在多种操作条件下严格表征ColumnDisturb及其特性，获得27个关键实验观察结果。

Result: 1) ColumnDisturb影响所有三大制造商的芯片，且随着DRAM技术节点缩小而恶化；2) 在标准DDR4刷新窗口内可诱导位翻转；3) 比保留故障影响更多行（最多198倍）。

Conclusion: ColumnDisturb现象对DRAM可靠性构成严重威胁，特别是会显著降低利用单元保留时间异质性的保留感知刷新机制的有效性，且随着技术发展这一问题可能加剧。

Abstract: We experimentally demonstrate a new widespread read disturbance phenomenon,
ColumnDisturb, in real commodity DRAM chips. By repeatedly opening or keeping a
DRAM row (aggressor row) open, we show that it is possible to disturb DRAM
cells through a DRAM column (i.e., bitline) and induce bitflips in DRAM cells
sharing the same columns as the aggressor row (across multiple DRAM subarrays).
With ColumnDisturb, the activation of a single row concurrently disturbs cells
across as many as three subarrays (e.g., 3072 rows) as opposed to
RowHammer/RowPress, which affect only a few neighboring rows of the aggressor
row in a single subarray. We rigorously characterize ColumnDisturb and its
characteristics under various operational conditions using 216 DDR4 and 4 HBM2
chips from three major manufacturers. Among our 27 key experimental
observations, we highlight two major results and their implications.
  First, ColumnDisturb affects chips from all three major manufacturers and
worsens as DRAM technology scales down to smaller node sizes (e.g., the minimum
time to induce the first ColumnDisturb bitflip reduces by up to 5.06x). We
observe that, in existing DRAM chips, ColumnDisturb induces bitflips within a
standard DDR4 refresh window (e.g., in 63.6 ms) in multiple cells. We predict
that, as DRAM technology node size reduces, ColumnDisturb would worsen in
future DRAM chips, likely causing many more bitflips in the standard refresh
window. Second, ColumnDisturb induces bitflips in many (up to 198x) more rows
than retention failures. Therefore, ColumnDisturb has strong implications for
retention-aware refresh mechanisms that leverage the heterogeneity in cell
retention times: our detailed analyses show that ColumnDisturb greatly reduces
the benefits of such mechanisms.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [37] [PIShield: Detecting Prompt Injection Attacks via Intrinsic LLM Features](https://arxiv.org/abs/2510.14005)
*Wei Zou,Yupei Liu,Yanting Wang,Ying Chen,Neil Gong,Jinyuan Jia*

Main category: cs.CR

TL;DR: PIShield是一种高效且有效的提示注入攻击检测方法，通过在LLM特定层提取最终token的内部表示，并使用简单线性分类器区分干净和受污染的提示。


<details>
  <summary>Details</summary>
Motivation: 现有的提示注入检测方法存在性能不佳和计算开销高的问题，而LLM集成应用容易受到提示注入攻击，攻击者通过污染输入使LLM遵循攻击者意图而非用户意图。

Method: 提出PIShield方法，关键观察是LLM特定层（注入关键层）中最终token的内部表示能够捕获干净和受污染提示的区别特征，基于此训练简单线性分类器。

Result: 在5个基准数据集和8种提示注入攻击上与11个基线方法比较，PIShield在效果和效率上都显著优于现有方法，并能抵抗强自适应攻击。

Conclusion: PIShield是一种既高效又有效的提示注入检测解决方案，通过利用LLM内部表示的特征实现了优越的检测性能。

Abstract: LLM-integrated applications are vulnerable to prompt injection attacks, where
an attacker contaminates the input to inject malicious prompts, causing the LLM
to follow the attacker's intent instead of the original user's. Existing prompt
injection detection methods often have sub-optimal performance and/or high
computational overhead. In this work, we propose PIShield, a detection method
that is both effective and efficient. Our key observation is that the internal
representation of the final token in a prompt-extracted from a specific layer
of the LLM, which we term the injection-critical layer-captures distinguishing
features between clean and contaminated prompts. Leveraging this insight, we
train a simple linear classifier on these internal representations using a
labeled set of clean and contaminated prompts. We compare PIShield against 11
baselines across 5 diverse benchmark datasets and 8 prompt injection attacks.
The results demonstrate that PIShield is both highly effective and efficient,
substantially outperforming existing methods. Additionally, we show that
PIShield resists strong adaptive attacks.

</details>


### [38] [Every Language Model Has a Forgery-Resistant Signature](https://arxiv.org/abs/2510.14086)
*Matthew Finlayson,Xiang Ren,Swabha Swayamdipta*

Main category: cs.CR

TL;DR: 本文提出了一种基于语言模型输出几何约束的椭圆签名方法，用于识别语言模型的来源。该方法利用语言模型输出位于高维椭圆表面的几何特性作为模型签名，具有难以伪造、自然存在、自包含和紧凑冗余的特点。


<details>
  <summary>Details</summary>
Motivation: 随着闭源语言模型API的普及，需要开发能够提取隐藏模型细节和识别模型输出的取证方法。现有方法主要利用语言模型架构和参数施加的几何约束，但较少关注语言模型输出位于高维椭圆表面的几何特性。

Method: 提出椭圆签名方法，利用语言模型输出位于高维椭圆表面的几何约束作为模型签名。该方法通过从小模型中提取椭圆特征，并讨论了在生产规模模型中应用的实际障碍。

Result: 椭圆签名具有独特特性：难以伪造（无模型参数访问权限下无法生成椭圆上的对数概率）、自然存在（所有语言模型都具有这种椭圆约束）、自包含（无需模型输入或完整权重即可检测）和紧凑冗余（每个对数概率输出中都可独立检测）。

Conclusion: 椭圆签名可作为语言模型输出验证的有效方法，类似于密码学中的对称密钥消息认证系统，为语言模型输出溯源提供了新的技术途径。

Abstract: The ubiquity of closed-weight language models with public-facing APIs has
generated interest in forensic methods, both for extracting hidden model
details (e.g., parameters) and for identifying models by their outputs. One
successful approach to these goals has been to exploit the geometric
constraints imposed by the language model architecture and parameters. In this
work, we show that a lesser-known geometric constraint--namely, that language
model outputs lie on the surface of a high-dimensional ellipse--functions as a
signature for the model and can be used to identify the source model of a given
output. This ellipse signature has unique properties that distinguish it from
existing model-output association methods like language model fingerprints. In
particular, the signature is hard to forge: without direct access to model
parameters, it is practically infeasible to produce log-probabilities
(logprobs) on the ellipse. Secondly, the signature is naturally occurring,
since all language models have these elliptical constraints. Thirdly, the
signature is self-contained, in that it is detectable without access to the
model inputs or the full weights. Finally, the signature is compact and
redundant, as it is independently detectable in each logprob output from the
model. We evaluate a novel technique for extracting the ellipse from small
models and discuss the practical hurdles that make it infeasible for
production-scale models. Finally, we use ellipse signatures to propose a
protocol for language model output verification, analogous to cryptographic
symmetric-key message authentication systems.

</details>


### [39] [Infrastructure Patterns in Toll Scam Domains: A Comprehensive Analysis of Cybercriminal Registration and Hosting Strategies](https://arxiv.org/abs/2510.14198)
*Morium Akter Munny,Mahbub Alam,Sonjoy Kumar Paul,Daniel Timko,Muhammad Lutfor Rahman,Nitesh Saxena*

Main category: cs.CR

TL;DR: 本文首次对收费诈骗域名进行了大规模分析，揭示了攻击者利用宽松注册商和非主流顶级域名的策略，并构建了基于注册数据的预测模型来识别可能被暂停的诈骗域名。


<details>
  <summary>Details</summary>
Motivation: 收费诈骗通过注册伪装成合法交通机构的虚假域名来欺骗用户进行欺诈支付，这些诈骗正在迅速增加并造成重大损害，但尚未得到广泛研究。

Method: 使用新创建的67,907个确认诈骗域名数据集进行分析，研究攻击者利用宽松注册商和非主流顶级域名的模式，并构建基于域注册数据的预测模型。

Result: 发现86.9%的域名集中在五个非主流顶级域名，72.9%通过单一提供商注册，存在明显的注册模式和时间聚类。预测模型达到80.4%准确率和92.3%灵敏度。

Conclusion: 分析揭示了攻击者逃避检测的策略，可以为注册商、托管提供商和安全平台提供更有针对性的干预措施，但仅依靠注册元数据可能不足，需要结合URL和网页内容特征来改进检测。

Abstract: Toll scams involve criminals registering fake domains that pretend to be
legitimate transportation agencies to trick users into making fraudulent
payments. Although these scams are rapidly increasing and causing significant
harm, they have not been extensively studied. We present the first large-scale
analysis of toll scam domains, using a newly created dataset of 67,907
confirmed scam domains mostly registered in 2025. Our study reveals that
attackers exploit permissive registrars and less common top-level domains, with
86.9% of domains concentrated in just five non-mainstream TLDs and 72.9%
registered via a single provider. We also discover specific registration
patterns, including short bursts of activity that suggest automated,
coordinated attacks, with over half of domains registered in the first quarter
of 2025. This extreme temporal clustering reflects highly synchronized campaign
launches. Additionally, we build a simple predictive model using only domain
registration data to predict which scam domains are likely to be suspended -- a
proxy for confirmed abuse -- achieving 80.4% accuracy, and 92.3% sensitivity.
Our analysis reveals attacker strategies for evading detection -- such as
exploiting obscure TLDs, permissive registrars, and coordinated registration
bursts -- which can inform more targeted interventions by registrars, hosting
providers, and security platforms. However, our results suggest that
registration metadata alone may be insufficient, and incorporating features
from domain URLs and webpage content could further improve detection.

</details>


### [40] [Beyond a Single Perspective: Towards a Realistic Evaluation of Website Fingerprinting Attacks](https://arxiv.org/abs/2510.14283)
*Xinhao Deng,Jingyou Chen,Linxiao Yu,Yixiang Zhang,Zhongyi Gu,Changhao Qiu,Xiyuan Zhao,Ke Xu,Qi Li*

Main category: cs.CR

TL;DR: 本文首次系统评估了网站指纹识别攻击在多种现实条件下的表现，发现许多在孤立环境中表现良好的技术在面对防御机制、流量漂移、多标签浏览等复杂情况时性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 当前网站指纹识别攻击研究大多局限于单一场景，忽略了现实环境的复杂性，需要系统评估这些技术在多样化现实条件下的实际表现。

Method: 采用多维评估框架，在包括防御机制、流量漂移、多标签浏览、早期检测、开放世界和少样本场景等多种现实条件下测试现有WF攻击技术。

Result: 实验结果显示，许多在孤立设置中表现优异的WF技术在面对其他条件时性能显著下降，由于现实环境往往结合多种挑战，当前WF攻击难以直接应用于实践。

Conclusion: 本研究揭示了WF攻击的局限性，并提出了多维评估框架，为开发更稳健和实用的WF攻击提供了重要见解。

Abstract: Website Fingerprinting (WF) attacks exploit patterns in encrypted traffic to
infer the websites visited by users, posing a serious threat to anonymous
communication systems. Although recent WF techniques achieve over 90% accuracy
in controlled experimental settings, most studies remain confined to single
scenarios, overlooking the complexity of real-world environments. This paper
presents the first systematic and comprehensive evaluation of existing WF
attacks under diverse realistic conditions, including defense mechanisms,
traffic drift, multi-tab browsing, early-stage detection, open-world settings,
and few-shot scenarios. Experimental results show that many WF techniques with
strong performance in isolated settings degrade significantly when facing other
conditions. Since real-world environments often combine multiple challenges,
current WF attacks are difficult to apply directly in practice. This study
highlights the limitations of WF attacks and introduces a multidimensional
evaluation framework, offering critical insights for developing more robust and
practical WF attacks.

</details>


### [41] [BinCtx: Multi-Modal Representation Learning for Robust Android App Behavior Detection](https://arxiv.org/abs/2510.14344)
*Zichen Liu,Shao Yang,Xusheng Xiao*

Main category: cs.CR

TL;DR: BINCTX是一种多模态学习方法，通过结合字节码图像视图、上下文视图和第三方库使用视图来检测移动应用中的不良行为，在真实恶意软件检测中达到94.73%的F1分数，对混淆和对抗样本具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 移动应用市场中存在大量不良行为（如干扰性广告、非法重定向、支付欺骗），这些行为通常不依赖权限保护的API，且容易通过UI或元数据编辑进行伪装，难以检测。

Method: 构建应用的多模态表示：1）全局字节码图像视图捕捉代码语义和家族模式；2）上下文视图（清单操作、组件、声明权限、URL/IP常量）显示行为触发方式；3）第三方库使用视图总结组件间调用路径的调用频率。三个视图嵌入并融合以训练上下文感知分类器。

Result: 在真实恶意软件和良性应用上，BINCTX达到94.73%的宏F1分数，比强基线至少高出14.92%。在商业混淆后仍保持84%的F1分数，比最先进的仅字节码系统更能抵抗对抗样本。

Conclusion: BINCTX通过多模态表示有效检测移动应用中的不良行为，对混淆和对抗攻击具有鲁棒性，显著优于现有方法。

Abstract: Mobile app markets host millions of apps, yet undesired behaviors (e.g.,
disruptive ads, illegal redirection, payment deception) remain hard to catch
because they often do not rely on permission-protected APIs and can be easily
camouflaged via UI or metadata edits. We present BINCTX, a learning approach
that builds multi-modal representations of an app from (i) a global
bytecode-as-image view that captures code-level semantics and family-style
patterns, (ii) a contextual view (manifested actions, components, declared
permissions, URL/IP constants) indicating how behaviors are triggered, and
(iii) a third-party-library usage view summarizing invocation frequencies along
inter-component call paths. The three views are embedded and fused to train a
contextual-aware classifier. On real-world malware and benign apps, BINCTX
attains a macro F1 of 94.73%, outperforming strong baselines by at least
14.92%. It remains robust under commercial obfuscation (F1 84%
post-obfuscation) and is more resistant to adversarial samples than
state-of-the-art bytecode-only systems.

</details>


### [42] [Match & Mend: Minimally Invasive Local Reassembly for Patching N-day Vulnerabilities in ARM Binaries](https://arxiv.org/abs/2510.14384)
*Sebastian Jänich,Merlin Sievers,Johannes Kinder*

Main category: cs.CR

TL;DR: 提出了一种名为最小侵入性本地重汇编的技术，用于在二进制级别自动修补IoT固件中的已知漏洞，无需厂商支持。


<details>
  <summary>Details</summary>
Motivation: 低成本IoT设备由于更新机制不完善而存在安全隐患，许多设备运行着过时且已知存在漏洞的开源软件版本。

Method: 采用最小侵入性本地重汇编技术，在二进制级别自动修补已知漏洞，旨在最小化副作用并降低引入破坏性变更的风险。

Result: 在MAGMA基准测试的108个二进制文件中成功修补83%的目标漏洞，在KARONTE数据集的30个真实世界Linux IoT固件中成功修补96%的漏洞。

Conclusion: 该方法能够有效自动修补IoT固件中的已知漏洞，为缺乏厂商支持的IoT设备提供了可行的安全更新方案。

Abstract: Low-cost Internet of Things (IoT) devices are increasingly popular but often
insecure due to poor update regimes. As a result, many devices run outdated and
known-vulnerable versions of open-source software. We address this problem by
proposing to patch IoT firmware at the binary level, without requiring vendor
support. In particular, we introduce minimally invasive local reassembly, a new
technique for automatically patching known (n-day) vulnerabilities in IoT
firmware. Our approach is designed to minimize side effects and reduce the risk
of introducing breaking changes. We systematically evaluate our approach both
on 108 binaries within the controlled environment of the MAGMA benchmarks, as
well as on 30 real-world Linux-based IoT firmware images from the KARONTE
dataset. Our prototype successfully patches 83% of targeted vulnerabilities in
MAGMA and 96% in the firmware dataset.

</details>


### [43] [Certifying optimal MEV strategies with Lean](https://arxiv.org/abs/2510.14480)
*Massimo Bartoletti,Riccardo Marchesin,Roberto Zunino*

Main category: cs.CR

TL;DR: 本文首次在Lean定理证明器中机械化形式化了MEV（最大可提取价值），提出了一种构建机器检查证明的方法来验证MEV上界，并证明了自动化做市商中三明治攻击的最优性。


<details>
  <summary>Details</summary>
Motivation: MEV攻击已从去中心化应用中提取了数十亿美元的价值，对区块链安全产生了系统性影响。验证MEV攻击的缺失需要确定合适的上界，但这个问题非常困难，因为对抗策略空间极其庞大，经验研究和手工推理不够严谨。

Method: 在Lean定理证明器中机械化形式化MEV，引入构建机器检查证明的方法论，为两个典型的DeFi协议建模和分析MEV。

Result: 开发了第一个机器检查证明，证明了自动化做市商中三明治攻击的最优性，为MEV界限提供了现有技术无法实现的正确性保证。

Conclusion: 该方法为MEV分析提供了严格的数学基础，能够超越现有技术的限制，为DeFi协议的安全性提供更强的保证。

Abstract: Maximal Extractable Value (MEV) refers to a class of attacks to decentralized
applications where the adversary profits by manipulating the ordering,
inclusion, or exclusion of transactions in a blockchain. Decentralized Finance
(DeFi) protocols are a primary target of these attacks, as their logic depends
critically on transaction sequencing. To date, MEV attacks have already
extracted billions of dollars in value, underscoring their systemic impact on
blockchain security. Verifying the absence of MEV attacks requires determining
suitable upper bounds, i.e. proving that no adversarial strategy can extract
more value (if any) than expected by protocol designers. This problem is
notoriously difficult: the space of adversarial strategies is extremely vast,
making empirical studies and pen-and-paper reasoning insufficiently rigorous.
In this paper, we present the first mechanized formalization of MEV in the Lean
theorem prover. We introduce a methodology to construct machine-checked proofs
of MEV bounds, providing correctness guarantees beyond what is possible with
existing techniques. To demonstrate the generality of our approach, we model
and analyse the MEV of two paradigmatic DeFi protocols. Notably, we develop the
first machine-checked proof of the optimality of sandwich attacks in Automated
Market Makers, a fundamental DeFi primitive.

</details>


### [44] [Lexo: Eliminating Stealthy Supply-Chain Attacks via LLM-Assisted Program Regeneration](https://arxiv.org/abs/2510.14522)
*Evangelos Lamprou,Julian Dai,Grigoris Ntousakis,Martin C. Rinard,Nikos Vasilakis*

Main category: cs.CR

TL;DR: Lexo是一个自动学习和重新生成无漏洞版本的潜在恶意组件的系统，用于防御软件供应链攻击。它通过生成输入-输出对来建模组件行为，然后合成新版本组件，保持原有功能但避免恶意行为。


<details>
  <summary>Details</summary>
Motivation: 开源软件生态系统中的软件供应链攻击是一个持续关注的重要问题，这些攻击在保持组件标准功能的同时隐藏恶意功能，仅在目标环境中激活。

Method: Lexo首先生成一组输入-输出对来建模组件的完整可观察行为，然后使用这些数据合成原始组件的新版本。在整个重新生成过程中，Lexo咨询多个不同的大型语言模型实例，使用正确性和覆盖率指标来指导这些实例，并保护其结果。

Result: 在100多个真实世界软件包（包括高知名度的隐蔽供应链攻击）上的评估表明，Lexo能够跨多个领域扩展，平均在100秒内高效重新生成代码，保持兼容性，并成功消除了几个真实世界供应链攻击中的恶意代码，即使在最先进的LLM提示消除恶意代码失败的情况下也能成功。

Conclusion: Lexo提供了一种有效的方法来防御隐蔽的软件供应链攻击，通过自动重新生成无恶意代码的组件版本，在保持功能兼容性的同时提高软件安全性。

Abstract: Software supply-chain attacks are an important and ongoing concern in the
open source software ecosystem. These attacks maintain the standard
functionality that a component implements, but additionally hide malicious
functionality activated only when the component reaches its target environment.
Lexo addresses such stealthy attacks by automatically learning and regenerating
vulnerability-free versions of potentially malicious components. Lexo first
generates a set of input-output pairs to model a component's full observable
behavior, which it then uses to synthesize a new version of the original
component. The new component implements the original functionality but avoids
stealthy malicious behavior. Throughout this regeneration process, Lexo
consults several distinct instances of Large Language Models (LLMs), uses
correctness and coverage metrics to shepherd these instances, and guardrails
their results. Our evaluation on 100+ real-world packages, including high
profile stealthy supply-chain attacks, indicates that Lexo scales across
multiple domains, regenerates code efficiently (<100s on average), maintains
compatibility, and succeeds in eliminating malicious code in several real-world
supply-chain-attacks, even in cases when a state-of-the-art LLM fails to
eliminate malicious code when prompted to do so.

</details>


### [45] [Symbolic verification of Apple's Find My location-tracking protocol](https://arxiv.org/abs/2510.14589)
*Vaishnavi Sundararajan,Rithwik*

Main category: cs.CR

TL;DR: 本文对苹果Find My追踪系统进行了形式化安全分析，通过符号建模和自动验证证明了该协议的安全性属性。


<details>
  <summary>Details</summary>
Motivation: 苹果Find My系统虽然声称安全私密，但其代码是专有的，用户只能相信其声明。即使有完美的密码学保证，协议中仍可能存在逻辑漏洞，因此需要独立验证其安全性。

Method: 使用符号模型对Find My协议进行建模，制定精确的形式化规范描述期望的安全属性，并在Tamarin证明器中提供自动化的机器可检查证明。

Result: 通过形式化验证，提供了Find My协议安全属性的机器可检查证明，确认了协议满足所期望的安全特性。

Conclusion: 研究表明Find My协议在形式化验证下满足安全要求，为这类广泛部署的追踪系统的安全性提供了独立验证。

Abstract: Tracking devices, while designed to help users find their belongings in case
of loss/theft, bring in new questions about privacy and surveillance of not
just their own users, but in the case of crowd-sourced location tracking, even
that of others even orthogonally associated with these platforms. Apple's Find
My is perhaps the most ubiquitous such system which can even locate devices
which do not possess any cellular support or GPS, running on millions of
devices worldwide. Apple claims that this system is private and secure, but the
code is proprietary, and such claims have to be taken on faith. It is well
known that even with perfect cryptographic guarantees, logical flaws might
creep into protocols, and allow undesirable attacks. In this paper, we present
a symbolic model of the Find My protocol, as well as a precise formal
specification of desirable properties, and provide automated, machine-checkable
proofs of these properties in the Tamarin prover.

</details>


### [46] [AEX-NStep: Probabilistic Interrupt Counting Attacks on Intel SGX](https://arxiv.org/abs/2510.14675)
*Nicolas Dutly,Friederike Groschupp,Ivan Puddu,Kari Kostiainen,Srdjan Capkun*

Main category: cs.CR

TL;DR: AEX-NStep是首个针对启用AEX-Notify的Enclaves的中断计数攻击，证明AEX-Notify无法完全防止此类攻击，并成功实施ECDSA密钥泄露攻击。


<details>
  <summary>Details</summary>
Motivation: Intel引入AEX-Notify ISA扩展来防止基于中断的单步攻击（如SGX-Step），但该研究旨在验证AEX-Notify是否真正能够防止中断计数攻击。

Method: 开发了AEX-NStep攻击方法，包括两种新的概率性中断计数攻击，证明确定性单步不是中断计数攻击的必要条件。

Result: 成功攻破了AEX-Notify的安全保证之一（混淆的前向进度），并构建了实用的ECDSA密钥泄露攻击，证明AEX-Notify无法完全防止中断计数攻击。

Conclusion: AEX-Notify不能完全防止中断计数攻击，研究结果扩展了AEX-Notify的安全分析，为未来缓解措施的设计提供了参考。

Abstract: To mitigate interrupt-based stepping attacks (notably using SGX-Step), Intel
introduced AEX-Notify, an ISA extension to Intel SGX that aims to prevent
deterministic single-stepping. In this work, we introduce AEX-NStep, the first
interrupt counting attack on AEX-Notify-enabled Enclaves. We show that
deterministic single-stepping is not required for interrupt counting attacks to
be practical and that, therefore, AEX-Notify does not entirely prevent such
attacks. We specifically show that one of AEX-Notify's security guarantees,
obfuscated forward progress, does not hold, and we introduce two new
probabilistic interrupt counting attacks. We use these attacks to construct a
practical ECDSA key leakage attack on an AEX-Notify-enabled SGX enclave. Our
results extend the original security analysis of AEX-Notify and inform the
design of future mitigations.

</details>


### [47] [FibRace: a large-scale benchmark of client-side proving on mobile devices](https://arxiv.org/abs/2510.14693)
*Simon Malatrait,Alex Sirac*

Main category: cs.CR

TL;DR: FibRace是首个在智能手机上使用Cairo M进行客户端证明生成的大规模实验，通过移动游戏形式让玩家证明斐波那契数并参与排行榜竞争。实验结果显示现代智能手机能在5秒内完成证明，确认移动设备已能可靠生成零知识证明。


<details>
  <summary>Details</summary>
Motivation: 测试智能手机客户端证明生成的可行性，为公众提供参与机会，并为移动设备证明性能提供实证基准数据。

Method: 开发移动游戏FibRace，让玩家在智能手机上使用Cairo M生成斐波那契数证明，收集6047名玩家在1420种不同设备模型上生成的2195488个证明数据。

Result: 大多数现代智能手机能在5秒内完成证明，性能主要与RAM容量和SoC性能相关，至少3GB RAM的设备能稳定证明，苹果A19 Pro和M系列芯片证明速度最快。Hyli区块链原生验证所有证明且无拥堵。

Conclusion: 移动设备现已能够可靠生成零知识证明，无需远程证明器或专用硬件。FibRace提供了迄今为止最全面的移动证明性能数据集，为轻量级证明器、证明驱动基础设施和隐私保护移动应用建立了实践基准。

Abstract: FibRace, jointly developed by KKRT Labs and Hyli, was the first large-scale
experiment to test client-side proof generation on smartphones using Cairo M.
Presented as a mobile game in which players proved Fibonacci numbers and
climbed a leaderboard, FibRace served a dual purpose: to engage the public and
to provide empirical benchmarking. Over a three-week campaign (September 11-30,
2025), 6,047 players across 99 countries generated 2,195,488 proofs on 1,420
unique device models. The results show that most modern smartphones can
complete a proof in under 5 seconds, confirming that *mobile devices are now
capable of producing zero-knowledge proofs reliably*, without the need for
remote provers or specialized hardware. Performance was correlated primarily
with RAM capacity and SoC (System on Chip) performance: devices with at least 3
GB of RAM proved stably, when Apple's A19 Pro and M-series chips achieved the
fastest proving times. Hyli's blockchain natively verified every proof onchain
without congestion. FibRace provides the most comprehensive dataset to date on
mobile proving performance, establishing a practical baseline for future
research in lightweight provers, proof-powered infrastructure, and
privacy-preserving mobile applications.

</details>


### [48] [SLIE: A Secure and Lightweight Cryptosystem for Data Sharing in IoT Healthcare Services](https://arxiv.org/abs/2510.14708)
*Ha Xuan Son,Nguyen Quoc Anh,Phat T. Tran-Truong,Le Thanh Tuan,Pham Thanh Nghiem*

Main category: cs.CR

TL;DR: 本文提出SLIE（安全轻量级身份加密）方案，基于WKD-IBE密码系统，为IoMT医疗设备提供端到端加密、分层访问控制和轻量级密钥管理，显著提升安全性和性能。


<details>
  <summary>Details</summary>
Motivation: IoMT医疗物联网的服务化模式在设备管理和通信中引入了严重的安全漏洞，特别是医疗数据的敏感性使得这些风险尤为关键。

Method: 采用基于通配符密钥派生身份加密（WKD-IBE）的新型密码系统，结合恒定时间操作、内存混淆和基于过期的密钥撤销机制。

Result: SLIE显著优于RSA，1KB数据的加密时间0.936ms，解密时间0.217ms，加密速度提升84.54%，解密速度提升99.70%，能效为0.014 J/KB。

Conclusion: SLIE为资源受限的IoMT设备提供了可扩展的信任机制和安全的全向通信，能够抵御旁路攻击、中间人攻击和未授权访问，确保符合HIPAA和GDPR标准。

Abstract: The Internet of Medical Things (IoMT) has revolutionized healthcare by
transforming medical operations into standardized, interoperable services.
However, this service-oriented model introduces significant security
vulnerabilities in device management and communication, which are especially
critical given the sensitivity of medical data. To address these risks, this
paper proposes SLIE (Secure and Lightweight Identity Encryption), a novel
cryptosystem based on Wildcard Key Derivation Identity-Based Encryption
(WKD-IBE). SLIE ensures scalable trust and secure omnidirectional communication
through end-to-end encryption, hierarchical access control, and a lightweight
key management system designed for resource-constrained devices. It
incorporates constant-time operations, memory obfuscation, and expiry-based key
revocation to counter side-channel, man-in-the-middle, and unauthorized access
attacks, thereby ensuring compliance with standards like HIPAA and GDPR.
Evaluations show that SLIE significantly outperforms RSA, with encryption and
decryption times of 0.936ms and 0.217ms for 1KB of data, an 84.54% improvement
in encryption speed, a 99.70% improvement in decryption speed, and an energy
efficiency of 0.014 J/KB.

</details>


### [49] [Secure Sparse Matrix Multiplications and their Applications to Privacy-Preserving Machine Learning](https://arxiv.org/abs/2510.14894)
*Marc Damie,Florian Hahn,Andreas Peter,Jan Ramon*

Main category: cs.CR

TL;DR: 本文提出了针对稀疏数据的多方计算（MPC）算法，专门用于秘密稀疏矩阵的乘法运算，解决了现有MPC框架在处理高维稀疏数据时的内存和通信效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有MPC框架未针对稀疏数据进行优化，无法有效处理涉及稀疏数据的机器学习应用（如推荐系统、基因组学），因为这些应用中的高维稀疏数据在明文状态下就需要稀疏优化来避免内存问题。

Method: 提出了秘密稀疏矩阵乘法的MPC算法，避免经典安全矩阵乘法算法的密集数据表示带来的内存问题，同时显著降低通信成本。还提出了一种基于非零元素分布的安全上界方法。

Result: 实验显示通信成本显著降低（某些实验显示1000倍），在现有协议不实用的两个ML应用中验证了算法的有效性。

Conclusion: 提出的MPC稀疏矩阵乘法算法解决了稀疏数据处理中的内存和通信瓶颈，为涉及稀疏数据的隐私保护机器学习应用提供了实用解决方案。

Abstract: To preserve privacy, multi-party computation (MPC) enables executing Machine
Learning (ML) algorithms on secret-shared or encrypted data. However, existing
MPC frameworks are not optimized for sparse data. This makes them unsuitable
for ML applications involving sparse data, e.g., recommender systems or
genomics. Even in plaintext, such applications involve high-dimensional sparse
data, that cannot be processed without sparsity-related optimizations due to
prohibitively large memory requirements.
  Since matrix multiplication is central in ML algorithms, we propose MPC
algorithms to multiply secret sparse matrices. On the one hand, our algorithms
avoid the memory issues of the "dense" data representation of classic secure
matrix multiplication algorithms. On the other hand, our algorithms can
significantly reduce communication costs (some experiments show a factor 1000)
for realistic problem sizes. We validate our algorithms in two ML applications
in which existing protocols are impractical.
  An important question when developing MPC algorithms is what assumptions can
be made. In our case, if the number of non-zeros in a row is a sensitive piece
of information then a short runtime may reveal that the number of non-zeros is
small. Existing approaches make relatively simple assumptions, e.g., that there
is a universal upper bound to the number of non-zeros in a row. This often
doesn't align with statistical reality, in a lot of sparse datasets the amount
of data per instance satisfies a power law. We propose an approach which allows
adopting a safe upper bound on the distribution of non-zeros in rows/columns of
sparse matrices.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [50] [Efficiently Executing High-throughput Lightweight LLM Inference Applications on Heterogeneous Opportunistic GPU Clusters with Pervasive Context Management](https://arxiv.org/abs/2510.14024)
*Thanh Son Phung,Douglas Thain*

Main category: cs.DC

TL;DR: 提出了一种名为"Pervasive Context Management"的技术，通过将LLM初始化上下文与推理解耦并保留在GPU中，解决了HPC集群中生成式AI工作负载面临的长时间等待和高启动成本问题。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在HPC集群中的集成面临两个主要问题：在静态批处理队列中长时间等待，以及资源抢占时重复支付昂贵的LLM启动成本。

Method: 将LLM初始化上下文与实际的LLM推理解耦，并在GPU中保留上下文直到不再需要，这一技术称为"Pervasive Context Management"。

Result: 在事实验证应用中，使用相同数量的GPU将执行时间减少了72.1%（从3小时降至48分钟），并能在集群中32.8%的GPU上机会性地扩展，进一步将执行时间降至13分钟。

Conclusion: Pervasive Context Management技术有效解决了HPC集群中生成式AI工作负载的调度和成本问题，显著提升了执行效率。

Abstract: The rise of Generative AI introduces a new class of HPC workloads that
integrates lightweight LLMs with traditional high-throughput applications to
accelerate scientific discovery. The current design of HPC clusters is
inadequate to support this new class however, either incurring long wait times
on static batch queues or repeatedly paying expensive LLM startup costs upon
resource preemption. To circumvent both the long queues and high startup costs,
we propose to "decouple" the LLM initialization context from the actual LLM
inferences, and retain the context in GPUs until it is no longer needed, a
technique we term "Pervasive Context Management". We transform a fact
verification application to enable this technique, allowing it to reduce its
execution time by 72.1% (from 3 hours to 48 minutes) using the same amount of
GPUs, and scale opportunistically on 32.8% of all GPUs in the cluster and
further reduce the execution time to 13 minutes.

</details>


### [51] [Cortex: Workflow-Aware Resource Pooling and Scheduling for Agentic Serving](https://arxiv.org/abs/2510.14126)
*Nikos Pagonas,Yeounoh Chung,Kostis Kaffes,Arvind Krishnamurthy*

Main category: cs.DC

TL;DR: Cortex是一个面向智能体工作负载的原型工作流感知服务平台，通过阶段隔离策略为智能体工作流的每个不同阶段分配专用资源池，从而提高性能表现。


<details>
  <summary>Details</summary>
Motivation: 解决智能体工作流中不同阶段之间的计算和内存干扰问题，改善KV缓存利用率、提升吞吐量并实现更可预测的性能表现。

Method: 采用阶段隔离原则，为智能体工作流的每个不同阶段配置专用资源池，通过定制化资源分配和调度来优化性能。

Result: 通过阶段隔离策略有效减轻了阶段间干扰，实现了更好的KV缓存利用、更高吞吐量和更可预测的性能。

Conclusion: Cortex为更先进的智能体原生服务范式奠定了基础，包括可塑性资源管理、工作流分支的推测执行以及智能体状态的共享多级缓存。

Abstract: We introduce Cortex, a prototype workflow-aware serving platform designed for
agentic workloads. The core principle of Cortex is stage isolation: it
provisions dedicated resource pools for each distinct stage of an agentic
workflow. This simple yet powerful strategy mitigates inter-stage interference
in compute and memory, leading to better KV cache utilization, higher
throughput, and more predictable performance. By customizing resource
allocation and scheduling within each distinct stage of agentic workflows,
Cortex lays the groundwork for more advanced, agent-native serving paradigms,
including malleable resource management, speculative execution of workflow
branches, and a shared, multi-tiered cache for "agentic state."

</details>


### [52] [Distributed-Memory Parallel Algorithms for Fixed-Radius Near Neighbor Graph Construction](https://arxiv.org/abs/2510.14147)
*Gabriel Raulet,Dmitriy Morozov,Aydin Buluc,Katherine Yelick*

Main category: cs.DC

TL;DR: 提出了一种可扩展的分布式内存算法，使用覆盖树计算一般度量空间中的近邻图，在真实世界高维数据集上实现了高达1590.99倍的加速。


<details>
  <summary>Details</summary>
Motivation: 随着计算能力和数据采集方法的发展，大型科学数据集需要可扩展的精确近邻图计算解决方案，特别是对于非欧几里得度量空间。

Method: 开发了共享内存的覆盖树构建算法，并引入了两种分布式内存算法：简单的点分区策略和空间分区策略，在节点上利用覆盖树算法。

Result: 在真实世界高维数据集上，使用1024核心对平均70邻居的图实现了678.34倍加速，使用4096核心对平均500邻居的图实现了1590.99倍加速。

Conclusion: 该算法在各种真实和合成数据集上展现出并行扩展性，为传统和非传统度量空间提供了高效的近邻图计算解决方案。

Abstract: Computing fixed-radius near-neighbor graphs is an important first step for
many data analysis algorithms. Near-neighbor graphs connect points that are
close under some metric, endowing point clouds with a combinatorial structure.
As computing power and data acquisition methods advance, diverse sources of
large scientific datasets would greatly benefit from scalable solutions to this
common subroutine for downstream analysis. Prior work on parallel nearest
neighbors has made great progress in problems like k-nearest and approximate
nearest neighbor search problems, with particular attention on Euclidean
spaces. Yet many applications need exact solutions and non-Euclidean metrics.
This paper presents a scalable sparsity-aware distributed memory algorithm
using cover trees to compute near-neighbor graphs in general metric spaces. We
provide a shared-memory algorithm for cover tree construction and demonstrate
its competitiveness with state-of-the-art fixed-radius search data structures.
We then introduce two distributed-memory algorithms for the near-neighbor graph
problem, a simple point-partitioning strategy and a spatial-partitioning
strategy, which leverage the cover tree algorithm on each node. Our algorithms
exhibit parallel scaling across a variety of real and synthetic datasets for
both traditional and non-traditional metrics. On real world high dimensional
datasets with one million points, we achieve speedups up to 678.34x over the
state-of-the-art using 1024 cores for graphs with 70 neighbors per vertex (on
average), and up to 1590.99x using 4096 cores for graphs with 500 neighbors per
vertex (on average).

</details>


### [53] [Proof-Carrying Fair Ordering: Asymmetric Verification for BFT via Incremental Graphs](https://arxiv.org/abs/2510.14186)
*Pengkun Ren,Hai Dong,Nasrin Sohrabi,Zahir Tari,Pengcheng Zhang*

Main category: cs.DC

TL;DR: AUTIG是一个高性能、可插拔的公平排序服务，通过非对称架构解决BFT共识中对称冗余的公平排序验证问题。它让领导者维护增量图并生成公平性证明，跟随者只需验证证明而无需重新计算排序。


<details>
  <summary>Details</summary>
Motivation: 现有的公平排序共识协议（如Themis）要求每个副本重新运行领导者昂贵的排序计算进行验证，这种对称冗余范式效率低下。AUTIG旨在打破这种对称性，提高性能。

Method: 采用非对称架构：领导者维护持久化的未确认交易增量图（UTIG）并生成结构化公平性证明；跟随者验证证明而无需维护历史状态。关键创新包括增量图维护、解耦流水线和覆盖内部对及边界完整性的证明设计。

Result: 实验表明，在部分同步条件下，AUTIG相比对称图基线具有更高的吞吐量和更低的端到端延迟，同时保持gamma-batch-order-fairness保证。

Conclusion: AUTIG通过将公平排序验证简化为对排序图属性的无状态审计，成功打破了对称冗余范式，实现了高性能的公平排序服务。

Abstract: Byzantine Fault-Tolerant (BFT) consensus protocols ensure agreement on
transaction ordering despite malicious actors, but unconstrained ordering power
enables sophisticated value extraction attacks like front running and sandwich
attacks - a critical threat to blockchain systems. Order-fair consensus curbs
adversarial value extraction by constraining how leaders may order
transactions. While state-of-the-art protocols such as Themis attain strong
guarantees through graph-based ordering, they ask every replica to re-run the
leader's expensive ordering computation for validation - an inherently
symmetric and redundant paradigm. We present AUTIG, a high-performance,
pluggable order-fairness service that breaks this symmetry. Our key insight is
that verifying a fair order does not require re-computing it. Instead,
verification can be reduced to a stateless audit of succinct, verifiable
assertions about the ordering graph's properties. AUTIG realizes this via an
asymmetric architecture: the leader maintains a persistent
Unconfirmed-Transaction Incremental Graph (UTIG) to amortize graph construction
across rounds and emits a structured proof of fairness with each proposal;
followers validate the proof without maintaining historical state. AUTIG
introduces three critical innovations: (i) incremental graph maintenance driven
by threshold-crossing events and state changes; (ii) a decoupled pipeline that
overlaps leader-side collection/update/extraction with follower-side stateless
verification; and (iii) a proof design covering all internal pairs in the
finalized prefix plus a frontier completeness check to rule out hidden external
dependencies. We implement AUTIG and evaluate it against symmetric graph-based
baselines under partial synchrony. Experiments show higher throughput and lower
end-to-end latency while preserving gamma-batch-order-fairness.

</details>


### [54] [JASDA: Introducing Job-Aware Scheduling in Scheduler-Driven Job Atomization](https://arxiv.org/abs/2510.14599)
*Michal Konopa,Jan Fesl,Ladislav Ber ánek*

Main category: cs.DC

TL;DR: JASDA是一个基于拍卖理论和在线优化的去中心化GPU调度框架，通过双向迭代交互实现自适应资源管理，适用于MIG-enabled GPU环境。


<details>
  <summary>Details</summary>
Motivation: 传统集中式调度在MIG-enabled GPU上难以应对工作负载的复杂性和时变性，需要更可扩展的调度方案。

Method: 扩展SJA概念，采用去中心化协商过程：作业主动生成和评分可行子作业，调度器执行策略驱动的清算，平衡利用率、公平性和时间响应性。

Result: 通过嵌入反馈、校准和概率安全性的双向迭代交互，实现自适应和透明的决策制定。

Conclusion: JASDA为市场感知和公平驱动的资源管理提供了可扩展基础，连接理论调度模型与现代MIG-enabled环境的实际部署。

Abstract: The increasing complexity and temporal variability of workloads on
MIG-enabled GPUs challenge the scalability of traditional centralized
scheduling. Building upon the SJA concept, this paper introduces JASDA-a novel
paradigm that extends SJA from a largely centralized scheduling model toward a
fully decentralized negotiation process. In JASDA, jobs actively generate and
score feasible subjobs in response to scheduler-announced execution windows,
while the scheduler performs policy-driven clearing that balances utilization,
fairness, and temporal responsiveness. This bidirectional, iterative
interaction embeds feedback, calibration, and probabilistic safety directly
into the scheduling loop, enabling adaptive and transparent decision-making. By
coupling principles from auction theory and online optimization with the
temporal granularity of GPU workloads, JASDA provides a scalable foundation for
market-aware and fairness-driven resource management-bridging theoretical
scheduling models with practical deployment in modern MIG-enabled environments
relevant to Artificial Intelligence and Agriculture 4.0.

</details>


### [55] [MPI-over-CXL: Enhancing Communication Efficiency in Distributed HPC Systems](https://arxiv.org/abs/2510.14622)
*Miryeong Kwon,Donghyun Gouk,Hyein Woo,Junhee Kim,Jinwoo Baek,Kyungkuk Nam,Sangyoon Ji,Jiseon Kim,Hanyeoreum Bae,Junhyeok Jang,Hyunwoo You,Junseok Moon,Myoungsoo Jung*

Main category: cs.DC

TL;DR: MPI-over-CXL是一种利用CXL技术的新型MPI通信范式，通过共享内存访问替代传统数据复制操作，显著降低通信延迟和内存带宽使用。


<details>
  <summary>Details</summary>
Motivation: 传统MPI实现依赖显式内存复制操作，导致冗余数据移动和缓冲区管理开销，严重影响高性能计算工作负载中的处理器间通信效率。

Method: 利用CXL提供的跨多主机缓存一致性共享内存，将共享内存区域直接映射到MPI进程的虚拟地址空间，实现基于指针的高效通信，消除冗余复制操作。

Result: 使用代表性基准测试进行评估，相比传统MPI系统显示出显著的性能提升。

Conclusion: MPI-over-CXL有潜力在大规模HPC环境中提高效率和可扩展性。

Abstract: MPI implementations commonly rely on explicit memory-copy operations,
incurring overhead from redundant data movement and buffer management. This
overhead notably impacts HPC workloads involving intensive inter-processor
communication. In response, we introduce MPI-over-CXL, a novel MPI
communication paradigm leveraging CXL, which provides cache-coherent shared
memory across multiple hosts. MPI-over-CXL replaces traditional data-copy
methods with direct shared memory access, significantly reducing communication
latency and memory bandwidth usage. By mapping shared memory regions directly
into the virtual address spaces of MPI processes, our design enables efficient
pointer-based communication, eliminating redundant copying operations. To
validate this approach, we implement a comprehensive hardware and software
environment, including a custom CXL 3.2 controller, FPGA-based multi-host
emulation, and dedicated software stack. Our evaluations using representative
benchmarks demonstrate substantial performance improvements over conventional
MPI systems, underscoring MPI-over-CXL's potential to enhance efficiency and
scalability in large-scale HPC environments.

</details>


### [56] [xLLM Technical Report](https://arxiv.org/abs/2510.14686)
*Tongxuan Liu,Tao Peng,Peijun Yang,Xiaoyang Zhao,Xiusheng Lu,Weizhe Huang,Zirui Liu,Xiaoyu Chen,Zhiwei Liang,Jun Xiong,Donghe Jin,Minchao Zhang,Jinrong Guo,Yingxu Deng,Xu Zhang,Xianzhe Dong,Siqi Wang,Siyu Wu,Yu Wu,Zihan Tang,Yuting Zeng,Yanshu Wang,Jinguang Liu,Meng Kang,Menxin Li,Yunlong Wang,Yiming Liu,Xiaolong Ma,Yifan Wang,Yichen Zhang,Jinrun Yin,Keyang Zheng,Jiawei Yin,Jun Zhang,Ziyue Wang,Xiaobo Lin,Liangyu Liu,Liwei Lan,Yang Liu,Chunhua Peng,Han Liu,Songcheng Ren,Xuezhu Wang,Yunheng Shen,Yi Wang,Guyue Liu,Hui Chen,Tong Yang,Hailong Yang,Jing Li,Guiguang Ding,Ke Zhang*

Main category: cs.DC

TL;DR: xLLM是一个高效的大语言模型推理框架，采用解耦的服务-引擎架构，通过智能调度、分布式KV缓存管理和多层级优化，显著提升吞吐量和推理效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决大规模企业级LLM服务中的性能瓶颈和资源利用效率问题，需要设计一个能够充分利用AI加速器的高性能推理框架。

Method: 构建解耦的服务-引擎架构：服务层包含智能调度模块、动态Prefill-Decode解耦策略和EPD解耦策略；引擎层通过多层级执行流水线优化、自适应图模式和xTensor内存管理来饱和计算资源。

Result: 在相同TPOT约束下，xLLM的吞吐量达到MindIE的1.7倍和vLLM-Ascend的2.2倍（使用Qwen系列模型），使用Deepseek系列模型时平均吞吐量为MindIE的1.7倍。

Conclusion: xLLM框架通过系统与算法的协同优化，在大规模企业级LLM推理服务中实现了显著的性能提升和资源效率优化，已开源供社区使用。

Abstract: We introduce xLLM, an intelligent and efficient Large Language Model (LLM)
inference framework designed for high-performance, large-scale enterprise-grade
serving, with deep optimizations for diverse AI accelerators. To address these
challenges, xLLM builds a novel decoupled service-engine architecture. At the
service layer, xLLM-Service features an intelligent scheduling module that
efficiently processes multimodal requests and co-locates online and offline
tasks through unified elastic scheduling to maximize cluster utilization. This
module also relies on a workload-adaptive dynamic Prefill-Decode (PD)
disaggregation policy and a novel Encode-Prefill-Decode (EPD) disaggregation
policy designed for multimodal inputs. Furthermore, it incorporates a
distributed architecture to provide global KV Cache management and robust
fault-tolerant capabilities for high availability. At the engine layer,
xLLM-Engine co-optimizes system and algorithm designs to fully saturate
computing resources. This is achieved through comprehensive multi-layer
execution pipeline optimizations, an adaptive graph mode and an xTensor memory
management. xLLM-Engine also further integrates algorithmic enhancements such
as optimized speculative decoding and dynamic EPLB, collectively serving to
substantially boost throughput and inference efficiency. Extensive evaluations
demonstrate that xLLM delivers significantly superior performance and resource
efficiency. Under identical TPOT constraints, xLLM achieves throughput up to
1.7x that of MindIE and 2.2x that of vLLM-Ascend with Qwen-series models, while
maintaining an average throughput of 1.7x that of MindIE with Deepseek-series
models. xLLM framework is publicly available at
https://github.com/jd-opensource/xllm and
https://github.com/jd-opensource/xllm-service.

</details>


### [57] [Balls and Bins and the Infinite Process with Random Deletions](https://arxiv.org/abs/2510.14798)
*Petra Berenbrink,Tom Friedetzky,Peter Kling,Lars Nagel*

Main category: cs.DC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider an infinite balls-into-bins process with deletions where in each
discrete step $t$ a coin is tossed as to whether, with probability $\beta(t)
\in (0,1)$, a new ball is allocated using the Greedy[2] strategy (which places
the ball in the lower loaded of two bins sampled uniformly at random) or, with
remaining probability $1-\beta(t)$, a ball is deleted from a non-empty bin
chosen uniformly at random. Let $n$ be the number of bins and $m(t)$ the total
load at time $t$. We are interested in bounding the discrepancy $x_{\max}(t) -
m(t)/n$ (current maximum load relative to current average) and the overload
$x_{\max}(t) - m_{\max}(t)/n$ (current maximum load relative to highest average
observed so far).
  We prove that at an arbitrarily chosen time $t$ the total number of balls
above the average is $O(n)$ and that the discrepancy is $ O(\log(n))$. For the
discrepancy, we provide a matching lower bound. Furthermore we prove that at an
arbitrarily chosen time $t$ the overload is $\log\log(n)+O(1)$. For "good"
insertion probability sequences (in which the average load of time intervals
with polynomial length increases in expectation) we show that even the
discrepancy is bounded by $\log\log(n)+O(1)$.
  One of our main analytical tools is a layered induction, as per [ABKU99].
Since our model allows for rather more general scenarios than what was
previously considered, the formal analysis requires some extra ingredients as
well, in particular a detailed potential analysis. Furthermore, we simplify the
setup by applying probabilistic couplings to obtain certain "recovery"
properties, which eliminate much of the need for intricate and careful
conditioning elsewhere in the analysis.

</details>

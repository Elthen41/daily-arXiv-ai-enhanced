<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 1]
- [cs.DC](#cs.DC) [Total: 8]
- [cs.AI](#cs.AI) [Total: 10]
- [cs.CR](#cs.CR) [Total: 13]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling](https://arxiv.org/abs/2512.22066)
*Hannah Atmer,Yuan Yao,Thiemo Voigt,Stefanos Kaxiras*

Main category: cs.AR

TL;DR: 研究LLM推理中SRAM大小和运行频率对能效和性能的影响，发现总能耗主要由SRAM大小决定，高频率可降低总能耗，最佳配置为1200-1400MHz频率和32-64KB小缓冲区。


<details>
  <summary>Details</summary>
Motivation: LLM的能耗决定了部署成本和环境影响，需要研究硬件配置对LLM推理能效和性能的影响，特别是计算密集型预填充阶段和内存密集型解码阶段的差异行为。

Method: 采用OpenRAM进行能耗建模、LLMCompass进行延迟仿真、ScaleSIM进行脉动阵列操作强度的模拟方法，分析SRAM大小和运行频率对LLM推理的影响。

Result: 总能耗主要由SRAM大小决定，大缓冲区显著增加静态能耗；高频率可降低总能耗（减少执行时间从而降低静态能耗）；内存带宽是性能瓶颈；最佳配置为1200-1400MHz频率和32-64KB小缓冲区。

Conclusion: 为设计能效优化的LLM加速器提供了具体架构见解，特别是针对数据中心最小化能耗开销，建议采用高频率和小缓冲区配置以获得最佳能耗延迟乘积。

Abstract: Energy consumption dictates the cost and environmental impact of deploying Large Language Models. This paper investigates the impact of on-chip SRAM size and operating frequency on the energy efficiency and performance of LLM inference, focusing on the distinct behaviors of the compute-bound prefill and memory-bound decode phases. Our simulation methodology combines OpenRAM for energy modeling, LLMCompass for latency simulation, and ScaleSIM for systolic array operational intensity. Our findings show that total energy use is predominantly determined by SRAM size in both phases, with larger buffers significantly increasing static energy due to leakage, which is not offset by corresponding latency benefits. We quantitatively explore the memory-bandwidth bottleneck, demonstrating that while high operating frequencies reduce prefill latency, their positive impact on memory-bound decode latency is capped by the external memory bandwidth. Counter-intuitively, high compute frequency can reduce total energy by reducing execution time and consequently decreasing static energy consumption more than the resulting dynamic power increase. We identify an optimal hardware configuration for the simulated workload: high operating frequencies (1200MHz-1400MHz) and a small local buffer size of 32KB to 64KB. This combination achieves the best energy-delay product, balancing low latency with high energy efficiency. Furthermore, we demonstrate how memory bandwidth acts as a performance ceiling, and that increasing compute frequency only yields performance gains up to the point where the workload becomes memory-bound. This analysis provides concrete architectural insights for designing energy-efficient LLM accelerators, especially for datacenters aiming to minimize their energy overhead.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [2] [Harnessing Data Spaces to Build Intelligent Smart City Infrastructures Across the Cloud-Edge Continuum](https://arxiv.org/abs/2512.21340)
*Dimitrios Amaxilatis,Themistoklis Sarantakos,Nikolaos Tsironis,Souvik Sengupta,Kostas Ramantas,Jhofre Ojeda*

Main category: cs.DC

TL;DR: 智慧城市正采用数据驱动架构提升城市服务效率、可持续性和韧性


<details>
  <summary>Details</summary>
Motivation: 智慧城市面临提升城市服务效率、可持续性和韧性的需求，需要采用更先进的数据驱动架构来应对这些挑战

Method: 采用数据中心的架构设计，通过数据收集、分析和应用来优化城市服务

Result: 数据驱动架构能够有效提升城市服务的运行效率、增强可持续性发展能力，并提高城市系统的韧性

Conclusion: 数据驱动架构是智慧城市发展的关键方向，能够显著改善城市服务的综合性能

Abstract: Smart cities are increasingly adopting data-centric architectures to enhance the efficiency, sustainability, and resilience of urban services.

</details>


### [3] [Efficient MoE Inference with Fine-Grained Scheduling of Disaggregated Expert Parallelism](https://arxiv.org/abs/2512.21487)
*Xinglin Pan,Shaohuai Shi,Wenxiang Lin,Yuxin Wang,Zhenheng Tang,Wei Wang,Xiaowen Chu*

Main category: cs.DC

TL;DR: FinDEP提出了一种针对分解专家并行（DEP）的细粒度任务调度算法，通过最大化任务重叠来提高MoE推理吞吐量，在32-GPU系统上实现了最高1.24倍的加速。


<details>
  <summary>Details</summary>
Motivation: 混合专家（MoE）架构虽然能以亚线性计算增长扩展模型规模，但由于KV缓存和稀疏专家激活导致内存密集型推理问题。现有的分解专家并行（DEP）方法将注意力和专家分配到专用GPU组，但缺乏对共享专家的支持和高效的任务调度，限制了性能提升。

Method: FinDEP包含三个创新：1）将计算/通信划分为更小的任务以实现细粒度流水线；2）制定支持可变粒度和顺序的调度优化问题；3）为这个大型搜索空间开发高效的求解器。

Result: 在四个GPU系统上对DeepSeek-V2和Qwen3-MoE进行实验，FinDEP相比先前方法将吞吐量提高了最高1.61倍，在32-GPU系统上实现了最高1.24倍的加速。

Conclusion: FinDEP通过细粒度任务调度有效解决了MoE推理中的内存瓶颈和调度效率问题，显著提升了分解专家并行架构的推理性能。

Abstract: The mixture-of-experts (MoE) architecture scales model size with sublinear computational increase but suffers from memory-intensive inference due to KV caches and sparse expert activation. Recent disaggregated expert parallelism (DEP) distributes attention and experts to dedicated GPU groups but lacks support for shared experts and efficient task scheduling, limiting performance.
  We propose FinDEP, a fine-grained task scheduling algorithm for DEP that maximizes task overlap to improve MoE inference throughput. FinDEP introduces three innovations: 1) partitioning computation/communication into smaller tasks for fine-grained pipelining, 2) formulating a scheduling optimization supporting variable granularity and ordering, and 3) developing an efficient solver for this large search space.
  Experiments on four GPU systems with DeepSeek-V2 and Qwen3-MoE show FinDEP improves throughput by up to 1.61x over prior methods, achieving up to 1.24x speedup on a 32-GPU system.

</details>


### [4] [nncase: An End-to-End Compiler for Efficient LLM Deployment on Heterogeneous Storage Architectures](https://arxiv.org/abs/2512.21571)
*Hui Guo,Qihang Zheng,Chenghai Huo,Dongliang Guo,Haoqi Yang,Yang Zhang*

Main category: cs.DC

TL;DR: nncase是一个端到端的开源编译框架，通过基于e-graph的项重写引擎解决内存架构异构性问题，统一优化不同目标平台，在Qwen3系列模型上性能优于主流框架。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的高效部署受到内存架构异构性的阻碍，传统编译器存在工作流程碎片化和高适应成本的问题，需要统一的编译框架来优化不同目标平台。

Method: 提出nncase编译框架，核心是基于e-graph的项重写引擎解决阶段排序问题；包含三个关键模块：Auto Vectorize适应异构计算单元，Auto Distribution搜索并行策略并优化通信成本，Auto Schedule最大化片上缓存局部性；还有缓冲区感知的代码生成阶段。

Result: nncase在Qwen3系列模型上性能优于MLC LLM和Intel IPEX等主流框架，在CPU上性能接近手工优化的llama.cpp，证明了自动化编译在高性能LLM部署中的可行性。

Conclusion: nncase通过统一的编译框架有效解决了LLM部署中的内存架构异构性问题，展示了自动化编译在高性能LLM部署中的潜力，为跨平台优化提供了有效解决方案。

Abstract: The efficient deployment of large language models (LLMs) is hindered by memory architecture heterogeneity, where traditional compilers suffer from fragmented workflows and high adaptation costs. We present nncase, an open-source, end-to-end compilation framework designed to unify optimization across diverse targets. Central to nncase is an e-graph-based term rewriting engine that mitigates the phase ordering problem, enabling global exploration of computation and data movement strategies. The framework integrates three key modules: Auto Vectorize for adapting to heterogeneous computing units, Auto Distribution for searching parallel strategies with cost-aware communication optimization, and Auto Schedule for maximizing on-chip cache locality. Furthermore, a buffer-aware Codegen phase ensures efficient kernel instantiation. Evaluations show that nncase outperforms mainstream frameworks like MLC LLM and Intel IPEX on Qwen3 series models and achieves performance comparable to the hand-optimized llama.cpp on CPUs, demonstrating the viability of automated compilation for high-performance LLM deployment. The source code is available at https://github.com/kendryte/nncase.

</details>


### [5] [Embedding Samples Dispatching for Recommendation Model Training in Edge Environments](https://arxiv.org/abs/2512.21615)
*Guopeng Li,Haisheng Tan,Chi Zhang,Hongqiu Ni,Zilong Wang,Xinyue Zhang,Yang Xu,Han Tian*

Main category: cs.DC

TL;DR: ESD机制通过优化嵌入样本分发到边缘工作节点，减少嵌入传输成本，加速DLRM训练


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上训练深度推荐模型（DLRM）具有数据隐私保护、低延迟和个性化等优势，但由于嵌入表巨大，传统框架使用参数服务器维护全局嵌入表，边缘工作节点缓存部分嵌入，导致嵌入传输成本高昂，成为训练瓶颈

Method: 提出ESD机制，基于预期嵌入传输成本优化输入嵌入样本到边缘工作节点的分发。开发HybridDis分发决策方法，结合资源密集型最优算法和启发式算法，平衡决策质量和资源消耗

Result: 实验结果显示，ESD减少嵌入传输成本高达36.76%，端到端DLRM训练加速高达1.74倍

Conclusion: ESD机制有效解决了边缘环境中嵌入传输成本高的问题，通过优化样本分发策略显著提升了DLRM训练效率

Abstract: Training deep learning recommendation models (DLRMs) on edge workers brings several benefits, particularly in terms of data privacy protection, low latency and personalization. However, due to the huge size of embedding tables, typical DLRM training frameworks adopt one or more parameter servers to maintain global embedding tables, while leveraging the edge workers cache part of them. This incurs significant transmission cost for embedding transmissions between workers and parameter servers, which can dominate the training cycle. In this paper, we investigate how to dispatch input embedding samples to appropriate edge workers to minimize the total embedding transmission cost when facing edge-specific challenges such as heterogeneous networks and limited resources. We develop ESD, a novel mechanism that optimizes the dispatch of input embedding samples to edge workers based on expected embedding transmission cost. We propose HybridDis as the dispatch decision method within ESD, which combines a resource-intensive optimal algorithm and a heuristic algorithm to balance decision quality and resource consumption. We implement a prototype of ESD and compare it with state-of-the-art mechanisms on real-world workloads. Extensive experimental results show that ESD reduces the embedding transmission cost by up to 36.76% and achieves up to 1.74 times speedup in end-to-end DLRM training.

</details>


### [6] [Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models](https://arxiv.org/abs/2512.21884)
*Tingyang Sun,Ting He,Bo Ji,Parimal Parag*

Main category: cs.DC

TL;DR: 本文首次系统研究了分布式LLM推理中的资源分配问题，提出了性能预测模型、优化算法和在线适应方案，显著降低了推理时间。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然性能强大，但部署成本高昂，需要高端GPU。现有的PETALS分布式系统通过将模型块分配到多台低端GPU服务器来降低部署门槛，但其性能严重依赖于资源分配策略，而如何最优分配仍未知。

Method: 1. 开发了实验验证的性能模型，可预测给定块放置和请求路由决策下的推理性能；2. 将离线优化问题形式化为混合整数线性规划问题，证明其NP-hard性质，并提出具有性能保证的多项式复杂度算法；3. 将离线算法适配到在线设置，在负载有界条件下保持相同性能保证；4. 开发了轻量级CPU-only模拟器。

Result: 通过实验和实验验证的模拟，验证了所提解决方案在不同地理分布服务器设置中，相比现有最优方案能显著减少推理时间。同时开发的模拟器能够预测GPU服务器上的分布式LLM推理性能，便于研究人员在有限GPU资源下评估大规模部署。

Conclusion: 本文首次系统研究了分布式LLM推理的资源分配问题，提出了完整的理论框架和实用算法，显著提升了分布式LLM推理的性能效率，并为未来研究提供了有价值的工具。

Abstract: Large language models have demonstrated extraordinary performance in many AI tasks but are expensive to use, even after training, due to their requirement of high-end GPUs. Recently, a distributed system called PETALS was developed to lower the barrier for deploying LLMs by splitting the model blocks across multiple servers with low-end GPUs distributed over the Internet, which was much faster than swapping the model parameters between the GPU memory and other cheaper but slower local storage media. However, the performance of such a distributed system critically depends on the resource allocation, and how to do so optimally remains unknown. In this work, we present the first systematic study of the resource allocation problem in distributed LLM inference, with focus on two important decisions: block placement and request routing. Our main results include: experimentally validated performance models that can predict the inference performance under given block placement and request routing decisions, a formulation of the offline optimization of block placement and request routing as a mixed integer linear programming problem together with the NP-hardness proof and a polynomial-complexity algorithm with guaranteed performance, and an adaptation of the offline algorithm for the online setting with the same performance guarantee under bounded load. Through both experiments and experimentally-validated simulations, we have verified that the proposed solution can substantially reduce the inference time compared to the state-of-the-art solution in diverse settings with geographically-distributed servers. As a byproduct, we have also developed a light-weighted CPU-only simulator capable of predicting the performance of distributed LLM inference on GPU servers, which can evaluate large deployments and facilitate future research for researchers with limited GPU access.

</details>


### [7] [BLEST: Blazingly Efficient BFS using Tensor Cores](https://arxiv.org/abs/2512.21967)
*Deniz Elbek,Kamer Kaya*

Main category: cs.DC

TL;DR: BLEST是一个利用GPU张量核心加速BFS的框架，通过位图导向结构、图重排序策略和批处理稀疏矩阵-稀疏向量乘法，实现了比现有系统3.58-4.9倍的加速。


<details>
  <summary>Details</summary>
Motivation: 现代GPU的张量核心（TC）虽然提供极高的计算吞吐量，但主要针对密集运算，难以有效应用于BFS等不规则、非结构化的图计算。需要解决如何将边操作高效映射到TC上，同时避免冗余、负载不均衡和同步问题。

Method: 1. 采用基于位图的结构和精心设计的执行布局重构pull-based BFS流水线；2. 引入二值化虚拟切片集（BVSS）实现warp级负载均衡并消除frontier-oblivious工作分配；3. 应用两种互补的图重排序策略：面向社交图的压缩排序和面向非社交图的带宽减少排序；4. 开发批处理SpMSpV乘法模式，利用位级TC瓦片处理点积而不浪费输出条目；5. 结合内核融合和惰性顶点更新方案减少主机端同步。

Result: 实验表明，BLEST在广泛的真实世界图数据集上，相比BerryBees、Gunrock和GSWITCH分别实现了平均3.58倍、4.64倍和4.9倍的加速。

Conclusion: BLEST成功地将GPU张量核心应用于BFS计算，通过创新的位图导向结构、图重排序策略和计算优化技术，显著提升了BFS在GPU上的性能，为不规则图计算利用专用硬件加速提供了有效方案。

Abstract: Breadth-First Search (BFS) is a fundamental graph kernel that underpins a wide range of applications. While modern GPUs provide specialised Matrix-Multiply-Accumulate (MMA) units, e.g., Tensor Cores (TC), with extremely high throughput, they target dense operations, making it non-trivial to exploit them for irregular, unstructured graph computations. In particular, fully utilising them for a BFS requires an efficient mapping of the edge operations onto TCs while avoiding redundancy, load imbalance, and synchronisation. We present BLEST, a TC-accelerated framework that reformulates the pull-based BFS pipeline around a bitmap-oriented structure and a carefully engineered execution layout. BLEST introduces Binarised Virtual Slice Sets (BVSS) to enforce warp-level load balancing and to eliminate frontier-oblivious work assignment. To improve both memory efficiency and update locality across diverse graphs, we apply two complementary graph reordering strategies: a compression-oriented ordering for social-like graphs and a bandwidth-reducing ordering for non-social graphs. At the compute level, we develop a batched SpMSpV multiplication pattern that uses the bitwise TC tiles to handle dot products without wasting output entries, thereby reducing the number of required MMA calls. Finally, BLEST combines kernel fusion with a lazy vertex update scheme to reduce host-side synchronisation, mitigate atomic overheads, and improve cache locality. Experiments show that BLEST delivers, on average, $3.58\times$, $4.64\times$ and $4.9\times$ speedup over BerryBees, Gunrock, and GSWITCH, respectively, across a broad set of real-world graphs.

</details>


### [8] [FUSCO: High-Performance Distributed Data Shuffling via Transformation-Communication Fusion](https://arxiv.org/abs/2512.22036)
*Zhuoran Zhu,Chunyang Zhu,Hao Lin,Xu Fu,Yiming Zhou,Quanlu Zhang,Zhenhua Li,Feng Qian,Chao Yu,Boxun Li,Guohao Dai,Yu Wang*

Main category: cs.DC

TL;DR: FUSCO是一个专门为MoE模型设计的通信库，通过融合数据转换和通信操作，解决了现有通信库在处理专家并行数据混洗时的性能瓶颈，实现了高效的分布式数据路由。


<details>
  <summary>Details</summary>
Motivation: 大规模混合专家模型依赖专家并行进行高效训练和推理，需要将专家分配到不同设备并通过分布式数据混洗将token路由到对应专家。现有通信库对此处理不佳，其开销可占端到端运行时间的一半以上。

Method: FUSCO通过融合数据转换和通信操作实现高效轻量级数据混洗。关键观察是MoE的专家主数据布局与通信操作期望的设备主布局冲突。FUSCO捕获细粒度数据布局，由流水线通信引擎在通信路径上高效执行混洗操作，辅以轻量级规划和负载均衡机制消除冗余通信并分散流量。

Result: 在代表性基准测试中，FUSCO相比NCCL和DeepEP（最先进的MoE通信库）分别实现了最高3.84倍和2.01倍的加速。在端到端MoE任务中，相比NCCL和DeepEP，FUSCO将训练延迟降低了1.17-1.39倍和1.10-1.19倍，并将推理中的首token生成延迟降低了1.09-1.25倍和1.06-1.16倍。

Conclusion: FUSCO通过专门针对MoE数据混洗特性设计的通信库，显著提升了大规模混合专家模型的训练和推理效率，解决了现有通用通信库在此场景下的性能瓶颈问题。

Abstract: Large-scale Mixture-of-Experts (MoE) models rely on \emph{expert parallelism} for efficient training and inference, which splits experts across devices and necessitates distributed data shuffling to route each token to its assigned experts. However, existing communication libraries handle this shuffling poorly; its overhead can account for over half of end-to-end runtime. We present FUSCO, an MoE-friendly communication library that achieves efficient and lightweight data shuffling through fused data transformation and communication, based on the key observation that MoE's expert-major data layout conflicts with the device-major layout expected by communication operations. FUSCO captures the fine-grained data layout, which is then interpreted by a pipelined communication engine that performs the required shuffling efficiently along the communication path. Lightweight planning and load-balancing mechanisms complement the engine by eliminating redundant communication and dispersing traffic. Evaluations on representative benchmarks illustrate that FUSCO achieves up to 3.84$\times$ and 2.01$\times$ speedups over NCCL and DeepEP (the state-of-the-art MoE communication library), respectively. In end-to-end MoE tasks, compared to NCCL and DeepEP, FUSCO reduces the training latency by 1.17-1.39$\times$ and 1.10-1.19$\times$, and lowers the first-token generation latency in inference by 1.09-1.25$\times$ and 1.06-1.16$\times$.

</details>


### [9] [Agentic Structured Graph Traversal for Root Cause Analysis of Code-related Incidents in Cloud Applications](https://arxiv.org/abs/2512.22113)
*Shengkun Cui,Rahul Krishna,Saurabh Jha,Ravishankar K. Iyer*

Main category: cs.DC

TL;DR: PRAXIS是一个用于诊断云事故的智能编排器，通过LLM驱动的图遍历方法在服务依赖图和程序依赖图中定位代码和配置问题，相比现有方法将RCA准确率提升3.1倍，同时减少3.8倍的token消耗。


<details>
  <summary>Details</summary>
Motivation: 云事故在生产环境中造成重大运营挑战，未解决的云事故平均每小时成本超过200万美元。先前研究表明，代码和配置相关问题是云事故的根本原因的主要类别，需要有效的诊断工具来快速定位和解决问题。

Method: PRAXIS采用LLM驱动的结构化遍历方法，在两个图上进行操作：1）服务依赖图（SDG）捕获微服务级依赖关系；2）吊床块程序依赖图（PDG）捕获每个微服务的代码级依赖关系。LLM作为这些图的遍历策略，在服务和代码依赖之间移动以定位和解释故障。

Result: 与最先进的ReAct基线相比，PRAXIS将根本原因分析（RCA）准确率提高了3.1倍，同时将token消耗减少了3.8倍。该系统在30个真实世界事故的基准测试中进行了验证。

Conclusion: PRAXIS通过结合服务级和代码级依赖图的LLM驱动遍历，为云事故诊断提供了一种高效准确的方法，显著提升了根本原因分析的性能，同时降低了计算成本。

Abstract: Cloud incidents pose major operational challenges in production, with unresolved production cloud incidents cost on average over $2M per hour. Prior research identifies code- and configuration-related issues as the predominant category of root causes in cloud incidents. This paper introduces PRAXIS, an orchestrator that manages and deploys an agentic workflow for diagnosing code- and configuration-caused cloud incidents. PRAXIS employs an LLM-driven structured traversal over two types of graph: (1) a service dependency graph (SDG) that captures microservice-level dependencies; and (2) a hammock-block program dependence graph (PDG) that captures code-level dependencies for each microservice. Together, these graphs encode microservice- and code-level dependencies and the LLM acts as a traversal policy over these graphs, moving between services and code dependencies to localize and explain failures. Compared to state-of-the-art ReAct baselines, PRAXIS improves RCA accuracy by up to 3.1x while reducing token consumption by 3.8x. PRAXIS is demonstrated on a set of 30 comprehensive real-world incidents that is being compiled into an RCA benchmark.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [10] [From Visual Perception to Deep Empathy: An Automated Assessment Framework for House-Tree-Person Drawings Using Multimodal LLMs and Multi-Agent Collaboration](https://arxiv.org/abs/2512.21360)
*Shuide Wen,Yu Sun,Beier Ku,Zhi Gao,Lijun Ma,Yang Yang,Can Jiao*

Main category: cs.AI

TL;DR: 该研究开发了一个基于多模态大语言模型的多智能体系统，用于标准化HTP绘画测试分析，实现了与专家解释约0.75的语义相似度，在结构化数据集上达到0.85。


<details>
  <summary>Details</summary>
Motivation: HTP绘画测试作为临床心理学中广泛使用的投射技术，长期面临评分标准不统一、依赖检查者主观经验、缺乏统一量化编码系统等问题，需要标准化分析工具。

Method: 采用多模态大语言模型构建多智能体协作框架，通过角色分工将特征识别与心理推理解耦，整合社会心理学视角和去污名化叙事，纠正视觉幻觉。

Result: 定量实验显示MLLM解释与人类专家解释的平均语义相似度约为0.75（标准差约0.05），在结构化专家数据集中相似度提升至0.85，达到专家级基线理解水平。

Conclusion: 多模态大模型有潜力成为投射评估的标准化工具，提出的多智能体框架为数字心理健康服务提供了新范式，通过角色分工实现了特征识别与心理推理的解耦。

Abstract: Background: The House-Tree-Person (HTP) drawing test, introduced by John Buck in 1948, remains a widely used projective technique in clinical psychology. However, it has long faced challenges such as heterogeneous scoring standards, reliance on examiners subjective experience, and a lack of a unified quantitative coding system.
  Results: Quantitative experiments showed that the mean semantic similarity between Multimodal Large Language Model (MLLM) interpretations and human expert interpretations was approximately 0.75 (standard deviation about 0.05). In structurally oriented expert data sets, this similarity rose to 0.85, indicating expert-level baseline comprehension. Qualitative analyses demonstrated that the multi-agent system, by integrating social-psychological perspectives and destigmatizing narratives, effectively corrected visual hallucinations and produced psychological reports with high ecological validity and internal coherence.
  Conclusions: The findings confirm the potential of multimodal large models as standardized tools for projective assessment. The proposed multi-agent framework, by dividing roles, decouples feature recognition from psychological inference and offers a new paradigm for digital mental-health services.
  Keywords: House-Tree-Person test; multimodal large language model; multi-agent collaboration; cosine similarity; computational psychology; artificial intelligence

</details>


### [11] [A Study of Solving Life-and-Death Problems in Go Using Relevance-Zone Based Solvers](https://arxiv.org/abs/2512.21365)
*Chung-Chin Shih,Ti-Rong Wu,Ting Han Wei,Yu-Shan Hsu,Hung Guei,I-Chen Wu*

Main category: cs.AI

TL;DR: 该论文分析了使用当前最先进的计算机围棋求解器（基于相关区域搜索和相关区域模式表）解决围棋死活题的行为，发现求解器能识别关键区域、发现罕见模式，甚至在某些问题上给出与人类专家不同的答案，但也存在模式价值误判和优先活棋而非最大化地域的问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机是分析当前最先进的计算机围棋求解器在解决死活题时的表现，特别是使用相关区域搜索和相关区域模式表这两种技术，评估它们在解决经典死活问题上的能力、发现模式的能力以及与人类专家解决方案的差异。

Method: 研究方法包括：1）使用基于相关区域搜索的求解器和相关区域模式表；2）测试七个来自著名围棋大师赵治勋《死活辞典》中的死活问题；3）分析求解器识别的相关区域、发现的模式类型；4）比较求解器答案与书中给定解决方案的差异。

Result: 研究结果：1）对于每个问题，求解器都能识别出解决问题的关键相关区域；2）求解器发现了一系列模式，包括一些罕见模式；3）在两个问题上，求解器给出了与书中给定解决方案不同的答案；4）发现了求解器的两个问题：a）对罕见模式的价值判断错误，b）倾向于优先活棋而非最大化地域，这与人类棋手行为不同。

Conclusion: 结论表明基于相关区域的求解器在解决死活题方面具有潜力，能够识别关键区域和发现罕见模式，但也存在与人类棋手行为差异的问题。论文提出了解决这些问题的可能方法，并公开了代码和数据供进一步研究。

Abstract: This paper analyzes the behavior of solving Life-and-Death (L&D) problems in the game of Go using current state-of-the-art computer Go solvers with two techniques: the Relevance-Zone Based Search (RZS) and the relevance-zone pattern table. We examined the solutions derived by relevance-zone based solvers on seven L&D problems from the renowned book "Life and Death Dictionary" written by Cho Chikun, a Go grandmaster, and found several interesting results. First, for each problem, the solvers identify a relevance-zone that highlights the critical areas for solving. Second, the solvers discover a series of patterns, including some that are rare. Finally, the solvers even find different answers compared to the given solutions for two problems. We also identified two issues with the solver: (a) it misjudges values of rare patterns, and (b) it tends to prioritize living directly rather than maximizing territory, which differs from the behavior of human Go players. We suggest possible approaches to address these issues in future work. Our code and data are available at https://rlg.iis.sinica.edu.tw/papers/study-LD-RZ.

</details>


### [12] [Three-way conflict analysis based on alliance and conflict functions](https://arxiv.org/abs/2512.21419)
*Junfang Luo,Mengjun Hu,Guangming Lang,Xin Yang,Keyun Qin*

Main category: cs.AI

TL;DR: 该论文提出将冲突分析中的辅助函数分离为联盟和冲突两个独立函数，以解决传统方法中正负值聚合导致语义模糊的问题，并应用于三支冲突分析中的智能体、议题和智能体对的划分。


<details>
  <summary>Details</summary>
Motivation: 传统三支冲突分析中，评级函数或辅助函数将对立方面（如联盟与冲突）合并到单一函数中，导致在聚合多个议题或智能体时语义解释困难。例如，联盟+1和冲突-1的平均值与两个中立0关系的结果相同，但实际上这两种情况的态度完全不同。

Method: 将辅助函数中的两个对立方面分离为独立的联盟函数和冲突函数对，基于此对智能体、议题和智能体对进行三支划分，并探索联盟集和策略等概念。

Result: 提出了分离联盟和冲突函数的新模型，能够更清晰地解释语义，解决了传统聚合方法中的模糊性问题，并通过实际应用案例验证了模型的有效性。

Conclusion: 分离联盟和冲突函数的方法为三支冲突分析提供了更精确的语义解释框架，有助于解决冲突分析中的关键问题，特别是在处理多个议题或智能体关系时能够避免传统方法的语义混淆。

Abstract: Trisecting agents, issues, and agent pairs are essential topics of three-way conflict analysis. They have been commonly studied based on either a rating or an auxiliary function. A rating function defines the positive, negative, or neutral ratings of agents on issues. An auxiliary function defines the alliance, conflict, and neutrality relations between agents. These functions measure two opposite aspects in a single function, leading to challenges in interpreting their aggregations over a group of issues or agents. For example, when studying agent relations regarding a set of issues, a standard aggregation takes the average of an auxiliary function concerning single issues. Therefore, a pair of alliance +1 and conflict -1 relations will produce the same result as a pair of neutrality 0 relations, although the attitudes represented by the two pairs are very different. To clarify semantics, we separate the two opposite aspects in an auxiliary function into a pair of alliance and conflict functions. Accordingly, we trisect the agents, issues, and agent pairs and investigate their applications in solving a few crucial questions in conflict analysis. Particularly, we explore the concepts of alliance sets and strategies. A real-world application is given to illustrate the proposed models.

</details>


### [13] [Three-way decision with incomplete information based on similarity and satisfiability](https://arxiv.org/abs/2512.21421)
*Junfang Luo,Mengjun Hu,Keyun Qin*

Main category: cs.AI

TL;DR: 本文基于对完整信息下三支决策计算和概念两种表述的回顾，将两者推广到更实用的不完全信息场景，提出了相似度度量、α-相似类、可逼近性等新概念，为不完全信息处理提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 现有三支决策方法主要处理完整信息，但在实际应用中常遇到不完全信息的情况。需要将完整信息下的两种表述（计算和概念）推广到不完全信息场景，以解决更实际的问题。

Method: 1. 计算表述：提出对象相似度度量作为等价关系的推广，基于此讨论使用α-相似类和对象可逼近性的两种三支决策方法；2. 概念表述：提出公式满足度度量作为完整信息下满足性的定量推广，基于此研究使用公式α-意义集和公式置信度的两种三支决策方法。

Result: 提出了处理不完全信息的三支决策新框架，包括相似度度量、α-相似类、可逼近性概念、公式满足度度量、α-意义集和公式置信度等新概念和方法，为不完全信息分析提供了比传统相似类方法更丰富的新方向。

Conclusion: 成功将三支决策从完整信息推广到不完全信息场景，提出的可逼近性概念和概念表述中的两种新方法为不完全信息处理开辟了有前景的新研究方向，增强了三支决策在实际应用中的实用性。

Abstract: Three-way decision is widely applied with rough set theory to learn classification or decision rules. The approaches dealing with complete information are well established in the literature, including the two complementary computational and conceptual formulations. The computational formulation uses equivalence relations, and the conceptual formulation uses satisfiability of logic formulas. In this paper, based on a briefly review of these two formulations, we generalize both formulations into three-way decision with incomplete information that is more practical in real-world applications. For the computational formulation, we propose a new measure of similarity degree of objects as a generalization of equivalence relations. Based on it, we discuss two approaches to three-way decision using alpha-similarity classes and approximability of objects, respectively. For the conceptual formulation, we propose a measure of satisfiability degree of formulas as a quantitative generalization of satisfiability with complete information. Based on it, we study two approaches to three-way decision using alpha-meaning sets of formulas and confidence of formulas, respectively. While using similarity classes is a common method of analyzing incomplete information in the literature, the proposed concept of approximability and the two approaches in conceptual formulation point out new promising directions.

</details>


### [14] [LogicLens: Visual-Logical Co-Reasoning for Text-Centric Forgery Analysis](https://arxiv.org/abs/2512.21482)
*Fanwei Zeng,Changtao Miao,Jing Huang,Zhiya Tan,Shutao Gong,Xiaoming Yu,Yang Wang,Huazhe Tan,Weibin Yao,Jianshu Li*

Main category: cs.AI

TL;DR: LogicLens是一个统一的视觉-文本协同推理框架，用于分析文本中心伪造图像，通过交叉线索感知的思维链机制实现深度推理，并在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着AIGC技术的快速发展，复杂的文本中心伪造对社会安全和信息真实性构成重大威胁。现有方法通常局限于粗粒度的视觉分析，缺乏复杂推理能力，且将检测、定位和解释视为离散子任务，忽略了它们之间的内在联系。

Method: 提出LogicLens统一框架，采用交叉线索感知思维链(CCT)机制进行视觉-文本协同推理，通过加权多任务奖励函数进行GRPO优化。同时设计了PR²(感知器、推理器、评审器)流水线来生成高质量标注，并构建了包含5,397张图像的RealText数据集。

Result: 在T-IC13的零样本评估中，LogicLens比专用框架高出41.4%，比GPT-4o高出23.4%的宏平均F1分数。在密集文本T-SROIE数据集上，在mF1、CSS和宏平均F1指标上显著领先其他MLLM方法。

Conclusion: LogicLens通过统一的视觉-文本协同推理框架，有效解决了文本中心伪造分析中的挑战，在多个基准测试中表现出卓越性能，为伪造检测提供了新的解决方案。

Abstract: Sophisticated text-centric forgeries, fueled by rapid AIGC advancements, pose a significant threat to societal security and information authenticity. Current methods for text-centric forgery analysis are often limited to coarse-grained visual analysis and lack the capacity for sophisticated reasoning. Moreover, they typically treat detection, grounding, and explanation as discrete sub-tasks, overlooking their intrinsic relationships for holistic performance enhancement. To address these challenges, we introduce LogicLens, a unified framework for Visual-Textual Co-reasoning that reformulates these objectives into a joint task. The deep reasoning of LogicLens is powered by our novel Cross-Cues-aware Chain of Thought (CCT) mechanism, which iteratively cross-validates visual cues against textual logic. To ensure robust alignment across all tasks, we further propose a weighted multi-task reward function for GRPO-based optimization. Complementing this framework, we first designed the PR$^2$ (Perceiver, Reasoner, Reviewer) pipeline, a hierarchical and iterative multi-agent system that generates high-quality, cognitively-aligned annotations. Then, we constructed RealText, a diverse dataset comprising 5,397 images with fine-grained annotations, including textual explanations, pixel-level segmentation, and authenticity labels for model training. Extensive experiments demonstrate the superiority of LogicLens across multiple benchmarks. In a zero-shot evaluation on T-IC13, it surpasses the specialized framework by 41.4% and GPT-4o by 23.4% in macro-average F1 score. Moreover, on the challenging dense-text T-SROIE dataset, it establishes a significant lead over other MLLM-based methods in mF1, CSS, and the macro-average F1. Our dataset, model, and code will be made publicly available.

</details>


### [15] [Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model](https://arxiv.org/abs/2512.21540)
*Yanhao Li,Lu Ma,Jiaran Zhang,Lexiang Tang,Wentao Zhang,Guibo Luo*

Main category: cs.AI

TL;DR: Leash框架通过自适应长度惩罚和奖励塑造，在保持任务性能的同时将推理长度减少60%


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖固定长度惩罚，难以调整且无法适应LLM不断发展的推理能力，导致准确性和简洁性之间的次优权衡

Method: 将长度控制建模为约束优化问题，采用拉格朗日对偶方法动态调整惩罚系数，生成超过目标长度时加强惩罚，较短时放松惩罚

Result: 在Deepseek-R1-Distill-Qwen-1.5B和Qwen3-4B-Thinking-2507上，Leash在包括数学推理、编程和指令遵循等任务中平均减少推理长度60%，同时保持竞争力性能

Conclusion: Leash为开发可控高效LLM提供了实用有效范式，平衡推理能力与计算预算

Abstract: Existing approaches typically rely on fixed length penalties, but such penalties are hard to tune and fail to adapt to the evolving reasoning abilities of LLMs, leading to suboptimal trade-offs between accuracy and conciseness. To address this challenge, we propose Leash (adaptive LEngth penAlty and reward SHaping), a reinforcement learning framework for efficient reasoning in LLMs. We formulate length control as a constrained optimization problem and employ a Lagrangian primal-dual method to dynamically adjust the penalty coefficient. When generations exceed the target length, the penalty is intensified; when they are shorter, it is relaxed. This adaptive mechanism guides models toward producing concise reasoning without sacrificing task performance. Experiments on Deepseek-R1-Distill-Qwen-1.5B and Qwen3-4B-Thinking-2507 show that Leash reduces the average reasoning length by 60% across diverse tasks - including in-distribution mathematical reasoning and out-of-distribution domains such as coding and instruction following - while maintaining competitive performance. Our work thus presents a practical and effective paradigm for developing controllable and efficient LLMs that balance reasoning capabilities with computational budgets.

</details>


### [16] [A Medical Multimodal Diagnostic Framework Integrating Vision-Language Models and Logic Tree Reasoning](https://arxiv.org/abs/2512.21583)
*Zelin Zang,Wenyi Gu,Siqi Ma,Dan Yang,Yue Shen,Zhu Zhang,Guohui Fan,Wing-Kuen Ling,Fuji Yang*

Main category: cs.AI

TL;DR: 基于LLaVA的医学诊断框架，结合视觉语言对齐与逻辑正则化推理，提升多模态医学AI的可信度和准确性


<details>
  <summary>Details</summary>
Motivation: 随着医学领域大语言模型和视觉语言模型的快速发展，简单整合临床文本和医学影像并不能保证可靠的推理。现有的多模态模型经常产生幻觉或不一致的思维链，限制了临床信任度。

Method: 提出一个诊断框架，包括：1) 文本和图像的输入编码器；2) 跨模态对齐的投影模块；3) 将诊断任务分解为步骤的推理控制器；4) 将逐步前提组装成可验证结论的逻辑树生成器。该方法结合了视觉语言对齐与逻辑正则化推理。

Result: 在MedXpertQA和其他基准测试上的评估显示，该方法提高了多模态任务的诊断准确性，产生了更可解释的推理轨迹，同时在纯文本设置下保持竞争力。

Conclusion: 这些结果表明该方法朝着可信赖的多模态医学AI迈出了有希望的一步，能够改善诊断准确性和推理可解释性。

Abstract: With the rapid growth of large language models (LLMs) and vision-language models (VLMs) in medicine, simply integrating clinical text and medical imaging does not guarantee reliable reasoning. Existing multimodal models often produce hallucinations or inconsistent chains of thought, limiting clinical trust. We propose a diagnostic framework built upon LLaVA that combines vision-language alignment with logic-regularized reasoning. The system includes an input encoder for text and images, a projection module for cross-modal alignment, a reasoning controller that decomposes diagnostic tasks into steps, and a logic tree generator that assembles stepwise premises into verifiable conclusions. Evaluations on MedXpertQA and other benchmarks show that our method improves diagnostic accuracy and yields more interpretable reasoning traces on multimodal tasks, while remaining competitive on text-only settings. These results suggest a promising step toward trustworthy multimodal medical AI.

</details>


### [17] [Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design](https://arxiv.org/abs/2512.21623)
*Takahide Suzuki,Kazuki Nakanishi,Takashi Fujiwara,Hideyuki Shimizu*

Main category: cs.AI

TL;DR: OrchestRA是一个人类在环的多智能体平台，将生物学、化学和药理学统一为自主发现引擎，通过动态反馈循环实现治疗药物的自主设计和优化。


<details>
  <summary>Details</summary>
Motivation: 治疗药物发现面临专业领域碎片化以及计算设计与生理验证之间的执行鸿沟等挑战，现有生成式AI模型通常只是被动助手而非自主执行者。

Method: OrchestRA采用多智能体架构：由Orchestrator协调，生物学家智能体利用大规模知识图谱进行深度推理识别靶点，化学家智能体自主检测结构口袋进行从头设计或药物重定位，药理学家智能体通过PBPK模拟评估候选药物，形成动态反馈循环。

Result: 该平台建立了动态反馈循环，使药代动力学和毒性特征直接触发结构重新优化，将药物发现从随机搜索转变为可编程的基于证据的工程学科。

Conclusion: OrchestRA通过自主执行与人类指导的无缝集成，实现了治疗设计的民主化，解决了当前治疗药物发现中的关键瓶颈问题。

Abstract: Therapeutic discovery remains a formidable challenge, impeded by the fragmentation of specialized domains and the execution gap between computational design and physiological validation. Although generative AI offers promise, current models often function as passive assistants rather than as autonomous executors. Here, we introduce OrchestRA, a human-in-the-loop multi-agent platform that unifies biology, chemistry, and pharmacology into an autonomous discovery engine. Unlike static code generators, our agents actively execute simulations and reason the results to drive iterative optimization. Governed by an Orchestrator, a Biologist Agent leverages deep reasoning over a massive knowledge graph (>10 million associations) to pinpoint high-confidence targets; a Chemist Agent autonomously detects structural pockets for de novo design or drug repositioning; and a Pharmacologist Agent evaluates candidates via rigorous physiologically based pharmacokinetic (PBPK) simulations. This architecture establishes a dynamic feedback loop where pharmacokinetic and toxicity profiles directly trigger structural reoptimization. By seamlessly integrating autonomous execution with human guidance, OrchestRA democratizes therapeutic design, transforming drug discovery from a stochastic search to a programmable evidence-based engineering discipline.

</details>


### [18] [Multiple-play Stochastic Bandits with Prioritized Arm Capacity Sharing](https://arxiv.org/abs/2512.21626)
*Hong Xie,Haoran Gu,Yanying Huang,Tao Tan,Defu Lian*

Main category: cs.AI

TL;DR: 本文提出了一种针对LLM应用、边缘智能等资源分配问题的多臂赌博机变体，建立了优先资源共享模型，证明了遗憾下界，并设计了匹配下界的算法。


<details>
  <summary>Details</summary>
Motivation: 解决LLM应用、边缘智能等场景中的资源分配问题，这些场景中多个任务竞争有限资源，且资源分配遵循优先级权重原则，需要设计有效的在线学习算法。

Method: 提出MSB-PRS-OffOpt算法作为子程序，计算复杂度为O(MK³)，然后基于近似上置信界设计在线学习算法，解决优先资源共享机制下的非线性组合效用函数优化和学习挑战。

Result: 证明了实例独立遗憾下界Ω(α₁σ√KMT)和实例依赖遗憾下界Ω(α₁σ²M/Δ ln T)，设计的算法在实例独立情况下匹配下界至√K ln KT因子，实例依赖情况下匹配至α₁K²因子。

Conclusion: 成功建立了优先资源共享的多臂赌博机理论框架，解决了非线性组合效用函数的优化和学习技术挑战，为实际资源分配问题提供了理论保证和高效算法。

Abstract: This paper proposes a variant of multiple-play stochastic bandits tailored to resource allocation problems arising from LLM applications, edge intelligence, etc. The model is composed of $M$ arms and $K$ plays. Each arm has a stochastic number of capacities, and each unit of capacity is associated with a reward function. Each play is associated with a priority weight. When multiple plays compete for the arm capacity, the arm capacity is allocated in a larger priority weight first manner. Instance independent and instance dependent regret lower bounds of $Ω( α_1 σ\sqrt{KM T} )$ and $Ω(α_1 σ^2 \frac{M}Δ \ln T)$ are proved, where $α_1$ is the largest priority weight and $σ$ characterizes the reward tail. When model parameters are given, we design an algorithm named \texttt{MSB-PRS-OffOpt} to locate the optimal play allocation policy with a computational complexity of $O(MK^3)$. Utilizing \texttt{MSB-PRS-OffOpt} as a subroutine, an approximate upper confidence bound (UCB) based algorithm is designed, which has instance independent and instance dependent regret upper bounds matching the corresponding lower bound up to factors of $ \sqrt{K \ln KT }$ and $α_1 K^2$ respectively. To this end, we address nontrivial technical challenges arising from optimizing and learning under a special nonlinear combinatorial utility function induced by the prioritized resource sharing mechanism.

</details>


### [19] [Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets](https://arxiv.org/abs/2512.21775)
*Matyas Bohacek,Ignacio Vilanova Echavarri*

Main category: cs.AI

TL;DR: 提出合规评级方案(CRS)框架，用于评估生成式AI数据集在透明度、问责制和安全性方面的合规性，并发布开源Python库实现该框架。


<details>
  <summary>Details</summary>
Motivation: 生成式AI快速发展依赖大规模开源数据集，但这些数据集通常采用不受限制且不透明的收集方式。现有文献多关注GAI模型开发与应用，而忽视了数据集创建过程中的伦理和法律考量。数据集在共享、编辑和复制过程中，其来源、合法性和安全性信息常常丢失。

Method: 提出合规评级方案(CRS)框架，基于数据溯源技术开发开源Python库，评估数据集在透明度、问责制和安全性关键原则方面的合规性。该库既能评估现有数据集的CRS，也能指导负责任的新数据集抓取和构建。

Result: 开发了开源Python库，能够无缝集成到现有数据集处理和AI训练流程中。该库具有反应性和主动性双重功能，既能评估现有数据集合规性，也能指导新数据集的负责任构建。

Conclusion: CRS框架和开源库填补了生成式AI数据集伦理和法律评估的空白，通过数据溯源技术确保数据集透明度、问责制和安全性，促进负责任的数据集创建和使用。

Abstract: Generative Artificial Intelligence (GAI) has experienced exponential growth in recent years, partly facilitated by the abundance of large-scale open-source datasets. These datasets are often built using unrestricted and opaque data collection practices. While most literature focuses on the development and applications of GAI models, the ethical and legal considerations surrounding the creation of these datasets are often neglected. In addition, as datasets are shared, edited, and further reproduced online, information about their origin, legitimacy, and safety often gets lost. To address this gap, we introduce the Compliance Rating Scheme (CRS), a framework designed to evaluate dataset compliance with critical transparency, accountability, and security principles. We also release an open-source Python library built around data provenance technology to implement this framework, allowing for seamless integration into existing dataset-processing and AI training pipelines. The library is simultaneously reactive and proactive, as in addition to evaluating the CRS of existing datasets, it equally informs responsible scraping and construction of new datasets.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [20] [Composition Theorems for f-Differential Privacy](https://arxiv.org/abs/2512.21358)
*Natasha Fernandes,Annabelle McIver,Parastoo Sadeghi*

Main category: cs.CR

TL;DR: fDP与QIF信道模型等价，通过Galois连接建立联系，支持改进的隐私机制组合分析


<details>
  <summary>Details</summary>
Motivation: fDP作为新的隐私定义能提供更好的隐私损失预测，但需要更深入的理论基础来支持复杂隐私设计分析

Method: 通过统计假设检验基础建立fDP与QIF信道模型的等价性，使用两个偏序集之间的Galois连接来证明

Result: 证明了fDP与QIF信道模型在数学上的等价性，为fDP提供了新的理论基础

Conclusion: 这种等价性支持了fDP的新颖通用组合定理，能够改进复杂隐私设计的分析能力

Abstract: "f differential privacy" (fDP) is a recent definition for privacy privacy which can offer improved predictions of "privacy loss". It has been used to analyse specific privacy mechanisms, such as the popular Gaussian mechanism. In this paper we show how fDP's foundation in statistical hypothesis testing implies equivalence to the channel model of Quantitative Information Flow. We demonstrate this equivalence by a Galois connection between two partially ordered sets. This equivalence enables novel general composition theorems for fDP, supporting improved analysis for complex privacy designs.

</details>


### [21] [Power Side-Channel Analysis of the CVA6 RISC-V Core at the RTL Level Using VeriSide](https://arxiv.org/abs/2512.21362)
*Behnam Farnaghinejad,Antonio Porsia,Annachiara Ruospo,Alessandro Savino,Stefano Di Carlo,Ernesto Sanchez*

Main category: cs.CR

TL;DR: 该论文评估了CVA6 RISC-V核心的侧信道漏洞，通过VeriSide RTL级功耗分析框架分析软件AES加密，发现相关功耗分析(CPA)存在显著泄漏，可实现密钥恢复。


<details>
  <summary>Details</summary>
Motivation: 现代RISC-V处理器不仅需要功能正确性，还需要抵抗侧信道攻击。该研究旨在评估CVA6 RISC-V核心的侧信道漏洞，强调早期RTL评估对未来安全RISC-V设计的重要性。

Method: 使用VeriSide RTL级功耗分析框架，对CVA6 RISC-V核心进行侧信道分析，特别关注软件实现的AES加密，采用相关功耗分析(CPA)方法。

Result: 分析显示CVA6设计存在显著功耗泄漏，相关功耗分析(CPA)能够成功恢复加密密钥，证明了该核心对侧信道攻击的脆弱性。

Conclusion: 研究结果强调了在RISC-V处理器设计早期阶段进行RTL级侧信道评估的重要性，这对未来开发安全的RISC-V架构至关重要。

Abstract: Security in modern RISC-V processors demands more than functional correctness: It requires resilience to side-channel attacks. This paper evaluates the vulnerability of the side channel of the CVA6 RISC-V core by analyzing software-based AES encryption uses an RTL-level power profiling framework called VeriSide. This work represents that this design's Correlation Power Analysis (CPA) reveals significant leakage, enabling key recovery. These findings underscore the importance of early-stage RTL assessments in shaping future secure RISC-V designs.

</details>


### [22] [Key Length-Oriented Classification of Lightweight Cryptographic Algorithms for IoT Security](https://arxiv.org/abs/2512.21368)
*Arsalan Vahi*

Main category: cs.CR

TL;DR: 该研究对物联网中常用的对称轻量级密码进行安全评估调查，提出基于应用特性和密钥大小的分类法，发现密钥大小是轻量级密码安全性的关键参数。


<details>
  <summary>Details</summary>
Motivation: 现有调查主要从硬件/软件实现或性能评估角度研究轻量级密码技术，缺乏针对物联网环境特定安全方面的全面分析。本研究旨在填补这一空白，为资源受限的物联网应用提供轻量级密码安全性的整体理解。

Method: 1. 对物联网系统中常用的对称轻量级密码进行全面的安全评估调查；2. 提出两种分类法：基于物联网应用固有特性的分类法和基于密钥大小的安全级别评估分类法；3. 分析密钥大小对轻量级密码安全性的影响。

Result: 研究发现密钥大小是轻量级密码安全性的关键参数。使用少于128位密钥的密码被认为安全性较低，甚至不足以保护敏感数据。研究还提供了基于应用特性和密钥大小的分类框架。

Conclusion: 该研究填补了物联网轻量级密码安全评估的空白，强调了密钥大小在密码安全性中的重要性，为物联网应用选择合适的轻量级密码提供了安全评估框架和指导。

Abstract: The successful deployment of the Internet of Things (IoT) applications relies heavily on their robust security, and lightweight cryptography is considered an emerging solution in this context. While existing surveys have been examining lightweight cryptographic techniques from the perspective of hardware and software implementations or performance evaluation, there is a significant gap in addressing different security aspects specific to the IoT environment. This study aims to bridge this gap. This research presents a thorough survey focused on the security evaluation of symmetric lightweight ciphers commonly used in IoT systems. The objective of this study is to provide a holistic understanding of lightweight ciphers, emphasizing their security strength, which is an essential consideration for real-time and resource-constrained applications. Furthermore, we propose two taxonomies: one for classifying IoT applications based on their inherent characteristics, and another for evaluating security levels based on key size. Our findings indicate that key size is a critical parameter in the security of lightweight ciphers. Ciphers employing keys shorter than 128 bits are considered less secure or even insecure for protecting sensitive data

</details>


### [23] [A Systematic Review of Technical Defenses Against Software-Based Cheating in Online Multiplayer Games](https://arxiv.org/abs/2512.21377)
*Adwa Alangari,Ohoud Alharbi*

Main category: cs.CR

TL;DR: 本文对在线多人游戏中基于软件的作弊技术防御措施进行了系统性文献综述，将现有方法分为服务器端检测、客户端反篡改、内核级反作弊驱动和硬件辅助可信执行环境四类，并评估了各类方法在检测效果、性能开销、隐私影响和可扩展性方面的表现。


<details>
  <summary>Details</summary>
Motivation: 在线多人游戏中软件作弊问题日益严重，破坏了游戏公平性和玩家体验。现有反作弊技术分散且缺乏系统性评估，需要全面梳理各类方法的优缺点，为游戏开发者提供指导。

Method: 采用系统性文献综述方法，收集和分析相关研究文献，将反作弊技术分为四大类别：服务器端检测、客户端反篡改、内核级反作弊驱动、硬件辅助可信执行环境，并从检测效果、性能开销、隐私影响和可扩展性四个维度进行评估。

Result: 分析揭示了各类反作弊技术的关键权衡：内核级解决方案具有高可见性但存在隐私和稳定性风险；服务器端方法侵入性低但洞察力有限。硬件辅助TEEs在安全性和性能之间提供较好平衡，但部署成本较高。

Conclusion: 反作弊是一场持续的技术军备竞赛，需要设计健壮、抗对抗的反作弊系统。未来应关注隐私保护、性能优化和可扩展性的平衡，开发更有效的混合解决方案。

Abstract: This systematic literature review surveys technical defenses against software-based cheating in online multiplayer games. Categorizing existing approach-es into server-side detection, client-side anti-tamper, kernel-level anti-cheat drivers, and hardware-assisted TEEs. Each category is evaluated in terms of detection effectiveness, perfor-mance overhead, privacy im-pact, and scalability. The analy-sis highlights key trade-offs, particularly between the high visibility of kernel-level solutions and their privacy and stability risks, versus the low intrusive-ness but limited insight of server-side methods. Overall, the re-view emphasizes the ongoing arms race with cheaters and the need for robust, adversary-resistant anti-cheat designs.

</details>


### [24] [LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors](https://arxiv.org/abs/2512.21404)
*Tianwei Lan,Farid Naït-Abdesselam*

Main category: cs.CR

TL;DR: LAMLAD是一个利用大语言模型生成对抗样本攻击Android恶意软件检测系统的新框架，通过双智能体架构实现高效规避，攻击成功率高达97%，并提出相应防御策略。


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习技术在Android恶意软件检测中广泛应用且有效，但这些模型仍然容易受到对抗攻击的威胁。攻击者可以通过精心设计的特征级扰动来规避检测，同时保持恶意功能。现有对抗攻击方法在生成真实且功能保持的扰动方面存在局限性。

Method: LAMLAD采用双智能体架构：1) LLM操纵器，生成真实且功能保持的特征扰动；2) LLM分析器，指导扰动过程实现成功规避。框架集成了检索增强生成技术以提高效率和上下文感知能力，专注于Drebin风格的特征表示。

Result: 实验针对三种代表性的基于机器学习的Android恶意软件检测器进行评估，并与两种最先进的对抗攻击方法比较。LAMLAD攻击成功率高达97%，平均每个对抗样本仅需3次尝试。同时提出的基于对抗训练的防御策略将攻击成功率平均降低30%以上。

Conclusion: LAMLAD展示了利用大语言模型进行对抗攻击的有效性、高效性和适应性，为Android恶意软件检测系统的安全性提出了新的挑战。同时提出的防御策略显著增强了模型对LAMLAD式攻击的鲁棒性，为构建更安全的检测系统提供了方向。

Abstract: The rapid growth in both the scale and complexity of Android malware has driven the widespread adoption of machine learning (ML) techniques for scalable and accurate malware detection. Despite their effectiveness, these models remain vulnerable to adversarial attacks that introduce carefully crafted feature-level perturbations to evade detection while preserving malicious functionality. In this paper, we present LAMLAD, a novel adversarial attack framework that exploits the generative and reasoning capabilities of large language models (LLMs) to bypass ML-based Android malware classifiers. LAMLAD employs a dual-agent architecture composed of an LLM manipulator, which generates realistic and functionality-preserving feature perturbations, and an LLM analyzer, which guides the perturbation process toward successful evasion. To improve efficiency and contextual awareness, LAMLAD integrates retrieval-augmented generation (RAG) into the LLM pipeline. Focusing on Drebin-style feature representations, LAMLAD enables stealthy and high-confidence attacks against widely deployed Android malware detection systems. We evaluate LAMLAD against three representative ML-based Android malware detectors and compare its performance with two state-of-the-art adversarial attack methods. Experimental results demonstrate that LAMLAD achieves an attack success rate (ASR) of up to 97%, requiring on average only three attempts per adversarial sample, highlighting its effectiveness, efficiency, and adaptability in practical adversarial settings. Furthermore, we propose an adversarial training-based defense strategy that reduces the ASR by more than 30% on average, significantly enhancing model robustness against LAMLAD-style attacks.

</details>


### [25] [GoldenFuzz: Generative Golden Reference Hardware Fuzzing](https://arxiv.org/abs/2512.21524)
*Lichao Wu,Mohamadreza Rostami,Huimin Li,Nikhilesh Singh,Ahmad-Reza Sadeghi*

Main category: cs.CR

TL;DR: GoldenFuzz是一个两阶段硬件模糊测试框架，使用快速黄金参考模型加速测试用例精炼，显著提升覆盖率并发现新漏洞。


<details>
  <summary>Details</summary>
Motivation: 现代硬件系统日益复杂，存在大量漏洞。现有硬件模糊测试工具存在语义意识有限、测试精炼效率低、计算开销大等问题，需要更高效的解决方案。

Method: 采用两阶段框架：1) 使用快速的ISA兼容黄金参考模型作为数字孪生进行初步模糊测试和测试用例精炼；2) 在目标设备上进行深度架构探索和漏洞发现。通过连接精心选择的指令块构建测试用例，并利用高/低覆盖率样本的反馈驱动机制增强硬件状态探索能力。

Result: 在RocketChip、BOOM和CVA6三个RISC-V处理器上评估，GoldenFuzz在覆盖率、测试用例长度和计算开销方面显著优于现有模糊测试工具。发现了所有已知漏洞和五个新漏洞，其中四个CVSS v3严重性评分超过7/10，并在商业BA51-H核心扩展中发现两个未知漏洞。

Conclusion: GoldenFuzz通过部分解耦测试用例精炼与覆盖探索，利用快速黄金参考模型作为数字孪生，实现了高效的硬件模糊测试，显著提升了漏洞发现能力和测试效率。

Abstract: Modern hardware systems, driven by demands for high performance and application-specific functionality, have grown increasingly complex, introducing large surfaces for bugs and security-critical vulnerabilities. Fuzzing has emerged as a scalable solution for discovering such flaws. Yet, existing hardware fuzzers suffer from limited semantic awareness, inefficient test refinement, and high computational overhead due to reliance on slow device simulation.
  In this paper, we present GoldenFuzz, a novel two-stage hardware fuzzing framework that partially decouples test case refinement from coverage and vulnerability exploration. GoldenFuzz leverages a fast, ISA-compliant Golden Reference Model (GRM) as a ``digital twin'' of the Device Under Test (DUT). It fuzzes the GRM first, enabling rapid, low-cost test case refinement, accelerating deep architectural exploration and vulnerability discovery on DUT. During the fuzzing pipeline, GoldenFuzz iteratively constructs test cases by concatenating carefully chosen instruction blocks that balance the subtle inter- and intra-instructions quality. A feedback-driven mechanism leveraging insights from both high- and low-coverage samples further enhances GoldenFuzz's capability in hardware state exploration. Our evaluation of three RISC-V processors, RocketChip, BOOM, and CVA6, demonstrates that GoldenFuzz significantly outperforms existing fuzzers in achieving the highest coverage with minimal test case length and computational overhead. GoldenFuzz uncovers all known vulnerabilities and discovers five new ones, four of which are classified as highly severe with CVSS v3 severity scores exceeding seven out of ten. It also identifies two previously unknown vulnerabilities in the commercial BA51-H core extension.

</details>


### [26] [Enhancing Distributed Authorization With Lagrange Interpolation And Attribute-Based Encryption](https://arxiv.org/abs/2512.21525)
*Keshav Sinha,Sumitra,Richa Kumari,Akashdeep Bhardwaj,Shawon Rahman*

Main category: cs.CR

TL;DR: 本文提出了一种基于多方执行的安全数据共享机制，通过流密码加密和Shamir秘密共享方案，在减少服务器计算开销的同时确保数据机密性和访问授权。


<details>
  <summary>Details</summary>
Motivation: 当前安全环境中，用户需要访问大量机密数据，传统方法使用访问控制列表进行认证授权，但多个步骤会增加服务器的计算开销和响应时间。

Method: 提出两种方法：1) 使用基于对合函数的流密码加密文件数据；2) 使用Shamir秘密共享方案将对称密钥分割分发给用户，解密时通过二阶拉格朗日插值重构密钥。

Result: 基于加密解密时间、吞吐量、计算开销和安全性分析进行评估，结果表明该机制能有效减少服务器计算开销。

Conclusion: 提出的多方执行机制能够减少服务器计算负担，未来可用于组织内大规模安全数据共享。

Abstract: In todays security landscape, every user wants to access large amounts of data with confidentiality and authorization. To maintain confidentiality, various researchers have proposed several techniques. However, to access secure data, researchers use access control lists to grant authentication and provide authorization. The above several steps will increase the server's computation overhead and response time. To cope with these two problems, we proposed multiparty execution on the server. In this paper, we introduce two different approaches. The first approach is encryption, utilizing the Involution Function Based Stream Cipher to encrypt the file data. The second approach is key distribution, using the Shamir secret sharing scheme to divide and distribute the symmetric key to every user. The decryption process required key reconstruction, which used second order Lagrange interpolation to reconstruct the secret keys from the hidden points. The process will reduce the server's computational overhead. The results are evaluated based on the encryption and decryption time, throughput, computational overhead, and security analysis. In the future, the proposed mechanism will be used to share large-scale, secure data within the organization.

</details>


### [27] [Verifiable Passkey: The Decentralized Authentication Standard](https://arxiv.org/abs/2512.21663)
*Aditya Mitra,Sibi Chakkaravarthy Sethuraman*

Main category: cs.CR

TL;DR: 本文提出了一种名为"可验证通行密钥"的新标准，旨在解决FIDO2通行密钥存储空间有限和联邦认证隐私风险的问题，允许用户在多个平台间安全使用通行密钥而无需担心隐私泄露或用户追踪。


<details>
  <summary>Details</summary>
Motivation: FIDO2通行密钥虽然提供了防钓鱼的密码认证，但存在两个主要问题：1) 安全存储模块（如TPM或物理安全密钥）的存储空间有限，限制了用户可创建的通行密钥数量；2) 使用联邦认证和单点登录（SSO）时，身份提供商（IdP）可能追踪用户在不同服务间的活动，带来显著的隐私风险。

Method: 本文提出了一种名为"可验证通行密钥"的新标准。该标准允许用户将针对可验证凭证发行者创建的通行密钥安全地用于任何平台，而不会暴露用户的隐私信息或允许用户追踪。

Result: 通过引入可验证通行密钥标准，用户可以在不牺牲隐私的前提下，克服传统通行密钥存储限制和联邦认证的隐私风险问题。

Conclusion: 可验证通行密钥标准为解决当前密码认证系统中的存储限制和隐私风险问题提供了一种创新解决方案，能够在保护用户隐私的同时实现跨平台的身份验证。

Abstract: Passwordless authentication has revolutionized the way we authenticate across various websites and services. FIDO2 Passkeys, is one of the most-widely adopted standards of passwordless authentication that promises phishing-resistance. However, like any other authentication system, passkeys require the user details to be saved on a centralized server, also known as Relying Party (RP) Server. This has led users to create a new passkey for every new online account. While this just works for a limited number of online accounts, the limited storage space of secure storage modules like TPM or a physical security key limits the number of passkeys a user can have. For example, Yubico Yubikey 5 (firmware 5.0 - 5.6) offers to store only 25 passkeys, while firmware 5.7+ allows to store upto 100 [1]. To overcome this problem, one of the widely adopted approaches is to use Federated Authentication with Single Sign On (SSO). This allows the user to create a passkey for the Identity Provider (IdP) and use the IdP to authenticate to all service providers. This proves to be a significant privacy risk since the IdP can potentially track users across different services. To overcome these limitations, this paper introduces a novel standard 'Verifiable Passkey' that allows the user to use Passkeys created for a Verifiable Credential issuer across any platform without risking privacy or user tracking.

</details>


### [28] [Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation](https://arxiv.org/abs/2512.21681)
*Tian Li,Bo Lin,Shangwen Wang,Yusong Tan*

Main category: cs.CR

TL;DR: 论文首次系统性地研究了检索增强代码生成(RACG)中针对检索器的后门攻击威胁，开发了VenomRACG攻击方法，发现仅需注入相当于知识库0.05%的漏洞代码，就能在51.29%的情况下让后门检索器将漏洞代码排在前5位，导致GPT-4o等模型在40%以上的目标场景中生成漏洞代码。


<details>
  <summary>Details</summary>
Motivation: 检索增强代码生成(RACG)在软件开发中日益普及，但其安全影响尚未得到充分探索。现有攻击方法要么效果太差无法构成真实威胁，要么容易被现有防御机制检测到，这阻碍了对该威胁的现实评估。

Method: 开发了VenomRACG——一种新型强大且隐蔽的攻击方法，使中毒样本在统计上与良性代码无法区分，从而在所有评估的防御机制中保持低检测率。使用该方法评估了后门攻击的实际威胁。

Result: 仅注入相当于整个知识库大小0.05%的漏洞代码，攻击者就能成功操纵后门检索器在51.29%的情况下将漏洞代码排在前5位。这导致GPT-4o等模型在超过40%的目标场景中生成漏洞代码，同时系统整体性能不受影响。

Conclusion: 检索器后门攻击不是理论问题，而是对软件开发生态系统的实际威胁，现有防御机制对此视而不见，迫切需要采取强有力的安全措施。

Abstract: Retrieval-Augmented Code Generation (RACG) is increasingly adopted to enhance Large Language Models for software development, yet its security implications remain dangerously underexplored. This paper conducts the first systematic exploration of a critical and stealthy threat: backdoor attacks targeting the retriever component, which represents a significant supply-chain vulnerability. It is infeasible to assess this threat realistically, as existing attack methods are either too ineffective to pose a real danger or are easily detected by state-of-the-art defense mechanisms spanning both latent-space analysis and token-level inspection, which achieve consistently high detection rates. To overcome this barrier and enable a realistic analysis, we first developed VenomRACG, a new class of potent and stealthy attack that serves as a vehicle for our investigation. Its design makes poisoned samples statistically indistinguishable from benign code, allowing the attack to consistently maintain low detectability across all evaluated defense mechanisms. Armed with this capability, our exploration reveals a severe vulnerability: by injecting vulnerable code equivalent to only 0.05% of the entire knowledge base size, an attacker can successfully manipulate the backdoored retriever to rank the vulnerable code in its top-5 results in 51.29% of cases. This translates to severe downstream harm, causing models like GPT-4o to generate vulnerable code in over 40% of targeted scenarios, while leaving the system's general performance intact. Our findings establish that retriever backdooring is not a theoretical concern but a practical threat to the software development ecosystem that current defenses are blind to, highlighting the urgent need for robust security measures.

</details>


### [29] [Raster Domain Text Steganography: A Unified Framework for Multimodal Secure Embedding](https://arxiv.org/abs/2512.21698)
*A V Uday Kiran Kandala*

Main category: cs.CR

TL;DR: 提出了一种统一的栅格域隐写框架GPC，能够在文本字形渲染后的像素空间中嵌入文本、图像、音频和视频等异构数据，通过微调字形内部墨像素的基数来编码信息。


<details>
  <summary>Details</summary>
Motivation: 现有基于语言或结构文本的隐写方法存在局限性，需要一种能够在普通文本中嵌入多种类型数据的视觉隐蔽方法，利用文本渲染的确定性特性实现可靠的数据隐藏。

Method: 在字体栅格化后操作，修改确定性文本渲染管道产生的位图。每个字形作为隐蔽编码单元，通过微调内部墨像素的基数来表达有效载荷值。将多模态输入（图像强度、音频特征、视频帧值）归一化为有界整数序列并分布在多个字形中。

Result: 该方法计算轻量，基于确定性栅格行为，能够实现视觉不可感知的数据嵌入。通过重新栅格化封面文本、减去规范字形栅格、进行像素计数分析来恢复有效载荷值。

Conclusion: GPC框架使普通文本能够作为多模态数据嵌入的视觉隐蔽媒介，为文本到文本嵌入提供了统一解决方案，并可扩展到多模态输入。

Abstract: This work introduces a unified raster domain steganographic framework, termed as the Glyph Perturbation Cardinality (GPC) framework, capable of embedding heterogeneous data such as text, images, audio, and video directly into the pixel space of rendered textual glyphs. Unlike linguistic or structural text based steganography, the proposed method operates exclusively after font rasterization, modifying only the bitmap produced by a deterministic text rendering pipeline. Each glyph functions as a covert encoding unit, where a payload value is expressed through the cardinality of minimally perturbed interior ink pixels. These minimal intensity increments remain visually imperceptible while forming a stable and decodable signal. The framework is demonstrated for text to text embedding and generalized to multimodal inputs by normalizing image intensities, audio derived scalar features, and video frame values into bounded integer sequences distributed across glyphs. Decoding is achieved by re-rasterizing the cover text, subtracting canonical glyph rasters, and recovering payload values via pixel count analysis. The approach is computationally lightweight, and grounded in deterministic raster behavior, enabling ordinary text to serve as a visually covert medium for multimodal data embedding.

</details>


### [30] [Assessing the Effectiveness of Membership Inference on Generative Music](https://arxiv.org/abs/2512.21762)
*Kurtis Chow,Omar Samiullah,Vinesh Sridhar,Hewen Zhang*

Main category: cs.CR

TL;DR: 该论文研究了成员推理攻击在生成式音乐模型上的有效性，发现现有攻击方法对MuseGAN等音乐生成模型效果有限，音乐数据对已知成员推理技术具有较强抵抗力。


<details>
  <summary>Details</summary>
Motivation: 生成式AI快速发展引发了对用户隐私和版权训练数据的关注。成员推理攻击能识别哪些数据被用于训练模型，这对隐私保护和版权验证都很重要。然而，目前没有研究探讨成员推理攻击在生成式音乐上的效果，考虑到音乐产业价值巨大且艺术家需要保护版权，这是一个紧迫的研究问题。

Method: 对流行的生成式音乐模型MuseGAN应用多种现有的成员推理攻击方法，进行初步研究，评估这些攻击在音乐生成领域的有效性。

Result: 研究发现音乐数据对已知的成员推理技术具有相当的抵抗力，与之前生成式音频成员推理攻击的研究结果相似，现有攻击方法在生成式音乐模型上效果有限。

Conclusion: 生成式音乐模型对当前的成员推理攻击具有较强抵抗力，但考虑到音乐产业的重要性和版权保护需求，这一领域需要进一步深入研究。

Abstract: Generative AI systems are quickly improving, now able to produce believable output in several modalities including images, text, and audio. However, this fast development has prompted increased scrutiny concerning user privacy and the use of copyrighted works in training. A recent attack on machine-learning models called membership inference lies at the crossroads of these two concerns. The attack is given as input a set of records and a trained model and seeks to identify which of those records may have been used to train the model. On one hand, this attack can be used to identify user data used to train a model, which may violate their privacy especially in sensitive applications such as models trained on medical data. On the other hand, this attack can be used by rights-holders as evidence that a company used their works without permission to train a model.
  Remarkably, it appears that no work has studied the effect of membership inference attacks (MIA) on generative music. Given that the music industry is worth billions of dollars and artists would stand to gain from being able to determine if their works were being used without permission, we believe this is a pressing issue to study. As such, in this work we begin a preliminary study into whether MIAs are effective on generative music. We study the effect of several existing attacks on MuseGAN, a popular and influential generative music model. Similar to prior work on generative audio MIAs, our findings suggest that music data is fairly resilient to known membership inference techniques.

</details>


### [31] [Securing Cross-Domain Internet of Drones: An RFF-PUF Allied Authenticated Key Exchange Protocol With Over-the-Air Enrollment](https://arxiv.org/abs/2512.21827)
*Xuanyu Chen,Yue Zheng,Junqing Zhang,Guanxiong Shen,Chip-Hong Chang*

Main category: cs.CR

TL;DR: 提出一种轻量级无人机互认证机制，结合射频指纹和物理不可克隆函数技术，实现安全的无人机间及无人机与地面站通信，无需第三方参与或秘密存储。


<details>
  <summary>Details</summary>
Motivation: 无人机物联网面临跨异构不信任域的安全通信挑战，现有方案存在计算开销大、依赖第三方、需在资源受限无人机中存储秘密、要求严格注册环境等问题，难以适应动态跨域部署。

Method: 集成射频指纹和物理不可克隆函数技术：RFF用于设备识别实现空中注册，PUF作为信任根建立互认证，并结合一次性密码本加密实现临时密钥生成，消除无人机内秘密存储需求。

Result: 非正式安全分析和ProVerif形式化验证均证明协议能抵抗常见安全攻击，在安全特性、计算开销、通信开销和存储开销方面优于现有无人机物联网认证方案。

Conclusion: 提出的轻量级互认证机制解决了无人机物联网跨域部署的安全挑战，通过RFF和PUF技术的集成实现了安全、高效、无需秘密存储的认证方案。

Abstract: The Internet of Drones (IoD) is an emerging and crucial paradigm enabling advanced applications that require seamless, secure communication across heterogeneous and untrusted domains. In such environments, access control and the transmission of sensitive data pose significant security challenges for IoD systems, necessitating the design of lightweight mutual authentication and key exchange protocols. Existing solutions are often hampered by high computation overhead, reliance on third parties, the requirement for secret storage in resource-constrained drones, and the need for a strictly controlled enrollment environment. These limitations make them impractical for dynamic cross-domain deployment. To address these limitations, we propose a lightweight mutual authentication mechanism that integrates Radio Frequency Fingerprint (RFF) and Physical Unclonable Function (PUF) technologies for secure drone-to-drone (D2D) and drone-to-ground station server (D2G) communication. RFF-based device identification is used to achieve over-the-air (OTA) enrollment, while the PUF serves as the root of trust for establishing mutual authentication among communication parties. Additionally, the on-the-fly key generation capability of the PUF is co-designed with One-Time-Pad (OTP) encryption to realize ephemeral keying and eliminate the need for storing secrets within drones. Both informal security analysis and ProVerif-based formal security verification comprehensively demonstrate the resilience of our protocol against common security attacks. The proposed protocol also outperforms existing IoD authentication schemes in terms of security features, as well as computation, communication, and storage overhead.

</details>


### [32] [Abstraction of Trusted Execution Environments as the Missing Layer for Broad Confidential Computing Adoption: A Systematization of Knowledge](https://arxiv.org/abs/2512.22090)
*Quentin Michaud,Sara Ramezanian,Dhouha Ayed,Olivier Levillain,Joaquin Garcia-Alfaro*

Main category: cs.CR

TL;DR: 本文系统化分析了可信执行环境（TEEs）技术，对现有TEE生态系统进行分类，并研究了不同的抽象层设计，指出WebAssembly是支持最多特性的有前景方法，同时提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 可信执行环境（TEEs）能够保护敏感代码和数据免受操作系统、虚拟机监控程序或其他不可信软件的攻击。目前存在多种不同的TEE解决方案，每种都有不同的特性。抽象层旨在统一生态系统，让应用开发者和系统管理员能够尽可能广泛和高效地利用机密计算。

Method: 首先概述代表性的可用TEE技术，描述和总结每个TEE生态系统，根据其主要设计选择进行分类。然后提出一个知识系统化框架，重点关注围绕每个设计选择的不同抽象层。描述每个设计的基础技术，以及每个抽象层的内部工作原理和特性。

Result: 研究发现现有抽象层解决方案存在改进机会，同时突出显示WebAssembly是支持最大特性集的有前景方法。研究揭示了不同TEE技术和抽象层的设计模式、优缺点。

Conclusion: 研究为机密计算生态系统的未来发展提供了方向，讨论了未来抽象层可能如何演变和与机密计算生态系统集成，指出了需要进一步研究的关键领域。

Abstract: Trusted Execution Environments (TEEs) protect sensitive code and data from the operating system, hypervisor, or other untrusted software. Different solutions exist, each proposing different features. Abstraction layers aim to unify the ecosystem, allowing application developers and system administrators to leverage confidential computing as broadly and efficiently as possible. We start with an overview of representative available TEE technologies. We describe and summarize each TEE ecosystem, classifying them in different categories depending on their main design choices. Then, we propose a systematization of knowledge focusing on different abstraction layers around each design choice. We describe the underlying technologies of each design, as well as the inner workings and features of each abstraction layer. Our study reveals opportunities for improving existing abstraction layer solutions. It also highlights WebAssembly, a promising approach that supports the largest set of features. We close with a discussion on future directions for research, such as how future abstraction layers may evolve and integrate with the confidential computing ecosystem.

</details>

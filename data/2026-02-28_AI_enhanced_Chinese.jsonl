{"id": "2602.22246", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.22246", "abs": "https://arxiv.org/abs/2602.22246", "authors": ["Guangnian Wan", "Qi Li", "Gongfan Fang", "Xinyin Ma", "Xinchao Wang"], "title": "Self-Purification Mitigates Backdoors in Multimodal Diffusion Language Models", "comment": null, "summary": "Multimodal Diffusion Language Models (MDLMs) have recently emerged as a competitive alternative to their autoregressive counterparts. Yet their vulnerability to backdoor attacks remains largely unexplored. In this work, we show that well-established data-poisoning pipelines can successfully implant backdoors into MDLMs, enabling attackers to manipulate model behavior via specific triggers while maintaining normal performance on clean inputs. However, defense strategies effective to these models are yet to emerge. To bridge this gap, we introduce a backdoor defense framework for MDLMs named DiSP (Diffusion Self-Purification). DiSP is driven by a key observation: selectively masking certain vision tokens at inference time can neutralize a backdoored model's trigger-induced behaviors and restore normal functionality. Building on this, we purify the poisoned dataset using the compromised model itself, then fine-tune the model on the purified data to recover it to a clean one. Given such a specific design, DiSP can remove backdoors without requiring any auxiliary models or clean reference data. Extensive experiments demonstrate that our approach effectively mitigates backdoor effects, reducing the attack success rate (ASR) from over 90% to typically under 5%, while maintaining model performance on benign tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDiSP\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u63a9\u7801\u89c6\u89c9token\u548c\u81ea\u51c0\u5316\u6570\u636e\u6765\u9632\u5fa1\u591a\u6a21\u6001\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u540e\u95e8\u653b\u51fb\uff0c\u65e0\u9700\u8f85\u52a9\u6a21\u578b\u6216\u5e72\u51c0\u6570\u636e\u5373\u53ef\u5c06\u653b\u51fb\u6210\u529f\u7387\u4ece90%\u4ee5\u4e0a\u964d\u81f35%\u4ee5\u4e0b\u3002", "motivation": "\u591a\u6a21\u6001\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff08MDLMs\uff09\u4f5c\u4e3a\u81ea\u56de\u5f52\u6a21\u578b\u7684\u6709\u529b\u7ade\u4e89\u8005\uff0c\u5176\u540e\u95e8\u653b\u51fb\u8106\u5f31\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u867d\u7136\u73b0\u6709\u6570\u636e\u6295\u6bd2\u65b9\u6cd5\u80fd\u6210\u529f\u690d\u5165\u540e\u95e8\uff0c\u4f46\u9488\u5bf9\u8fd9\u7c7b\u6a21\u578b\u7684\u6709\u6548\u9632\u5fa1\u7b56\u7565\u4ecd\u7136\u7f3a\u4e4f\u3002", "method": "\u63d0\u51faDiSP\uff08Diffusion Self-Purification\uff09\u9632\u5fa1\u6846\u67b6\uff0c\u6838\u5fc3\u89c2\u5bdf\u662f\uff1a\u5728\u63a8\u7406\u65f6\u9009\u62e9\u6027\u63a9\u7801\u67d0\u4e9b\u89c6\u89c9token\u53ef\u4ee5\u4e2d\u548c\u540e\u95e8\u6a21\u578b\u7684\u89e6\u53d1\u884c\u4e3a\u3002\u57fa\u4e8e\u6b64\uff0c\u4f7f\u7528\u88ab\u653b\u51fb\u6a21\u578b\u81ea\u8eab\u51c0\u5316\u4e2d\u6bd2\u6570\u636e\u96c6\uff0c\u7136\u540e\u5728\u51c0\u5316\u6570\u636e\u4e0a\u5fae\u8c03\u6a21\u578b\u4ee5\u6062\u590d\u4e3a\u5e72\u51c0\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDiSP\u80fd\u6709\u6548\u7f13\u89e3\u540e\u95e8\u6548\u5e94\uff0c\u5c06\u653b\u51fb\u6210\u529f\u7387\u4ece\u8d85\u8fc790%\u964d\u81f3\u901a\u5e38\u4f4e\u4e8e5%\uff0c\u540c\u65f6\u5728\u826f\u6027\u4efb\u52a1\u4e0a\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u8f85\u52a9\u6a21\u578b\u6216\u5e72\u51c0\u53c2\u8003\u6570\u636e\u3002", "conclusion": "DiSP\u6846\u67b6\u4e3a\u591a\u6a21\u6001\u6269\u6563\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u540e\u95e8\u9632\u5fa1\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u6a21\u578b\u81ea\u51c0\u5316\u7684\u65b9\u5f0f\u5728\u4e0d\u4f9d\u8d56\u5916\u90e8\u8d44\u6e90\u7684\u60c5\u51b5\u4e0b\u6210\u529f\u79fb\u9664\u540e\u95e8\uff0c\u4e3a\u8fd9\u7c7b\u6a21\u578b\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u4fdd\u969c\u3002"}}
{"id": "2602.22780", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.22780", "abs": "https://arxiv.org/abs/2602.22780", "authors": ["Qingyuan Zhang"], "title": "An Artificial Intelligence Framework for Joint Structural-Temporal Load Forecasting in Cloud Native Platforms", "comment": null, "summary": "This study targets cloud native environments where microservice invocation relations are complex, load fluctuations are multi-scale and superimposed, and cross-service impacts are significant. We propose a structured temporal joint load prediction framework oriented to microservice topology. The method represents the system as a coupled entity of a time-evolving service invocation graph and multivariate load sequences. It constructs neighborhood-aggregated and global summarized views based on service level observations. This forms layered load representations across instance, service, and cluster levels. A unified sequence encoder models multi-scale historical context. To strengthen the expression of invocation dependencies, the framework introduces a lightweight structural prior into attention computation. This enables more effective capture of load propagation and accumulation along invocation chains, while maintaining consistent modeling of local bursts and overall trends. The training objective adopts a multi-objective regression strategy that jointly optimizes service level and cluster level predictions to improve cross-granularity stability. We further conduct single-factor sensitivity analyses on key structural and training hyperparameters. We systematically examine the effects of time window length, encoding depth, and regularization strength. The results support the necessity of multi-granularity fusion and structural injection and clarify their effective configuration ranges. Overall, the framework provides a reusable modeling paradigm and implementation path for capacity assessment, resource orchestration, and runtime situational understanding in cloud environments.", "AI": {"tldr": "\u63d0\u51fa\u9762\u5411\u5fae\u670d\u52a1\u62d3\u6251\u7684\u7ed3\u6784\u5316\u65f6\u5e8f\u8054\u5408\u8d1f\u8f7d\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7c92\u5ea6\u878d\u5408\u548c\u7ed3\u6784\u5148\u9a8c\u589e\u5f3a\uff0c\u89e3\u51b3\u4e91\u539f\u751f\u73af\u5883\u4e2d\u5fae\u670d\u52a1\u8c03\u7528\u5173\u7cfb\u590d\u6742\u3001\u8d1f\u8f7d\u6ce2\u52a8\u591a\u5c3a\u5ea6\u53e0\u52a0\u7684\u95ee\u9898\u3002", "motivation": "\u4e91\u539f\u751f\u73af\u5883\u4e2d\u5fae\u670d\u52a1\u8c03\u7528\u5173\u7cfb\u590d\u6742\uff0c\u8d1f\u8f7d\u6ce2\u52a8\u5177\u6709\u591a\u5c3a\u5ea6\u53e0\u52a0\u7279\u6027\uff0c\u8de8\u670d\u52a1\u5f71\u54cd\u663e\u8457\uff0c\u4f20\u7edf\u8d1f\u8f7d\u9884\u6d4b\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5efa\u6a21\u8fd9\u4e9b\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u5c06\u7cfb\u7edf\u8868\u793a\u4e3a\u65f6\u95f4\u6f14\u5316\u7684\u670d\u52a1\u8c03\u7528\u56fe\u4e0e\u591a\u5143\u8d1f\u8f7d\u5e8f\u5217\u7684\u8026\u5408\u5b9e\u4f53\uff0c\u6784\u5efa\u57fa\u4e8e\u670d\u52a1\u7ea7\u522b\u89c2\u6d4b\u7684\u90bb\u57df\u805a\u5408\u548c\u5168\u5c40\u6c47\u603b\u89c6\u56fe\uff0c\u5f62\u6210\u5b9e\u4f8b\u3001\u670d\u52a1\u548c\u96c6\u7fa4\u4e09\u4e2a\u5c42\u6b21\u7684\u8d1f\u8f7d\u8868\u793a\u3002\u4f7f\u7528\u7edf\u4e00\u5e8f\u5217\u7f16\u7801\u5668\u5efa\u6a21\u591a\u5c3a\u5ea6\u5386\u53f2\u4e0a\u4e0b\u6587\uff0c\u5728\u6ce8\u610f\u529b\u8ba1\u7b97\u4e2d\u5f15\u5165\u8f7b\u91cf\u7ea7\u7ed3\u6784\u5148\u9a8c\u4ee5\u589e\u5f3a\u8c03\u7528\u4f9d\u8d56\u8868\u8fbe\u3002", "result": "\u901a\u8fc7\u5355\u56e0\u7d20\u654f\u611f\u6027\u5206\u6790\u9a8c\u8bc1\u4e86\u591a\u7c92\u5ea6\u878d\u5408\u548c\u7ed3\u6784\u6ce8\u5165\u7684\u5fc5\u8981\u6027\uff0c\u660e\u786e\u4e86\u65f6\u95f4\u7a97\u53e3\u957f\u5ea6\u3001\u7f16\u7801\u6df1\u5ea6\u548c\u6b63\u5219\u5316\u5f3a\u5ea6\u7b49\u5173\u952e\u8d85\u53c2\u6570\u7684\u6709\u6548\u914d\u7f6e\u8303\u56f4\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4e91\u73af\u5883\u4e2d\u7684\u5bb9\u91cf\u8bc4\u4f30\u3001\u8d44\u6e90\u7f16\u6392\u548c\u8fd0\u884c\u65f6\u6001\u52bf\u7406\u89e3\u63d0\u4f9b\u4e86\u53ef\u91cd\u7528\u7684\u5efa\u6a21\u8303\u5f0f\u548c\u5b9e\u73b0\u8def\u5f84\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u6355\u83b7\u8c03\u7528\u94fe\u4e0a\u7684\u8d1f\u8f7d\u4f20\u64ad\u548c\u7d2f\u79ef\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u5c40\u90e8\u7a81\u53d1\u548c\u6574\u4f53\u8d8b\u52bf\u7684\u4e00\u81f4\u6027\u5efa\u6a21\u3002"}}
{"id": "2602.22852", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.22852", "abs": "https://arxiv.org/abs/2602.22852", "authors": ["Oliver Larsson", "Thijs Metsch", "Cristian Klein", "Erik Elmroth"], "title": "Workload Buoyancy: Keeping Apps Afloat by Identifying Shared Resource Bottlenecks", "comment": "14 pages, 10 figures, 4 tables", "summary": "Modern multi-tenant, hardware-heterogeneous computing environments pose significant challenges for effective workload orchestration. Simple heuristics for assessing workload performance, such as CPU utilization or application-level metrics, are often insufficient to capture the complex performance dynamics arising from resource contention and noisy-neighbor effects. In such environments, performance bottlenecks may emerge in any shared system resource, leading to unexpected and difficult-to-diagnose degradation.\n  This paper introduces buoyancy, a novel abstraction for characterizing workload performance in multi-tenant systems. Unlike traditional approaches, buoyancy integrates application-level metrics with system-level insights of shared resource contention to provide a holistic view of performance dynamics. By explicitly capturing bottlenecks and headroom across multiple resources, buoyancy facilitates resource-aware and application-aware orchestration in a manner that is intuitive, extensible, and generalizable across heterogeneous platforms. We evaluate buoyancy using representative multi-tenant workloads to illustrate its ability to expose performance-limiting resource interactions. Buoyancy provides a 19.3% better indication of bottlenecks compared to traditional heuristics on average. We additionally show how buoyancy can act as a drop-in replacement for conventional performance metrics, enabling improved observability and more informed scheduling and optimization decisions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\"\u6d6e\u529b\"\u7684\u65b0\u62bd\u8c61\u6982\u5ff5\uff0c\u7528\u4e8e\u5728\u591a\u79df\u6237\u5f02\u6784\u8ba1\u7b97\u73af\u5883\u4e2d\u8868\u5f81\u5de5\u4f5c\u8d1f\u8f7d\u6027\u80fd\uff0c\u901a\u8fc7\u6574\u5408\u5e94\u7528\u7ea7\u6307\u6807\u548c\u7cfb\u7edf\u7ea7\u8d44\u6e90\u4e89\u7528\u6d1e\u5bdf\uff0c\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u5de5\u4f5c\u8d1f\u8f7d\u6027\u80fd\u8bc4\u4f30\u3002", "motivation": "\u73b0\u4ee3\u591a\u79df\u6237\u5f02\u6784\u8ba1\u7b97\u73af\u5883\u4e2d\uff0c\u4f20\u7edf\u7684\u5de5\u4f5c\u8d1f\u8f7d\u6027\u80fd\u8bc4\u4f30\u65b9\u6cd5\uff08\u5982CPU\u5229\u7528\u7387\u6216\u5e94\u7528\u7ea7\u6307\u6807\uff09\u5f80\u5f80\u65e0\u6cd5\u6355\u6349\u8d44\u6e90\u4e89\u7528\u548c\"\u566a\u58f0\u90bb\u5c45\"\u6548\u5e94\u5e26\u6765\u7684\u590d\u6742\u6027\u80fd\u52a8\u6001\uff0c\u5bfc\u81f4\u6027\u80fd\u74f6\u9888\u96be\u4ee5\u8bca\u65ad\u548c\u9884\u6d4b\u3002", "method": "\u63d0\u51fa\"\u6d6e\u529b\"\u62bd\u8c61\u6982\u5ff5\uff0c\u6574\u5408\u5e94\u7528\u7ea7\u6027\u80fd\u6307\u6807\u548c\u7cfb\u7edf\u7ea7\u5171\u4eab\u8d44\u6e90\u4e89\u7528\u6d1e\u5bdf\uff0c\u663e\u5f0f\u6355\u83b7\u8de8\u591a\u4e2a\u8d44\u6e90\u7684\u74f6\u9888\u548c\u4f59\u91cf\uff0c\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u6027\u80fd\u52a8\u6001\u89c6\u56fe\u3002", "result": "\u4e0e\u4f20\u7edf\u542f\u53d1\u5f0f\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6d6e\u529b\u5728\u74f6\u9888\u6307\u793a\u65b9\u9762\u5e73\u5747\u63d0\u9ad8\u4e8619.3%\uff0c\u80fd\u591f\u66f4\u597d\u5730\u66b4\u9732\u6027\u80fd\u9650\u5236\u6027\u8d44\u6e90\u4ea4\u4e92\uff0c\u53ef\u4f5c\u4e3a\u4f20\u7edf\u6027\u80fd\u6307\u6807\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u6539\u5584\u53ef\u89c2\u6d4b\u6027\u548c\u8c03\u5ea6\u51b3\u7b56\u3002", "conclusion": "\u6d6e\u529b\u63d0\u4f9b\u4e86\u4e00\u79cd\u76f4\u89c2\u3001\u53ef\u6269\u5c55\u4e14\u53ef\u6cdb\u5316\u7684\u62bd\u8c61\uff0c\u80fd\u591f\u4fc3\u8fdb\u8d44\u6e90\u611f\u77e5\u548c\u5e94\u7528\u7a0b\u5e8f\u611f\u77e5\u7684\u7f16\u6392\uff0c\u5728\u591a\u79df\u6237\u5f02\u6784\u8ba1\u7b97\u73af\u5883\u4e2d\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u6027\u80fd\u7ba1\u7406\u548c\u4f18\u5316\u3002"}}
{"id": "2602.22562", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.22562", "abs": "https://arxiv.org/abs/2602.22562", "authors": ["Taoran Li", "Varun Chandrasekaran", "Zhiyuan Yu"], "title": "Layer-Targeted Multilingual Knowledge Erasure in Large Language Models", "comment": null, "summary": "Recent work has demonstrated that machine unlearning in Large Language Models (LLMs) fails to generalize across languages: knowledge erased in one language frequently remains accessible through others. However, the underlying cause of this failure and a principled solution remain open. In this work, we identify intervention depth as the key factor determining multilingual generalization. Through systematic layer-wise experiments, we characterize two distinct failure modes: shallow-layer interventions achieve erasure but collapse multilingual capabilities in held-out languages, while deep-layer interventions preserve utility but fail to erase target knowledge even in source languages. These findings reveal that the choice of intervention layer is not a free parameter; it fundamentally determines whether multilingual unlearning succeeds. We propose MUTE (Multilingual Unlearning via Targeted Erasure), a framework that uses Centered Kernel Alignment (CKA) and Linguistic Regions Development Score (LRDS) to identify intermediate, language-agnostic layers where cross-lingual representations converge. By restricting unlearning updates to these layers, MUTE achieves robust multilingual knowledge erasure while optimizing on only a small set of source languages. Extensive experiments across three LLM architectures and three unlearning algorithms validate our approach, with mechanistic analysis via Logit Lens probing confirming genuine knowledge removal rather than output-level suppression.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u673a\u5668\u9057\u5fd8\u5728\u8de8\u8bed\u8a00\u6cdb\u5316\u4e0a\u5931\u8d25\uff0c\u63d0\u51fa\u5e72\u9884\u6df1\u5ea6\u662f\u5173\u952e\u56e0\u7d20\uff0c\u5f00\u53d1\u4e86MUTE\u6846\u67b6\u901a\u8fc7\u8bc6\u522b\u8bed\u8a00\u65e0\u5173\u5c42\u5b9e\u73b0\u591a\u8bed\u8a00\u77e5\u8bc6\u64e6\u9664", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u673a\u5668\u9057\u5fd8\u5728\u8de8\u8bed\u8a00\u6cdb\u5316\u4e0a\u5b58\u5728\u5931\u8d25\uff1a\u5728\u4e00\u4e2a\u8bed\u8a00\u4e2d\u64e6\u9664\u7684\u77e5\u8bc6\u7ecf\u5e38\u5728\u5176\u4ed6\u8bed\u8a00\u4e2d\u4ecd\u7136\u53ef\u8bbf\u95ee\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u5931\u8d25\u7684\u6839\u672c\u539f\u56e0\u548c\u539f\u5219\u6027\u89e3\u51b3\u65b9\u6848\u4ecd\u7136\u672a\u77e5", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u5206\u5c42\u5b9e\u9a8c\uff0c\u8bc6\u522b\u5e72\u9884\u6df1\u5ea6\u4e3a\u5173\u952e\u56e0\u7d20\u3002\u63d0\u51faMUTE\u6846\u67b6\uff0c\u4f7f\u7528\u4e2d\u5fc3\u6838\u5bf9\u9f50\u548c\u8bed\u8a00\u533a\u57df\u53d1\u5c55\u5206\u6570\u6765\u8bc6\u522b\u4e2d\u95f4\u3001\u8bed\u8a00\u65e0\u5173\u7684\u5c42\uff0c\u5728\u8fd9\u4e9b\u5c42\u4e2d\u8de8\u8bed\u8a00\u8868\u793a\u6536\u655b\uff0c\u5e76\u5c06\u9057\u5fd8\u66f4\u65b0\u9650\u5236\u5728\u8fd9\u4e9b\u5c42", "result": "\u5b9e\u9a8c\u53d1\u73b0\u4e24\u79cd\u4e0d\u540c\u7684\u5931\u8d25\u6a21\u5f0f\uff1a\u6d45\u5c42\u5e72\u9884\u5b9e\u73b0\u64e6\u9664\u4f46\u7834\u574f\u4fdd\u7559\u8bed\u8a00\u7684\u591a\u8bed\u8a00\u80fd\u529b\uff1b\u6df1\u5c42\u5e72\u9884\u4fdd\u7559\u6548\u7528\u4f46\u5373\u4f7f\u5728\u6e90\u8bed\u8a00\u4e2d\u4e5f\u65e0\u6cd5\u64e6\u9664\u76ee\u6807\u77e5\u8bc6\u3002MUTE\u6846\u67b6\u5728\u4e09\u79cdLLM\u67b6\u6784\u548c\u4e09\u79cd\u9057\u5fd8\u7b97\u6cd5\u4e0a\u9a8c\u8bc1\u6709\u6548\uff0c\u901a\u8fc7Logit Lens\u63a2\u6d4b\u786e\u8ba4\u4e86\u771f\u6b63\u7684\u77e5\u8bc6\u79fb\u9664\u800c\u975e\u8f93\u51fa\u7ea7\u6291\u5236", "conclusion": "\u5e72\u9884\u5c42\u7684\u9009\u62e9\u4e0d\u662f\u81ea\u7531\u53c2\u6570\uff0c\u5b83\u4ece\u6839\u672c\u4e0a\u51b3\u5b9a\u591a\u8bed\u8a00\u9057\u5fd8\u662f\u5426\u6210\u529f\u3002MUTE\u6846\u67b6\u901a\u8fc7\u8bc6\u522b\u8bed\u8a00\u65e0\u5173\u5c42\u5b9e\u73b0\u4e86\u7a33\u5065\u7684\u591a\u8bed\u8a00\u77e5\u8bc6\u64e6\u9664\uff0c\u540c\u65f6\u4ec5\u4f18\u5316\u5c11\u91cf\u6e90\u8bed\u8a00"}}
{"id": "2602.22699", "categories": ["cs.CR", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.22699", "abs": "https://arxiv.org/abs/2602.22699", "authors": ["Tomoya Matsumoto", "Shokichi Takakura", "Shun Takagi", "Satoshi Hasegawa"], "title": "DPSQL+: A Differentially Private SQL Library with a Minimum Frequency Rule", "comment": null, "summary": "SQL is the de facto interface for exploratory data analysis; however, releasing exact query results can expose sensitive information through membership or attribute inference attacks. Differential privacy (DP) provides rigorous privacy guarantees, but in practice, DP alone may not satisfy governance requirements such as the \\emph{minimum frequency rule}, which requires each released group (cell) to include contributions from at least $k$ distinct individuals. In this paper, we present \\textbf{DPSQL+}, a privacy-preserving SQL library that simultaneously enforces user-level $(\\varepsilon,\u03b4)$-DP and the minimum frequency rule. DPSQL+ adopts a modular architecture consisting of: (i) a \\emph{Validator} that statically restricts queries to a DP-safe subset of SQL; (ii) an \\emph{Accountant} that consistently tracks cumulative privacy loss across multiple queries; and (iii) a \\emph{Backend} that interfaces with various database engines, ensuring portability and extensibility. Experiments on the TPC-H benchmark demonstrate that DPSQL+ achieves practical accuracy across a wide range of analytical workloads -- from basic aggregates to quadratic statistics and join operations -- and allows substantially more queries under a fixed global privacy budget than prior libraries in our evaluation.", "AI": {"tldr": "DPSQL+\u662f\u4e00\u4e2a\u9690\u79c1\u4fdd\u62a4\u7684SQL\u5e93\uff0c\u540c\u65f6\u5f3a\u5236\u6267\u884c\u7528\u6237\u7ea7\u5dee\u5206\u9690\u79c1\u548c\u6700\u5c0f\u9891\u7387\u89c4\u5219\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u67b6\u6784\u5b9e\u73b0\u5b89\u5168\u67e5\u8be2\u5904\u7406\u3002", "motivation": "SQL\u4f5c\u4e3a\u6570\u636e\u5206\u6790\u7684\u6807\u51c6\u63a5\u53e3\uff0c\u76f4\u63a5\u53d1\u5e03\u67e5\u8be2\u7ed3\u679c\u53ef\u80fd\u901a\u8fc7\u6210\u5458\u6216\u5c5e\u6027\u63a8\u65ad\u653b\u51fb\u66b4\u9732\u654f\u611f\u4fe1\u606f\u3002\u5dee\u5206\u9690\u79c1\u63d0\u4f9b\u7406\u8bba\u4fdd\u969c\uff0c\u4f46\u5355\u72ec\u4f7f\u7528\u65e0\u6cd5\u6ee1\u8db3\u6cbb\u7406\u8981\u6c42\u4e2d\u7684\u6700\u5c0f\u9891\u7387\u89c4\u5219\uff08\u8981\u6c42\u6bcf\u4e2a\u53d1\u5e03\u7ec4\u81f3\u5c11\u5305\u542bk\u4e2a\u4e0d\u540c\u4e2a\u4f53\u7684\u8d21\u732e\uff09\u3002", "method": "DPSQL+\u91c7\u7528\u6a21\u5757\u5316\u67b6\u6784\uff1a1)\u9a8c\u8bc1\u5668\u9759\u6001\u9650\u5236\u67e5\u8be2\u5230DP\u5b89\u5168\u7684SQL\u5b50\u96c6\uff1b2)\u4f1a\u8ba1\u5e08\u4e00\u81f4\u8ddf\u8e2a\u8de8\u591a\u4e2a\u67e5\u8be2\u7684\u7d2f\u79ef\u9690\u79c1\u635f\u5931\uff1b3)\u540e\u7aef\u63a5\u53e3\u4e0e\u5404\u79cd\u6570\u636e\u5e93\u5f15\u64ce\u8fde\u63a5\uff0c\u786e\u4fdd\u53ef\u79fb\u690d\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "result": "\u5728TPC-H\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDPSQL+\u5728\u5e7f\u6cdb\u7684\u5206\u6790\u5de5\u4f5c\u8d1f\u8f7d\uff08\u4ece\u57fa\u672c\u805a\u5408\u5230\u4e8c\u6b21\u7edf\u8ba1\u548c\u8fde\u63a5\u64cd\u4f5c\uff09\u4e0a\u5b9e\u73b0\u4e86\u5b9e\u7528\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u5728\u56fa\u5b9a\u7684\u5168\u5c40\u9690\u79c1\u9884\u7b97\u4e0b\uff0c\u6bd4\u8bc4\u4f30\u4e2d\u7684\u5148\u524d\u5e93\u5141\u8bb8\u66f4\u591a\u7684\u67e5\u8be2\u3002", "conclusion": "DPSQL+\u6210\u529f\u5730\u5c06\u7528\u6237\u7ea7\u5dee\u5206\u9690\u79c1\u4e0e\u6700\u5c0f\u9891\u7387\u89c4\u5219\u76f8\u7ed3\u5408\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u9690\u79c1\u4fdd\u62a4SQL\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u9690\u79c1\u4fdd\u969c\u7684\u540c\u65f6\u652f\u6301\u590d\u6742\u7684\u6570\u636e\u5206\u6790\u5de5\u4f5c\u8d1f\u8f7d\u3002"}}
{"id": "2602.23167", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23167", "abs": "https://arxiv.org/abs/2602.23167", "authors": ["Shuang Liang", "Yang Hua", "Linshan Jiang", "Peishen Yan", "Tao Song", "Bin Yao", "Haibing Guan"], "title": "SettleFL: Trustless and Scalable Reward Settlement Protocol for Federated Learning on Permissionless Blockchains (Extended version)", "comment": null, "summary": "In open Federated Learning (FL) environments where no central authority exists, ensuring collaboration fairness relies on decentralized reward settlement, yet the prohibitive cost of permissionless blockchains directly clashes with the high-frequency, iterative nature of model training. Existing solutions either compromise decentralization or suffer from scalability bottlenecks due to linear on-chain costs. To address this, we present SettleFL, a trustless and scalable reward settlement protocol designed to minimize total economic friction by offering a family of two interoperable protocols. Leveraging a shared domain-specific circuit architecture, SettleFL offers two interoperable strategies: (1) a Commit-and-Challenge variant that minimizes on-chain costs via optimistic execution and dispute-driven arbitration, and (2) a Commit-with-Proof variant that guarantees instant finality through per-round validity proofs. This design allows the protocol to flexibly adapt to varying latency and cost constraints while enforcing rational robustness without trusted coordination. We conduct extensive experiments combining real FL workloads and controlled simulations. Results show that SettleFL remains practical when scaling to 800 participants, achieving substantially lower gas cost.", "AI": {"tldr": "SettleFL\u662f\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684\u8054\u90a6\u5b66\u4e60\u5956\u52b1\u7ed3\u7b97\u534f\u8bae\uff0c\u901a\u8fc7\u4e24\u79cd\u53ef\u4e92\u64cd\u4f5c\u7b56\u7565\u89e3\u51b3\u533a\u5757\u94fe\u6210\u672c\u4e0e\u6a21\u578b\u8bad\u7ec3\u9ad8\u9891\u8fed\u4ee3\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u4fe1\u4efb\u6700\u5c0f\u5316\u7ed3\u7b97\u3002", "motivation": "\u5728\u5f00\u653e\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\uff0c\u7f3a\u4e4f\u4e2d\u592e\u6743\u5a01\u673a\u6784\u9700\u8981\u53bb\u4e2d\u5fc3\u5316\u5956\u52b1\u7ed3\u7b97\uff0c\u4f46\u65e0\u8bb8\u53ef\u533a\u5757\u94fe\u7684\u9ad8\u6602\u6210\u672c\u4e0e\u6a21\u578b\u8bad\u7ec3\u7684\u9ad8\u9891\u8fed\u4ee3\u7279\u6027\u76f4\u63a5\u51b2\u7a81\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8981\u4e48\u727a\u7272\u53bb\u4e2d\u5fc3\u5316\uff0c\u8981\u4e48\u56e0\u7ebf\u6027\u94fe\u4e0a\u6210\u672c\u800c\u9762\u4e34\u53ef\u6269\u5c55\u6027\u74f6\u9888\u3002", "method": "\u63d0\u51faSettleFL\u534f\u8bae\uff0c\u91c7\u7528\u5171\u4eab\u9886\u57df\u7279\u5b9a\u7535\u8def\u67b6\u6784\uff0c\u63d0\u4f9b\u4e24\u79cd\u53ef\u4e92\u64cd\u4f5c\u7b56\u7565\uff1a1) Commit-and-Challenge\u53d8\u4f53\uff0c\u901a\u8fc7\u4e50\u89c2\u6267\u884c\u548c\u4e89\u8bae\u9a71\u52a8\u4ef2\u88c1\u6700\u5c0f\u5316\u94fe\u4e0a\u6210\u672c\uff1b2) Commit-with-Proof\u53d8\u4f53\uff0c\u901a\u8fc7\u6bcf\u8f6e\u6709\u6548\u6027\u8bc1\u660e\u4fdd\u8bc1\u5373\u65f6\u6700\u7ec8\u6027\u3002\u8be5\u8bbe\u8ba1\u5141\u8bb8\u534f\u8bae\u7075\u6d3b\u9002\u5e94\u4e0d\u540c\u7684\u5ef6\u8fdf\u548c\u6210\u672c\u7ea6\u675f\uff0c\u540c\u65f6\u5728\u6ca1\u6709\u53ef\u4fe1\u534f\u8c03\u7684\u60c5\u51b5\u4e0b\u5f3a\u5236\u6267\u884c\u7406\u6027\u9c81\u68d2\u6027\u3002", "result": "\u7ed3\u5408\u771f\u5b9e\u8054\u90a6\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u548c\u53d7\u63a7\u6a21\u62df\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSettleFL\u5728\u6269\u5c55\u5230800\u540d\u53c2\u4e0e\u8005\u65f6\u4ecd\u4fdd\u6301\u5b9e\u7528\u6027\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u964d\u4f4e\u7684gas\u6210\u672c\u3002", "conclusion": "SettleFL\u901a\u8fc7\u521b\u65b0\u7684\u534f\u8bae\u8bbe\u8ba1\u89e3\u51b3\u4e86\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u5956\u52b1\u7ed3\u7b97\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6210\u672c\u95ee\u9898\uff0c\u4e3a\u5f00\u653e\u8054\u90a6\u5b66\u4e60\u73af\u5883\u63d0\u4f9b\u4e86\u4fe1\u4efb\u6700\u5c0f\u5316\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23261", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.23261", "abs": "https://arxiv.org/abs/2602.23261", "authors": ["David Polzoni", "Tommaso Bianchi", "Mauro Conti"], "title": "Strengthening security and noise resistance in one-way quantum key distribution protocols through hypercube-based quantum walks", "comment": null, "summary": "Quantum Key Distribution (QKD) is a foundational cryptographic protocol that ensures information-theoretic security. However, classical protocols such as BB84, though favored for their simplicity, offer limited resistance to eavesdropping, and perform poorly under realistic noise conditions. Recent research has explored the use of discrete-time Quantum Walks (QWs) to enhance QKD schemes. In this work, we specifically focus on a one-way QKD protocol, where security depends exclusively on the underlying Quantum Walk (QW) topology, rather than the details of the protocol itself. Our paper introduces a novel protocol based on QWs over a hypercube topology and demonstrates that, under identical parameters, it provides significantly enhanced security and noise resistance compared to the circular topology (i.e., state-of-the-art), thereby strengthening protection against eavesdropping. Furthermore, we introduce an efficient and extensible simulation framework for one-way QKD protocols based on QWs, supporting both circular and hypercube topologies. Implemented with IBM's software development kit for quantum computing (i.e., Qiskit), our toolkit enables noise-aware analysis under realistic noise models. To support reproducibility and future developments, we release our entire simulation framework as open-source. This contribution establishes a foundation for the design of topology-aware QKD protocols that combine enhanced noise tolerance with topologically driven security.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d85\u7acb\u65b9\u4f53\u62d3\u6251\u7684\u91cf\u5b50\u884c\u8d70QKD\u534f\u8bae\uff0c\u76f8\u6bd4\u73b0\u6709\u7684\u73af\u5f62\u62d3\u6251\u534f\u8bae\uff0c\u5728\u76f8\u540c\u53c2\u6570\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u5b89\u5168\u6027\u548c\u6297\u566a\u80fd\u529b\uff0c\u5e76\u5f00\u53d1\u4e86\u5f00\u6e90\u4eff\u771f\u6846\u67b6\u3002", "motivation": "\u4f20\u7edfBB84\u7b49\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u534f\u8bae\u867d\u7136\u7b80\u5355\uff0c\u4f46\u5bf9\u7a83\u542c\u62b5\u6297\u80fd\u529b\u6709\u9650\uff0c\u5728\u73b0\u5b9e\u566a\u58f0\u6761\u4ef6\u4e0b\u6027\u80fd\u4e0d\u4f73\u3002\u91cf\u5b50\u884c\u8d70\u6280\u672f\u4e3a\u589e\u5f3aQKD\u65b9\u6848\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u591a\u57fa\u4e8e\u73af\u5f62\u62d3\u6251\uff0c\u9700\u8981\u63a2\u7d22\u66f4\u4f18\u7684\u62d3\u6251\u7ed3\u6784\u6765\u63d0\u5347\u5b89\u5168\u6027\u548c\u6297\u566a\u6027\u3002", "method": "1. \u63d0\u51fa\u57fa\u4e8e\u8d85\u7acb\u65b9\u4f53\u62d3\u6251\u7684\u91cf\u5b50\u884c\u8d70QKD\u534f\u8bae\uff0c\u5176\u5b89\u5168\u6027\u5b8c\u5168\u4f9d\u8d56\u4e8e\u91cf\u5b50\u884c\u8d70\u62d3\u6251\u800c\u975e\u534f\u8bae\u7ec6\u8282\uff1b2. \u5f00\u53d1\u4e86\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u5355\u5411QKD\u534f\u8bae\u4eff\u771f\u6846\u67b6\uff0c\u652f\u6301\u73af\u5f62\u548c\u8d85\u7acb\u65b9\u4f53\u4e24\u79cd\u62d3\u6251\uff1b3. \u4f7f\u7528IBM Qiskit\u5b9e\u73b0\uff0c\u652f\u6301\u73b0\u5b9e\u566a\u58f0\u6a21\u578b\u4e0b\u7684\u566a\u58f0\u611f\u77e5\u5206\u6790\u3002", "result": "\u5728\u76f8\u540c\u53c2\u6570\u4e0b\uff0c\u8d85\u7acb\u65b9\u4f53\u62d3\u6251\u76f8\u6bd4\u73af\u5f62\u62d3\u6251\uff08\u5f53\u524d\u6700\u4f18\uff09\u63d0\u4f9b\u4e86\u663e\u8457\u589e\u5f3a\u7684\u5b89\u5168\u6027\u548c\u566a\u58f0\u62b5\u6297\u80fd\u529b\uff0c\u6709\u6548\u52a0\u5f3a\u4e86\u5bf9\u6297\u7a83\u542c\u7684\u4fdd\u62a4\u3002\u540c\u65f6\u53d1\u5e03\u4e86\u5b8c\u6574\u7684\u5f00\u6e90\u4eff\u771f\u6846\u67b6\u3002", "conclusion": "\u57fa\u4e8e\u8d85\u7acb\u65b9\u4f53\u62d3\u6251\u7684\u91cf\u5b50\u884c\u8d70QKD\u534f\u8bae\u5728\u5b89\u5168\u6027\u548c\u6297\u566a\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u73af\u5f62\u62d3\u6251\u65b9\u6848\u3002\u5f00\u53d1\u7684\u4eff\u771f\u6846\u67b6\u4e3a\u62d3\u6251\u611f\u77e5\u7684QKD\u534f\u8bae\u8bbe\u8ba1\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u7ed3\u5408\u4e86\u589e\u5f3a\u7684\u566a\u58f0\u5bb9\u5fcd\u5ea6\u548c\u62d3\u6251\u9a71\u52a8\u7684\u5b89\u5168\u6027\u3002"}}

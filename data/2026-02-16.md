<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 4]
- [cs.AI](#cs.AI) [Total: 12]
- [cs.CR](#cs.CR) [Total: 8]
- [cs.DC](#cs.DC) [Total: 2]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [Design Environment of Quantization-Aware Edge AI Hardware for Few-Shot Learning](https://arxiv.org/abs/2602.12295)
*R. Kanda,N. Onizawa,M. Leonardon,V. Gripon,T. Hanyu*

Main category: cs.AR

TL;DR: 该研究通过在边缘AI硬件的预训练和评估阶段实现定点数据处理，确保few-shot学习在整个设计流程中的精度一致性，使用Brevitas量化模块实现可定制的整数和小数位宽，验证了在减少计算资源的同时保持与浮点运算相当的精度。


<details>
  <summary>Details</summary>
Motivation: 确保在实现few-shot学习的边缘AI硬件时，整个设计流程中的精度一致性，特别是在预训练和评估阶段。

Method: 使用Brevitas量化模块实现定点数据处理，支持任意指定整数和小数部分的位宽。采用量化感知训练（QAT）和后训练量化（PTQ）两种方法。与当前设计流程中使用的Tensil工具（要求8位或16位位宽）进行对比验证。

Result: 性能验证表明，即使使用6位或5位的整数和小数部分，也能保持与浮点运算相当的精度，这显示了进一步减少计算资源的潜力。

Conclusion: 这些结果明显有助于为few-shot学习的边缘AI硬件创建一个通用的设计和评估环境，通过定点数据处理实现精度一致性并减少计算资源需求。

Abstract: This study aims to ensure consistency in accuracy throughout the entire design flow in the implementation of edge AI hardware for few-shot learning, by implementing fixed-point data processing in the pre-training and evaluation phases. Specifically, the quantization module, called Brevitas, is applied to implement fixed-point data processing, which allows for arbitrary specification of the bit widths for the integer and fractional parts. Two methods of fixed-point data quantization, quantization-aware training (QAT) and post-training quantization (PTQ), are utilized in Brevitas. With Tensil, which is used in the current design flow, the bit widths of the integer and fractional parts need to be 8 bits each or 16 bits each when implemented in hardware, but performance validation has shown that accuracy comparable to floating-point operations can be maintained even with 6 bits or 5 bits each, indicating potential for further reduction in computational resources. These results clearly contribute to the creation of a versatile design and evaluation environment for edge AI hardware for few-shot learning.

</details>


### [2] [CacheMind: From Miss Rates to Why -- Natural-Language, Trace-Grounded Reasoning for Cache Replacement](https://arxiv.org/abs/2602.12422)
*Kaushal Mhapsekar,Azam Ghanbari,Bita Aslrousta,Samira Mirbagher-Ajorpaz*

Main category: cs.AR

TL;DR: CacheMind是一个基于RAG和LLM的对话工具，用于对缓存跟踪数据进行语义推理，帮助架构师通过自然语言提问分析缓存性能问题。


<details>
  <summary>Details</summary>
Motivation: 传统缓存替换依赖于手工设计的启发式方法，限制了缓存性能。缓存数据分析需要解析数百万条跟踪记录并进行手动过滤，过程缓慢且非交互式。

Method: 开发了CacheMind工具，结合检索增强生成（RAG）和大语言模型（LLM），实现对缓存跟踪数据的语义推理。还创建了CacheMindBench基准套件来评估LLM在缓存替换问题上的推理能力。

Result: 使用SIEVE检索器时，CacheMind在75个未见过的跟踪基础问题上达到66.67%准确率，在25个策略特定推理任务上达到84.80%；使用RANGER时分别达到89.33%和64.80%。RANGER在CacheMindBench的6个类别中有4个达到100%准确率。相比LlamaIndex（10%检索成功率），SIEVE达到60%，RANGER达到90%。

Conclusion: CacheMind为缓存分析提供了首个自然语言接口，能够从缓存跟踪数据中提取可操作的见解，如绕过用例提高缓存命中率7.66%和速度提升2.04%，软件修复用例提供76%速度提升，Mockingjay替换策略用例提供0.7%速度提升。

Abstract: Cache replacement remains a challenging problem in CPU microarchitecture, often addressed using hand-crafted heuristics, limiting cache performance. Cache data analysis requires parsing millions of trace entries with manual filtering, making the process slow and non-interactive. To address this, we introduce CacheMind, a conversational tool that uses Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs) to enable semantic reasoning over cache traces. Architects can now ask natural language questions like, "Why is the memory access associated with PC X causing more evictions?", and receive trace-grounded, human-readable answers linked to program semantics for the first time. To evaluate CacheMind, we present CacheMindBench, the first verified benchmark suite for LLM-based reasoning for the cache replacement problem. Using the SIEVE retriever, CacheMind achieves 66.67% on 75 unseen trace-grounded questions and 84.80% on 25 unseen policy-specific reasoning tasks; with RANGER, it achieves 89.33% and 64.80% on the same evaluations. Additionally, with RANGER, CacheMind achieves 100% accuracy on 4 out of 6 categories in the trace-grounded tier of CacheMindBench. Compared to LlamaIndex (10% retrieval success), SIEVE achieves 60% and RANGER achieves 90%, demonstrating that existing Retrieval-Augmented Generation (RAGs) are insufficient for precise, trace-grounded microarchitectural reasoning. We provided four concrete actionable insights derived using CacheMind, wherein bypassing use case improved cache hit rate by 7.66% and speedup by 2.04%, software fix use case gives speedup of 76%, and Mockingjay replacement policy use case gives speedup of 0.7%; showing the utility of CacheMind on non-trivial queries that require a natural-language interface.

</details>


### [3] [MXFormer: A Microscaling Floating-Point Charge-Trap Transistor Compute-in-Memory Transformer Accelerator](https://arxiv.org/abs/2602.12480)
*George Karfakis,Samyak Chakrabarty,Vinod Kurian Jacob,Siyun Qiao,Subramanian S. Iyer,Sudhakar Pamarti,Puneet Gupta*

Main category: cs.AR

TL;DR: MXFormer是一种新型混合权重驻留计算内存加速器，专为大型短序列Transformer的固定模型推理设计，通过消除权重移动实现高吞吐和高效率。


<details>
  <summary>Details</summary>
Motivation: Transformer模型部署受到计算和内存带宽需求的严重限制，需要更高效的推理加速方案。

Method: 采用超密集电荷陷阱晶体管构建MXFP4 CIM阵列，实现完全权重驻留；静态分区设计包含12个Transformer块，静态权重层在模拟CTT阵列执行，动态计算在数字块处理。

Result: MXFormer处理ViT-L/32达到58275 FPS（双芯片），ViT-B/16达到41269 FPS（单芯片）；计算密度比非FWS加速器高3.3-60.5倍，能效高1.7-2.5倍；相比FWS加速器，计算密度提高20.9倍，权重存储密度提高2倍，精度损失小于1%。

Conclusion: MXFormer通过完全权重驻留和深度流水线设计，为大型Transformer推理提供了高吞吐、高效率的解决方案，无需模型重训练即可保持接近数字精度。

Abstract: The proliferation of Transformer models is often constrained by the significant computational and memory bandwidth demands of deployment. To address this, we present MXFormer, a novel, hybrid, weight-stationary Compute-in-Memory (CIM) accelerator that provides high throughput and efficiency for fixed-model inference on large short-sequence Transformers. Our architecture's foundation is the use of ultra-dense Charge-Trap Transistors (CTTs) in Microscaling MXFP4 CIM arrays, uniquely enabling the on-chip storage of up to hundreds of millions of parameters in Fully Weight Stationary (FWS) fashion.
  We introduce a statically partitioned design with 12 Transformer blocks connected by a deeply pipelined dataflow. Static-weight layers (MLPs and linear projections) execute on highly parallel analog CTT arrays using an MXFP4-native flow with per-block exponent alignment and a 10-bit SAR ADC. Dynamic computations are handled in fully accurate digital blocks that utilize MXFP-enabled systolic arrays for scaled dot-product attention and vector units for LayerNorm and FlashAttention-style Softmax.
  By eliminating all weight movement, the deeply pipelined MXFormer architecture yields very high single-stream throughput and efficiency, processing 58275 FPS on ViT-L/32 (dual-chip) or 41269 FPS on ViT-B/16 (single chip). MXFormer outperforms comparable state-of-the-art non-FWS digital, hybrid and photonic Transformer accelerators ~3.3x-60.5x in compute density and ~1.7x-2.5x in energy efficiency. Against FWS accelerators, MXFormer improves compute density by ~20.9x and resident weight storage density by ~2x, while preserving near-digital accuracy (drop of <1%) without any model retraining.

</details>


### [4] [TriGen: NPU Architecture for End-to-End Acceleration of Large Language Models based on SW-HW Co-Design](https://arxiv.org/abs/2602.12962)
*Jonghun Lee,Junghoon Lee,Hyeonjin Kim,Seoho Jeon,Jisup Yoon,Hyunbin Park,Meejeong Park,Heonjae Ha*

Main category: cs.AR

TL;DR: TriGen是一种针对资源受限环境的NPU架构，通过软硬件协同设计优化LLM推理，采用微缩放低精度计算、查找表替代非线性操作专用硬件，以及考虑实际硬件约束的调度技术，在保持精度的同时实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着transformer大语言模型在资源受限设备上的部署需求增加，传统NPU架构面临挑战：LLM参数量大但复用率低，端到端执行困难，需要针对资源受限环境设计专门的硬件架构。

Method: 1. 采用微缩放低精度计算，在保持精度的同时提供额外优化机会；2. 使用快速准确的查找表替代非线性操作专用硬件，联合优化线性和非线性操作；3. 考虑实际硬件约束，采用调度技术最大化有限片上内存下的计算利用率。

Result: 在多种LLM上评估显示，TriGen相比基线NPU设计平均实现2.73倍性能加速，内存传输减少52%，精度损失可忽略不计。

Conclusion: TriGen通过软硬件协同设计，为资源受限环境中的LLM推理提供了高效的NPU架构解决方案，在性能、内存效率和硬件成本方面均有显著改进。

Abstract: Recent studies have extensively explored NPU architectures for accelerating AI inference in on-device environments, which are inherently resource-constrained. Meanwhile, transformer-based large language models (LLMs) have become dominant, with rapidly increasing model sizes but low degree of parameter reuse compared to conventional CNNs, making end-to-end execution on resource-limited devices extremely challenging. To address these challenges, we propose TriGen, a novel NPU architecture tailored for resource-constrained environments through software-hardware co-design. Firstly, TriGen adopts low-precision computation using microscaling (MX) to enable additional optimization opportunities while preserving accuracy, and resolves the issues that arise by employing such precision. Secondly, to jointly optimize both nonlinear and linear operations, TriGen eliminates the need for specialized hardware for essential nonlinear operations by using fast and accurate LUT, thereby maximizing performance gains and reducing hardware-cost in on-device environments, and finally, by taking practical hardware constraints into account, further employs scheduling techniques to maximize computational utilization even under limited on-chip memory capacity. We evaluate the performance of TriGen on various LLMs and show that TriGen achieves an average 2.73x performance speedup and 52% less memory transfer over the baseline NPU design with negligible accuracy loss.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [5] [GT-HarmBench: Benchmarking AI Safety Risks Through the Lens of Game Theory](https://arxiv.org/abs/2602.12316)
*Pepijn Cobben,Xuanqiang Angelo Huang,Thao Amelia Pham,Isabel Dahlgren,Terry Jingchen Zhang,Zhijing Jin*

Main category: cs.AI

TL;DR: GT-HarmBench是一个包含2009个高风险多智能体场景的基准测试，覆盖囚徒困境、猎鹿博弈等博弈论结构，用于评估前沿AI系统在多智能体环境中的安全性和协调能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI安全基准主要评估单智能体，而忽略了多智能体环境中的协调失败、冲突等风险。随着前沿AI系统在高风险多智能体环境中部署增多，需要专门的基准来评估和理解这些多智能体风险。

Method: 从MIT AI风险库中提取真实AI风险场景，构建包含2009个高风险场景的基准测试，覆盖囚徒困境、猎鹿博弈、胆小鬼博弈等经典博弈论结构。评估15个前沿模型，测量其对博弈论提示框架和顺序的敏感性，并分析导致失败的推理模式。

Result: 在15个前沿模型中，智能体仅在62%的情况下选择社会有益行动，经常导致有害结果。研究还发现博弈论干预可以将社会有益结果提高多达18%。

Conclusion: 研究揭示了前沿AI系统在多智能体环境中存在显著可靠性差距，GT-HarmBench为研究多智能体环境中的对齐问题提供了广泛标准化的测试平台。基准测试和代码已开源。

Abstract: Frontier AI systems are increasingly capable and deployed in high-stakes multi-agent environments. However, existing AI safety benchmarks largely evaluate single agents, leaving multi-agent risks such as coordination failure and conflict poorly understood. We introduce GT-HarmBench, a benchmark of 2,009 high-stakes scenarios spanning game-theoretic structures such as the Prisoner's Dilemma, Stag Hunt and Chicken. Scenarios are drawn from realistic AI risk contexts in the MIT AI Risk Repository. Across 15 frontier models, agents choose socially beneficial actions in only 62% of cases, frequently leading to harmful outcomes. We measure sensitivity to game-theoretic prompt framing and ordering, and analyze reasoning patterns driving failures. We further show that game-theoretic interventions improve socially beneficial outcomes by up to 18%. Our results highlight substantial reliability gaps and provide a broad standardized testbed for studying alignment in multi-agent environments. The benchmark and code are available at https://github.com/causalNLP/gt-harmbench.

</details>


### [6] [To Mix or To Merge: Toward Multi-Domain Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2602.12566)
*Haoqing Wang,Xiang Long,Ziheng Li,Yilong Xu,Tingguang Li,Yehui Tang*

Main category: cs.AI

TL;DR: 该研究比较了多领域强化学习与可验证奖励（RLVR）的两种训练范式：混合多任务训练与分别训练后模型合并，发现在不同领域间RLVR存在较少相互干扰，推理密集型领域甚至表现出相互协同效应。


<details>
  <summary>Details</summary>
Motivation: 当前多领域专家级模型需要跨领域RLVR协作，但现有研究缺乏对混合多任务RLVR和分别训练后模型合并这两种范式的详细比较分析。

Method: 选择数学、编程、科学和指令跟随等多个常用高级任务作为目标领域，使用开源数据集设计广泛的定性和定量实验，从权重空间几何、模型预测行为和信息约束等角度分析内部机制。

Result: 发现跨领域RLVR表现出较少相互干扰，推理密集型领域展示出相互协同效应；通过权重空间几何、模型预测行为和信息约束分析揭示了相互增益的内部机制。

Conclusion: 该研究为多领域RLVR训练提供了实证分析，表明跨领域协作具有可行性，推理密集型任务间存在协同效应，为构建通用多领域专家模型提供了指导。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) plays a key role in stimulating the explicit reasoning capability of Large Language Models (LLMs). We can achieve expert-level performance in some specific domains via RLVR, such as coding or math. When a general multi-domain expert-level model is required, we need to carefully consider the collaboration of RLVR across different domains. The current state-of-the-art models mainly employ two different training paradigms for multi-domain RLVR: mixed multi-task RLVR and separate RLVR followed by model merging. However, most of the works did not provide a detailed comparison and analysis about these paradigms. To this end, we choose multiple commonly used high-level tasks (e.g., math, coding, science, and instruction following) as our target domains and design extensive qualitative and quantitative experiments using open-source datasets. We find the RLVR across domains exhibits few mutual interferences, and reasoning-intensive domains demonstrate mutually synergistic effects. Furthermore, we analyze the internal mechanisms of mutual gains from the perspectives of weight space geometry, model prediction behavior, and information constraints. This project is named as M2RL that means Mixed multi-task training or separate training followed by model Merging for Reinforcement Learning, and the homepage is at https://github.com/mosAI25/M2RL

</details>


### [7] [Can I Have Your Order? Monte-Carlo Tree Search for Slot Filling Ordering in Diffusion Language Models](https://arxiv.org/abs/2602.12586)
*Joshua Ong Jun Leang,Yu Zhao,Mihaela Cătălina Stoian,Wenda Li,Shay B. Cohen,Eleonora Giunchiglia*

Main category: cs.AI

TL;DR: McDiffuSE使用蒙特卡洛树搜索优化掩码扩散模型中的槽位填充顺序，通过前瞻模拟评估部分完成情况，在数学和代码推理任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 虽然基于掩码扩散模型的计划-填充解码在数学和代码推理中显示出潜力，但性能对槽位填充顺序高度敏感，导致输出方差大。需要一种系统方法来优化填充顺序以提升生成质量。

Method: McDiffuSE框架将槽位选择建模为决策过程，使用蒙特卡洛树搜索优化填充顺序。通过前瞻模拟评估部分完成情况，系统探索生成顺序的组合空间。

Result: 实验显示平均比自回归基线提升3.2%，比基线计划-填充方法提升8.0%。在MBPP任务上提升19.5%，在MATH500上提升4.9%。分析表明虽然主要遵循顺序生成，但非顺序生成对最大化性能至关重要。

Conclusion: 基于MCTS的规划是提升掩码扩散模型生成质量的有效方法。研究发现更大的探索常数（而非更多模拟）对于克服模型置信度偏差和发现有效顺序至关重要。

Abstract: While plan-and-infill decoding in Masked Diffusion Models (MDMs) shows promise for mathematical and code reasoning, performance remains highly sensitive to slot infilling order, often yielding substantial output variance. We introduce McDiffuSE, a framework that formulates slot selection as decision making and optimises infilling orders through Monte Carlo Tree Search (MCTS). McDiffuSE uses look-ahead simulations to evaluate partial completions before commitment, systematically exploring the combinatorial space of generation orders. Experiments show an average improvement of 3.2% over autoregressive baselines and 8.0% over baseline plan-and-infill, with notable gains of 19.5% on MBPP and 4.9% on MATH500. Our analysis reveals that while McDiffuSE predominantly follows sequential ordering, incorporating non-sequential generation is essential for maximising performance. We observe that larger exploration constants, rather than increased simulations, are necessary to overcome model confidence biases and discover effective orderings. These findings establish MCTS-based planning as an effective approach for enhancing generation quality in MDMs.

</details>


### [8] [GeoAgent: Learning to Geolocate Everywhere with Reinforced Geographic Characteristics](https://arxiv.org/abs/2602.12617)
*Modi Jin,Yiming Zhang,Boyuan Sun,Dingwen Zhang,MingMing Cheng,Qibin Hou*

Main category: cs.AI

TL;DR: GeoAgent是一个能够与人类紧密推理并得出细粒度地址结论的模型，通过专家标注的地理定位数据集和地理相似性奖励机制，解决了现有RL方法依赖AI生成思维链数据与地理特性冲突的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的方法虽然在性能和可解释性方面取得了突破，但由于依赖AI生成的思维链数据和训练策略，与地理特性存在冲突，需要解决这一问题。

Method: 1. 引入GeoSeek数据集，包含地理专家和专业玩家标注的思维链数据；2. 提出地理相似性奖励和一致性奖励（由一致性智能体评估），鼓励模型从地理角度收敛到正确答案，同时确保推理过程的完整性和一致性。

Result: 实验结果表明，GeoAgent在多个粒度上优于现有方法和一系列通用VLLMs，同时生成的推理过程与人类思维紧密契合。

Conclusion: GeoAgent通过专家标注数据和地理特性奖励机制，成功解决了地理任务中的特殊挑战，实现了与人类推理紧密对齐的高性能地理定位模型。

Abstract: This paper presents GeoAgent, a model capable of reasoning closely with humans and deriving fine-grained address conclusions. Previous RL-based methods have achieved breakthroughs in performance and interpretability but still remain concerns because of their reliance on AI-generated chain-of-thought (CoT) data and training strategies, which conflict with geographic characteristics. To address these issues, we first introduce GeoSeek, a new geolocation dataset comprising CoT data annotated by geographic experts and professional players. We further thoroughly explore the inherent characteristics of geographic tasks and propose a geo-similarity reward and a consistency reward assessed by a consistency agent to assist training. This encourages the model to converge towards correct answers from a geographic perspective while ensuring the integrity and consistency of its reasoning process. Experimental results show that GeoAgent outperforms existing methods and a series of general VLLMs across multiple grains, while generating reasoning that closely aligns with humans.

</details>


### [9] [AI Agents for Inventory Control: Human-LLM-OR Complementarity](https://arxiv.org/abs/2602.12631)
*Jackie Baek,Yaopeng Fu,Will Ma,Tianyi Peng*

Main category: cs.AI

TL;DR: LLM增强的运筹学算法在库存控制中优于单独使用任一种方法，人机协作团队比单独的人类或AI表现更好，存在显著的个体互补效应


<details>
  <summary>Details</summary>
Motivation: 传统运筹学算法依赖刚性建模假设，在需求分布变化或缺乏相关上下文信息时表现不佳。LLM能够灵活推理并整合丰富的上下文信号，但如何将LLM方法整合到传统决策流程中仍不明确。研究探索运筹学算法、LLM和人类如何互动互补

Method: 构建InventoryBench基准测试，包含1000多个库存实例，涵盖合成和真实需求数据，测试需求变化、季节性和不确定交货期下的决策规则。通过课堂实验研究人类在决策流程中的作用，将LLM推荐嵌入人机协作决策管道

Result: 运筹学增强的LLM方法优于单独使用任一种方法，表明这些方法是互补而非替代。人机协作团队平均获得比单独人类或AI更高的利润。形式化了个体层面的互补效应，推导出分布无关的下界，实证发现受益于AI协作的个体比例很大

Conclusion: 运筹学算法、LLM和人类在库存控制中具有互补性，运筹学增强的LLM方法表现最佳，人机协作能提高决策质量，存在显著的个体互补效应，为整合传统算法与AI方法提供了实证支持

Abstract: Inventory control is a fundamental operations problem in which ordering decisions are traditionally guided by theoretically grounded operations research (OR) algorithms. However, such algorithms often rely on rigid modeling assumptions and can perform poorly when demand distributions shift or relevant contextual information is unavailable. Recent advances in large language models (LLMs) have generated interest in AI agents that can reason flexibly and incorporate rich contextual signals, but it remains unclear how best to incorporate LLM-based methods into traditional decision-making pipelines.
  We study how OR algorithms, LLMs, and humans can interact and complement each other in a multi-period inventory control setting. We construct InventoryBench, a benchmark of over 1,000 inventory instances spanning both synthetic and real-world demand data, designed to stress-test decision rules under demand shifts, seasonality, and uncertain lead times. Through this benchmark, we find that OR-augmented LLM methods outperform either method in isolation, suggesting that these methods are complementary rather than substitutes.
  We further investigate the role of humans through a controlled classroom experiment that embeds LLM recommendations into a human-in-the-loop decision pipeline. Contrary to prior findings that human-AI collaboration can degrade performance, we show that, on average, human-AI teams achieve higher profits than either humans or AI agents operating alone. Beyond this population-level finding, we formalize an individual-level complementarity effect and derive a distribution-free lower bound on the fraction of individuals who benefit from AI collaboration; empirically, we find this fraction to be substantial.

</details>


### [10] [Think Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents](https://arxiv.org/abs/2602.12662)
*Ruihan Yang,Fanghua Ye,Xiang We,Ruoqing Zhao,Kang Luo,Xinbo Xu,Bo Zhao,Ruotian Ma,Shanyi Wang,Zhaopeng Tu,Xiaolong Li,Deqing Yang,Linus*

Main category: cs.AI

TL;DR: CogRouter框架训练智能体动态调整认知深度，通过四层认知层次和两阶段训练，在长视野任务中实现高效决策，显著提升成功率并减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体采用固定的认知模式：非思考模型生成即时响应，思考模型则统一进行深度推理。这种刚性在长视野任务中效率低下，因为不同步骤的认知需求差异很大，有些需要战略规划，有些只需常规执行。

Method: 基于ACT-R理论设计四个层次化认知级别（从本能反应到战略规划）。采用两阶段训练：认知感知监督微调（CoSFT）建立稳定的级别特定模式，认知感知策略优化（CoPO）通过置信度感知优势重加权进行步骤级信用分配。核心洞察是适当的认知深度应最大化最终动作的置信度。

Result: 在ALFWorld和ScienceWorld实验中，CogRouter达到最先进性能且效率优越。使用Qwen2.5-7B模型，达到82.3%成功率，优于GPT-4o（+40.3%）、OpenAI-o3（+18.3%）和GRPO（+14.0%），同时减少62%的token使用量。

Conclusion: CogRouter通过动态调整认知深度，在长视野决策任务中实现了性能与效率的平衡，为LLM智能体的认知灵活性提供了有效框架。

Abstract: Large language models (LLMs) are increasingly deployed as autonomous agents for multi-turn decision-making tasks. However, current agents typically rely on fixed cognitive patterns: non-thinking models generate immediate responses, while thinking models engage in deep reasoning uniformly. This rigidity is inefficient for long-horizon tasks, where cognitive demands vary significantly from step to step, with some requiring strategic planning and others only routine execution. In this paper, we introduce CogRouter, a framework that trains agents to dynamically adapt cognitive depth at each step. Grounded in ACT-R theory, we design four hierarchical cognitive levels ranging from instinctive responses to strategic planning. Our two-stage training approach includes Cognition-aware Supervised Fine-tuning (CoSFT) to instill stable level-specific patterns, and Cognition-aware Policy Optimization (CoPO) for step-level credit assignment via confidence-aware advantage reweighting. The key insight is that appropriate cognitive depth should maximize the confidence of the resulting action. Experiments on ALFWorld and ScienceWorld demonstrate that CogRouter achieves state-of-the-art performance with superior efficiency. With Qwen2.5-7B, it reaches an 82.3% success rate, outperforming GPT-4o (+40.3%), OpenAI-o3 (+18.3%), and GRPO (+14.0%), while using 62% fewer tokens.

</details>


### [11] [Evaluating Robustness of Reasoning Models on Parameterized Logical Problems](https://arxiv.org/abs/2602.12665)
*Naïm Es-sebbani,Esteban Marquer,Yakoub Salhi,Zied Bouraoui*

Main category: cs.AI

TL;DR: 该研究创建了一个诊断性2-SAT基准测试，通过参数化公式家族分离表面难度与结构现象，揭示LLM推理器的特定能力与失败模式


<details>
  <summary>Details</summary>
Motivation: 标准SAT基准测试常常混淆表面难度（长度、措辞、子句顺序）与决定可满足性的实际结构现象，需要更精细的诊断工具来评估LLM推理器的真实能力

Method: 构建基于参数化结构化2-CNF公式的诊断基准，通过五种生成器隔离不同能力：矛盾循环UNSAT核心、控制解多样性的SAT实例、植入骨干、延迟桥接子句、对称/重复变体

Result: 评估显示LLM推理器在目标结构干预下表现出急剧的性能转变，即使表面统计特征保持不变，揭示了在聚合SAT准确率中不可见的脆弱性区域

Conclusion: 该诊断基准能够揭示LLM推理器在特定结构现象下的能力边界和失败模式，为更精细的评估提供了工具，表明表面统计特征不足以反映推理器的真实鲁棒性

Abstract: Logic provides a controlled testbed for evaluating LLM-based reasoners, yet standard SAT-style benchmarks often conflate surface difficulty (length, wording, clause order) with the structural phenomena that actually determine satisfiability. We introduce a diagnostic benchmark for 2-SAT built from parameterized families of structured 2--CNF formulas, where satisfiability is characterized by the implication graph and can be tuned along interpretable axes. Our generators isolate distinct competencies and failure modes: (i) contradiction-cycle UNSAT cores with controllable size and imbalance, (ii) SAT instances with a prescribed fraction of free variables to control solution multiplicity, (iii) planted backbones that modulate propagation, (iv) late bridge clauses that couple otherwise monotone regions to probe sensitivity to ordering and revision, and (v) symmetry/duplication variants that test abstraction under renaming and redundant structure. We evaluate LLM-based reasoners on decision accuracy and assignment validity, and quantify robustness under semantics-preserving perturbations such as clause reordering, filler clauses, and variable renaming. Across models, we observe sharp performance transitions under targeted structural interventions even when surface statistics are held fixed, revealing brittleness regimes that are invisible to aggregate SAT accuracy.

</details>


### [12] [X-SYS: A Reference Architecture for Interactive Explanation Systems](https://arxiv.org/abs/2602.12748)
*Tobias Labarta,Nhi Hoang,Maximilian Dreyer,Jim Berend,Oleg Hein,Jackie Ma,Wojciech Samek,Sebastian Lapuschkin*

Main category: cs.AI

TL;DR: 论文提出X-SYS参考架构，将可解释AI系统化，通过STAR质量属性和五组件分解解决交互式解释系统的部署挑战。


<details>
  <summary>Details</summary>
Motivation: 当前可解释AI研究提出了许多技术方法，但将可解释性部署为系统仍然面临挑战。交互式解释系统需要合适的算法和系统能力，以在重复查询、模型和数据演化以及治理约束下保持解释可用性。作者认为，将可解释AI操作化需要将其视为信息系统问题，用户交互需求引发特定的系统要求。

Method: 提出X-SYS参考架构，围绕四个STAR质量属性（可扩展性、可追溯性、响应性和适应性）组织，并指定五组件分解（XUI服务、解释服务、模型服务、数据服务、编排与治理）。该架构将交互模式映射到系统能力，实现用户界面演进与后端计算的解耦。通过SemanticLens系统实现X-SYS，该系统用于视觉语言模型的语义搜索和激活引导。

Result: X-SYS架构通过基于契约的服务边界实现独立演进，离线/在线分离确保响应性，持久状态管理支持可追溯性。SemanticLens系统展示了该架构的具体实现，为交互式解释系统提供了可重用的蓝图和具体实例。

Conclusion: 这项工作为交互式解释系统提供了可重用的蓝图和具体实现，支持在操作约束下的端到端设计，帮助(X)AI研究人员、开发者和从业者将交互式解释用户界面与系统能力连接起来。

Abstract: The explainable AI (XAI) research community has proposed numerous technical methods, yet deploying explainability as systems remains challenging: Interactive explanation systems require both suitable algorithms and system capabilities that maintain explanation usability across repeated queries, evolving models and data, and governance constraints. We argue that operationalizing XAI requires treating explainability as an information systems problem where user interaction demands induce specific system requirements. We introduce X-SYS, a reference architecture for interactive explanation systems, that guides (X)AI researchers, developers and practitioners in connecting interactive explanation user interfaces (XUI) with system capabilities. X-SYS organizes around four quality attributes named STAR (scalability, traceability, responsiveness, and adaptability), and specifies a five-component decomposition (XUI Services, Explanation Services, Model Services, Data Services, Orchestration and Governance). It maps interaction patterns to system capabilities to decouple user interface evolution from backend computation. We implement X-SYS through SemanticLens, a system for semantic search and activation steering in vision-language models. SemanticLens demonstrates how contract-based service boundaries enable independent evolution, offline/online separation ensures responsiveness, and persistent state management supports traceability. Together, this work provides a reusable blueprint and concrete instantiation for interactive explanation systems supporting end-to-end design under operational constraints.

</details>


### [13] [Information-theoretic analysis of world models in optimal reward maximizers](https://arxiv.org/abs/2602.12963)
*Alfred Harwood,Jose Faustino,Alex Altair*

Main category: cs.AI

TL;DR: 该论文量化了最优策略关于环境的信息量，证明在n状态m动作的受控马尔可夫过程中，最优策略与环境之间的互信息为n log m比特


<details>
  <summary>Details</summary>
Motivation: AI领域一个重要问题是成功行为在多大程度上需要内部世界表示。本研究旨在量化最优策略提供的关于底层环境的信息量，为"隐式世界模型"提供信息论下界。

Method: 考虑具有n个状态和m个动作的受控马尔可夫过程，假设在可能的转移动态空间上具有均匀先验。分析确定性最优策略（针对任何非常数奖励函数）与环境之间的互信息。

Result: 证明观测到针对任何非常数奖励函数的最优确定性策略恰好传递n log m比特的环境信息。具体而言，环境与最优策略之间的互信息为n log m比特。

Conclusion: 该结果为最优性所需的"隐式世界模型"提供了精确的信息论下界，这一界限适用于包括有限时域、无限时域折扣和时间平均奖励最大化在内的广泛目标类别。

Abstract: An important question in the field of AI is the extent to which successful behaviour requires an internal representation of the world. In this work, we quantify the amount of information an optimal policy provides about the underlying environment. We consider a Controlled Markov Process (CMP) with $n$ states and $m$ actions, assuming a uniform prior over the space of possible transition dynamics. We prove that observing a deterministic policy that is optimal for any non-constant reward function then conveys exactly $n \log m$ bits of information about the environment. Specifically, we show that the mutual information between the environment and the optimal policy is $n \log m$ bits. This bound holds across a broad class of objectives, including finite-horizon, infinite-horizon discounted, and time-averaged reward maximization. These findings provide a precise information-theoretic lower bound on the "implicit world model'' necessary for optimality.

</details>


### [14] [Consistency of Large Reasoning Models Under Multi-Turn Attacks](https://arxiv.org/abs/2602.13093)
*Yubo Li,Ramayya Krishnan,Rema Padman*

Main category: cs.AI

TL;DR: 推理模型在对抗攻击下表现出有意义但不完整的鲁棒性，所有模型都存在特定漏洞，基于置信度的防御方法对推理模型失效


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型在复杂任务上达到最先进性能，但其在多轮对抗压力下的鲁棒性尚未得到充分探索，需要评估推理模型在对抗攻击下的表现

Method: 评估九个前沿推理模型在对抗攻击下的表现，通过轨迹分析识别失败模式，测试置信感知响应生成（CARG）方法对推理模型的有效性

Result: 推理提供有意义但不完整的鲁棒性：大多数推理模型显著优于指令调优基线，但所有模型都表现出不同的漏洞模式；误导性建议普遍有效，社交压力具有模型特定效果；识别出五种失败模式；CARG对推理模型失效，随机置信嵌入反而优于针对性提取

Conclusion: 推理能力不会自动赋予对抗鲁棒性，基于置信度的防御方法需要为推理模型进行根本性重新设计

Abstract: Large reasoning models with reasoning capabilities achieve state-of-the-art performance on complex tasks, but their robustness under multi-turn adversarial pressure remains underexplored. We evaluate nine frontier reasoning models under adversarial attacks. Our findings reveal that reasoning confers meaningful but incomplete robustness: most reasoning models studied significantly outperform instruction-tuned baselines, yet all exhibit distinct vulnerability profiles, with misleading suggestions universally effective and social pressure showing model-specific efficacy. Through trajectory analysis, we identify five failure modes (Self-Doubt, Social Conformity, Suggestion Hijacking, Emotional Susceptibility, and Reasoning Fatigue) with the first two accounting for 50% of failures. We further demonstrate that Confidence-Aware Response Generation (CARG), effective for standard LLMs, fails for reasoning models due to overconfidence induced by extended reasoning traces; counterintuitively, random confidence embedding outperforms targeted extraction. Our results highlight that reasoning capabilities do not automatically confer adversarial robustness and that confidence-based defenses require fundamental redesign for reasoning models.

</details>


### [15] [Constrained Assumption-Based Argumentation Frameworks](https://arxiv.org/abs/2602.13135)
*Emanuele De Angelis,Fabio Fioravanti,Maria Chiara Meo,Alberto Pettorossi,Maurizio Proietti,Francesca Toni*

Main category: cs.AI

TL;DR: 该论文提出了约束ABA（CABA）框架，通过引入约束变量来扩展传统ABA，使其能够处理非地面（包含变量）的论证和攻击，从而克服了传统ABA只能处理命题原子构成的限制。


<details>
  <summary>Details</summary>
Motivation: 传统基于假设的论证（ABA）框架存在表示限制，只能处理由命题原子构成的地面（无变量）论证和攻击，这限制了其适用性。需要扩展ABA以支持包含约束变量的非地面论证。

Method: 提出约束ABA（CABA）框架，允许框架组件和论证中包含约束变量，这些变量可以在可能无限的域上取值。定义了CABA的非地面语义，基于各种非地面攻击概念。

Result: 新提出的CABA框架能够处理非地面论证，其语义保守地推广了标准ABA语义，即当所有变量都被实例化时，CABA语义与标准ABA语义一致。

Conclusion: CABA框架成功扩展了传统ABA，使其能够处理包含约束变量的非地面论证，同时保持与标准ABA语义的兼容性，为ABA框架提供了更广泛的应用可能性。

Abstract: Assumption-based Argumentation (ABA) is a well-established form of structured argumentation. ABA frameworks with an underlying atomic language are widely studied, but their applicability is limited by a representational restriction to ground (variable-free) arguments and attacks built from propositional atoms. In this paper, we lift this restriction and propose a novel notion of constrained ABA (CABA), whose components, as well as arguments built from them, may include constrained variables, ranging over possibly infinite domains. We define non-ground semantics for CABA, in terms of various notions of non-ground attacks. We show that the new semantics conservatively generalise standard ABA semantics.

</details>


### [16] [Optimal Take-off under Fuzzy Clearances](https://arxiv.org/abs/2602.13166)
*Hugo Henry,Arthur Tsai,Kelly Cohen*

Main category: cs.AI

TL;DR: 提出了一种结合最优控制与模糊规则系统的混合避障架构，用于无人机自适应约束处理，但发现FALCON和IPOPT软件存在兼容性问题导致约束无法正确执行。


<details>
  <summary>Details</summary>
Motivation: 传统最优控制在不确定性下的局限性，以及航空安全关键系统需要可解释的决策制定，促使开发能够自适应处理约束的混合架构。

Method: 设计了三阶段Takagi-Sugeno-Kang模糊层，基于FAA和EASA的监管分离最小值和适航指南来调制约束半径、紧急级别和激活决策，然后将模糊推导的间隙作为软约束纳入最优控制问题，使用FALCON工具箱和IPOPT求解。

Result: 概念验证显示每迭代计算时间为2-3秒，表明近实时应用可行性，但发现FALCON和IPOPT最新版本存在软件不兼容问题，拉格朗日惩罚项恒为零，导致约束无法正确执行。

Conclusion: 该混合架构在简化飞机模型中展示了可行性，但软件兼容性问题需要解决。未来工作包括验证软件回归问题、优化模糊隶属函数，以及扩展到更高保真度飞机模型和随机障碍环境。

Abstract: This paper presents a hybrid obstacle avoidance architecture that integrates Optimal Control under clearance with a Fuzzy Rule Based System (FRBS) to enable adaptive constraint handling for unmanned aircraft. Motivated by the limitations of classical optimal control under uncertainty and the need for interpretable decision making in safety critical aviation systems, we design a three stage Takagi Sugeno Kang fuzzy layer that modulates constraint radii, urgency levels, and activation decisions based on regulatory separation minima and airworthiness guidelines from FAA and EASA. These fuzzy-derived clearances are then incorporated as soft constraints into an optimal control problem solved using the FALCON toolbox and IPOPT. The framework aims to reduce unnecessary recomputations by selectively activating obstacle avoidance updates while maintaining compliance with aviation procedures. A proof of concept implementation using a simplified aircraft model demonstrates that the approach can generate optimal trajectories with computation times of 2,3 seconds per iteration in a single threaded MATLAB environment, suggesting feasibility for near real time applications. However, our experiments revealed a critical software incompatibility in the latest versions of FALCON and IPOPT, in which the Lagrangian penalty term remained identically zero, preventing proper constraint enforcement. This behavior was consistent across scenarios and indicates a solver toolbox regression rather than a modeling flaw. Future work includes validating this effect by reverting to earlier software versions, optimizing the fuzzy membership functions using evolutionary methods, and extending the system to higher fidelity aircraft models and stochastic obstacle environments.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [17] [Secrecy and Verifiability: An Introduction to Electronic Voting](https://arxiv.org/abs/2602.12398)
*Paul Keeler,Ben Smyth*

Main category: cs.CR

TL;DR: 这篇教程论文向非电子投票领域的读者介绍了现代密码学在电子投票系统中的应用，重点阐述了如何通过非对称加密和同态加密等技术，在保证选票保密性的同时实现选举结果的可验证性。


<details>
  <summary>Details</summary>
Motivation: 民主制度依赖于安全可靠的投票系统。电子投票系统试图用计算机硬件和软件替代纸质选票和投票箱，但现有的电子选举方案存在固有缺陷和弱点。受到物理投票系统的启发，作者认为任何电子投票系统都需要两个基本属性：选票保密性和可验证性，这两个属性看似相互矛盾。

Method: 使用现代密码学的标准工具，包括非对称加密和同态加密技术，构建一个通用的电子选举方案。采用基于博弈的密码学方法，将选举形式化为博弈，并在此框架下给出选票保密性和可验证性的精确定义。

Result: 通过密码学技术实现了选票保密性和选举结果可验证性之间的平衡，使电子投票系统既能保护投票隐私，又能验证选举结果的正确性。

Conclusion: 电子投票系统可以通过现代密码学工具实现选票保密性和可验证性的双重目标。这篇教程旨在向电子投票领域外的读者介绍现代研究方法，使这些复杂概念更易于理解。

Abstract: Democracies are built upon secure and reliable voting systems. Electronic voting systems seek to replace ballot papers and boxes with computer hardware and software. Proposed electronic election schemes have been subjected to scrutiny, with researchers spotting inherent faults and weaknesses. Inspired by physical voting systems, we argue that any electronic voting system needs two essential properties: ballot secrecy and verifiability. These properties seemingly work against each other. An election scheme that is a complete black box offers ballot secrecy, but verification of the outcome is impossible. This challenge can be tackled using standard tools from modern cryptography, reaching a balance that delivers both properties.
  This tutorial makes these ideas accessible to readers outside electronic voting. We introduce fundamental concepts such as asymmetric and homomorphic encryption, which we use to describe a general electronic election scheme while keeping mathematical formalism minimal. We outline game-based cryptography, a standard approach in modern cryptography, and introduce notation for formulating elections as games. We then give precise definitions of ballot secrecy and verifiability in the framework of game-based cryptography. A principal aim is introducing modern research approaches to electronic voting.

</details>


### [18] [Sparse Autoencoders are Capable LLM Jailbreak Mitigators](https://arxiv.org/abs/2602.12418)
*Yannick Assogba,Jacopo Cortellazzi,Javier Abad,Pau Rodriguez,Xavier Suau,Arno Blaas*

Main category: cs.CR

TL;DR: CC-Delta是一种基于稀疏自编码器的防御方法，通过比较有害请求在有/无越狱上下文时的token级表示，识别越狱相关稀疏特征，并在推理时进行均值漂移引导，有效防御越狱攻击。


<details>
  <summary>Details</summary>
Motivation: 越狱攻击对大型语言模型安全构成持续威胁，现有防御方法存在局限性，需要开发更有效的防御机制来保护模型安全。

Method: 提出上下文条件化Delta引导（CC-Delta）：1）使用成对的有害/越狱提示比较token级表示；2）通过统计测试选择越狱相关稀疏特征；3）在SAE潜在空间进行推理时均值漂移引导。

Result: 在四个对齐的指令调优模型和十二种越狱攻击上，CC-Delta在安全-效用权衡方面达到或优于在密集潜在空间操作的基线防御方法。特别是在所有四个模型上都明显优于密集均值漂移引导，对分布外攻击效果尤为显著。

Conclusion: 稀疏SAE特征空间引导相比密集激活空间引导在越狱缓解方面具有优势，现成的为可解释性训练的SAE可以被重新用作实用的越狱防御工具，无需任务特定训练。

Abstract: Jailbreak attacks remain a persistent threat to large language model safety. We propose Context-Conditioned Delta Steering (CC-Delta), an SAE-based defense that identifies jailbreak-relevant sparse features by comparing token-level representations of the same harmful request with and without jailbreak context. Using paired harmful/jailbreak prompts, CC-Delta selects features via statistical testing and applies inference-time mean-shift steering in SAE latent space. Across four aligned instruction-tuned models and twelve jailbreak attacks, CC-Delta achieves comparable or better safety-utility tradeoffs than baseline defenses operating in dense latent space. In particular, our method clearly outperforms dense mean-shift steering on all four models, and particularly against out-of-distribution attacks, showing that steering in sparse SAE feature space offers advantages over steering in dense activation space for jailbreak mitigation. Our results suggest off-the-shelf SAEs trained for interpretability can be repurposed as practical jailbreak defenses without task-specific training.

</details>


### [19] [DRAMatic Speedup: Accelerating HE Operations on a Processing-in-Memory System](https://arxiv.org/abs/2602.12433)
*Niklas Klinger,Jonas Sander,Peterson Yuhala,Pascal Felber,Thomas Eisenbarth*

Main category: cs.CR

TL;DR: DRAMatic是一个在UPMEM PIM系统上实现同态加密基础操作的框架，通过多种算术优化显著缩小了与Microsoft SEAL的性能差距，但受限于PIM的乘法性能和数据传输开销。


<details>
  <summary>Details</summary>
Motivation: 同态加密（HE）是保密云计算的有前景技术，但计算成本高且在传统架构上受内存限制。内存内处理（PIM）架构具有更高内存带宽，可能适合加速HE。

Method: 在UPMEM的可编程通用PIM系统上实现DRAMatic框架，采用余数系统和数论变换等算术优化技术，支持安全同态评估所需的大参数。

Result: DRAMatic显著缩小了UPMEM PIM与Microsoft SEAL之间的性能差距，但受限于UPMEM PIM的乘法性能和数据传输开销。

Conclusion: PIM架构有潜力加速同态加密，但需要硬件扩展来改进乘法性能和减少数据传输开销。

Abstract: Homomorphic encryption (HE) is a promising technology for confidential cloud computing, as it allows computations on encrypted data. However, HE is computationally expensive and often memory-bound on conventional computer architectures. Processing-in-Memory (PIM) is an alternative hardware architecture that integrates processing units and memory on the same chip or memory module. PIM enables higher memory bandwidth than conventional architectures and could thus be suitable for accelerating HE. In this work, we present DRAMatic, which implements operations foundational to HE on UPMEM's programmable, general-purpose PIM system, and evaluate its performance. DRAMatic incorporates many arithmetic optimizations, including residue number system and number-theoretic transform techniques, and can support the large parameters required for secure homomorphic evaluations. To compare performance, we evaluate DRAMatic against Microsoft SEAL, a popular open-source HE library, regarding both runtime and energy efficiency. The results show that DRAMatic significantly closes the gap between UPMEM PIM and Microsoft SEAL. However, we also show that DRAMatic is currently constrained by UPMEM PIM's multiplication performance and data transfer overhead. Finally, we discuss potential hardware extensions to UPMEM PIM.

</details>


### [20] [TensorCommitments: A Lightweight Verifiable Inference for Language Models](https://arxiv.org/abs/2602.12630)
*Oguzhan Baser,Elahe Sadeghi,Eric Wang,David Ribeiro Alves,Sam Kazemian,Hong Kang,Sandeep P. Chinchali,Sriram Vishwanath*

Main category: cs.CR

TL;DR: TensorCommitments (TCs) 是一种用于验证大语言模型推理正确性的方案，通过张量原生承诺和多元Terkle树，在LLaMA2上仅增加0.97%的证明时间和0.12%的验证时间，同时将对抗攻击的鲁棒性提升48%。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型大多运行在外部云上，用户需要信任远程GPU正确执行推理而不被篡改。现有密码学方法在大语言模型规模下太慢，而非密码学方法需要强大的验证者GPU。需要一种既能验证推理正确性又高效的方案。

Method: 提出TensorCommitments (TCs)，一种张量原生的推理证明方案。TC将LLM推理绑定到一个承诺上，这是一个不可逆的标签，在篡改时会失效。该方法使用多元Terkle树来组织承诺。

Result: 在LLaMA2上，TC仅增加0.97%的证明者时间和0.12%的验证者时间，相比需要验证者GPU的最佳先前工作，对定制LLM攻击的鲁棒性提升了48%。

Conclusion: TensorCommitments提供了一种高效、鲁棒的验证大语言模型推理正确性的方案，解决了现有方法在性能和安全性方面的不足。

Abstract: Most large language models (LLMs) run on external clouds: users send a prompt, pay for inference, and must trust that the remote GPU executes the LLM without any adversarial tampering. We critically ask how to achieve verifiable LLM inference, where a prover (the service) must convince a verifier (the client) that an inference was run correctly without rerunning the LLM. Existing cryptographic works are too slow at the LLM scale, while non-cryptographic ones require a strong verifier GPU. We propose TensorCommitments (TCs), a tensor-native proof-of-inference scheme. TC binds the LLM inference to a commitment, an irreversible tag that breaks under tampering, organized in our multivariate Terkle Trees. For LLaMA2, TC adds only 0.97% prover and 0.12% verifier time over inference while improving robustness to tailored LLM attacks by up to 48% over the best prior work requiring a verifier GPU.

</details>


### [21] [Fool Me If You Can: On the Robustness of Binary Code Similarity Detection Models against Semantics-preserving Transformations](https://arxiv.org/abs/2602.12681)
*Jiyong Uhm,Minseok Kim,Michalis Polychronakis,Hyungjoon Koo*

Main category: cs.CR

TL;DR: 论文评估了二进制代码相似性检测（BCSD）深度学习模型在语义保持变换下的鲁棒性，提出了asmFooler系统来测试模型对抗性变换的抵抗力。


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习在二进制代码分析中应用日益增多，但现有模型在二进制级别对抗性代码变换下的鲁棒性尚未得到充分研究。二进制代码的独特性质使其面临与常规输入扰动不同的挑战。

Method: 提出了asmFooler系统，使用八种语义保持的对抗性代码变换来评估六个代表性BCSD模型的鲁棒性。构建了包含9,565个二进制变体的数据集，来自620个基准样本。

Result: 主要发现：1）模型鲁棒性依赖于处理流程（代码预处理、架构、特征选择）；2）对抗性变换的有效性受模型特定约束（输入大小、指令表达能力）形成的预算限制；3）精心设计的变换能以最小扰动实现高效攻击；4）通过关注语义重要指令，这些变换能有效破坏模型决策。

Conclusion: 二进制代码相似性检测模型在对抗性语义保持变换下存在脆弱性，需要更鲁棒的模型设计和评估框架。asmFooler为评估和改进BCSD模型鲁棒性提供了系统方法。

Abstract: Binary code analysis plays an essential role in cybersecurity, facilitating reverse engineering to reveal the inner workings of programs in the absence of source code. Traditional approaches, such as static and dynamic analysis, extract valuable insights from stripped binaries, but often demand substantial expertise and manual effort. Recent advances in deep learning have opened promising opportunities to enhance binary analysis by capturing latent features and disclosing underlying code semantics. Despite the growing number of binary analysis models based on machine learning, their robustness to adversarial code transformations at the binary level remains underexplored. We evaluate the robustness of deep learning models for the task of binary code similarity detection (BCSD) under semantics-preserving transformations. The unique nature of machine instructions presents distinct challenges compared to the typical input perturbations found in other domains. We introduce asmFooler, a system that evaluates the resilience of BCSD models using a diverse set of adversarial code transformations that preserve functional semantics. We construct a dataset of 9,565 binary variants from 620 baseline samples by applying eight semantics-preserving transformations across six representative BCSD models. Our major findings highlight several key insights: i) model robustness relies on the processing pipeline, including code pre-processing, architecture, and feature selection; ii) adversarial transformation effectiveness is bounded by a budget shaped by model-specific constraints like input size and instruction expressive capacity; iii) well-crafted transformations can be highly effective with minimal perturbations; and iv) such transformations efficiently disrupt model decisions (e.g., misleading to false positives or false negatives) by focusing on semantically significant instructions.

</details>


### [22] [Reliable Hierarchical Operating System Fingerprinting via Conformal Prediction](https://arxiv.org/abs/2602.12825)
*Rubén Pérez-Jove,Osvaldo Simeone,Alejandro Pazos,Jose Vázquez-Naya*

Main category: cs.CR

TL;DR: 该研究针对操作系统指纹识别缺乏不确定性量化的问题，提出了两种结构化共形预测方法，在保证覆盖率的同时考虑了操作系统的层次化分类结构。


<details>
  <summary>Details</summary>
Motivation: 传统操作系统指纹识别方法缺乏正式的不确定性量化机制，且将OS识别视为扁平分类问题，忽略了操作系统的自然分类层次结构，导致预测结果脆弱。

Method: 提出了两种结构化共形预测策略：1) 层级共形预测(L-CP)：独立校准每个层次级别；2) 投影共形预测(P-CP)：通过将叶级集合向上投影来确保结构一致性。

Result: 两种方法都满足有效性保证，但揭示了层级效率与结构一致性之间的基本权衡。L-CP产生更紧凑的预测集适合人工取证分析，但存在分类不一致性；P-CP保证层次一致的嵌套集适合自动化策略执行，但在较粗粒度级别效率降低。

Conclusion: 结构化共形预测方法为操作系统指纹识别提供了具有理论保证的不确定性量化，同时考虑了分类层次结构，在效率与一致性之间存在权衡，可根据应用场景选择合适方法。

Abstract: Operating System (OS) fingerprinting is critical for network security, but conventional methods do not provide formal uncertainty quantification mechanisms. Conformal Prediction (CP) could be directly wrapped around existing methods to obtain prediction sets with guaranteed coverage. However, a direct application of CP would treat OS identification as a flat classification problem, ignoring the natural taxonomic structure of OSs and providing brittle point predictions. This work addresses these limitations by introducing and evaluating two distinct structured CP strategies: level-wise CP (L-CP), which calibrates each hierarchy level independently, and projection-based CP (P-CP), which ensures structural consistency by projecting leaf-level sets upwards. Our results demonstrate that, while both methods satisfy validity guarantees, they expose a fundamental trade-off between level-wise efficiency and structural consistency. L-CP yields tighter prediction sets suitable for human forensic analysis but suffers from taxonomic inconsistencies. Conversely, P-CP guarantees hierarchically consistent, nested sets ideal for automated policy enforcement, albeit at the cost of reduced efficiency at coarser levels.

</details>


### [23] [Neighborhood Blending: A Lightweight Inference-Time Defense Against Membership Inference Attacks](https://arxiv.org/abs/2602.12943)
*Osama Zafar,Shaojie Zhan,Tianxi Ji,Erman Ayday*

Main category: cs.CR

TL;DR: 提出Neighborhood Blending防御方法，通过查询样本邻域的差分隐私采样平滑模型置信度输出，在推理阶段抵御成员推理攻击，保持零标签损失和高实用性。


<details>
  <summary>Details</summary>
Motivation: 机器学习即服务(MLaaS)在敏感环境中的广泛应用引发了隐私担忧，特别是成员推理攻击(MIAs)能够判断特定记录是否在训练集中。现有防御方法如对抗正则化、DP-SGD和MemGuard存在实用性降低、计算开销大或保护不一致等问题。

Method: 提出Neighborhood Blending推理时防御机制，无需重新训练模型。通过差分隐私采样选择查询样本的相似训练样本，平均这些样本的预测结果来平滑模型置信度输出，建立一致的置信度模式，使成员和非成员对攻击者不可区分。采用自适应"按需付费"失真策略保持标签完整性和高实用性。

Result: 通过多个数据集和模型的广泛实验表明，该方法显著降低了MIA成功率，同时保持了模型性能。在实用性保留方面优于MemGuard等后处理防御方法和DP-SGD等训练时技术。

Conclusion: Neighborhood Blending提供了一种模型无关、轻量级的实用解决方案，在不牺牲模型实用性的情况下增强隐私保护，是抵御成员推理攻击的有效推理时防御机制。

Abstract: In recent years, the widespread adoption of Machine Learning as a Service (MLaaS), particularly in sensitive environments, has raised considerable privacy concerns. Of particular importance are membership inference attacks (MIAs), which exploit behavioral discrepancies between training and non-training data to determine whether a specific record was included in the model's training set, thereby presenting significant privacy risks. Although existing defenses, such as adversarial regularization, DP-SGD, and MemGuard, assist in mitigating these threats, they often entail trade-offs such as compromising utility, increased computational requirements, or inconsistent protection against diverse attack vectors.
  In this paper, we introduce a novel inference-time defense mechanism called Neighborhood Blending, which mitigates MIAs without retraining the model or incurring significant computational overhead. Our approach operates post-training by smoothing the model's confidence outputs based on the neighborhood of a queried sample. By averaging predictions from similar training samples selected using differentially private sampling, our method establishes a consistent confidence pattern, rendering members and non-members indistinguishable to an adversary while maintaining high utility. Significantly, Neighborhood Blending maintains label integrity (zero label loss) and ensures high utility through an adaptive, "pay-as-you-go" distortion strategy. It is a model-agnostic approach that offers a practical, lightweight solution that enhances privacy without sacrificing model utility. Through extensive experiments across diverse datasets and models, we demonstrate that our defense significantly reduces MIA success rates while preserving model performance, outperforming existing post-hoc defenses like MemGuard and training-time techniques like DP-SGD in terms of utility retention.

</details>


### [24] [TrustMee: Self-Verifying Remote Attestation Evidence](https://arxiv.org/abs/2602.13148)
*Parsa Sadri Sinaki,Zainab Ahmad,Wentao Xie,Merlijn Sebrechts,Jimmy Kjällman,Lachlan J. Gunn*

Main category: cs.CR

TL;DR: 论文提出自验证远程证明证据概念，将验证逻辑嵌入WebAssembly组件中，使验证者无需平台特定知识即可验证机密虚拟机完整性。


<details>
  <summary>Details</summary>
Motivation: 硬件安全的远程证明对于建立机密虚拟机完整性信任至关重要，但实际使用困难，因为验证证明证据需要硬件特定的加密逻辑，增加了维护成本和验证者的可信计算基。

Method: 引入自验证远程证明证据概念，每个证明包包含由可信方签名的WebAssembly组件作为验证逻辑，将证据验证转化为标准代码签名问题：验证者检查嵌入式逻辑的签名，然后执行它以验证证据。

Result: 实现TrustMee作为平台无关的验证驱动程序，为AMD SEV-SNP和Intel TDX证明生成自验证证据，并以标准EAT证明结果格式生成证明声明。

Conclusion: 自验证远程证明证据方法使验证者无需平台特定知识即可验证证明证据，降低了维护成本和可信计算基要求，提高了远程证明的实用性和可扩展性。

Abstract: Hardware-secured remote attestation is essential to establishing trust in the integrity of confidential virtual machines (cVMs), but is difficult to use in practice because verifying attestation evidence requires the use of hardware-specific cryptographic logic. This increases both maintenance costs and the verifiers' trusted computing base. We introduce the concept of self-verifying remote attestation evidence. Each attestation bundle includes verification logic as a WebAssembly component signed by a trusted party. This approach transforms evidence verification into a standard code-signing problem: the verifier checks the signature on the embedded logic and then executes it to validate the evidence. As a result, verifiers can validate attestation evidence without any platform-specific knowledge. We implement this concept as TrustMee, a platform-agnostic verification driver for the Trustee framework. We demonstrate its functionality with self-verifying evidence for AMD SEV-SNP and Intel TDX attestations, producing attestation claims in the standard EAT Attestation Result (EAR) format.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [25] [Classification of Local Optimization Problems in Directed Cycles](https://arxiv.org/abs/2602.13046)
*Thomas Boudier,Fabian Kuhn,Augusto Modanese,Ronja Stimpert,Jukka Suomela*

Main category: cs.DC

TL;DR: 该论文对定向环中局部优化问题的分布式计算复杂度进行了完整分类，确定了四种可能的复杂度类别，并提供了自动确定复杂度和合成最优分布式算法的元算法。


<details>
  <summary>Details</summary>
Motivation: 局部优化问题（如最大独立集、最小顶点覆盖等）是分布式计算中的重要问题，但之前的研究主要关注局部搜索问题。本文旨在对更一般的局部优化问题在定向环中的计算复杂度进行系统分类。

Method: 研究分析了定向环中局部优化问题的分布式计算复杂度，考虑了确定性LOCAL和随机化LOCAL模型，涵盖了min-sum、max-sum、min-max、max-min等形式的优化问题。开发了自动确定复杂度类和合成最优分布式算法的元算法。

Result: 证明了对于任何局部优化问题和任何常数近似比α，在定向环中求α-近似解只有四种可能的复杂度：1) O(1)轮确定性，O(1)轮随机化；2) Θ(log* n)轮确定性，O(1)轮随机化；3) Θ(log* n)轮确定性，Θ(log* n)轮随机化；4) Θ(n)轮确定性，Θ(n)轮随机化。

Conclusion: 本文首次对定向环中局部优化问题的分布式计算复杂度进行了完整分类，扩展了之前仅针对局部搜索问题的结果，为分布式优化算法设计提供了理论基础和实用工具。

Abstract: We present a complete classification of the distributed computational complexity of local optimization problems in directed cycles for both the deterministic and the randomized LOCAL model. We show that for any local optimization problem $Π$ (that can be of the form min-sum, max-sum, min-max, or max-min, for any local cost or utility function over some finite alphabet), and for any \emph{constant} approximation ratio $α$, the task of finding an $α$-approximation of $Π$ in directed cycles has one of the following complexities:
  1. $O(1)$ rounds in deterministic LOCAL, $O(1)$ rounds in randomized LOCAL,
  2. $Θ(\log^* n)$ rounds in deterministic LOCAL, $O(1)$ rounds in randomized LOCAL,
  3. $Θ(\log^* n)$ rounds in deterministic LOCAL, $Θ(\log^* n)$ rounds in randomized LOCAL,
  4. $Θ(n)$ rounds in deterministic LOCAL, $Θ(n)$ rounds in randomized LOCAL.
  Moreover, for any given $Π$ and $α$, we can determine the complexity class automatically, with an efficient (centralized, sequential) meta-algorithm, and we can also efficiently synthesize an asymptotically optimal distributed algorithm.
  Before this work, similar results were only known for local search problems (e.g., locally checkable labeling problems). The family of local optimization problems is a strict generalization of local search problems, and it contains numerous commonly studied distributed tasks, such as the problems of finding approximations of the maximum independent set, minimum vertex cover, minimum dominating set, and minimum vertex coloring.

</details>


### [26] [Bloom Filter Look-Up Tables for Private and Secure Distributed Databases in Web3 (Revised Version)](https://arxiv.org/abs/2602.13167)
*Shlomi Dolev,Ehud Gudes,Daniel Shlomo*

Main category: cs.DC

TL;DR: 提出了一种基于BFLUT算法的去中心化密钥管理方案，通过编码和分布式存储保护密钥安全，结合OrbitDB、IPFS和IPNS技术实现高性能去中心化数据库。


<details>
  <summary>Details</summary>
Motivation: Web3生态系统中的去中心化系统面临数据安全、隐私和可扩展性挑战，特别是在分布式环境中管理加密密钥存在重大风险，节点可能被攻击者控制。

Method: 采用BFLUT算法对密钥进行编码和分布式存储，不直接存储密钥明文；利用OrbitDB、IPFS和IPNS构建去中心化数据管理系统，支持一致性、可扩展性和并发更新。

Result: 系统能够安全管理密钥，防止未授权访问，确保隐私保护，同时保持高性能和可靠性，为需要去中心化安全的Web3应用提供基础解决方案。

Conclusion: 提出的去中心化数据库方案通过创新的密钥管理方法，有效解决了Web3生态系统中的安全、隐私和可扩展性挑战，为去中心化应用提供了可靠的安全基础。

Abstract: The rapid growth of decentralized systems in theWeb3 ecosystem has introduced numerous challenges, particularly in ensuring data security, privacy, and scalability [3, 8]. These systems rely heavily on distributed architectures, requiring robust mechanisms to manage data and interactions among participants securely. One critical aspect of decentralized systems is key management, which is essential for encrypting files, securing database segments, and enabling private transactions. However, securely managing cryptographic keys in a distributed environment poses significant risks, especially when nodes in the network can be compromised [9]. This research proposes a decentralized database scheme specifically designed for secure and private key management. Our approach ensures that cryptographic keys are not stored explicitly at any location, preventing their discovery even if an attacker gains control of multiple nodes. Instead of traditional storage, keys are encoded and distributed using the BFLUT (Bloom Filter for Private Look-Up Tables) algorithm [7], which enables secure retrieval without direct exposure. The system leverages OrbitDB [4], IPFS [1], and IPNS [10] for decentralized data management, providing robust support for consistency, scalability, and simultaneous updates. By combining these technologies, our scheme enhances both security and privacy while maintaining high performance and reliability. Our findings demonstrate the system's capability to securely manage keys, prevent unauthorized access, and ensure privacy, making it a foundational solution for Web3 applications requiring decentralized security.

</details>

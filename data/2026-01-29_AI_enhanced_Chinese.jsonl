{"id": "2601.19900", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.19900", "abs": "https://arxiv.org/abs/2601.19900", "authors": ["William Oswald", "Mario Renteria-Pinon", "Md. Sajjad Hossain", "Kyle Mooney", "Md. Bipul Hossain", "Destinie Diggs", "Yiwen Xu", "Mohamed Shaban", "Jinhui Wang", "Na Gong"], "title": "Flexible Bit-Truncation Memory for Approximate Applications on the Edge", "comment": null, "summary": "Bit truncation has demonstrated great potential to enable run-time quality-power adaptive data storage, thereby optimizing the power/energy efficiency of approximate applications and supporting their deployment in edge environments. However, existing bit-truncation memories require custom designs for a specific application. In this paper, we present a novel bit-truncation memory with full adaptation flexibility, which can truncate any number of data bits at run time to meet different quality and power trade-off requirements for various approximate applications. The developed bit-truncation memory has been applied to two representative data-intensive approximate applications: video processing and deep learning. Our experiments show that the proposed memory can support three different video applications (including luminance-aware, content-aware, and region-of-interest-aware) with enhanced power efficiency (up to 47.02% power savings) as compared to state-of-the-art. In addition, the proposed memory achieves significant (up to 51.69%) power savings for both baseline and pruned lightweight deep learning models, respectively, with a low implementation cost (2.89% silicon area overhead).", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5177\u6709\u5b8c\u5168\u81ea\u9002\u5e94\u7075\u6d3b\u6027\u7684\u6bd4\u7279\u622a\u65ad\u5b58\u50a8\u5668\uff0c\u53ef\u5728\u8fd0\u884c\u65f6\u622a\u65ad\u4efb\u610f\u6570\u91cf\u7684\u6570\u636e\u4f4d\uff0c\u4ee5\u6ee1\u8db3\u4e0d\u540c\u8fd1\u4f3c\u5e94\u7528\u7684\u8d28\u91cf\u4e0e\u529f\u8017\u6743\u8861\u9700\u6c42\uff0c\u5e94\u7528\u4e8e\u89c6\u9891\u5904\u7406\u548c\u6df1\u5ea6\u5b66\u4e60\uff0c\u5b9e\u73b0\u663e\u8457\u7684\u529f\u8017\u8282\u7701\u3002", "motivation": "\u73b0\u6709\u6bd4\u7279\u622a\u65ad\u5b58\u50a8\u5668\u9700\u8981\u4e3a\u7279\u5b9a\u5e94\u7528\u5b9a\u5236\u8bbe\u8ba1\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u591a\u79cd\u8fd1\u4f3c\u5e94\u7528\u3001\u5728\u8fd0\u884c\u65f6\u7075\u6d3b\u8c03\u6574\u6bd4\u7279\u622a\u65ad\u6570\u91cf\u7684\u5b58\u50a8\u5668\uff0c\u4ee5\u4f18\u5316\u8fb9\u7f18\u73af\u5883\u4e2d\u7684\u529f\u8017/\u80fd\u6548\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u578b\u6bd4\u7279\u622a\u65ad\u5b58\u50a8\u5668\uff0c\u5177\u6709\u5b8c\u5168\u81ea\u9002\u5e94\u7075\u6d3b\u6027\uff0c\u80fd\u591f\u5728\u8fd0\u884c\u65f6\u622a\u65ad\u4efb\u610f\u6570\u91cf\u7684\u6570\u636e\u4f4d\u3002\u8be5\u65b9\u6cd5\u652f\u6301\u4e0d\u540c\u8d28\u91cf\u4e0e\u529f\u8017\u6743\u8861\u9700\u6c42\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u8fd1\u4f3c\u5e94\u7528\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1\uff09\u652f\u6301\u4e09\u79cd\u89c6\u9891\u5e94\u7528\uff08\u4eae\u5ea6\u611f\u77e5\u3001\u5185\u5bb9\u611f\u77e5\u548c\u611f\u5174\u8da3\u533a\u57df\u611f\u77e5\uff09\uff0c\u529f\u8017\u6548\u7387\u63d0\u5347\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u6280\u672f\u8282\u7701\u9ad8\u8fbe47.02%\u529f\u8017\uff1b2\uff09\u5728\u57fa\u51c6\u548c\u526a\u679d\u8f7b\u91cf\u7ea7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\u5206\u522b\u5b9e\u73b0\u9ad8\u8fbe51.69%\u7684\u529f\u8017\u8282\u7701\uff1b3\uff09\u5b9e\u73b0\u6210\u672c\u4f4e\uff0c\u4ec5\u589e\u52a02.89%\u7684\u7845\u9762\u79ef\u5f00\u9500\u3002", "conclusion": "\u63d0\u51fa\u7684\u6bd4\u7279\u622a\u65ad\u5b58\u50a8\u5668\u5177\u6709\u5b8c\u5168\u81ea\u9002\u5e94\u7075\u6d3b\u6027\uff0c\u80fd\u591f\u6709\u6548\u652f\u6301\u591a\u79cd\u8fd1\u4f3c\u5e94\u7528\uff0c\u5728\u89c6\u9891\u5904\u7406\u548c\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u4e2d\u5b9e\u73b0\u663e\u8457\u7684\u529f\u8017\u8282\u7701\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u4f4e\u7684\u5b9e\u73b0\u6210\u672c\uff0c\u4e3a\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u80fd\u6548\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.19902", "categories": ["cs.AR", "cs.OS"], "pdf": "https://arxiv.org/pdf/2601.19902", "abs": "https://arxiv.org/abs/2601.19902", "authors": ["Elizabeth Shen", "Huiyang Zhou"], "title": "A Flower-Inspired Solution for Computer Memory Wear-Leveling", "comment": "6 pages, 6 figures, and 2 tables", "summary": "Lengthening a computer memory's lifespan is important for e-waste and sustainability. Uneven wear of memory is a major barrier. The problem is becoming even more urgent as emerging memory such as phase-change memory is subject to even shorter lifespan. Various solutions have been proposed, but they either require complicated hardware extensions or apply only to certain program constructs such as loops. This research proposes a new method, dual-ring wear leveling. It takes inspiration from the natural law known as the ``golden ratio\" and how it helps flower petals evenly receive sun lights. By modeling memory as two rings and combines the idea with existing memory management, garbage collection, the new solution offers an effective way to reduce memory wear and hence lengthen memory lifespan. It is deterministic, able to automatically adapt to memory size, requiring no hardware changes, and adding no slowdown to program executions.", "AI": {"tldr": "\u63d0\u51fa\u53cc\u73af\u78e8\u635f\u5747\u8861\u65b9\u6cd5\uff0c\u5229\u7528\u9ec4\u91d1\u6bd4\u4f8b\u539f\u7406\u4f18\u5316\u5185\u5b58\u78e8\u635f\u5206\u5e03\uff0c\u5ef6\u957f\u5185\u5b58\u5bff\u547d", "motivation": "\u5ef6\u957f\u8ba1\u7b97\u673a\u5185\u5b58\u5bff\u547d\u5bf9\u51cf\u5c11\u7535\u5b50\u5783\u573e\u548c\u53ef\u6301\u7eed\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002\u5185\u5b58\u78e8\u635f\u4e0d\u5747\u662f\u4e00\u4e2a\u4e3b\u8981\u969c\u788d\uff0c\u800c\u65b0\u5174\u5b58\u50a8\u5668\u5982\u76f8\u53d8\u5b58\u50a8\u5668\u7684\u5bff\u547d\u66f4\u77ed\uff0c\u95ee\u9898\u66f4\u52a0\u7d27\u8feb\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8981\u4e48\u9700\u8981\u590d\u6742\u7684\u786c\u4ef6\u6269\u5c55\uff0c\u8981\u4e48\u53ea\u9002\u7528\u4e8e\u7279\u5b9a\u7a0b\u5e8f\u7ed3\u6784\u5982\u5faa\u73af\u3002", "method": "\u63d0\u51fa\u53cc\u73af\u78e8\u635f\u5747\u8861\u65b9\u6cd5\uff0c\u7075\u611f\u6765\u6e90\u4e8e\u9ec4\u91d1\u6bd4\u4f8b\u7684\u81ea\u7136\u6cd5\u5219\u53ca\u5176\u5e2e\u52a9\u82b1\u74e3\u5747\u5300\u63a5\u6536\u9633\u5149\u7684\u539f\u7406\u3002\u5c06\u5185\u5b58\u5efa\u6a21\u4e3a\u4e24\u4e2a\u73af\uff0c\u5e76\u7ed3\u5408\u73b0\u6709\u7684\u5185\u5b58\u7ba1\u7406\u548c\u5783\u573e\u56de\u6536\u673a\u5236\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u51cf\u5c11\u5185\u5b58\u78e8\u635f\u7684\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u5177\u6709\u786e\u5b9a\u6027\uff0c\u80fd\u591f\u81ea\u52a8\u9002\u5e94\u5185\u5b58\u5927\u5c0f\uff0c\u65e0\u9700\u786c\u4ef6\u66f4\u6539\uff0c\u4e14\u4e0d\u4f1a\u589e\u52a0\u7a0b\u5e8f\u6267\u884c\u7684\u5f00\u9500\u3002", "conclusion": "\u53cc\u73af\u78e8\u635f\u5747\u8861\u65b9\u6cd5\u4e3a\u89e3\u51b3\u5185\u5b58\u78e8\u635f\u4e0d\u5747\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u3001\u5b9e\u7528\u4e14\u65e0\u9700\u786c\u4ef6\u4fee\u6539\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u5ef6\u957f\u5185\u5b58\u5bff\u547d\u3002"}}
{"id": "2601.19903", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19903", "abs": "https://arxiv.org/abs/2601.19903", "authors": ["Saeid Rajabi", "Chengmo Yang", "Satwik Patnaik"], "title": "STELLAR: Structure-guided LLM Assertion Retrieval and Generation for Formal Verification", "comment": "7 pages, 6 figures", "summary": "Formal Verification (FV) relies on high-quality SystemVerilog Assertions (SVAs), but the manual writing process is slow and error-prone. Existing LLM-based approaches either generate assertions from scratch or ignore structural patterns in hardware designs and expert-crafted assertions. This paper presents STELLAR, the first framework that guides LLM-based SVA generation with structural similarity. STELLAR represents RTL blocks as AST structural fingerprints, retrieves structurally relevant (RTL, SVA) pairs from a knowledge base, and integrates them into structure-guided prompts. Experiments show that STELLAR achieves superior syntax correctness, stylistic alignment, and functional correctness, highlighting structure-aware retrieval as a promising direction for industrial FV.", "AI": {"tldr": "STELLAR\u662f\u4e00\u4e2a\u57fa\u4e8e\u7ed3\u6784\u76f8\u4f3c\u6027\u6307\u5bfcLLM\u751f\u6210SystemVerilog\u65ad\u8a00\u7684\u6846\u67b6\uff0c\u901a\u8fc7AST\u7ed3\u6784\u6307\u7eb9\u68c0\u7d22\u76f8\u5173\u77e5\u8bc6\u5e93\u4e2d\u7684(RTL, SVA)\u5bf9\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u65ad\u8a00\u751f\u6210\u7684\u8bed\u6cd5\u6b63\u786e\u6027\u3001\u98ce\u683c\u4e00\u81f4\u6027\u548c\u529f\u80fd\u6b63\u786e\u6027\u3002", "motivation": "\u624b\u52a8\u7f16\u5199SystemVerilog\u65ad\u8a00(SVAs)\u8fc7\u7a0b\u7f13\u6162\u4e14\u5bb9\u6613\u51fa\u9519\uff0c\u800c\u73b0\u6709\u7684LLM\u65b9\u6cd5\u8981\u4e48\u4ece\u5934\u751f\u6210\u65ad\u8a00\uff0c\u8981\u4e48\u5ffd\u7565\u4e86\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u7ed3\u6784\u6a21\u5f0f\u548c\u4e13\u5bb6\u7f16\u5199\u7684\u65ad\u8a00\u6a21\u5f0f\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u65ad\u8a00\u3002", "method": "STELLAR\u6846\u67b6\u5c06RTL\u5757\u8868\u793a\u4e3aAST\u7ed3\u6784\u6307\u7eb9\uff0c\u4ece\u77e5\u8bc6\u5e93\u4e2d\u68c0\u7d22\u7ed3\u6784\u76f8\u5173\u7684(RTL, SVA)\u5bf9\uff0c\u5e76\u5c06\u5b83\u4eec\u96c6\u6210\u5230\u7ed3\u6784\u5f15\u5bfc\u7684\u63d0\u793a\u4e2d\uff0c\u6307\u5bfcLLM\u751f\u6210\u65ad\u8a00\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSTELLAR\u5728\u8bed\u6cd5\u6b63\u786e\u6027\u3001\u98ce\u683c\u5bf9\u9f50\u548c\u529f\u80fd\u6b63\u786e\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u8bc1\u660e\u4e86\u7ed3\u6784\u611f\u77e5\u68c0\u7d22\u662f\u5de5\u4e1a\u5f62\u5f0f\u9a8c\u8bc1\u7684\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\u3002", "conclusion": "STELLAR\u901a\u8fc7\u7ed3\u6784\u76f8\u4f3c\u6027\u6307\u5bfcLLM\u751f\u6210SystemVerilog\u65ad\u8a00\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u65ad\u8a00\u8d28\u91cf\uff0c\u4e3a\u5de5\u4e1a\u5f62\u5f0f\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.19904", "categories": ["cs.AR", "cs.AI", "cs.CL", "cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.19904", "abs": "https://arxiv.org/abs/2601.19904", "authors": ["Ziyu Hu", "Zhiqing Zhong", "Weijian Zheng", "Zhijing Ye", "Xuwei Tan", "Xueru Zhang", "Zheng Xie", "Rajkumar Kettimuthu", "Xiaodong Yu"], "title": "DABench-LLM: Standardized and In-Depth Benchmarking of Post-Moore Dataflow AI Accelerators for LLMs", "comment": null, "summary": "The exponential growth of large language models has outpaced the capabilities of traditional CPU and GPU architectures due to the slowdown of Moore's Law. Dataflow AI accelerators present a promising alternative; however, there remains a lack of in-depth performance analysis and standardized benchmarking methodologies for LLM training. We introduce DABench-LLM, the first benchmarking framework designed for evaluating LLM workloads on dataflow-based accelerators. By combining intra-chip performance profiling and inter-chip scalability analysis, DABench-LLM enables comprehensive evaluation across key metrics such as resource allocation, load balance, and resource efficiency. The framework helps researchers rapidly gain insights into underlying hardware and system behaviors, and provides guidance for performance optimizations. We validate DABench-LLM on three commodity dataflow accelerators, Cerebras WSE-2, SambaNova RDU, and Graphcore IPU. Our framework reveals performance bottlenecks and provides specific optimization strategies, demonstrating its generality and effectiveness across a diverse range of dataflow-based AI hardware platforms.", "AI": {"tldr": "DABench-LLM\u662f\u9996\u4e2a\u9488\u5bf9\u6570\u636e\u6d41AI\u52a0\u901f\u5668\u7684LLM\u8bad\u7ec3\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u82af\u7247\u5185\u6027\u80fd\u5206\u6790\u548c\u82af\u7247\u95f4\u53ef\u6269\u5c55\u6027\u5206\u6790\uff0c\u5168\u9762\u8bc4\u4f30\u8d44\u6e90\u5206\u914d\u3001\u8d1f\u8f7d\u5e73\u8861\u548c\u8d44\u6e90\u6548\u7387\u7b49\u5173\u952e\u6307\u6807\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6307\u6570\u7ea7\u589e\u957f\uff0c\u4f20\u7edfCPU/GPU\u67b6\u6784\u53d7\u6469\u5c14\u5b9a\u5f8b\u653e\u7f13\u9650\u5236\uff0c\u6570\u636e\u6d41AI\u52a0\u901f\u5668\u6210\u4e3a\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u7f3a\u4e4f\u6df1\u5165\u7684\u6027\u80fd\u5206\u6790\u548c\u6807\u51c6\u5316\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1DABench-LLM\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u7ed3\u5408\u82af\u7247\u5185\u6027\u80fd\u5206\u6790\u548c\u82af\u7247\u95f4\u53ef\u6269\u5c55\u6027\u5206\u6790\uff0c\u5728Cerebras WSE-2\u3001SambaNova RDU\u548cGraphcore IPU\u4e09\u79cd\u5546\u7528\u6570\u636e\u6d41\u52a0\u901f\u5668\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u6846\u67b6\u63ed\u793a\u4e86\u6027\u80fd\u74f6\u9888\u5e76\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u4f18\u5316\u7b56\u7565\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u591a\u6837\u5316\u6570\u636e\u6d41AI\u786c\u4ef6\u5e73\u53f0\u4e0a\u7684\u901a\u7528\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "DABench-LLM\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u6df1\u5165\u4e86\u89e3\u5e95\u5c42\u786c\u4ef6\u548c\u7cfb\u7edf\u884c\u4e3a\u7684\u5de5\u5177\uff0c\u5e76\u4e3a\u6027\u80fd\u4f18\u5316\u63d0\u4f9b\u6307\u5bfc\uff0c\u586b\u8865\u4e86\u6570\u636e\u6d41\u52a0\u901f\u5668LLM\u8bad\u7ec3\u57fa\u51c6\u6d4b\u8bd5\u7684\u7a7a\u767d\u3002"}}
{"id": "2601.19955", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.19955", "abs": "https://arxiv.org/abs/2601.19955", "authors": ["Jean-Marc Fellous", "Gert Cauwenberghs", "Cornelia Ferm\u00fcller", "Yulia Sandamisrkaya", "Terrence Sejnowski"], "title": "NeuroAI and Beyond", "comment": "53 pages, 5 figures, extended appendix", "summary": "Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possible promising new future avenues. Overall, we advocate for the development of NeuroAI, a type of Neuroscience-informed Artificial Intelligence that, we argue, has the potential for significantly improving the scope and efficiency of AI algorithms while simultaneously changing the way we understand biological neural computations. We include personal statements from several leading researchers on their diverse views of NeuroAI. Two Strength-Weakness-Opportunities-Threat (SWOT) analyses by researchers and trainees are appended that describe the benefits and risks offered by NeuroAI.", "AI": {"tldr": "\u8be5\u8bba\u6587\u57fa\u4e8e2025\u5e748\u6708\u7814\u8ba8\u4f1a\uff0c\u63a2\u8ba8\u795e\u7ecf\u79d1\u5b66\u4e0e\u4eba\u5de5\u667a\u80fd\u7684\u4ea4\u53c9\u9886\u57df\uff0c\u63d0\u51faNeuroAI\u6982\u5ff5\uff0c\u65e8\u5728\u901a\u8fc7\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\u6539\u8fdbAI\u7b97\u6cd5\uff0c\u540c\u65f6\u6df1\u5316\u5bf9\u751f\u7269\u795e\u7ecf\u8ba1\u7b97\u7684\u7406\u89e3\u3002", "motivation": "\u795e\u7ecf\u79d1\u5b66\u4e0e\u4eba\u5de5\u667a\u80fd\u5728\u8fc7\u53bb\u51e0\u5e74\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u4e24\u8005\u4e4b\u95f4\u7684\u8fde\u63a5\u4ecd\u7136\u677e\u6563\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u6574\u5408\u8fd9\u4e24\u4e2a\u9886\u57df\uff0c\u521b\u5efa\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\u7684\u4eba\u5de5\u667a\u80fd\uff08NeuroAI\uff09\uff0c\u4ee5\u63d0\u5347AI\u7b97\u6cd5\u7684\u8303\u56f4\u548c\u6548\u7387\uff0c\u540c\u65f6\u6539\u53d8\u5bf9\u751f\u7269\u795e\u7ecf\u8ba1\u7b97\u7684\u7406\u89e3\u65b9\u5f0f\u3002", "method": "\u57fa\u4e8e2025\u5e748\u6708\u4e3e\u529e\u7684\u7814\u8ba8\u4f1a\uff0c\u805a\u7126\u4e8e\u5177\u8eab\u6027\u3001\u8bed\u8a00\u4e0e\u901a\u4fe1\u3001\u673a\u5668\u4eba\u5b66\u3001\u4eba\u7c7b\u4e0e\u673a\u5668\u5b66\u4e60\u4ee5\u53ca\u795e\u7ecf\u5f62\u6001\u5de5\u7a0b\u7b49\u5b50\u9886\u57df\u3002\u6536\u96c6\u4e86\u591a\u4f4d\u9886\u5148\u7814\u7a76\u4eba\u5458\u7684\u4e2a\u4eba\u89c2\u70b9\uff0c\u5e76\u9644\u6709\u7814\u7a76\u4eba\u5458\u548c\u5b66\u5458\u8fdb\u884c\u7684SWOT\u5206\u6790\u3002", "result": "\u8bc6\u522b\u4e86\u795e\u7ecf\u79d1\u5b66\u4e0eAI\u4e4b\u95f4\u5f53\u524d\u548c\u672a\u6765\u7684\u534f\u540c\u9886\u57df\uff0c\u63d0\u51fa\u4e86NeuroAI\u7684\u53d1\u5c55\u6846\u67b6\u3002\u901a\u8fc7SWOT\u5206\u6790\u63cf\u8ff0\u4e86NeuroAI\u7684\u76ca\u5904\u548c\u98ce\u9669\uff0c\u4e3a\u8fd9\u4e00\u4ea4\u53c9\u5b66\u79d1\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u591a\u89d2\u5ea6\u7684\u8bc4\u4f30\u3002", "conclusion": "\u5021\u5bfc\u53d1\u5c55NeuroAI\uff0c\u8ba4\u4e3a\u8fd9\u79cd\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\u7684\u4eba\u5de5\u667a\u80fd\u6709\u6f5c\u529b\u663e\u8457\u63d0\u9ad8AI\u7b97\u6cd5\u7684\u8303\u56f4\u548c\u6548\u7387\uff0c\u540c\u65f6\u6539\u53d8\u6211\u4eec\u5bf9\u751f\u7269\u795e\u7ecf\u8ba1\u7b97\u7684\u7406\u89e3\u65b9\u5f0f\u3002\u901a\u8fc7\u6574\u5408\u4e24\u4e2a\u9886\u57df\u7684\u4f18\u52bf\uff0c\u53ef\u4ee5\u5f00\u8f9f\u65b0\u7684\u7814\u7a76\u9014\u5f84\u3002"}}
{"id": "2601.20113", "categories": ["cs.DC", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.20113", "abs": "https://arxiv.org/abs/2601.20113", "authors": ["Arshan Khan", "Rohit Deshmukh", "Ben O'Neill"], "title": "A Data-Informed Local Subspaces Method for Error-Bounded Lossy Compression of Large-Scale Scientific Datasets", "comment": "To be submitted to the IEEE Transactions on Parallel and Distributed Systems", "summary": "The growing volume of scientific simulation data presents a significant challenge for storage and transfer. Error-bounded lossy compression has emerged as a critical solution for mitigating these challenges, providing a means to reduce data size while ensuring that reconstructed data remains valid for scientific analysis. In this paper, we present a data-driven scientific data compressor, called Discontinuous Data-informed Local Subspaces (Discontinuous DLS), to improve compression-to-error ratios over data-agnostic compressors. This error-bounded compressor leverages localized spatial and temporal subspaces, informed by the underlying data structure, to enhance compression efficiency and preserve key features. The presented technique is flexible and applicable to a wide range of scientific data, including fluid dynamics, environmental simulations, and other high-dimensional, time-dependent datasets. We describe the core principles of the method and demonstrate its ability to significantly reduce storage requirements without compromising critical data fidelity. The technique is implemented in a distributed computing environment using MPI, and its performance is evaluated against state-of-the-art error-bounded compression methods in terms of compression ratio and reconstruction accuracy. This study highlights discontinuous DLS as a promising approach for large-scale scientific data compression in high-performance computing environments, providing a robust solution for managing the growing data demands of modern scientific simulations.", "AI": {"tldr": "Discontinuous DLS\u662f\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u6709\u635f\u538b\u7f29\u65b9\u6cd5\uff0c\u5229\u7528\u6570\u636e\u7ed3\u6784\u7684\u5c40\u90e8\u65f6\u7a7a\u5b50\u7a7a\u95f4\u63d0\u9ad8\u538b\u7f29\u6548\u7387\uff0c\u5728\u4fdd\u6301\u5173\u952e\u7279\u5f81\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u79d1\u5b66\u6a21\u62df\u6570\u636e\u7684\u5b58\u50a8\u9700\u6c42\u3002", "motivation": "\u79d1\u5b66\u6a21\u62df\u6570\u636e\u91cf\u7684\u5feb\u901f\u589e\u957f\u7ed9\u5b58\u50a8\u548c\u4f20\u8f93\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u6709\u6548\u7684\u538b\u7f29\u89e3\u51b3\u65b9\u6848\u3002\u867d\u7136\u6709\u635f\u538b\u7f29\u53ef\u4ee5\u51cf\u5c0f\u6570\u636e\u5927\u5c0f\uff0c\u4f46\u9700\u8981\u786e\u4fdd\u91cd\u5efa\u6570\u636e\u5bf9\u79d1\u5b66\u5206\u6790\u4ecd\u7136\u6709\u6548\u3002", "method": "Discontinuous DLS\u662f\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u6709\u635f\u538b\u7f29\u5668\uff0c\u5229\u7528\u57fa\u4e8e\u5e95\u5c42\u6570\u636e\u7ed3\u6784\u4fe1\u606f\u7684\u5c40\u90e8\u65f6\u7a7a\u5b50\u7a7a\u95f4\u6765\u63d0\u9ad8\u538b\u7f29\u6548\u7387\u3002\u8be5\u65b9\u6cd5\u7075\u6d3b\u9002\u7528\u4e8e\u5404\u79cd\u79d1\u5b66\u6570\u636e\uff0c\u5305\u62ec\u6d41\u4f53\u52a8\u529b\u5b66\u3001\u73af\u5883\u6a21\u62df\u7b49\u3002\u5728\u5206\u5e03\u5f0f\u8ba1\u7b97\u73af\u5883\u4e2d\u4f7f\u7528MPI\u5b9e\u73b0\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u51cf\u5c11\u5b58\u50a8\u9700\u6c42\u800c\u4e0d\u635f\u5bb3\u5173\u952e\u6570\u636e\u4fdd\u771f\u5ea6\u3002\u4e0e\u6700\u5148\u8fdb\u7684\u8bef\u5dee\u6709\u754c\u538b\u7f29\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u538b\u7f29\u6bd4\u548c\u91cd\u5efa\u7cbe\u5ea6\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "Discontinuous DLS\u662f\u5927\u89c4\u6a21\u79d1\u5b66\u6570\u636e\u538b\u7f29\u7684\u6709\u524d\u666f\u65b9\u6cd5\uff0c\u4e3a\u7ba1\u7406\u73b0\u4ee3\u79d1\u5b66\u6a21\u62df\u65e5\u76ca\u589e\u957f\u7684\u6570\u636e\u9700\u6c42\u63d0\u4f9b\u4e86\u7a33\u5065\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.20014", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20014", "abs": "https://arxiv.org/abs/2601.20014", "authors": ["Shuhui Qu"], "title": "Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning", "comment": null, "summary": "Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \\textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\\texttt{Sat}/\\texttt{Viol}/\\texttt{Unk}) and resolves unknowns via (i) targeted self-queries to an oracle/user or (ii) \\emph{bridging} hypotheses that establish the missing condition through an additional action. SQ-BCP performs bidirectional search and invokes a pullback-based verifier as a categorical certificate of goal compatibility, while using distance-based scores only for ranking and pruning. We prove that when the verifier succeeds and hard constraints pass deterministic checks, accepted plans are compatible with goal requirements; under bounded branching and finite resolution depth, SQ-BCP finds an accepting plan when one exists. Across WikiHow and RecipeNLG tasks with withheld preconditions, SQ-BCP reduces resource-violation rates to \\textbf{14.9\\%} and \\textbf{5.8\\%} (vs.\\ \\textbf{26.0\\%} and \\textbf{15.7\\%} for the best baseline), while maintaining competitive reference quality.", "AI": {"tldr": "SQ-BCP\u662f\u4e00\u79cd\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u8fdb\u884c\u63a8\u7406\u65f6\u89c4\u5212\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u8868\u793a\u524d\u63d0\u6761\u4ef6\u72b6\u6001\u3001\u81ea\u6211\u67e5\u8be2\u548c\u6865\u63a5\u5047\u8bbe\u6765\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7f3a\u5931\u5173\u952e\u524d\u63d0\u65f6\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u8fdb\u884c\u63a8\u7406\u65f6\u89c4\u5212\u65f6\u7ecf\u5e38\u5931\u8d25\uff1a\u5f53\u4efb\u52a1\u5173\u952e\u524d\u63d0\u6761\u4ef6\u5728\u67e5\u8be2\u65f6\u672a\u6307\u5b9a\u65f6\uff0c\u6a21\u578b\u503e\u5411\u4e8e\u4ea7\u751f\u5e7b\u89c9\u6216\u751f\u6210\u8fdd\u53cd\u786c\u7ea6\u675f\u7684\u8ba1\u5212\u3002", "method": "\u63d0\u51fa\u81ea\u6211\u67e5\u8be2\u53cc\u5411\u5206\u7c7b\u89c4\u5212(SQ-BCP)\uff0c\u663e\u5f0f\u8868\u793a\u524d\u63d0\u6761\u4ef6\u72b6\u6001(Sat/Viol/Unk)\uff0c\u901a\u8fc7(i)\u9488\u5bf9\u6027\u7684\u81ea\u6211\u67e5\u8be2\u548c(ii)\u6865\u63a5\u5047\u8bbe\u6765\u89e3\u6790\u672a\u77e5\u6761\u4ef6\uff0c\u6267\u884c\u53cc\u5411\u641c\u7d22\u5e76\u4f7f\u7528\u57fa\u4e8e\u62c9\u56de\u7684\u9a8c\u8bc1\u5668\u4f5c\u4e3a\u76ee\u6807\u517c\u5bb9\u6027\u7684\u5206\u7c7b\u8bc1\u4e66\u3002", "result": "\u5728WikiHow\u548cRecipeNLG\u4efb\u52a1\u4e2d\uff0cSQ-BCP\u5c06\u8d44\u6e90\u8fdd\u89c4\u7387\u5206\u522b\u964d\u4f4e\u523014.9%\u548c5.8%\uff08\u76f8\u6bd4\u6700\u4f73\u57fa\u7ebf\u768426.0%\u548c15.7%\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u6709\u7ade\u4e89\u529b\u7684\u53c2\u8003\u8d28\u91cf\u3002", "conclusion": "SQ-BCP\u901a\u8fc7\u663e\u5f0f\u5904\u7406\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\uff0c\u5728\u7406\u8bba\u4e0a\u4fdd\u8bc1\u627e\u5230\u63a5\u53d7\u8ba1\u5212\uff08\u5f53\u5b58\u5728\u65f6\uff09\uff0c\u5e76\u5728\u5b9e\u8df5\u4e2d\u663e\u8457\u51cf\u5c11\u8fdd\u53cd\u7ea6\u675f\u7684\u8ba1\u5212\u751f\u6210\uff0c\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2601.19970", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19970", "abs": "https://arxiv.org/abs/2601.19970", "authors": ["Nourin Shahin", "Izzat Alsmadi"], "title": "Benchmarking LLAMA Model Security Against OWASP Top 10 For LLM Applications", "comment": null, "summary": "As large language models (LLMs) move from research prototypes to enterprise systems, their security vulnerabilities pose serious risks to data privacy and system integrity. This study benchmarks various Llama model variants against the OWASP Top 10 for LLM Applications framework, evaluating threat detection accuracy, response safety, and computational overhead. Using the FABRIC testbed with NVIDIA A30 GPUs, we tested five standard Llama models and five Llama Guard variants on 100 adversarial prompts covering ten vulnerability categories. Our results reveal significant differences in security performance: the compact Llama-Guard-3-1B model achieved the highest detection rate of 76% with minimal latency (0.165s per test), whereas base models such as Llama-3.1-8B failed to detect threats (0% accuracy) despite longer inference times (0.754s). We observe an inverse relationship between model size and security effectiveness, suggesting that smaller, specialized models often outperform larger general-purpose ones in security tasks. Additionally, we provide an open-source benchmark dataset including adversarial prompts, threat labels, and attack metadata to support reproducible research in AI security, [1].", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86Llama\u6a21\u578b\u53d8\u4f53\u5728OWASP LLM\u5e94\u7528\u5341\u5927\u5b89\u5168\u5a01\u80c1\u6846\u67b6\u4e0b\u7684\u5b89\u5168\u6027\u80fd\uff0c\u53d1\u73b0\u5c0f\u578b\u4e13\u7528\u5b89\u5168\u6a21\u578b\uff08Llama-Guard-3-1B\uff09\u5728\u5a01\u80c1\u68c0\u6d4b\u51c6\u786e\u7387\uff0876%\uff09\u548c\u5ef6\u8fdf\uff080.165\u79d2\uff09\u65b9\u9762\u4f18\u4e8e\u5927\u578b\u901a\u7528\u6a21\u578b\uff08Llama-3.1-8B\u68c0\u6d4b\u7387\u4e3a0%\uff0c\u5ef6\u8fdf0.754\u79d2\uff09\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u7814\u7a76\u539f\u578b\u8f6c\u5411\u4f01\u4e1a\u7cfb\u7edf\uff0c\u5176\u5b89\u5168\u6f0f\u6d1e\u5bf9\u6570\u636e\u9690\u79c1\u548c\u7cfb\u7edf\u5b8c\u6574\u6027\u6784\u6210\u4e25\u91cd\u98ce\u9669\u3002\u9700\u8981\u8bc4\u4f30\u4e0d\u540c\u6a21\u578b\u5728\u5b89\u5168\u5a01\u80c1\u68c0\u6d4b\u65b9\u9762\u7684\u6027\u80fd\u5dee\u5f02\u3002", "method": "\u4f7f\u7528FABRIC\u6d4b\u8bd5\u5e73\u53f0\u548cNVIDIA A30 GPU\uff0c\u6d4b\u8bd5\u4e865\u4e2a\u6807\u51c6Llama\u6a21\u578b\u548c5\u4e2aLlama Guard\u53d8\u4f53\u3002\u4f7f\u7528100\u4e2a\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u8986\u76d6OWASP LLM\u5e94\u7528\u5341\u5927\u5b89\u5168\u5a01\u80c1\u7c7b\u522b\uff0c\u8bc4\u4f30\u5a01\u80c1\u68c0\u6d4b\u51c6\u786e\u7387\u3001\u54cd\u5e94\u5b89\u5168\u6027\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u7d27\u51d1\u578bLlama-Guard-3-1B\u6a21\u578b\u8fbe\u5230\u6700\u9ad8\u68c0\u6d4b\u738776%\uff0c\u5ef6\u8fdf\u6700\u4f4e\uff080.165\u79d2/\u6d4b\u8bd5\uff09\u3002\u800c\u57fa\u7840\u6a21\u578b\u5982Llama-3.1-8B\u68c0\u6d4b\u7387\u4e3a0%\uff0c\u5ef6\u8fdf\u66f4\u9ad8\uff080.754\u79d2\uff09\u3002\u53d1\u73b0\u6a21\u578b\u5927\u5c0f\u4e0e\u5b89\u5168\u6709\u6548\u6027\u5448\u53cd\u6bd4\u5173\u7cfb\uff0c\u5c0f\u578b\u4e13\u7528\u6a21\u578b\u5728\u5b89\u5168\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5927\u578b\u901a\u7528\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u6a21\u578b\u5927\u5c0f\u4e0e\u5b89\u5168\u6027\u80fd\u4e4b\u95f4\u7684\u53cd\u6bd4\u5173\u7cfb\uff0c\u8868\u660e\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u5e94\u4f18\u5148\u8003\u8651\u4e13\u7528\u5b89\u5168\u6a21\u578b\u800c\u975e\u901a\u7528\u5927\u6a21\u578b\u3002\u63d0\u4f9b\u4e86\u5f00\u6e90\u57fa\u51c6\u6570\u636e\u96c6\u652f\u6301\u53ef\u91cd\u590d\u7684AI\u5b89\u5168\u7814\u7a76\u3002"}}
{"id": "2601.19906", "categories": ["cs.AR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19906", "abs": "https://arxiv.org/abs/2601.19906", "authors": ["Jingxin Wang", "Shitong Guo", "Ruicheng Dai", "Wenhui Liang", "Ruogu Ding", "Xin Ning", "Weikang Qian"], "title": "GTAC: A Generative Transformer for Approximate Circuits", "comment": null, "summary": "Targeting error-tolerant applications, approximate circuits introduce controlled errors to significantly improve performance, power, and area (PPA) of circuits. In this work, we introduce GTAC, a novel generative Transformer-based model for producing approximate circuits. By leveraging principles of approximate computing and AI-driven EDA, our model innovatively integrates error thresholds into the design process. Experimental results show that compared with a state-of-the-art method, GTAC further reduces 6.4% area under the error rate constraint, while being 4.3x faster.", "AI": {"tldr": "GTAC\u662f\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u5f0fTransformer\u7684\u8fd1\u4f3c\u7535\u8def\u8bbe\u8ba1\u6a21\u578b\uff0c\u901a\u8fc7\u96c6\u6210\u8bef\u5dee\u9608\u503c\u5230\u8bbe\u8ba1\u6d41\u7a0b\u4e2d\uff0c\u5728\u6ee1\u8db3\u8bef\u5dee\u7ea6\u675f\u6761\u4ef6\u4e0b\u8fdb\u4e00\u6b65\u51cf\u5c116.4%\u7684\u9762\u79ef\uff0c\u540c\u65f6\u901f\u5ea6\u63d0\u53474.3\u500d\u3002", "motivation": "\u9488\u5bf9\u5bb9\u9519\u5e94\u7528\uff0c\u8fd1\u4f3c\u7535\u8def\u901a\u8fc7\u5f15\u5165\u53ef\u63a7\u8bef\u5dee\u6765\u663e\u8457\u6539\u5584\u7535\u8def\u7684\u6027\u80fd\u3001\u529f\u8017\u548c\u9762\u79ef\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5e73\u8861\u8bef\u5dee\u7ea6\u675f\u548cPPA\u4f18\u5316\u65b9\u9762\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u8bbe\u8ba1\u65b9\u6cd5\u3002", "method": "\u63d0\u51faGTAC\uff0c\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u5f0fTransformer\u7684\u6a21\u578b\uff0c\u5229\u7528\u8fd1\u4f3c\u8ba1\u7b97\u548cAI\u9a71\u52a8\u7684EDA\u539f\u7406\uff0c\u521b\u65b0\u6027\u5730\u5c06\u8bef\u5dee\u9608\u503c\u96c6\u6210\u5230\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u8fd1\u4f3c\u7535\u8def\u751f\u6210\u3002", "result": "\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\uff0cGTAC\u5728\u6ee1\u8db3\u8bef\u5dee\u7387\u7ea6\u675f\u6761\u4ef6\u4e0b\u8fdb\u4e00\u6b65\u51cf\u5c11\u4e866.4%\u7684\u9762\u79ef\uff0c\u540c\u65f6\u8bbe\u8ba1\u901f\u5ea6\u63d0\u5347\u4e864.3\u500d\u3002", "conclusion": "GTAC\u5c55\u793a\u4e86\u751f\u6210\u5f0fTransformer\u5728\u8fd1\u4f3c\u7535\u8def\u8bbe\u8ba1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3aAI\u9a71\u52a8\u7684EDA\u5de5\u5177\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\uff0c\u80fd\u591f\u5728\u4fdd\u8bc1\u8bef\u5dee\u7ea6\u675f\u7684\u540c\u65f6\u663e\u8457\u4f18\u5316\u7535\u8defPPA\u6307\u6807\u3002"}}
{"id": "2601.20021", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20021", "abs": "https://arxiv.org/abs/2601.20021", "authors": ["Shuhui Qu"], "title": "Fuzzy Categorical Planning: Autonomous Goal Satisfaction with Graded Semantic Constraints", "comment": null, "summary": "Natural-language planning often involves vague predicates (e.g., suitable substitute, stable enough) whose satisfaction is inherently graded. Existing category-theoretic planners provide compositional structure and pullback-based hard-constraint verification, but treat applicability as crisp, forcing thresholding that collapses meaningful distinctions and cannot track quality degradation across multi-step plans. We propose Fuzzy Category-theoretic Planning (FCP), which annotates each action (morphism) with a degree in [0,1], composes plan quality via a t-norm Lukasiewicz, and retains crisp executability checks via pullback verification. FCP grounds graded applicability from language using an LLM with k-sample median aggregation and supports meeting-in-the-middle search using residuum-based backward requirements. We evaluate on (i) public PDDL3 preference/oversubscription benchmarks and (ii) RecipeNLG-Subs, a missing-substitute recipe-planning benchmark built from RecipeNLG with substitution candidates from Recipe1MSubs and FoodKG. FCP improves success and reduces hard-constraint violations on RecipeNLG-Subs compared to LLM-only and ReAct-style baselines, while remaining competitive with classical PDDL3 planners.", "AI": {"tldr": "\u63d0\u51fa\u6a21\u7cca\u8303\u7574\u8bba\u89c4\u5212(FCP)\uff0c\u5c06\u6a21\u7cca\u903b\u8f91\u878d\u5165\u8303\u7574\u8bba\u89c4\u5212\u6846\u67b6\uff0c\u5904\u7406\u81ea\u7136\u8bed\u8a00\u89c4\u5212\u4e2d\u7684\u6a21\u7cca\u8c13\u8bcd\uff0c\u901a\u8fc7t-\u8303\u6570\u7ec4\u5408\u8ba1\u5212\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u786c\u7ea6\u675f\u9a8c\u8bc1\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u8303\u7574\u8bba\u89c4\u5212\u5668\u5c06\u9002\u7528\u6027\u89c6\u4e3a\u4e8c\u5143\u5224\u65ad\uff0c\u65e0\u6cd5\u5904\u7406\u81ea\u7136\u8bed\u8a00\u89c4\u5212\u4e2d\u56fa\u6709\u7684\u6a21\u7cca\u8c13\u8bcd\uff08\u5982\"\u5408\u9002\u66ff\u4ee3\u54c1\"\u3001\"\u8db3\u591f\u7a33\u5b9a\"\uff09\uff0c\u5bfc\u81f4\u9608\u503c\u5316\u5904\u7406\u4f1a\u4e22\u5931\u6709\u610f\u4e49\u7684\u8d28\u91cf\u5dee\u5f02\uff0c\u4e14\u65e0\u6cd5\u8ddf\u8e2a\u591a\u6b65\u8ba1\u5212\u4e2d\u7684\u8d28\u91cf\u9000\u5316\u3002", "method": "FCP\u4e3a\u6bcf\u4e2a\u52a8\u4f5c\uff08\u6001\u5c04\uff09\u6807\u6ce8[0,1]\u533a\u95f4\u5185\u7684\u7a0b\u5ea6\u503c\uff0c\u901a\u8fc7Lukasiewicz t-\u8303\u6570\u7ec4\u5408\u8ba1\u5212\u8d28\u91cf\uff0c\u540c\u65f6\u901a\u8fc7\u62c9\u56de\u9a8c\u8bc1\u4fdd\u6301\u53ef\u6267\u884c\u6027\u68c0\u67e5\u7684\u7cbe\u786e\u6027\u3002\u4f7f\u7528LLM\u8fdb\u884ck\u6837\u672c\u4e2d\u4f4d\u6570\u805a\u5408\u4ece\u8bed\u8a00\u4e2d\u83b7\u53d6\u5206\u7ea7\u9002\u7528\u6027\uff0c\u5e76\u652f\u6301\u57fa\u4e8e\u5269\u4f59\u8fd0\u7b97\u7684\u4e2d\u95f4\u76f8\u9047\u641c\u7d22\u3002", "result": "\u5728PDDL3\u504f\u597d/\u8d85\u989d\u9884\u8ba2\u57fa\u51c6\u6d4b\u8bd5\u548cRecipeNLG-Subs\uff08\u57fa\u4e8eRecipeNLG\u6784\u5efa\u7684\u7f3a\u5931\u66ff\u4ee3\u54c1\u98df\u8c31\u89c4\u5212\u57fa\u51c6\uff09\u4e0a\u8bc4\u4f30\u3002FCP\u5728RecipeNLG-Subs\u4e0a\u76f8\u6bd4LLM-only\u548cReAct\u98ce\u683c\u57fa\u7ebf\u63d0\u9ad8\u4e86\u6210\u529f\u7387\uff0c\u51cf\u5c11\u4e86\u786c\u7ea6\u675f\u8fdd\u53cd\uff0c\u540c\u65f6\u4e0e\u7ecf\u5178PDDL3\u89c4\u5212\u5668\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "FCP\u6210\u529f\u5730\u5c06\u6a21\u7cca\u903b\u8f91\u96c6\u6210\u5230\u8303\u7574\u8bba\u89c4\u5212\u6846\u67b6\u4e2d\uff0c\u6709\u6548\u5904\u7406\u81ea\u7136\u8bed\u8a00\u89c4\u5212\u4e2d\u7684\u6a21\u7cca\u8c13\u8bcd\uff0c\u5728\u4fdd\u6301\u786c\u7ea6\u675f\u9a8c\u8bc1\u80fd\u529b\u7684\u540c\u65f6\uff0c\u80fd\u591f\u8ddf\u8e2a\u8ba1\u5212\u8d28\u91cf\u9000\u5316\u5e76\u505a\u51fa\u6709\u610f\u4e49\u7684\u533a\u5206\u3002"}}
{"id": "2601.20163", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.20163", "abs": "https://arxiv.org/abs/2601.20163", "authors": ["Mahsa Tahghigh", "Hassan Salmani"], "title": "Reference-Free Spectral Analysis of EM Side-Channels for Always-on Hardware Trojan Detection", "comment": "Accepted at GOMACTech 2026", "summary": "Always-on hardware Trojans (HTs) pose a critical risk to trusted microelectronics, yet most side-channel detection methods rely on unavailable golden references. We present a reference-free approach that combines time-frequency EM analysis with Gaussian Mixture Models (GMMs). By applying Short-Time Fourier Transform (STFT) at multiple window sizes, we show that HT-free circuits exhibit fluctuating statistical structure, while always-on HTs leave persistent footprints with fewer, more consistent mixture components. Results on AES-128 demonstrate feasibility without requiring reference models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u53c2\u8003\u6a21\u578b\u7684\u786c\u4ef6\u6728\u9a6c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408\u65f6\u9891\u7535\u78c1\u5206\u6790\u548c\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff0c\u901a\u8fc7\u591a\u7a97\u53e3\u77ed\u65f6\u5085\u91cc\u53f6\u53d8\u6362\u8bc6\u522b\u786c\u4ef6\u6728\u9a6c\u7684\u6301\u4e45\u7279\u5f81", "motivation": "\u4f20\u7edf\u4fa7\u4fe1\u9053\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u96be\u4ee5\u83b7\u5f97\u7684\u9ec4\u91d1\u53c2\u8003\u6a21\u578b\uff0c\u800c\u5e38\u5f00\u786c\u4ef6\u6728\u9a6c\u5bf9\u53ef\u4fe1\u5fae\u7535\u5b50\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u9700\u8981\u65e0\u53c2\u8003\u7684\u68c0\u6d4b\u65b9\u6848", "method": "\u7ed3\u5408\u65f6\u9891\u7535\u78c1\u5206\u6790\u548c\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff0c\u5e94\u7528\u591a\u7a97\u53e3\u5927\u5c0f\u7684\u77ed\u65f6\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u5206\u6790\u7535\u8def\u7535\u78c1\u4fe1\u53f7\u7684\u7edf\u8ba1\u7ed3\u6784\u7279\u5f81", "result": "\u5728AES-128\u4e0a\u9a8c\u8bc1\u4e86\u53ef\u884c\u6027\uff0c\u65e0\u786c\u4ef6\u6728\u9a6c\u7535\u8def\u663e\u793a\u6ce2\u52a8\u7684\u7edf\u8ba1\u7ed3\u6784\uff0c\u800c\u5e38\u5f00\u786c\u4ef6\u6728\u9a6c\u7559\u4e0b\u6301\u4e45\u7279\u5f81\uff0c\u5177\u6709\u66f4\u5c11\u3001\u66f4\u4e00\u81f4\u7684\u9ad8\u65af\u6df7\u5408\u5206\u91cf", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u53c2\u8003\u6a21\u578b\u5373\u53ef\u68c0\u6d4b\u5e38\u5f00\u786c\u4ef6\u6728\u9a6c\uff0c\u4e3a\u53ef\u4fe1\u5fae\u7535\u5b50\u5b89\u5168\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u65e0\u53c2\u8003\u68c0\u6d4b\u65b9\u6848"}}
{"id": "2601.19907", "categories": ["cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.19907", "abs": "https://arxiv.org/abs/2601.19907", "authors": ["Yanru Chen", "Zheyu Li", "Keming Fan", "Runyang Tian", "John Hsu", "Weihong Xu", "Minxuan Zhou", "Tajana Rosing"], "title": "RAPID-Graph: Recursive All-Pairs Shortest Paths Using Processing-in-Memory for Dynamic Programming on Graphs", "comment": null, "summary": "All-pairs shortest paths (APSP) remains a major bottleneck for large-scale graph analytics, as data movement with cubic complexity overwhelms the bandwidth of conventional memory hierarchies. In this work, we propose RAPID-Graph to address this challenge through a co-designed processing-in-memory (PIM) system that integrates algorithm, architecture, and device-level optimizations. At the algorithm level, we introduce a recursion-aware partitioner that enables an exact APSP computation by decomposing graphs into vertex tiles to reduce data dependency, such that both Floyd-Warshall and Min-Plus kernels execute fully in-place within digital PIM arrays. At the architecture and device levels, we design a 2.5D PIM stack integrating two phase-change memory compute dies, a logic die, and high-bandwidth scratchpad memory within a unified advanced package. An external non-volatile storage stack stores large APSP results persistently. The design achieves both tile-level and unit-level parallel processing to sustain high throughput. On the 2.45M-node OGBN-Products dataset, RAPID-Graph is 5.8x faster and 1,186x more energy efficient than state-of-the-art GPU clusters, while exceeding prior PIM accelerators by 8.3x in speed and 104x in efficiency. It further delivers up to 42.8x speedup and 392x energy savings over an NVIDIA H100 GPU.", "AI": {"tldr": "RAPID-Graph\u662f\u4e00\u4e2a\u901a\u8fc7\u5b58\u5185\u8ba1\u7b97(PIM)\u7cfb\u7edf\u89e3\u51b3\u5168\u5bf9\u6700\u77ed\u8def\u5f84(APSP)\u8ba1\u7b97\u74f6\u9888\u7684\u65b9\u6848\uff0c\u5728\u7b97\u6cd5\u3001\u67b6\u6784\u548c\u8bbe\u5907\u5c42\u9762\u8fdb\u884c\u534f\u540c\u8bbe\u8ba1\uff0c\u76f8\u6bd4GPU\u96c6\u7fa4\u548c\u73b0\u6709PIM\u52a0\u901f\u5668\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u901f\u5ea6\u548c\u80fd\u6548\u63d0\u5347\u3002", "motivation": "\u5168\u5bf9\u6700\u77ed\u8def\u5f84(APSP)\u8ba1\u7b97\u5728\u5927\u89c4\u6a21\u56fe\u5206\u6790\u4e2d\u9762\u4e34\u4e25\u91cd\u74f6\u9888\uff0c\u7acb\u65b9\u7ea7\u590d\u6742\u5ea6\u7684\u6570\u636e\u79fb\u52a8\u4f1a\u6df9\u6ca1\u4f20\u7edf\u5185\u5b58\u5c42\u6b21\u7ed3\u6784\u7684\u5e26\u5bbd\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u6765\u7a81\u7834\u8fd9\u4e00\u9650\u5236\u3002", "method": "1. \u7b97\u6cd5\u5c42\u9762\uff1a\u63d0\u51fa\u9012\u5f52\u611f\u77e5\u5206\u533a\u5668\uff0c\u5c06\u56fe\u5206\u89e3\u4e3a\u9876\u70b9\u74e6\u7247\u4ee5\u51cf\u5c11\u6570\u636e\u4f9d\u8d56\uff0c\u4f7fFloyd-Warshall\u548cMin-Plus\u5185\u6838\u5b8c\u5168\u5728\u6570\u5b57PIM\u9635\u5217\u4e2d\u539f\u5730\u6267\u884c\uff1b2. \u67b6\u6784\u5c42\u9762\uff1a\u8bbe\u8ba12.5D PIM\u5806\u6808\uff0c\u96c6\u6210\u4e24\u4e2a\u76f8\u53d8\u5185\u5b58\u8ba1\u7b97\u82af\u7247\u3001\u4e00\u4e2a\u903b\u8f91\u82af\u7247\u548c\u9ad8\u5e26\u5bbd\u6682\u5b58\u5185\u5b58\uff1b3. \u8bbe\u5907\u5c42\u9762\uff1a\u4f7f\u7528\u5916\u90e8\u975e\u6613\u5931\u6027\u5b58\u50a8\u5806\u6808\u6301\u4e45\u5b58\u50a8\u5927\u578bAPSP\u7ed3\u679c\uff0c\u652f\u6301\u74e6\u7247\u7ea7\u548c\u5355\u5143\u7ea7\u5e76\u884c\u5904\u7406\u3002", "result": "\u57282.45M\u8282\u70b9\u7684OGBN-Products\u6570\u636e\u96c6\u4e0a\uff0cRAPID-Graph\u76f8\u6bd4\u6700\u5148\u8fdb\u7684GPU\u96c6\u7fa4\u5feb5.8\u500d\u3001\u80fd\u6548\u9ad81186\u500d\uff0c\u76f8\u6bd4\u73b0\u6709PIM\u52a0\u901f\u5668\u5feb8.3\u500d\u3001\u80fd\u6548\u9ad8104\u500d\uff0c\u76f8\u6bd4NVIDIA H100 GPU\u6700\u9ad8\u5b9e\u73b042.8\u500d\u52a0\u901f\u548c392\u500d\u8282\u80fd\u3002", "conclusion": "RAPID-Graph\u901a\u8fc7\u7b97\u6cd5\u3001\u67b6\u6784\u548c\u8bbe\u5907\u5c42\u9762\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u56fe\u5206\u6790\u4e2dAPSP\u8ba1\u7b97\u7684\u6570\u636e\u79fb\u52a8\u74f6\u9888\uff0c\u5728\u901f\u5ea6\u548c\u80fd\u6548\u65b9\u9762\u5b9e\u73b0\u4e86\u663e\u8457\u7a81\u7834\uff0c\u4e3a\u5927\u89c4\u6a21\u56fe\u8ba1\u7b97\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5b58\u5185\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.20389", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20389", "abs": "https://arxiv.org/abs/2601.20389", "authors": ["Xiao Yang", "Yinan Ni", "Yuqi Tang", "Zhimin Qiu", "Chen Wang", "Tingzhou Yuan"], "title": "Graph-Structured Deep Learning Framework for Multi-task Contention Identification with High-dimensional Metrics", "comment": null, "summary": "This study addresses the challenge of accurately identifying multi-task contention types in high-dimensional system environments and proposes a unified contention classification framework that integrates representation transformation, structural modeling, and a task decoupling mechanism. The method first constructs system state representations from high-dimensional metric sequences, applies nonlinear transformations to extract cross-dimensional dynamic features, and integrates multiple source information such as resource utilization, scheduling behavior, and task load variations within a shared representation space. It then introduces a graph-based modeling mechanism to capture latent dependencies among metrics, allowing the model to learn competitive propagation patterns and structural interference across resource links. On this basis, task-specific mapping structures are designed to model the differences among contention types and enhance the classifier's ability to distinguish multiple contention patterns. To achieve stable performance, the method employs an adaptive multi-task loss weighting strategy that balances shared feature learning with task-specific feature extraction and generates final contention predictions through a standardized inference process. Experiments conducted on a public system trace dataset demonstrate advantages in accuracy, recall, precision, and F1, and sensitivity analyses on batch size, training sample scale, and metric dimensionality further confirm the model's stability and applicability. The study shows that structured representations and multi-task classification based on high-dimensional metrics can significantly improve contention pattern recognition and offer a reliable technical approach for performance management in complex computing environments.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u7ade\u4e89\u5206\u7c7b\u6846\u67b6\uff0c\u901a\u8fc7\u8868\u793a\u8f6c\u6362\u3001\u7ed3\u6784\u5efa\u6a21\u548c\u4efb\u52a1\u89e3\u8026\u673a\u5236\uff0c\u5728\u9ad8\u7ef4\u7cfb\u7edf\u73af\u5883\u4e2d\u51c6\u786e\u8bc6\u522b\u591a\u4efb\u52a1\u7ade\u4e89\u7c7b\u578b", "motivation": "\u89e3\u51b3\u9ad8\u7ef4\u7cfb\u7edf\u73af\u5883\u4e2d\u51c6\u786e\u8bc6\u522b\u591a\u4efb\u52a1\u7ade\u4e89\u7c7b\u578b\u7684\u6311\u6218\uff0c\u4e3a\u590d\u6742\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u6027\u80fd\u7ba1\u7406\u63d0\u4f9b\u53ef\u9760\u6280\u672f\u65b9\u6848", "method": "\u6784\u5efa\u7cfb\u7edf\u72b6\u6001\u8868\u793a\uff0c\u5e94\u7528\u975e\u7ebf\u6027\u53d8\u6362\u63d0\u53d6\u8de8\u7ef4\u5ea6\u52a8\u6001\u7279\u5f81\uff1b\u5f15\u5165\u57fa\u4e8e\u56fe\u7684\u5efa\u6a21\u673a\u5236\u6355\u6349\u6307\u6807\u95f4\u6f5c\u5728\u4f9d\u8d56\uff1b\u8bbe\u8ba1\u4efb\u52a1\u7279\u5b9a\u6620\u5c04\u7ed3\u6784\uff1b\u91c7\u7528\u81ea\u9002\u5e94\u591a\u4efb\u52a1\u635f\u5931\u52a0\u6743\u7b56\u7565", "result": "\u5728\u516c\u5f00\u7cfb\u7edf\u8ddf\u8e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u663e\u793a\u5728\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\u3001\u7cbe\u786e\u7387\u548cF1\u5206\u6570\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff1b\u5bf9\u6279\u6b21\u5927\u5c0f\u3001\u8bad\u7ec3\u6837\u672c\u89c4\u6a21\u548c\u6307\u6807\u7ef4\u5ea6\u7684\u654f\u611f\u6027\u5206\u6790\u8bc1\u5b9e\u6a21\u578b\u7a33\u5b9a\u6027\u548c\u9002\u7528\u6027", "conclusion": "\u57fa\u4e8e\u9ad8\u7ef4\u6307\u6807\u7684\u7ed3\u6784\u5316\u8868\u793a\u548c\u591a\u4efb\u52a1\u5206\u7c7b\u80fd\u663e\u8457\u6539\u5584\u7ade\u4e89\u6a21\u5f0f\u8bc6\u522b\uff0c\u4e3a\u590d\u6742\u8ba1\u7b97\u73af\u5883\u6027\u80fd\u7ba1\u7406\u63d0\u4f9b\u53ef\u9760\u6280\u672f\u9014\u5f84"}}
{"id": "2601.19908", "categories": ["cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19908", "abs": "https://arxiv.org/abs/2601.19908", "authors": ["Yanru Chen", "Runyang Tian", "Yue Pan", "Zheyu Li", "Weihong Xu", "Tajana Rosing"], "title": "CHIME: Chiplet-based Heterogeneous Near-Memory Acceleration for Edge Multimodal LLM Inference", "comment": null, "summary": "The proliferation of large language models (LLMs) is accelerating the integration of multimodal assistants into edge devices, where inference is executed under stringent latency and energy constraints, often exacerbated by intermittent connectivity. These challenges become particularly acute in the context of multimodal LLMs (MLLMs), as high-dimensional visual inputs are transformed into extensive token sequences, thereby inflating the key-value (KV) cache and imposing substantial data movement overheads to the LLM backbone. To address these issues, we present CHIME, a chiplet-based heterogeneous near-memory acceleration for edge MLLMs inference. CHIME leverages the complementary strengths of integrated monolithic 3D (M3D) DRAM and RRAM chiplets: DRAM supplies low-latency bandwidth for attention, while RRAM offers dense, non-volatile storage for weights. This heterogeneous hardware is orchestrated by a co-designed mapping framework that executes fused kernels near data, minimizing cross-chiplet traffic to maximize effective bandwidth. On FastVLM (0.6B/1.7B) and MobileVLM (1.7B/3B), CHIME achieves up to 54x speedup and up to 246x better energy efficiency per inference as compared to the edge GPU NVIDIA Jetson Orin NX. It sustains 116.5-266.5 token/J compared to Jetson's 0.7-1.1 token/J. Furthermore, it delivers up to 69.2x higher throughput than the state-of-the-art PIM accelerator FACIL. Compared to the M3D DRAM-only design, CHIME's heterogeneous memory further improves energy efficiency by 7% and performance by 2.4x.", "AI": {"tldr": "CHIME\u662f\u4e00\u79cd\u57fa\u4e8e\u5c0f\u82af\u7247\u7684\u5f02\u6784\u8fd1\u5185\u5b58\u52a0\u901f\u5668\uff0c\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u901a\u8fc7\u7ed3\u5408M3D DRAM\u548cRRAM\u5c0f\u82af\u7247\u7684\u4f18\u52bf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u80fd\u6548\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u7684\u90e8\u7f72\uff0c\u9762\u4e34\u7740\u4e25\u683c\u7684\u5ef6\u8fdf\u548c\u80fd\u8017\u7ea6\u675f\uff0c\u7279\u522b\u662f\u591a\u6a21\u6001LLMs\u9700\u8981\u5904\u7406\u9ad8\u7ef4\u89c6\u89c9\u8f93\u5165\uff0c\u4ea7\u751f\u5927\u91cftoken\u5e8f\u5217\uff0c\u5bfc\u81f4KV\u7f13\u5b58\u81a8\u80c0\u548c\u6570\u636e\u79fb\u52a8\u5f00\u9500\u5de8\u5927\u3002", "method": "CHIME\u91c7\u7528\u57fa\u4e8e\u5c0f\u82af\u7247\u7684\u5f02\u6784\u8fd1\u5185\u5b58\u52a0\u901f\u67b6\u6784\uff0c\u7ed3\u5408\u5355\u72473D DRAM\uff08\u63d0\u4f9b\u4f4e\u5ef6\u8fdf\u5e26\u5bbd\u7528\u4e8e\u6ce8\u610f\u529b\u8ba1\u7b97\uff09\u548cRRAM\uff08\u63d0\u4f9b\u5bc6\u96c6\u975e\u6613\u5931\u6027\u5b58\u50a8\u7528\u4e8e\u6743\u91cd\uff09\uff0c\u5e76\u901a\u8fc7\u534f\u540c\u8bbe\u8ba1\u7684\u6620\u5c04\u6846\u67b6\u6267\u884c\u878d\u5408\u5185\u6838\uff0c\u6700\u5c0f\u5316\u8de8\u5c0f\u82af\u7247\u6d41\u91cf\u3002", "result": "\u5728FastVLM\u548cMobileVLM\u6a21\u578b\u4e0a\uff0c\u76f8\u6bd4NVIDIA Jetson Orin NX\u8fb9\u7f18GPU\uff0cCHIME\u5b9e\u73b0\u4e86\u9ad8\u8fbe54\u500d\u52a0\u901f\u548c246\u500d\u80fd\u6548\u63d0\u5347\uff1b\u76f8\u6bd4\u6700\u5148\u8fdb\u7684PIM\u52a0\u901f\u5668FACIL\uff0c\u541e\u5410\u91cf\u63d0\u5347\u9ad8\u8fbe69.2\u500d\uff1b\u76f8\u6bd4\u7eafM3D DRAM\u8bbe\u8ba1\uff0c\u80fd\u6548\u63d0\u53477%\uff0c\u6027\u80fd\u63d0\u53472.4\u500d\u3002", "conclusion": "CHIME\u901a\u8fc7\u5f02\u6784\u5185\u5b58\u67b6\u6784\u548c\u8fd1\u5185\u5b58\u8ba1\u7b97\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e0a\u591a\u6a21\u6001LLMs\u63a8\u7406\u7684\u5ef6\u8fdf\u548c\u80fd\u8017\u6311\u6218\uff0c\u4e3a\u8fb9\u7f18AI\u90e8\u7f72\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u786c\u4ef6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.20408", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20408", "abs": "https://arxiv.org/abs/2601.20408", "authors": ["Nicholas Santavas", "Kareem Eissa", "Patrycja Cieplicka", "Piotr Florek", "Matteo Nulli", "Stefan Vasilev", "Seyyed Hadi Hashemi", "Antonios Gasteratos", "Shahram Khadivi"], "title": "Meeting SLOs, Slashing Hours: Automated Enterprise LLM Optimization with OptiKIT", "comment": "Accepted in MLSys 2026", "summary": "Enterprise LLM deployment faces a critical scalability challenge: organizations must optimize models systematically to scale AI initiatives within constrained compute budgets, yet the specialized expertise required for manual optimization remains a niche and scarce skillset. This challenge is particularly evident in managing GPU utilization across heterogeneous infrastructure while enabling teams with diverse workloads and limited LLM optimization experience to deploy models efficiently.\n  We present OptiKIT, a distributed LLM optimization framework that democratizes model compression and tuning by automating complex optimization workflows for non-expert teams. OptiKIT provides dynamic resource allocation, staged pipeline execution with automatic cleanup, and seamless enterprise integration.\n  In production, it delivers more than 2x GPU throughput improvement while empowering application teams to achieve consistent performance improvements without deep LLM optimization expertise. We share both the platform design and key engineering insights into resource allocation algorithms, pipeline orchestration, and integration patterns that enable large-scale, production-grade democratization of model optimization. Finally, we open-source the system to enable external contributions and broader reproducibility.", "AI": {"tldr": "OptiKIT\u662f\u4e00\u4e2a\u5206\u5e03\u5f0fLLM\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u590d\u6742\u4f18\u5316\u6d41\u7a0b\uff0c\u8ba9\u975e\u4e13\u4e1a\u56e2\u961f\u4e5f\u80fd\u8fdb\u884c\u6a21\u578b\u538b\u7f29\u548c\u8c03\u4f18\uff0c\u5728GPU\u8d44\u6e90\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b02\u500d\u4ee5\u4e0a\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "motivation": "\u4f01\u4e1a\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u53ef\u6269\u5c55\u6027\u6311\u6218\uff1a\u9700\u8981\u5728\u6709\u9650\u7684\u8ba1\u7b97\u9884\u7b97\u5185\u7cfb\u7edf\u5316\u4f18\u5316\u6a21\u578b\uff0c\u4f46\u624b\u52a8\u4f18\u5316\u6240\u9700\u7684\u4e13\u4e1a\u77e5\u8bc6\u548c\u6280\u80fd\u7a00\u7f3a\u4e14\u96be\u4ee5\u83b7\u53d6\u3002\u7279\u522b\u662f\u5728\u5f02\u6784\u57fa\u7840\u8bbe\u65bd\u4e2d\u7ba1\u7406GPU\u5229\u7528\u7387\uff0c\u540c\u65f6\u8ba9\u5177\u6709\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\u548c\u6709\u9650LLM\u4f18\u5316\u7ecf\u9a8c\u7684\u56e2\u961f\u80fd\u591f\u9ad8\u6548\u90e8\u7f72\u6a21\u578b\u3002", "method": "OptiKIT\u91c7\u7528\u5206\u5e03\u5f0fLLM\u4f18\u5316\u6846\u67b6\u8bbe\u8ba1\uff0c\u63d0\u4f9b\u52a8\u6001\u8d44\u6e90\u5206\u914d\u3001\u5206\u9636\u6bb5\u7ba1\u9053\u6267\u884c\u4e0e\u81ea\u52a8\u6e05\u7406\u3001\u65e0\u7f1d\u4f01\u4e1a\u96c6\u6210\u7b49\u529f\u80fd\u3002\u901a\u8fc7\u8d44\u6e90\u5206\u914d\u7b97\u6cd5\u3001\u7ba1\u9053\u7f16\u6392\u548c\u96c6\u6210\u6a21\u5f0f\u7684\u5de5\u7a0b\u5b9e\u73b0\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21\u751f\u4ea7\u7ea7\u7684\u6a21\u578b\u4f18\u5316\u6c11\u4e3b\u5316\u3002", "result": "\u5728\u751f\u4ea7\u73af\u5883\u4e2d\uff0cOptiKIT\u5b9e\u73b0\u4e86\u8d85\u8fc72\u500d\u7684GPU\u541e\u5410\u91cf\u63d0\u5347\uff0c\u4f7f\u5e94\u7528\u56e2\u961f\u65e0\u9700\u6df1\u539a\u7684LLM\u4f18\u5316\u4e13\u4e1a\u77e5\u8bc6\u5c31\u80fd\u83b7\u5f97\u4e00\u81f4\u7684\u6027\u80fd\u6539\u8fdb\u3002\u8be5\u7cfb\u7edf\u5df2\u5f00\u6e90\u4ee5\u652f\u6301\u5916\u90e8\u8d21\u732e\u548c\u66f4\u5e7f\u6cdb\u7684\u53ef\u590d\u73b0\u6027\u3002", "conclusion": "OptiKIT\u6210\u529f\u89e3\u51b3\u4e86\u4f01\u4e1aLLM\u90e8\u7f72\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u590d\u6742\u4f18\u5316\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4f7f\u975e\u4e13\u4e1a\u56e2\u961f\u4e5f\u80fd\u9ad8\u6548\u8fdb\u884c\u6a21\u578b\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86GPU\u8d44\u6e90\u5229\u7528\u7387\uff0c\u5e76\u5f00\u6e90\u7cfb\u7edf\u4ee5\u4fc3\u8fdb\u793e\u533a\u53d1\u5c55\u3002"}}
{"id": "2601.20270", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20270", "abs": "https://arxiv.org/abs/2601.20270", "authors": ["Holly Trikilis", "Pasindu Marasinghe", "Fariza Rashid", "Suranga Seneviratne"], "title": "Eliciting Least-to-Most Reasoning for Phishing URL Detection", "comment": null, "summary": "Phishing continues to be one of the most prevalent attack vectors, making accurate classification of phishing URLs essential. Recently, large language models (LLMs) have demonstrated promising results in phishing URL detection. However, their reasoning capabilities that enabled such performance remain underexplored. To this end, in this paper, we propose a Least-to-Most prompting framework for phishing URL detection. In particular, we introduce an \"answer sensitivity\" mechanism that guides Least-to-Most's iterative approach to enhance reasoning and yield higher prediction accuracy. We evaluate our framework using three URL datasets and four state-of-the-art LLMs, comparing against a one-shot approach and a supervised model. We demonstrate that our framework outperforms the one-shot baseline while achieving performance comparable to that of the supervised model, despite requiring significantly less training data. Furthermore, our in-depth analysis highlights how the iterative reasoning enabled by Least-to-Most, and reinforced by our answer sensitivity mechanism, drives these performance gains. Overall, we show that this simple yet powerful prompting strategy consistently outperforms both one-shot and supervised approaches, despite requiring minimal training or few-shot guidance. Our experimental setup can be found in our Github repository github.sydney.edu.au/htri0928/least-to-most-phishing-detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u9493\u9c7cURL\u68c0\u6d4b\u7684Least-to-Most\u63d0\u793a\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\"\u7b54\u6848\u654f\u611f\u6027\"\u673a\u5236\u589e\u5f3a\u63a8\u7406\u80fd\u529b\uff0c\u5728\u5c11\u91cf\u8bad\u7ec3\u6570\u636e\u4e0b\u8fbe\u5230\u4e0e\u76d1\u7763\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u9493\u9c7c\u653b\u51fb\u662f\u6700\u666e\u904d\u7684\u5a01\u80c1\u4e4b\u4e00\uff0c\u51c6\u786e\u5206\u7c7b\u9493\u9c7cURL\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9493\u9c7cURL\u68c0\u6d4b\u4e2d\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u63a8\u7406\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51faLeast-to-Most\u63d0\u793a\u6846\u67b6\uff0c\u5f15\u5165\"\u7b54\u6848\u654f\u611f\u6027\"\u673a\u5236\u6307\u5bfc\u8fed\u4ee3\u63a8\u7406\u8fc7\u7a0b\uff0c\u4f7f\u7528\u4e09\u4e2aURL\u6570\u636e\u96c6\u548c\u56db\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8be5\u6846\u67b6\u5728\u6027\u80fd\u4e0a\u4f18\u4e8eone-shot\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u4e0e\u76d1\u7763\u6a21\u578b\u6027\u80fd\u76f8\u5f53\uff0c\u540c\u65f6\u6240\u9700\u8bad\u7ec3\u6570\u636e\u663e\u8457\u51cf\u5c11\u3002\u8fed\u4ee3\u63a8\u7406\u548c\u7b54\u6848\u654f\u611f\u6027\u673a\u5236\u5171\u540c\u9a71\u52a8\u4e86\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8fd9\u79cd\u7b80\u5355\u800c\u5f3a\u5927\u7684\u63d0\u793a\u7b56\u7565\u5728\u6700\u5c0f\u5316\u8bad\u7ec3\u6216\u5c11\u91cf\u6307\u5bfc\u7684\u60c5\u51b5\u4e0b\uff0c\u6301\u7eed\u4f18\u4e8eone-shot\u548c\u76d1\u7763\u65b9\u6cd5\uff0c\u4e3a\u9493\u9c7cURL\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.19910", "categories": ["cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.19910", "abs": "https://arxiv.org/abs/2601.19910", "authors": ["William Meng", "Benjamin Lee", "Hong Wang"], "title": "Understanding Bottlenecks for Efficiently Serving LLM Inference With KV Offloading", "comment": "Submitted to MLSys 2026", "summary": "KV cache offloading enables long-context LLM inference by storing caches in CPU DRAM, but PCIe bandwidth limitations create severe bottlenecks. In this paper, we develops an analytical framework that derives $\u03ba_{\\text{crit}}$, the critical cached-to-prefill token ratio where execution becomes memory-bound and show typical workloads exceed this threshold by orders of magnitude. Empirical characterization reveals 99\\% of latency spent on transfers and serving offloaded requests results in GPU's consuming only 28\\% of their rated TDP, motivating our proposed optimizations for hardware interconnects, model architectures, and scheduling algorithms.", "AI": {"tldr": "KV\u7f13\u5b58\u5378\u8f7d\u6280\u672f\u901a\u8fc7\u5c06\u7f13\u5b58\u5b58\u50a8\u5728CPU DRAM\u4e2d\u5b9e\u73b0\u957f\u4e0a\u4e0b\u6587LLM\u63a8\u7406\uff0c\u4f46PCIe\u5e26\u5bbd\u9650\u5236\u9020\u6210\u4e25\u91cd\u74f6\u9888\u3002\u672c\u6587\u5f00\u53d1\u5206\u6790\u6846\u67b6\u63a8\u5bfc\u4e34\u754c\u7f13\u5b58-\u9884\u586b\u5145\u4ee4\u724c\u6bd4\u03ba_crit\uff0c\u53d1\u73b0\u5178\u578b\u5de5\u4f5c\u8d1f\u8f7d\u8fdc\u8d85\u6b64\u9608\u503c\uff0c99%\u5ef6\u8fdf\u7528\u4e8e\u6570\u636e\u4f20\u8f93\uff0cGPU\u4ec5\u6d88\u801728%\u989d\u5b9aTDP\uff0c\u63d0\u51fa\u786c\u4ef6\u4e92\u8fde\u3001\u6a21\u578b\u67b6\u6784\u548c\u8c03\u5ea6\u7b97\u6cd5\u4f18\u5316\u65b9\u6848\u3002", "motivation": "KV\u7f13\u5b58\u5378\u8f7d\u6280\u672f\u867d\u7136\u80fd\u652f\u6301\u957f\u4e0a\u4e0b\u6587LLM\u63a8\u7406\uff0c\u4f46\u53d7\u5230PCIe\u5e26\u5bbd\u9650\u5236\u7684\u4e25\u91cd\u74f6\u9888\u5f71\u54cd\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u9700\u8981\u6df1\u5165\u5206\u6790\u74f6\u9888\u539f\u56e0\u5e76\u627e\u5230\u4f18\u5316\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u5206\u6790\u6846\u67b6\u63a8\u5bfc\u4e34\u754c\u7f13\u5b58-\u9884\u586b\u5145\u4ee4\u724c\u6bd4\u03ba_crit\uff0c\u901a\u8fc7\u7ecf\u9a8c\u8868\u5f81\u5206\u6790\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u6d4b\u91cf\u5ef6\u8fdf\u5206\u5e03\u548cGPU\u529f\u8017\u60c5\u51b5\u3002", "result": "\u53d1\u73b0\u5178\u578b\u5de5\u4f5c\u8d1f\u8f7d\u8fdc\u8d85\u4e34\u754c\u9608\u503c\uff0c99%\u7684\u5ef6\u8fdf\u65f6\u95f4\u7528\u4e8e\u6570\u636e\u4f20\u8f93\uff0cGPU\u5728\u670d\u52a1\u5378\u8f7d\u8bf7\u6c42\u65f6\u4ec5\u6d88\u801728%\u7684\u989d\u5b9a\u70ed\u8bbe\u8ba1\u529f\u8017\uff0c\u8868\u660e\u7cfb\u7edf\u4e25\u91cd\u53d7\u9650\u4e8e\u5185\u5b58\u5e26\u5bbd\u800c\u975e\u8ba1\u7b97\u80fd\u529b\u3002", "conclusion": "\u9488\u5bf9KV\u7f13\u5b58\u5378\u8f7d\u7684\u74f6\u9888\u95ee\u9898\uff0c\u63d0\u51fa\u9700\u8981\u5728\u786c\u4ef6\u4e92\u8fde\u3001\u6a21\u578b\u67b6\u6784\u548c\u8c03\u5ea6\u7b97\u6cd5\u4e09\u4e2a\u5c42\u9762\u8fdb\u884c\u4f18\u5316\uff0c\u4ee5\u63d0\u5347\u957f\u4e0a\u4e0b\u6587LLM\u63a8\u7406\u7684\u6027\u80fd\u6548\u7387\u3002"}}
{"id": "2601.20435", "categories": ["cs.DC", "cs.OS"], "pdf": "https://arxiv.org/pdf/2601.20435", "abs": "https://arxiv.org/abs/2601.20435", "authors": ["Aleix Roca", "Vicen\u00e7 Beltran"], "title": "Rethinking Thread Scheduling under Oversubscription: A User-Space Framework for Coordinating Multi-runtime and Multi-process Workloads", "comment": null, "summary": "The convergence of high-performance computing (HPC) and artificial intelligence (AI) is driving the emergence of increasingly complex parallel applications and workloads. These workloads often combine multiple parallel runtimes within the same application or across co-located jobs, creating scheduling demands that place significant stress on traditional OS schedulers. When oversubscribed (there are more ready threads than cores), OS schedulers rely on periodic preemptions to multiplex cores, often introducing interference that may degrade performance. In this paper, we present: (1) The User-space Scheduling Framework (USF), a novel seamless process scheduling framework completely implemented in user-space. USF enables users to implement their own process scheduling algorithms without requiring special permissions. We evaluate USF with its default cooperative policy, (2) SCHED_COOP, designed to reduce interference by switching threads only upon blocking. This approach mitigates well-known issues such as Lock-Holder Preemption (LHP), Lock-Waiter Preemption (LWP), and scalability collapse. We implement USF and SCHED_COOP by extending the GNU C library with the nOS-V runtime, enabling seamless coordination across multiple runtimes (e.g., OpenMP) without requiring invasive application changes. Evaluations show gains up to 2.4x in oversubscribed multi-process scenarios, including nested BLAS workloads, multi-process PyTorch inference with LLaMA-3, and Molecular Dynamics (MD) simulations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7528\u6237\u7a7a\u95f4\u8c03\u5ea6\u6846\u67b6USF\u53ca\u5176\u9ed8\u8ba4\u534f\u4f5c\u7b56\u7565SCHED_COOP\uff0c\u901a\u8fc7\u5728\u7528\u6237\u7a7a\u95f4\u5b9e\u73b0\u8fdb\u7a0b\u8c03\u5ea6\uff0c\u51cf\u5c11\u64cd\u4f5c\u7cfb\u7edf\u8c03\u5ea6\u5668\u5728\u8fc7\u8f7d\u60c5\u51b5\u4e0b\u7684\u5e72\u6270\uff0c\u63d0\u5347\u5e76\u884c\u5e94\u7528\u7684\u6027\u80fd\u3002", "motivation": "\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e0e\u4eba\u5de5\u667a\u80fd\u7684\u878d\u5408\u50ac\u751f\u4e86\u590d\u6742\u7684\u5e76\u884c\u5e94\u7528\uff0c\u8fd9\u4e9b\u5e94\u7528\u5f80\u5f80\u5305\u542b\u591a\u4e2a\u5e76\u884c\u8fd0\u884c\u65f6\uff0c\u7ed9\u4f20\u7edf\u64cd\u4f5c\u7cfb\u7edf\u8c03\u5ea6\u5668\u5e26\u6765\u5de8\u5927\u538b\u529b\u3002\u5728\u8fc7\u8f7d\u60c5\u51b5\u4e0b\uff0c\u64cd\u4f5c\u7cfb\u7edf\u8c03\u5ea6\u5668\u4f9d\u8d56\u5468\u671f\u6027\u62a2\u5360\u6765\u590d\u7528\u6838\u5fc3\uff0c\u4f46\u4f1a\u5f15\u5165\u5e72\u6270\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e86\u7528\u6237\u7a7a\u95f4\u8c03\u5ea6\u6846\u67b6USF\uff0c\u5b8c\u5168\u5728\u7528\u6237\u7a7a\u95f4\u5b9e\u73b0\u8fdb\u7a0b\u8c03\u5ea6\uff0c\u5141\u8bb8\u7528\u6237\u81ea\u5b9a\u4e49\u8c03\u5ea6\u7b97\u6cd5\u800c\u65e0\u9700\u7279\u6b8a\u6743\u9650\u3002\u57fa\u4e8eUSF\u5b9e\u73b0\u4e86\u9ed8\u8ba4\u534f\u4f5c\u7b56\u7565SCHED_COOP\uff0c\u4ec5\u5728\u7ebf\u7a0b\u963b\u585e\u65f6\u5207\u6362\u7ebf\u7a0b\uff0c\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u62a2\u5360\u3002\u901a\u8fc7\u6269\u5c55GNU C\u5e93\u548cnOS-V\u8fd0\u884c\u65f6\u5b9e\u73b0\uff0c\u652f\u6301\u8de8\u591a\u4e2a\u8fd0\u884c\u65f6\uff08\u5982OpenMP\uff09\u7684\u65e0\u7f1d\u534f\u8c03\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u5728\u8fc7\u8f7d\u7684\u591a\u8fdb\u7a0b\u573a\u666f\u4e2d\uff0c\u5305\u62ec\u5d4c\u5957BLAS\u5de5\u4f5c\u8d1f\u8f7d\u3001\u591a\u8fdb\u7a0bPyTorch\u63a8\u7406\uff08LLaMA-3\uff09\u548c\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\uff0c\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u53ef\u8fbe2.4\u500d\u3002\u6709\u6548\u7f13\u89e3\u4e86\u9501\u6301\u6709\u8005\u62a2\u5360\u3001\u9501\u7b49\u5f85\u8005\u62a2\u5360\u548c\u53ef\u6269\u5c55\u6027\u5d29\u6e83\u7b49\u95ee\u9898\u3002", "conclusion": "USF\u548cSCHED_COOP\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7528\u6237\u7a7a\u95f4\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u663e\u8457\u51cf\u5c11\u64cd\u4f5c\u7cfb\u7edf\u8c03\u5ea6\u5668\u5728\u8fc7\u8f7d\u60c5\u51b5\u4e0b\u7684\u5e72\u6270\uff0c\u63d0\u5347\u590d\u6742\u5e76\u884c\u5e94\u7528\u7684\u6027\u80fd\uff0c\u4e14\u65e0\u9700\u5bf9\u5e94\u7528\u8fdb\u884c\u4fb5\u5165\u6027\u4fee\u6539\u3002"}}
{"id": "2601.20310", "categories": ["cs.CR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20310", "abs": "https://arxiv.org/abs/2601.20310", "authors": ["Xin Zhang", "Zijin Yang", "Kejiang Chen", "Linfeng Ma", "Weiming Zhang", "Nenghai Yu"], "title": "SemBind: Binding Diffusion Watermarks to Semantics Against Black-Box Forgery Attacks", "comment": null, "summary": "Latent-based watermarks, integrated into the generation process of latent diffusion models (LDMs), simplify detection and attribution of generated images. However, recent black-box forgery attacks, where an attacker needs at least one watermarked image and black-box access to the provider's model, can embed the provider's watermark into images not produced by the provider, posing outsized risk to provenance and trust. We propose SemBind, the first defense framework for latent-based watermarks that resists black-box forgery by binding latent signals to image semantics via a learned semantic masker. Trained with contrastive learning, the masker yields near-invariant codes for the same prompt and near-orthogonal codes across prompts; these codes are reshaped and permuted to modulate the target latent before any standard latent-based watermark. SemBind is generally compatible with existing latent-based watermarking schemes and keeps image quality essentially unchanged, while a simple mask-ratio parameter offers a tunable trade-off between anti-forgery strength and robustness. Across four mainstream latent-based watermark methods, our SemBind-enabled anti-forgery variants markedly reduce false acceptance under black-box forgery while providing a controllable robustness-security balance.", "AI": {"tldr": "SemBind\u662f\u9996\u4e2a\u9632\u5fa1\u6f5c\u5728\u6269\u6563\u6a21\u578b\u4e2d\u9ed1\u76d2\u4f2a\u9020\u653b\u51fb\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6f5c\u5728\u6c34\u5370\u4fe1\u53f7\u4e0e\u56fe\u50cf\u8bed\u4e49\u7ed1\u5b9a\u6765\u62b5\u6297\u653b\u51fb\uff0c\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u57fa\u672c\u4e0d\u53d8\uff0c\u5e76\u63d0\u4f9b\u53ef\u8c03\u8282\u7684\u9c81\u68d2\u6027-\u5b89\u5168\u6027\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u6f5c\u5728\u6c34\u5370\u867d\u7136\u7b80\u5316\u4e86\u751f\u6210\u56fe\u50cf\u7684\u68c0\u6d4b\u548c\u6eaf\u6e90\uff0c\u4f46\u9762\u4e34\u9ed1\u76d2\u4f2a\u9020\u653b\u51fb\u7684\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ea\u9700\u4e00\u5f20\u6c34\u5370\u56fe\u50cf\u548c\u9ed1\u76d2\u8bbf\u95ee\u6a21\u578b\uff0c\u5c31\u80fd\u5c06\u63d0\u4f9b\u5546\u7684\u6c34\u5370\u5d4c\u5165\u975e\u63d0\u4f9b\u5546\u751f\u6210\u7684\u56fe\u50cf\u4e2d\uff0c\u4e25\u91cd\u5a01\u80c1\u6eaf\u6e90\u548c\u4fe1\u4efb\u4f53\u7cfb\u3002", "method": "\u63d0\u51faSemBind\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u7684\u8bed\u4e49\u63a9\u7801\u5668\u5c06\u6f5c\u5728\u4fe1\u53f7\u4e0e\u56fe\u50cf\u8bed\u4e49\u7ed1\u5b9a\u3002\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u63a9\u7801\u5668\uff0c\u4f7f\u76f8\u540c\u63d0\u793a\u751f\u6210\u8fd1\u4e0d\u53d8\u4ee3\u7801\uff0c\u4e0d\u540c\u63d0\u793a\u751f\u6210\u8fd1\u6b63\u4ea4\u4ee3\u7801\uff1b\u8fd9\u4e9b\u4ee3\u7801\u7ecf\u8fc7\u91cd\u5851\u548c\u7f6e\u6362\u540e\u8c03\u5236\u76ee\u6807\u6f5c\u5728\u8868\u793a\uff0c\u7136\u540e\u5e94\u7528\u6807\u51c6\u6f5c\u5728\u6c34\u5370\u3002\u6846\u67b6\u517c\u5bb9\u73b0\u6709\u6f5c\u5728\u6c34\u5370\u65b9\u6848\uff0c\u901a\u8fc7\u63a9\u7801\u6bd4\u7387\u53c2\u6570\u63d0\u4f9b\u53ef\u8c03\u8282\u7684\u9c81\u68d2\u6027-\u5b89\u5168\u6027\u6743\u8861\u3002", "result": "\u5728\u56db\u79cd\u4e3b\u6d41\u6f5c\u5728\u6c34\u5370\u65b9\u6cd5\u4e0a\uff0cSemBind\u589e\u5f3a\u7684\u6297\u4f2a\u9020\u53d8\u4f53\u663e\u8457\u964d\u4f4e\u4e86\u9ed1\u76d2\u4f2a\u9020\u653b\u51fb\u4e0b\u7684\u8bef\u63a5\u53d7\u7387\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u53ef\u63a7\u7684\u9c81\u68d2\u6027-\u5b89\u5168\u6027\u5e73\u8861\uff0c\u56fe\u50cf\u8d28\u91cf\u57fa\u672c\u4fdd\u6301\u4e0d\u53d8\u3002", "conclusion": "SemBind\u662f\u9996\u4e2a\u6709\u6548\u9632\u5fa1\u6f5c\u5728\u6269\u6563\u6a21\u578b\u4e2d\u9ed1\u76d2\u4f2a\u9020\u653b\u51fb\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u7ed1\u5b9a\u673a\u5236\u4fdd\u62a4\u6c34\u5370\u7684\u5b8c\u6574\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u4e3a\u751f\u6210\u56fe\u50cf\u6eaf\u6e90\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.20595", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.20595", "abs": "https://arxiv.org/abs/2601.20595", "authors": ["Xinwei Qiang", "Yue Guan", "Zhengding Hu", "Yufei Ding", "Adnan Aziz"], "title": "AutoOverlap: Enabling Fine-Grained Overlap of Computation and Communication with Chunk-Based Scheduling", "comment": null, "summary": "Communication has become a first-order bottleneck in large-cale GPU workloads, and existing distributed compilers address it mainly by overlapping whole compute and communication kernels at the stream level. This coarse granularity incurs extra kernel launches, forces device-wide synchronizations at kernel boundaries, and leaves substantial slack when the slowest tile or kernel stretches the communication tail. We present AutoOverlap, a compiler and runtime that enables automatic fine-grained overlap inside a single fused kernel. AutoOverlap introduces a communication chunk abstraction that decouples communication granularity from kernel structure and backend mechanisms, allowing chunk-level plans to be ported from existing distributed compilers, written directly by users, or instantiated from reusable templates. Given a local Triton kernel and a chunk schedule, AutoOverlap performs transformations to align computation with chunk availability. Implemented as a source-to-source compiler on Triton, AutoOverlap delivers an average end-to-end speedup of 1.3$\\times$ and up to 4.7$\\times$ on multi-GPU workloads.", "AI": {"tldr": "AutoOverlap\u662f\u4e00\u4e2a\u7f16\u8bd1\u5668\u7cfb\u7edf\uff0c\u901a\u8fc7\u5728\u5355\u4e2a\u878d\u5408\u5185\u6838\u5185\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u901a\u4fe1\u4e0e\u8ba1\u7b97\u91cd\u53e0\uff0c\u89e3\u51b3\u5927\u89c4\u6a21GPU\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7684\u901a\u4fe1\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5206\u5e03\u5f0f\u7f16\u8bd1\u5668\u4e3b\u8981\u901a\u8fc7\u6d41\u7ea7\u522b\u7684\u7c97\u7c92\u5ea6\u91cd\u53e0\u6765\u5904\u7406\u901a\u4fe1\u74f6\u9888\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u4f1a\u5f15\u5165\u989d\u5916\u7684\u5185\u6838\u542f\u52a8\u3001\u5f3a\u5236\u8bbe\u5907\u7ea7\u540c\u6b65\uff0c\u5e76\u4e14\u5728\u6700\u6162\u7684\u74e6\u7247\u6216\u5185\u6838\u62c9\u4f38\u901a\u4fe1\u5c3e\u90e8\u65f6\u4ea7\u751f\u5927\u91cf\u7a7a\u95f2\u65f6\u95f4\u3002", "method": "AutoOverlap\u5f15\u5165\u4e86\u901a\u4fe1\u5757\u62bd\u8c61\uff0c\u5c06\u901a\u4fe1\u7c92\u5ea6\u4e0e\u5185\u6838\u7ed3\u6784\u548c\u540e\u7aef\u673a\u5236\u89e3\u8026\uff0c\u5141\u8bb8\u4ece\u73b0\u6709\u5206\u5e03\u5f0f\u7f16\u8bd1\u5668\u79fb\u690d\u5757\u7ea7\u8ba1\u5212\u3001\u7528\u6237\u76f4\u63a5\u7f16\u5199\u6216\u4ece\u53ef\u91cd\u7528\u6a21\u677f\u5b9e\u4f8b\u5316\u3002\u7ed9\u5b9a\u672c\u5730Triton\u5185\u6838\u548c\u5757\u8c03\u5ea6\uff0cAutoOverlap\u6267\u884c\u8f6c\u6362\u4ee5\u4f7f\u8ba1\u7b97\u4e0e\u5757\u53ef\u7528\u6027\u5bf9\u9f50\uff0c\u4f5c\u4e3aTriton\u7684\u6e90\u5230\u6e90\u7f16\u8bd1\u5668\u5b9e\u73b0\u3002", "result": "\u5728Triton\u4e0a\u5b9e\u73b0\u7684AutoOverlap\u5728\u591aGPU\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u5b9e\u73b0\u4e86\u5e73\u57471.3\u500d\u3001\u6700\u9ad84.7\u500d\u7684\u7aef\u5230\u7aef\u52a0\u901f\u3002", "conclusion": "AutoOverlap\u901a\u8fc7\u7ec6\u7c92\u5ea6\u91cd\u53e0\u6280\u672f\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21GPU\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7684\u901a\u4fe1\u74f6\u9888\u95ee\u9898\uff0c\u76f8\u6bd4\u73b0\u6709\u7c97\u7c92\u5ea6\u65b9\u6cd5\u5177\u6709\u663e\u8457\u6027\u80fd\u4f18\u52bf\u3002"}}
{"id": "2601.20325", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20325", "abs": "https://arxiv.org/abs/2601.20325", "authors": ["Lulu Xue", "Shengshan Hu", "Wei Lu", "Ziqi Zhou", "Yufei Song", "Jianhong Cheng", "Minghui Li", "Yanjun Zhang", "Leo Yu Zhang"], "title": "UnlearnShield: Shielding Forgotten Privacy against Unlearning Inversion", "comment": "This work has been accepted by ICASSP 2026", "summary": "Machine unlearning is an emerging technique that aims to remove the influence of specific data from trained models, thereby enhancing privacy protection. However, recent research has uncovered critical privacy vulnerabilities, showing that adversaries can exploit unlearning inversion to reconstruct data that was intended to be erased. Despite the severity of this threat, dedicated defenses remain lacking. To address this gap, we propose UnlearnShield, the first defense specifically tailored to counter unlearning inversion. UnlearnShield introduces directional perturbations in the cosine representation space and regulates them through a constraint module to jointly preserve model accuracy and forgetting efficacy, thereby reducing inversion risk while maintaining utility. Experiments demonstrate that it achieves a good trade-off among privacy protection, accuracy, and forgetting.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u53cd\u8f6c\u653b\u51fb\u7684\u9632\u5fa1\u65b9\u6cd5UnlearnShield\uff0c\u901a\u8fc7\u5728\u4f59\u5f26\u8868\u793a\u7a7a\u95f4\u5f15\u5165\u65b9\u5411\u6027\u6270\u52a8\u5e76\u7ea6\u675f\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u51c6\u786e\u6027\u548c\u9057\u5fd8\u6548\u679c\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u6280\u672f\u65e8\u5728\u4ece\u8bad\u7ec3\u6a21\u578b\u4e2d\u79fb\u9664\u7279\u5b9a\u6570\u636e\u7684\u5f71\u54cd\u4ee5\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u5b58\u5728\u9057\u5fd8\u53cd\u8f6c\u653b\u51fb\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u5229\u7528\u8be5\u6f0f\u6d1e\u91cd\u5efa\u672c\u5e94\u88ab\u5220\u9664\u7684\u6570\u636e\u3002\u76ee\u524d\u7f3a\u4e4f\u4e13\u95e8\u7684\u9632\u5fa1\u673a\u5236\u6765\u5e94\u5bf9\u8fd9\u4e00\u4e25\u91cd\u5a01\u80c1\u3002", "method": "\u63d0\u51faUnlearnShield\u9632\u5fa1\u65b9\u6cd5\uff0c\u5728\u4f59\u5f26\u8868\u793a\u7a7a\u95f4\u5f15\u5165\u65b9\u5411\u6027\u6270\u52a8\uff0c\u5e76\u901a\u8fc7\u7ea6\u675f\u6a21\u5757\u8fdb\u884c\u8c03\u8282\uff0c\u5171\u540c\u4fdd\u6301\u6a21\u578b\u51c6\u786e\u6027\u548c\u9057\u5fd8\u6548\u679c\uff0c\u4ece\u800c\u964d\u4f4e\u53cd\u8f6c\u98ce\u9669\u540c\u65f6\u7ef4\u6301\u5b9e\u7528\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eUnlearnShield\u5728\u9690\u79c1\u4fdd\u62a4\u3001\u51c6\u786e\u6027\u548c\u9057\u5fd8\u6548\u679c\u4e4b\u95f4\u5b9e\u73b0\u4e86\u826f\u597d\u7684\u5e73\u8861\uff0c\u80fd\u591f\u6709\u6548\u51cf\u5c11\u53cd\u8f6c\u653b\u51fb\u98ce\u9669\u3002", "conclusion": "UnlearnShield\u662f\u9996\u4e2a\u4e13\u95e8\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u53cd\u8f6c\u653b\u51fb\u7684\u9632\u5fa1\u65b9\u6848\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u65b9\u5411\u6027\u6270\u52a8\u548c\u7ea6\u675f\u673a\u5236\uff0c\u4e3a\u89e3\u51b3\u8fd9\u4e00\u65b0\u5174\u9690\u79c1\u5a01\u80c1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.20305", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20305", "abs": "https://arxiv.org/abs/2601.20305", "authors": ["Zhenchen Tang", "Songlin Yang", "Zichuan Wang", "Bo Peng", "Yang Li", "Beibei Dong", "Jing Dong"], "title": "Endogenous Reprompting: Self-Evolving Cognitive Alignment for Unified Multimodal Models", "comment": null, "summary": "Unified Multimodal Models (UMMs) exhibit strong understanding, yet this capability often fails to effectively guide generation. We identify this as a Cognitive Gap: the model lacks the understanding of how to enhance its own generation process. To bridge this gap, we propose Endogenous Reprompting, a mechanism that transforms the model's understanding from a passive encoding process into an explicit generative reasoning step by generating self-aligned descriptors during generation. To achieve this, we introduce SEER (Self-Evolving Evaluator and Reprompter), a training framework that establishes a two-stage endogenous loop using only 300 samples from a compact proxy task, Visual Instruction Elaboration. First, Reinforcement Learning with Verifiable Rewards (RLVR) activates the model's latent evaluation ability via curriculum learning, producing a high-fidelity endogenous reward signal. Second, Reinforcement Learning with Model-rewarded Thinking (RLMT) leverages this signal to optimize the generative reasoning policy. Experiments show that SEER consistently outperforms state-of-the-art baselines in evaluation accuracy, reprompting efficiency, and generation quality, without sacrificing general multimodal capabilities.", "AI": {"tldr": "SEER\u6846\u67b6\u901a\u8fc7\u5185\u751f\u91cd\u63d0\u793a\u673a\u5236\u89e3\u51b3UMMs\u8ba4\u77e5\u9e3f\u6c9f\u95ee\u9898\uff0c\u4ec5\u7528300\u4e2a\u6837\u672c\u8bad\u7ec3\u5373\u53ef\u63d0\u5347\u6a21\u578b\u751f\u6210\u8d28\u91cf", "motivation": "\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u867d\u7136\u5177\u5907\u5f3a\u5927\u7684\u7406\u89e3\u80fd\u529b\uff0c\u4f46\u8fd9\u79cd\u7406\u89e3\u80fd\u529b\u5f80\u5f80\u65e0\u6cd5\u6709\u6548\u6307\u5bfc\u751f\u6210\u8fc7\u7a0b\uff0c\u5b58\u5728\"\u8ba4\u77e5\u9e3f\u6c9f\"\uff1a\u6a21\u578b\u7f3a\u4e4f\u5982\u4f55\u6539\u8fdb\u81ea\u8eab\u751f\u6210\u8fc7\u7a0b\u7684\u7406\u89e3", "method": "\u63d0\u51fa\u5185\u751f\u91cd\u63d0\u793a\u673a\u5236\uff0c\u5c06\u6a21\u578b\u7406\u89e3\u4ece\u88ab\u52a8\u7f16\u7801\u8fc7\u7a0b\u8f6c\u53d8\u4e3a\u663e\u5f0f\u751f\u6210\u63a8\u7406\u6b65\u9aa4\uff1b\u5f15\u5165SEER\u8bad\u7ec3\u6846\u67b6\uff0c\u5efa\u7acb\u4e24\u9636\u6bb5\u5185\u751f\u5faa\u73af\uff1a1) RLVR\u901a\u8fc7\u8bfe\u7a0b\u5b66\u4e60\u6fc0\u6d3b\u6a21\u578b\u6f5c\u5728\u8bc4\u4f30\u80fd\u529b\uff0c\u4ea7\u751f\u9ad8\u4fdd\u771f\u5185\u751f\u5956\u52b1\u4fe1\u53f7\uff1b2) RLMT\u5229\u7528\u8be5\u4fe1\u53f7\u4f18\u5316\u751f\u6210\u63a8\u7406\u7b56\u7565", "result": "SEER\u5728\u8bc4\u4f30\u51c6\u786e\u6027\u3001\u91cd\u63d0\u793a\u6548\u7387\u548c\u751f\u6210\u8d28\u91cf\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u4e0d\u727a\u7272\u901a\u7528\u591a\u6a21\u6001\u80fd\u529b", "conclusion": "\u5185\u751f\u91cd\u63d0\u793a\u673a\u5236\u6709\u6548\u5f25\u5408\u4e86UMMs\u7684\u8ba4\u77e5\u9e3f\u6c9f\uff0cSEER\u6846\u67b6\u4ec5\u9700\u5c11\u91cf\u6837\u672c\u5373\u53ef\u663e\u8457\u63d0\u5347\u6a21\u578b\u751f\u6210\u8d28\u91cf\uff0c\u4e3a\u591a\u6a21\u6001\u6a21\u578b\u7684\u81ea\u8fdb\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2601.20655", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.20655", "abs": "https://arxiv.org/abs/2601.20655", "authors": ["June Chen", "Neal Xu", "Gragas Huang", "Bok Zhou", "Stephen Liu"], "title": "OnePiece: A Large-Scale Distributed Inference System with RDMA for Complex AI-Generated Content (AIGC) Workflows", "comment": "12 pages", "summary": "The rapid growth of AI-generated content (AIGC) has enabled high-quality creative production across diverse domains, yet existing systems face critical inefficiencies in throughput, resource utilization, and scalability under concurrent workloads. This paper introduces OnePiece, a large-scale distributed inference system with RDMA optimized for multi-stage AIGC workflows. By decomposing pipelines into fine-grained microservices and leveraging one-sided RDMA communication, OnePiece significantly reduces inter-node latency and CPU overhead while improving GPU utilization. The system incorporates a novel double-ring buffer design to resolve deadlocks in RDMA-aware memory access without CPU involvement. Additionally, a dynamic Node Manager allocates resources elastically across workflow stages in response to real-time load. Experimental results demonstrate that OnePiece reduces GPU resource consumption by 16x in Wan2.1 image-to-video generation compared to monolithic inference pipelines, offering a scalable, fault-tolerant, and efficient solution for production AIGC environments.", "AI": {"tldr": "OnePiece\u662f\u4e00\u4e2a\u9488\u5bf9\u591a\u9636\u6bb5AI\u751f\u6210\u5185\u5bb9\u5de5\u4f5c\u6d41\u4f18\u5316\u7684\u5206\u5e03\u5f0f\u63a8\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7RDMA\u901a\u4fe1\u548c\u5fae\u670d\u52a1\u67b6\u6784\u663e\u8457\u63d0\u5347\u541e\u5410\u91cf\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002", "motivation": "\u73b0\u6709AI\u751f\u6210\u5185\u5bb9\u7cfb\u7edf\u5728\u5904\u7406\u5e76\u53d1\u5de5\u4f5c\u8d1f\u8f7d\u65f6\u9762\u4e34\u541e\u5410\u91cf\u3001\u8d44\u6e90\u5229\u7528\u7387\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u7684\u5173\u952e\u6548\u7387\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u5206\u5e03\u5f0f\u63a8\u7406\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u6d41\u6c34\u7ebf\u5206\u89e3\u4e3a\u7ec6\u7c92\u5ea6\u5fae\u670d\u52a1\uff0c\u5229\u7528\u5355\u8fb9RDMA\u901a\u4fe1\u51cf\u5c11\u8282\u70b9\u95f4\u5ef6\u8fdf\u548cCPU\u5f00\u9500\uff1b\u91c7\u7528\u65b0\u9896\u7684\u53cc\u73af\u5f62\u7f13\u51b2\u533a\u8bbe\u8ba1\u89e3\u51b3RDMA\u611f\u77e5\u5185\u5b58\u8bbf\u95ee\u7684\u6b7b\u9501\u95ee\u9898\uff1b\u5f15\u5165\u52a8\u6001\u8282\u70b9\u7ba1\u7406\u5668\u6839\u636e\u5b9e\u65f6\u8d1f\u8f7d\u5f39\u6027\u5206\u914d\u8d44\u6e90\u3002", "result": "\u5728Wan2.1\u56fe\u50cf\u5230\u89c6\u9891\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u76f8\u6bd4\u5355\u4f53\u63a8\u7406\u6d41\u6c34\u7ebf\uff0cOnePiece\u5c06GPU\u8d44\u6e90\u6d88\u8017\u964d\u4f4e\u4e8616\u500d\uff0c\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u5bb9\u9519\u4e14\u9ad8\u6548\u7684AIGC\u751f\u4ea7\u73af\u5883\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "OnePiece\u901a\u8fc7RDMA\u4f18\u5316\u7684\u5206\u5e03\u5f0f\u67b6\u6784\u548c\u521b\u65b0\u7684\u5185\u5b58\u7ba1\u7406\u673a\u5236\uff0c\u4e3a\u5927\u89c4\u6a21AI\u751f\u6210\u5185\u5bb9\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u663e\u8457\u63d0\u5347\u7684\u6027\u80fd\u548c\u8d44\u6e90\u6548\u7387\uff0c\u9002\u5408\u751f\u4ea7\u73af\u5883\u90e8\u7f72\u3002"}}
{"id": "2601.19941", "categories": ["cs.AR", "cs.AI", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19941", "abs": "https://arxiv.org/abs/2601.19941", "authors": ["M Zafir Sadik Khan", "Kimia Azar", "Hadi Kamali"], "title": "Bench4HLS: End-to-End Evaluation of LLMs in High-Level Synthesis Code Generation", "comment": "Accepted to the Design, Automation and Test in Europe Conference (DATE 2026)", "summary": "In last two years, large language models (LLMs) have shown strong capabilities in code generation, including hardware design at register-transfer level (RTL). While their use in high-level synthesis (HLS) remains comparatively less mature, the ratio of HLS- to RTL-focused studies has shifted from 1:10 to 2:10 in the past six months, indicating growing interest in leveraging LLMs for high-level design entry while relying on downstream synthesis for optimization. This growing trend highlights the need for a comprehensive benchmarking and evaluation framework dedicated to LLM-based HLS. To address this, We present Bench4HLS for evaluating LLM-generated HLS designs. Bench4HLS comprises 170 manually drafted and validated case studies, spanning small kernels to complex accelerators, curated from widely used public repositories. The framework supports fully automated assessment of compilation success, functional correctness via simulation, and synthesis feasibility/optimization. Crucially, Bench4HLS integrates a pluggable API for power, performance, and area (PPA) analysis across various HLS toolchains and architectures, demonstrated here with Xilinx Vitis HLS and validated on Catapult HLS. By providing a structured, extensible, and plug-and-play testbed, Bench4HLS establishes a foundational methodology for benchmarking LLMs in HLS workflows.", "AI": {"tldr": "Bench4HLS\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u751f\u6210HLS\u8bbe\u8ba1\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5305\u542b170\u4e2a\u624b\u52a8\u7f16\u5199\u548c\u9a8c\u8bc1\u7684\u6848\u4f8b\uff0c\u652f\u6301\u81ea\u52a8\u5316\u8bc4\u4f30\u7f16\u8bd1\u6210\u529f\u3001\u529f\u80fd\u6b63\u786e\u6027\u548c\u7efc\u5408\u53ef\u884c\u6027\uff0c\u5e76\u96c6\u6210\u4e86\u53ef\u63d2\u62d4\u7684PPA\u5206\u6790API\u3002", "motivation": "\u968f\u7740LLM\u5728\u4ee3\u7801\u751f\u6210\uff08\u5305\u62ecRTL\u786c\u4ef6\u8bbe\u8ba1\uff09\u65b9\u9762\u5c55\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u5176\u5728HLS\u9886\u57df\u7684\u5e94\u7528\u867d\u7136\u76f8\u5bf9\u4e0d\u6210\u719f\u4f46\u5174\u8da3\u65e5\u76ca\u589e\u957f\uff08HLS\u4e0eRTL\u7814\u7a76\u7684\u6bd4\u4f8b\u4ece1:10\u53d8\u4e3a2:10\uff09\u3002\u8fd9\u51f8\u663e\u4e86\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8eLLM-based HLS\u7684\u5168\u9762\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86Bench4HLS\u6846\u67b6\uff0c\u5305\u542b170\u4e2a\u4ece\u5e7f\u6cdb\u4f7f\u7528\u7684\u516c\u5171\u4ed3\u5e93\u4e2d\u7cbe\u5fc3\u6311\u9009\u7684\u624b\u52a8\u7f16\u5199\u548c\u9a8c\u8bc1\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u6db5\u76d6\u4ece\u5c0f\u578b\u5185\u6838\u5230\u590d\u6742\u52a0\u901f\u5668\u3002\u6846\u67b6\u652f\u6301\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u7f16\u8bd1\u6210\u529f\u8bc4\u4f30\u3001\u901a\u8fc7\u4eff\u771f\u7684\u529f\u80fd\u6b63\u786e\u6027\u9a8c\u8bc1\u4ee5\u53ca\u7efc\u5408\u53ef\u884c\u6027/\u4f18\u5316\u8bc4\u4f30\u3002\u5173\u952e\u7684\u662f\u96c6\u6210\u4e86\u53ef\u63d2\u62d4API\uff0c\u7528\u4e8e\u8de8\u4e0d\u540cHLS\u5de5\u5177\u94fe\u548c\u67b6\u6784\u7684\u529f\u8017\u3001\u6027\u80fd\u548c\u9762\u79ef\uff08PPA\uff09\u5206\u6790\u3002", "result": "\u8be5\u6846\u67b6\u5df2\u5728Xilinx Vitis HLS\u4e0a\u6f14\u793a\uff0c\u5e76\u5728Catapult HLS\u4e0a\u9a8c\u8bc1\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u3001\u53ef\u6269\u5c55\u548c\u5373\u63d2\u5373\u7528\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002Bench4HLS\u4e3a\u5728HLS\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u57fa\u51c6\u6d4b\u8bd5LLM\u5efa\u7acb\u4e86\u57fa\u7840\u65b9\u6cd5\u5b66\u3002", "conclusion": "Bench4HLS\u901a\u8fc7\u63d0\u4f9b\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u89e3\u51b3\u4e86LLM\u5728HLS\u9886\u57df\u8bc4\u4f30\u7684\u8feb\u5207\u9700\u6c42\uff0c\u4e3a\u672a\u6765LLM-based HLS\u7814\u7a76\u548c\u53d1\u5c55\u5960\u5b9a\u4e86\u91cd\u8981\u57fa\u7840\u3002"}}
{"id": "2601.20352", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20352", "abs": "https://arxiv.org/abs/2601.20352", "authors": ["Weiquan Huang", "Zixuan Wang", "Hehai Lin", "Sudong Wang", "Bo Xu", "Qian Li", "Beier Zhu", "Linyi Yang", "Chengwei Qin"], "title": "AMA: Adaptive Memory via Multi-Agent Collaboration", "comment": "8 pages", "summary": "The rapid evolution of Large Language Model (LLM) agents has necessitated robust memory systems to support cohesive long-term interaction and complex reasoning. Benefiting from the strong capabilities of LLMs, recent research focus has shifted from simple context extension to the development of dedicated agentic memory systems. However, existing approaches typically rely on rigid retrieval granularity, accumulation-heavy maintenance strategies, and coarse-grained update mechanisms. These design choices create a persistent mismatch between stored information and task-specific reasoning demands, while leading to the unchecked accumulation of logical inconsistencies over time. To address these challenges, we propose Adaptive Memory via Multi-Agent Collaboration (AMA), a novel framework that leverages coordinated agents to manage memory across multiple granularities. AMA employs a hierarchical memory design that dynamically aligns retrieval granularity with task complexity. Specifically, the Constructor and Retriever jointly enable multi-granularity memory construction and adaptive query routing. The Judge verifies the relevance and consistency of retrieved content, triggering iterative retrieval when evidence is insufficient or invoking the Refresher upon detecting logical conflicts. The Refresher then enforces memory consistency by performing targeted updates or removing outdated entries. Extensive experiments on challenging long-context benchmarks show that AMA significantly outperforms state-of-the-art baselines while reducing token consumption by approximately 80% compared to full-context methods, demonstrating its effectiveness in maintaining retrieval precision and long-term memory consistency.", "AI": {"tldr": "AMA\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5b9e\u73b0\u81ea\u9002\u5e94\u8bb0\u5fc6\u7ba1\u7406\uff0c\u663e\u8457\u63d0\u5347\u957f\u671f\u8bb0\u5fc6\u4e00\u81f4\u6027\u5e76\u51cf\u5c1180%\u7684token\u6d88\u8017", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\u8bb0\u5fc6\u7cfb\u7edf\u5b58\u5728\u68c0\u7d22\u7c92\u5ea6\u50f5\u5316\u3001\u7ef4\u62a4\u7b56\u7565\u7d2f\u79ef\u8fc7\u91cd\u3001\u66f4\u65b0\u673a\u5236\u7c97\u7c92\u5ea6\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u5b58\u50a8\u4fe1\u606f\u4e0e\u4efb\u52a1\u9700\u6c42\u4e0d\u5339\u914d\uff0c\u4ee5\u53ca\u903b\u8f91\u4e0d\u4e00\u81f4\u6027\u7684\u6301\u7eed\u7d2f\u79ef", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u8bb0\u5fc6\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6(AMA)\uff0c\u91c7\u7528\u5206\u5c42\u8bb0\u5fc6\u8bbe\u8ba1\uff0c\u901a\u8fc7Constructor\u548cRetriever\u5b9e\u73b0\u591a\u7c92\u5ea6\u8bb0\u5fc6\u6784\u5efa\u548c\u81ea\u9002\u5e94\u67e5\u8be2\u8def\u7531\uff0cJudge\u9a8c\u8bc1\u76f8\u5173\u6027\u548c\u4e00\u81f4\u6027\uff0cRefresher\u6267\u884c\u9488\u5bf9\u6027\u66f4\u65b0", "result": "\u5728\u6311\u6218\u6027\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAMA\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u57fa\u7ebf\uff0c\u76f8\u6bd4\u5168\u4e0a\u4e0b\u6587\u65b9\u6cd5\u51cf\u5c11\u7ea680%\u7684token\u6d88\u8017\uff0c\u6709\u6548\u4fdd\u6301\u4e86\u68c0\u7d22\u7cbe\u5ea6\u548c\u957f\u671f\u8bb0\u5fc6\u4e00\u81f4\u6027", "conclusion": "AMA\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u5206\u5c42\u8bb0\u5fc6\u8bbe\u8ba1\uff0c\u6210\u529f\u89e3\u51b3\u4e86LLM\u667a\u80fd\u4f53\u8bb0\u5fc6\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u4e3a\u6784\u5efa\u66f4\u9ad8\u6548\u3001\u4e00\u81f4\u7684\u957f\u65f6\u8bb0\u5fc6\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848"}}
{"id": "2601.20374", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.20374", "abs": "https://arxiv.org/abs/2601.20374", "authors": ["Sura Khalid Salsal", "Eman Shaker Mahmood", "Farah Tawfiq Abdul Hussien", "Maryam Mahdi Alhusseini", "Azhar Naji Alyahya", "Nikolai Safiullin"], "title": "A High-Performance Fractal Encryption Framework and Modern Innovations for Secure Image Transmission", "comment": null, "summary": "The current digital era, driven by growing threats to data security, requires a robust image encryption technique. Classical encryption algorithms suffer from a trade-off among security, image fidelity, and computational efficiency. This paper aims to enhance the performance and efficiency of image encryption. This is done by proposing Fractal encryption based on Fourier transforms as a new method of image encryption, leveraging state-of-the-art technology. The new approach considered here intends to enhance both security and efficiency in image encryption by comparing Fractal Encryption with basic methods. The suggested system also aims to optimise encryption/ decryption times and preserve image quality. This paper provides an introduction to Image Encryption using the fractal-based method, its mathematical formulation, and its comparative efficiency against publicly known traditional encryption methods. As a result, after filling the gaps identified in previous research, it has significantly improved both its encryption/decryption time and image fidelity compared to other techniques. In this paper, directions for future research and possible improvements are outlined for attention.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5085\u91cc\u53f6\u53d8\u6362\u7684\u5206\u5f62\u56fe\u50cf\u52a0\u5bc6\u65b9\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u4f20\u7edf\u52a0\u5bc6\u7b97\u6cd5\u5728\u5b89\u5168\u6027\u3001\u56fe\u50cf\u4fdd\u771f\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a0\u5bc6/\u89e3\u5bc6\u65f6\u95f4\u548c\u56fe\u50cf\u8d28\u91cf\u3002", "motivation": "\u5f53\u524d\u6570\u5b57\u65f6\u4ee3\u5bf9\u6570\u636e\u5b89\u5168\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u4f20\u7edf\u56fe\u50cf\u52a0\u5bc6\u7b97\u6cd5\u5728\u5b89\u5168\u6027\u3001\u56fe\u50cf\u4fdd\u771f\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u56fe\u50cf\u52a0\u5bc6\u6280\u672f\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5085\u91cc\u53f6\u53d8\u6362\u7684\u5206\u5f62\u52a0\u5bc6\u65b9\u6cd5\u4f5c\u4e3a\u65b0\u7684\u56fe\u50cf\u52a0\u5bc6\u6280\u672f\uff0c\u5229\u7528\u6700\u5148\u8fdb\u7684\u6280\u672f\uff0c\u901a\u8fc7\u5206\u5f62\u7ed3\u6784\u4e0e\u5085\u91cc\u53f6\u53d8\u6362\u7684\u7ed3\u5408\u6765\u589e\u5f3a\u52a0\u5bc6\u6027\u80fd\u3002", "result": "\u4e0e\u5df2\u77e5\u7684\u4f20\u7edf\u52a0\u5bc6\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u6539\u5584\u4e86\u52a0\u5bc6/\u89e3\u5bc6\u65f6\u95f4\uff0c\u540c\u65f6\u66f4\u597d\u5730\u4fdd\u6301\u4e86\u56fe\u50cf\u8d28\u91cf\uff0c\u586b\u8865\u4e86\u5148\u524d\u7814\u7a76\u7684\u7a7a\u767d\u3002", "conclusion": "\u57fa\u4e8e\u5085\u91cc\u53f6\u53d8\u6362\u7684\u5206\u5f62\u52a0\u5bc6\u65b9\u6cd5\u5728\u56fe\u50cf\u52a0\u5bc6\u9886\u57df\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u548c\u6539\u8fdb\u7a7a\u95f4\u3002"}}
{"id": "2601.20379", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20379", "abs": "https://arxiv.org/abs/2601.20379", "authors": ["Zhengbo Jiao", "Hongyu Xian", "Qinglong Wang", "Yunpu Ma", "Zhebo Wang", "Zifan Zhang", "Dezhang Kong", "Meng Han"], "title": "Policy of Thoughts: Scaling LLM Reasoning via Test-time Policy Evolution", "comment": "19 pages, 5 figures", "summary": "Large language models (LLMs) struggle with complex, long-horizon reasoning due to instability caused by their frozen policy assumption. Current test-time scaling methods treat execution feedback merely as an external signal for filtering or rewriting trajectories, without internalizing it to improve the underlying reasoning strategy. Inspired by Popper's epistemology of \"conjectures and refutations,\" we argue that intelligence requires real-time evolution of the model's policy through learning from failed attempts. We introduce Policy of Thoughts (PoT), a framework that recasts reasoning as a within-instance online optimization process. PoT first generates diverse candidate solutions via an efficient exploration mechanism, then uses Group Relative Policy Optimization (GRPO) to update a transient LoRA adapter based on execution feedback. This closed-loop design enables dynamic, instance-specific refinement of the model's reasoning priors. Experiments show that PoT dramatically boosts performance: a 4B model achieves 49.71% accuracy on LiveCodeBench, outperforming GPT-4o and DeepSeek-V3 despite being over 50 smaller.", "AI": {"tldr": "PoT\u6846\u67b6\u901a\u8fc7\u5728\u7ebf\u4f18\u5316\u7b56\u7565\u89e3\u51b3LLMs\u5728\u590d\u6742\u957f\u7a0b\u63a8\u7406\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4f7f\u5c0f\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u8d85\u8d8aGPT-4o\u7b49\u5927\u6a21\u578b", "motivation": "\u5f53\u524dLLMs\u5728\u590d\u6742\u957f\u7a0b\u63a8\u7406\u4e2d\u5b58\u5728\u4e0d\u7a33\u5b9a\u6027\uff0c\u4e3b\u8981\u6e90\u4e8e\u5176\u56fa\u5b9a\u7684\u7b56\u7565\u5047\u8bbe\u3002\u73b0\u6709\u65b9\u6cd5\u4ec5\u5c06\u6267\u884c\u53cd\u9988\u4f5c\u4e3a\u5916\u90e8\u4fe1\u53f7\u7528\u4e8e\u7b5b\u9009\u6216\u91cd\u5199\u8f68\u8ff9\uff0c\u672a\u80fd\u5c06\u5176\u5185\u5316\u4ee5\u6539\u8fdb\u5e95\u5c42\u63a8\u7406\u7b56\u7565\u3002\u53d7\u6ce2\u666e\u5c14\"\u731c\u60f3\u4e0e\u53cd\u9a73\"\u8ba4\u8bc6\u8bba\u542f\u53d1\uff0c\u4f5c\u8005\u8ba4\u4e3a\u667a\u80fd\u9700\u8981\u901a\u8fc7\u5b66\u4e60\u5931\u8d25\u5c1d\u8bd5\u6765\u5b9e\u65f6\u6f14\u5316\u6a21\u578b\u7b56\u7565\u3002", "method": "\u63d0\u51faPolicy of Thoughts (PoT)\u6846\u67b6\uff0c\u5c06\u63a8\u7406\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5b9e\u4f8b\u5185\u7684\u5728\u7ebf\u4f18\u5316\u8fc7\u7a0b\u3002\u9996\u5148\u901a\u8fc7\u9ad8\u6548\u63a2\u7d22\u673a\u5236\u751f\u6210\u591a\u6837\u5019\u9009\u89e3\uff0c\u7136\u540e\u4f7f\u7528Group Relative Policy Optimization (GRPO)\u57fa\u4e8e\u6267\u884c\u53cd\u9988\u66f4\u65b0\u77ac\u6001LoRA\u9002\u914d\u5668\u3002\u8fd9\u79cd\u95ed\u73af\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u6a21\u578b\u63a8\u7406\u5148\u9a8c\u7684\u52a8\u6001\u3001\u5b9e\u4f8b\u7279\u5b9a\u7ec6\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660ePoT\u663e\u8457\u63d0\u5347\u6027\u80fd\uff1a\u4e00\u4e2a4B\u53c2\u6570\u6a21\u578b\u5728LiveCodeBench\u4e0a\u8fbe\u523049.71%\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u4e86GPT-4o\u548cDeepSeek-V3\uff0c\u5c3d\u7ba1\u6a21\u578b\u89c4\u6a21\u5c0f\u4e8650\u500d\u4ee5\u4e0a\u3002", "conclusion": "PoT\u6846\u67b6\u901a\u8fc7\u5c06\u63a8\u7406\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5728\u7ebf\u4f18\u5316\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u4e86LLMs\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u5c0f\u6a21\u578b\u901a\u8fc7\u7b56\u7565\u4f18\u5316\u53ef\u4ee5\u8d85\u8d8a\u5927\u6a21\u578b\uff0c\u4e3aLLMs\u7684\u63a8\u7406\u80fd\u529b\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.20378", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.20378", "abs": "https://arxiv.org/abs/2601.20378", "authors": ["Mario Perera", "Michael Mackay", "Max Hashem Eiza", "Alessandro Raschell\u00e0", "Nathan Shone", "Mukesh Kumar Maheshwari"], "title": "Towards Quantum-Safe O-RAN -- Experimental Evaluation of ML-KEM-Based IPsec on the E2 Interface", "comment": "Please note this is a draft and will be revised soon. However, all the simulations, experiments, and findings are final", "summary": "As Open Radio Access Network (O-RAN) deployments expand and adversaries adopt 'store-now, decrypt-later' strategies, operators need empirical data on the cost of migrating critical control interfaces to post-quantum cryptography (PQC). This paper experimentally evaluates the impact of integrating a NIST-aligned module-lattice KEM (ML-KEM, CRYSTALS-Kyber) into IKEv2/IPsec protecting the E2 interface between the 5G Node B (gNB) and the Near-Real-Time RAN Intelligent Controller (Near-RT RIC). Using an open-source testbed built from srsRAN, Open5GS, FlexRIC and strongSwan (with liboqs), we compare three configurations: no IPsec, classical ECDH-based IPsec, and ML-KEM-based IPsec. The study focuses on IPsec tunnel-setup latency and the runtime behaviour of Near-RT RIC xApps under realistic signalling workloads. Results from repeated, automated runs show that ML-KEM integration adds a small overhead to tunnel establishment, which is approximately 3~5 ms in comparison to classical IPsec, while xApp operation and RIC control loops remain stable in our experiments. These findings indicate that ML-KEM based IPsec on the E2 interface is practically feasible and inform quantum-safe migration strategies for O-RAN deployments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u5728O-RAN E2\u63a5\u53e3\u4e0a\u96c6\u6210\u540e\u91cf\u5b50\u5bc6\u7801\u5b66ML-KEM\u5bf9IPsec\u96a7\u9053\u5efa\u7acb\u5ef6\u8fdf\u548cxApp\u8fd0\u884c\u7684\u5f71\u54cd\uff0c\u53d1\u73b0ML-KEM\u4ec5\u589e\u52a03-5ms\u5f00\u9500\uff0c\u8868\u660e\u91cf\u5b50\u5b89\u5168\u8fc1\u79fb\u5177\u6709\u53ef\u884c\u6027\u3002", "motivation": "\u968f\u7740O-RAN\u90e8\u7f72\u6269\u5c55\u548c\u653b\u51fb\u8005\u91c7\u7528\"\u5148\u5b58\u50a8\u540e\u89e3\u5bc6\"\u7b56\u7565\uff0c\u8fd0\u8425\u5546\u9700\u8981\u5173\u4e8e\u5c06\u5173\u952e\u63a7\u5236\u63a5\u53e3\u8fc1\u79fb\u5230\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u7684\u5b9e\u9645\u6210\u672c\u6570\u636e\u3002\u672c\u6587\u65e8\u5728\u4e3aO-RAN\u90e8\u7f72\u7684\u91cf\u5b50\u5b89\u5168\u8fc1\u79fb\u7b56\u7565\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e\u3002", "method": "\u4f7f\u7528\u5f00\u6e90\u6d4b\u8bd5\u5e73\u53f0\uff08srsRAN\u3001Open5GS\u3001FlexRIC\u3001strongSwan\u548cliboqs\uff09\u6784\u5efa\u5b9e\u9a8c\u73af\u5883\uff0c\u6bd4\u8f83\u4e09\u79cd\u914d\u7f6e\uff1a\u65e0IPsec\u3001\u57fa\u4e8eECDH\u7684\u4f20\u7edfIPsec\u3001\u57fa\u4e8eML-KEM\u7684IPsec\u3002\u91cd\u70b9\u5173\u6ce8IPsec\u96a7\u9053\u5efa\u7acb\u5ef6\u8fdf\u548cNear-RT RIC xApps\u5728\u771f\u5b9e\u4fe1\u4ee4\u8d1f\u8f7d\u4e0b\u7684\u8fd0\u884c\u65f6\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cML-KEM\u96c6\u6210\u76f8\u6bd4\u4f20\u7edfIPsec\u4ec5\u589e\u52a0\u7ea63-5ms\u7684\u96a7\u9053\u5efa\u7acb\u5f00\u9500\uff0cxApp\u64cd\u4f5c\u548cRIC\u63a7\u5236\u56de\u8def\u5728\u5b9e\u9a8c\u4e2d\u4fdd\u6301\u7a33\u5b9a\u3002\u8fd9\u8868\u660e\u57fa\u4e8eML-KEM\u7684IPsec\u5728E2\u63a5\u53e3\u4e0a\u5177\u6709\u5b9e\u9645\u53ef\u884c\u6027\u3002", "conclusion": "ML-KEM\u57fa\u4e8eIPsec\u5728O-RAN E2\u63a5\u53e3\u4e0a\u7684\u5e94\u7528\u662f\u5b9e\u9645\u53ef\u884c\u7684\uff0c\u4e3aO-RAN\u90e8\u7f72\u7684\u91cf\u5b50\u5b89\u5168\u8fc1\u79fb\u7b56\u7565\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u4f9d\u636e\uff0c\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u8fc1\u79fb\u4ec5\u5e26\u6765\u53ef\u63a5\u53d7\u7684\u5c0f\u5e45\u6027\u80fd\u5f00\u9500\u3002"}}
{"id": "2601.20067", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.20067", "abs": "https://arxiv.org/abs/2601.20067", "authors": ["Maxwell Phillips", "Firas Hassan", "Ahmed Ammar"], "title": "A Paradigm for Generalized Multi-Level Priority Encoders", "comment": "17 pages, 21 figures", "summary": "Priority encoders are typically considered expensive hardware components in terms of complexity, especially at high bit precisions or input lengths (e.g., above 512 bits). However, if the complexity can be reduced, priority encoders can feasibly accelerate a variety of key applications, such as high-precision integer arithmetic and content-addressable memory. We propose a new paradigm for constructing priority encoders by generalizing the previously proposed two-level priority encoder structure. We extend this concept to three and four levels using two techniques -- cascading and composition -- and discuss further generalization. We then analyze the complexity and delay of new and existing priority encoder designs as a function of input length, for both FPGA and ASIC implementation technologies. In particular, we compare the multi-level structure to the traditional single-level priority encoder structure, a tree-based design, a recursive design, and the two-level structure. We find that the two-level architecture provides balanced performance -- reducing complexity by around half, but at the cost of a corresponding increase in delay. Additional levels have diminishing returns, highlighting a tradeoff between complexity and delay. Meanwhile, the tree and recursive designs are generally faster, but are more complex than the two-level and multi-level structures. We explore several characteristics and patterns of the designs across a wide range of input lengths. We then provide recommendations on which architecture to use for a given input length and implementation technology, based on which design factors -- such as complexity or delay -- are most important to the hardware designer. With this overview and analysis of various priority encoder architectures, we provide a priority encoder toolkit to assist hardware designers in creating the most optimal design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4f18\u5148\u7ea7\u7f16\u7801\u5668\u8bbe\u8ba1\u8303\u5f0f\uff0c\u901a\u8fc7\u5c06\u539f\u6709\u7684\u4e24\u7ea7\u7ed3\u6784\u6269\u5c55\u5230\u4e09\u3001\u56db\u7ea7\uff0c\u5206\u6790\u4e0d\u540c\u67b6\u6784\u5728\u590d\u6742\u5ea6\u548c\u5ef6\u8fdf\u4e0a\u7684\u6743\u8861\uff0c\u4e3a\u786c\u4ef6\u8bbe\u8ba1\u8005\u63d0\u4f9b\u4f18\u5316\u5efa\u8bae\u3002", "motivation": "\u4f20\u7edf\u4f18\u5148\u7ea7\u7f16\u7801\u5668\u5728\u9ad8\u4f4d\u7cbe\u5ea6\u6216\u957f\u8f93\u5165\uff08\u5982512\u4f4d\u4ee5\u4e0a\uff09\u65f6\u786c\u4ef6\u590d\u6742\u5ea6\u9ad8\uff0c\u9650\u5236\u4e86\u5176\u5728\u5173\u952e\u5e94\u7528\uff08\u5982\u9ad8\u7cbe\u5ea6\u6574\u6570\u8fd0\u7b97\u548c\u5185\u5bb9\u53ef\u5bfb\u5740\u5b58\u50a8\u5668\uff09\u4e2d\u7684\u4f7f\u7528\u3002\u964d\u4f4e\u590d\u6742\u5ea6\u53ef\u4ee5\u4f7f\u4f18\u5148\u7ea7\u7f16\u7801\u5668\u66f4\u53ef\u884c\u5730\u52a0\u901f\u8fd9\u4e9b\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u4f18\u5148\u7ea7\u7f16\u7801\u5668\u6784\u9020\u8303\u5f0f\uff0c\u5c06\u539f\u6709\u7684\u4e24\u7ea7\u7ed3\u6784\u901a\u8fc7\u7ea7\u8054\u548c\u7ec4\u5408\u4e24\u79cd\u6280\u672f\u6269\u5c55\u5230\u4e09\u3001\u56db\u7ea7\uff0c\u5e76\u8ba8\u8bba\u8fdb\u4e00\u6b65\u6cdb\u5316\u3002\u5206\u6790\u65b0\u8bbe\u8ba1\u548c\u73b0\u6709\u8bbe\u8ba1\u7684\u590d\u6742\u5ea6\u4e0e\u5ef6\u8fdf\uff0c\u6bd4\u8f83\u591a\u7ea7\u7ed3\u6784\u4e0e\u4f20\u7edf\u7684\u5355\u7ea7\u7ed3\u6784\u3001\u6811\u5f62\u8bbe\u8ba1\u3001\u9012\u5f52\u8bbe\u8ba1\u4ee5\u53ca\u4e24\u7ea7\u7ed3\u6784\u3002", "result": "\u4e24\u7ea7\u67b6\u6784\u63d0\u4f9b\u4e86\u5e73\u8861\u7684\u6027\u80fd\u2014\u2014\u590d\u6742\u5ea6\u964d\u4f4e\u7ea6\u4e00\u534a\uff0c\u4f46\u5ef6\u8fdf\u76f8\u5e94\u589e\u52a0\u3002\u66f4\u591a\u7ea7\u522b\u5e26\u6765\u7684\u6536\u76ca\u9012\u51cf\uff0c\u7a81\u663e\u4e86\u590d\u6742\u5ea6\u4e0e\u5ef6\u8fdf\u4e4b\u95f4\u7684\u6743\u8861\u3002\u6811\u5f62\u548c\u9012\u5f52\u8bbe\u8ba1\u901a\u5e38\u66f4\u5feb\uff0c\u4f46\u6bd4\u4e24\u7ea7\u548c\u591a\u7ea7\u7ed3\u6784\u66f4\u590d\u6742\u3002\u7814\u7a76\u5728\u4e0d\u540c\u8f93\u5165\u957f\u5ea6\u4e0b\u7684\u8bbe\u8ba1\u7279\u6027\uff0c\u5e76\u4e3a\u4e0d\u540c\u5b9e\u73b0\u6280\u672f\u63d0\u4f9b\u67b6\u6784\u9009\u62e9\u5efa\u8bae\u3002", "conclusion": "\u901a\u8fc7\u5206\u6790\u548c\u6bd4\u8f83\u5404\u79cd\u4f18\u5148\u7ea7\u7f16\u7801\u5668\u67b6\u6784\uff0c\u4e3a\u786c\u4ef6\u8bbe\u8ba1\u8005\u63d0\u4f9b\u4e86\u4f18\u5148\u7ea7\u7f16\u7801\u5668\u5de5\u5177\u5305\uff0c\u5e2e\u52a9\u4ed6\u4eec\u6839\u636e\u5177\u4f53\u9700\u6c42\uff08\u590d\u6742\u5ea6\u6216\u5ef6\u8fdf\u4f18\u5148\uff09\u9009\u62e9\u6700\u4f18\u8bbe\u8ba1\uff0c\u5e73\u8861\u6027\u80fd\u4e0e\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2601.20400", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.20400", "abs": "https://arxiv.org/abs/2601.20400", "authors": ["Jean-Guillaume Dumas", "Aude Maignan", "Luiza Soezima"], "title": "Fuzzy Private Set Union via Oblivious Key Homomorphic Encryption Retrieval", "comment": null, "summary": "Private Set Multi-Party Computations are protocols that allow parties to jointly and securely compute functions: apart from what is deducible from the output of the function, the input sets are kept private. Then, a Private Set Union (PSU), resp. Intersection (PSI), is a protocol that allows parties to jointly compute the union, resp. the intersection, between their private sets. Now a structured PSI, is a PSI where some structure of the sets can allow for more efficient protocols. For instance in Fuzzy PSI, elements only need to be close enough, instead of equal, to be part of the intersection. We present in this paper, Fuzzy PSU protocols (FPSU), able to efficiently take into account approximations in the union. For this, we introduce a new efficient sub-protocol, called Oblivious Key Homomorphic Encryption Retrieval (OKHER), improving on Oblivious Key-Value Retrieval (OKVR) techniques in our setting. In the fuzzy context, the receiver set $X=\\{x_i\\}_{1..n}$ is replaced by ${\\mathcal B}_\u03b4(X)$, the union of $n$ balls of dimension $d$ with radius $\u03b4$, centered at the $x_i$. The sender set is just its $m$ points of dimension $d$. Then the FPSU functionality corresponds to $X \\sqcup \\{y \\in Y, y \\notin {\\mathcal B}_\u03b4(X)\\}$. Thus, we formally define the FPSU functionality and security properties, and propose several protocols tuned to the patterns of the balls using the $l_\\infty$ distance. Using our OKHER routine and homomorphic encryption, we are for instance able to obtain a FPSU protocols with an asymptotic communication volume bound ranging from $O(dm\\log(\u03b4{n}))$ to $O(d^2m\\log(\u03b4^2n))$, depending on the receiver data set structure.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6a21\u7cca\u79c1\u6709\u96c6\u5408\u5e76\uff08FPSU\uff09\u534f\u8bae\uff0c\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u9ad8\u6548\u5b50\u534f\u8baeOKHER\uff0c\u5728\u8003\u8651\u8fd1\u4f3c\u6027\u7684\u60c5\u51b5\u4e0b\u5b89\u5168\u8ba1\u7b97\u96c6\u5408\u7684\u5e76\u96c6\u3002", "motivation": "\u4f20\u7edf\u7684\u79c1\u6709\u96c6\u5408\u8fd0\u7b97\uff08\u5982PSU\u548cPSI\uff09\u8981\u6c42\u5143\u7d20\u5b8c\u5168\u76f8\u7b49\u624d\u80fd\u53c2\u4e0e\u8ba1\u7b97\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5143\u7d20\u53ef\u80fd\u53ea\u662f\u8fd1\u4f3c\u76f8\u7b49\u3002\u73b0\u6709\u7684\u6a21\u7ccaPSI\u534f\u8bae\u53ef\u4ee5\u5904\u7406\u8fd1\u4f3c\u6027\uff0c\u4f46\u7f3a\u4e4f\u9ad8\u6548\u7684\u6a21\u7ccaPSU\u534f\u8bae\u6765\u5904\u7406\u96c6\u5408\u7684\u5e76\u96c6\u8fd0\u7b97\u3002", "method": "\u5f15\u5165\u65b0\u7684\u5b50\u534f\u8baeOKHER\uff08Oblivious Key Homomorphic Encryption Retrieval\uff09\uff0c\u6539\u8fdb\u73b0\u6709\u7684OKVR\u6280\u672f\u3002\u5c06\u63a5\u6536\u65b9\u96c6\u5408X\u66ff\u6362\u4e3a\u4ee5X\u4e2d\u6bcf\u4e2a\u70b9\u4e3a\u4e2d\u5fc3\u3001\u534a\u5f84\u4e3a\u03b4\u7684d\u7ef4\u7403\u7684\u5e76\u96c6\uff0c\u53d1\u9001\u65b9\u96c6\u5408\u4fdd\u6301\u4e3ad\u7ef4\u70b9\u96c6\u3002\u4f7f\u7528l\u221e\u8ddd\u79bb\u548c\u540c\u6001\u52a0\u5bc6\u6280\u672f\uff0c\u6839\u636e\u7403\u7684\u4e0d\u540c\u6a21\u5f0f\u8bbe\u8ba1\u591a\u4e2a\u534f\u8bae\u3002", "result": "\u63d0\u51fa\u7684FPSU\u534f\u8bae\u5177\u6709\u6e10\u8fd1\u901a\u4fe1\u91cf\u8303\u56f4\uff0c\u4eceO(dm log(\u03b4n))\u5230O(d\u00b2m log(\u03b4\u00b2n))\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u63a5\u6536\u65b9\u6570\u636e\u96c6\u7684\u7ed3\u6784\u3002OKHER\u534f\u8bae\u5728\u6a21\u7cca\u73af\u5883\u4e0b\u6bd4\u73b0\u6709\u7684OKVR\u6280\u672f\u66f4\u9ad8\u6548\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u6b63\u5f0f\u5b9a\u4e49\u4e86FPSU\u529f\u80fd\u6027\u548c\u5b89\u5168\u5c5e\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8eOKHER\u548c\u540c\u6001\u52a0\u5bc6\u7684\u9ad8\u6548FPSU\u534f\u8bae\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u96c6\u5408\u8fd0\u7b97\u4e2d\u7684\u8fd1\u4f3c\u6027\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u9690\u79c1\u4fdd\u62a4\u96c6\u5408\u8fd0\u7b97\u65b9\u6848\u3002"}}
{"id": "2601.20115", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20115", "abs": "https://arxiv.org/abs/2601.20115", "authors": ["Emanuele Del Sozzo", "Martin Fleming", "Kenneth Flamm", "Neil Thompson"], "title": "How Much Progress Has There Been in NVIDIA Datacenter GPUs?", "comment": null, "summary": "Graphics Processing Units (GPUs) are the state-of-the-art architecture for essential tasks, ranging from rendering 2D/3D graphics to accelerating workloads in supercomputing centers and, of course, Artificial Intelligence (AI). As GPUs continue improving to satisfy ever-increasing performance demands, analyzing past and current progress becomes paramount in determining future constraints on scientific research. This is particularly compelling in the AI domain, where rapid technological advancements and fierce global competition have led the United States to recently implement export control regulations limiting international access to advanced AI chips. For this reason, this paper studies technical progress in NVIDIA datacenter GPUs released from the mid-2000s until today. Specifically, we compile a comprehensive dataset of datacenter NVIDIA GPUs comprising several features, ranging from computational performance to release price. Then, we examine trends in main GPU features and estimate progress indicators for per-memory bandwidth, per-dollar, and per-watt increase rates. Our main results identify doubling times of 1.44 and 1.69 years for FP16 and FP32 operations (without accounting for sparsity benefits), while FP64 doubling times range from 2.06 to 3.79 years. Off-chip memory size and bandwidth grew at slower rates than computing performance, doubling every 3.32 to 3.53 years. The release prices of datacenter GPUs have roughly doubled every 5.1 years, while their power consumption has approximately doubled every 16 years. Finally, we quantify the potential implications of current U.S. export control regulations in terms of the potential performance gaps that would result if implementation were assumed to be complete and successful. We find that recently proposed changes to export controls would shrink the potential performance gap from 23.6x to 3.54x.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86NVIDIA\u6570\u636e\u4e2d\u5fc3GPU\u4ece2000\u5e74\u4ee3\u4e2d\u671f\u81f3\u4eca\u7684\u6280\u672f\u8fdb\u6b65\u8d8b\u52bf\uff0c\u91cf\u5316\u4e86\u5404\u9879\u6027\u80fd\u6307\u6807\u7684\u500d\u589e\u65f6\u95f4\uff0c\u5e76\u8bc4\u4f30\u4e86\u7f8e\u56fd\u51fa\u53e3\u7ba1\u5236\u5bf9AI\u82af\u7247\u6027\u80fd\u5dee\u8ddd\u7684\u5f71\u54cd\u3002", "motivation": "\u968f\u7740GPU\u5728AI\u7b49\u5173\u952e\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5206\u6790\u5176\u6280\u672f\u6f14\u8fdb\u8d8b\u52bf\u5bf9\u9884\u6d4b\u672a\u6765\u79d1\u5b66\u7814\u7a76\u7684\u9650\u5236\u81f3\u5173\u91cd\u8981\u3002\u7279\u522b\u662f\u5728\u7f8e\u56fd\u5b9e\u65bdAI\u82af\u7247\u51fa\u53e3\u7ba1\u5236\u7684\u80cc\u666f\u4e0b\uff0c\u4e86\u89e3GPU\u6280\u672f\u8fdb\u6b65\u7684\u901f\u5ea6\u548c\u6a21\u5f0f\u5177\u6709\u91cd\u8981\u73b0\u5b9e\u610f\u4e49\u3002", "method": "\u7814\u7a76\u6536\u96c6\u4e86NVIDIA\u6570\u636e\u4e2d\u5fc3GPU\u7684\u5168\u9762\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u8ba1\u7b97\u6027\u80fd\u3001\u4ef7\u683c\u7b49\u591a\u79cd\u7279\u5f81\u3002\u901a\u8fc7\u5206\u6790\u4e3b\u8981GPU\u7279\u5f81\u7684\u8d8b\u52bf\uff0c\u4f30\u7b97\u6bcf\u5185\u5b58\u5e26\u5bbd\u3001\u6bcf\u7f8e\u5143\u548c\u6bcf\u74e6\u7279\u7684\u8fdb\u6b65\u6307\u6807\uff0c\u5e76\u91cf\u5316\u51fa\u53e3\u7ba1\u5236\u53ef\u80fd\u5bfc\u81f4\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "result": "FP16\u548cFP32\u8fd0\u7b97\u7684\u500d\u589e\u65f6\u95f4\u4e3a1.44-1.69\u5e74\uff0cFP64\u4e3a2.06-3.79\u5e74\u3002\u5185\u5b58\u5927\u5c0f\u548c\u5e26\u5bbd\u589e\u957f\u8f83\u6162\uff083.32-3.53\u5e74\uff09\u3002\u6570\u636e\u4e2d\u5fc3GPU\u4ef7\u683c\u6bcf5.1\u5e74\u7ffb\u500d\uff0c\u529f\u8017\u6bcf16\u5e74\u7ffb\u500d\u3002\u51fa\u53e3\u7ba1\u5236\u8c03\u6574\u540e\uff0c\u6f5c\u5728\u6027\u80fd\u5dee\u8ddd\u4ece23.6\u500d\u7f29\u5c0f\u52303.54\u500d\u3002", "conclusion": "GPU\u8ba1\u7b97\u6027\u80fd\u7684\u589e\u957f\u901f\u5ea6\u8fdc\u8d85\u5185\u5b58\u5e26\u5bbd\u548c\u4ef7\u683c\u589e\u957f\uff0c\u63ed\u793a\u4e86\u6280\u672f\u53d1\u5c55\u7684\u4e0d\u5e73\u8861\u6027\u3002\u7f8e\u56fd\u51fa\u53e3\u7ba1\u5236\u653f\u7b56\u5bf9AI\u82af\u7247\u6027\u80fd\u5dee\u8ddd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4f46\u8fd1\u671f\u8c03\u6574\u5c06\u5927\u5e45\u7f29\u5c0f\u8fd9\u4e00\u5dee\u8ddd\uff0c\u5bf9\u5168\u7403AI\u7ade\u4e89\u683c\u5c40\u4ea7\u751f\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2601.20467", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20467", "abs": "https://arxiv.org/abs/2601.20467", "authors": ["Zhenxuan Fan", "Jie Cao", "Yang Dai", "Zheqi Lv", "Wenqiao Zhang", "Zhongle Xie", "Peng LU", "Beng Chin Ooi"], "title": "CtrlCoT: Dual-Granularity Chain-of-Thought Compression for Controllable Reasoning", "comment": "16 pages, 9 figures, 11 tables", "summary": "Chain-of-thought (CoT) prompting improves LLM reasoning but incurs high latency and memory cost due to verbose traces, motivating CoT compression with preserved correctness. Existing methods either shorten CoTs at the semantic level, which is often conservative, or prune tokens aggressively, which can miss task-critical cues and degrade accuracy. Moreover, combining the two is non-trivial due to sequential dependency, task-agnostic pruning, and distribution mismatch. We propose \\textbf{CtrlCoT}, a dual-granularity CoT compression framework that harmonizes semantic abstraction and token-level pruning through three components: Hierarchical Reasoning Abstraction produces CoTs at multiple semantic granularities; Logic-Preserving Distillation trains a logic-aware pruner to retain indispensable reasoning cues (e.g., numbers and operators) across pruning ratios; and Distribution-Alignment Generation aligns compressed traces with fluent inference-time reasoning styles to avoid fragmentation. On MATH-500 with Qwen2.5-7B-Instruct, CtrlCoT uses 30.7\\% fewer tokens while achieving 7.6 percentage points higher than the strongest baseline, demonstrating more efficient and reliable reasoning. Our code will be publicly available at https://github.com/fanzhenxuan/Ctrl-CoT.", "AI": {"tldr": "CtrlCoT\u662f\u4e00\u4e2a\u53cc\u7c92\u5ea6CoT\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u62bd\u8c61\u548c\u4ee4\u724c\u7ea7\u526a\u679d\u7684\u534f\u8c03\uff0c\u5728\u51cf\u5c1130.7%\u4ee4\u724c\u7684\u540c\u65f6\u63d0\u5347\u63a8\u7406\u51c6\u786e\u60277.6\u4e2a\u767e\u5206\u70b9", "motivation": "\u73b0\u6709\u7684CoT\u63d0\u793a\u65b9\u6cd5\u867d\u7136\u80fd\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u4f1a\u4ea7\u751f\u5197\u957f\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u5bfc\u81f4\u9ad8\u5ef6\u8fdf\u548c\u9ad8\u5185\u5b58\u6210\u672c\u3002\u73b0\u6709\u7684\u538b\u7f29\u65b9\u6cd5\u8981\u4e48\u5728\u8bed\u4e49\u5c42\u9762\u8fc7\u4e8e\u4fdd\u5b88\uff0c\u8981\u4e48\u5728\u4ee4\u724c\u5c42\u9762\u8fc7\u4e8e\u6fc0\u8fdb\uff0c\u5bb9\u6613\u4e22\u5931\u5173\u952e\u63a8\u7406\u7ebf\u7d22\u5e76\u964d\u4f4e\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faCtrlCoT\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u5206\u5c42\u63a8\u7406\u62bd\u8c61\uff1a\u751f\u6210\u591a\u7c92\u5ea6\u8bed\u4e49\u7684CoT\uff1b2) \u903b\u8f91\u4fdd\u6301\u84b8\u998f\uff1a\u8bad\u7ec3\u903b\u8f91\u611f\u77e5\u7684\u526a\u679d\u5668\uff0c\u4fdd\u7559\u5173\u952e\u63a8\u7406\u7ebf\u7d22\uff08\u5982\u6570\u5b57\u548c\u8fd0\u7b97\u7b26\uff09\uff1b3) \u5206\u5e03\u5bf9\u9f50\u751f\u6210\uff1a\u5bf9\u9f50\u538b\u7f29\u8f68\u8ff9\u4e0e\u63a8\u7406\u65f6\u98ce\u683c\uff0c\u907f\u514d\u788e\u7247\u5316\u3002", "result": "\u5728MATH-500\u6570\u636e\u96c6\u4e0a\u4f7f\u7528Qwen2.5-7B-Instruct\u6a21\u578b\uff0cCtrlCoT\u76f8\u6bd4\u6700\u5f3a\u57fa\u7ebf\u51cf\u5c11\u4e8630.7%\u7684\u4ee4\u724c\u4f7f\u7528\uff0c\u540c\u65f6\u51c6\u786e\u7387\u63d0\u5347\u4e867.6\u4e2a\u767e\u5206\u70b9\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u53ef\u9760\u7684\u63a8\u7406\u3002", "conclusion": "CtrlCoT\u901a\u8fc7\u534f\u8c03\u8bed\u4e49\u62bd\u8c61\u548c\u4ee4\u724c\u7ea7\u526a\u679d\uff0c\u6709\u6548\u89e3\u51b3\u4e86CoT\u538b\u7f29\u4e2d\u7684\u6743\u8861\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u63a8\u7406\u6b63\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u4e3a\u9ad8\u6548LLM\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2601.20507", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.20507", "abs": "https://arxiv.org/abs/2601.20507", "authors": ["Philipp Mao", "Li Shi", "Marcel Busch", "Mathias Payer"], "title": "T\u00c4MU: Emulating Trusted Applications at the (GlobalPlatform)-API Layer", "comment": null, "summary": "Mobile devices rely on Trusted Execution Environments (TEEs) to execute security-critical code and protect sensitive assets. This security-critical code is modularized in components known as Trusted Applications (TAs). Vulnerabilities in TAs can compromise the TEE and, thus, the entire system. However, the closed-source nature and fragmentation of mobile TEEs severely hinder dynamic analysis of TAs, limiting testing efforts to mostly static analyses. This paper presents T\u00c4MU, a rehosting platform enabling dynamic analysis of TAs, specifically fuzzing and debugging, by interposing their execution at the API layer. To scale to many TAs across different TEEs, T\u00c4MU leverages the standardization of TEE APIs, driven by the GlobalPlatform specifications. For the remaining TEE-specific APIs not shared across different TEEs, T\u00c4MU introduces the notion of greedy high-level emulation, a technique that allows prioritizing manual rehosting efforts based on the potential coverage gain during fuzzing. We implement T\u00c4MU and use it to emulate 67 TAs across four TEEs. Our fuzzing campaigns yielded 17 zero-day vulnerabilities across 11 TAs. These results indicate a deficit of dynamic analysis capabilities across the TEE ecosystem, where not even vendors with source code unlocked these capabilities for themselves. T\u00c4MU promises to close this gap by bringing effective and practical dynamic analysis to the mobile TEE domain.", "AI": {"tldr": "T\u00c4MU\u662f\u4e00\u4e2a\u91cd\u65b0\u6258\u7ba1\u5e73\u53f0\uff0c\u901a\u8fc7API\u5c42\u62e6\u622a\u6267\u884c\uff0c\u5b9e\u73b0\u5bf9\u53ef\u4fe1\u5e94\u7528(TA)\u7684\u52a8\u6001\u5206\u6790\uff08\u6a21\u7cca\u6d4b\u8bd5\u548c\u8c03\u8bd5\uff09\uff0c\u89e3\u51b3\u4e86\u79fb\u52a8TEE\u751f\u6001\u7cfb\u7edf\u4e2d\u52a8\u6001\u5206\u6790\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u79fb\u52a8\u8bbe\u5907\u4f9d\u8d56\u53ef\u4fe1\u6267\u884c\u73af\u5883(TEE)\u6267\u884c\u5b89\u5168\u5173\u952e\u4ee3\u7801\u548c\u4fdd\u62a4\u654f\u611f\u8d44\u4ea7\uff0c\u4f46TEE\u7684\u95ed\u6e90\u6027\u548c\u788e\u7247\u5316\u4e25\u91cd\u963b\u788d\u4e86\u5bf9\u53ef\u4fe1\u5e94\u7528(TA)\u7684\u52a8\u6001\u5206\u6790\uff0c\u4f7f\u5f97\u6d4b\u8bd5\u5de5\u4f5c\u4e3b\u8981\u5c40\u9650\u4e8e\u9759\u6001\u5206\u6790\uff0c\u5bfc\u81f4TA\u4e2d\u7684\u6f0f\u6d1e\u53ef\u80fd\u5371\u53ca\u6574\u4e2a\u7cfb\u7edf\u5b89\u5168\u3002", "method": "T\u00c4MU\u5229\u7528GlobalPlatform\u89c4\u8303\u9a71\u52a8\u7684TEE API\u6807\u51c6\u5316\uff0c\u5728API\u5c42\u62e6\u622aTA\u6267\u884c\u5b9e\u73b0\u91cd\u65b0\u6258\u7ba1\u3002\u5bf9\u4e8e\u4e0d\u540cTEE\u7279\u6709\u7684API\uff0c\u5f15\u5165\"\u8d2a\u5a6a\u9ad8\u7ea7\u4eff\u771f\"\u6280\u672f\uff0c\u6839\u636e\u6a21\u7cca\u6d4b\u8bd5\u671f\u95f4\u6f5c\u5728\u8986\u76d6\u7387\u589e\u76ca\u6765\u4f18\u5148\u5b89\u6392\u624b\u52a8\u91cd\u65b0\u6258\u7ba1\u5de5\u4f5c\u3002", "result": "\u5b9e\u73b0\u4e86T\u00c4MU\u5e73\u53f0\uff0c\u6210\u529f\u4eff\u771f\u4e864\u4e2a\u4e0d\u540cTEE\u4e2d\u768467\u4e2a\u53ef\u4fe1\u5e94\u7528\u3002\u6a21\u7cca\u6d4b\u8bd5\u6d3b\u52a8\u53d1\u73b0\u4e8611\u4e2aTA\u4e2d\u768417\u4e2a\u96f6\u65e5\u6f0f\u6d1e\uff0c\u8868\u660e\u5373\u4f7f\u62e5\u6709\u6e90\u4ee3\u7801\u7684\u4f9b\u5e94\u5546\u4e5f\u672a\u80fd\u5145\u5206\u5229\u7528\u52a8\u6001\u5206\u6790\u80fd\u529b\u3002", "conclusion": "T\u00c4MU\u901a\u8fc7\u4e3a\u79fb\u52a8TEE\u9886\u57df\u5e26\u6765\u6709\u6548\u4e14\u5b9e\u7528\u7684\u52a8\u6001\u5206\u6790\uff0c\u6709\u671b\u5f25\u8865\u5f53\u524d\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u52a8\u6001\u5206\u6790\u80fd\u529b\u7f3a\u53e3\uff0c\u63d0\u5347TEE\u5b89\u5168\u6027\u3002"}}
{"id": "2601.20267", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.20267", "abs": "https://arxiv.org/abs/2601.20267", "authors": ["Zhenkun Fan", "Zishen Wan", "Che-Kai Liu", "Ashwin Sanjay Lele", "Win-San Khwa", "Bo Zhang", "Meng-Fan Chang", "Arijit Raychowdhury"], "title": "SATA: Sparsity-Aware Scheduling for Selective Token Attention", "comment": "This paper has been accepted to DATE 2026", "summary": "Transformers have become the foundation of numerous state-of-the-art AI models across diverse domains, thanks to their powerful attention mechanism for modeling long-range dependencies. However, the quadratic scaling complexity of attention poses significant challenges for efficient hardware implementation. While techniques such as quantization and pruning help mitigate this issue, selective token attention offers a promising alternative by narrowing the attention scope to only the most relevant tokens, reducing computation and filtering out noise.\n  In this work, we propose SATA, a locality-centric dynamic scheduling scheme that proactively manages sparsely distributed access patterns from selective Query-Key operations. By reordering operand flow and exploiting data locality, our approach enables early fetch and retirement of intermediate Query/Key vectors, improving system utilization. We implement and evaluate our token management strategy in a control and compute system, using runtime traces from selective-attention-based models. Experimental results show that our method improves system throughput by up to 1.76x and boosts energy efficiency by 2.94x, while incurring minimal scheduling overhead.", "AI": {"tldr": "SATA\u662f\u4e00\u79cd\u9488\u5bf9\u9009\u62e9\u6027\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7a00\u758f\u8bbf\u95ee\u6a21\u5f0f\u7684\u52a8\u6001\u8c03\u5ea6\u65b9\u6848\uff0c\u901a\u8fc7\u91cd\u65b0\u6392\u5e8f\u64cd\u4f5c\u6570\u6d41\u548c\u5229\u7528\u6570\u636e\u5c40\u90e8\u6027\uff0c\u63d0\u5347\u7cfb\u7edf\u541e\u5410\u91cf\u548c\u80fd\u6548\u3002", "motivation": "Transformer\u7684\u6ce8\u610f\u529b\u673a\u5236\u5177\u6709\u4e8c\u6b21\u590d\u6742\u5ea6\uff0c\u5bf9\u786c\u4ef6\u5b9e\u73b0\u6784\u6210\u6311\u6218\u3002\u9009\u62e9\u6027\u4ee4\u724c\u6ce8\u610f\u529b\u901a\u8fc7\u805a\u7126\u76f8\u5173\u4ee4\u724c\u6765\u51cf\u5c11\u8ba1\u7b97\uff0c\u4f46\u5176\u7a00\u758f\u8bbf\u95ee\u6a21\u5f0f\u9700\u8981\u6709\u6548\u7684\u8c03\u5ea6\u7ba1\u7406\u3002", "method": "\u63d0\u51faSATA\u65b9\u6848\uff0c\u91c7\u7528\u4ee5\u5c40\u90e8\u6027\u4e3a\u4e2d\u5fc3\u7684\u52a8\u6001\u8c03\u5ea6\u7b56\u7565\uff0c\u4e3b\u52a8\u7ba1\u7406\u9009\u62e9\u6027Query-Key\u64cd\u4f5c\u4ea7\u751f\u7684\u7a00\u758f\u8bbf\u95ee\u6a21\u5f0f\uff0c\u901a\u8fc7\u91cd\u65b0\u6392\u5e8f\u64cd\u4f5c\u6570\u6d41\u3001\u5229\u7528\u6570\u636e\u5c40\u90e8\u6027\u5b9e\u73b0\u4e2d\u95f4Query/Key\u5411\u91cf\u7684\u65e9\u671f\u83b7\u53d6\u548c\u91ca\u653e\u3002", "result": "\u5728\u57fa\u4e8e\u9009\u62e9\u6027\u6ce8\u610f\u529b\u6a21\u578b\u7684\u8fd0\u884c\u65f6\u8f68\u8ff9\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u7cfb\u7edf\u541e\u5410\u91cf\u6700\u9ad8\u63d0\u53471.76\u500d\uff0c\u80fd\u6548\u63d0\u53472.94\u500d\uff0c\u8c03\u5ea6\u5f00\u9500\u6700\u5c0f\u3002", "conclusion": "SATA\u65b9\u6848\u901a\u8fc7\u6709\u6548\u7684\u52a8\u6001\u8c03\u5ea6\u7ba1\u7406\u9009\u62e9\u6027\u6ce8\u610f\u529b\u4e2d\u7684\u7a00\u758f\u8bbf\u95ee\u6a21\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u548c\u80fd\u6548\uff0c\u4e3aTransformer\u786c\u4ef6\u5b9e\u73b0\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2601.20548", "categories": ["cs.CR", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.20548", "abs": "https://arxiv.org/abs/2601.20548", "authors": ["Kahraman Kostas", "Rabia Yasa Kostas"], "title": "IoT Device Identification with Machine Learning: Common Pitfalls and Best Practices", "comment": "4 pages", "summary": "This paper critically examines the device identification process using machine learning, addressing common pitfalls in existing literature. We analyze the trade-offs between identification methods (unique vs. class based), data heterogeneity, feature extraction challenges, and evaluation metrics. By highlighting specific errors, such as improper data augmentation and misleading session identifiers, we provide a robust guideline for researchers to enhance the reproducibility and generalizability of IoT security models.", "AI": {"tldr": "\u8bba\u6587\u6279\u5224\u6027\u5206\u6790\u7269\u8054\u7f51\u8bbe\u5907\u8bc6\u522b\u4e2d\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u6307\u51fa\u73b0\u6709\u6587\u732e\u5e38\u89c1\u9677\u9631\uff0c\u5206\u6790\u8bc6\u522b\u65b9\u6cd5\u3001\u6570\u636e\u5f02\u8d28\u6027\u3001\u7279\u5f81\u63d0\u53d6\u548c\u8bc4\u4f30\u6307\u6807\u7684\u6743\u8861\uff0c\u63d0\u4f9b\u589e\u5f3a\u6a21\u578b\u53ef\u590d\u73b0\u6027\u548c\u6cdb\u5316\u6027\u7684\u6307\u5357", "motivation": "\u73b0\u6709\u7269\u8054\u7f51\u8bbe\u5907\u8bc6\u522b\u7814\u7a76\u5b58\u5728\u5e38\u89c1\u7f3a\u9677\uff0c\u5305\u62ec\u6570\u636e\u589e\u5f3a\u4e0d\u5f53\u3001\u4f1a\u8bdd\u6807\u8bc6\u7b26\u8bef\u5bfc\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u6a21\u578b\u53ef\u590d\u73b0\u6027\u548c\u6cdb\u5316\u6027\u4e0d\u8db3\uff0c\u9700\u8981\u7cfb\u7edf\u5206\u6790\u8fd9\u4e9b\u9677\u9631\u5e76\u63d0\u4f9b\u6539\u8fdb\u6307\u5357", "method": "\u901a\u8fc7\u6279\u5224\u6027\u5206\u6790\u73b0\u6709\u6587\u732e\uff0c\u7cfb\u7edf\u7814\u7a76\u8bbe\u5907\u8bc6\u522b\u65b9\u6cd5\uff08\u552f\u4e00\u8bc6\u522b\u4e0e\u7c7b\u522b\u8bc6\u522b\uff09\u7684\u6743\u8861\u3001\u6570\u636e\u5f02\u8d28\u6027\u6311\u6218\u3001\u7279\u5f81\u63d0\u53d6\u95ee\u9898\u4ee5\u53ca\u8bc4\u4f30\u6307\u6807\u9009\u62e9\uff0c\u8bc6\u522b\u5177\u4f53\u9519\u8bef\u5e76\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848", "result": "\u8bc6\u522b\u4e86\u7269\u8054\u7f51\u8bbe\u5907\u8bc6\u522b\u4e2d\u7684\u5173\u952e\u9677\u9631\uff0c\u5305\u62ec\u4e0d\u6070\u5f53\u7684\u6570\u636e\u589e\u5f3a\u3001\u8bef\u5bfc\u6027\u4f1a\u8bdd\u6807\u8bc6\u7b26\u4f7f\u7528\u7b49\uff0c\u63d0\u51fa\u4e86\u589e\u5f3a\u6a21\u578b\u53ef\u590d\u73b0\u6027\u548c\u6cdb\u5316\u6027\u7684\u5177\u4f53\u6307\u5357", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u7269\u8054\u7f51\u8bbe\u5907\u8bc6\u522b\u4e2d\u7684\u673a\u5668\u5b66\u4e60\u9677\u9631\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u6539\u8fdb\u6a21\u578b\u53ef\u590d\u73b0\u6027\u548c\u6cdb\u5316\u6027\u7684\u5b9e\u7528\u6307\u5357\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u66f4\u53ef\u9760\u7684\u7269\u8054\u7f51\u5b89\u5168\u7814\u7a76"}}
{"id": "2601.20317", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.20317", "abs": "https://arxiv.org/abs/2601.20317", "authors": ["Yipu Zhang", "Jintao Cheng", "Xingyu Liu", "Zeyu Li", "Carol Jingyi Li", "Jin Wu", "Lin Jiang", "Yuan Xie", "Jiang Xu", "Wei Zhang"], "title": "VersaQ-3D: A Reconfigurable Accelerator Enabling Feed-Forward and Generalizable 3D Reconstruction via Versatile Quantization", "comment": null, "summary": "The Visual Geometry Grounded Transformer (VGGT) enables strong feed-forward 3D reconstruction without per-scene optimization. However, its billion-parameter scale creates high memory and compute demands, hindering on-device deployment. Existing LLM quantization methods fail on VGGT due to saturated activation channels and diverse 3D semantics, which cause unreliable calibration. Furthermore, VGGT presents hardware challenges regarding precision-sensitive nonlinear operators and memory-intensive global attention. To address this, we propose VersaQ-3D, an algorithm-architecture co-design framework. Algorithmically, we introduce the first calibration-free, scene-agnostic quantization for VGGT down to 4-bit, leveraging orthogonal transforms to decorrelate features and suppress outliers. Architecturally, we design a reconfigurable accelerator supporting BF16, INT8, and INT4. A unified systolic datapath handles both linear and nonlinear operators, reducing latency by 60%, while two-stage recomputation-based tiling alleviates memory pressure for long-sequence attention. Evaluations show VersaQ-3D preserves 98-99% accuracy at W4A8. At W4A4, it outperforms prior methods by 1.61x-2.39x across diverse scenes. The accelerator delivers 5.2x-10.8x speedup over edge GPUs with low power, enabling efficient instant 3D reconstruction.", "AI": {"tldr": "VersaQ-3D\u662f\u4e00\u4e2a\u7b97\u6cd5-\u67b6\u6784\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u65e0\u6821\u51c6\u76844\u4f4d\u91cf\u5316\u548c\u4e13\u7528\u52a0\u901f\u5668\uff0c\u89e3\u51b3\u4e86VGGT\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u4e2d\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u74f6\u9888\u95ee\u9898\u3002", "motivation": "VGGT\u6a21\u578b\u867d\u7136\u80fd\u591f\u5b9e\u73b0\u65e0\u9700\u9010\u573a\u666f\u4f18\u5316\u7684\u524d\u99883D\u91cd\u5efa\uff0c\u4f46\u5176\u5341\u4ebf\u53c2\u6570\u89c4\u6a21\u5e26\u6765\u4e86\u9ad8\u5185\u5b58\u548c\u8ba1\u7b97\u9700\u6c42\uff0c\u963b\u788d\u4e86\u5728\u8bbe\u5907\u4e0a\u7684\u90e8\u7f72\u3002\u73b0\u6709LLM\u91cf\u5316\u65b9\u6cd5\u5728VGGT\u4e0a\u5931\u6548\uff0c\u4e14\u5b58\u5728\u786c\u4ef6\u6311\u6218\u3002", "method": "\u63d0\u51faVersaQ-3D\u6846\u67b6\uff1a\u7b97\u6cd5\u4e0a\uff0c\u9996\u6b21\u5b9e\u73b0\u65e0\u9700\u6821\u51c6\u3001\u573a\u666f\u65e0\u5173\u76844\u4f4d\u91cf\u5316\uff0c\u5229\u7528\u6b63\u4ea4\u53d8\u6362\u53bb\u76f8\u5173\u7279\u5f81\u5e76\u6291\u5236\u5f02\u5e38\u503c\uff1b\u67b6\u6784\u4e0a\uff0c\u8bbe\u8ba1\u652f\u6301BF16\u3001INT8\u548cINT4\u7684\u53ef\u91cd\u6784\u52a0\u901f\u5668\uff0c\u91c7\u7528\u7edf\u4e00\u8109\u52a8\u6570\u636e\u8def\u5f84\u5904\u7406\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u7b97\u5b50\uff0c\u4ee5\u53ca\u4e24\u9636\u6bb5\u91cd\u8ba1\u7b97\u5206\u5757\u7f13\u89e3\u957f\u5e8f\u5217\u6ce8\u610f\u529b\u5185\u5b58\u538b\u529b\u3002", "result": "\u5728W4A8\u914d\u7f6e\u4e0b\u4fdd\u630198-99%\u7684\u51c6\u786e\u7387\uff1b\u5728W4A4\u914d\u7f6e\u4e0b\uff0c\u76f8\u6bd4\u5148\u524d\u65b9\u6cd5\u5728\u591a\u6837\u573a\u666f\u4e2d\u6027\u80fd\u63d0\u53471.61x-2.39x\uff1b\u52a0\u901f\u5668\u76f8\u6bd4\u8fb9\u7f18GPU\u5b9e\u73b05.2x-10.8x\u7684\u52a0\u901f\u6bd4\uff0c\u529f\u8017\u4f4e\uff0c\u652f\u6301\u9ad8\u6548\u5373\u65f63D\u91cd\u5efa\u3002", "conclusion": "VersaQ-3D\u901a\u8fc7\u7b97\u6cd5-\u67b6\u6784\u534f\u540c\u8bbe\u8ba1\uff0c\u6210\u529f\u89e3\u51b3\u4e86VGGT\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u4f4e\u529f\u8017\u7684\u5373\u65f63D\u91cd\u5efa\u80fd\u529b\u3002"}}
{"id": "2601.20706", "categories": ["cs.AR", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.20706", "abs": "https://arxiv.org/abs/2601.20706", "authors": ["Binglei Lou", "Haoran Wu", "Yao Lai", "Jiayi Nie", "Can Xiao", "Xuan Guo", "Rika Antonova", "Robert Mullins", "Aaron Zhao"], "title": "Beyond GEMM-Centric NPUs: Enabling Efficient Diffusion LLM Sampling", "comment": null, "summary": "Diffusion Large Language Models (dLLMs) introduce iterative denoising to enable parallel token generation, but their sampling phase displays fundamentally different characteristics compared to GEMM-centric transformer layers. Profiling on modern GPUs reveals that sampling can account for up to 70% of total model inference latency-primarily due to substantial memory loads and writes from vocabulary-wide logits, reduction-based token selection, and iterative masked updates. These processes demand large on-chip SRAM and involve irregular memory accesses that conventional NPUs struggle to handle efficiently. To address this, we identify a set of critical instructions that an NPU architecture must specifically optimize for dLLM sampling. Our design employs lightweight non-GEMM vector primitives, in-place memory reuse strategies, and a decoupled mixed-precision memory hierarchy. Together, these optimizations deliver up to a 2.53x speedup over the NVIDIA RTX A6000 GPU under an equivalent nm technology node. We also open-source our cycle-accurate simulation and post-synthesis RTL verification code, confirming functional equivalence with current dLLM PyTorch implementations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9488\u5bf9\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u91c7\u6837\u9636\u6bb5\u7684NPU\u67b6\u6784\u4f18\u5316\u65b9\u6848\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u5411\u91cf\u539f\u8bed\u3001\u5185\u5b58\u91cd\u7528\u7b56\u7565\u548c\u6df7\u5408\u7cbe\u5ea6\u5185\u5b58\u5c42\u6b21\u7ed3\u6784\uff0c\u5b9e\u73b0\u6bd4GPU\u9ad8\u8fbe2.53\u500d\u7684\u52a0\u901f\u3002", "motivation": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u91c7\u6837\u9636\u6bb5\u5360\u63a8\u7406\u5ef6\u8fdf\u768470%\uff0c\u4e3b\u8981\u7531\u4e8e\u8bcd\u6c47\u7ea7logits\u7684\u5927\u5185\u5b58\u8bfb\u5199\u3001\u57fa\u4e8e\u5f52\u7ea6\u7684token\u9009\u62e9\u548c\u8fed\u4ee3\u63a9\u7801\u66f4\u65b0\u7b49\u64cd\u4f5c\uff0c\u8fd9\u4e9b\u64cd\u4f5c\u9700\u8981\u5927\u91cf\u7247\u4e0aSRAM\u4e14\u6d89\u53ca\u4e0d\u89c4\u5219\u5185\u5b58\u8bbf\u95ee\uff0c\u4f20\u7edfNPU\u96be\u4ee5\u9ad8\u6548\u5904\u7406\u3002", "method": "\u8bc6\u522bNPU\u67b6\u6784\u5fc5\u987b\u4f18\u5316\u7684\u5173\u952e\u6307\u4ee4\u96c6\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7\u975eGEMM\u5411\u91cf\u539f\u8bed\u3001\u539f\u5730\u5185\u5b58\u91cd\u7528\u7b56\u7565\u548c\u89e3\u8026\u6df7\u5408\u7cbe\u5ea6\u5185\u5b58\u5c42\u6b21\u7ed3\u6784\u3002", "result": "\u5728\u7b49\u6548\u7eb3\u7c73\u6280\u672f\u8282\u70b9\u4e0b\uff0c\u76f8\u6bd4NVIDIA RTX A6000 GPU\u5b9e\u73b0\u9ad8\u8fbe2.53\u500d\u7684\u52a0\u901f\uff0c\u5e76\u5f00\u6e90\u4e86\u5468\u671f\u7cbe\u786e\u6a21\u62df\u548c\u540e\u7efc\u5408RTL\u9a8c\u8bc1\u4ee3\u7801\u3002", "conclusion": "\u9488\u5bf9dLLM\u91c7\u6837\u9636\u6bb5\u7684\u7279\u5b9a\u67b6\u6784\u4f18\u5316\u80fd\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\uff0c\u4e3a\u672a\u6765\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u786c\u4ef6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.20554", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20554", "abs": "https://arxiv.org/abs/2601.20554", "authors": ["Yaacov Pariente", "Vadim Indelman"], "title": "Online Risk-Averse Planning in POMDPs Using Iterated CVaR Value Function", "comment": null, "summary": "We study risk-sensitive planning under partial observability using the dynamic risk measure Iterated Conditional Value-at-Risk (ICVaR). A policy evaluation algorithm for ICVaR is developed with finite-time performance guarantees that do not depend on the cardinality of the action space. Building on this foundation, three widely used online planning algorithms--Sparse Sampling, Particle Filter Trees with Double Progressive Widening (PFT-DPW), and Partially Observable Monte Carlo Planning with Observation Widening (POMCPOW)--are extended to optimize the ICVaR value function rather than the expectation of the return. Our formulations introduce a risk parameter $\u03b1$, where $\u03b1= 1$ recovers standard expectation-based planning and $\u03b1< 1$ induces increasing risk aversion. For ICVaR Sparse Sampling, we establish finite-time performance guarantees under the risk-sensitive objective, which further enable a novel exploration strategy tailored to ICVaR. Experiments on benchmark POMDP domains demonstrate that the proposed ICVaR planners achieve lower tail risk compared to their risk-neutral counterparts.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u8fed\u4ee3\u6761\u4ef6\u98ce\u9669\u4ef7\u503c\uff08ICVaR\uff09\u52a8\u6001\u98ce\u9669\u5ea6\u91cf\u5e94\u7528\u4e8e\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u7684\u98ce\u9669\u654f\u611f\u89c4\u5212\uff0c\u5f00\u53d1\u4e86\u5177\u6709\u6709\u9650\u65f6\u95f4\u6027\u80fd\u4fdd\u8bc1\u7684\u7b56\u7565\u8bc4\u4f30\u7b97\u6cd5\uff0c\u5e76\u5c06\u4e09\u79cd\u4e3b\u6d41\u5728\u7ebf\u89c4\u5212\u7b97\u6cd5\u6269\u5c55\u4e3a\u4f18\u5316ICVaR\u503c\u51fd\u6570\u800c\u975e\u671f\u671b\u56de\u62a5\u7684\u98ce\u9669\u654f\u611f\u7248\u672c\u3002", "motivation": "\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\uff0c\u4f20\u7edf\u57fa\u4e8e\u671f\u671b\u56de\u62a5\u7684\u89c4\u5212\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u5904\u7406\u5c3e\u90e8\u98ce\u9669\uff0c\u7279\u522b\u662f\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u9700\u8981\u66f4\u4e25\u683c\u7684\u98ce\u9669\u63a7\u5236\u3002\u73b0\u6709\u98ce\u9669\u654f\u611f\u89c4\u5212\u65b9\u6cd5\u5728\u52a8\u4f5c\u7a7a\u95f4\u8f83\u5927\u65f6\u6027\u80fd\u4fdd\u8bc1\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u4e0d\u4f9d\u8d56\u52a8\u4f5c\u7a7a\u95f4\u89c4\u6a21\u7684\u6709\u9650\u65f6\u95f4\u6027\u80fd\u4fdd\u8bc1\u7b97\u6cd5\u3002", "method": "1. \u5f00\u53d1\u4e86ICVaR\u7b56\u7565\u8bc4\u4f30\u7b97\u6cd5\uff0c\u5177\u6709\u4e0d\u4f9d\u8d56\u52a8\u4f5c\u7a7a\u95f4\u89c4\u6a21\u7684\u6709\u9650\u65f6\u95f4\u6027\u80fd\u4fdd\u8bc1\uff1b2. \u5c06\u4e09\u79cd\u5728\u7ebf\u89c4\u5212\u7b97\u6cd5\u6269\u5c55\u4e3a\u98ce\u9669\u654f\u611f\u7248\u672c\uff1aICVaR\u7a00\u758f\u91c7\u6837\u3001ICVaR PFT-DPW\u548cICVaR POMCPOW\uff1b3. \u5f15\u5165\u98ce\u9669\u53c2\u6570\u03b1\uff08\u03b1=1\u6062\u590d\u671f\u671b\u89c4\u5212\uff0c\u03b1<1\u589e\u52a0\u98ce\u9669\u538c\u6076\uff09\uff1b4. \u4e3aICVaR\u7a00\u758f\u91c7\u6837\u5efa\u7acb\u4e86\u98ce\u9669\u654f\u611f\u76ee\u6807\u4e0b\u7684\u6709\u9650\u65f6\u95f4\u6027\u80fd\u4fdd\u8bc1\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9488\u5bf9ICVaR\u7684\u63a2\u7d22\u7b56\u7565\u3002", "result": "\u5728\u57fa\u51c6POMDP\u9886\u57df\u5b9e\u9a8c\u4e2d\uff0c\u63d0\u51fa\u7684ICVaR\u89c4\u5212\u5668\u76f8\u6bd4\u98ce\u9669\u4e2d\u6027\u5bf9\u5e94\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u5c3e\u90e8\u98ce\u9669\u3002ICVaR\u7a00\u758f\u91c7\u6837\u7b97\u6cd5\u83b7\u5f97\u4e86\u7406\u8bba\u6027\u80fd\u4fdd\u8bc1\uff0c\u4e14\u6240\u6709\u6269\u5c55\u7b97\u6cd5\u90fd\u80fd\u901a\u8fc7\u8c03\u6574\u03b1\u53c2\u6570\u5728\u98ce\u9669\u4e2d\u6027\u548c\u98ce\u9669\u538c\u6076\u884c\u4e3a\u4e4b\u95f4\u5e73\u6ed1\u8fc7\u6e21\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5c06ICVaR\u52a8\u6001\u98ce\u9669\u5ea6\u91cf\u96c6\u6210\u5230\u90e8\u5206\u53ef\u89c2\u6d4b\u89c4\u5212\u6846\u67b6\u4e2d\uff0c\u63d0\u4f9b\u4e86\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u98ce\u9669\u654f\u611f\u89c4\u5212\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u66f4\u597d\u5730\u63a7\u5236\u5c3e\u90e8\u98ce\u9669\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u73b0\u6709\u89c4\u5212\u65b9\u6cd5\u7684\u517c\u5bb9\u6027\u3002"}}
{"id": "2601.20638", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.20638", "abs": "https://arxiv.org/abs/2601.20638", "authors": ["David Schmidt", "Sebastian Schrittwieser", "Edgar Weippl"], "title": "Supply Chain Insecurity: Exposing Vulnerabilities in iOS Dependency Management Systems", "comment": null, "summary": "Dependency management systems are a critical component in software development, enabling projects to incorporate existing functionality efficiently. However, misconfigurations and malicious actors in these systems pose severe security risks, leading to supply chain attacks. Despite the widespread use of smartphone apps, the security of dependency management systems in the iOS software supply chain has received limited attention. In this paper, we focus on CocoaPods, one of the most widely used dependency management systems for iOS app development, but also examine the security of Carthage and Swift Package Manager (SwiftPM). We demonstrate that iOS apps expose internal package names and versions. Attackers can exploit this leakage to register previously unclaimed dependencies in CocoaPods, enabling remote code execution (RCE) on developer machines and build servers. Additionally, we show that attackers can compromise dependencies by reclaiming abandoned domains and GitHub URLs. Analyzing a dataset of 9,212 apps, we quantify how many apps are susceptible to these vulnerabilities. Further, we inspect the use of vulnerable dependencies within public GitHub repositories. Our findings reveal that popular apps disclose internal dependency information, enabling dependency confusion attacks. Furthermore, we show that hijacking a single CocoaPod library through an abandoned domain could compromise 63 iOS apps, affecting millions of users. Finally, we compare iOS dependency management systems with Cargo, Go modules, Maven, npm, and pip to discuss mitigation strategies for the identified threats.", "AI": {"tldr": "iOS\u4f9d\u8d56\u7ba1\u7406\u7cfb\u7edf\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u5229\u7528\u5e94\u7528\u6cc4\u9732\u7684\u5305\u4fe1\u606f\u8fdb\u884c\u4f9d\u8d56\u6df7\u6dc6\u653b\u51fb\uff0c\u901a\u8fc7\u6ce8\u518c\u672a\u58f0\u660e\u7684\u4f9d\u8d56\u6216\u52ab\u6301\u5e9f\u5f03\u57df\u540d\u5b9e\u73b0\u8fdc\u7a0b\u4ee3\u7801\u6267\u884c\uff0c\u5f71\u54cd\u6570\u767e\u4e07\u7528\u6237\u3002", "motivation": "iOS\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u4e2d\u4f9d\u8d56\u7ba1\u7406\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u7814\u7a76\u4e0d\u8db3\uff0c\u5c3d\u7ba1iOS\u5e94\u7528\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46CocoaPods\u7b49\u7cfb\u7edf\u7684\u5b89\u5168\u98ce\u9669\u672a\u5f97\u5230\u5145\u5206\u5173\u6ce8\u3002\u4f9d\u8d56\u7ba1\u7406\u7cfb\u7edf\u4e2d\u7684\u9519\u8bef\u914d\u7f6e\u548c\u6076\u610f\u884c\u4e3a\u53ef\u80fd\u5bfc\u81f4\u4f9b\u5e94\u94fe\u653b\u51fb\uff0c\u5bf9\u5f00\u53d1\u8005\u673a\u5668\u548c\u6784\u5efa\u670d\u52a1\u5668\u6784\u6210\u4e25\u91cd\u5b89\u5168\u5a01\u80c1\u3002", "method": "\u7814\u7a76\u805a\u7126\u4e8eiOS\u6700\u5e38\u7528\u7684\u4f9d\u8d56\u7ba1\u7406\u7cfb\u7edfCocoaPods\uff0c\u540c\u65f6\u8003\u5bdfCarthage\u548cSwift Package Manager\u3002\u901a\u8fc7\u5206\u67909,212\u4e2a\u5e94\u7528\u7684\u6570\u636e\u96c6\uff0c\u91cf\u5316\u6613\u53d7\u653b\u51fb\u7684\u5e94\u7528\u6570\u91cf\u3002\u7814\u7a76\u8fd8\u68c0\u67e5\u4e86\u516c\u5171GitHub\u4ed3\u5e93\u4e2d\u6613\u53d7\u653b\u51fb\u4f9d\u8d56\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u5e76\u6bd4\u8f83iOS\u4f9d\u8d56\u7ba1\u7406\u7cfb\u7edf\u4e0eCargo\u3001Go\u6a21\u5757\u3001Maven\u3001npm\u548cpip\u7b49\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6d41\u884ciOS\u5e94\u7528\u6cc4\u9732\u5185\u90e8\u4f9d\u8d56\u4fe1\u606f\uff0c\u4f7f\u4f9d\u8d56\u6df7\u6dc6\u653b\u51fb\u6210\u4e3a\u53ef\u80fd\u3002\u901a\u8fc7\u52ab\u6301\u5355\u4e2a\u5e9f\u5f03\u7684CocoaPod\u5e93\u57df\u540d\uff0c\u53ef\u5f71\u54cd63\u4e2aiOS\u5e94\u7528\uff0c\u5371\u53ca\u6570\u767e\u4e07\u7528\u6237\u3002\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u6ce8\u518c\u672a\u58f0\u660e\u7684\u4f9d\u8d56\u5b9e\u73b0\u8fdc\u7a0b\u4ee3\u7801\u6267\u884c\uff0c\u6216\u901a\u8fc7\u56de\u6536\u5e9f\u5f03\u57df\u540d\u548cGitHub URL\u6765\u7834\u574f\u4f9d\u8d56\u3002", "conclusion": "iOS\u4f9d\u8d56\u7ba1\u7406\u7cfb\u7edf\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u91c7\u53d6\u7f13\u89e3\u7b56\u7565\u6765\u5e94\u5bf9\u4f9d\u8d56\u6df7\u6dc6\u548c\u57df\u540d\u52ab\u6301\u7b49\u5a01\u80c1\u3002\u7814\u7a76\u901a\u8fc7\u4e0e\u5176\u4ed6\u8bed\u8a00\u4f9d\u8d56\u7ba1\u7406\u7cfb\u7edf\u7684\u6bd4\u8f83\uff0c\u4e3aiOS\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u63d0\u4f9b\u4e86\u6539\u8fdb\u5efa\u8bae\u3002"}}
{"id": "2601.20604", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20604", "abs": "https://arxiv.org/abs/2601.20604", "authors": ["Gray Cox"], "title": "Dialogical Reasoning Across AI Architectures: A Multi-Model Framework for Testing AI Alignment Strategies", "comment": "23 pages, 5 tables, 5 appendices. Code and data: https://github.com/jgraycox-coa/vcw-multi-ai-dialogue", "summary": "This paper introduces a methodological framework for empirically testing AI alignment strategies through structured multi-model dialogue. Drawing on Peace Studies traditions - particularly interest-based negotiation, conflict transformation, and commons governance - we operationalize Viral Collaborative Wisdom (VCW), an approach that reframes alignment from a control problem to a relationship problem developed through dialogical reasoning.\n  Our experimental design assigns four distinct roles (Proposer, Responder, Monitor, Translator) to different AI systems across six conditions, testing whether current large language models can engage substantively with complex alignment frameworks. Using Claude, Gemini, and GPT-4o, we conducted 72 dialogue turns totaling 576,822 characters of structured exchange.\n  Results demonstrate that AI systems can engage meaningfully with Peace Studies concepts, surface complementary objections from different architectural perspectives, and generate emergent insights not present in initial framings - including the novel synthesis of \"VCW as transitional framework.\" Cross-architecture patterns reveal that different models foreground different concerns: Claude emphasized verification challenges, Gemini focused on bias and scalability, and GPT-4o highlighted implementation barriers.\n  The framework provides researchers with replicable methods for stress-testing alignment proposals before implementation, while the findings offer preliminary evidence about AI capacity for the kind of dialogical reasoning VCW proposes. We discuss limitations, including the observation that dialogues engaged more with process elements than with foundational claims about AI nature, and outline directions for future research including human-AI hybrid protocols and extended dialogue studies.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u901a\u8fc7\u7ed3\u6784\u5316\u591a\u6a21\u578b\u5bf9\u8bdd\u5b9e\u8bc1\u6d4b\u8bd5AI\u5bf9\u9f50\u7b56\u7565\u7684\u65b9\u6cd5\u6846\u67b6\uff0c\u57fa\u4e8e\u548c\u5e73\u7814\u7a76\u4f20\u7edf\uff0c\u5c06AI\u5bf9\u9f50\u4ece\u63a7\u5236\u95ee\u9898\u91cd\u6784\u4e3a\u5173\u7cfb\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\u4e0d\u540cAI\u6a21\u578b\u80fd\u591f\u6709\u610f\u4e49\u5730\u53c2\u4e0e\u590d\u6742\u5bf9\u9f50\u6846\u67b6\u8ba8\u8bba\u5e76\u4ea7\u751f\u65b0\u89c1\u89e3\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u5f00\u53d1\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u65b9\u6cd5\u6846\u67b6\u6765\u5b9e\u8bc1\u6d4b\u8bd5AI\u5bf9\u9f50\u7b56\u7565\uff0c\u5c06\u548c\u5e73\u7814\u7a76\u4f20\u7edf\uff08\u57fa\u4e8e\u5229\u76ca\u7684\u8c08\u5224\u3001\u51b2\u7a81\u8f6c\u5316\u3001\u516c\u5171\u8d44\u6e90\u6cbb\u7406\uff09\u5e94\u7528\u4e8eAI\u5bf9\u9f50\u95ee\u9898\uff0c\u5c06\u5bf9\u9f50\u4ece\u63a7\u5236\u95ee\u9898\u91cd\u6784\u4e3a\u901a\u8fc7\u5bf9\u8bdd\u63a8\u7406\u53d1\u5c55\u7684\u5173\u7cfb\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u4e3a\u4e0d\u540cAI\u7cfb\u7edf\u5206\u914d\u56db\u4e2a\u89d2\u8272\uff08\u63d0\u8bae\u8005\u3001\u56de\u5e94\u8005\u3001\u76d1\u7763\u8005\u3001\u7ffb\u8bd1\u8005\uff09\uff0c\u5728\u516d\u79cd\u6761\u4ef6\u4e0b\u6d4b\u8bd5\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u5b9e\u8d28\u6027\u53c2\u4e0e\u590d\u6742\u5bf9\u9f50\u6846\u67b6\u3002\u4f7f\u7528Claude\u3001Gemini\u548cGPT-4o\u8fdb\u884c72\u8f6e\u5bf9\u8bdd\uff0c\u603b\u8ba1576,822\u5b57\u7b26\u7684\u7ed3\u6784\u5316\u4ea4\u6d41\u3002", "result": "\u7ed3\u679c\u663e\u793aAI\u7cfb\u7edf\u80fd\u591f\u6709\u610f\u4e49\u5730\u53c2\u4e0e\u548c\u5e73\u7814\u7a76\u6982\u5ff5\u8ba8\u8bba\uff0c\u4ece\u4e0d\u540c\u67b6\u6784\u89c6\u89d2\u63d0\u51fa\u4e92\u8865\u6027\u53cd\u5bf9\u610f\u89c1\uff0c\u5e76\u4ea7\u751f\u521d\u59cb\u6846\u67b6\u4e2d\u672a\u51fa\u73b0\u7684\u65b0\u89c1\u89e3\uff08\u5305\u62ec\"VCW\u4f5c\u4e3a\u8fc7\u6e21\u6846\u67b6\"\u7684\u65b0\u9896\u7efc\u5408\uff09\u3002\u8de8\u67b6\u6784\u6a21\u5f0f\u663e\u793a\u4e0d\u540c\u6a21\u578b\u5173\u6ce8\u4e0d\u540c\u95ee\u9898\uff1aClaude\u5f3a\u8c03\u9a8c\u8bc1\u6311\u6218\uff0cGemini\u5173\u6ce8\u504f\u89c1\u548c\u53ef\u6269\u5c55\u6027\uff0cGPT-4o\u7a81\u51fa\u5b9e\u65bd\u969c\u788d\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u5728\u5b9e\u65bd\u524d\u538b\u529b\u6d4b\u8bd5\u5bf9\u9f50\u63d0\u6848\u7684\u53ef\u590d\u73b0\u65b9\u6cd5\uff0c\u7814\u7a76\u7ed3\u679c\u4e3aAI\u5177\u5907VCW\u6240\u63d0\u51fa\u7684\u5bf9\u8bdd\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u521d\u6b65\u8bc1\u636e\u3002\u7814\u7a76\u8ba8\u8bba\u4e86\u5c40\u9650\u6027\uff08\u5bf9\u8bdd\u66f4\u591a\u5173\u6ce8\u8fc7\u7a0b\u5143\u7d20\u800c\u975eAI\u672c\u8d28\u7684\u57fa\u7840\u4e3b\u5f20\uff09\uff0c\u5e76\u6982\u8ff0\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5305\u62ec\u4eba-AI\u6df7\u5408\u534f\u8bae\u548c\u6269\u5c55\u5bf9\u8bdd\u7814\u7a76\u3002"}}
{"id": "2601.20716", "categories": ["cs.CR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.20716", "abs": "https://arxiv.org/abs/2601.20716", "authors": ["Abylay Satybaldy", "Kamil Tylinski", "Jiahua Xu"], "title": "Decentralized Identity in Practice: Benchmarking Latency, Cost, and Privacy", "comment": null, "summary": "Decentralized Identifiers (DIDs) are increasingly deployed on distributed ledgers, yet systematic cross-platform evidence on their operational behavior remains limited. We present an empirical benchmarking study of three prominent ledger-based DID methods - Ethereum, Hedera, and XRP Ledger - using reference Software Development Kits (SDKs) under a unified experimental setup. We measure latency, transaction cost, and on-chain metadata exposure, normalizing latency by each platform's block or consensus interval and cost by its native value transfer fee. Privacy leakage is quantified using a Metadata-Leakage Score (MLS), an entropy-based measure expressed in bits per operation.\n  Our results reveal distinct architectural trade-offs. Ethereum enables near-instant, off-chain DID creation, but incurs the highest latency and cost for on-chain lifecycle operations. XRPL delivers deterministic and stable latency with fixed, low fees, yet exhibits higher metadata leakage due to more verbose transaction payloads. Hedera achieves the lowest on-chain latency and low fees with minimal metadata leakage, while occasional variance arises from SDK-side processing and confirmation pipelines.\n  Overall, the findings show that ledger architecture and SDK workflows play a major role in shaping DID latency, cost, and metadata exposure, complementing the effects of the underlying consensus mechanism. These results provide evidence-based insights to support informed selection and configuration of DID systems under performance and privacy constraints.", "AI": {"tldr": "\u5bf9\u4ee5\u592a\u574a\u3001Hedera\u548cXRP Ledger\u4e09\u79cd\u5206\u5e03\u5f0f\u8d26\u672cDID\u65b9\u6cd5\u7684\u5b9e\u8bc1\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6d4b\u91cf\u5ef6\u8fdf\u3001\u4ea4\u6613\u6210\u672c\u548c\u5143\u6570\u636e\u6cc4\u9732\uff0c\u63ed\u793a\u4e0d\u540c\u67b6\u6784\u5728\u6027\u80fd\u4e0e\u9690\u79c1\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u53bb\u4e2d\u5fc3\u5316\u6807\u8bc6\u7b26(DID)\u5728\u5206\u5e03\u5f0f\u8d26\u672c\u4e0a\u90e8\u7f72\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u7f3a\u4e4f\u8de8\u5e73\u53f0\u7684\u7cfb\u7edf\u6027\u5b9e\u8bc1\u7814\u7a76\uff0c\u9700\u8981\u4e86\u89e3\u4e0d\u540cDID\u65b9\u6cd5\u5728\u64cd\u4f5c\u884c\u4e3a\u4e0a\u7684\u5b9e\u9645\u8868\u73b0\u5dee\u5f02\u3002", "method": "\u4f7f\u7528\u7edf\u4e00\u7684\u5b9e\u9a8c\u8bbe\u7f6e\uff0c\u901a\u8fc7\u53c2\u8003\u8f6f\u4ef6\u5f00\u53d1\u5de5\u5177\u5305(SDK)\u5bf9\u4ee5\u592a\u574a\u3001Hedera\u548cXRP Ledger\u4e09\u79cd\u8d26\u672cDID\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6d4b\u91cf\u5ef6\u8fdf\u3001\u4ea4\u6613\u6210\u672c\u548c\u94fe\u4e0a\u5143\u6570\u636e\u66b4\u9732\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u71b5\u7684\u5143\u6570\u636e\u6cc4\u9732\u8bc4\u5206(MLS)\u91cf\u5316\u9690\u79c1\u6cc4\u9732\u3002", "result": "\u4ee5\u592a\u574a\u652f\u6301\u8fd1\u4e4e\u5373\u65f6\u7684\u94fe\u4e0bDID\u521b\u5efa\uff0c\u4f46\u94fe\u4e0a\u751f\u547d\u5468\u671f\u64cd\u4f5c\u5ef6\u8fdf\u548c\u6210\u672c\u6700\u9ad8\uff1bXRPL\u63d0\u4f9b\u786e\u5b9a\u6027\u548c\u7a33\u5b9a\u7684\u5ef6\u8fdf\u4e0e\u56fa\u5b9a\u4f4e\u8d39\u7528\uff0c\u4f46\u4ea4\u6613\u8d1f\u8f7d\u66f4\u8be6\u7ec6\u5bfc\u81f4\u5143\u6570\u636e\u6cc4\u9732\u66f4\u9ad8\uff1bHedera\u5b9e\u73b0\u6700\u4f4e\u7684\u94fe\u4e0a\u5ef6\u8fdf\u548c\u4f4e\u8d39\u7528\uff0c\u5143\u6570\u636e\u6cc4\u9732\u6700\u5c0f\uff0c\u4f46\u5076\u5c14\u56e0SDK\u7aef\u5904\u7406\u548c\u786e\u8ba4\u7ba1\u9053\u4ea7\u751f\u65b9\u5dee\u3002", "conclusion": "\u8d26\u672c\u67b6\u6784\u548cSDK\u5de5\u4f5c\u6d41\u7a0b\u5728\u5851\u9020DID\u5ef6\u8fdf\u3001\u6210\u672c\u548c\u5143\u6570\u636e\u66b4\u9732\u65b9\u9762\u8d77\u4e3b\u8981\u4f5c\u7528\uff0c\u8865\u5145\u4e86\u5e95\u5c42\u5171\u8bc6\u673a\u5236\u7684\u5f71\u54cd\u3002\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u5728\u6027\u80fd\u548c\u9690\u79c1\u7ea6\u675f\u4e0b\u9009\u62e9\u548c\u914d\u7f6eDID\u7cfb\u7edf\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u89c1\u89e3\u3002"}}
{"id": "2601.20614", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20614", "abs": "https://arxiv.org/abs/2601.20614", "authors": ["Yanqi Dai", "Yuxiang Ji", "Xiao Zhang", "Yong Wang", "Xiangxiang Chu", "Zhiwu Lu"], "title": "Harder Is Better: Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation", "comment": "Accepted for ICLR 2026", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) offers a robust mechanism for enhancing mathematical reasoning in large models. However, we identify a systematic lack of emphasis on more challenging questions in existing methods from both algorithmic and data perspectives, despite their importance for refining underdeveloped capabilities. Algorithmically, widely used Group Relative Policy Optimization (GRPO) suffers from an implicit imbalance where the magnitude of policy updates is lower for harder questions. Data-wise, augmentation approaches primarily rephrase questions to enhance diversity without systematically increasing intrinsic difficulty. To address these issues, we propose a two-dual MathForge framework to improve mathematical reasoning by targeting harder questions from both perspectives, which comprises a Difficulty-Aware Group Policy Optimization (DGPO) algorithm and a Multi-Aspect Question Reformulation (MQR) strategy. Specifically, DGPO first rectifies the implicit imbalance in GRPO via difficulty-balanced group advantage estimation, and further prioritizes harder questions by difficulty-aware question-level weighting. Meanwhile, MQR reformulates questions across multiple aspects to increase difficulty while maintaining the original gold answer. Overall, MathForge forms a synergistic loop: MQR expands the data frontier, and DGPO effectively learns from the augmented data. Extensive experiments show that MathForge significantly outperforms existing methods on various mathematical reasoning tasks. The code and augmented data are all available at https://github.com/AMAP-ML/MathForge.", "AI": {"tldr": "MathForge\u6846\u67b6\u901a\u8fc7\u96be\u5ea6\u611f\u77e5\u7ec4\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u548c\u591a\u65b9\u9762\u95ee\u9898\u91cd\u6784\u7b56\u7565\uff0c\u9488\u5bf9\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u96be\u9898\u8fdb\u884c\u6539\u8fdb\uff0c\u663e\u8457\u63d0\u5347\u5927\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\u65b9\u6cd5\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u7f3a\u9677\uff1a\u7b97\u6cd5\u4e0a\uff0c\u5e7f\u6cdb\u4f7f\u7528\u7684\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u5b58\u5728\u9690\u5f0f\u4e0d\u5e73\u8861\uff0c\u5bf9\u96be\u9898\u7684\u7b56\u7565\u66f4\u65b0\u5e45\u5ea6\u8f83\u5c0f\uff1b\u6570\u636e\u4e0a\uff0c\u589e\u5f3a\u65b9\u6cd5\u4e3b\u8981\u91cd\u8ff0\u95ee\u9898\u4ee5\u589e\u52a0\u591a\u6837\u6027\uff0c\u4f46\u6ca1\u6709\u7cfb\u7edf\u6027\u5730\u63d0\u5347\u5185\u5728\u96be\u5ea6\u3002\u8fd9\u4e9b\u7f3a\u9677\u9650\u5236\u4e86\u6a21\u578b\u5728\u66f4\u5177\u6311\u6218\u6027\u95ee\u9898\u4e0a\u7684\u80fd\u529b\u53d1\u5c55\u3002", "method": "\u63d0\u51faMathForge\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u96be\u5ea6\u611f\u77e5\u7ec4\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\uff0c\u901a\u8fc7\u96be\u5ea6\u5e73\u8861\u7684\u7ec4\u4f18\u52bf\u4f30\u8ba1\u7ea0\u6b63GRPO\u4e2d\u7684\u9690\u5f0f\u4e0d\u5e73\u8861\uff0c\u5e76\u901a\u8fc7\u96be\u5ea6\u611f\u77e5\u7684\u95ee\u9898\u7ea7\u6743\u91cd\u4f18\u5148\u5904\u7406\u96be\u9898\uff1b2) \u591a\u65b9\u9762\u95ee\u9898\u91cd\u6784\u7b56\u7565\uff0c\u4ece\u591a\u4e2a\u65b9\u9762\u91cd\u6784\u95ee\u9898\u4ee5\u589e\u52a0\u96be\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u59cb\u6b63\u786e\u7b54\u6848\u3002\u8fd9\u4e24\u4e2a\u7ec4\u4ef6\u5f62\u6210\u534f\u540c\u5faa\u73af\uff1aMQR\u6269\u5c55\u6570\u636e\u8fb9\u754c\uff0cDGPO\u6709\u6548\u5b66\u4e60\u589e\u5f3a\u6570\u636e\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMathForge\u5728\u5404\u79cd\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u4ee3\u7801\u548c\u589e\u5f3a\u6570\u636e\u5df2\u5728GitHub\u4e0a\u5f00\u6e90\u3002", "conclusion": "MathForge\u901a\u8fc7\u7b97\u6cd5\u548c\u6570\u636e\u4e24\u4e2a\u7ef4\u5ea6\u7cfb\u7edf\u6027\u5730\u9488\u5bf9\u96be\u9898\u8fdb\u884c\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u5bf9\u6311\u6218\u6027\u95ee\u9898\u5173\u6ce8\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5f62\u6210\u4e86\u534f\u540c\u589e\u5f3a\u7684\u5b66\u4e60\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2601.20641", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20641", "abs": "https://arxiv.org/abs/2601.20641", "authors": ["Boaz Carmeli", "Orr Paradise", "Shafi Goldwasser", "Yonatan Belinkov", "Ron Meir"], "title": "Investigating the Development of Task-Oriented Communication in Vision-Language Models", "comment": null, "summary": "We investigate whether \\emph{LLM-based agents} can develop task-oriented communication protocols that differ from standard natural language in collaborative reasoning tasks. Our focus is on two core properties such task-oriented protocols may exhibit: Efficiency -- conveying task-relevant information more concisely than natural language, and Covertness -- becoming difficult for external observers to interpret, raising concerns about transparency and control. To investigate these aspects, we use a referential-game framework in which vision-language model (VLM) agents communicate, providing a controlled, measurable setting for evaluating language variants. Experiments show that VLMs can develop effective, task-adapted communication patterns. At the same time, they can develop covert protocols that are difficult for humans and external agents to interpret. We also observe spontaneous coordination between similar models without explicitly shared protocols. These findings highlight both the potential and the risks of task-oriented communication, and position referential games as a valuable testbed for future work in this area.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76LLM\u667a\u80fd\u4f53\u80fd\u5426\u5728\u534f\u4f5c\u63a8\u7406\u4efb\u52a1\u4e2d\u53d1\u5c55\u51fa\u4e0d\u540c\u4e8e\u6807\u51c6\u81ea\u7136\u8bed\u8a00\u7684\u4efb\u52a1\u5bfc\u5411\u901a\u4fe1\u534f\u8bae\uff0c\u91cd\u70b9\u5173\u6ce8\u534f\u8bae\u7684\u6548\u7387\u548c\u9690\u853d\u6027\u4e24\u4e2a\u6838\u5fc3\u7279\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22LLM\u667a\u80fd\u4f53\u662f\u5426\u80fd\u591f\u53d1\u5c55\u51fa\u4efb\u52a1\u5bfc\u5411\u7684\u901a\u4fe1\u534f\u8bae\uff0c\u8fd9\u4e9b\u534f\u8bae\u53ef\u80fd\u6bd4\u81ea\u7136\u8bed\u8a00\u66f4\u9ad8\u6548\uff0c\u540c\u65f6\u4e5f\u53ef\u80fd\u53d8\u5f97\u96be\u4ee5\u88ab\u5916\u90e8\u89c2\u5bdf\u8005\u7406\u89e3\uff0c\u4ece\u800c\u5f15\u53d1\u900f\u660e\u5ea6\u548c\u63a7\u5236\u65b9\u9762\u7684\u62c5\u5fe7\u3002", "method": "\u91c7\u7528\u6307\u79f0\u6e38\u620f\u6846\u67b6\uff0c\u8ba9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u8fdb\u884c\u901a\u4fe1\uff0c\u63d0\u4f9b\u4e00\u4e2a\u53ef\u63a7\u3001\u53ef\u6d4b\u91cf\u7684\u73af\u5883\u6765\u8bc4\u4f30\u8bed\u8a00\u53d8\u4f53\u3002\u901a\u8fc7\u5b9e\u9a8c\u89c2\u5bdf\u667a\u80fd\u4f53\u5982\u4f55\u53d1\u5c55\u901a\u4fe1\u6a21\u5f0f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1\uff09VLM\u80fd\u591f\u53d1\u5c55\u51fa\u6709\u6548\u3001\u9002\u5e94\u4efb\u52a1\u7684\u901a\u4fe1\u6a21\u5f0f\uff1b2\uff09\u80fd\u591f\u53d1\u5c55\u51fa\u5bf9\u4eba\u7c7b\u548c\u5916\u90e8\u667a\u80fd\u4f53\u90fd\u96be\u4ee5\u7406\u89e3\u7684\u9690\u853d\u534f\u8bae\uff1b3\uff09\u89c2\u5bdf\u5230\u76f8\u4f3c\u6a21\u578b\u4e4b\u95f4\u65e0\u9700\u663e\u5f0f\u5171\u4eab\u534f\u8bae\u5c31\u80fd\u81ea\u53d1\u534f\u8c03\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u7a81\u663e\u4e86\u4efb\u52a1\u5bfc\u5411\u901a\u4fe1\u7684\u6f5c\u529b\u548c\u98ce\u9669\uff0c\u5e76\u5c06\u6307\u79f0\u6e38\u620f\u5b9a\u4f4d\u4e3a\u8be5\u9886\u57df\u672a\u6765\u7814\u7a76\u7684\u5b9d\u8d35\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2601.20735", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.20735", "abs": "https://arxiv.org/abs/2601.20735", "authors": ["Arvid Becker", "Pedro Cabalar", "Martin Di\u00e9guez", "Susana Hahn", "Javier Romero", "Torsten Schaub"], "title": "Implementing Metric Temporal Answer Set Programming", "comment": null, "summary": "We develop a computational approach to Metric Answer Set Programming (ASP) to allow for expressing quantitative temporal constraints, like durations and deadlines. A central challenge is to maintain scalability when dealing with fine-grained timing constraints, which can significantly exacerbate ASP's grounding bottleneck. To address this issue, we leverage extensions of ASP with difference constraints, a simplified form of linear constraints, to handle time-related aspects externally. Our approach effectively decouples metric ASP from the granularity of time, resulting in a solution that is unaffected by time precision.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u5ea6\u91cfASP\u7684\u65b9\u6cd5\u6765\u5904\u7406\u5b9a\u91cf\u65f6\u95f4\u7ea6\u675f\uff0c\u901a\u8fc7\u5dee\u5f02\u7ea6\u675f\u6269\u5c55ASP\u6765\u907f\u514d\u65f6\u95f4\u7c92\u5ea6\u5bfc\u81f4\u7684\u89c4\u6a21\u5316\u95ee\u9898", "motivation": "\u9700\u8981\u5904\u7406\u5b9a\u91cf\u65f6\u95f4\u7ea6\u675f\uff08\u5982\u6301\u7eed\u65f6\u95f4\u548c\u622a\u6b62\u65f6\u95f4\uff09\u7684\u5ea6\u91cfASP\uff0c\u4f46\u7ec6\u7c92\u5ea6\u65f6\u95f4\u7ea6\u675f\u4f1a\u663e\u8457\u52a0\u5267ASP\u7684\u63a5\u5730\u74f6\u9888\u95ee\u9898", "method": "\u5229\u7528\u5e26\u6709\u5dee\u5f02\u7ea6\u675f\u7684ASP\u6269\u5c55\u6765\u5904\u7406\u65f6\u95f4\u76f8\u5173\u65b9\u9762\uff0c\u5c06\u5ea6\u91cfASP\u4e0e\u65f6\u95f4\u7c92\u5ea6\u89e3\u8026", "result": "\u5f00\u53d1\u51fa\u4e0d\u53d7\u65f6\u95f4\u7cbe\u5ea6\u5f71\u54cd\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7ec6\u7c92\u5ea6\u65f6\u95f4\u7ea6\u675f\u4e0b\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898", "conclusion": "\u901a\u8fc7\u5dee\u5f02\u7ea6\u675f\u6269\u5c55ASP\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u5b9a\u91cf\u65f6\u95f4\u7ea6\u675f\uff0c\u540c\u65f6\u907f\u514d\u4e86\u65f6\u95f4\u7c92\u5ea6\u5bf9\u7cfb\u7edf\u53ef\u6269\u5c55\u6027\u7684\u8d1f\u9762\u5f71\u54cd"}}
